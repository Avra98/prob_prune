Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.2858e-06, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.842214
Average KL loss: 51.205980
Average total loss: 53.048193
tensor(-0.3263, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(2.3036e-06, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.539445
Average KL loss: 43.283579
Average total loss: 44.823023
tensor(-0.6075, device='cuda:0') tensor(0.0950, device='cuda:0') tensor(2.0862e-06, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.328707
Average KL loss: 36.797161
Average total loss: 38.125868
tensor(-0.8654, device='cuda:0') tensor(0.1945, device='cuda:0') tensor(1.8518e-06, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.195685
Average KL loss: 31.636416
Average total loss: 32.832100
tensor(-1.0985, device='cuda:0') tensor(0.3052, device='cuda:0') tensor(1.6975e-06, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.113441
Average KL loss: 27.604928
Average total loss: 28.718368
tensor(-1.3075, device='cuda:0') tensor(0.4152, device='cuda:0') tensor(1.5482e-06, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.041288
Average KL loss: 24.434859
Average total loss: 25.476146
tensor(-1.4953, device='cuda:0') tensor(0.5183, device='cuda:0') tensor(1.3772e-06, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.983985
Average KL loss: 21.899403
Average total loss: 22.883387
tensor(-1.6647, device='cuda:0') tensor(0.6125, device='cuda:0') tensor(1.2520e-06, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.935748
Average KL loss: 19.833767
Average total loss: 20.769514
tensor(-1.8184, device='cuda:0') tensor(0.6975, device='cuda:0') tensor(1.1509e-06, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.874812
Average KL loss: 18.122524
Average total loss: 18.997336
tensor(-1.9588, device='cuda:0') tensor(0.7737, device='cuda:0') tensor(1.0574e-06, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.853488
Average KL loss: 16.678564
Average total loss: 17.532052
tensor(-2.0880, device='cuda:0') tensor(0.8419, device='cuda:0') tensor(1.0042e-06, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.826411
Average KL loss: 15.443607
Average total loss: 16.270018
tensor(-2.2074, device='cuda:0') tensor(0.9032, device='cuda:0') tensor(9.2353e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.795674
Average KL loss: 14.375667
Average total loss: 15.171340
tensor(-2.3183, device='cuda:0') tensor(0.9585, device='cuda:0') tensor(8.4631e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.756798
Average KL loss: 13.443233
Average total loss: 14.200031
tensor(-2.4218, device='cuda:0') tensor(1.0085, device='cuda:0') tensor(8.0595e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.757134
Average KL loss: 12.620784
Average total loss: 13.377918
tensor(-2.5188, device='cuda:0') tensor(1.0540, device='cuda:0') tensor(7.5902e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.732274
Average KL loss: 11.889878
Average total loss: 12.622151
tensor(-2.6100, device='cuda:0') tensor(1.0955, device='cuda:0') tensor(7.3302e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.706229
Average KL loss: 11.236757
Average total loss: 11.942986
tensor(-2.6961, device='cuda:0') tensor(1.1337, device='cuda:0') tensor(6.8779e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.678526
Average KL loss: 10.648519
Average total loss: 11.327044
tensor(-2.7776, device='cuda:0') tensor(1.1687, device='cuda:0') tensor(6.4534e-07, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.682383
Average KL loss: 10.116205
Average total loss: 10.798589
tensor(-2.8549, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(6.1790e-07, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.667043
Average KL loss: 9.633089
Average total loss: 10.300132
tensor(-2.9285, device='cuda:0') tensor(1.2319, device='cuda:0') tensor(5.7920e-07, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.656584
Average KL loss: 9.192422
Average total loss: 9.849005
tensor(-2.9987, device='cuda:0') tensor(1.2604, device='cuda:0') tensor(5.6006e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.645927
Average KL loss: 8.788566
Average total loss: 9.434493
tensor(-3.0657, device='cuda:0') tensor(1.2872, device='cuda:0') tensor(5.2622e-07, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.628530
Average KL loss: 8.417790
Average total loss: 9.046320
tensor(-3.1298, device='cuda:0') tensor(1.3126, device='cuda:0') tensor(4.9079e-07, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.619190
Average KL loss: 8.076343
Average total loss: 8.695533
tensor(-3.1913, device='cuda:0') tensor(1.3366, device='cuda:0') tensor(5.0753e-07, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.616374
Average KL loss: 7.760306
Average total loss: 8.376679
tensor(-3.2504, device='cuda:0') tensor(1.3594, device='cuda:0') tensor(4.8043e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.604985
Average KL loss: 7.467135
Average total loss: 8.072120
tensor(-3.3072, device='cuda:0') tensor(1.3813, device='cuda:0') tensor(4.6585e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.593856
Average KL loss: 7.194880
Average total loss: 7.788736
tensor(-3.3620, device='cuda:0') tensor(1.4022, device='cuda:0') tensor(4.4420e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.589742
Average KL loss: 6.940971
Average total loss: 7.530713
tensor(-3.4149, device='cuda:0') tensor(1.4224, device='cuda:0') tensor(4.2884e-07, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.585291
Average KL loss: 6.703803
Average total loss: 7.289094
tensor(-3.4659, device='cuda:0') tensor(1.4419, device='cuda:0') tensor(4.0310e-07, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.581726
Average KL loss: 6.482873
Average total loss: 7.064598
tensor(-3.5152, device='cuda:0') tensor(1.4610, device='cuda:0') tensor(4.1135e-07, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.572865
Average KL loss: 6.275629
Average total loss: 6.848494
tensor(-3.5630, device='cuda:0') tensor(1.4794, device='cuda:0') tensor(3.8294e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.576111
Average KL loss: 6.080650
Average total loss: 6.656761
tensor(-3.6093, device='cuda:0') tensor(1.4972, device='cuda:0') tensor(3.7036e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.559167
Average KL loss: 5.897320
Average total loss: 6.456487
tensor(-3.6543, device='cuda:0') tensor(1.5146, device='cuda:0') tensor(3.5365e-07, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.556533
Average KL loss: 5.724549
Average total loss: 6.281082
tensor(-3.6979, device='cuda:0') tensor(1.5316, device='cuda:0') tensor(3.5672e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.552031
Average KL loss: 5.561272
Average total loss: 6.113302
tensor(-3.7404, device='cuda:0') tensor(1.5481, device='cuda:0') tensor(3.4287e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.555476
Average KL loss: 5.406817
Average total loss: 5.962293
tensor(-3.7817, device='cuda:0') tensor(1.5643, device='cuda:0') tensor(3.3613e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.550190
Average KL loss: 5.260993
Average total loss: 5.811182
tensor(-3.8219, device='cuda:0') tensor(1.5805, device='cuda:0') tensor(3.1190e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.549583
Average KL loss: 5.122980
Average total loss: 5.672563
tensor(-3.8611, device='cuda:0') tensor(1.5963, device='cuda:0') tensor(3.0091e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.545864
Average KL loss: 4.992138
Average total loss: 5.538002
tensor(-3.8993, device='cuda:0') tensor(1.6120, device='cuda:0') tensor(3.0265e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.544505
Average KL loss: 4.867985
Average total loss: 5.412490
tensor(-3.9365, device='cuda:0') tensor(1.6275, device='cuda:0') tensor(2.9679e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.531598
Average KL loss: 4.749891
Average total loss: 5.281488
tensor(-3.9729, device='cuda:0') tensor(1.6426, device='cuda:0') tensor(3.0232e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.524677
Average KL loss: 4.636990
Average total loss: 5.161666
tensor(-4.0085, device='cuda:0') tensor(1.6575, device='cuda:0') tensor(2.8441e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.522023
Average KL loss: 4.529288
Average total loss: 5.051311
tensor(-4.0433, device='cuda:0') tensor(1.6722, device='cuda:0') tensor(2.8483e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.521305
Average KL loss: 4.426519
Average total loss: 4.947824
tensor(-4.0773, device='cuda:0') tensor(1.6870, device='cuda:0') tensor(2.7090e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.536584
Average KL loss: 4.329073
Average total loss: 4.865657
tensor(-4.1106, device='cuda:0') tensor(1.7017, device='cuda:0') tensor(2.6280e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.521662
Average KL loss: 4.236020
Average total loss: 4.757682
tensor(-4.1433, device='cuda:0') tensor(1.7163, device='cuda:0') tensor(2.6730e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.519539
Average KL loss: 4.146740
Average total loss: 4.666279
tensor(-4.1752, device='cuda:0') tensor(1.7307, device='cuda:0') tensor(2.4931e-07, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.534664
Average KL loss: 4.061456
Average total loss: 4.596120
tensor(-4.2065, device='cuda:0') tensor(1.7452, device='cuda:0') tensor(2.4164e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.521344
Average KL loss: 3.979865
Average total loss: 4.501209
tensor(-4.2372, device='cuda:0') tensor(1.7597, device='cuda:0') tensor(2.5577e-07, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.510377
Average KL loss: 3.901862
Average total loss: 4.412239
tensor(-4.2673, device='cuda:0') tensor(1.7740, device='cuda:0') tensor(2.2066e-07, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.513646
Average KL loss: 3.826668
Average total loss: 4.340314
tensor(-4.2970, device='cuda:0') tensor(1.7881, device='cuda:0') tensor(2.2143e-07, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.514702
Average KL loss: 3.754366
Average total loss: 4.269069
tensor(-4.3260, device='cuda:0') tensor(1.8023, device='cuda:0') tensor(2.1656e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.507663
Average KL loss: 3.685278
Average total loss: 4.192941
tensor(-4.3546, device='cuda:0') tensor(1.8164, device='cuda:0') tensor(2.1863e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.514687
Average KL loss: 3.618614
Average total loss: 4.133301
tensor(-4.3826, device='cuda:0') tensor(1.8305, device='cuda:0') tensor(2.1488e-07, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.511667
Average KL loss: 3.554920
Average total loss: 4.066587
tensor(-4.4101, device='cuda:0') tensor(1.8448, device='cuda:0') tensor(2.1300e-07, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.498976
Average KL loss: 3.493183
Average total loss: 3.992159
tensor(-4.4373, device='cuda:0') tensor(1.8586, device='cuda:0') tensor(2.0968e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.505660
Average KL loss: 3.433297
Average total loss: 3.938957
tensor(-4.4640, device='cuda:0') tensor(1.8724, device='cuda:0') tensor(1.9194e-07, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.507553
Average KL loss: 3.375632
Average total loss: 3.883184
tensor(-4.4903, device='cuda:0') tensor(1.8862, device='cuda:0') tensor(1.9000e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.504094
Average KL loss: 3.320220
Average total loss: 3.824314
tensor(-4.5163, device='cuda:0') tensor(1.9001, device='cuda:0') tensor(1.9408e-07, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.502175
Average KL loss: 3.266663
Average total loss: 3.768838
tensor(-4.5418, device='cuda:0') tensor(1.9139, device='cuda:0') tensor(2.0107e-07, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.500447
Average KL loss: 3.214900
Average total loss: 3.715346
tensor(-4.5670, device='cuda:0') tensor(1.9277, device='cuda:0') tensor(1.8367e-07, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.487795
Average KL loss: 3.165048
Average total loss: 3.652843
tensor(-4.5918, device='cuda:0') tensor(1.9416, device='cuda:0') tensor(1.8234e-07, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.490343
Average KL loss: 3.116778
Average total loss: 3.607121
tensor(-4.6162, device='cuda:0') tensor(1.9553, device='cuda:0') tensor(1.8423e-07, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.498563
Average KL loss: 3.070068
Average total loss: 3.568632
tensor(-4.6403, device='cuda:0') tensor(1.9693, device='cuda:0') tensor(1.7992e-07, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.493252
Average KL loss: 3.024785
Average total loss: 3.518036
tensor(-4.6642, device='cuda:0') tensor(1.9829, device='cuda:0') tensor(1.8341e-07, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.487083
Average KL loss: 2.980680
Average total loss: 3.467763
tensor(-4.6877, device='cuda:0') tensor(1.9965, device='cuda:0') tensor(1.6692e-07, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.492769
Average KL loss: 2.938040
Average total loss: 3.430809
tensor(-4.7109, device='cuda:0') tensor(2.0102, device='cuda:0') tensor(1.6593e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.490921
Average KL loss: 2.896723
Average total loss: 3.387644
tensor(-4.7338, device='cuda:0') tensor(2.0239, device='cuda:0') tensor(1.5149e-07, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.494679
Average KL loss: 2.856781
Average total loss: 3.351460
tensor(-4.7565, device='cuda:0') tensor(2.0377, device='cuda:0') tensor(1.6813e-07, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.492806
Average KL loss: 2.817994
Average total loss: 3.310800
tensor(-4.7789, device='cuda:0') tensor(2.0514, device='cuda:0') tensor(1.5543e-07, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.491064
Average KL loss: 2.780354
Average total loss: 3.271418
tensor(-4.8010, device='cuda:0') tensor(2.0652, device='cuda:0') tensor(1.6071e-07, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.491181
Average KL loss: 2.744007
Average total loss: 3.235188
tensor(-4.8228, device='cuda:0') tensor(2.0790, device='cuda:0') tensor(1.4201e-07, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.488938
Average KL loss: 2.708530
Average total loss: 3.197467
tensor(-4.8444, device='cuda:0') tensor(2.0928, device='cuda:0') tensor(1.3768e-07, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.491107
Average KL loss: 2.674094
Average total loss: 3.165202
tensor(-4.8658, device='cuda:0') tensor(2.1066, device='cuda:0') tensor(1.6251e-07, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.486348
Average KL loss: 2.640636
Average total loss: 3.126984
tensor(-4.8869, device='cuda:0') tensor(2.1204, device='cuda:0') tensor(1.4952e-07, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.482604
Average KL loss: 2.608030
Average total loss: 3.090634
tensor(-4.9078, device='cuda:0') tensor(2.1342, device='cuda:0') tensor(1.4731e-07, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.482443
Average KL loss: 2.576319
Average total loss: 3.058762
tensor(-4.9284, device='cuda:0') tensor(2.1480, device='cuda:0') tensor(1.3978e-07, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.483632
Average KL loss: 2.545459
Average total loss: 3.029091
tensor(-4.9489, device='cuda:0') tensor(2.1617, device='cuda:0') tensor(1.2753e-07, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.484485
Average KL loss: 2.515388
Average total loss: 2.999873
tensor(-4.9691, device='cuda:0') tensor(2.1755, device='cuda:0') tensor(1.4583e-07, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.485255
Average KL loss: 2.486402
Average total loss: 2.971657
tensor(-4.9891, device='cuda:0') tensor(2.1895, device='cuda:0') tensor(1.3792e-07, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.471576
Average KL loss: 2.458076
Average total loss: 2.929653
tensor(-5.0089, device='cuda:0') tensor(2.2033, device='cuda:0') tensor(1.3015e-07, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.475109
Average KL loss: 2.430230
Average total loss: 2.905339
tensor(-5.0286, device='cuda:0') tensor(2.2172, device='cuda:0') tensor(1.4438e-07, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.476049
Average KL loss: 2.403008
Average total loss: 2.879056
tensor(-5.0480, device='cuda:0') tensor(2.2309, device='cuda:0') tensor(1.3079e-07, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.475509
Average KL loss: 2.376513
Average total loss: 2.852022
tensor(-5.0673, device='cuda:0') tensor(2.2447, device='cuda:0') tensor(1.3166e-07, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.479487
Average KL loss: 2.350591
Average total loss: 2.830078
tensor(-5.0865, device='cuda:0') tensor(2.2585, device='cuda:0') tensor(1.2825e-07, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.481842
Average KL loss: 2.325544
Average total loss: 2.807386
tensor(-5.1054, device='cuda:0') tensor(2.2726, device='cuda:0') tensor(1.4395e-07, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.474544
Average KL loss: 2.301071
Average total loss: 2.775615
tensor(-5.1242, device='cuda:0') tensor(2.2865, device='cuda:0') tensor(1.2670e-07, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.475302
Average KL loss: 2.277022
Average total loss: 2.752324
tensor(-5.1428, device='cuda:0') tensor(2.3003, device='cuda:0') tensor(1.2291e-07, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.478173
Average KL loss: 2.253570
Average total loss: 2.731742
tensor(-5.1612, device='cuda:0') tensor(2.3142, device='cuda:0') tensor(1.2534e-07, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.474599
Average KL loss: 2.230634
Average total loss: 2.705233
tensor(-5.1795, device='cuda:0') tensor(2.3281, device='cuda:0') tensor(1.3062e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.472311
Average KL loss: 2.208195
Average total loss: 2.680506
tensor(-5.1976, device='cuda:0') tensor(2.3421, device='cuda:0') tensor(1.1532e-07, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.474693
Average KL loss: 2.186444
Average total loss: 2.661137
tensor(-5.2156, device='cuda:0') tensor(2.3562, device='cuda:0') tensor(1.1428e-07, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.470633
Average KL loss: 2.165189
Average total loss: 2.635823
tensor(-5.2335, device='cuda:0') tensor(2.3702, device='cuda:0') tensor(1.1286e-07, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.468099
Average KL loss: 2.144102
Average total loss: 2.612201
tensor(-5.2512, device='cuda:0') tensor(2.3841, device='cuda:0') tensor(1.0846e-07, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.468303
Average KL loss: 2.123573
Average total loss: 2.591877
tensor(-5.2687, device='cuda:0') tensor(2.3981, device='cuda:0') tensor(1.1339e-07, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.471813
Average KL loss: 2.103516
Average total loss: 2.575329
tensor(-5.2862, device='cuda:0') tensor(2.4122, device='cuda:0') tensor(1.1694e-07, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.472561
Average KL loss: 2.084057
Average total loss: 2.556618
tensor(-5.3035, device='cuda:0') tensor(2.4263, device='cuda:0') tensor(1.1651e-07, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.471955
Average KL loss: 2.064852
Average total loss: 2.536807
tensor(-5.3207, device='cuda:0') tensor(2.4404, device='cuda:0') tensor(1.1378e-07, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.469138
Average KL loss: 2.046223
Average total loss: 2.515361
tensor(-5.3378, device='cuda:0') tensor(2.4546, device='cuda:0') tensor(1.1637e-07, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.465387
Average KL loss: 2.027854
Average total loss: 2.493241
tensor(-5.3547, device='cuda:0') tensor(2.4688, device='cuda:0') tensor(1.1477e-07, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.465038
Average KL loss: 2.009871
Average total loss: 2.474910
tensor(-5.3715, device='cuda:0') tensor(2.4829, device='cuda:0') tensor(1.0636e-07, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.465685
Average KL loss: 1.992220
Average total loss: 2.457905
tensor(-5.3882, device='cuda:0') tensor(2.4971, device='cuda:0') tensor(1.0462e-07, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.468923
Average KL loss: 1.974948
Average total loss: 2.443871
tensor(-5.4048, device='cuda:0') tensor(2.5114, device='cuda:0') tensor(1.0224e-07, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.463956
Average KL loss: 1.958164
Average total loss: 2.422121
tensor(-5.4213, device='cuda:0') tensor(2.5257, device='cuda:0') tensor(1.0493e-07, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.463122
Average KL loss: 1.941444
Average total loss: 2.404566
tensor(-5.4377, device='cuda:0') tensor(2.5398, device='cuda:0') tensor(1.0277e-07, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.459215
Average KL loss: 1.925087
Average total loss: 2.384302
tensor(-5.4540, device='cuda:0') tensor(2.5541, device='cuda:0') tensor(1.0298e-07, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.442619
Average KL loss: 1.908870
Average total loss: 2.351489
tensor(-5.4702, device='cuda:0') tensor(2.5680, device='cuda:0') tensor(9.6574e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.465471
Average KL loss: 1.892843
Average total loss: 2.358313
tensor(-5.4863, device='cuda:0') tensor(2.5823, device='cuda:0') tensor(9.5756e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.458515
Average KL loss: 1.877469
Average total loss: 2.335984
tensor(-5.5022, device='cuda:0') tensor(2.5967, device='cuda:0') tensor(9.4216e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.446775
Average KL loss: 1.862239
Average total loss: 2.309014
tensor(-5.5182, device='cuda:0') tensor(2.6109, device='cuda:0') tensor(9.4383e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.458059
Average KL loss: 1.847184
Average total loss: 2.305243
tensor(-5.5340, device='cuda:0') tensor(2.6251, device='cuda:0') tensor(9.5232e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.466265
Average KL loss: 1.832542
Average total loss: 2.298808
tensor(-5.5497, device='cuda:0') tensor(2.6395, device='cuda:0') tensor(9.9198e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.444903
Average KL loss: 1.818084
Average total loss: 2.262987
tensor(-5.5654, device='cuda:0') tensor(2.6538, device='cuda:0') tensor(8.9611e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.450223
Average KL loss: 1.803718
Average total loss: 2.253940
tensor(-5.5809, device='cuda:0') tensor(2.6681, device='cuda:0') tensor(9.6014e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.454013
Average KL loss: 1.789800
Average total loss: 2.243813
tensor(-5.5964, device='cuda:0') tensor(2.6825, device='cuda:0') tensor(9.7146e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.456398
Average KL loss: 1.776120
Average total loss: 2.232517
tensor(-5.6118, device='cuda:0') tensor(2.6969, device='cuda:0') tensor(9.2893e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.454218
Average KL loss: 1.762788
Average total loss: 2.217006
tensor(-5.6271, device='cuda:0') tensor(2.7114, device='cuda:0') tensor(8.8015e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.462865
Average KL loss: 1.749761
Average total loss: 2.212626
tensor(-5.6424, device='cuda:0') tensor(2.7260, device='cuda:0') tensor(9.4739e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.451861
Average KL loss: 1.736863
Average total loss: 2.188724
tensor(-5.6575, device='cuda:0') tensor(2.7405, device='cuda:0') tensor(8.8386e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.449553
Average KL loss: 1.723978
Average total loss: 2.173531
tensor(-5.6726, device='cuda:0') tensor(2.7549, device='cuda:0') tensor(9.2654e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.447552
Average KL loss: 1.711339
Average total loss: 2.158891
tensor(-5.6876, device='cuda:0') tensor(2.7693, device='cuda:0') tensor(8.8543e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.452308
Average KL loss: 1.698924
Average total loss: 2.151231
tensor(-5.7025, device='cuda:0') tensor(2.7838, device='cuda:0') tensor(8.8323e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.446000
Average KL loss: 1.686673
Average total loss: 2.132673
tensor(-5.7174, device='cuda:0') tensor(2.7983, device='cuda:0') tensor(7.0316e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.448399
Average KL loss: 1.674671
Average total loss: 2.123070
tensor(-5.7322, device='cuda:0') tensor(2.8129, device='cuda:0') tensor(8.2577e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.444125
Average KL loss: 1.662855
Average total loss: 2.106980
tensor(-5.7469, device='cuda:0') tensor(2.8274, device='cuda:0') tensor(8.5501e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.439580
Average KL loss: 1.651109
Average total loss: 2.090689
tensor(-5.7615, device='cuda:0') tensor(2.8419, device='cuda:0') tensor(8.7612e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.450935
Average KL loss: 1.639508
Average total loss: 2.090443
tensor(-5.7761, device='cuda:0') tensor(2.8566, device='cuda:0') tensor(9.2686e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.444557
Average KL loss: 1.628356
Average total loss: 2.072913
tensor(-5.7906, device='cuda:0') tensor(2.8713, device='cuda:0') tensor(7.9586e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.447671
Average KL loss: 1.617285
Average total loss: 2.064956
tensor(-5.8051, device='cuda:0') tensor(2.8860, device='cuda:0') tensor(9.1277e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.439084
Average KL loss: 1.606427
Average total loss: 2.045511
tensor(-5.8195, device='cuda:0') tensor(2.9006, device='cuda:0') tensor(8.6817e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.438613
Average KL loss: 1.595452
Average total loss: 2.034064
tensor(-5.8338, device='cuda:0') tensor(2.9151, device='cuda:0') tensor(7.5140e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.444171
Average KL loss: 1.584826
Average total loss: 2.028997
tensor(-5.8481, device='cuda:0') tensor(2.9300, device='cuda:0') tensor(6.4193e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.438284
Average KL loss: 1.574346
Average total loss: 2.012630
tensor(-5.8623, device='cuda:0') tensor(2.9446, device='cuda:0') tensor(7.8627e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.438658
Average KL loss: 1.564104
Average total loss: 2.002762
tensor(-5.8764, device='cuda:0') tensor(2.9594, device='cuda:0') tensor(7.0150e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.438160
Average KL loss: 1.554040
Average total loss: 1.992200
tensor(-5.8905, device='cuda:0') tensor(2.9742, device='cuda:0') tensor(7.9039e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.441449
Average KL loss: 1.543979
Average total loss: 1.985428
tensor(-5.9046, device='cuda:0') tensor(2.9890, device='cuda:0') tensor(7.8630e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.441399
Average KL loss: 1.534135
Average total loss: 1.975534
tensor(-5.9186, device='cuda:0') tensor(3.0039, device='cuda:0') tensor(8.3640e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.427006
Average KL loss: 1.524415
Average total loss: 1.951421
tensor(-5.9325, device='cuda:0') tensor(3.0185, device='cuda:0') tensor(7.4105e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.437143
Average KL loss: 1.514679
Average total loss: 1.951821
tensor(-5.9464, device='cuda:0') tensor(3.0334, device='cuda:0') tensor(7.6033e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.431741
Average KL loss: 1.505414
Average total loss: 1.937155
tensor(-5.9602, device='cuda:0') tensor(3.0484, device='cuda:0') tensor(7.8190e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.437519
Average KL loss: 1.496163
Average total loss: 1.933682
tensor(-5.9740, device='cuda:0') tensor(3.0634, device='cuda:0') tensor(7.7272e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.437155
Average KL loss: 1.487114
Average total loss: 1.924269
tensor(-5.9877, device='cuda:0') tensor(3.0785, device='cuda:0') tensor(6.7683e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.433321
Average KL loss: 1.478233
Average total loss: 1.911554
tensor(-6.0013, device='cuda:0') tensor(3.0935, device='cuda:0') tensor(7.4660e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.431575
Average KL loss: 1.469277
Average total loss: 1.900853
tensor(-6.0150, device='cuda:0') tensor(3.1084, device='cuda:0') tensor(7.1062e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.433957
Average KL loss: 1.460463
Average total loss: 1.894421
tensor(-6.0285, device='cuda:0') tensor(3.1235, device='cuda:0') tensor(7.4544e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.436878
Average KL loss: 1.451790
Average total loss: 1.888668
tensor(-6.0420, device='cuda:0') tensor(3.1386, device='cuda:0') tensor(7.2201e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.432951
Average KL loss: 1.443429
Average total loss: 1.876381
tensor(-6.0555, device='cuda:0') tensor(3.1538, device='cuda:0') tensor(7.3998e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.434673
Average KL loss: 1.435009
Average total loss: 1.869682
tensor(-6.0689, device='cuda:0') tensor(3.1689, device='cuda:0') tensor(7.1224e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.429562
Average KL loss: 1.426744
Average total loss: 1.856305
tensor(-6.0823, device='cuda:0') tensor(3.1840, device='cuda:0') tensor(7.4976e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.429825
Average KL loss: 1.418622
Average total loss: 1.848447
tensor(-6.0956, device='cuda:0') tensor(3.1992, device='cuda:0') tensor(6.6171e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.428428
Average KL loss: 1.410479
Average total loss: 1.838907
tensor(-6.1089, device='cuda:0') tensor(3.2143, device='cuda:0') tensor(6.6892e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.431636
Average KL loss: 1.402513
Average total loss: 1.834149
tensor(-6.1221, device='cuda:0') tensor(3.2295, device='cuda:0') tensor(6.7829e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.428615
Average KL loss: 1.394653
Average total loss: 1.823268
tensor(-6.1353, device='cuda:0') tensor(3.2446, device='cuda:0') tensor(6.5519e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.429541
Average KL loss: 1.386973
Average total loss: 1.816514
tensor(-6.1484, device='cuda:0') tensor(3.2600, device='cuda:0') tensor(6.0865e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.434732
Average KL loss: 1.379475
Average total loss: 1.814207
tensor(-6.1615, device='cuda:0') tensor(3.2753, device='cuda:0') tensor(6.1608e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.421468
Average KL loss: 1.372003
Average total loss: 1.793472
tensor(-6.1745, device='cuda:0') tensor(3.2906, device='cuda:0') tensor(6.0175e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.424112
Average KL loss: 1.364456
Average total loss: 1.788568
tensor(-6.1875, device='cuda:0') tensor(3.3058, device='cuda:0') tensor(6.8825e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.429464
Average KL loss: 1.357107
Average total loss: 1.786571
tensor(-6.2005, device='cuda:0') tensor(3.3211, device='cuda:0') tensor(5.8403e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.422614
Average KL loss: 1.349824
Average total loss: 1.772438
tensor(-6.2134, device='cuda:0') tensor(3.3364, device='cuda:0') tensor(6.5213e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.423723
Average KL loss: 1.342688
Average total loss: 1.766410
tensor(-6.2263, device='cuda:0') tensor(3.3517, device='cuda:0') tensor(7.0336e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.423852
Average KL loss: 1.335656
Average total loss: 1.759508
tensor(-6.2391, device='cuda:0') tensor(3.3670, device='cuda:0') tensor(6.6554e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.423059
Average KL loss: 1.328625
Average total loss: 1.751684
tensor(-6.2519, device='cuda:0') tensor(3.3824, device='cuda:0') tensor(6.5692e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.419431
Average KL loss: 1.321625
Average total loss: 1.741056
tensor(-6.2647, device='cuda:0') tensor(3.3977, device='cuda:0') tensor(6.1913e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.421778
Average KL loss: 1.314806
Average total loss: 1.736584
tensor(-6.2774, device='cuda:0') tensor(3.4131, device='cuda:0') tensor(5.5575e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.421768
Average KL loss: 1.308051
Average total loss: 1.729819
tensor(-6.2901, device='cuda:0') tensor(3.4284, device='cuda:0') tensor(6.4232e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.423576
Average KL loss: 1.301317
Average total loss: 1.724892
tensor(-6.3027, device='cuda:0') tensor(3.4438, device='cuda:0') tensor(5.3302e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.418693
Average KL loss: 1.294683
Average total loss: 1.713376
tensor(-6.3153, device='cuda:0') tensor(3.4591, device='cuda:0') tensor(6.8156e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.415929
Average KL loss: 1.288071
Average total loss: 1.704000
tensor(-6.3279, device='cuda:0') tensor(3.4744, device='cuda:0') tensor(6.1179e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.417302
Average KL loss: 1.281555
Average total loss: 1.698857
tensor(-6.3404, device='cuda:0') tensor(3.4897, device='cuda:0') tensor(7.2587e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.418535
Average KL loss: 1.275069
Average total loss: 1.693605
tensor(-6.3529, device='cuda:0') tensor(3.5051, device='cuda:0') tensor(6.0368e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.410300
Average KL loss: 1.268721
Average total loss: 1.679021
tensor(-6.3654, device='cuda:0') tensor(3.5203, device='cuda:0') tensor(6.2437e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.424532
Average KL loss: 1.262372
Average total loss: 1.686904
tensor(-6.3779, device='cuda:0') tensor(3.5358, device='cuda:0') tensor(6.1727e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.412060
Average KL loss: 1.256291
Average total loss: 1.668352
tensor(-6.3903, device='cuda:0') tensor(3.5512, device='cuda:0') tensor(6.2370e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.417192
Average KL loss: 1.250202
Average total loss: 1.667394
tensor(-6.4026, device='cuda:0') tensor(3.5666, device='cuda:0') tensor(5.8171e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.413626
Average KL loss: 1.244288
Average total loss: 1.657915
tensor(-6.4150, device='cuda:0') tensor(3.5821, device='cuda:0') tensor(5.7366e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.417897
Average KL loss: 1.238357
Average total loss: 1.656253
tensor(-6.4272, device='cuda:0') tensor(3.5975, device='cuda:0') tensor(5.6383e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.415333
Average KL loss: 1.232405
Average total loss: 1.647738
tensor(-6.4395, device='cuda:0') tensor(3.6130, device='cuda:0') tensor(4.6799e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.408220
Average KL loss: 1.226627
Average total loss: 1.634846
tensor(-6.4517, device='cuda:0') tensor(3.6285, device='cuda:0') tensor(6.1062e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.410511
Average KL loss: 1.220827
Average total loss: 1.631338
tensor(-6.4639, device='cuda:0') tensor(3.6438, device='cuda:0') tensor(6.4015e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.408300
Average KL loss: 1.215074
Average total loss: 1.623374
tensor(-6.4761, device='cuda:0') tensor(3.6592, device='cuda:0') tensor(4.9350e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.410301
Average KL loss: 1.209339
Average total loss: 1.619640
tensor(-6.4882, device='cuda:0') tensor(3.6744, device='cuda:0') tensor(5.7480e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.402803
Average KL loss: 1.203742
Average total loss: 1.606545
tensor(-6.5003, device='cuda:0') tensor(3.6899, device='cuda:0') tensor(5.5435e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.414716
Average KL loss: 1.198352
Average total loss: 1.613068
tensor(-6.5124, device='cuda:0') tensor(3.7054, device='cuda:0') tensor(5.3487e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.402951
Average KL loss: 1.192902
Average total loss: 1.595853
tensor(-6.5244, device='cuda:0') tensor(3.7207, device='cuda:0') tensor(5.8015e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.405851
Average KL loss: 1.187428
Average total loss: 1.593279
tensor(-6.5364, device='cuda:0') tensor(3.7360, device='cuda:0') tensor(5.0210e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.412808
Average KL loss: 1.182042
Average total loss: 1.594850
tensor(-6.5484, device='cuda:0') tensor(3.7514, device='cuda:0') tensor(4.1565e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.411997
Average KL loss: 1.176697
Average total loss: 1.588694
tensor(-6.5604, device='cuda:0') tensor(3.7667, device='cuda:0') tensor(4.9017e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.399024
Average KL loss: 1.171468
Average total loss: 1.570492
tensor(-6.5723, device='cuda:0') tensor(3.7820, device='cuda:0') tensor(6.0434e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.404094
Average KL loss: 1.166225
Average total loss: 1.570319
tensor(-6.5842, device='cuda:0') tensor(3.7973, device='cuda:0') tensor(6.0415e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.403723
Average KL loss: 1.161062
Average total loss: 1.564785
tensor(-6.5960, device='cuda:0') tensor(3.8125, device='cuda:0') tensor(4.9899e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.407377
Average KL loss: 1.155941
Average total loss: 1.563317
tensor(-6.6079, device='cuda:0') tensor(3.8279, device='cuda:0') tensor(4.7984e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.397062
Average KL loss: 1.150946
Average total loss: 1.548008
tensor(-6.6196, device='cuda:0') tensor(3.8431, device='cuda:0') tensor(5.0047e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.407399
Average KL loss: 1.145871
Average total loss: 1.553270
tensor(-6.6314, device='cuda:0') tensor(3.8584, device='cuda:0') tensor(5.2612e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.399513
Average KL loss: 1.140891
Average total loss: 1.540404
tensor(-6.6431, device='cuda:0') tensor(3.8736, device='cuda:0') tensor(3.9395e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.395851
Average KL loss: 1.136023
Average total loss: 1.531874
tensor(-6.6548, device='cuda:0') tensor(3.8890, device='cuda:0') tensor(3.9196e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.394635
Average KL loss: 1.131256
Average total loss: 1.525891
tensor(-6.6665, device='cuda:0') tensor(3.9042, device='cuda:0') tensor(4.2344e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.398895
Average KL loss: 1.126391
Average total loss: 1.525286
tensor(-6.6782, device='cuda:0') tensor(3.9195, device='cuda:0') tensor(5.4317e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.397468
Average KL loss: 1.121593
Average total loss: 1.519060
tensor(-6.6898, device='cuda:0') tensor(3.9346, device='cuda:0') tensor(5.0857e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.400240
Average KL loss: 1.116772
Average total loss: 1.517012
tensor(-6.7014, device='cuda:0') tensor(3.9497, device='cuda:0') tensor(5.0760e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.393764
Average KL loss: 1.112041
Average total loss: 1.505805
tensor(-6.7130, device='cuda:0') tensor(3.9647, device='cuda:0') tensor(4.9230e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.397167
Average KL loss: 1.107373
Average total loss: 1.504540
 Percentile value: -5.329737663269043
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =    1715 /    1728             ( 99.25%) | total_pruned =      13 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   32974 /   36864             ( 89.45%) | total_pruned =    3890 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   33211 /   36864             ( 90.09%) | total_pruned =    3653 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   32563 /   36864             ( 88.33%) | total_pruned =    4301 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   32220 /   36864             ( 87.40%) | total_pruned =    4644 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   63741 /   73728             ( 86.45%) | total_pruned =    9987 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  122256 /  147456             ( 82.91%) | total_pruned =   25200 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7869 /    8192             ( 96.06%) | total_pruned =     323 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  115927 /  147456             ( 78.62%) | total_pruned =   31529 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  115980 /  147456             ( 78.65%) | total_pruned =   31476 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  233267 /  294912             ( 79.10%) | total_pruned =   61645 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  439800 /  589824             ( 74.56%) | total_pruned =  150024 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   29750 /   32768             ( 90.79%) | total_pruned =    3018 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  369583 /  589824             ( 62.66%) | total_pruned =  220241 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  366222 /  589824             ( 62.09%) | total_pruned =  223602 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  771828 / 1179648             ( 65.43%) | total_pruned =  407820 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1191667 / 2359296             ( 50.51%) | total_pruned = 1167629 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  103239 /  131072             ( 78.77%) | total_pruned =   27833 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  773035 / 2359296             ( 32.77%) | total_pruned = 1586261 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  737868 / 2359296             ( 31.27%) | total_pruned = 1621428 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5077 /    5120             ( 99.16%) | total_pruned =      43 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 28/100 Loss: 0.000437 Accuracy: 86.54 100.00 % Best test Accuracy: 86.61%
tensor(-6.7245, device='cuda:0') tensor(3.9798, device='cuda:0') tensor(4.4849e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.435667
Average KL loss: 1.040783
Average total loss: 1.476449
tensor(-6.9021, device='cuda:0') tensor(3.7613, device='cuda:0') tensor(3.8193e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.443558
Average KL loss: 0.987618
Average total loss: 1.431176
tensor(-7.0221, device='cuda:0') tensor(3.7298, device='cuda:0') tensor(3.7090e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.435427
Average KL loss: 0.964886
Average total loss: 1.400313
tensor(-7.1164, device='cuda:0') tensor(3.7495, device='cuda:0') tensor(3.2424e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.434822
Average KL loss: 0.950734
Average total loss: 1.385556
tensor(-7.1954, device='cuda:0') tensor(3.7905, device='cuda:0') tensor(3.1596e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.432420
Average KL loss: 0.940532
Average total loss: 1.372952
tensor(-7.2642, device='cuda:0') tensor(3.8417, device='cuda:0') tensor(3.7455e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.432632
Average KL loss: 0.932622
Average total loss: 1.365253
tensor(-7.3253, device='cuda:0') tensor(3.8978, device='cuda:0') tensor(3.0914e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.426236
Average KL loss: 0.925973
Average total loss: 1.352209
tensor(-7.3807, device='cuda:0') tensor(3.9562, device='cuda:0') tensor(3.4554e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.425399
Average KL loss: 0.920252
Average total loss: 1.345651
tensor(-7.4313, device='cuda:0') tensor(4.0153, device='cuda:0') tensor(3.3022e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.431494
Average KL loss: 0.915173
Average total loss: 1.346668
tensor(-7.4781, device='cuda:0') tensor(4.0744, device='cuda:0') tensor(2.6915e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.418801
Average KL loss: 0.910658
Average total loss: 1.329459
tensor(-7.5217, device='cuda:0') tensor(4.1329, device='cuda:0') tensor(3.0127e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.420598
Average KL loss: 0.906411
Average total loss: 1.327009
tensor(-7.5625, device='cuda:0') tensor(4.1904, device='cuda:0') tensor(2.6813e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.415986
Average KL loss: 0.902505
Average total loss: 1.318491
tensor(-7.6010, device='cuda:0') tensor(4.2467, device='cuda:0') tensor(3.2501e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.413485
Average KL loss: 0.898759
Average total loss: 1.312244
tensor(-7.6374, device='cuda:0') tensor(4.3017, device='cuda:0') tensor(3.6869e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.413525
Average KL loss: 0.895109
Average total loss: 1.308633
tensor(-7.6720, device='cuda:0') tensor(4.3553, device='cuda:0') tensor(3.1821e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.412309
Average KL loss: 0.891584
Average total loss: 1.303893
tensor(-7.7049, device='cuda:0') tensor(4.4076, device='cuda:0') tensor(3.1709e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.411305
Average KL loss: 0.888255
Average total loss: 1.299560
tensor(-7.7364, device='cuda:0') tensor(4.4586, device='cuda:0') tensor(2.8886e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.410567
Average KL loss: 0.885096
Average total loss: 1.295663
tensor(-7.7666, device='cuda:0') tensor(4.5083, device='cuda:0') tensor(3.5301e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.406062
Average KL loss: 0.881990
Average total loss: 1.288053
tensor(-7.7955, device='cuda:0') tensor(4.5566, device='cuda:0') tensor(2.8661e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.404444
Average KL loss: 0.878972
Average total loss: 1.283415
tensor(-7.8234, device='cuda:0') tensor(4.6038, device='cuda:0') tensor(3.3769e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.408767
Average KL loss: 0.875960
Average total loss: 1.284726
tensor(-7.8502, device='cuda:0') tensor(4.6496, device='cuda:0') tensor(3.1522e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.401113
Average KL loss: 0.873116
Average total loss: 1.274230
tensor(-7.8761, device='cuda:0') tensor(4.6945, device='cuda:0') tensor(1.3627e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.409609
Average KL loss: 0.870381
Average total loss: 1.279990
tensor(-7.9012, device='cuda:0') tensor(4.7382, device='cuda:0') tensor(2.4642e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.398723
Average KL loss: 0.867636
Average total loss: 1.266359
tensor(-7.9255, device='cuda:0') tensor(4.7807, device='cuda:0') tensor(2.8855e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.401825
Average KL loss: 0.864863
Average total loss: 1.266688
tensor(-7.9490, device='cuda:0') tensor(4.8222, device='cuda:0') tensor(2.8833e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.399614
Average KL loss: 0.862234
Average total loss: 1.261848
tensor(-7.9719, device='cuda:0') tensor(4.8627, device='cuda:0') tensor(3.4008e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.398912
Average KL loss: 0.859657
Average total loss: 1.258570
tensor(-7.9941, device='cuda:0') tensor(4.9022, device='cuda:0') tensor(2.9024e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.388914
Average KL loss: 0.857073
Average total loss: 1.245986
tensor(-8.0157, device='cuda:0') tensor(4.9407, device='cuda:0') tensor(2.9109e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.397427
Average KL loss: 0.854477
Average total loss: 1.251904
tensor(-8.0367, device='cuda:0') tensor(4.9782, device='cuda:0') tensor(2.9108e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.387876
Average KL loss: 0.851917
Average total loss: 1.239793
tensor(-8.0573, device='cuda:0') tensor(5.0149, device='cuda:0') tensor(3.4845e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.399470
Average KL loss: 0.849338
Average total loss: 1.248808
tensor(-8.0773, device='cuda:0') tensor(5.0507, device='cuda:0') tensor(2.8653e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.395559
Average KL loss: 0.846931
Average total loss: 1.242490
tensor(-8.0968, device='cuda:0') tensor(5.0858, device='cuda:0') tensor(3.3286e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.394765
Average KL loss: 0.844557
Average total loss: 1.239321
tensor(-8.1159, device='cuda:0') tensor(5.1199, device='cuda:0') tensor(3.2471e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.392946
Average KL loss: 0.842231
Average total loss: 1.235177
tensor(-8.1346, device='cuda:0') tensor(5.1535, device='cuda:0') tensor(3.1621e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.391546
Average KL loss: 0.839930
Average total loss: 1.231476
tensor(-8.1529, device='cuda:0') tensor(5.1861, device='cuda:0') tensor(2.2230e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.389924
Average KL loss: 0.837561
Average total loss: 1.227485
tensor(-8.1708, device='cuda:0') tensor(5.2181, device='cuda:0') tensor(2.3821e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.392148
Average KL loss: 0.835232
Average total loss: 1.227380
tensor(-8.1883, device='cuda:0') tensor(5.2493, device='cuda:0') tensor(3.2539e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.387058
Average KL loss: 0.832962
Average total loss: 1.220020
tensor(-8.2055, device='cuda:0') tensor(5.2799, device='cuda:0') tensor(3.4908e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.387798
Average KL loss: 0.830674
Average total loss: 1.218472
tensor(-8.2223, device='cuda:0') tensor(5.3099, device='cuda:0') tensor(2.4421e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.380112
Average KL loss: 0.828435
Average total loss: 1.208548
tensor(-8.2389, device='cuda:0') tensor(5.3391, device='cuda:0') tensor(2.8199e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.387568
Average KL loss: 0.826125
Average total loss: 1.213693
tensor(-8.2551, device='cuda:0') tensor(5.3677, device='cuda:0') tensor(1.3997e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.381945
Average KL loss: 0.823937
Average total loss: 1.205882
tensor(-8.2711, device='cuda:0') tensor(5.3959, device='cuda:0') tensor(2.4886e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.380608
Average KL loss: 0.821765
Average total loss: 1.202373
tensor(-8.2867, device='cuda:0') tensor(5.4234, device='cuda:0') tensor(2.4684e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.387601
Average KL loss: 0.819638
Average total loss: 1.207239
tensor(-8.3021, device='cuda:0') tensor(5.4505, device='cuda:0') tensor(3.1589e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.382520
Average KL loss: 0.817557
Average total loss: 1.200076
tensor(-8.3172, device='cuda:0') tensor(5.4769, device='cuda:0') tensor(2.6967e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.376854
Average KL loss: 0.815358
Average total loss: 1.192212
tensor(-8.3321, device='cuda:0') tensor(5.5027, device='cuda:0') tensor(1.6977e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.385758
Average KL loss: 0.813295
Average total loss: 1.199053
tensor(-8.3468, device='cuda:0') tensor(5.5283, device='cuda:0') tensor(2.7462e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.376033
Average KL loss: 0.811268
Average total loss: 1.187301
tensor(-8.3612, device='cuda:0') tensor(5.5532, device='cuda:0') tensor(3.2945e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.384947
Average KL loss: 0.809252
Average total loss: 1.194199
tensor(-8.3754, device='cuda:0') tensor(5.5777, device='cuda:0') tensor(3.0257e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.377708
Average KL loss: 0.807282
Average total loss: 1.184990
tensor(-8.3894, device='cuda:0') tensor(5.6017, device='cuda:0') tensor(2.7476e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.381449
Average KL loss: 0.805270
Average total loss: 1.186719
tensor(-8.4032, device='cuda:0') tensor(5.6252, device='cuda:0') tensor(2.1214e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.380462
Average KL loss: 0.803278
Average total loss: 1.183740
tensor(-8.4168, device='cuda:0') tensor(5.6483, device='cuda:0') tensor(2.1698e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.379013
Average KL loss: 0.801343
Average total loss: 1.180357
tensor(-8.4302, device='cuda:0') tensor(5.6710, device='cuda:0') tensor(2.8279e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.378259
Average KL loss: 0.799344
Average total loss: 1.177603
tensor(-8.4435, device='cuda:0') tensor(5.6931, device='cuda:0') tensor(2.4828e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.369799
Average KL loss: 0.797441
Average total loss: 1.167240
tensor(-8.4565, device='cuda:0') tensor(5.7149, device='cuda:0') tensor(2.3550e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.374424
Average KL loss: 0.795450
Average total loss: 1.169874
tensor(-8.4694, device='cuda:0') tensor(5.7362, device='cuda:0') tensor(2.5717e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.374777
Average KL loss: 0.793503
Average total loss: 1.168279
tensor(-8.4821, device='cuda:0') tensor(5.7571, device='cuda:0') tensor(3.2063e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.369472
Average KL loss: 0.791561
Average total loss: 1.161033
tensor(-8.4947, device='cuda:0') tensor(5.7777, device='cuda:0') tensor(2.2859e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.368823
Average KL loss: 0.789581
Average total loss: 1.158404
tensor(-8.5071, device='cuda:0') tensor(5.7978, device='cuda:0') tensor(2.7153e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.371202
Average KL loss: 0.787628
Average total loss: 1.158830
tensor(-8.5193, device='cuda:0') tensor(5.8176, device='cuda:0') tensor(2.6605e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.369042
Average KL loss: 0.785721
Average total loss: 1.154763
tensor(-8.5315, device='cuda:0') tensor(5.8369, device='cuda:0') tensor(2.5990e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.375548
Average KL loss: 0.783845
Average total loss: 1.159392
tensor(-8.5434, device='cuda:0') tensor(5.8561, device='cuda:0') tensor(2.9275e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.365156
Average KL loss: 0.782045
Average total loss: 1.147202
tensor(-8.5553, device='cuda:0') tensor(5.8748, device='cuda:0') tensor(3.0342e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.370061
Average KL loss: 0.780155
Average total loss: 1.150216
tensor(-8.5669, device='cuda:0') tensor(5.8932, device='cuda:0') tensor(2.0642e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.362224
Average KL loss: 0.778307
Average total loss: 1.140531
tensor(-8.5785, device='cuda:0') tensor(5.9112, device='cuda:0') tensor(2.2877e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.367909
Average KL loss: 0.776401
Average total loss: 1.144310
tensor(-8.5899, device='cuda:0') tensor(5.9290, device='cuda:0') tensor(2.5515e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.365376
Average KL loss: 0.774513
Average total loss: 1.139889
tensor(-8.6013, device='cuda:0') tensor(5.9463, device='cuda:0') tensor(2.9998e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.366810
Average KL loss: 0.772646
Average total loss: 1.139456
tensor(-8.6125, device='cuda:0') tensor(5.9634, device='cuda:0') tensor(2.7416e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.368641
Average KL loss: 0.770843
Average total loss: 1.139484
tensor(-8.6235, device='cuda:0') tensor(5.9803, device='cuda:0') tensor(2.8811e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.365828
Average KL loss: 0.769105
Average total loss: 1.134933
tensor(-8.6345, device='cuda:0') tensor(5.9969, device='cuda:0') tensor(1.9921e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.360180
Average KL loss: 0.767367
Average total loss: 1.127546
tensor(-8.6454, device='cuda:0') tensor(6.0130, device='cuda:0') tensor(1.8991e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.362349
Average KL loss: 0.765529
Average total loss: 1.127879
tensor(-8.6561, device='cuda:0') tensor(6.0288, device='cuda:0') tensor(2.1672e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.366301
Average KL loss: 0.763758
Average total loss: 1.130059
tensor(-8.6668, device='cuda:0') tensor(6.0446, device='cuda:0') tensor(2.0417e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.360352
Average KL loss: 0.762056
Average total loss: 1.122408
tensor(-8.6773, device='cuda:0') tensor(6.0599, device='cuda:0') tensor(2.8240e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.363360
Average KL loss: 0.760297
Average total loss: 1.123657
tensor(-8.6878, device='cuda:0') tensor(6.0751, device='cuda:0') tensor(2.3525e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.355693
Average KL loss: 0.758592
Average total loss: 1.114284
tensor(-8.6981, device='cuda:0') tensor(6.0899, device='cuda:0') tensor(2.1634e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.353057
Average KL loss: 0.756908
Average total loss: 1.109965
tensor(-8.7084, device='cuda:0') tensor(6.1047, device='cuda:0') tensor(2.8250e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.358776
Average KL loss: 0.755186
Average total loss: 1.113962
tensor(-8.7186, device='cuda:0') tensor(6.1190, device='cuda:0') tensor(2.7754e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.354821
Average KL loss: 0.753473
Average total loss: 1.108294
tensor(-8.7286, device='cuda:0') tensor(6.1332, device='cuda:0') tensor(2.3622e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.353180
Average KL loss: 0.751766
Average total loss: 1.104946
tensor(-8.7386, device='cuda:0') tensor(6.1471, device='cuda:0') tensor(2.5710e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.351593
Average KL loss: 0.750054
Average total loss: 1.101647
tensor(-8.7485, device='cuda:0') tensor(6.1605, device='cuda:0') tensor(2.2666e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.354631
Average KL loss: 0.748318
Average total loss: 1.102949
tensor(-8.7583, device='cuda:0') tensor(6.1740, device='cuda:0') tensor(1.8813e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.357565
Average KL loss: 0.746663
Average total loss: 1.104228
tensor(-8.7681, device='cuda:0') tensor(6.1871, device='cuda:0') tensor(2.9496e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.349483
Average KL loss: 0.745045
Average total loss: 1.094528
tensor(-8.7777, device='cuda:0') tensor(6.2001, device='cuda:0') tensor(2.0816e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.351215
Average KL loss: 0.743397
Average total loss: 1.094613
tensor(-8.7873, device='cuda:0') tensor(6.2127, device='cuda:0') tensor(1.5977e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.349703
Average KL loss: 0.741705
Average total loss: 1.091408
tensor(-8.7968, device='cuda:0') tensor(6.2252, device='cuda:0') tensor(2.1241e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.350992
Average KL loss: 0.740091
Average total loss: 1.091083
tensor(-8.8063, device='cuda:0') tensor(6.2375, device='cuda:0') tensor(2.4179e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.349945
Average KL loss: 0.738388
Average total loss: 1.088333
tensor(-8.8156, device='cuda:0') tensor(6.2495, device='cuda:0') tensor(1.8435e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.345454
Average KL loss: 0.736757
Average total loss: 1.082211
tensor(-8.8249, device='cuda:0') tensor(6.2613, device='cuda:0') tensor(2.5705e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.349566
Average KL loss: 0.735132
Average total loss: 1.084698
tensor(-8.8341, device='cuda:0') tensor(6.2730, device='cuda:0') tensor(2.2189e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.346539
Average KL loss: 0.733546
Average total loss: 1.080085
tensor(-8.8433, device='cuda:0') tensor(6.2843, device='cuda:0') tensor(2.2954e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.350719
Average KL loss: 0.731975
Average total loss: 1.082695
tensor(-8.8524, device='cuda:0') tensor(6.2956, device='cuda:0') tensor(2.5207e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.346510
Average KL loss: 0.730402
Average total loss: 1.076912
tensor(-8.8614, device='cuda:0') tensor(6.3067, device='cuda:0') tensor(3.1433e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.347774
Average KL loss: 0.728768
Average total loss: 1.076542
tensor(-8.8703, device='cuda:0') tensor(6.3175, device='cuda:0') tensor(2.0997e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.349573
Average KL loss: 0.727184
Average total loss: 1.076757
tensor(-8.8792, device='cuda:0') tensor(6.3281, device='cuda:0') tensor(2.5987e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.344375
Average KL loss: 0.725664
Average total loss: 1.070040
tensor(-8.8881, device='cuda:0') tensor(6.3386, device='cuda:0') tensor(2.0847e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.341388
Average KL loss: 0.724187
Average total loss: 1.065575
tensor(-8.8968, device='cuda:0') tensor(6.3491, device='cuda:0') tensor(2.1448e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.343077
Average KL loss: 0.722645
Average total loss: 1.065722
tensor(-8.9055, device='cuda:0') tensor(6.3592, device='cuda:0') tensor(2.5461e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.338678
Average KL loss: 0.721088
Average total loss: 1.059766
tensor(-8.9142, device='cuda:0') tensor(6.3691, device='cuda:0') tensor(1.7474e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.340594
Average KL loss: 0.719485
Average total loss: 1.060079
tensor(-8.9228, device='cuda:0') tensor(6.3788, device='cuda:0') tensor(2.6407e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.339276
Average KL loss: 0.717919
Average total loss: 1.057194
tensor(-8.9313, device='cuda:0') tensor(6.3883, device='cuda:0') tensor(2.3006e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.341228
Average KL loss: 0.716382
Average total loss: 1.057610
tensor(-8.9398, device='cuda:0') tensor(6.3978, device='cuda:0') tensor(2.2434e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.334914
Average KL loss: 0.714824
Average total loss: 1.049737
tensor(-8.9482, device='cuda:0') tensor(6.4071, device='cuda:0') tensor(1.8793e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.341087
Average KL loss: 0.713259
Average total loss: 1.054346
tensor(-8.9566, device='cuda:0') tensor(6.4162, device='cuda:0') tensor(2.0539e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.340944
Average KL loss: 0.711711
Average total loss: 1.052655
tensor(-8.9649, device='cuda:0') tensor(6.4251, device='cuda:0') tensor(2.2704e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.342132
Average KL loss: 0.710248
Average total loss: 1.052380
tensor(-8.9732, device='cuda:0') tensor(6.4341, device='cuda:0') tensor(2.3278e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.337750
Average KL loss: 0.708918
Average total loss: 1.046667
tensor(-8.9814, device='cuda:0') tensor(6.4428, device='cuda:0') tensor(1.6568e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.336572
Average KL loss: 0.707467
Average total loss: 1.044039
tensor(-8.9896, device='cuda:0') tensor(6.4512, device='cuda:0') tensor(1.7411e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.340514
Average KL loss: 0.705988
Average total loss: 1.046502
tensor(-8.9977, device='cuda:0') tensor(6.4595, device='cuda:0') tensor(1.8216e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.333530
Average KL loss: 0.704553
Average total loss: 1.038083
tensor(-9.0058, device='cuda:0') tensor(6.4676, device='cuda:0') tensor(2.7170e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.335779
Average KL loss: 0.702995
Average total loss: 1.038773
tensor(-9.0139, device='cuda:0') tensor(6.4755, device='cuda:0') tensor(2.0769e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.333499
Average KL loss: 0.701544
Average total loss: 1.035043
tensor(-9.0218, device='cuda:0') tensor(6.4834, device='cuda:0') tensor(2.1162e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.335379
Average KL loss: 0.700075
Average total loss: 1.035454
tensor(-9.0298, device='cuda:0') tensor(6.4912, device='cuda:0') tensor(1.6504e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.331802
Average KL loss: 0.698603
Average total loss: 1.030405
tensor(-9.0377, device='cuda:0') tensor(6.4987, device='cuda:0') tensor(1.9370e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.333163
Average KL loss: 0.697233
Average total loss: 1.030396
tensor(-9.0455, device='cuda:0') tensor(6.5063, device='cuda:0') tensor(2.5138e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.329136
Average KL loss: 0.695872
Average total loss: 1.025008
tensor(-9.0534, device='cuda:0') tensor(6.5137, device='cuda:0') tensor(2.2318e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.332419
Average KL loss: 0.694517
Average total loss: 1.026936
tensor(-9.0611, device='cuda:0') tensor(6.5209, device='cuda:0') tensor(1.7104e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.326859
Average KL loss: 0.693137
Average total loss: 1.019996
tensor(-9.0688, device='cuda:0') tensor(6.5281, device='cuda:0') tensor(1.9673e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.329589
Average KL loss: 0.691753
Average total loss: 1.021342
tensor(-9.0765, device='cuda:0') tensor(6.5350, device='cuda:0') tensor(2.4837e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.330100
Average KL loss: 0.690381
Average total loss: 1.020481
tensor(-9.0842, device='cuda:0') tensor(6.5419, device='cuda:0') tensor(2.2589e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.325969
Average KL loss: 0.689049
Average total loss: 1.015019
tensor(-9.0918, device='cuda:0') tensor(6.5486, device='cuda:0') tensor(2.0390e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.329892
Average KL loss: 0.687635
Average total loss: 1.017527
tensor(-9.0994, device='cuda:0') tensor(6.5551, device='cuda:0') tensor(2.0561e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.326087
Average KL loss: 0.686313
Average total loss: 1.012400
tensor(-9.1069, device='cuda:0') tensor(6.5617, device='cuda:0') tensor(2.0783e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.321057
Average KL loss: 0.684976
Average total loss: 1.006033
tensor(-9.1144, device='cuda:0') tensor(6.5680, device='cuda:0') tensor(2.4459e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.326835
Average KL loss: 0.683581
Average total loss: 1.010416
tensor(-9.1218, device='cuda:0') tensor(6.5742, device='cuda:0') tensor(2.3934e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.321715
Average KL loss: 0.682227
Average total loss: 1.003943
tensor(-9.1293, device='cuda:0') tensor(6.5803, device='cuda:0') tensor(2.3647e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.324026
Average KL loss: 0.680829
Average total loss: 1.004855
tensor(-9.1366, device='cuda:0') tensor(6.5862, device='cuda:0') tensor(1.6134e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.320959
Average KL loss: 0.679440
Average total loss: 1.000400
tensor(-9.1440, device='cuda:0') tensor(6.5920, device='cuda:0') tensor(1.5657e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.327377
Average KL loss: 0.678184
Average total loss: 1.005561
tensor(-9.1513, device='cuda:0') tensor(6.5980, device='cuda:0') tensor(1.8318e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.324875
Average KL loss: 0.676948
Average total loss: 1.001823
tensor(-9.1586, device='cuda:0') tensor(6.6037, device='cuda:0') tensor(2.3022e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.322785
Average KL loss: 0.675590
Average total loss: 0.998374
tensor(-9.1658, device='cuda:0') tensor(6.6092, device='cuda:0') tensor(2.2850e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.321124
Average KL loss: 0.674297
Average total loss: 0.995421
tensor(-9.1730, device='cuda:0') tensor(6.6146, device='cuda:0') tensor(2.9064e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.317440
Average KL loss: 0.672979
Average total loss: 0.990419
tensor(-9.1802, device='cuda:0') tensor(6.6199, device='cuda:0') tensor(2.2228e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.319649
Average KL loss: 0.671677
Average total loss: 0.991326
tensor(-9.1874, device='cuda:0') tensor(6.6250, device='cuda:0') tensor(1.8970e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.321804
Average KL loss: 0.670373
Average total loss: 0.992177
tensor(-9.1945, device='cuda:0') tensor(6.6301, device='cuda:0') tensor(2.0183e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.321996
Average KL loss: 0.669068
Average total loss: 0.991064
tensor(-9.2016, device='cuda:0') tensor(6.6349, device='cuda:0') tensor(2.0345e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.319501
Average KL loss: 0.667764
Average total loss: 0.987265
tensor(-9.2087, device='cuda:0') tensor(6.6397, device='cuda:0') tensor(2.4060e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.317734
Average KL loss: 0.666461
Average total loss: 0.984196
tensor(-9.2157, device='cuda:0') tensor(6.6444, device='cuda:0') tensor(1.9373e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.312170
Average KL loss: 0.665136
Average total loss: 0.977306
tensor(-9.2228, device='cuda:0') tensor(6.6490, device='cuda:0') tensor(1.3295e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.316428
Average KL loss: 0.663880
Average total loss: 0.980308
tensor(-9.2297, device='cuda:0') tensor(6.6535, device='cuda:0') tensor(1.8705e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.317959
Average KL loss: 0.662647
Average total loss: 0.980606
tensor(-9.2367, device='cuda:0') tensor(6.6580, device='cuda:0') tensor(2.2877e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.314687
Average KL loss: 0.661458
Average total loss: 0.976145
tensor(-9.2436, device='cuda:0') tensor(6.6624, device='cuda:0') tensor(1.1609e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.312095
Average KL loss: 0.660281
Average total loss: 0.972376
tensor(-9.2505, device='cuda:0') tensor(6.6668, device='cuda:0') tensor(1.9394e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.314331
Average KL loss: 0.659100
Average total loss: 0.973430
tensor(-9.2574, device='cuda:0') tensor(6.6709, device='cuda:0') tensor(1.5180e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.315449
Average KL loss: 0.657843
Average total loss: 0.973292
tensor(-9.2642, device='cuda:0') tensor(6.6749, device='cuda:0') tensor(2.1964e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.310114
Average KL loss: 0.656599
Average total loss: 0.966714
tensor(-9.2710, device='cuda:0') tensor(6.6790, device='cuda:0') tensor(1.4717e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.311982
Average KL loss: 0.655341
Average total loss: 0.967323
tensor(-9.2778, device='cuda:0') tensor(6.6828, device='cuda:0') tensor(2.3141e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.311241
Average KL loss: 0.654082
Average total loss: 0.965323
tensor(-9.2845, device='cuda:0') tensor(6.6865, device='cuda:0') tensor(1.6245e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.307514
Average KL loss: 0.652879
Average total loss: 0.960393
tensor(-9.2913, device='cuda:0') tensor(6.6903, device='cuda:0') tensor(2.2018e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.311040
Average KL loss: 0.651650
Average total loss: 0.962690
tensor(-9.2980, device='cuda:0') tensor(6.6938, device='cuda:0') tensor(1.9272e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.310793
Average KL loss: 0.650406
Average total loss: 0.961199
tensor(-9.3047, device='cuda:0') tensor(6.6972, device='cuda:0') tensor(1.5312e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.313449
Average KL loss: 0.649248
Average total loss: 0.962697
tensor(-9.3113, device='cuda:0') tensor(6.7008, device='cuda:0') tensor(2.3639e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.309750
Average KL loss: 0.648098
Average total loss: 0.957848
tensor(-9.3180, device='cuda:0') tensor(6.7041, device='cuda:0') tensor(2.0647e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.307723
Average KL loss: 0.646879
Average total loss: 0.954602
tensor(-9.3246, device='cuda:0') tensor(6.7073, device='cuda:0') tensor(1.2449e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.312170
Average KL loss: 0.645695
Average total loss: 0.957864
tensor(-9.3312, device='cuda:0') tensor(6.7105, device='cuda:0') tensor(2.2721e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.307239
Average KL loss: 0.644558
Average total loss: 0.951798
tensor(-9.3377, device='cuda:0') tensor(6.7137, device='cuda:0') tensor(1.3849e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.304338
Average KL loss: 0.643426
Average total loss: 0.947764
tensor(-9.3442, device='cuda:0') tensor(6.7169, device='cuda:0') tensor(2.2642e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.307143
Average KL loss: 0.642302
Average total loss: 0.949444
tensor(-9.3508, device='cuda:0') tensor(6.7197, device='cuda:0') tensor(2.3355e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.303499
Average KL loss: 0.641134
Average total loss: 0.944633
tensor(-9.3573, device='cuda:0') tensor(6.7226, device='cuda:0') tensor(2.0442e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.301935
Average KL loss: 0.639928
Average total loss: 0.941863
tensor(-9.3638, device='cuda:0') tensor(6.7252, device='cuda:0') tensor(2.0499e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.303377
Average KL loss: 0.638752
Average total loss: 0.942129
tensor(-9.3702, device='cuda:0') tensor(6.7279, device='cuda:0') tensor(2.6846e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.302308
Average KL loss: 0.637629
Average total loss: 0.939937
tensor(-9.3766, device='cuda:0') tensor(6.7304, device='cuda:0') tensor(2.0141e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.306023
Average KL loss: 0.636496
Average total loss: 0.942520
tensor(-9.3830, device='cuda:0') tensor(6.7330, device='cuda:0') tensor(1.7618e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.306585
Average KL loss: 0.635374
Average total loss: 0.941959
tensor(-9.3894, device='cuda:0') tensor(6.7354, device='cuda:0') tensor(1.8618e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.302470
Average KL loss: 0.634253
Average total loss: 0.936723
tensor(-9.3958, device='cuda:0') tensor(6.7378, device='cuda:0') tensor(1.6475e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.301416
Average KL loss: 0.633125
Average total loss: 0.934540
tensor(-9.4022, device='cuda:0') tensor(6.7399, device='cuda:0') tensor(1.5958e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.296262
Average KL loss: 0.632007
Average total loss: 0.928269
tensor(-9.4085, device='cuda:0') tensor(6.7420, device='cuda:0') tensor(1.8961e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.297940
Average KL loss: 0.630886
Average total loss: 0.928826
tensor(-9.4148, device='cuda:0') tensor(6.7440, device='cuda:0') tensor(1.1857e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.303104
Average KL loss: 0.629778
Average total loss: 0.932882
tensor(-9.4211, device='cuda:0') tensor(6.7461, device='cuda:0') tensor(2.0871e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.301916
Average KL loss: 0.628667
Average total loss: 0.930584
tensor(-9.4274, device='cuda:0') tensor(6.7481, device='cuda:0') tensor(1.7428e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.297357
Average KL loss: 0.627540
Average total loss: 0.924897
tensor(-9.4336, device='cuda:0') tensor(6.7501, device='cuda:0') tensor(1.8844e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.292361
Average KL loss: 0.626431
Average total loss: 0.918793
tensor(-9.4399, device='cuda:0') tensor(6.7518, device='cuda:0') tensor(1.4462e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.295197
Average KL loss: 0.625236
Average total loss: 0.920433
tensor(-9.4461, device='cuda:0') tensor(6.7533, device='cuda:0') tensor(2.2641e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.300481
Average KL loss: 0.624106
Average total loss: 0.924587
tensor(-9.4523, device='cuda:0') tensor(6.7550, device='cuda:0') tensor(1.1065e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.296545
Average KL loss: 0.623012
Average total loss: 0.919557
tensor(-9.4585, device='cuda:0') tensor(6.7566, device='cuda:0') tensor(1.6626e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.295811
Average KL loss: 0.621942
Average total loss: 0.917752
tensor(-9.4646, device='cuda:0') tensor(6.7581, device='cuda:0') tensor(1.9383e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.296646
Average KL loss: 0.620868
Average total loss: 0.917514
tensor(-9.4708, device='cuda:0') tensor(6.7596, device='cuda:0') tensor(2.0516e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.296002
Average KL loss: 0.619783
Average total loss: 0.915786
tensor(-9.4769, device='cuda:0') tensor(6.7611, device='cuda:0') tensor(1.7968e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.292656
Average KL loss: 0.618717
Average total loss: 0.911373
tensor(-9.4830, device='cuda:0') tensor(6.7626, device='cuda:0') tensor(1.5686e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.294907
Average KL loss: 0.617680
Average total loss: 0.912587
tensor(-9.4891, device='cuda:0') tensor(6.7638, device='cuda:0') tensor(1.6949e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.295995
Average KL loss: 0.616652
Average total loss: 0.912647
tensor(-9.4951, device='cuda:0') tensor(6.7651, device='cuda:0') tensor(1.4861e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.291324
Average KL loss: 0.615604
Average total loss: 0.906928
tensor(-9.5012, device='cuda:0') tensor(6.7663, device='cuda:0') tensor(1.8686e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.291176
Average KL loss: 0.614566
Average total loss: 0.905741
tensor(-9.5072, device='cuda:0') tensor(6.7674, device='cuda:0') tensor(1.3560e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.287224
Average KL loss: 0.613515
Average total loss: 0.900739
tensor(-9.5133, device='cuda:0') tensor(6.7685, device='cuda:0') tensor(1.7644e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.292535
Average KL loss: 0.612498
Average total loss: 0.905032
tensor(-9.5193, device='cuda:0') tensor(6.7696, device='cuda:0') tensor(1.8684e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.290139
Average KL loss: 0.611514
Average total loss: 0.901653
tensor(-9.5252, device='cuda:0') tensor(6.7705, device='cuda:0') tensor(1.5712e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.289769
Average KL loss: 0.610511
Average total loss: 0.900280
tensor(-9.5312, device='cuda:0') tensor(6.7715, device='cuda:0') tensor(1.8024e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.288932
Average KL loss: 0.609508
Average total loss: 0.898440
tensor(-9.5372, device='cuda:0') tensor(6.7722, device='cuda:0') tensor(1.7243e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.288831
Average KL loss: 0.608511
Average total loss: 0.897342
tensor(-9.5431, device='cuda:0') tensor(6.7731, device='cuda:0') tensor(1.5004e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.287367
Average KL loss: 0.607563
Average total loss: 0.894931
tensor(-9.5490, device='cuda:0') tensor(6.7739, device='cuda:0') tensor(2.0205e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.286824
Average KL loss: 0.606581
Average total loss: 0.893405
tensor(-9.5549, device='cuda:0') tensor(6.7746, device='cuda:0') tensor(1.3404e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.285445
Average KL loss: 0.605631
Average total loss: 0.891077
tensor(-9.5608, device='cuda:0') tensor(6.7752, device='cuda:0') tensor(1.5798e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.285301
Average KL loss: 0.604609
Average total loss: 0.889911
tensor(-9.5667, device='cuda:0') tensor(6.7757, device='cuda:0') tensor(1.6910e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.289637
Average KL loss: 0.603636
Average total loss: 0.893273
tensor(-9.5725, device='cuda:0') tensor(6.7762, device='cuda:0') tensor(1.6227e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.287052
Average KL loss: 0.602676
Average total loss: 0.889728
tensor(-9.5784, device='cuda:0') tensor(6.7766, device='cuda:0') tensor(1.4509e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.286259
Average KL loss: 0.601639
Average total loss: 0.887898
tensor(-9.5842, device='cuda:0') tensor(6.7770, device='cuda:0') tensor(1.2348e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.281721
Average KL loss: 0.600648
Average total loss: 0.882369
tensor(-9.5900, device='cuda:0') tensor(6.7773, device='cuda:0') tensor(1.6468e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.282282
Average KL loss: 0.599723
Average total loss: 0.882005
tensor(-9.5958, device='cuda:0') tensor(6.7776, device='cuda:0') tensor(1.6132e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.280026
Average KL loss: 0.598729
Average total loss: 0.878755
tensor(-9.6016, device='cuda:0') tensor(6.7779, device='cuda:0') tensor(1.0931e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.283675
Average KL loss: 0.597815
Average total loss: 0.881490
tensor(-9.6074, device='cuda:0') tensor(6.7781, device='cuda:0') tensor(1.6076e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.277222
Average KL loss: 0.596862
Average total loss: 0.874084
 Percentile value: -5.971364498138428
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =    1667 /    1728             ( 96.47%) | total_pruned =      61 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   25069 /   36864             ( 68.00%) | total_pruned =   11795 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   25555 /   36864             ( 69.32%) | total_pruned =   11309 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   24532 /   36864             ( 66.55%) | total_pruned =   12332 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   23915 /   36864             ( 64.87%) | total_pruned =   12949 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   47671 /   73728             ( 64.66%) | total_pruned =   26057 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   86730 /  147456             ( 58.82%) | total_pruned =   60726 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    6903 /    8192             ( 84.27%) | total_pruned =    1289 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   77697 /  147456             ( 52.69%) | total_pruned =   69759 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   78040 /  147456             ( 52.92%) | total_pruned =   69416 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  158312 /  294912             ( 53.68%) | total_pruned =  136600 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  278283 /  589824             ( 47.18%) | total_pruned =  311541 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   23901 /   32768             ( 72.94%) | total_pruned =    8867 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  190735 /  589824             ( 32.34%) | total_pruned =  399089 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  191773 /  589824             ( 32.51%) | total_pruned =  398051 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  399865 / 1179648             ( 33.90%) | total_pruned =  779783 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     484 /     512             ( 94.53%) | total_pruned =      28 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  503798 / 2359296             ( 21.35%) | total_pruned = 1855498 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   62152 /  131072             ( 47.42%) | total_pruned =   68920 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  279037 / 2359296             ( 11.83%) | total_pruned = 2080259 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     406 /     512             ( 79.30%) | total_pruned =     106 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     268 /     512             ( 52.34%) | total_pruned =     244 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  294944 / 2359296             ( 12.50%) | total_pruned = 2064352 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
linear.weight        | nonzeros =    4951 /    5120             ( 96.70%) | total_pruned =     169 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       7 /      10             ( 70.00%) | total_pruned =       3 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 30/100 Loss: 0.002360 Accuracy: 86.07 99.98 % Best test Accuracy: 86.74%
tensor(-9.6132, device='cuda:0') tensor(6.7781, device='cuda:0') tensor(1.1714e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.351724
Average KL loss: 0.575745
Average total loss: 0.927469
tensor(-9.6833, device='cuda:0') tensor(6.3453, device='cuda:0') tensor(8.9353e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.343133
Average KL loss: 0.559346
Average total loss: 0.902479
tensor(-9.7309, device='cuda:0') tensor(6.1114, device='cuda:0') tensor(6.1546e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.342858
Average KL loss: 0.552546
Average total loss: 0.895404
tensor(-9.7684, device='cuda:0') tensor(5.9527, device='cuda:0') tensor(1.1224e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.339436
Average KL loss: 0.548491
Average total loss: 0.887927
tensor(-9.8000, device='cuda:0') tensor(5.8347, device='cuda:0') tensor(1.4277e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.332194
Average KL loss: 0.545697
Average total loss: 0.877892
tensor(-9.8276, device='cuda:0') tensor(5.7421, device='cuda:0') tensor(8.3312e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.329613
Average KL loss: 0.543596
Average total loss: 0.873209
tensor(-9.8523, device='cuda:0') tensor(5.6670, device='cuda:0') tensor(9.2901e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.331813
Average KL loss: 0.541961
Average total loss: 0.873774
tensor(-9.8748, device='cuda:0') tensor(5.6045, device='cuda:0') tensor(4.4654e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.325255
Average KL loss: 0.540635
Average total loss: 0.865890
tensor(-9.8955, device='cuda:0') tensor(5.5515, device='cuda:0') tensor(1.1587e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.320840
Average KL loss: 0.539424
Average total loss: 0.860264
tensor(-9.9148, device='cuda:0') tensor(5.5059, device='cuda:0') tensor(8.8284e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.327716
Average KL loss: 0.538378
Average total loss: 0.866094
tensor(-9.9329, device='cuda:0') tensor(5.4661, device='cuda:0') tensor(7.9523e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.324767
Average KL loss: 0.537407
Average total loss: 0.862175
tensor(-9.9500, device='cuda:0') tensor(5.4311, device='cuda:0') tensor(5.3554e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.322341
Average KL loss: 0.536572
Average total loss: 0.858913
tensor(-9.9662, device='cuda:0') tensor(5.4002, device='cuda:0') tensor(1.7952e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.316715
Average KL loss: 0.535780
Average total loss: 0.852496
tensor(-9.9816, device='cuda:0') tensor(5.3726, device='cuda:0') tensor(1.1732e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.321574
Average KL loss: 0.535049
Average total loss: 0.856623
tensor(-9.9964, device='cuda:0') tensor(5.3478, device='cuda:0') tensor(1.2964e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.316722
Average KL loss: 0.534350
Average total loss: 0.851072
tensor(-10.0106, device='cuda:0') tensor(5.3256, device='cuda:0') tensor(3.8479e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.314644
Average KL loss: 0.533666
Average total loss: 0.848310
tensor(-10.0242, device='cuda:0') tensor(5.3054, device='cuda:0') tensor(6.6564e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.312046
Average KL loss: 0.533019
Average total loss: 0.845065
tensor(-10.0373, device='cuda:0') tensor(5.2872, device='cuda:0') tensor(1.0668e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.309303
Average KL loss: 0.532402
Average total loss: 0.841705
tensor(-10.0500, device='cuda:0') tensor(5.2705, device='cuda:0') tensor(8.4508e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.307197
Average KL loss: 0.531829
Average total loss: 0.839026
tensor(-10.0624, device='cuda:0') tensor(5.2553, device='cuda:0') tensor(1.0980e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.312020
Average KL loss: 0.531249
Average total loss: 0.843269
tensor(-10.0743, device='cuda:0') tensor(5.2415, device='cuda:0') tensor(4.6050e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.305810
Average KL loss: 0.530700
Average total loss: 0.836511
tensor(-10.0859, device='cuda:0') tensor(5.2286, device='cuda:0') tensor(1.0259e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.313754
Average KL loss: 0.530101
Average total loss: 0.843855
tensor(-10.0972, device='cuda:0') tensor(5.2169, device='cuda:0') tensor(1.0243e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.307886
Average KL loss: 0.529549
Average total loss: 0.837435
tensor(-10.1082, device='cuda:0') tensor(5.2061, device='cuda:0') tensor(8.1770e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.302463
Average KL loss: 0.529029
Average total loss: 0.831492
tensor(-10.1189, device='cuda:0') tensor(5.1961, device='cuda:0') tensor(9.1267e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.304863
Average KL loss: 0.528467
Average total loss: 0.833330
tensor(-10.1294, device='cuda:0') tensor(5.1866, device='cuda:0') tensor(4.4057e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.305229
Average KL loss: 0.527899
Average total loss: 0.833128
tensor(-10.1397, device='cuda:0') tensor(5.1782, device='cuda:0') tensor(1.1122e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.303350
Average KL loss: 0.527365
Average total loss: 0.830715
tensor(-10.1497, device='cuda:0') tensor(5.1702, device='cuda:0') tensor(1.2025e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.307205
Average KL loss: 0.526839
Average total loss: 0.834044
tensor(-10.1595, device='cuda:0') tensor(5.1627, device='cuda:0') tensor(9.0812e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.298869
Average KL loss: 0.526341
Average total loss: 0.825210
tensor(-10.1692, device='cuda:0') tensor(5.1557, device='cuda:0') tensor(9.0726e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.296924
Average KL loss: 0.525787
Average total loss: 0.822711
tensor(-10.1786, device='cuda:0') tensor(5.1493, device='cuda:0') tensor(8.7242e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.302555
Average KL loss: 0.525298
Average total loss: 0.827853
tensor(-10.1879, device='cuda:0') tensor(5.1433, device='cuda:0') tensor(1.1558e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.302695
Average KL loss: 0.524807
Average total loss: 0.827503
tensor(-10.1970, device='cuda:0') tensor(5.1378, device='cuda:0') tensor(1.3040e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.294395
Average KL loss: 0.524319
Average total loss: 0.818714
tensor(-10.2060, device='cuda:0') tensor(5.1325, device='cuda:0') tensor(5.8911e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.300106
Average KL loss: 0.523795
Average total loss: 0.823900
tensor(-10.2147, device='cuda:0') tensor(5.1277, device='cuda:0') tensor(8.3829e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.293815
Average KL loss: 0.523306
Average total loss: 0.817121
tensor(-10.2234, device='cuda:0') tensor(5.1232, device='cuda:0') tensor(1.4748e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.296244
Average KL loss: 0.522810
Average total loss: 0.819054
tensor(-10.2319, device='cuda:0') tensor(5.1191, device='cuda:0') tensor(9.0133e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.298454
Average KL loss: 0.522376
Average total loss: 0.820830
tensor(-10.2403, device='cuda:0') tensor(5.1151, device='cuda:0') tensor(1.0833e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.292260
Average KL loss: 0.521920
Average total loss: 0.814179
tensor(-10.2486, device='cuda:0') tensor(5.1115, device='cuda:0') tensor(6.7792e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.295149
Average KL loss: 0.521443
Average total loss: 0.816592
tensor(-10.2567, device='cuda:0') tensor(5.1080, device='cuda:0') tensor(6.6724e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.291957
Average KL loss: 0.520945
Average total loss: 0.812902
tensor(-10.2648, device='cuda:0') tensor(5.1046, device='cuda:0') tensor(1.0032e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.288248
Average KL loss: 0.520474
Average total loss: 0.808722
tensor(-10.2727, device='cuda:0') tensor(5.1015, device='cuda:0') tensor(1.0122e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.287005
Average KL loss: 0.519982
Average total loss: 0.806987
tensor(-10.2805, device='cuda:0') tensor(5.0986, device='cuda:0') tensor(9.8622e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.287693
Average KL loss: 0.519538
Average total loss: 0.807231
tensor(-10.2883, device='cuda:0') tensor(5.0960, device='cuda:0') tensor(9.0556e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.288372
Average KL loss: 0.519101
Average total loss: 0.807472
tensor(-10.2959, device='cuda:0') tensor(5.0934, device='cuda:0') tensor(6.0783e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.291583
Average KL loss: 0.518612
Average total loss: 0.810195
tensor(-10.3034, device='cuda:0') tensor(5.0910, device='cuda:0') tensor(5.5081e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.286437
Average KL loss: 0.518157
Average total loss: 0.804594
tensor(-10.3109, device='cuda:0') tensor(5.0888, device='cuda:0') tensor(1.0977e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.287652
Average KL loss: 0.517717
Average total loss: 0.805369
tensor(-10.3182, device='cuda:0') tensor(5.0867, device='cuda:0') tensor(1.1699e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.291361
Average KL loss: 0.517232
Average total loss: 0.808593
tensor(-10.3255, device='cuda:0') tensor(5.0847, device='cuda:0') tensor(8.8562e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.283077
Average KL loss: 0.516751
Average total loss: 0.799828
tensor(-10.3327, device='cuda:0') tensor(5.0828, device='cuda:0') tensor(1.2434e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.280332
Average KL loss: 0.516232
Average total loss: 0.796564
tensor(-10.3398, device='cuda:0') tensor(5.0808, device='cuda:0') tensor(8.7899e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.283219
Average KL loss: 0.515778
Average total loss: 0.798997
tensor(-10.3468, device='cuda:0') tensor(5.0794, device='cuda:0') tensor(5.4122e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.284446
Average KL loss: 0.515352
Average total loss: 0.799799
tensor(-10.3538, device='cuda:0') tensor(5.0778, device='cuda:0') tensor(1.1020e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.275959
Average KL loss: 0.514931
Average total loss: 0.790890
tensor(-10.3607, device='cuda:0') tensor(5.0763, device='cuda:0') tensor(1.0165e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.281456
Average KL loss: 0.514480
Average total loss: 0.795936
tensor(-10.3676, device='cuda:0') tensor(5.0748, device='cuda:0') tensor(1.2796e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.284230
Average KL loss: 0.514006
Average total loss: 0.798235
tensor(-10.3743, device='cuda:0') tensor(5.0735, device='cuda:0') tensor(9.8033e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.284175
Average KL loss: 0.513576
Average total loss: 0.797751
tensor(-10.3810, device='cuda:0') tensor(5.0723, device='cuda:0') tensor(9.5663e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.281186
Average KL loss: 0.513152
Average total loss: 0.794337
tensor(-10.3876, device='cuda:0') tensor(5.0712, device='cuda:0') tensor(1.0447e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.277432
Average KL loss: 0.512692
Average total loss: 0.790124
tensor(-10.3942, device='cuda:0') tensor(5.0700, device='cuda:0') tensor(7.5308e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.279752
Average KL loss: 0.512199
Average total loss: 0.791952
tensor(-10.4007, device='cuda:0') tensor(5.0689, device='cuda:0') tensor(1.2512e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.275677
Average KL loss: 0.511741
Average total loss: 0.787418
tensor(-10.4072, device='cuda:0') tensor(5.0678, device='cuda:0') tensor(7.6126e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.273005
Average KL loss: 0.511281
Average total loss: 0.784286
tensor(-10.4136, device='cuda:0') tensor(5.0669, device='cuda:0') tensor(1.3852e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.274059
Average KL loss: 0.510867
Average total loss: 0.784926
tensor(-10.4199, device='cuda:0') tensor(5.0661, device='cuda:0') tensor(7.1168e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.275395
Average KL loss: 0.510400
Average total loss: 0.785795
tensor(-10.4262, device='cuda:0') tensor(5.0653, device='cuda:0') tensor(9.4262e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.273967
Average KL loss: 0.510005
Average total loss: 0.783973
tensor(-10.4324, device='cuda:0') tensor(5.0646, device='cuda:0') tensor(8.8764e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.274034
Average KL loss: 0.509603
Average total loss: 0.783636
tensor(-10.4386, device='cuda:0') tensor(5.0639, device='cuda:0') tensor(8.5588e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.273968
Average KL loss: 0.509156
Average total loss: 0.783123
tensor(-10.4448, device='cuda:0') tensor(5.0633, device='cuda:0') tensor(9.7610e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.273865
Average KL loss: 0.508741
Average total loss: 0.782605
tensor(-10.4509, device='cuda:0') tensor(5.0626, device='cuda:0') tensor(1.1919e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.265700
Average KL loss: 0.508345
Average total loss: 0.774046
tensor(-10.4569, device='cuda:0') tensor(5.0620, device='cuda:0') tensor(5.5941e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.269247
Average KL loss: 0.507930
Average total loss: 0.777177
tensor(-10.4629, device='cuda:0') tensor(5.0615, device='cuda:0') tensor(1.0691e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.275790
Average KL loss: 0.507495
Average total loss: 0.783286
tensor(-10.4688, device='cuda:0') tensor(5.0608, device='cuda:0') tensor(9.8334e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.270271
Average KL loss: 0.507071
Average total loss: 0.777343
tensor(-10.4748, device='cuda:0') tensor(5.0602, device='cuda:0') tensor(9.0421e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.273594
Average KL loss: 0.506658
Average total loss: 0.780252
tensor(-10.4806, device='cuda:0') tensor(5.0597, device='cuda:0') tensor(8.2426e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.266186
Average KL loss: 0.506228
Average total loss: 0.772414
tensor(-10.4864, device='cuda:0') tensor(5.0592, device='cuda:0') tensor(1.2483e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.269621
Average KL loss: 0.505810
Average total loss: 0.775431
tensor(-10.4922, device='cuda:0') tensor(5.0586, device='cuda:0') tensor(7.2242e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.267071
Average KL loss: 0.505320
Average total loss: 0.772391
tensor(-10.4980, device='cuda:0') tensor(5.0580, device='cuda:0') tensor(1.0567e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.263855
Average KL loss: 0.504841
Average total loss: 0.768695
tensor(-10.5037, device='cuda:0') tensor(5.0575, device='cuda:0') tensor(7.9692e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.265064
Average KL loss: 0.504392
Average total loss: 0.769456
tensor(-10.5093, device='cuda:0') tensor(5.0571, device='cuda:0') tensor(9.3456e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.263546
Average KL loss: 0.503967
Average total loss: 0.767513
tensor(-10.5149, device='cuda:0') tensor(5.0566, device='cuda:0') tensor(9.5690e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.262654
Average KL loss: 0.503546
Average total loss: 0.766200
tensor(-10.5205, device='cuda:0') tensor(5.0562, device='cuda:0') tensor(7.8619e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.262750
Average KL loss: 0.503143
Average total loss: 0.765893
tensor(-10.5261, device='cuda:0') tensor(5.0558, device='cuda:0') tensor(5.1751e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.258764
Average KL loss: 0.502729
Average total loss: 0.761493
tensor(-10.5316, device='cuda:0') tensor(5.0555, device='cuda:0') tensor(5.1305e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.263225
Average KL loss: 0.502321
Average total loss: 0.765546
tensor(-10.5371, device='cuda:0') tensor(5.0550, device='cuda:0') tensor(1.2059e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.260889
Average KL loss: 0.501894
Average total loss: 0.762783
tensor(-10.5425, device='cuda:0') tensor(5.0546, device='cuda:0') tensor(5.9615e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.263949
Average KL loss: 0.501450
Average total loss: 0.765399
tensor(-10.5480, device='cuda:0') tensor(5.0541, device='cuda:0') tensor(1.5822e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.263621
Average KL loss: 0.501074
Average total loss: 0.764694
tensor(-10.5533, device='cuda:0') tensor(5.0538, device='cuda:0') tensor(7.1013e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.256845
Average KL loss: 0.500667
Average total loss: 0.757512
tensor(-10.5587, device='cuda:0') tensor(5.0533, device='cuda:0') tensor(6.1269e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.258190
Average KL loss: 0.500219
Average total loss: 0.758409
tensor(-10.5640, device='cuda:0') tensor(5.0529, device='cuda:0') tensor(8.1437e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.256379
Average KL loss: 0.499774
Average total loss: 0.756153
tensor(-10.5693, device='cuda:0') tensor(5.0524, device='cuda:0') tensor(1.2770e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.256609
Average KL loss: 0.499327
Average total loss: 0.755935
tensor(-10.5746, device='cuda:0') tensor(5.0520, device='cuda:0') tensor(1.0411e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.257203
Average KL loss: 0.498881
Average total loss: 0.756084
tensor(-10.5798, device='cuda:0') tensor(5.0515, device='cuda:0') tensor(8.5206e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.257249
Average KL loss: 0.498409
Average total loss: 0.755658
tensor(-10.5850, device='cuda:0') tensor(5.0510, device='cuda:0') tensor(9.1835e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.257483
Average KL loss: 0.497948
Average total loss: 0.755431
tensor(-10.5902, device='cuda:0') tensor(5.0504, device='cuda:0') tensor(8.0926e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.256582
Average KL loss: 0.497514
Average total loss: 0.754095
tensor(-10.5953, device='cuda:0') tensor(5.0500, device='cuda:0') tensor(1.0616e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.256767
Average KL loss: 0.497113
Average total loss: 0.753880
tensor(-10.6004, device='cuda:0') tensor(5.0497, device='cuda:0') tensor(1.1578e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.252682
Average KL loss: 0.496697
Average total loss: 0.749378
tensor(-10.6055, device='cuda:0') tensor(5.0492, device='cuda:0') tensor(1.3632e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.257602
Average KL loss: 0.496247
Average total loss: 0.753849
tensor(-10.6106, device='cuda:0') tensor(5.0487, device='cuda:0') tensor(7.9384e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.256542
Average KL loss: 0.495863
Average total loss: 0.752405
tensor(-10.6156, device='cuda:0') tensor(5.0483, device='cuda:0') tensor(9.8857e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.252152
Average KL loss: 0.495455
Average total loss: 0.747607
tensor(-10.6206, device='cuda:0') tensor(5.0478, device='cuda:0') tensor(4.5667e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.250769
Average KL loss: 0.495037
Average total loss: 0.745806
tensor(-10.6256, device='cuda:0') tensor(5.0473, device='cuda:0') tensor(6.4638e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.254344
Average KL loss: 0.494638
Average total loss: 0.748982
tensor(-10.6306, device='cuda:0') tensor(5.0469, device='cuda:0') tensor(1.0070e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.250883
Average KL loss: 0.494190
Average total loss: 0.745072
tensor(-10.6355, device='cuda:0') tensor(5.0464, device='cuda:0') tensor(9.6069e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.251433
Average KL loss: 0.493765
Average total loss: 0.745199
tensor(-10.6404, device='cuda:0') tensor(5.0459, device='cuda:0') tensor(1.0131e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.247232
Average KL loss: 0.493356
Average total loss: 0.740588
tensor(-10.6453, device='cuda:0') tensor(5.0454, device='cuda:0') tensor(5.9456e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.244974
Average KL loss: 0.492946
Average total loss: 0.737920
tensor(-10.6502, device='cuda:0') tensor(5.0449, device='cuda:0') tensor(1.0328e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.248255
Average KL loss: 0.492530
Average total loss: 0.740785
tensor(-10.6550, device='cuda:0') tensor(5.0444, device='cuda:0') tensor(4.9408e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.248459
Average KL loss: 0.492117
Average total loss: 0.740576
tensor(-10.6598, device='cuda:0') tensor(5.0438, device='cuda:0') tensor(8.4083e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.248418
Average KL loss: 0.491685
Average total loss: 0.740104
tensor(-10.6646, device='cuda:0') tensor(5.0433, device='cuda:0') tensor(1.2253e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.247282
Average KL loss: 0.491241
Average total loss: 0.738523
tensor(-10.6694, device='cuda:0') tensor(5.0427, device='cuda:0') tensor(1.1724e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.247504
Average KL loss: 0.490779
Average total loss: 0.738283
tensor(-10.6742, device='cuda:0') tensor(5.0420, device='cuda:0') tensor(1.1965e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.244128
Average KL loss: 0.490338
Average total loss: 0.734466
tensor(-10.6789, device='cuda:0') tensor(5.0414, device='cuda:0') tensor(5.1291e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.246788
Average KL loss: 0.489902
Average total loss: 0.736689
tensor(-10.6836, device='cuda:0') tensor(5.0407, device='cuda:0') tensor(1.0724e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.248811
Average KL loss: 0.489471
Average total loss: 0.738281
tensor(-10.6883, device='cuda:0') tensor(5.0402, device='cuda:0') tensor(7.7230e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.242330
Average KL loss: 0.489038
Average total loss: 0.731368
tensor(-10.6930, device='cuda:0') tensor(5.0395, device='cuda:0') tensor(8.5805e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.245179
Average KL loss: 0.488618
Average total loss: 0.733797
tensor(-10.6976, device='cuda:0') tensor(5.0389, device='cuda:0') tensor(1.2115e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.243703
Average KL loss: 0.488193
Average total loss: 0.731896
tensor(-10.7022, device='cuda:0') tensor(5.0382, device='cuda:0') tensor(5.3575e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.244328
Average KL loss: 0.487787
Average total loss: 0.732116
tensor(-10.7068, device='cuda:0') tensor(5.0376, device='cuda:0') tensor(4.1846e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.245098
Average KL loss: 0.487413
Average total loss: 0.732511
tensor(-10.7114, device='cuda:0') tensor(5.0370, device='cuda:0') tensor(7.1941e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.241768
Average KL loss: 0.487027
Average total loss: 0.728795
tensor(-10.7160, device='cuda:0') tensor(5.0362, device='cuda:0') tensor(7.3117e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.240483
Average KL loss: 0.486633
Average total loss: 0.727117
tensor(-10.7206, device='cuda:0') tensor(5.0355, device='cuda:0') tensor(8.5765e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.243076
Average KL loss: 0.486213
Average total loss: 0.729290
tensor(-10.7251, device='cuda:0') tensor(5.0347, device='cuda:0') tensor(9.4486e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.238349
Average KL loss: 0.485774
Average total loss: 0.724123
tensor(-10.7296, device='cuda:0') tensor(5.0339, device='cuda:0') tensor(7.2876e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.239273
Average KL loss: 0.485361
Average total loss: 0.724634
tensor(-10.7341, device='cuda:0') tensor(5.0331, device='cuda:0') tensor(1.0919e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.239656
Average KL loss: 0.484961
Average total loss: 0.724617
tensor(-10.7386, device='cuda:0') tensor(5.0324, device='cuda:0') tensor(1.0201e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.238546
Average KL loss: 0.484581
Average total loss: 0.723127
tensor(-10.7430, device='cuda:0') tensor(5.0317, device='cuda:0') tensor(8.9031e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.238108
Average KL loss: 0.484170
Average total loss: 0.722278
tensor(-10.7475, device='cuda:0') tensor(5.0309, device='cuda:0') tensor(1.1012e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.239213
Average KL loss: 0.483789
Average total loss: 0.723001
tensor(-10.7519, device='cuda:0') tensor(5.0301, device='cuda:0') tensor(9.7924e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.238588
Average KL loss: 0.483423
Average total loss: 0.722010
tensor(-10.7563, device='cuda:0') tensor(5.0293, device='cuda:0') tensor(6.1900e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.240737
Average KL loss: 0.483054
Average total loss: 0.723791
tensor(-10.7607, device='cuda:0') tensor(5.0285, device='cuda:0') tensor(7.9386e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.236442
Average KL loss: 0.482663
Average total loss: 0.719105
tensor(-10.7651, device='cuda:0') tensor(5.0277, device='cuda:0') tensor(8.3393e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.237429
Average KL loss: 0.482302
Average total loss: 0.719731
tensor(-10.7694, device='cuda:0') tensor(5.0270, device='cuda:0') tensor(8.2716e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.234437
Average KL loss: 0.481911
Average total loss: 0.716348
tensor(-10.7738, device='cuda:0') tensor(5.0262, device='cuda:0') tensor(7.1559e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.237350
Average KL loss: 0.481512
Average total loss: 0.718863
tensor(-10.7781, device='cuda:0') tensor(5.0254, device='cuda:0') tensor(6.9195e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.231894
Average KL loss: 0.481080
Average total loss: 0.712974
tensor(-10.7824, device='cuda:0') tensor(5.0243, device='cuda:0') tensor(5.8306e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.232256
Average KL loss: 0.480622
Average total loss: 0.712878
tensor(-10.7867, device='cuda:0') tensor(5.0235, device='cuda:0') tensor(8.8045e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.232769
Average KL loss: 0.480185
Average total loss: 0.712954
tensor(-10.7910, device='cuda:0') tensor(5.0225, device='cuda:0') tensor(4.5269e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.232340
Average KL loss: 0.479767
Average total loss: 0.712106
tensor(-10.7952, device='cuda:0') tensor(5.0216, device='cuda:0') tensor(8.2894e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.231703
Average KL loss: 0.479403
Average total loss: 0.711106
tensor(-10.7995, device='cuda:0') tensor(5.0207, device='cuda:0') tensor(5.0112e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.229470
Average KL loss: 0.479032
Average total loss: 0.708502
tensor(-10.8037, device='cuda:0') tensor(5.0198, device='cuda:0') tensor(1.0437e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.232901
Average KL loss: 0.478678
Average total loss: 0.711579
tensor(-10.8079, device='cuda:0') tensor(5.0189, device='cuda:0') tensor(9.2578e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.227868
Average KL loss: 0.478299
Average total loss: 0.706167
tensor(-10.8121, device='cuda:0') tensor(5.0179, device='cuda:0') tensor(5.1457e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.230780
Average KL loss: 0.477904
Average total loss: 0.708684
tensor(-10.8163, device='cuda:0') tensor(5.0168, device='cuda:0') tensor(2.8374e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.229484
Average KL loss: 0.477522
Average total loss: 0.707006
tensor(-10.8205, device='cuda:0') tensor(5.0158, device='cuda:0') tensor(5.1443e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.229321
Average KL loss: 0.477113
Average total loss: 0.706434
tensor(-10.8247, device='cuda:0') tensor(5.0147, device='cuda:0') tensor(8.7248e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.226769
Average KL loss: 0.476735
Average total loss: 0.703504
tensor(-10.8288, device='cuda:0') tensor(5.0136, device='cuda:0') tensor(1.0319e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.225888
Average KL loss: 0.476334
Average total loss: 0.702222
tensor(-10.8330, device='cuda:0') tensor(5.0125, device='cuda:0') tensor(1.7490e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.227374
Average KL loss: 0.475969
Average total loss: 0.703343
tensor(-10.8371, device='cuda:0') tensor(5.0115, device='cuda:0') tensor(6.1424e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.230477
Average KL loss: 0.475608
Average total loss: 0.706085
tensor(-10.8412, device='cuda:0') tensor(5.0104, device='cuda:0') tensor(7.9233e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.233291
Average KL loss: 0.475269
Average total loss: 0.708560
tensor(-10.8453, device='cuda:0') tensor(5.0095, device='cuda:0') tensor(4.1619e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.229418
Average KL loss: 0.474937
Average total loss: 0.704355
tensor(-10.8494, device='cuda:0') tensor(5.0084, device='cuda:0') tensor(1.0495e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.228168
Average KL loss: 0.474581
Average total loss: 0.702748
tensor(-10.8534, device='cuda:0') tensor(5.0073, device='cuda:0') tensor(7.0217e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.225077
Average KL loss: 0.474210
Average total loss: 0.699287
tensor(-10.8575, device='cuda:0') tensor(5.0062, device='cuda:0') tensor(3.3554e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.225443
Average KL loss: 0.473870
Average total loss: 0.699312
tensor(-10.8615, device='cuda:0') tensor(5.0052, device='cuda:0') tensor(3.1935e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.227045
Average KL loss: 0.473510
Average total loss: 0.700555
tensor(-10.8656, device='cuda:0') tensor(5.0039, device='cuda:0') tensor(1.0065e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.224518
Average KL loss: 0.473107
Average total loss: 0.697625
tensor(-10.8696, device='cuda:0') tensor(5.0027, device='cuda:0') tensor(9.1171e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.224707
Average KL loss: 0.472722
Average total loss: 0.697429
tensor(-10.8736, device='cuda:0') tensor(5.0014, device='cuda:0') tensor(5.9474e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.224426
Average KL loss: 0.472344
Average total loss: 0.696769
tensor(-10.8776, device='cuda:0') tensor(5.0002, device='cuda:0') tensor(7.3231e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.221647
Average KL loss: 0.471965
Average total loss: 0.693612
tensor(-10.8816, device='cuda:0') tensor(4.9990, device='cuda:0') tensor(9.7010e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.221289
Average KL loss: 0.471584
Average total loss: 0.692873
tensor(-10.8855, device='cuda:0') tensor(4.9978, device='cuda:0') tensor(1.0720e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.223934
Average KL loss: 0.471196
Average total loss: 0.695129
tensor(-10.8895, device='cuda:0') tensor(4.9964, device='cuda:0') tensor(7.2489e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.218562
Average KL loss: 0.470778
Average total loss: 0.689340
tensor(-10.8934, device='cuda:0') tensor(4.9950, device='cuda:0') tensor(9.0242e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.218793
Average KL loss: 0.470412
Average total loss: 0.689205
tensor(-10.8974, device='cuda:0') tensor(4.9936, device='cuda:0') tensor(9.3118e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.215783
Average KL loss: 0.470024
Average total loss: 0.685807
tensor(-10.9013, device='cuda:0') tensor(4.9922, device='cuda:0') tensor(2.0746e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.219813
Average KL loss: 0.469664
Average total loss: 0.689478
tensor(-10.9052, device='cuda:0') tensor(4.9910, device='cuda:0') tensor(7.0587e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.220374
Average KL loss: 0.469300
Average total loss: 0.689674
tensor(-10.9091, device='cuda:0') tensor(4.9897, device='cuda:0') tensor(1.1751e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.224690
Average KL loss: 0.468895
Average total loss: 0.693585
tensor(-10.9130, device='cuda:0') tensor(4.9882, device='cuda:0') tensor(1.1954e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.222644
Average KL loss: 0.468521
Average total loss: 0.691165
tensor(-10.9169, device='cuda:0') tensor(4.9868, device='cuda:0') tensor(4.4660e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.220244
Average KL loss: 0.468171
Average total loss: 0.688415
tensor(-10.9208, device='cuda:0') tensor(4.9854, device='cuda:0') tensor(8.9388e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.220332
Average KL loss: 0.467804
Average total loss: 0.688135
tensor(-10.9246, device='cuda:0') tensor(4.9840, device='cuda:0') tensor(7.0045e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.218595
Average KL loss: 0.467443
Average total loss: 0.686038
tensor(-10.9285, device='cuda:0') tensor(4.9826, device='cuda:0') tensor(7.4789e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.218937
Average KL loss: 0.467084
Average total loss: 0.686020
tensor(-10.9323, device='cuda:0') tensor(4.9812, device='cuda:0') tensor(8.1792e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.216163
Average KL loss: 0.466745
Average total loss: 0.682908
tensor(-10.9361, device='cuda:0') tensor(4.9797, device='cuda:0') tensor(8.7229e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.218580
Average KL loss: 0.466411
Average total loss: 0.684991
tensor(-10.9399, device='cuda:0') tensor(4.9783, device='cuda:0') tensor(5.2989e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.216425
Average KL loss: 0.466090
Average total loss: 0.682515
tensor(-10.9438, device='cuda:0') tensor(4.9769, device='cuda:0') tensor(6.7967e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.216102
Average KL loss: 0.465764
Average total loss: 0.681866
tensor(-10.9476, device='cuda:0') tensor(4.9753, device='cuda:0') tensor(6.7592e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.213904
Average KL loss: 0.465391
Average total loss: 0.679295
tensor(-10.9513, device='cuda:0') tensor(4.9737, device='cuda:0') tensor(7.9606e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.215836
Average KL loss: 0.465039
Average total loss: 0.680875
tensor(-10.9551, device='cuda:0') tensor(4.9721, device='cuda:0') tensor(8.1703e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.213903
Average KL loss: 0.464665
Average total loss: 0.678568
tensor(-10.9589, device='cuda:0') tensor(4.9705, device='cuda:0') tensor(3.3147e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.214169
Average KL loss: 0.464315
Average total loss: 0.678484
tensor(-10.9627, device='cuda:0') tensor(4.9690, device='cuda:0') tensor(6.6782e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.213766
Average KL loss: 0.463996
Average total loss: 0.677762
tensor(-10.9664, device='cuda:0') tensor(4.9675, device='cuda:0') tensor(6.7814e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.212118
Average KL loss: 0.463671
Average total loss: 0.675788
tensor(-10.9701, device='cuda:0') tensor(4.9658, device='cuda:0') tensor(7.0598e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.214976
Average KL loss: 0.463301
Average total loss: 0.678277
tensor(-10.9739, device='cuda:0') tensor(4.9642, device='cuda:0') tensor(6.0923e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.210627
Average KL loss: 0.462967
Average total loss: 0.673593
tensor(-10.9776, device='cuda:0') tensor(4.9627, device='cuda:0') tensor(8.2273e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.209212
Average KL loss: 0.462642
Average total loss: 0.671854
tensor(-10.9813, device='cuda:0') tensor(4.9610, device='cuda:0') tensor(6.5473e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.210063
Average KL loss: 0.462281
Average total loss: 0.672343
tensor(-10.9850, device='cuda:0') tensor(4.9593, device='cuda:0') tensor(8.5565e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.210329
Average KL loss: 0.461919
Average total loss: 0.672247
tensor(-10.9887, device='cuda:0') tensor(4.9576, device='cuda:0') tensor(6.1266e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.207973
Average KL loss: 0.461555
Average total loss: 0.669529
tensor(-10.9924, device='cuda:0') tensor(4.9560, device='cuda:0') tensor(7.9618e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.208951
Average KL loss: 0.461237
Average total loss: 0.670187
tensor(-10.9960, device='cuda:0') tensor(4.9543, device='cuda:0') tensor(4.6469e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.208643
Average KL loss: 0.460887
Average total loss: 0.669530
tensor(-10.9997, device='cuda:0') tensor(4.9525, device='cuda:0') tensor(9.3369e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.208677
Average KL loss: 0.460536
Average total loss: 0.669213
tensor(-11.0034, device='cuda:0') tensor(4.9507, device='cuda:0') tensor(4.5610e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.206003
Average KL loss: 0.460189
Average total loss: 0.666193
tensor(-11.0070, device='cuda:0') tensor(4.9491, device='cuda:0') tensor(6.4352e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.208910
Average KL loss: 0.459875
Average total loss: 0.668785
tensor(-11.0106, device='cuda:0') tensor(4.9474, device='cuda:0') tensor(8.7847e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.207201
Average KL loss: 0.459527
Average total loss: 0.666728
tensor(-11.0143, device='cuda:0') tensor(4.9456, device='cuda:0') tensor(6.6497e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.208636
Average KL loss: 0.459194
Average total loss: 0.667830
tensor(-11.0179, device='cuda:0') tensor(4.9438, device='cuda:0') tensor(1.3310e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.203157
Average KL loss: 0.458873
Average total loss: 0.662030
tensor(-11.0215, device='cuda:0') tensor(4.9419, device='cuda:0') tensor(7.9514e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.204375
Average KL loss: 0.458518
Average total loss: 0.662893
tensor(-11.0251, device='cuda:0') tensor(4.9400, device='cuda:0') tensor(8.6522e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.207272
Average KL loss: 0.458171
Average total loss: 0.665444
tensor(-11.0287, device='cuda:0') tensor(4.9382, device='cuda:0') tensor(7.8376e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.201435
Average KL loss: 0.457820
Average total loss: 0.659255
tensor(-11.0323, device='cuda:0') tensor(4.9365, device='cuda:0') tensor(9.1033e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.201172
Average KL loss: 0.457473
Average total loss: 0.658645
tensor(-11.0359, device='cuda:0') tensor(4.9346, device='cuda:0') tensor(2.3779e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.204502
Average KL loss: 0.457121
Average total loss: 0.661623
tensor(-11.0394, device='cuda:0') tensor(4.9327, device='cuda:0') tensor(6.8654e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.203803
Average KL loss: 0.456808
Average total loss: 0.660611
 Percentile value: -6.299157619476318
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =    1591 /    1728             ( 92.07%) | total_pruned =     137 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   18085 /   36864             ( 49.06%) | total_pruned =   18779 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   18528 /   36864             ( 50.26%) | total_pruned =   18336 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   16857 /   36864             ( 45.73%) | total_pruned =   20007 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   16110 /   36864             ( 43.70%) | total_pruned =   20754 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   33315 /   73728             ( 45.19%) | total_pruned =   40413 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   57403 /  147456             ( 38.93%) | total_pruned =   90053 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5642 /    8192             ( 68.87%) | total_pruned =    2550 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   47621 /  147456             ( 32.30%) | total_pruned =   99835 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   47952 /  147456             ( 32.52%) | total_pruned =   99504 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   99243 /  294912             ( 33.65%) | total_pruned =  195669 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  161956 /  589824             ( 27.46%) | total_pruned =  427868 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   17282 /   32768             ( 52.74%) | total_pruned =   15486 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   92131 /  589824             ( 15.62%) | total_pruned =  497693 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     181 /     256             ( 70.70%) | total_pruned =      75 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   94612 /  589824             ( 16.04%) | total_pruned =  495212 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  186158 / 1179648             ( 15.78%) | total_pruned =  993490 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     452 /     512             ( 88.28%) | total_pruned =      60 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     381 /     512             ( 74.41%) | total_pruned =     131 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  203254 / 2359296             (  8.62%) | total_pruned = 2156042 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     485 /     512             ( 94.73%) | total_pruned =      27 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   32436 /  131072             ( 24.75%) | total_pruned =   98636 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  108682 / 2359296             (  4.61%) | total_pruned = 2250614 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     298 /     512             ( 58.20%) | total_pruned =     214 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     162 /     512             ( 31.64%) | total_pruned =     350 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  125233 / 2359296             (  5.31%) | total_pruned = 2234063 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
linear.weight        | nonzeros =    4711 /    5120             ( 92.01%) | total_pruned =     409 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 24/100 Loss: 0.000025 Accuracy: 86.61 100.00 % Best test Accuracy: 86.68%
tensor(-11.0430, device='cuda:0') tensor(4.9309, device='cuda:0') tensor(7.4637e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.277219
Average KL loss: 0.448135
Average total loss: 0.725354
tensor(-11.0742, device='cuda:0') tensor(4.6670, device='cuda:0') tensor(4.0164e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.266801
Average KL loss: 0.441740
Average total loss: 0.708541
tensor(-11.0955, device='cuda:0') tensor(4.5197, device='cuda:0') tensor(5.5719e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.261001
Average KL loss: 0.439177
Average total loss: 0.700178
tensor(-11.1126, device='cuda:0') tensor(4.4168, device='cuda:0') tensor(1.3206e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.258571
Average KL loss: 0.437734
Average total loss: 0.696304
tensor(-11.1271, device='cuda:0') tensor(4.3382, device='cuda:0') tensor(-3.2911e-11, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.249466
Average KL loss: 0.436738
Average total loss: 0.686204
tensor(-11.1399, device='cuda:0') tensor(4.2748, device='cuda:0') tensor(8.6287e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.250010
Average KL loss: 0.436027
Average total loss: 0.686037
tensor(-11.1515, device='cuda:0') tensor(4.2221, device='cuda:0') tensor(4.6216e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.252269
Average KL loss: 0.435479
Average total loss: 0.687747
tensor(-11.1621, device='cuda:0') tensor(4.1773, device='cuda:0') tensor(-7.2637e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.245333
Average KL loss: 0.435052
Average total loss: 0.680385
tensor(-11.1720, device='cuda:0') tensor(4.1384, device='cuda:0') tensor(9.8025e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.245390
Average KL loss: 0.434688
Average total loss: 0.680078
tensor(-11.1813, device='cuda:0') tensor(4.1040, device='cuda:0') tensor(8.0334e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.242590
Average KL loss: 0.434350
Average total loss: 0.676940
tensor(-11.1901, device='cuda:0') tensor(4.0735, device='cuda:0') tensor(1.8370e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.240617
Average KL loss: 0.434095
Average total loss: 0.674712
tensor(-11.1985, device='cuda:0') tensor(4.0461, device='cuda:0') tensor(5.6805e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.239200
Average KL loss: 0.433843
Average total loss: 0.673043
tensor(-11.2065, device='cuda:0') tensor(4.0211, device='cuda:0') tensor(4.5219e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.240334
Average KL loss: 0.433571
Average total loss: 0.673905
tensor(-11.2141, device='cuda:0') tensor(3.9983, device='cuda:0') tensor(5.6994e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.236156
Average KL loss: 0.433310
Average total loss: 0.669465
tensor(-11.2215, device='cuda:0') tensor(3.9774, device='cuda:0') tensor(6.3785e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.234364
Average KL loss: 0.433064
Average total loss: 0.667427
tensor(-11.2287, device='cuda:0') tensor(3.9581, device='cuda:0') tensor(3.9327e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.237381
Average KL loss: 0.432874
Average total loss: 0.670254
tensor(-11.2356, device='cuda:0') tensor(3.9404, device='cuda:0') tensor(9.9736e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.232055
Average KL loss: 0.432701
Average total loss: 0.664757
tensor(-11.2423, device='cuda:0') tensor(3.9239, device='cuda:0') tensor(5.5312e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.233718
Average KL loss: 0.432489
Average total loss: 0.666206
tensor(-11.2488, device='cuda:0') tensor(3.9084, device='cuda:0') tensor(5.3562e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.231709
Average KL loss: 0.432323
Average total loss: 0.664032
tensor(-11.2552, device='cuda:0') tensor(3.8939, device='cuda:0') tensor(5.4917e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.231953
Average KL loss: 0.432136
Average total loss: 0.664089
tensor(-11.2614, device='cuda:0') tensor(3.8802, device='cuda:0') tensor(3.8978e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.231749
Average KL loss: 0.431938
Average total loss: 0.663687
tensor(-11.2675, device='cuda:0') tensor(3.8674, device='cuda:0') tensor(5.1534e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.226287
Average KL loss: 0.431731
Average total loss: 0.658018
tensor(-11.2734, device='cuda:0') tensor(3.8554, device='cuda:0') tensor(6.8384e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.224726
Average KL loss: 0.431578
Average total loss: 0.656304
tensor(-11.2792, device='cuda:0') tensor(3.8440, device='cuda:0') tensor(8.7728e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.223390
Average KL loss: 0.431437
Average total loss: 0.654827
tensor(-11.2849, device='cuda:0') tensor(3.8332, device='cuda:0') tensor(3.7183e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.226853
Average KL loss: 0.431268
Average total loss: 0.658120
tensor(-11.2905, device='cuda:0') tensor(3.8229, device='cuda:0') tensor(7.8460e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.222122
Average KL loss: 0.431118
Average total loss: 0.653240
tensor(-11.2960, device='cuda:0') tensor(3.8131, device='cuda:0') tensor(5.9283e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.223424
Average KL loss: 0.430954
Average total loss: 0.654378
tensor(-11.3014, device='cuda:0') tensor(3.8039, device='cuda:0') tensor(5.2302e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.220606
Average KL loss: 0.430790
Average total loss: 0.651396
tensor(-11.3068, device='cuda:0') tensor(3.7950, device='cuda:0') tensor(4.6556e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.221455
Average KL loss: 0.430626
Average total loss: 0.652081
tensor(-11.3120, device='cuda:0') tensor(3.7866, device='cuda:0') tensor(6.2306e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.223078
Average KL loss: 0.430424
Average total loss: 0.653502
tensor(-11.3171, device='cuda:0') tensor(3.7784, device='cuda:0') tensor(6.5596e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.223304
Average KL loss: 0.430252
Average total loss: 0.653556
tensor(-11.3222, device='cuda:0') tensor(3.7707, device='cuda:0') tensor(2.1611e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.216204
Average KL loss: 0.430108
Average total loss: 0.646312
tensor(-11.3273, device='cuda:0') tensor(3.7632, device='cuda:0') tensor(5.4601e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.217896
Average KL loss: 0.429958
Average total loss: 0.647853
tensor(-11.3322, device='cuda:0') tensor(3.7561, device='cuda:0') tensor(5.4176e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.215944
Average KL loss: 0.429814
Average total loss: 0.645758
tensor(-11.3371, device='cuda:0') tensor(3.7492, device='cuda:0') tensor(3.9697e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.218505
Average KL loss: 0.429646
Average total loss: 0.648151
tensor(-11.3419, device='cuda:0') tensor(3.7426, device='cuda:0') tensor(3.9843e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.214860
Average KL loss: 0.429484
Average total loss: 0.644343
tensor(-11.3466, device='cuda:0') tensor(3.7364, device='cuda:0') tensor(8.6415e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.213018
Average KL loss: 0.429340
Average total loss: 0.642358
tensor(-11.3514, device='cuda:0') tensor(3.7303, device='cuda:0') tensor(5.1650e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.213345
Average KL loss: 0.429179
Average total loss: 0.642524
tensor(-11.3560, device='cuda:0') tensor(3.7245, device='cuda:0') tensor(2.9376e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.212553
Average KL loss: 0.429048
Average total loss: 0.641600
tensor(-11.3606, device='cuda:0') tensor(3.7189, device='cuda:0') tensor(1.4635e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.214397
Average KL loss: 0.428897
Average total loss: 0.643294
tensor(-11.3651, device='cuda:0') tensor(3.7133, device='cuda:0') tensor(4.4559e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.214210
Average KL loss: 0.428727
Average total loss: 0.642937
tensor(-11.3696, device='cuda:0') tensor(3.7081, device='cuda:0') tensor(4.5174e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.212074
Average KL loss: 0.428581
Average total loss: 0.640655
tensor(-11.3741, device='cuda:0') tensor(3.7030, device='cuda:0') tensor(6.7566e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.211155
Average KL loss: 0.428433
Average total loss: 0.639587
tensor(-11.3785, device='cuda:0') tensor(3.6980, device='cuda:0') tensor(5.3698e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.208693
Average KL loss: 0.428261
Average total loss: 0.636953
tensor(-11.3829, device='cuda:0') tensor(3.6933, device='cuda:0') tensor(2.7297e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.209710
Average KL loss: 0.428098
Average total loss: 0.637809
tensor(-11.3872, device='cuda:0') tensor(3.6886, device='cuda:0') tensor(4.2297e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.206477
Average KL loss: 0.427952
Average total loss: 0.634429
tensor(-11.3915, device='cuda:0') tensor(3.6841, device='cuda:0') tensor(4.2338e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.210734
Average KL loss: 0.427784
Average total loss: 0.638518
tensor(-11.3958, device='cuda:0') tensor(3.6797, device='cuda:0') tensor(4.4869e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.204745
Average KL loss: 0.427633
Average total loss: 0.632378
tensor(-11.4000, device='cuda:0') tensor(3.6755, device='cuda:0') tensor(1.1628e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.206300
Average KL loss: 0.427477
Average total loss: 0.633777
tensor(-11.4042, device='cuda:0') tensor(3.6714, device='cuda:0') tensor(4.0581e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.207252
Average KL loss: 0.427326
Average total loss: 0.634578
tensor(-11.4083, device='cuda:0') tensor(3.6672, device='cuda:0') tensor(2.8126e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.207191
Average KL loss: 0.427153
Average total loss: 0.634344
tensor(-11.4124, device='cuda:0') tensor(3.6633, device='cuda:0') tensor(6.6271e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.206595
Average KL loss: 0.427023
Average total loss: 0.633618
tensor(-11.4165, device='cuda:0') tensor(3.6595, device='cuda:0') tensor(4.4149e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.204410
Average KL loss: 0.426891
Average total loss: 0.631301
tensor(-11.4206, device='cuda:0') tensor(3.6558, device='cuda:0') tensor(6.8314e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.204040
Average KL loss: 0.426729
Average total loss: 0.630769
tensor(-11.4246, device='cuda:0') tensor(3.6521, device='cuda:0') tensor(2.3891e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.198493
Average KL loss: 0.426547
Average total loss: 0.625041
tensor(-11.4286, device='cuda:0') tensor(3.6486, device='cuda:0') tensor(4.6007e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.201753
Average KL loss: 0.426395
Average total loss: 0.628147
tensor(-11.4325, device='cuda:0') tensor(3.6451, device='cuda:0') tensor(4.4849e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.202299
Average KL loss: 0.426236
Average total loss: 0.628535
tensor(-11.4365, device='cuda:0') tensor(3.6419, device='cuda:0') tensor(3.7464e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.201920
Average KL loss: 0.426093
Average total loss: 0.628013
tensor(-11.4404, device='cuda:0') tensor(3.6386, device='cuda:0') tensor(4.1051e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.200580
Average KL loss: 0.425945
Average total loss: 0.626525
tensor(-11.4442, device='cuda:0') tensor(3.6354, device='cuda:0') tensor(4.1582e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.200930
Average KL loss: 0.425778
Average total loss: 0.626708
tensor(-11.4481, device='cuda:0') tensor(3.6323, device='cuda:0') tensor(-2.3621e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.202236
Average KL loss: 0.425629
Average total loss: 0.627865
tensor(-11.4519, device='cuda:0') tensor(3.6292, device='cuda:0') tensor(1.3528e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.198035
Average KL loss: 0.425490
Average total loss: 0.623525
tensor(-11.4557, device='cuda:0') tensor(3.6262, device='cuda:0') tensor(4.9076e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.201967
Average KL loss: 0.425326
Average total loss: 0.627293
tensor(-11.4595, device='cuda:0') tensor(3.6232, device='cuda:0') tensor(7.1788e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.195260
Average KL loss: 0.425176
Average total loss: 0.620436
tensor(-11.4632, device='cuda:0') tensor(3.6205, device='cuda:0') tensor(4.5429e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.195946
Average KL loss: 0.425024
Average total loss: 0.620970
tensor(-11.4669, device='cuda:0') tensor(3.6177, device='cuda:0') tensor(5.8106e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.198322
Average KL loss: 0.424863
Average total loss: 0.623185
tensor(-11.4706, device='cuda:0') tensor(3.6150, device='cuda:0') tensor(9.3424e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.197910
Average KL loss: 0.424707
Average total loss: 0.622617
tensor(-11.4743, device='cuda:0') tensor(3.6123, device='cuda:0') tensor(3.0292e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.200388
Average KL loss: 0.424544
Average total loss: 0.624933
tensor(-11.4780, device='cuda:0') tensor(3.6097, device='cuda:0') tensor(4.1919e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.196197
Average KL loss: 0.424397
Average total loss: 0.620594
tensor(-11.4816, device='cuda:0') tensor(3.6071, device='cuda:0') tensor(9.7585e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.193983
Average KL loss: 0.424234
Average total loss: 0.618218
tensor(-11.4852, device='cuda:0') tensor(3.6045, device='cuda:0') tensor(1.8242e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.195033
Average KL loss: 0.424091
Average total loss: 0.619124
tensor(-11.4888, device='cuda:0') tensor(3.6020, device='cuda:0') tensor(2.3658e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.189245
Average KL loss: 0.423951
Average total loss: 0.613196
tensor(-11.4924, device='cuda:0') tensor(3.5997, device='cuda:0') tensor(2.7169e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.192880
Average KL loss: 0.423810
Average total loss: 0.616690
tensor(-11.4959, device='cuda:0') tensor(3.5973, device='cuda:0') tensor(4.1096e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.193015
Average KL loss: 0.423626
Average total loss: 0.616641
tensor(-11.4995, device='cuda:0') tensor(3.5948, device='cuda:0') tensor(6.3134e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.190055
Average KL loss: 0.423423
Average total loss: 0.613478
tensor(-11.5030, device='cuda:0') tensor(3.5925, device='cuda:0') tensor(5.9787e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.193339
Average KL loss: 0.423249
Average total loss: 0.616588
tensor(-11.5065, device='cuda:0') tensor(3.5901, device='cuda:0') tensor(1.9741e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.192100
Average KL loss: 0.423087
Average total loss: 0.615187
tensor(-11.5100, device='cuda:0') tensor(3.5878, device='cuda:0') tensor(3.0046e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.194587
Average KL loss: 0.422919
Average total loss: 0.617506
tensor(-11.5135, device='cuda:0') tensor(3.5856, device='cuda:0') tensor(1.0581e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.189595
Average KL loss: 0.422760
Average total loss: 0.612355
tensor(-11.5169, device='cuda:0') tensor(3.5835, device='cuda:0') tensor(3.0293e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.190852
Average KL loss: 0.422578
Average total loss: 0.613430
tensor(-11.5203, device='cuda:0') tensor(3.5813, device='cuda:0') tensor(2.9168e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.192174
Average KL loss: 0.422382
Average total loss: 0.614556
tensor(-11.5237, device='cuda:0') tensor(3.5792, device='cuda:0') tensor(4.8537e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.189458
Average KL loss: 0.422228
Average total loss: 0.611686
tensor(-11.5271, device='cuda:0') tensor(3.5771, device='cuda:0') tensor(4.0158e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.190442
Average KL loss: 0.422045
Average total loss: 0.612487
tensor(-11.5305, device='cuda:0') tensor(3.5750, device='cuda:0') tensor(3.8890e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.188505
Average KL loss: 0.421846
Average total loss: 0.610352
tensor(-11.5339, device='cuda:0') tensor(3.5729, device='cuda:0') tensor(2.5708e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.191449
Average KL loss: 0.421662
Average total loss: 0.613112
tensor(-11.5372, device='cuda:0') tensor(3.5710, device='cuda:0') tensor(6.6016e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.188460
Average KL loss: 0.421510
Average total loss: 0.609971
tensor(-11.5406, device='cuda:0') tensor(3.5690, device='cuda:0') tensor(4.7370e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.188603
Average KL loss: 0.421347
Average total loss: 0.609950
tensor(-11.5439, device='cuda:0') tensor(3.5670, device='cuda:0') tensor(1.4516e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.189660
Average KL loss: 0.421209
Average total loss: 0.610869
tensor(-11.5472, device='cuda:0') tensor(3.5651, device='cuda:0') tensor(3.6000e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.186322
Average KL loss: 0.421047
Average total loss: 0.607369
tensor(-11.5505, device='cuda:0') tensor(3.5632, device='cuda:0') tensor(5.2949e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.185799
Average KL loss: 0.420901
Average total loss: 0.606700
tensor(-11.5537, device='cuda:0') tensor(3.5614, device='cuda:0') tensor(6.5430e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.183298
Average KL loss: 0.420720
Average total loss: 0.604018
tensor(-11.5570, device='cuda:0') tensor(3.5594, device='cuda:0') tensor(7.0890e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.184925
Average KL loss: 0.420536
Average total loss: 0.605460
tensor(-11.5603, device='cuda:0') tensor(3.5576, device='cuda:0') tensor(6.0391e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.185933
Average KL loss: 0.420365
Average total loss: 0.606298
tensor(-11.5635, device='cuda:0') tensor(3.5557, device='cuda:0') tensor(3.7434e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.187384
Average KL loss: 0.420212
Average total loss: 0.607596
tensor(-11.5667, device='cuda:0') tensor(3.5540, device='cuda:0') tensor(1.5457e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.182600
Average KL loss: 0.420059
Average total loss: 0.602659
tensor(-11.5699, device='cuda:0') tensor(3.5522, device='cuda:0') tensor(5.0469e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.181251
Average KL loss: 0.419891
Average total loss: 0.601142
tensor(-11.5731, device='cuda:0') tensor(3.5504, device='cuda:0') tensor(4.6200e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.181236
Average KL loss: 0.419691
Average total loss: 0.600926
tensor(-11.5763, device='cuda:0') tensor(3.5487, device='cuda:0') tensor(-8.2158e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.181860
Average KL loss: 0.419490
Average total loss: 0.601350
tensor(-11.5794, device='cuda:0') tensor(3.5469, device='cuda:0') tensor(-1.5354e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.184515
Average KL loss: 0.419329
Average total loss: 0.603844
tensor(-11.5826, device='cuda:0') tensor(3.5451, device='cuda:0') tensor(1.5478e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.178468
Average KL loss: 0.419160
Average total loss: 0.597628
tensor(-11.5857, device='cuda:0') tensor(3.5433, device='cuda:0') tensor(5.5229e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.177909
Average KL loss: 0.418994
Average total loss: 0.596903
tensor(-11.5889, device='cuda:0') tensor(3.5416, device='cuda:0') tensor(6.8711e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.183125
Average KL loss: 0.418846
Average total loss: 0.601971
tensor(-11.5920, device='cuda:0') tensor(3.5400, device='cuda:0') tensor(2.6017e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.179968
Average KL loss: 0.418681
Average total loss: 0.598649
tensor(-11.5951, device='cuda:0') tensor(3.5383, device='cuda:0') tensor(6.8604e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.180511
Average KL loss: 0.418525
Average total loss: 0.599036
tensor(-11.5982, device='cuda:0') tensor(3.5366, device='cuda:0') tensor(1.6596e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.179627
Average KL loss: 0.418346
Average total loss: 0.597973
tensor(-11.6013, device='cuda:0') tensor(3.5350, device='cuda:0') tensor(3.8772e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.177779
Average KL loss: 0.418205
Average total loss: 0.595984
tensor(-11.6043, device='cuda:0') tensor(3.5334, device='cuda:0') tensor(5.6627e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.176693
Average KL loss: 0.418032
Average total loss: 0.594725
tensor(-11.6074, device='cuda:0') tensor(3.5317, device='cuda:0') tensor(2.8075e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.175127
Average KL loss: 0.417827
Average total loss: 0.592954
tensor(-11.6105, device='cuda:0') tensor(3.5299, device='cuda:0') tensor(4.7044e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.179259
Average KL loss: 0.417660
Average total loss: 0.596919
tensor(-11.6135, device='cuda:0') tensor(3.5283, device='cuda:0') tensor(3.5486e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.177592
Average KL loss: 0.417503
Average total loss: 0.595095
tensor(-11.6165, device='cuda:0') tensor(3.5267, device='cuda:0') tensor(5.2625e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.177692
Average KL loss: 0.417326
Average total loss: 0.595018
tensor(-11.6195, device='cuda:0') tensor(3.5251, device='cuda:0') tensor(3.7360e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.176540
Average KL loss: 0.417131
Average total loss: 0.593671
tensor(-11.6226, device='cuda:0') tensor(3.5235, device='cuda:0') tensor(4.2048e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.176210
Average KL loss: 0.416953
Average total loss: 0.593164
tensor(-11.6256, device='cuda:0') tensor(3.5219, device='cuda:0') tensor(8.4346e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.175494
Average KL loss: 0.416797
Average total loss: 0.592292
tensor(-11.6285, device='cuda:0') tensor(3.5202, device='cuda:0') tensor(4.7488e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.174169
Average KL loss: 0.416615
Average total loss: 0.590785
tensor(-11.6315, device='cuda:0') tensor(3.5187, device='cuda:0') tensor(5.4207e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.176463
Average KL loss: 0.416458
Average total loss: 0.592921
tensor(-11.6345, device='cuda:0') tensor(3.5171, device='cuda:0') tensor(3.5460e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.171396
Average KL loss: 0.416319
Average total loss: 0.587714
tensor(-11.6374, device='cuda:0') tensor(3.5156, device='cuda:0') tensor(5.9327e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.175143
Average KL loss: 0.416160
Average total loss: 0.591303
tensor(-11.6404, device='cuda:0') tensor(3.5141, device='cuda:0') tensor(5.0453e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.172449
Average KL loss: 0.416000
Average total loss: 0.588449
tensor(-11.6433, device='cuda:0') tensor(3.5126, device='cuda:0') tensor(2.2444e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.174689
Average KL loss: 0.415876
Average total loss: 0.590565
tensor(-11.6463, device='cuda:0') tensor(3.5111, device='cuda:0') tensor(4.5120e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.171842
Average KL loss: 0.415732
Average total loss: 0.587574
tensor(-11.6492, device='cuda:0') tensor(3.5096, device='cuda:0') tensor(5.5027e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.170764
Average KL loss: 0.415568
Average total loss: 0.586332
tensor(-11.6521, device='cuda:0') tensor(3.5082, device='cuda:0') tensor(3.3753e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.173361
Average KL loss: 0.415450
Average total loss: 0.588811
tensor(-11.6550, device='cuda:0') tensor(3.5067, device='cuda:0') tensor(4.7797e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.170731
Average KL loss: 0.415300
Average total loss: 0.586031
tensor(-11.6579, device='cuda:0') tensor(3.5053, device='cuda:0') tensor(2.9938e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.172748
Average KL loss: 0.415141
Average total loss: 0.587888
tensor(-11.6607, device='cuda:0') tensor(3.5038, device='cuda:0') tensor(3.1185e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.173292
Average KL loss: 0.414964
Average total loss: 0.588256
tensor(-11.6636, device='cuda:0') tensor(3.5023, device='cuda:0') tensor(2.7268e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.171906
Average KL loss: 0.414793
Average total loss: 0.586700
tensor(-11.6665, device='cuda:0') tensor(3.5008, device='cuda:0') tensor(1.8481e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.170621
Average KL loss: 0.414640
Average total loss: 0.585261
tensor(-11.6693, device='cuda:0') tensor(3.4994, device='cuda:0') tensor(5.6140e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.167895
Average KL loss: 0.414492
Average total loss: 0.582386
tensor(-11.6722, device='cuda:0') tensor(3.4980, device='cuda:0') tensor(6.5536e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.169077
Average KL loss: 0.414330
Average total loss: 0.583407
tensor(-11.6750, device='cuda:0') tensor(3.4965, device='cuda:0') tensor(4.2540e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.166265
Average KL loss: 0.414174
Average total loss: 0.580438
tensor(-11.6778, device='cuda:0') tensor(3.4951, device='cuda:0') tensor(3.5998e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.165398
Average KL loss: 0.413995
Average total loss: 0.579393
tensor(-11.6806, device='cuda:0') tensor(3.4936, device='cuda:0') tensor(4.6313e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.170077
Average KL loss: 0.413815
Average total loss: 0.583891
tensor(-11.6835, device='cuda:0') tensor(3.4921, device='cuda:0') tensor(3.6092e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.169280
Average KL loss: 0.413647
Average total loss: 0.582927
tensor(-11.6863, device='cuda:0') tensor(3.4906, device='cuda:0') tensor(2.6555e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.167834
Average KL loss: 0.413477
Average total loss: 0.581311
tensor(-11.6890, device='cuda:0') tensor(3.4892, device='cuda:0') tensor(2.9027e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.167780
Average KL loss: 0.413331
Average total loss: 0.581111
tensor(-11.6918, device='cuda:0') tensor(3.4878, device='cuda:0') tensor(1.3015e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.169612
Average KL loss: 0.413173
Average total loss: 0.582785
tensor(-11.6946, device='cuda:0') tensor(3.4865, device='cuda:0') tensor(6.0269e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.165084
Average KL loss: 0.413004
Average total loss: 0.578088
tensor(-11.6974, device='cuda:0') tensor(3.4852, device='cuda:0') tensor(2.9101e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.166343
Average KL loss: 0.412890
Average total loss: 0.579233
tensor(-11.7001, device='cuda:0') tensor(3.4839, device='cuda:0') tensor(3.2565e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.166675
Average KL loss: 0.412767
Average total loss: 0.579442
tensor(-11.7029, device='cuda:0') tensor(3.4825, device='cuda:0') tensor(1.6190e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.161359
Average KL loss: 0.412638
Average total loss: 0.573996
tensor(-11.7056, device='cuda:0') tensor(3.4811, device='cuda:0') tensor(4.5377e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.164185
Average KL loss: 0.412467
Average total loss: 0.576652
tensor(-11.7084, device='cuda:0') tensor(3.4797, device='cuda:0') tensor(3.4384e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.166429
Average KL loss: 0.412340
Average total loss: 0.578769
tensor(-11.7111, device='cuda:0') tensor(3.4784, device='cuda:0') tensor(2.6500e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.162663
Average KL loss: 0.412197
Average total loss: 0.574860
tensor(-11.7138, device='cuda:0') tensor(3.4770, device='cuda:0') tensor(5.1589e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.161514
Average KL loss: 0.412046
Average total loss: 0.573560
tensor(-11.7165, device='cuda:0') tensor(3.4756, device='cuda:0') tensor(3.2633e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.164189
Average KL loss: 0.411891
Average total loss: 0.576080
tensor(-11.7192, device='cuda:0') tensor(3.4742, device='cuda:0') tensor(5.0976e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.162545
Average KL loss: 0.411753
Average total loss: 0.574298
tensor(-11.7219, device='cuda:0') tensor(3.4728, device='cuda:0') tensor(4.7492e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.161844
Average KL loss: 0.411615
Average total loss: 0.573458
tensor(-11.7246, device='cuda:0') tensor(3.4715, device='cuda:0') tensor(5.6123e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.161455
Average KL loss: 0.411459
Average total loss: 0.572914
tensor(-11.7273, device='cuda:0') tensor(3.4701, device='cuda:0') tensor(2.3279e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.158810
Average KL loss: 0.411298
Average total loss: 0.570108
tensor(-11.7300, device='cuda:0') tensor(3.4688, device='cuda:0') tensor(3.5008e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.160205
Average KL loss: 0.411112
Average total loss: 0.571317
tensor(-11.7327, device='cuda:0') tensor(3.4673, device='cuda:0') tensor(5.1846e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.159785
Average KL loss: 0.410946
Average total loss: 0.570731
tensor(-11.7353, device='cuda:0') tensor(3.4658, device='cuda:0') tensor(4.5978e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.162232
Average KL loss: 0.410766
Average total loss: 0.572997
tensor(-11.7380, device='cuda:0') tensor(3.4644, device='cuda:0') tensor(4.3959e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.161987
Average KL loss: 0.410595
Average total loss: 0.572582
tensor(-11.7407, device='cuda:0') tensor(3.4630, device='cuda:0') tensor(3.1947e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.161158
Average KL loss: 0.410436
Average total loss: 0.571594
tensor(-11.7433, device='cuda:0') tensor(3.4616, device='cuda:0') tensor(3.6472e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.158937
Average KL loss: 0.410272
Average total loss: 0.569209
tensor(-11.7459, device='cuda:0') tensor(3.4602, device='cuda:0') tensor(1.0357e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.160485
Average KL loss: 0.410143
Average total loss: 0.570628
tensor(-11.7486, device='cuda:0') tensor(3.4588, device='cuda:0') tensor(3.2519e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.159841
Average KL loss: 0.410007
Average total loss: 0.569848
tensor(-11.7512, device='cuda:0') tensor(3.4574, device='cuda:0') tensor(4.6133e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.160031
Average KL loss: 0.409851
Average total loss: 0.569882
tensor(-11.7538, device='cuda:0') tensor(3.4560, device='cuda:0') tensor(4.5407e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.155464
Average KL loss: 0.409678
Average total loss: 0.565141
tensor(-11.7565, device='cuda:0') tensor(3.4545, device='cuda:0') tensor(3.8554e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.156083
Average KL loss: 0.409507
Average total loss: 0.565589
tensor(-11.7591, device='cuda:0') tensor(3.4532, device='cuda:0') tensor(4.7250e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.157941
Average KL loss: 0.409313
Average total loss: 0.567255
tensor(-11.7617, device='cuda:0') tensor(3.4517, device='cuda:0') tensor(5.5586e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.158634
Average KL loss: 0.409125
Average total loss: 0.567759
tensor(-11.7643, device='cuda:0') tensor(3.4502, device='cuda:0') tensor(6.1645e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.155463
Average KL loss: 0.408976
Average total loss: 0.564439
tensor(-11.7668, device='cuda:0') tensor(3.4488, device='cuda:0') tensor(4.4079e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.158327
Average KL loss: 0.408841
Average total loss: 0.567168
tensor(-11.7694, device='cuda:0') tensor(3.4475, device='cuda:0') tensor(3.9839e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.154474
Average KL loss: 0.408714
Average total loss: 0.563188
tensor(-11.7720, device='cuda:0') tensor(3.4461, device='cuda:0') tensor(5.7786e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.155875
Average KL loss: 0.408546
Average total loss: 0.564421
tensor(-11.7746, device='cuda:0') tensor(3.4447, device='cuda:0') tensor(4.2280e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.157665
Average KL loss: 0.408380
Average total loss: 0.566044
tensor(-11.7771, device='cuda:0') tensor(3.4433, device='cuda:0') tensor(2.5651e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.155075
Average KL loss: 0.408192
Average total loss: 0.563267
tensor(-11.7797, device='cuda:0') tensor(3.4418, device='cuda:0') tensor(4.0354e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.150861
Average KL loss: 0.408026
Average total loss: 0.558887
tensor(-11.7822, device='cuda:0') tensor(3.4405, device='cuda:0') tensor(6.0827e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.158040
Average KL loss: 0.407882
Average total loss: 0.565921
tensor(-11.7848, device='cuda:0') tensor(3.4392, device='cuda:0') tensor(3.8261e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.151410
Average KL loss: 0.407731
Average total loss: 0.559142
tensor(-11.7873, device='cuda:0') tensor(3.4377, device='cuda:0') tensor(3.1293e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.155504
Average KL loss: 0.407563
Average total loss: 0.563067
tensor(-11.7899, device='cuda:0') tensor(3.4363, device='cuda:0') tensor(4.5928e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.154674
Average KL loss: 0.407427
Average total loss: 0.562102
tensor(-11.7924, device='cuda:0') tensor(3.4349, device='cuda:0') tensor(5.2995e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.153912
Average KL loss: 0.407276
Average total loss: 0.561188
tensor(-11.7949, device='cuda:0') tensor(3.4335, device='cuda:0') tensor(3.3432e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.153704
Average KL loss: 0.407128
Average total loss: 0.560832
tensor(-11.7974, device='cuda:0') tensor(3.4322, device='cuda:0') tensor(3.7516e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.151447
Average KL loss: 0.407004
Average total loss: 0.558450
tensor(-11.7999, device='cuda:0') tensor(3.4308, device='cuda:0') tensor(3.2826e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.150736
Average KL loss: 0.406838
Average total loss: 0.557574
tensor(-11.8025, device='cuda:0') tensor(3.4294, device='cuda:0') tensor(3.2525e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.152451
Average KL loss: 0.406674
Average total loss: 0.559125
tensor(-11.8050, device='cuda:0') tensor(3.4280, device='cuda:0') tensor(6.6273e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.151406
Average KL loss: 0.406510
Average total loss: 0.557916
tensor(-11.8074, device='cuda:0') tensor(3.4266, device='cuda:0') tensor(4.8177e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.150932
Average KL loss: 0.406365
Average total loss: 0.557297
tensor(-11.8099, device='cuda:0') tensor(3.4251, device='cuda:0') tensor(5.9286e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.151541
Average KL loss: 0.406225
Average total loss: 0.557766
tensor(-11.8124, device='cuda:0') tensor(3.4238, device='cuda:0') tensor(3.2785e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.150529
Average KL loss: 0.406073
Average total loss: 0.556602
tensor(-11.8149, device='cuda:0') tensor(3.4224, device='cuda:0') tensor(2.6618e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.150989
Average KL loss: 0.405928
Average total loss: 0.556917
tensor(-11.8174, device='cuda:0') tensor(3.4209, device='cuda:0') tensor(2.4398e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.150676
Average KL loss: 0.405769
Average total loss: 0.556445
tensor(-11.8199, device='cuda:0') tensor(3.4195, device='cuda:0') tensor(4.6523e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.150834
Average KL loss: 0.405644
Average total loss: 0.556478
tensor(-11.8223, device='cuda:0') tensor(3.4180, device='cuda:0') tensor(7.0835e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.149496
Average KL loss: 0.405488
Average total loss: 0.554984
tensor(-11.8248, device='cuda:0') tensor(3.4166, device='cuda:0') tensor(5.9783e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.149684
Average KL loss: 0.405322
Average total loss: 0.555006
tensor(-11.8272, device='cuda:0') tensor(3.4152, device='cuda:0') tensor(4.9741e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.149327
Average KL loss: 0.405174
Average total loss: 0.554502
tensor(-11.8297, device='cuda:0') tensor(3.4138, device='cuda:0') tensor(4.0349e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.148681
Average KL loss: 0.405034
Average total loss: 0.553715
tensor(-11.8321, device='cuda:0') tensor(3.4124, device='cuda:0') tensor(3.9975e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.144732
Average KL loss: 0.404903
Average total loss: 0.549636
tensor(-11.8345, device='cuda:0') tensor(3.4111, device='cuda:0') tensor(4.0821e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.145944
Average KL loss: 0.404773
Average total loss: 0.550716
tensor(-11.8370, device='cuda:0') tensor(3.4096, device='cuda:0') tensor(3.9206e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.146013
Average KL loss: 0.404651
Average total loss: 0.550664
tensor(-11.8394, device='cuda:0') tensor(3.4082, device='cuda:0') tensor(2.7068e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.147421
Average KL loss: 0.404521
Average total loss: 0.551942
tensor(-11.8418, device='cuda:0') tensor(3.4068, device='cuda:0') tensor(4.3526e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.146962
Average KL loss: 0.404374
Average total loss: 0.551336
tensor(-11.8443, device='cuda:0') tensor(3.4054, device='cuda:0') tensor(3.6425e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.148359
Average KL loss: 0.404236
Average total loss: 0.552595
tensor(-11.8467, device='cuda:0') tensor(3.4040, device='cuda:0') tensor(1.9289e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.146351
Average KL loss: 0.404096
Average total loss: 0.550448
tensor(-11.8491, device='cuda:0') tensor(3.4026, device='cuda:0') tensor(1.0934e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.145725
Average KL loss: 0.403951
Average total loss: 0.549676
tensor(-11.8515, device='cuda:0') tensor(3.4011, device='cuda:0') tensor(3.2477e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.144402
Average KL loss: 0.403810
Average total loss: 0.548211
tensor(-11.8539, device='cuda:0') tensor(3.3997, device='cuda:0') tensor(4.2476e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.141713
Average KL loss: 0.403660
Average total loss: 0.545373
 Percentile value: -6.38330078125
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =    1459 /    1728             ( 84.43%) | total_pruned =     269 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   12216 /   36864             ( 33.14%) | total_pruned =   24648 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   12416 /   36864             ( 33.68%) | total_pruned =   24448 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   10929 /   36864             ( 29.65%) | total_pruned =   25935 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   10378 /   36864             ( 28.15%) | total_pruned =   26486 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   21547 /   73728             ( 29.22%) | total_pruned =   52181 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   34804 /  147456             ( 23.60%) | total_pruned =  112652 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4380 /    8192             ( 53.47%) | total_pruned =    3812 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   27072 /  147456             ( 18.36%) | total_pruned =  120384 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   27068 /  147456             ( 18.36%) | total_pruned =  120388 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   57050 /  294912             ( 19.34%) | total_pruned =  237862 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   85982 /  589824             ( 14.58%) | total_pruned =  503842 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   11524 /   32768             ( 35.17%) | total_pruned =   21244 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   41973 /  589824             (  7.12%) | total_pruned =  547851 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     139 /     256             ( 54.30%) | total_pruned =     117 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   44399 /  589824             (  7.53%) | total_pruned =  545425 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   85332 / 1179648             (  7.23%) | total_pruned = 1094316 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     357 /     512             ( 69.73%) | total_pruned =     155 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     309 /     512             ( 60.35%) | total_pruned =     203 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   83862 / 2359296             (  3.55%) | total_pruned = 2275434 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     439 /     512             ( 85.74%) | total_pruned =      73 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     421 /     512             ( 82.23%) | total_pruned =      91 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   16724 /  131072             ( 12.76%) | total_pruned =  114348 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   44958 / 2359296             (  1.91%) | total_pruned = 2314338 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     233 /     512             ( 45.51%) | total_pruned =     279 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   52961 / 2359296             (  2.24%) | total_pruned = 2306335 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     430 /     512             ( 83.98%) | total_pruned =      82 | shape = torch.Size([512])
linear.weight        | nonzeros =    4208 /    5120             ( 82.19%) | total_pruned =     912 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 22/100 Loss: 0.000019 Accuracy: 86.92 100.00 % Best test Accuracy: 87.15%
tensor(-11.8563, device='cuda:0') tensor(3.3982, device='cuda:0') tensor(2.6185e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.204868
Average KL loss: 0.399435
Average total loss: 0.604303
tensor(-11.8718, device='cuda:0') tensor(3.2461, device='cuda:0') tensor(-2.3784e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.199856
Average KL loss: 0.396459
Average total loss: 0.596315
tensor(-11.8825, device='cuda:0') tensor(3.1619, device='cuda:0') tensor(-6.9352e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.196937
Average KL loss: 0.395324
Average total loss: 0.592261
tensor(-11.8911, device='cuda:0') tensor(3.1033, device='cuda:0') tensor(2.1339e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.186937
Average KL loss: 0.394679
Average total loss: 0.581616
tensor(-11.8986, device='cuda:0') tensor(3.0586, device='cuda:0') tensor(4.5613e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.190224
Average KL loss: 0.394248
Average total loss: 0.584472
tensor(-11.9052, device='cuda:0') tensor(3.0225, device='cuda:0') tensor(3.5137e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.189563
Average KL loss: 0.393930
Average total loss: 0.583493
tensor(-11.9113, device='cuda:0') tensor(2.9924, device='cuda:0') tensor(2.8142e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.182648
Average KL loss: 0.393696
Average total loss: 0.576343
tensor(-11.9170, device='cuda:0') tensor(2.9667, device='cuda:0') tensor(5.2845e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.184305
Average KL loss: 0.393506
Average total loss: 0.577811
tensor(-11.9223, device='cuda:0') tensor(2.9442, device='cuda:0') tensor(-2.3909e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.188017
Average KL loss: 0.393349
Average total loss: 0.581366
tensor(-11.9273, device='cuda:0') tensor(2.9243, device='cuda:0') tensor(4.1912e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.181958
Average KL loss: 0.393182
Average total loss: 0.575140
tensor(-11.9321, device='cuda:0') tensor(2.9064, device='cuda:0') tensor(5.0683e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.177006
Average KL loss: 0.393035
Average total loss: 0.570041
tensor(-11.9367, device='cuda:0') tensor(2.8903, device='cuda:0') tensor(9.1406e-11, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.179662
Average KL loss: 0.392929
Average total loss: 0.572590
tensor(-11.9412, device='cuda:0') tensor(2.8757, device='cuda:0') tensor(-5.6921e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.178831
Average KL loss: 0.392840
Average total loss: 0.571670
tensor(-11.9454, device='cuda:0') tensor(2.8623, device='cuda:0') tensor(-1.3733e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.178810
Average KL loss: 0.392769
Average total loss: 0.571578
tensor(-11.9496, device='cuda:0') tensor(2.8499, device='cuda:0') tensor(-5.9543e-12, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.174351
Average KL loss: 0.392672
Average total loss: 0.567023
tensor(-11.9536, device='cuda:0') tensor(2.8383, device='cuda:0') tensor(2.2347e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.174597
Average KL loss: 0.392613
Average total loss: 0.567210
tensor(-11.9576, device='cuda:0') tensor(2.8275, device='cuda:0') tensor(-2.9363e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.176217
Average KL loss: 0.392540
Average total loss: 0.568757
tensor(-11.9614, device='cuda:0') tensor(2.8175, device='cuda:0') tensor(9.9122e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.174539
Average KL loss: 0.392463
Average total loss: 0.567002
tensor(-11.9652, device='cuda:0') tensor(2.8080, device='cuda:0') tensor(5.6179e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.169943
Average KL loss: 0.392374
Average total loss: 0.562317
tensor(-11.9689, device='cuda:0') tensor(2.7991, device='cuda:0') tensor(1.8249e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.170160
Average KL loss: 0.392310
Average total loss: 0.562470
tensor(-11.9725, device='cuda:0') tensor(2.7907, device='cuda:0') tensor(2.9232e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.166218
Average KL loss: 0.392251
Average total loss: 0.558469
tensor(-11.9760, device='cuda:0') tensor(2.7828, device='cuda:0') tensor(1.9609e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.170038
Average KL loss: 0.392190
Average total loss: 0.562228
tensor(-11.9795, device='cuda:0') tensor(2.7753, device='cuda:0') tensor(-1.2388e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.169912
Average KL loss: 0.392135
Average total loss: 0.562047
tensor(-11.9830, device='cuda:0') tensor(2.7681, device='cuda:0') tensor(4.0028e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.166827
Average KL loss: 0.392072
Average total loss: 0.558899
tensor(-11.9864, device='cuda:0') tensor(2.7613, device='cuda:0') tensor(-1.3484e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.165533
Average KL loss: 0.392033
Average total loss: 0.557565
tensor(-11.9897, device='cuda:0') tensor(2.7548, device='cuda:0') tensor(1.4021e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.167232
Average KL loss: 0.391973
Average total loss: 0.559205
tensor(-11.9930, device='cuda:0') tensor(2.7486, device='cuda:0') tensor(1.5146e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.165739
Average KL loss: 0.391906
Average total loss: 0.557645
tensor(-11.9962, device='cuda:0') tensor(2.7427, device='cuda:0') tensor(6.3217e-12, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.163426
Average KL loss: 0.391876
Average total loss: 0.555302
tensor(-11.9994, device='cuda:0') tensor(2.7371, device='cuda:0') tensor(6.3605e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.162483
Average KL loss: 0.391831
Average total loss: 0.554314
tensor(-12.0026, device='cuda:0') tensor(2.7317, device='cuda:0') tensor(4.9433e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.161610
Average KL loss: 0.391766
Average total loss: 0.553376
tensor(-12.0057, device='cuda:0') tensor(2.7265, device='cuda:0') tensor(3.6769e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.163214
Average KL loss: 0.391694
Average total loss: 0.554907
tensor(-12.0088, device='cuda:0') tensor(2.7214, device='cuda:0') tensor(7.3323e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.161833
Average KL loss: 0.391639
Average total loss: 0.553472
tensor(-12.0119, device='cuda:0') tensor(2.7166, device='cuda:0') tensor(2.3472e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.158366
Average KL loss: 0.391595
Average total loss: 0.549960
tensor(-12.0149, device='cuda:0') tensor(2.7119, device='cuda:0') tensor(9.3444e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.159257
Average KL loss: 0.391542
Average total loss: 0.550798
tensor(-12.0179, device='cuda:0') tensor(2.7073, device='cuda:0') tensor(2.8270e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.163530
Average KL loss: 0.391491
Average total loss: 0.555021
tensor(-12.0209, device='cuda:0') tensor(2.7030, device='cuda:0') tensor(3.6353e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.158379
Average KL loss: 0.391459
Average total loss: 0.549838
tensor(-12.0238, device='cuda:0') tensor(2.6988, device='cuda:0') tensor(9.3900e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.156687
Average KL loss: 0.391412
Average total loss: 0.548099
tensor(-12.0267, device='cuda:0') tensor(2.6948, device='cuda:0') tensor(6.9336e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.158599
Average KL loss: 0.391356
Average total loss: 0.549956
tensor(-12.0296, device='cuda:0') tensor(2.6909, device='cuda:0') tensor(1.8534e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.157985
Average KL loss: 0.391324
Average total loss: 0.549309
tensor(-12.0325, device='cuda:0') tensor(2.6872, device='cuda:0') tensor(1.1332e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.158217
Average KL loss: 0.391285
Average total loss: 0.549502
tensor(-12.0353, device='cuda:0') tensor(2.6835, device='cuda:0') tensor(5.0467e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.157633
Average KL loss: 0.391228
Average total loss: 0.548862
tensor(-12.0382, device='cuda:0') tensor(2.6799, device='cuda:0') tensor(9.3324e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.155331
Average KL loss: 0.391160
Average total loss: 0.546491
tensor(-12.0410, device='cuda:0') tensor(2.6764, device='cuda:0') tensor(1.3795e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.156066
Average KL loss: 0.391098
Average total loss: 0.547164
tensor(-12.0437, device='cuda:0') tensor(2.6730, device='cuda:0') tensor(3.6810e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.153609
Average KL loss: 0.391049
Average total loss: 0.544658
tensor(-12.0465, device='cuda:0') tensor(2.6697, device='cuda:0') tensor(1.6155e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.154625
Average KL loss: 0.390990
Average total loss: 0.545615
tensor(-12.0492, device='cuda:0') tensor(2.6665, device='cuda:0') tensor(4.8784e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.151855
Average KL loss: 0.390931
Average total loss: 0.542786
tensor(-12.0520, device='cuda:0') tensor(2.6634, device='cuda:0') tensor(3.5988e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.153035
Average KL loss: 0.390884
Average total loss: 0.543919
tensor(-12.0547, device='cuda:0') tensor(2.6605, device='cuda:0') tensor(2.2004e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.152455
Average KL loss: 0.390808
Average total loss: 0.543262
tensor(-12.0573, device='cuda:0') tensor(2.6574, device='cuda:0') tensor(-8.7176e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.151743
Average KL loss: 0.390727
Average total loss: 0.542470
tensor(-12.0600, device='cuda:0') tensor(2.6545, device='cuda:0') tensor(8.1873e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.150037
Average KL loss: 0.390681
Average total loss: 0.540718
tensor(-12.0627, device='cuda:0') tensor(2.6517, device='cuda:0') tensor(3.0638e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.151509
Average KL loss: 0.390629
Average total loss: 0.542138
tensor(-12.0653, device='cuda:0') tensor(2.6489, device='cuda:0') tensor(1.1140e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.153134
Average KL loss: 0.390563
Average total loss: 0.543697
tensor(-12.0679, device='cuda:0') tensor(2.6463, device='cuda:0') tensor(7.7083e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.150540
Average KL loss: 0.390491
Average total loss: 0.541031
tensor(-12.0705, device='cuda:0') tensor(2.6436, device='cuda:0') tensor(9.2849e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.153229
Average KL loss: 0.390439
Average total loss: 0.543668
tensor(-12.0731, device='cuda:0') tensor(2.6410, device='cuda:0') tensor(8.4463e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.147965
Average KL loss: 0.390376
Average total loss: 0.538341
tensor(-12.0757, device='cuda:0') tensor(2.6386, device='cuda:0') tensor(1.3097e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.153122
Average KL loss: 0.390308
Average total loss: 0.543429
tensor(-12.0783, device='cuda:0') tensor(2.6361, device='cuda:0') tensor(1.3565e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.151379
Average KL loss: 0.390254
Average total loss: 0.541633
tensor(-12.0808, device='cuda:0') tensor(2.6337, device='cuda:0') tensor(4.5757e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.148682
Average KL loss: 0.390179
Average total loss: 0.538862
tensor(-12.0833, device='cuda:0') tensor(2.6314, device='cuda:0') tensor(4.1128e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.146748
Average KL loss: 0.390150
Average total loss: 0.536899
tensor(-12.0859, device='cuda:0') tensor(2.6291, device='cuda:0') tensor(-3.1615e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.144944
Average KL loss: 0.390110
Average total loss: 0.535055
tensor(-12.0884, device='cuda:0') tensor(2.6269, device='cuda:0') tensor(2.8607e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.145256
Average KL loss: 0.390037
Average total loss: 0.535292
tensor(-12.0909, device='cuda:0') tensor(2.6246, device='cuda:0') tensor(2.6661e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.145428
Average KL loss: 0.389966
Average total loss: 0.535394
tensor(-12.0933, device='cuda:0') tensor(2.6225, device='cuda:0') tensor(3.2291e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.144886
Average KL loss: 0.389910
Average total loss: 0.534797
tensor(-12.0958, device='cuda:0') tensor(2.6204, device='cuda:0') tensor(3.9171e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.144501
Average KL loss: 0.389839
Average total loss: 0.534340
tensor(-12.0983, device='cuda:0') tensor(2.6184, device='cuda:0') tensor(2.2177e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.141441
Average KL loss: 0.389770
Average total loss: 0.531211
tensor(-12.1007, device='cuda:0') tensor(2.6163, device='cuda:0') tensor(3.0105e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.142331
Average KL loss: 0.389692
Average total loss: 0.532023
tensor(-12.1032, device='cuda:0') tensor(2.6143, device='cuda:0') tensor(4.1710e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.146383
Average KL loss: 0.389629
Average total loss: 0.536012
tensor(-12.1056, device='cuda:0') tensor(2.6124, device='cuda:0') tensor(1.2545e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.143196
Average KL loss: 0.389585
Average total loss: 0.532781
tensor(-12.1080, device='cuda:0') tensor(2.6105, device='cuda:0') tensor(9.5760e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.142606
Average KL loss: 0.389513
Average total loss: 0.532119
tensor(-12.1104, device='cuda:0') tensor(2.6086, device='cuda:0') tensor(9.3042e-11, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.142919
Average KL loss: 0.389461
Average total loss: 0.532380
tensor(-12.1128, device='cuda:0') tensor(2.6068, device='cuda:0') tensor(1.5272e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.142140
Average KL loss: 0.389410
Average total loss: 0.531550
tensor(-12.1152, device='cuda:0') tensor(2.6050, device='cuda:0') tensor(-1.2805e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.141788
Average KL loss: 0.389341
Average total loss: 0.531129
tensor(-12.1175, device='cuda:0') tensor(2.6032, device='cuda:0') tensor(-2.3100e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.145148
Average KL loss: 0.389294
Average total loss: 0.534442
tensor(-12.1199, device='cuda:0') tensor(2.6015, device='cuda:0') tensor(-9.9779e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.140988
Average KL loss: 0.389251
Average total loss: 0.530239
tensor(-12.1222, device='cuda:0') tensor(2.5998, device='cuda:0') tensor(1.4866e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.142369
Average KL loss: 0.389197
Average total loss: 0.531567
tensor(-12.1246, device='cuda:0') tensor(2.5980, device='cuda:0') tensor(1.8923e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.139764
Average KL loss: 0.389122
Average total loss: 0.528886
tensor(-12.1269, device='cuda:0') tensor(2.5963, device='cuda:0') tensor(-1.4222e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.139070
Average KL loss: 0.389057
Average total loss: 0.528127
tensor(-12.1293, device='cuda:0') tensor(2.5947, device='cuda:0') tensor(2.8448e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.138588
Average KL loss: 0.388987
Average total loss: 0.527575
tensor(-12.1316, device='cuda:0') tensor(2.5930, device='cuda:0') tensor(3.0450e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.136667
Average KL loss: 0.388924
Average total loss: 0.525592
tensor(-12.1339, device='cuda:0') tensor(2.5914, device='cuda:0') tensor(1.0121e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.140100
Average KL loss: 0.388846
Average total loss: 0.528946
tensor(-12.1362, device='cuda:0') tensor(2.5898, device='cuda:0') tensor(-1.2851e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.139602
Average KL loss: 0.388792
Average total loss: 0.528394
tensor(-12.1385, device='cuda:0') tensor(2.5883, device='cuda:0') tensor(1.4775e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.134570
Average KL loss: 0.388715
Average total loss: 0.523284
tensor(-12.1407, device='cuda:0') tensor(2.5868, device='cuda:0') tensor(2.8942e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.138265
Average KL loss: 0.388641
Average total loss: 0.526906
tensor(-12.1430, device='cuda:0') tensor(2.5853, device='cuda:0') tensor(2.6468e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.137228
Average KL loss: 0.388582
Average total loss: 0.525810
tensor(-12.1453, device='cuda:0') tensor(2.5837, device='cuda:0') tensor(1.6479e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.135725
Average KL loss: 0.388492
Average total loss: 0.524217
tensor(-12.1475, device='cuda:0') tensor(2.5822, device='cuda:0') tensor(8.2612e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.137635
Average KL loss: 0.388415
Average total loss: 0.526050
tensor(-12.1498, device='cuda:0') tensor(2.5807, device='cuda:0') tensor(5.1539e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.138028
Average KL loss: 0.388347
Average total loss: 0.526376
tensor(-12.1520, device='cuda:0') tensor(2.5793, device='cuda:0') tensor(-3.9915e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.135947
Average KL loss: 0.388286
Average total loss: 0.524232
tensor(-12.1543, device='cuda:0') tensor(2.5778, device='cuda:0') tensor(3.0859e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.134388
Average KL loss: 0.388201
Average total loss: 0.522589
tensor(-12.1565, device='cuda:0') tensor(2.5764, device='cuda:0') tensor(7.3032e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.133322
Average KL loss: 0.388131
Average total loss: 0.521453
tensor(-12.1587, device='cuda:0') tensor(2.5750, device='cuda:0') tensor(2.0839e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.133892
Average KL loss: 0.388073
Average total loss: 0.521965
tensor(-12.1609, device='cuda:0') tensor(2.5737, device='cuda:0') tensor(3.2265e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.132241
Average KL loss: 0.388025
Average total loss: 0.520266
tensor(-12.1631, device='cuda:0') tensor(2.5724, device='cuda:0') tensor(1.0494e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.135943
Average KL loss: 0.387973
Average total loss: 0.523916
tensor(-12.1653, device='cuda:0') tensor(2.5711, device='cuda:0') tensor(4.1925e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.134845
Average KL loss: 0.387912
Average total loss: 0.522757
tensor(-12.1675, device='cuda:0') tensor(2.5698, device='cuda:0') tensor(3.4683e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.133850
Average KL loss: 0.387832
Average total loss: 0.521683
tensor(-12.1697, device='cuda:0') tensor(2.5684, device='cuda:0') tensor(2.2295e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.133760
Average KL loss: 0.387763
Average total loss: 0.521523
tensor(-12.1718, device='cuda:0') tensor(2.5672, device='cuda:0') tensor(3.9331e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.132185
Average KL loss: 0.387698
Average total loss: 0.519883
tensor(-12.1740, device='cuda:0') tensor(2.5660, device='cuda:0') tensor(2.4113e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.132411
Average KL loss: 0.387656
Average total loss: 0.520067
tensor(-12.1762, device='cuda:0') tensor(2.5647, device='cuda:0') tensor(3.9203e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.130819
Average KL loss: 0.387589
Average total loss: 0.518409
tensor(-12.1783, device='cuda:0') tensor(2.5634, device='cuda:0') tensor(2.5897e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.133063
Average KL loss: 0.387528
Average total loss: 0.520591
tensor(-12.1805, device='cuda:0') tensor(2.5622, device='cuda:0') tensor(1.3077e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.130551
Average KL loss: 0.387474
Average total loss: 0.518025
tensor(-12.1826, device='cuda:0') tensor(2.5608, device='cuda:0') tensor(-3.2602e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.128705
Average KL loss: 0.387389
Average total loss: 0.516094
tensor(-12.1848, device='cuda:0') tensor(2.5597, device='cuda:0') tensor(4.0970e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.129262
Average KL loss: 0.387320
Average total loss: 0.516582
tensor(-12.1869, device='cuda:0') tensor(2.5585, device='cuda:0') tensor(2.8774e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.129421
Average KL loss: 0.387253
Average total loss: 0.516674
tensor(-12.1890, device='cuda:0') tensor(2.5573, device='cuda:0') tensor(-3.2754e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.128073
Average KL loss: 0.387190
Average total loss: 0.515263
tensor(-12.1911, device='cuda:0') tensor(2.5560, device='cuda:0') tensor(-2.6057e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.130940
Average KL loss: 0.387134
Average total loss: 0.518074
tensor(-12.1932, device='cuda:0') tensor(2.5549, device='cuda:0') tensor(2.3183e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.132615
Average KL loss: 0.387055
Average total loss: 0.519670
tensor(-12.1954, device='cuda:0') tensor(2.5536, device='cuda:0') tensor(4.4516e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.126414
Average KL loss: 0.386974
Average total loss: 0.513388
tensor(-12.1974, device='cuda:0') tensor(2.5525, device='cuda:0') tensor(3.9221e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.128669
Average KL loss: 0.386895
Average total loss: 0.515563
tensor(-12.1995, device='cuda:0') tensor(2.5513, device='cuda:0') tensor(1.9745e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.127414
Average KL loss: 0.386810
Average total loss: 0.514223
tensor(-12.2016, device='cuda:0') tensor(2.5501, device='cuda:0') tensor(1.2535e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.127452
Average KL loss: 0.386743
Average total loss: 0.514195
tensor(-12.2037, device='cuda:0') tensor(2.5490, device='cuda:0') tensor(-5.2927e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.129951
Average KL loss: 0.386679
Average total loss: 0.516629
tensor(-12.2058, device='cuda:0') tensor(2.5479, device='cuda:0') tensor(3.2648e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.127270
Average KL loss: 0.386596
Average total loss: 0.513866
tensor(-12.2079, device='cuda:0') tensor(2.5468, device='cuda:0') tensor(2.2909e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.127801
Average KL loss: 0.386527
Average total loss: 0.514328
tensor(-12.2099, device='cuda:0') tensor(2.5457, device='cuda:0') tensor(9.9795e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.125430
Average KL loss: 0.386458
Average total loss: 0.511887
tensor(-12.2120, device='cuda:0') tensor(2.5446, device='cuda:0') tensor(3.6854e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.127137
Average KL loss: 0.386402
Average total loss: 0.513539
tensor(-12.2140, device='cuda:0') tensor(2.5435, device='cuda:0') tensor(8.2577e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.123517
Average KL loss: 0.386337
Average total loss: 0.509854
tensor(-12.2161, device='cuda:0') tensor(2.5425, device='cuda:0') tensor(3.2531e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.125269
Average KL loss: 0.386275
Average total loss: 0.511544
tensor(-12.2181, device='cuda:0') tensor(2.5415, device='cuda:0') tensor(3.1744e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.125337
Average KL loss: 0.386207
Average total loss: 0.511545
tensor(-12.2202, device='cuda:0') tensor(2.5404, device='cuda:0') tensor(1.5019e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.124848
Average KL loss: 0.386138
Average total loss: 0.510986
tensor(-12.2222, device='cuda:0') tensor(2.5393, device='cuda:0') tensor(2.0733e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.125188
Average KL loss: 0.386050
Average total loss: 0.511238
tensor(-12.2242, device='cuda:0') tensor(2.5383, device='cuda:0') tensor(3.2712e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.122571
Average KL loss: 0.385958
Average total loss: 0.508528
tensor(-12.2262, device='cuda:0') tensor(2.5372, device='cuda:0') tensor(5.6268e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.125206
Average KL loss: 0.385887
Average total loss: 0.511092
tensor(-12.2283, device='cuda:0') tensor(2.5361, device='cuda:0') tensor(5.9594e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.121746
Average KL loss: 0.385821
Average total loss: 0.507567
tensor(-12.2303, device='cuda:0') tensor(2.5351, device='cuda:0') tensor(1.0784e-11, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.123660
Average KL loss: 0.385745
Average total loss: 0.509405
tensor(-12.2323, device='cuda:0') tensor(2.5341, device='cuda:0') tensor(3.3212e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.121564
Average KL loss: 0.385680
Average total loss: 0.507243
tensor(-12.2343, device='cuda:0') tensor(2.5331, device='cuda:0') tensor(1.2962e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.124985
Average KL loss: 0.385605
Average total loss: 0.510590
tensor(-12.2363, device='cuda:0') tensor(2.5320, device='cuda:0') tensor(3.7101e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.121028
Average KL loss: 0.385531
Average total loss: 0.506559
tensor(-12.2383, device='cuda:0') tensor(2.5311, device='cuda:0') tensor(1.1697e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.122567
Average KL loss: 0.385480
Average total loss: 0.508048
tensor(-12.2402, device='cuda:0') tensor(2.5301, device='cuda:0') tensor(3.3005e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.122371
Average KL loss: 0.385416
Average total loss: 0.507787
tensor(-12.2422, device='cuda:0') tensor(2.5290, device='cuda:0') tensor(2.6035e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.123996
Average KL loss: 0.385362
Average total loss: 0.509357
tensor(-12.2442, device='cuda:0') tensor(2.5282, device='cuda:0') tensor(2.2276e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.118563
Average KL loss: 0.385301
Average total loss: 0.503864
tensor(-12.2462, device='cuda:0') tensor(2.5271, device='cuda:0') tensor(1.6183e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.123862
Average KL loss: 0.385223
Average total loss: 0.509084
tensor(-12.2481, device='cuda:0') tensor(2.5262, device='cuda:0') tensor(7.7991e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.121646
Average KL loss: 0.385144
Average total loss: 0.506790
tensor(-12.2501, device='cuda:0') tensor(2.5251, device='cuda:0') tensor(3.2844e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.121294
Average KL loss: 0.385062
Average total loss: 0.506356
tensor(-12.2521, device='cuda:0') tensor(2.5242, device='cuda:0') tensor(3.3603e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.119396
Average KL loss: 0.384987
Average total loss: 0.504383
tensor(-12.2540, device='cuda:0') tensor(2.5232, device='cuda:0') tensor(-1.1363e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.122946
Average KL loss: 0.384911
Average total loss: 0.507857
tensor(-12.2560, device='cuda:0') tensor(2.5222, device='cuda:0') tensor(3.0717e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.120040
Average KL loss: 0.384850
Average total loss: 0.504891
tensor(-12.2579, device='cuda:0') tensor(2.5213, device='cuda:0') tensor(1.8940e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.116348
Average KL loss: 0.384776
Average total loss: 0.501125
tensor(-12.2599, device='cuda:0') tensor(2.5204, device='cuda:0') tensor(3.9274e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.119537
Average KL loss: 0.384710
Average total loss: 0.504247
tensor(-12.2618, device='cuda:0') tensor(2.5194, device='cuda:0') tensor(1.3390e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.120157
Average KL loss: 0.384636
Average total loss: 0.504793
tensor(-12.2637, device='cuda:0') tensor(2.5185, device='cuda:0') tensor(3.1296e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.117751
Average KL loss: 0.384553
Average total loss: 0.502304
tensor(-12.2657, device='cuda:0') tensor(2.5175, device='cuda:0') tensor(3.2878e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.119084
Average KL loss: 0.384465
Average total loss: 0.503549
tensor(-12.2676, device='cuda:0') tensor(2.5165, device='cuda:0') tensor(3.0310e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.116480
Average KL loss: 0.384372
Average total loss: 0.500853
tensor(-12.2695, device='cuda:0') tensor(2.5156, device='cuda:0') tensor(1.6656e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.115301
Average KL loss: 0.384292
Average total loss: 0.499593
tensor(-12.2714, device='cuda:0') tensor(2.5146, device='cuda:0') tensor(-1.3021e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.116873
Average KL loss: 0.384230
Average total loss: 0.501102
tensor(-12.2733, device='cuda:0') tensor(2.5138, device='cuda:0') tensor(3.2904e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.117301
Average KL loss: 0.384155
Average total loss: 0.501456
tensor(-12.2752, device='cuda:0') tensor(2.5129, device='cuda:0') tensor(1.8565e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.116333
Average KL loss: 0.384100
Average total loss: 0.500433
tensor(-12.2771, device='cuda:0') tensor(2.5120, device='cuda:0') tensor(2.3056e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.117994
Average KL loss: 0.384035
Average total loss: 0.502029
tensor(-12.2790, device='cuda:0') tensor(2.5112, device='cuda:0') tensor(2.5335e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.115141
Average KL loss: 0.383959
Average total loss: 0.499100
tensor(-12.2809, device='cuda:0') tensor(2.5102, device='cuda:0') tensor(1.4251e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.117419
Average KL loss: 0.383895
Average total loss: 0.501314
tensor(-12.2828, device='cuda:0') tensor(2.5094, device='cuda:0') tensor(2.0836e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.115978
Average KL loss: 0.383828
Average total loss: 0.499805
tensor(-12.2847, device='cuda:0') tensor(2.5085, device='cuda:0') tensor(1.1915e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.118338
Average KL loss: 0.383768
Average total loss: 0.502106
tensor(-12.2866, device='cuda:0') tensor(2.5078, device='cuda:0') tensor(1.2016e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.116778
Average KL loss: 0.383719
Average total loss: 0.500497
tensor(-12.2884, device='cuda:0') tensor(2.5070, device='cuda:0') tensor(-1.8354e-13, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.114528
Average KL loss: 0.383659
Average total loss: 0.498187
tensor(-12.2903, device='cuda:0') tensor(2.5061, device='cuda:0') tensor(4.1606e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.114108
Average KL loss: 0.383571
Average total loss: 0.497679
tensor(-12.2922, device='cuda:0') tensor(2.5052, device='cuda:0') tensor(2.1481e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.113855
Average KL loss: 0.383501
Average total loss: 0.497356
tensor(-12.2941, device='cuda:0') tensor(2.5043, device='cuda:0') tensor(2.1489e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.117142
Average KL loss: 0.383419
Average total loss: 0.500560
tensor(-12.2959, device='cuda:0') tensor(2.5035, device='cuda:0') tensor(1.5465e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.113403
Average KL loss: 0.383365
Average total loss: 0.496767
tensor(-12.2978, device='cuda:0') tensor(2.5026, device='cuda:0') tensor(2.2280e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.113275
Average KL loss: 0.383305
Average total loss: 0.496580
tensor(-12.2996, device='cuda:0') tensor(2.5018, device='cuda:0') tensor(2.7880e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.112683
Average KL loss: 0.383212
Average total loss: 0.495894
tensor(-12.3015, device='cuda:0') tensor(2.5008, device='cuda:0') tensor(8.3670e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.113079
Average KL loss: 0.383140
Average total loss: 0.496220
tensor(-12.3033, device='cuda:0') tensor(2.5000, device='cuda:0') tensor(2.4611e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.113765
Average KL loss: 0.383060
Average total loss: 0.496825
tensor(-12.3052, device='cuda:0') tensor(2.4992, device='cuda:0') tensor(3.2685e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.114279
Average KL loss: 0.382974
Average total loss: 0.497253
tensor(-12.3070, device='cuda:0') tensor(2.4983, device='cuda:0') tensor(-3.7035e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.112417
Average KL loss: 0.382895
Average total loss: 0.495312
tensor(-12.3089, device='cuda:0') tensor(2.4974, device='cuda:0') tensor(3.2786e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.112303
Average KL loss: 0.382811
Average total loss: 0.495114
tensor(-12.3107, device='cuda:0') tensor(2.4965, device='cuda:0') tensor(6.5223e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.112690
Average KL loss: 0.382742
Average total loss: 0.495432
tensor(-12.3125, device='cuda:0') tensor(2.4957, device='cuda:0') tensor(1.4543e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.112614
Average KL loss: 0.382675
Average total loss: 0.495289
tensor(-12.3143, device='cuda:0') tensor(2.4948, device='cuda:0') tensor(3.7180e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.113293
Average KL loss: 0.382603
Average total loss: 0.495896
tensor(-12.3162, device='cuda:0') tensor(2.4940, device='cuda:0') tensor(1.4369e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.110993
Average KL loss: 0.382544
Average total loss: 0.493537
tensor(-12.3180, device='cuda:0') tensor(2.4932, device='cuda:0') tensor(2.1302e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.111080
Average KL loss: 0.382474
Average total loss: 0.493554
tensor(-12.3198, device='cuda:0') tensor(2.4923, device='cuda:0') tensor(2.2755e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.109466
Average KL loss: 0.382407
Average total loss: 0.491874
tensor(-12.3216, device='cuda:0') tensor(2.4914, device='cuda:0') tensor(6.5949e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.109878
Average KL loss: 0.382340
Average total loss: 0.492219
tensor(-12.3234, device='cuda:0') tensor(2.4907, device='cuda:0') tensor(-1.6697e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.111049
Average KL loss: 0.382284
Average total loss: 0.493333
tensor(-12.3252, device='cuda:0') tensor(2.4899, device='cuda:0') tensor(-6.9355e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.111234
Average KL loss: 0.382216
Average total loss: 0.493450
tensor(-12.3270, device='cuda:0') tensor(2.4891, device='cuda:0') tensor(8.7978e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.108504
Average KL loss: 0.382142
Average total loss: 0.490647
tensor(-12.3288, device='cuda:0') tensor(2.4883, device='cuda:0') tensor(1.3452e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.108970
Average KL loss: 0.382073
Average total loss: 0.491043
tensor(-12.3306, device='cuda:0') tensor(2.4874, device='cuda:0') tensor(3.1535e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.110482
Average KL loss: 0.381978
Average total loss: 0.492460
tensor(-12.3324, device='cuda:0') tensor(2.4865, device='cuda:0') tensor(5.2732e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.108754
Average KL loss: 0.381912
Average total loss: 0.490666
tensor(-12.3342, device='cuda:0') tensor(2.4856, device='cuda:0') tensor(3.7254e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.108823
Average KL loss: 0.381852
Average total loss: 0.490675
tensor(-12.3360, device='cuda:0') tensor(2.4849, device='cuda:0') tensor(3.4151e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.109619
Average KL loss: 0.381789
Average total loss: 0.491408
tensor(-12.3378, device='cuda:0') tensor(2.4840, device='cuda:0') tensor(2.6827e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.110095
Average KL loss: 0.381713
Average total loss: 0.491807
tensor(-12.3396, device='cuda:0') tensor(2.4831, device='cuda:0') tensor(2.3099e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.108261
Average KL loss: 0.381662
Average total loss: 0.489924
tensor(-12.3413, device='cuda:0') tensor(2.4824, device='cuda:0') tensor(1.7974e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.109082
Average KL loss: 0.381610
Average total loss: 0.490692
tensor(-12.3431, device='cuda:0') tensor(2.4816, device='cuda:0') tensor(2.0151e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.107311
Average KL loss: 0.381545
Average total loss: 0.488856
tensor(-12.3449, device='cuda:0') tensor(2.4808, device='cuda:0') tensor(1.6980e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.108950
Average KL loss: 0.381475
Average total loss: 0.490424
tensor(-12.3467, device='cuda:0') tensor(2.4800, device='cuda:0') tensor(3.1775e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.108584
Average KL loss: 0.381404
Average total loss: 0.489988
tensor(-12.3484, device='cuda:0') tensor(2.4792, device='cuda:0') tensor(1.7555e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.107184
Average KL loss: 0.381339
Average total loss: 0.488523
tensor(-12.3502, device='cuda:0') tensor(2.4785, device='cuda:0') tensor(1.5215e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.107414
Average KL loss: 0.381261
Average total loss: 0.488675
tensor(-12.3519, device='cuda:0') tensor(2.4777, device='cuda:0') tensor(2.0030e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.105494
Average KL loss: 0.381188
Average total loss: 0.486683
tensor(-12.3537, device='cuda:0') tensor(2.4769, device='cuda:0') tensor(2.4982e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.107189
Average KL loss: 0.381151
Average total loss: 0.488339
tensor(-12.3554, device='cuda:0') tensor(2.4761, device='cuda:0') tensor(1.0002e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.107926
Average KL loss: 0.381090
Average total loss: 0.489017
tensor(-12.3572, device='cuda:0') tensor(2.4754, device='cuda:0') tensor(9.4824e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.106664
Average KL loss: 0.381014
Average total loss: 0.487678
tensor(-12.3589, device='cuda:0') tensor(2.4745, device='cuda:0') tensor(2.6285e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.105965
Average KL loss: 0.380917
Average total loss: 0.486882
tensor(-12.3607, device='cuda:0') tensor(2.4737, device='cuda:0') tensor(5.3584e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.104275
Average KL loss: 0.380853
Average total loss: 0.485128
tensor(-12.3624, device='cuda:0') tensor(2.4729, device='cuda:0') tensor(2.5000e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.104578
Average KL loss: 0.380782
Average total loss: 0.485360
tensor(-12.3641, device='cuda:0') tensor(2.4720, device='cuda:0') tensor(2.6357e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.105593
Average KL loss: 0.380719
Average total loss: 0.486312
tensor(-12.3659, device='cuda:0') tensor(2.4712, device='cuda:0') tensor(2.2320e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.104118
Average KL loss: 0.380670
Average total loss: 0.484788
tensor(-12.3676, device='cuda:0') tensor(2.4704, device='cuda:0') tensor(2.7954e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.105870
Average KL loss: 0.380615
Average total loss: 0.486485
tensor(-12.3693, device='cuda:0') tensor(2.4696, device='cuda:0') tensor(3.3727e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.105338
Average KL loss: 0.380553
Average total loss: 0.485891
 Percentile value: -6.2403764724731445
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =    1272 /    1728             ( 73.61%) | total_pruned =     456 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    7295 /   36864             ( 19.79%) | total_pruned =   29569 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    7591 /   36864             ( 20.59%) | total_pruned =   29273 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    6685 /   36864             ( 18.13%) | total_pruned =   30179 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    6292 /   36864             ( 17.07%) | total_pruned =   30572 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13049 /   73728             ( 17.70%) | total_pruned =   60679 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   19834 /  147456             ( 13.45%) | total_pruned =  127622 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3175 /    8192             ( 38.76%) | total_pruned =    5017 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   14624 /  147456             (  9.92%) | total_pruned =  132832 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   14202 /  147456             (  9.63%) | total_pruned =  133254 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   30805 /  294912             ( 10.45%) | total_pruned =  264107 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   42996 /  589824             (  7.29%) | total_pruned =  546828 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     182 /     256             ( 71.09%) | total_pruned =      74 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7208 /   32768             ( 22.00%) | total_pruned =   25560 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   19201 /  589824             (  3.26%) | total_pruned =  570623 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   20340 /  589824             (  3.45%) | total_pruned =  569484 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   38935 / 1179648             (  3.30%) | total_pruned = 1140713 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     308 /     512             ( 60.16%) | total_pruned =     204 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     228 /     512             ( 44.53%) | total_pruned =     284 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   36016 / 2359296             (  1.53%) | total_pruned = 2323280 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     379 /     512             ( 74.02%) | total_pruned =     133 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     365 /     512             ( 71.29%) | total_pruned =     147 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    8542 /  131072             (  6.52%) | total_pruned =  122530 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     304 /     512             ( 59.38%) | total_pruned =     208 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     367 /     512             ( 71.68%) | total_pruned =     145 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   18777 / 2359296             (  0.80%) | total_pruned = 2340519 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     179 /     512             ( 34.96%) | total_pruned =     333 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   22628 / 2359296             (  0.96%) | total_pruned = 2336668 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     404 /     512             ( 78.91%) | total_pruned =     108 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     314 /     512             ( 61.33%) | total_pruned =     198 | shape = torch.Size([512])
linear.weight        | nonzeros =    3590 /    5120             ( 70.12%) | total_pruned =    1530 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 22/100 Loss: 0.000032 Accuracy: 86.39 100.00 % Best test Accuracy: 86.73%
tensor(-12.3710, device='cuda:0') tensor(2.4688, device='cuda:0') tensor(5.6701e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.181873
Average KL loss: 0.378372
Average total loss: 0.560245
tensor(-12.3795, device='cuda:0') tensor(2.3773, device='cuda:0') tensor(-1.1812e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.173784
Average KL loss: 0.376903
Average total loss: 0.550688
tensor(-12.3854, device='cuda:0') tensor(2.3275, device='cuda:0') tensor(5.2653e-11, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.169733
Average KL loss: 0.376373
Average total loss: 0.546105
tensor(-12.3903, device='cuda:0') tensor(2.2934, device='cuda:0') tensor(-1.0168e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.165357
Average KL loss: 0.376099
Average total loss: 0.541457
tensor(-12.3945, device='cuda:0') tensor(2.2677, device='cuda:0') tensor(-4.3365e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.167170
Average KL loss: 0.375968
Average total loss: 0.543138
tensor(-12.3984, device='cuda:0') tensor(2.2472, device='cuda:0') tensor(5.1779e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.165365
Average KL loss: 0.375867
Average total loss: 0.541233
tensor(-12.4019, device='cuda:0') tensor(2.2304, device='cuda:0') tensor(8.8115e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.160845
Average KL loss: 0.375800
Average total loss: 0.536645
tensor(-12.4053, device='cuda:0') tensor(2.2160, device='cuda:0') tensor(-4.7071e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.158528
Average KL loss: 0.375750
Average total loss: 0.534277
tensor(-12.4084, device='cuda:0') tensor(2.2034, device='cuda:0') tensor(5.4973e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.155298
Average KL loss: 0.375711
Average total loss: 0.531009
tensor(-12.4115, device='cuda:0') tensor(2.1923, device='cuda:0') tensor(2.8985e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.154744
Average KL loss: 0.375692
Average total loss: 0.530436
tensor(-12.4144, device='cuda:0') tensor(2.1823, device='cuda:0') tensor(-1.7184e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.152440
Average KL loss: 0.375684
Average total loss: 0.528124
tensor(-12.4172, device='cuda:0') tensor(2.1733, device='cuda:0') tensor(-6.4071e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.149884
Average KL loss: 0.375697
Average total loss: 0.525581
tensor(-12.4199, device='cuda:0') tensor(2.1652, device='cuda:0') tensor(2.9096e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.148512
Average KL loss: 0.375690
Average total loss: 0.524202
tensor(-12.4226, device='cuda:0') tensor(2.1577, device='cuda:0') tensor(4.8897e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.142450
Average KL loss: 0.375702
Average total loss: 0.518153
tensor(-12.4252, device='cuda:0') tensor(2.1507, device='cuda:0') tensor(2.9765e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.147917
Average KL loss: 0.375705
Average total loss: 0.523622
tensor(-12.4278, device='cuda:0') tensor(2.1443, device='cuda:0') tensor(2.1268e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.148399
Average KL loss: 0.375718
Average total loss: 0.524117
tensor(-12.4303, device='cuda:0') tensor(2.1383, device='cuda:0') tensor(-6.9784e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.143523
Average KL loss: 0.375723
Average total loss: 0.519247
tensor(-12.4327, device='cuda:0') tensor(2.1325, device='cuda:0') tensor(9.6842e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.144792
Average KL loss: 0.375736
Average total loss: 0.520528
tensor(-12.4351, device='cuda:0') tensor(2.1272, device='cuda:0') tensor(4.6666e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.142375
Average KL loss: 0.375739
Average total loss: 0.518113
tensor(-12.4375, device='cuda:0') tensor(2.1221, device='cuda:0') tensor(1.5383e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.141668
Average KL loss: 0.375727
Average total loss: 0.517395
tensor(-12.4398, device='cuda:0') tensor(2.1174, device='cuda:0') tensor(-1.9273e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.138458
Average KL loss: 0.375723
Average total loss: 0.514181
tensor(-12.4421, device='cuda:0') tensor(2.1129, device='cuda:0') tensor(2.8590e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.142844
Average KL loss: 0.375710
Average total loss: 0.518554
tensor(-12.4444, device='cuda:0') tensor(2.1087, device='cuda:0') tensor(4.4704e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.139703
Average KL loss: 0.375719
Average total loss: 0.515422
tensor(-12.4466, device='cuda:0') tensor(2.1046, device='cuda:0') tensor(-1.5119e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.136687
Average KL loss: 0.375719
Average total loss: 0.512406
tensor(-12.4488, device='cuda:0') tensor(2.1007, device='cuda:0') tensor(2.0307e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.136185
Average KL loss: 0.375719
Average total loss: 0.511904
tensor(-12.4510, device='cuda:0') tensor(2.0970, device='cuda:0') tensor(-2.7335e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.136811
Average KL loss: 0.375704
Average total loss: 0.512516
tensor(-12.4532, device='cuda:0') tensor(2.0935, device='cuda:0') tensor(-3.6501e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.134659
Average KL loss: 0.375708
Average total loss: 0.510367
tensor(-12.4554, device='cuda:0') tensor(2.0901, device='cuda:0') tensor(-6.8167e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.135216
Average KL loss: 0.375725
Average total loss: 0.510941
tensor(-12.4575, device='cuda:0') tensor(2.0870, device='cuda:0') tensor(8.1791e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.135208
Average KL loss: 0.375760
Average total loss: 0.510968
tensor(-12.4596, device='cuda:0') tensor(2.0838, device='cuda:0') tensor(-1.2031e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.132758
Average KL loss: 0.375775
Average total loss: 0.508533
tensor(-12.4617, device='cuda:0') tensor(2.0808, device='cuda:0') tensor(-1.5817e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.129423
Average KL loss: 0.375766
Average total loss: 0.505189
tensor(-12.4638, device='cuda:0') tensor(2.0779, device='cuda:0') tensor(-1.2022e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.130905
Average KL loss: 0.375778
Average total loss: 0.506683
tensor(-12.4658, device='cuda:0') tensor(2.0752, device='cuda:0') tensor(9.3620e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.133278
Average KL loss: 0.375799
Average total loss: 0.509077
tensor(-12.4678, device='cuda:0') tensor(2.0726, device='cuda:0') tensor(-2.2273e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.128648
Average KL loss: 0.375808
Average total loss: 0.504456
tensor(-12.4699, device='cuda:0') tensor(2.0700, device='cuda:0') tensor(-6.7323e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.132296
Average KL loss: 0.375791
Average total loss: 0.508087
tensor(-12.4719, device='cuda:0') tensor(2.0675, device='cuda:0') tensor(-3.7844e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.127371
Average KL loss: 0.375769
Average total loss: 0.503140
tensor(-12.4739, device='cuda:0') tensor(2.0650, device='cuda:0') tensor(1.3624e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.128689
Average KL loss: 0.375764
Average total loss: 0.504453
tensor(-12.4759, device='cuda:0') tensor(2.0627, device='cuda:0') tensor(5.7841e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.127092
Average KL loss: 0.375774
Average total loss: 0.502866
tensor(-12.4778, device='cuda:0') tensor(2.0605, device='cuda:0') tensor(7.0007e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.127846
Average KL loss: 0.375784
Average total loss: 0.503630
tensor(-12.4798, device='cuda:0') tensor(2.0584, device='cuda:0') tensor(1.1793e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.125881
Average KL loss: 0.375789
Average total loss: 0.501670
tensor(-12.4818, device='cuda:0') tensor(2.0562, device='cuda:0') tensor(2.4273e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.125074
Average KL loss: 0.375776
Average total loss: 0.500850
tensor(-12.4837, device='cuda:0') tensor(2.0542, device='cuda:0') tensor(-7.5040e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.125683
Average KL loss: 0.375792
Average total loss: 0.501475
tensor(-12.4856, device='cuda:0') tensor(2.0522, device='cuda:0') tensor(-1.5243e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.126635
Average KL loss: 0.375785
Average total loss: 0.502420
tensor(-12.4875, device='cuda:0') tensor(2.0503, device='cuda:0') tensor(-3.6245e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.121213
Average KL loss: 0.375794
Average total loss: 0.497007
tensor(-12.4894, device='cuda:0') tensor(2.0484, device='cuda:0') tensor(1.3731e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.124881
Average KL loss: 0.375788
Average total loss: 0.500669
tensor(-12.4913, device='cuda:0') tensor(2.0466, device='cuda:0') tensor(-1.5863e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.123206
Average KL loss: 0.375790
Average total loss: 0.498997
tensor(-12.4932, device='cuda:0') tensor(2.0448, device='cuda:0') tensor(6.5774e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.121223
Average KL loss: 0.375791
Average total loss: 0.497014
tensor(-12.4951, device='cuda:0') tensor(2.0431, device='cuda:0') tensor(-4.7985e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.123775
Average KL loss: 0.375804
Average total loss: 0.499578
tensor(-12.4970, device='cuda:0') tensor(2.0415, device='cuda:0') tensor(-8.5479e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.121074
Average KL loss: 0.375817
Average total loss: 0.496892
tensor(-12.4988, device='cuda:0') tensor(2.0398, device='cuda:0') tensor(1.9562e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.123056
Average KL loss: 0.375810
Average total loss: 0.498866
tensor(-12.5007, device='cuda:0') tensor(2.0382, device='cuda:0') tensor(-1.5461e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.117812
Average KL loss: 0.375820
Average total loss: 0.493632
tensor(-12.5025, device='cuda:0') tensor(2.0367, device='cuda:0') tensor(-1.4225e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.121166
Average KL loss: 0.375825
Average total loss: 0.496992
tensor(-12.5043, device='cuda:0') tensor(2.0351, device='cuda:0') tensor(1.5069e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.118261
Average KL loss: 0.375822
Average total loss: 0.494084
tensor(-12.5061, device='cuda:0') tensor(2.0337, device='cuda:0') tensor(-3.7619e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.118091
Average KL loss: 0.375819
Average total loss: 0.493909
tensor(-12.5079, device='cuda:0') tensor(2.0322, device='cuda:0') tensor(-6.6490e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.117333
Average KL loss: 0.375801
Average total loss: 0.493134
tensor(-12.5097, device='cuda:0') tensor(2.0308, device='cuda:0') tensor(2.2784e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.119248
Average KL loss: 0.375790
Average total loss: 0.495038
tensor(-12.5115, device='cuda:0') tensor(2.0294, device='cuda:0') tensor(9.6661e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.115947
Average KL loss: 0.375782
Average total loss: 0.491729
tensor(-12.5133, device='cuda:0') tensor(2.0280, device='cuda:0') tensor(-1.1317e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.119670
Average KL loss: 0.375777
Average total loss: 0.495447
tensor(-12.5151, device='cuda:0') tensor(2.0267, device='cuda:0') tensor(-2.6254e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.117950
Average KL loss: 0.375787
Average total loss: 0.493737
tensor(-12.5169, device='cuda:0') tensor(2.0255, device='cuda:0') tensor(2.8737e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.116621
Average KL loss: 0.375796
Average total loss: 0.492417
tensor(-12.5186, device='cuda:0') tensor(2.0242, device='cuda:0') tensor(2.6095e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.117378
Average KL loss: 0.375795
Average total loss: 0.493172
tensor(-12.5204, device='cuda:0') tensor(2.0230, device='cuda:0') tensor(1.6142e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.119006
Average KL loss: 0.375789
Average total loss: 0.494795
tensor(-12.5222, device='cuda:0') tensor(2.0217, device='cuda:0') tensor(7.6867e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.114441
Average KL loss: 0.375771
Average total loss: 0.490212
tensor(-12.5239, device='cuda:0') tensor(2.0205, device='cuda:0') tensor(-1.4235e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.115603
Average KL loss: 0.375763
Average total loss: 0.491365
tensor(-12.5257, device='cuda:0') tensor(2.0193, device='cuda:0') tensor(-1.2696e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.112031
Average KL loss: 0.375757
Average total loss: 0.487788
tensor(-12.5274, device='cuda:0') tensor(2.0182, device='cuda:0') tensor(5.2899e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.113276
Average KL loss: 0.375753
Average total loss: 0.489029
tensor(-12.5291, device='cuda:0') tensor(2.0171, device='cuda:0') tensor(4.1680e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.113172
Average KL loss: 0.375752
Average total loss: 0.488924
tensor(-12.5308, device='cuda:0') tensor(2.0159, device='cuda:0') tensor(1.2036e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.111615
Average KL loss: 0.375742
Average total loss: 0.487357
tensor(-12.5326, device='cuda:0') tensor(2.0148, device='cuda:0') tensor(-6.5775e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.110717
Average KL loss: 0.375735
Average total loss: 0.486452
tensor(-12.5343, device='cuda:0') tensor(2.0137, device='cuda:0') tensor(-4.1033e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.112802
Average KL loss: 0.375719
Average total loss: 0.488521
tensor(-12.5360, device='cuda:0') tensor(2.0126, device='cuda:0') tensor(-1.3325e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.112310
Average KL loss: 0.375709
Average total loss: 0.488019
tensor(-12.5377, device='cuda:0') tensor(2.0115, device='cuda:0') tensor(1.5035e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.112578
Average KL loss: 0.375691
Average total loss: 0.488269
tensor(-12.5394, device='cuda:0') tensor(2.0105, device='cuda:0') tensor(1.8154e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.110268
Average KL loss: 0.375678
Average total loss: 0.485946
tensor(-12.5411, device='cuda:0') tensor(2.0094, device='cuda:0') tensor(2.4857e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.110093
Average KL loss: 0.375665
Average total loss: 0.485758
tensor(-12.5428, device='cuda:0') tensor(2.0084, device='cuda:0') tensor(-2.6439e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.110556
Average KL loss: 0.375651
Average total loss: 0.486207
tensor(-12.5445, device='cuda:0') tensor(2.0075, device='cuda:0') tensor(-6.6883e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.108124
Average KL loss: 0.375645
Average total loss: 0.483769
tensor(-12.5461, device='cuda:0') tensor(2.0065, device='cuda:0') tensor(2.0725e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.107934
Average KL loss: 0.375632
Average total loss: 0.483566
tensor(-12.5478, device='cuda:0') tensor(2.0056, device='cuda:0') tensor(-2.5939e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.106478
Average KL loss: 0.375633
Average total loss: 0.482111
tensor(-12.5495, device='cuda:0') tensor(2.0046, device='cuda:0') tensor(-1.8515e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.108339
Average KL loss: 0.375625
Average total loss: 0.483964
tensor(-12.5511, device='cuda:0') tensor(2.0038, device='cuda:0') tensor(1.3926e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.109752
Average KL loss: 0.375605
Average total loss: 0.485357
tensor(-12.5528, device='cuda:0') tensor(2.0029, device='cuda:0') tensor(-1.3458e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.109479
Average KL loss: 0.375580
Average total loss: 0.485060
tensor(-12.5545, device='cuda:0') tensor(2.0020, device='cuda:0') tensor(2.5346e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.107921
Average KL loss: 0.375552
Average total loss: 0.483473
tensor(-12.5561, device='cuda:0') tensor(2.0011, device='cuda:0') tensor(6.6346e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.108892
Average KL loss: 0.375552
Average total loss: 0.484445
tensor(-12.5577, device='cuda:0') tensor(2.0003, device='cuda:0') tensor(2.1983e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.107694
Average KL loss: 0.375536
Average total loss: 0.483230
tensor(-12.5594, device='cuda:0') tensor(1.9995, device='cuda:0') tensor(-1.1009e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.107739
Average KL loss: 0.375508
Average total loss: 0.483246
tensor(-12.5610, device='cuda:0') tensor(1.9986, device='cuda:0') tensor(-9.5824e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.105749
Average KL loss: 0.375484
Average total loss: 0.481233
tensor(-12.5626, device='cuda:0') tensor(1.9979, device='cuda:0') tensor(7.4714e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.106636
Average KL loss: 0.375476
Average total loss: 0.482112
tensor(-12.5643, device='cuda:0') tensor(1.9971, device='cuda:0') tensor(1.4015e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.103410
Average KL loss: 0.375455
Average total loss: 0.478865
tensor(-12.5659, device='cuda:0') tensor(1.9963, device='cuda:0') tensor(7.1415e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.106256
Average KL loss: 0.375423
Average total loss: 0.481679
tensor(-12.5675, device='cuda:0') tensor(1.9956, device='cuda:0') tensor(-4.5441e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.104191
Average KL loss: 0.375414
Average total loss: 0.479605
tensor(-12.5691, device='cuda:0') tensor(1.9948, device='cuda:0') tensor(4.2427e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.103026
Average KL loss: 0.375387
Average total loss: 0.478414
tensor(-12.5707, device='cuda:0') tensor(1.9940, device='cuda:0') tensor(-1.3268e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.104793
Average KL loss: 0.375367
Average total loss: 0.480160
tensor(-12.5723, device='cuda:0') tensor(1.9932, device='cuda:0') tensor(-5.3027e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.104245
Average KL loss: 0.375362
Average total loss: 0.479607
tensor(-12.5739, device='cuda:0') tensor(1.9926, device='cuda:0') tensor(1.2804e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.102070
Average KL loss: 0.375354
Average total loss: 0.477424
tensor(-12.5755, device='cuda:0') tensor(1.9918, device='cuda:0') tensor(-7.5123e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.103274
Average KL loss: 0.375335
Average total loss: 0.478609
tensor(-12.5771, device='cuda:0') tensor(1.9911, device='cuda:0') tensor(1.7555e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.104904
Average KL loss: 0.375310
Average total loss: 0.480214
tensor(-12.5787, device='cuda:0') tensor(1.9904, device='cuda:0') tensor(5.9956e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.103097
Average KL loss: 0.375278
Average total loss: 0.478375
tensor(-12.5803, device='cuda:0') tensor(1.9898, device='cuda:0') tensor(-1.4996e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.105806
Average KL loss: 0.375275
Average total loss: 0.481081
tensor(-12.5818, device='cuda:0') tensor(1.9891, device='cuda:0') tensor(-5.1173e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.103684
Average KL loss: 0.375258
Average total loss: 0.478943
tensor(-12.5834, device='cuda:0') tensor(1.9885, device='cuda:0') tensor(-3.2626e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.103387
Average KL loss: 0.375233
Average total loss: 0.478620
tensor(-12.5850, device='cuda:0') tensor(1.9878, device='cuda:0') tensor(-1.0624e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.102438
Average KL loss: 0.375220
Average total loss: 0.477658
tensor(-12.5865, device='cuda:0') tensor(1.9871, device='cuda:0') tensor(3.5990e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.100878
Average KL loss: 0.375195
Average total loss: 0.476073
tensor(-12.5881, device='cuda:0') tensor(1.9864, device='cuda:0') tensor(5.9678e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.101172
Average KL loss: 0.375167
Average total loss: 0.476338
tensor(-12.5897, device='cuda:0') tensor(1.9858, device='cuda:0') tensor(2.1797e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.102117
Average KL loss: 0.375142
Average total loss: 0.477260
tensor(-12.5912, device='cuda:0') tensor(1.9851, device='cuda:0') tensor(6.9059e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.100125
Average KL loss: 0.375106
Average total loss: 0.475231
tensor(-12.5928, device='cuda:0') tensor(1.9844, device='cuda:0') tensor(-1.4109e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.099864
Average KL loss: 0.375087
Average total loss: 0.474951
tensor(-12.5943, device='cuda:0') tensor(1.9839, device='cuda:0') tensor(4.0400e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.100684
Average KL loss: 0.375063
Average total loss: 0.475748
tensor(-12.5959, device='cuda:0') tensor(1.9832, device='cuda:0') tensor(1.6607e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.100757
Average KL loss: 0.375032
Average total loss: 0.475789
tensor(-12.5974, device='cuda:0') tensor(1.9826, device='cuda:0') tensor(1.6480e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.101075
Average KL loss: 0.375024
Average total loss: 0.476100
tensor(-12.5990, device='cuda:0') tensor(1.9820, device='cuda:0') tensor(-6.4225e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.098926
Average KL loss: 0.375004
Average total loss: 0.473931
tensor(-12.6005, device='cuda:0') tensor(1.9813, device='cuda:0') tensor(-9.4800e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.098869
Average KL loss: 0.374980
Average total loss: 0.473850
tensor(-12.6020, device='cuda:0') tensor(1.9807, device='cuda:0') tensor(-1.1528e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.097752
Average KL loss: 0.374969
Average total loss: 0.472721
tensor(-12.6036, device='cuda:0') tensor(1.9802, device='cuda:0') tensor(8.0123e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.097595
Average KL loss: 0.374937
Average total loss: 0.472532
tensor(-12.6051, device='cuda:0') tensor(1.9796, device='cuda:0') tensor(-2.3110e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.095949
Average KL loss: 0.374907
Average total loss: 0.470855
tensor(-12.6066, device='cuda:0') tensor(1.9790, device='cuda:0') tensor(9.3230e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.098565
Average KL loss: 0.374866
Average total loss: 0.473430
tensor(-12.6081, device='cuda:0') tensor(1.9785, device='cuda:0') tensor(3.0910e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.099249
Average KL loss: 0.374824
Average total loss: 0.474073
tensor(-12.6097, device='cuda:0') tensor(1.9779, device='cuda:0') tensor(1.0125e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.097866
Average KL loss: 0.374796
Average total loss: 0.472663
tensor(-12.6112, device='cuda:0') tensor(1.9773, device='cuda:0') tensor(4.0198e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.095888
Average KL loss: 0.374774
Average total loss: 0.470662
tensor(-12.6127, device='cuda:0') tensor(1.9767, device='cuda:0') tensor(-1.0753e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.095973
Average KL loss: 0.374744
Average total loss: 0.470717
tensor(-12.6142, device='cuda:0') tensor(1.9761, device='cuda:0') tensor(-7.4653e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.098907
Average KL loss: 0.374708
Average total loss: 0.473615
tensor(-12.6157, device='cuda:0') tensor(1.9756, device='cuda:0') tensor(1.2429e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.095761
Average KL loss: 0.374671
Average total loss: 0.470432
tensor(-12.6172, device='cuda:0') tensor(1.9750, device='cuda:0') tensor(1.7532e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.094807
Average KL loss: 0.374637
Average total loss: 0.469444
tensor(-12.6187, device='cuda:0') tensor(1.9744, device='cuda:0') tensor(7.2340e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.096664
Average KL loss: 0.374615
Average total loss: 0.471279
tensor(-12.6202, device='cuda:0') tensor(1.9740, device='cuda:0') tensor(-1.0915e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.096408
Average KL loss: 0.374595
Average total loss: 0.471003
tensor(-12.6217, device='cuda:0') tensor(1.9734, device='cuda:0') tensor(4.9972e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.094794
Average KL loss: 0.374563
Average total loss: 0.469356
tensor(-12.6232, device='cuda:0') tensor(1.9729, device='cuda:0') tensor(2.4858e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.096206
Average KL loss: 0.374513
Average total loss: 0.470719
tensor(-12.6247, device='cuda:0') tensor(1.9724, device='cuda:0') tensor(2.1049e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.096486
Average KL loss: 0.374482
Average total loss: 0.470968
tensor(-12.6262, device='cuda:0') tensor(1.9719, device='cuda:0') tensor(-9.4568e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.093462
Average KL loss: 0.374446
Average total loss: 0.467908
tensor(-12.6276, device='cuda:0') tensor(1.9714, device='cuda:0') tensor(-1.6026e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.094787
Average KL loss: 0.374412
Average total loss: 0.469199
tensor(-12.6291, device='cuda:0') tensor(1.9709, device='cuda:0') tensor(-2.6156e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.094667
Average KL loss: 0.374382
Average total loss: 0.469049
tensor(-12.6306, device='cuda:0') tensor(1.9705, device='cuda:0') tensor(-4.3582e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.091919
Average KL loss: 0.374340
Average total loss: 0.466259
tensor(-12.6321, device='cuda:0') tensor(1.9699, device='cuda:0') tensor(4.5442e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.091001
Average KL loss: 0.374288
Average total loss: 0.465289
tensor(-12.6335, device='cuda:0') tensor(1.9694, device='cuda:0') tensor(1.3043e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.093790
Average KL loss: 0.374254
Average total loss: 0.468043
tensor(-12.6350, device='cuda:0') tensor(1.9689, device='cuda:0') tensor(1.0714e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.093655
Average KL loss: 0.374232
Average total loss: 0.467887
tensor(-12.6364, device='cuda:0') tensor(1.9684, device='cuda:0') tensor(3.2680e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.091292
Average KL loss: 0.374196
Average total loss: 0.465488
tensor(-12.6379, device='cuda:0') tensor(1.9679, device='cuda:0') tensor(3.5969e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.093298
Average KL loss: 0.374145
Average total loss: 0.467443
tensor(-12.6394, device='cuda:0') tensor(1.9674, device='cuda:0') tensor(-9.1493e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.093566
Average KL loss: 0.374118
Average total loss: 0.467683
tensor(-12.6408, device='cuda:0') tensor(1.9670, device='cuda:0') tensor(5.4901e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.090419
Average KL loss: 0.374063
Average total loss: 0.464482
tensor(-12.6423, device='cuda:0') tensor(1.9664, device='cuda:0') tensor(7.1373e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.093985
Average KL loss: 0.374027
Average total loss: 0.468013
tensor(-12.6437, device='cuda:0') tensor(1.9660, device='cuda:0') tensor(1.2533e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.092363
Average KL loss: 0.373990
Average total loss: 0.466354
tensor(-12.6452, device='cuda:0') tensor(1.9655, device='cuda:0') tensor(1.2384e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.090373
Average KL loss: 0.373951
Average total loss: 0.464324
tensor(-12.6466, device='cuda:0') tensor(1.9650, device='cuda:0') tensor(1.4548e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.091300
Average KL loss: 0.373906
Average total loss: 0.465205
tensor(-12.6481, device='cuda:0') tensor(1.9646, device='cuda:0') tensor(2.0169e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.090513
Average KL loss: 0.373860
Average total loss: 0.464373
tensor(-12.6495, device='cuda:0') tensor(1.9642, device='cuda:0') tensor(2.7153e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.092110
Average KL loss: 0.373824
Average total loss: 0.465935
tensor(-12.6509, device='cuda:0') tensor(1.9637, device='cuda:0') tensor(2.6825e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.091337
Average KL loss: 0.373787
Average total loss: 0.465124
tensor(-12.6524, device='cuda:0') tensor(1.9633, device='cuda:0') tensor(8.6426e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.089905
Average KL loss: 0.373750
Average total loss: 0.463655
tensor(-12.6538, device='cuda:0') tensor(1.9628, device='cuda:0') tensor(-1.9121e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.090335
Average KL loss: 0.373712
Average total loss: 0.464047
tensor(-12.6552, device='cuda:0') tensor(1.9624, device='cuda:0') tensor(-2.3320e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.091441
Average KL loss: 0.373690
Average total loss: 0.465131
tensor(-12.6567, device='cuda:0') tensor(1.9620, device='cuda:0') tensor(7.4176e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.090414
Average KL loss: 0.373656
Average total loss: 0.464070
tensor(-12.6581, device='cuda:0') tensor(1.9616, device='cuda:0') tensor(5.9795e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.090812
Average KL loss: 0.373627
Average total loss: 0.464439
tensor(-12.6595, device='cuda:0') tensor(1.9612, device='cuda:0') tensor(-4.0862e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.087081
Average KL loss: 0.373596
Average total loss: 0.460678
tensor(-12.6609, device='cuda:0') tensor(1.9608, device='cuda:0') tensor(1.2645e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.089816
Average KL loss: 0.373560
Average total loss: 0.463376
tensor(-12.6623, device='cuda:0') tensor(1.9603, device='cuda:0') tensor(9.2798e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.087470
Average KL loss: 0.373521
Average total loss: 0.460991
tensor(-12.6638, device='cuda:0') tensor(1.9599, device='cuda:0') tensor(-1.8568e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.087638
Average KL loss: 0.373482
Average total loss: 0.461120
tensor(-12.6652, device='cuda:0') tensor(1.9594, device='cuda:0') tensor(1.3831e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.088454
Average KL loss: 0.373451
Average total loss: 0.461905
tensor(-12.6666, device='cuda:0') tensor(1.9589, device='cuda:0') tensor(-4.8275e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.088519
Average KL loss: 0.373409
Average total loss: 0.461928
tensor(-12.6680, device='cuda:0') tensor(1.9585, device='cuda:0') tensor(-9.1403e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.087044
Average KL loss: 0.373382
Average total loss: 0.460426
tensor(-12.6694, device='cuda:0') tensor(1.9581, device='cuda:0') tensor(2.2937e-11, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.088655
Average KL loss: 0.373351
Average total loss: 0.462006
tensor(-12.6708, device='cuda:0') tensor(1.9578, device='cuda:0') tensor(1.1409e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.089339
Average KL loss: 0.373316
Average total loss: 0.462655
tensor(-12.6722, device='cuda:0') tensor(1.9574, device='cuda:0') tensor(1.9820e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.088903
Average KL loss: 0.373280
Average total loss: 0.462183
tensor(-12.6736, device='cuda:0') tensor(1.9569, device='cuda:0') tensor(9.0705e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.088471
Average KL loss: 0.373238
Average total loss: 0.461709
tensor(-12.6750, device='cuda:0') tensor(1.9566, device='cuda:0') tensor(4.9000e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.088259
Average KL loss: 0.373200
Average total loss: 0.461459
tensor(-12.6764, device='cuda:0') tensor(1.9561, device='cuda:0') tensor(-2.1316e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.087017
Average KL loss: 0.373156
Average total loss: 0.460173
tensor(-12.6778, device='cuda:0') tensor(1.9557, device='cuda:0') tensor(1.5498e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.087329
Average KL loss: 0.373112
Average total loss: 0.460441
tensor(-12.6792, device='cuda:0') tensor(1.9553, device='cuda:0') tensor(4.9122e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.088196
Average KL loss: 0.373069
Average total loss: 0.461264
tensor(-12.6806, device='cuda:0') tensor(1.9549, device='cuda:0') tensor(1.3026e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.085786
Average KL loss: 0.373021
Average total loss: 0.458807
tensor(-12.6819, device='cuda:0') tensor(1.9546, device='cuda:0') tensor(-8.2665e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.086860
Average KL loss: 0.372987
Average total loss: 0.459847
tensor(-12.6833, device='cuda:0') tensor(1.9543, device='cuda:0') tensor(2.7543e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.084884
Average KL loss: 0.372948
Average total loss: 0.457833
tensor(-12.6847, device='cuda:0') tensor(1.9539, device='cuda:0') tensor(1.2737e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.084418
Average KL loss: 0.372904
Average total loss: 0.457322
tensor(-12.6861, device='cuda:0') tensor(1.9535, device='cuda:0') tensor(2.3164e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.086732
Average KL loss: 0.372879
Average total loss: 0.459611
tensor(-12.6874, device='cuda:0') tensor(1.9532, device='cuda:0') tensor(3.2715e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.085183
Average KL loss: 0.372853
Average total loss: 0.458035
tensor(-12.6888, device='cuda:0') tensor(1.9528, device='cuda:0') tensor(7.6049e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.086900
Average KL loss: 0.372814
Average total loss: 0.459714
tensor(-12.6902, device='cuda:0') tensor(1.9524, device='cuda:0') tensor(1.9832e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.085944
Average KL loss: 0.372762
Average total loss: 0.458705
tensor(-12.6916, device='cuda:0') tensor(1.9520, device='cuda:0') tensor(2.4695e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.084799
Average KL loss: 0.372719
Average total loss: 0.457518
tensor(-12.6929, device='cuda:0') tensor(1.9517, device='cuda:0') tensor(4.4062e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.085088
Average KL loss: 0.372683
Average total loss: 0.457770
tensor(-12.6943, device='cuda:0') tensor(1.9513, device='cuda:0') tensor(2.5205e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.082991
Average KL loss: 0.372637
Average total loss: 0.455628
tensor(-12.6956, device='cuda:0') tensor(1.9509, device='cuda:0') tensor(9.6085e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.086227
Average KL loss: 0.372596
Average total loss: 0.458823
tensor(-12.6970, device='cuda:0') tensor(1.9505, device='cuda:0') tensor(1.3386e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.086047
Average KL loss: 0.372566
Average total loss: 0.458613
tensor(-12.6984, device='cuda:0') tensor(1.9502, device='cuda:0') tensor(7.5373e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.084180
Average KL loss: 0.372522
Average total loss: 0.456702
tensor(-12.6997, device='cuda:0') tensor(1.9498, device='cuda:0') tensor(1.3370e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.082269
Average KL loss: 0.372489
Average total loss: 0.454758
tensor(-12.7011, device='cuda:0') tensor(1.9494, device='cuda:0') tensor(8.7781e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.084140
Average KL loss: 0.372440
Average total loss: 0.456580
tensor(-12.7024, device='cuda:0') tensor(1.9490, device='cuda:0') tensor(5.4432e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.085239
Average KL loss: 0.372404
Average total loss: 0.457643
tensor(-12.7038, device='cuda:0') tensor(1.9486, device='cuda:0') tensor(2.0271e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.083608
Average KL loss: 0.372374
Average total loss: 0.455982
tensor(-12.7051, device='cuda:0') tensor(1.9481, device='cuda:0') tensor(2.2331e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.082837
Average KL loss: 0.372334
Average total loss: 0.455171
tensor(-12.7065, device='cuda:0') tensor(1.9478, device='cuda:0') tensor(1.2025e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.083685
Average KL loss: 0.372310
Average total loss: 0.455994
tensor(-12.7078, device='cuda:0') tensor(1.9474, device='cuda:0') tensor(-1.6384e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.083778
Average KL loss: 0.372258
Average total loss: 0.456036
tensor(-12.7092, device='cuda:0') tensor(1.9470, device='cuda:0') tensor(-1.0196e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.080986
Average KL loss: 0.372218
Average total loss: 0.453205
tensor(-12.7105, device='cuda:0') tensor(1.9467, device='cuda:0') tensor(1.1172e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.081819
Average KL loss: 0.372183
Average total loss: 0.454002
tensor(-12.7118, device='cuda:0') tensor(1.9463, device='cuda:0') tensor(1.2726e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.082967
Average KL loss: 0.372140
Average total loss: 0.455107
tensor(-12.7132, device='cuda:0') tensor(1.9458, device='cuda:0') tensor(5.0955e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.083273
Average KL loss: 0.372101
Average total loss: 0.455374
tensor(-12.7145, device='cuda:0') tensor(1.9455, device='cuda:0') tensor(1.0322e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.082734
Average KL loss: 0.372070
Average total loss: 0.454804
tensor(-12.7158, device='cuda:0') tensor(1.9451, device='cuda:0') tensor(2.5226e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.083423
Average KL loss: 0.372026
Average total loss: 0.455450
tensor(-12.7172, device='cuda:0') tensor(1.9447, device='cuda:0') tensor(1.4759e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.083029
Average KL loss: 0.371988
Average total loss: 0.455017
tensor(-12.7185, device='cuda:0') tensor(1.9444, device='cuda:0') tensor(3.8309e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.082053
Average KL loss: 0.371943
Average total loss: 0.453996
tensor(-12.7198, device='cuda:0') tensor(1.9439, device='cuda:0') tensor(6.2165e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.083333
Average KL loss: 0.371903
Average total loss: 0.455236
tensor(-12.7212, device='cuda:0') tensor(1.9436, device='cuda:0') tensor(2.2534e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.080656
Average KL loss: 0.371865
Average total loss: 0.452522
tensor(-12.7225, device='cuda:0') tensor(1.9432, device='cuda:0') tensor(9.7031e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.080393
Average KL loss: 0.371809
Average total loss: 0.452202
tensor(-12.7238, device='cuda:0') tensor(1.9428, device='cuda:0') tensor(-5.7081e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.082664
Average KL loss: 0.371752
Average total loss: 0.454416
tensor(-12.7251, device='cuda:0') tensor(1.9424, device='cuda:0') tensor(-6.2966e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.079224
Average KL loss: 0.371711
Average total loss: 0.450935
tensor(-12.7264, device='cuda:0') tensor(1.9421, device='cuda:0') tensor(2.1926e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.081048
Average KL loss: 0.371654
Average total loss: 0.452702
 Percentile value: -5.712053298950195
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =    1076 /    1728             ( 62.27%) | total_pruned =     652 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4116 /   36864             ( 11.17%) | total_pruned =   32748 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4344 /   36864             ( 11.78%) | total_pruned =   32520 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3799 /   36864             ( 10.31%) | total_pruned =   33065 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3582 /   36864             (  9.72%) | total_pruned =   33282 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    7308 /   73728             (  9.91%) | total_pruned =   66420 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   10614 /  147456             (  7.20%) | total_pruned =  136842 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2180 /    8192             ( 26.61%) | total_pruned =    6012 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    7583 /  147456             (  5.14%) | total_pruned =  139873 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    7292 /  147456             (  4.95%) | total_pruned =  140164 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   15838 /  294912             (  5.37%) | total_pruned =  279074 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     138 /     256             ( 53.91%) | total_pruned =     118 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   20734 /  589824             (  3.52%) | total_pruned =  569090 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     237 /     256             ( 92.58%) | total_pruned =      19 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4305 /   32768             ( 13.14%) | total_pruned =   28463 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    8899 /  589824             (  1.51%) | total_pruned =  580925 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    9438 /  589824             (  1.60%) | total_pruned =  580386 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   17690 / 1179648             (  1.50%) | total_pruned = 1161958 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     288 /     512             ( 56.25%) | total_pruned =     224 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     165 /     512             ( 32.23%) | total_pruned =     347 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   15274 / 2359296             (  0.65%) | total_pruned = 2344022 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     347 /     512             ( 67.77%) | total_pruned =     165 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     297 /     512             ( 58.01%) | total_pruned =     215 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4289 /  131072             (  3.27%) | total_pruned =  126783 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     268 /     512             ( 52.34%) | total_pruned =     244 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     287 /     512             ( 56.05%) | total_pruned =     225 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    8055 / 2359296             (  0.34%) | total_pruned = 2351241 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     148 /     512             ( 28.91%) | total_pruned =     364 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   10086 / 2359296             (  0.43%) | total_pruned = 2349210 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     372 /     512             ( 72.66%) | total_pruned =     140 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     162 /     512             ( 31.64%) | total_pruned =     350 | shape = torch.Size([512])
linear.weight        | nonzeros =    2884 /    5120             ( 56.33%) | total_pruned =    2236 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 25/100 Loss: 0.000254 Accuracy: 86.63 100.00 % Best test Accuracy: 86.66%
tensor(-12.7278, device='cuda:0') tensor(1.9417, device='cuda:0') tensor(-3.6196e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.206866
Average KL loss: 0.370417
Average total loss: 0.577282
tensor(-12.7328, device='cuda:0') tensor(1.8818, device='cuda:0') tensor(-7.7628e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.197938
Average KL loss: 0.369670
Average total loss: 0.567608
tensor(-12.7364, device='cuda:0') tensor(1.8497, device='cuda:0') tensor(-5.2531e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.192324
Average KL loss: 0.369449
Average total loss: 0.561773
tensor(-12.7394, device='cuda:0') tensor(1.8282, device='cuda:0') tensor(-9.6355e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.183156
Average KL loss: 0.369372
Average total loss: 0.552528
tensor(-12.7421, device='cuda:0') tensor(1.8123, device='cuda:0') tensor(-1.5199e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.180534
Average KL loss: 0.369345
Average total loss: 0.549880
tensor(-12.7445, device='cuda:0') tensor(1.7999, device='cuda:0') tensor(-6.5936e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.180490
Average KL loss: 0.369347
Average total loss: 0.549836
tensor(-12.7468, device='cuda:0') tensor(1.7898, device='cuda:0') tensor(-2.5532e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.173389
Average KL loss: 0.369355
Average total loss: 0.542744
tensor(-12.7490, device='cuda:0') tensor(1.7813, device='cuda:0') tensor(-1.1713e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.172429
Average KL loss: 0.369370
Average total loss: 0.541799
tensor(-12.7511, device='cuda:0') tensor(1.7740, device='cuda:0') tensor(-6.5483e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.169728
Average KL loss: 0.369400
Average total loss: 0.539128
tensor(-12.7531, device='cuda:0') tensor(1.7676, device='cuda:0') tensor(-1.5250e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.163882
Average KL loss: 0.369425
Average total loss: 0.533307
tensor(-12.7550, device='cuda:0') tensor(1.7618, device='cuda:0') tensor(-3.9693e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.164094
Average KL loss: 0.369464
Average total loss: 0.533558
tensor(-12.7569, device='cuda:0') tensor(1.7566, device='cuda:0') tensor(-5.7739e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.158251
Average KL loss: 0.369514
Average total loss: 0.527765
tensor(-12.7588, device='cuda:0') tensor(1.7520, device='cuda:0') tensor(-3.1325e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.161173
Average KL loss: 0.369568
Average total loss: 0.530741
tensor(-12.7606, device='cuda:0') tensor(1.7477, device='cuda:0') tensor(-3.6355e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.157042
Average KL loss: 0.369622
Average total loss: 0.526664
tensor(-12.7624, device='cuda:0') tensor(1.7437, device='cuda:0') tensor(-4.6405e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.157895
Average KL loss: 0.369667
Average total loss: 0.527561
tensor(-12.7641, device='cuda:0') tensor(1.7400, device='cuda:0') tensor(-1.6293e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.151853
Average KL loss: 0.369706
Average total loss: 0.521558
tensor(-12.7659, device='cuda:0') tensor(1.7366, device='cuda:0') tensor(-1.1018e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.153569
Average KL loss: 0.369756
Average total loss: 0.523325
tensor(-12.7676, device='cuda:0') tensor(1.7334, device='cuda:0') tensor(-3.4479e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.148869
Average KL loss: 0.369809
Average total loss: 0.518677
tensor(-12.7693, device='cuda:0') tensor(1.7304, device='cuda:0') tensor(-4.4100e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.144714
Average KL loss: 0.369855
Average total loss: 0.514568
tensor(-12.7709, device='cuda:0') tensor(1.7277, device='cuda:0') tensor(-1.5626e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.144946
Average KL loss: 0.369898
Average total loss: 0.514843
tensor(-12.7726, device='cuda:0') tensor(1.7250, device='cuda:0') tensor(-2.2761e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.141856
Average KL loss: 0.369949
Average total loss: 0.511805
tensor(-12.7742, device='cuda:0') tensor(1.7225, device='cuda:0') tensor(-3.1028e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.144785
Average KL loss: 0.369997
Average total loss: 0.514782
tensor(-12.7758, device='cuda:0') tensor(1.7202, device='cuda:0') tensor(-2.3208e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.141132
Average KL loss: 0.370043
Average total loss: 0.511176
tensor(-12.7774, device='cuda:0') tensor(1.7180, device='cuda:0') tensor(4.8057e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.140601
Average KL loss: 0.370091
Average total loss: 0.510691
tensor(-12.7790, device='cuda:0') tensor(1.7159, device='cuda:0') tensor(5.5256e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.139628
Average KL loss: 0.370131
Average total loss: 0.509759
tensor(-12.7805, device='cuda:0') tensor(1.7138, device='cuda:0') tensor(7.0996e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.137587
Average KL loss: 0.370166
Average total loss: 0.507753
tensor(-12.7821, device='cuda:0') tensor(1.7119, device='cuda:0') tensor(-1.1274e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.139485
Average KL loss: 0.370212
Average total loss: 0.509697
tensor(-12.7836, device='cuda:0') tensor(1.7101, device='cuda:0') tensor(-3.4035e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.136499
Average KL loss: 0.370268
Average total loss: 0.506767
tensor(-12.7852, device='cuda:0') tensor(1.7084, device='cuda:0') tensor(-4.4952e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.137044
Average KL loss: 0.370302
Average total loss: 0.507346
tensor(-12.7867, device='cuda:0') tensor(1.7066, device='cuda:0') tensor(-8.7316e-11, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.136767
Average KL loss: 0.370336
Average total loss: 0.507103
tensor(-12.7882, device='cuda:0') tensor(1.7050, device='cuda:0') tensor(1.0424e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.132534
Average KL loss: 0.370378
Average total loss: 0.502912
tensor(-12.7897, device='cuda:0') tensor(1.7034, device='cuda:0') tensor(-3.9431e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.134135
Average KL loss: 0.370421
Average total loss: 0.504556
tensor(-12.7912, device='cuda:0') tensor(1.7019, device='cuda:0') tensor(-2.1367e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.133818
Average KL loss: 0.370458
Average total loss: 0.504277
tensor(-12.7927, device='cuda:0') tensor(1.7004, device='cuda:0') tensor(2.5841e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.132104
Average KL loss: 0.370484
Average total loss: 0.502588
tensor(-12.7942, device='cuda:0') tensor(1.6990, device='cuda:0') tensor(-1.6106e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.133188
Average KL loss: 0.370513
Average total loss: 0.503701
tensor(-12.7956, device='cuda:0') tensor(1.6977, device='cuda:0') tensor(7.8359e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.128949
Average KL loss: 0.370538
Average total loss: 0.499488
tensor(-12.7971, device='cuda:0') tensor(1.6963, device='cuda:0') tensor(-6.8579e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.128475
Average KL loss: 0.370578
Average total loss: 0.499052
tensor(-12.7985, device='cuda:0') tensor(1.6951, device='cuda:0') tensor(-1.3141e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.129996
Average KL loss: 0.370623
Average total loss: 0.500619
tensor(-12.8000, device='cuda:0') tensor(1.6939, device='cuda:0') tensor(-6.8125e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.127413
Average KL loss: 0.370640
Average total loss: 0.498053
tensor(-12.8014, device='cuda:0') tensor(1.6927, device='cuda:0') tensor(-1.7254e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.125704
Average KL loss: 0.370659
Average total loss: 0.496362
tensor(-12.8029, device='cuda:0') tensor(1.6915, device='cuda:0') tensor(-1.6450e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.126886
Average KL loss: 0.370664
Average total loss: 0.497550
tensor(-12.8043, device='cuda:0') tensor(1.6905, device='cuda:0') tensor(-7.6438e-11, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.123097
Average KL loss: 0.370675
Average total loss: 0.493771
tensor(-12.8057, device='cuda:0') tensor(1.6895, device='cuda:0') tensor(-6.8539e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.125570
Average KL loss: 0.370689
Average total loss: 0.496258
tensor(-12.8071, device='cuda:0') tensor(1.6885, device='cuda:0') tensor(-7.2235e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.124805
Average KL loss: 0.370701
Average total loss: 0.495505
tensor(-12.8085, device='cuda:0') tensor(1.6875, device='cuda:0') tensor(3.9426e-11, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.122601
Average KL loss: 0.370715
Average total loss: 0.493317
tensor(-12.8099, device='cuda:0') tensor(1.6864, device='cuda:0') tensor(-1.7782e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.121515
Average KL loss: 0.370720
Average total loss: 0.492235
tensor(-12.8113, device='cuda:0') tensor(1.6855, device='cuda:0') tensor(-8.4103e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.120766
Average KL loss: 0.370730
Average total loss: 0.491495
tensor(-12.8127, device='cuda:0') tensor(1.6846, device='cuda:0') tensor(6.1750e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.122721
Average KL loss: 0.370743
Average total loss: 0.493463
tensor(-12.8141, device='cuda:0') tensor(1.6837, device='cuda:0') tensor(3.8059e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.119623
Average KL loss: 0.370758
Average total loss: 0.490381
tensor(-12.8155, device='cuda:0') tensor(1.6828, device='cuda:0') tensor(-1.4138e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.118317
Average KL loss: 0.370783
Average total loss: 0.489100
tensor(-12.8169, device='cuda:0') tensor(1.6820, device='cuda:0') tensor(-1.5086e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.119065
Average KL loss: 0.370801
Average total loss: 0.489866
tensor(-12.8182, device='cuda:0') tensor(1.6813, device='cuda:0') tensor(-2.2592e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.119673
Average KL loss: 0.370819
Average total loss: 0.490492
tensor(-12.8196, device='cuda:0') tensor(1.6804, device='cuda:0') tensor(-4.4805e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.119231
Average KL loss: 0.370833
Average total loss: 0.490064
tensor(-12.8210, device='cuda:0') tensor(1.6796, device='cuda:0') tensor(-2.0470e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.119416
Average KL loss: 0.370848
Average total loss: 0.490263
tensor(-12.8223, device='cuda:0') tensor(1.6789, device='cuda:0') tensor(-9.4146e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.116983
Average KL loss: 0.370866
Average total loss: 0.487849
tensor(-12.8237, device='cuda:0') tensor(1.6782, device='cuda:0') tensor(-2.7820e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.115416
Average KL loss: 0.370894
Average total loss: 0.486310
tensor(-12.8250, device='cuda:0') tensor(1.6775, device='cuda:0') tensor(-2.6202e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.117854
Average KL loss: 0.370906
Average total loss: 0.488761
tensor(-12.8264, device='cuda:0') tensor(1.6768, device='cuda:0') tensor(-7.6857e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.117689
Average KL loss: 0.370903
Average total loss: 0.488593
tensor(-12.8277, device='cuda:0') tensor(1.6761, device='cuda:0') tensor(-1.0710e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.115109
Average KL loss: 0.370905
Average total loss: 0.486014
tensor(-12.8290, device='cuda:0') tensor(1.6755, device='cuda:0') tensor(4.2493e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.115013
Average KL loss: 0.370916
Average total loss: 0.485929
tensor(-12.8304, device='cuda:0') tensor(1.6749, device='cuda:0') tensor(-6.2391e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.115057
Average KL loss: 0.370928
Average total loss: 0.485985
tensor(-12.8317, device='cuda:0') tensor(1.6743, device='cuda:0') tensor(1.3869e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.112605
Average KL loss: 0.370931
Average total loss: 0.483536
tensor(-12.8330, device='cuda:0') tensor(1.6737, device='cuda:0') tensor(-1.1745e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.112640
Average KL loss: 0.370931
Average total loss: 0.483571
tensor(-12.8343, device='cuda:0') tensor(1.6730, device='cuda:0') tensor(-1.1187e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.114691
Average KL loss: 0.370934
Average total loss: 0.485625
tensor(-12.8356, device='cuda:0') tensor(1.6724, device='cuda:0') tensor(-4.0450e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.111264
Average KL loss: 0.370942
Average total loss: 0.482206
tensor(-12.8370, device='cuda:0') tensor(1.6718, device='cuda:0') tensor(-1.2620e-11, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.112258
Average KL loss: 0.370937
Average total loss: 0.483195
tensor(-12.8383, device='cuda:0') tensor(1.6712, device='cuda:0') tensor(7.2368e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.110556
Average KL loss: 0.370941
Average total loss: 0.481496
tensor(-12.8396, device='cuda:0') tensor(1.6708, device='cuda:0') tensor(-1.2329e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.109948
Average KL loss: 0.370952
Average total loss: 0.480900
tensor(-12.8409, device='cuda:0') tensor(1.6702, device='cuda:0') tensor(-1.4162e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.109816
Average KL loss: 0.370958
Average total loss: 0.480774
tensor(-12.8422, device='cuda:0') tensor(1.6697, device='cuda:0') tensor(-6.3661e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.109761
Average KL loss: 0.370970
Average total loss: 0.480731
tensor(-12.8435, device='cuda:0') tensor(1.6693, device='cuda:0') tensor(-1.0333e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.108555
Average KL loss: 0.370978
Average total loss: 0.479534
tensor(-12.8448, device='cuda:0') tensor(1.6688, device='cuda:0') tensor(8.7101e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.109712
Average KL loss: 0.370984
Average total loss: 0.480696
tensor(-12.8460, device='cuda:0') tensor(1.6683, device='cuda:0') tensor(9.0170e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.107663
Average KL loss: 0.370996
Average total loss: 0.478658
tensor(-12.8473, device='cuda:0') tensor(1.6679, device='cuda:0') tensor(-2.5430e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.106515
Average KL loss: 0.371024
Average total loss: 0.477539
tensor(-12.8486, device='cuda:0') tensor(1.6675, device='cuda:0') tensor(5.0741e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.107242
Average KL loss: 0.371018
Average total loss: 0.478260
tensor(-12.8499, device='cuda:0') tensor(1.6670, device='cuda:0') tensor(-1.3119e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.105429
Average KL loss: 0.371008
Average total loss: 0.476437
tensor(-12.8512, device='cuda:0') tensor(1.6665, device='cuda:0') tensor(-1.5880e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.105896
Average KL loss: 0.371023
Average total loss: 0.476919
tensor(-12.8524, device='cuda:0') tensor(1.6661, device='cuda:0') tensor(-3.8369e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.107695
Average KL loss: 0.371032
Average total loss: 0.478727
tensor(-12.8537, device='cuda:0') tensor(1.6657, device='cuda:0') tensor(2.1780e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.102392
Average KL loss: 0.371037
Average total loss: 0.473428
tensor(-12.8550, device='cuda:0') tensor(1.6652, device='cuda:0') tensor(8.1392e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.104836
Average KL loss: 0.371036
Average total loss: 0.475872
tensor(-12.8562, device='cuda:0') tensor(1.6648, device='cuda:0') tensor(2.2190e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.106370
Average KL loss: 0.371036
Average total loss: 0.477407
tensor(-12.8575, device='cuda:0') tensor(1.6644, device='cuda:0') tensor(-7.2706e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.106644
Average KL loss: 0.371032
Average total loss: 0.477676
tensor(-12.8588, device='cuda:0') tensor(1.6641, device='cuda:0') tensor(-1.5949e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.105821
Average KL loss: 0.371043
Average total loss: 0.476864
tensor(-12.8600, device='cuda:0') tensor(1.6637, device='cuda:0') tensor(-2.2859e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.103442
Average KL loss: 0.371039
Average total loss: 0.474481
tensor(-12.8613, device='cuda:0') tensor(1.6633, device='cuda:0') tensor(5.6859e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.103902
Average KL loss: 0.371011
Average total loss: 0.474913
tensor(-12.8625, device='cuda:0') tensor(1.6630, device='cuda:0') tensor(-1.9045e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.100478
Average KL loss: 0.371016
Average total loss: 0.471494
tensor(-12.8638, device='cuda:0') tensor(1.6626, device='cuda:0') tensor(-2.5089e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.105172
Average KL loss: 0.371005
Average total loss: 0.476177
tensor(-12.8650, device='cuda:0') tensor(1.6622, device='cuda:0') tensor(-3.0085e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.101882
Average KL loss: 0.370989
Average total loss: 0.472871
tensor(-12.8663, device='cuda:0') tensor(1.6618, device='cuda:0') tensor(-2.2095e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.100907
Average KL loss: 0.370971
Average total loss: 0.471878
tensor(-12.8675, device='cuda:0') tensor(1.6614, device='cuda:0') tensor(-4.6770e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.102499
Average KL loss: 0.370966
Average total loss: 0.473466
tensor(-12.8687, device='cuda:0') tensor(1.6611, device='cuda:0') tensor(-2.1131e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.102124
Average KL loss: 0.370958
Average total loss: 0.473082
tensor(-12.8700, device='cuda:0') tensor(1.6608, device='cuda:0') tensor(-1.2662e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.103127
Average KL loss: 0.370941
Average total loss: 0.474068
tensor(-12.8712, device='cuda:0') tensor(1.6605, device='cuda:0') tensor(-7.3010e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.101371
Average KL loss: 0.370929
Average total loss: 0.472300
tensor(-12.8724, device='cuda:0') tensor(1.6602, device='cuda:0') tensor(1.4012e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.099608
Average KL loss: 0.370922
Average total loss: 0.470531
tensor(-12.8737, device='cuda:0') tensor(1.6599, device='cuda:0') tensor(6.3175e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.096439
Average KL loss: 0.370919
Average total loss: 0.467358
tensor(-12.8749, device='cuda:0') tensor(1.6596, device='cuda:0') tensor(-2.6365e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.097375
Average KL loss: 0.370918
Average total loss: 0.468293
tensor(-12.8761, device='cuda:0') tensor(1.6594, device='cuda:0') tensor(8.8053e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.098124
Average KL loss: 0.370900
Average total loss: 0.469023
tensor(-12.8773, device='cuda:0') tensor(1.6591, device='cuda:0') tensor(-1.2790e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.099800
Average KL loss: 0.370892
Average total loss: 0.470691
tensor(-12.8785, device='cuda:0') tensor(1.6589, device='cuda:0') tensor(9.9785e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.097804
Average KL loss: 0.370889
Average total loss: 0.468693
tensor(-12.8798, device='cuda:0') tensor(1.6586, device='cuda:0') tensor(-1.6782e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.100798
Average KL loss: 0.370876
Average total loss: 0.471674
tensor(-12.8810, device='cuda:0') tensor(1.6583, device='cuda:0') tensor(-1.6148e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.096693
Average KL loss: 0.370881
Average total loss: 0.467575
tensor(-12.8822, device='cuda:0') tensor(1.6581, device='cuda:0') tensor(-1.7885e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.097897
Average KL loss: 0.370864
Average total loss: 0.468760
tensor(-12.8834, device='cuda:0') tensor(1.6578, device='cuda:0') tensor(-7.1299e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.097988
Average KL loss: 0.370830
Average total loss: 0.468818
tensor(-12.8846, device='cuda:0') tensor(1.6575, device='cuda:0') tensor(-6.9826e-11, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.096256
Average KL loss: 0.370827
Average total loss: 0.467082
tensor(-12.8858, device='cuda:0') tensor(1.6573, device='cuda:0') tensor(-1.0888e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.098659
Average KL loss: 0.370819
Average total loss: 0.469478
tensor(-12.8870, device='cuda:0') tensor(1.6570, device='cuda:0') tensor(-2.4303e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.099507
Average KL loss: 0.370809
Average total loss: 0.470317
tensor(-12.8882, device='cuda:0') tensor(1.6567, device='cuda:0') tensor(-6.1898e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.094013
Average KL loss: 0.370784
Average total loss: 0.464797
tensor(-12.8894, device='cuda:0') tensor(1.6565, device='cuda:0') tensor(1.1376e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.097223
Average KL loss: 0.370777
Average total loss: 0.468000
tensor(-12.8906, device='cuda:0') tensor(1.6563, device='cuda:0') tensor(-1.5511e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.098408
Average KL loss: 0.370776
Average total loss: 0.469184
tensor(-12.8918, device='cuda:0') tensor(1.6561, device='cuda:0') tensor(-4.7972e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.096991
Average KL loss: 0.370780
Average total loss: 0.467771
tensor(-12.8930, device='cuda:0') tensor(1.6559, device='cuda:0') tensor(-7.7965e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.095517
Average KL loss: 0.370777
Average total loss: 0.466294
tensor(-12.8942, device='cuda:0') tensor(1.6557, device='cuda:0') tensor(-1.5177e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.094290
Average KL loss: 0.370784
Average total loss: 0.465074
tensor(-12.8954, device='cuda:0') tensor(1.6555, device='cuda:0') tensor(-4.4457e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.094023
Average KL loss: 0.370779
Average total loss: 0.464801
tensor(-12.8965, device='cuda:0') tensor(1.6554, device='cuda:0') tensor(-9.3862e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.093943
Average KL loss: 0.370754
Average total loss: 0.464697
tensor(-12.8977, device='cuda:0') tensor(1.6551, device='cuda:0') tensor(-9.3127e-11, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.094083
Average KL loss: 0.370726
Average total loss: 0.464809
tensor(-12.8989, device='cuda:0') tensor(1.6549, device='cuda:0') tensor(1.2690e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.093616
Average KL loss: 0.370713
Average total loss: 0.464329
tensor(-12.9001, device='cuda:0') tensor(1.6546, device='cuda:0') tensor(4.1639e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.091317
Average KL loss: 0.370719
Average total loss: 0.462036
tensor(-12.9013, device='cuda:0') tensor(1.6545, device='cuda:0') tensor(-9.9373e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.094368
Average KL loss: 0.370714
Average total loss: 0.465082
tensor(-12.9024, device='cuda:0') tensor(1.6543, device='cuda:0') tensor(5.4972e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.093630
Average KL loss: 0.370703
Average total loss: 0.464333
tensor(-12.9036, device='cuda:0') tensor(1.6541, device='cuda:0') tensor(4.4886e-11, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.090834
Average KL loss: 0.370702
Average total loss: 0.461536
tensor(-12.9048, device='cuda:0') tensor(1.6540, device='cuda:0') tensor(-5.5747e-11, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.093263
Average KL loss: 0.370692
Average total loss: 0.463955
tensor(-12.9059, device='cuda:0') tensor(1.6539, device='cuda:0') tensor(-1.4879e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.093245
Average KL loss: 0.370675
Average total loss: 0.463920
tensor(-12.9071, device='cuda:0') tensor(1.6537, device='cuda:0') tensor(-2.7873e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.092571
Average KL loss: 0.370663
Average total loss: 0.463234
tensor(-12.9083, device='cuda:0') tensor(1.6535, device='cuda:0') tensor(-3.7744e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.092320
Average KL loss: 0.370658
Average total loss: 0.462979
tensor(-12.9094, device='cuda:0') tensor(1.6535, device='cuda:0') tensor(-2.0110e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.092812
Average KL loss: 0.370660
Average total loss: 0.463472
tensor(-12.9106, device='cuda:0') tensor(1.6533, device='cuda:0') tensor(-2.7091e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.092311
Average KL loss: 0.370642
Average total loss: 0.462953
tensor(-12.9117, device='cuda:0') tensor(1.6532, device='cuda:0') tensor(4.7026e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.090606
Average KL loss: 0.370620
Average total loss: 0.461227
tensor(-12.9129, device='cuda:0') tensor(1.6530, device='cuda:0') tensor(9.1821e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.091694
Average KL loss: 0.370606
Average total loss: 0.462301
tensor(-12.9141, device='cuda:0') tensor(1.6528, device='cuda:0') tensor(5.5240e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.090862
Average KL loss: 0.370593
Average total loss: 0.461454
tensor(-12.9152, device='cuda:0') tensor(1.6526, device='cuda:0') tensor(1.1502e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.087596
Average KL loss: 0.370577
Average total loss: 0.458172
tensor(-12.9164, device='cuda:0') tensor(1.6524, device='cuda:0') tensor(1.1403e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.088931
Average KL loss: 0.370556
Average total loss: 0.459487
tensor(-12.9175, device='cuda:0') tensor(1.6523, device='cuda:0') tensor(1.1456e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.089280
Average KL loss: 0.370528
Average total loss: 0.459809
tensor(-12.9187, device='cuda:0') tensor(1.6522, device='cuda:0') tensor(1.1276e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.089636
Average KL loss: 0.370500
Average total loss: 0.460136
tensor(-12.9198, device='cuda:0') tensor(1.6520, device='cuda:0') tensor(-1.4392e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.091250
Average KL loss: 0.370490
Average total loss: 0.461740
tensor(-12.9209, device='cuda:0') tensor(1.6520, device='cuda:0') tensor(-8.0772e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.089210
Average KL loss: 0.370485
Average total loss: 0.459695
tensor(-12.9221, device='cuda:0') tensor(1.6518, device='cuda:0') tensor(2.8199e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.090012
Average KL loss: 0.370461
Average total loss: 0.460473
tensor(-12.9232, device='cuda:0') tensor(1.6517, device='cuda:0') tensor(-5.1771e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.088568
Average KL loss: 0.370444
Average total loss: 0.459011
tensor(-12.9244, device='cuda:0') tensor(1.6516, device='cuda:0') tensor(-1.7794e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.089530
Average KL loss: 0.370443
Average total loss: 0.459972
tensor(-12.9255, device='cuda:0') tensor(1.6515, device='cuda:0') tensor(-3.6468e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.089079
Average KL loss: 0.370420
Average total loss: 0.459498
tensor(-12.9266, device='cuda:0') tensor(1.6514, device='cuda:0') tensor(6.8036e-11, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.085954
Average KL loss: 0.370405
Average total loss: 0.456359
tensor(-12.9278, device='cuda:0') tensor(1.6513, device='cuda:0') tensor(2.0351e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.087930
Average KL loss: 0.370388
Average total loss: 0.458318
tensor(-12.9289, device='cuda:0') tensor(1.6512, device='cuda:0') tensor(-1.4127e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.085554
Average KL loss: 0.370361
Average total loss: 0.455915
tensor(-12.9301, device='cuda:0') tensor(1.6510, device='cuda:0') tensor(-9.9307e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.086420
Average KL loss: 0.370336
Average total loss: 0.456757
tensor(-12.9312, device='cuda:0') tensor(1.6509, device='cuda:0') tensor(3.2834e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.085891
Average KL loss: 0.370312
Average total loss: 0.456203
tensor(-12.9323, device='cuda:0') tensor(1.6507, device='cuda:0') tensor(7.4237e-11, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.086131
Average KL loss: 0.370289
Average total loss: 0.456420
tensor(-12.9334, device='cuda:0') tensor(1.6506, device='cuda:0') tensor(-1.4195e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.086649
Average KL loss: 0.370281
Average total loss: 0.456930
tensor(-12.9346, device='cuda:0') tensor(1.6505, device='cuda:0') tensor(-1.8543e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.088148
Average KL loss: 0.370259
Average total loss: 0.458407
tensor(-12.9357, device='cuda:0') tensor(1.6504, device='cuda:0') tensor(9.4553e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.085211
Average KL loss: 0.370244
Average total loss: 0.455455
tensor(-12.9368, device='cuda:0') tensor(1.6503, device='cuda:0') tensor(-2.8986e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.086470
Average KL loss: 0.370233
Average total loss: 0.456704
tensor(-12.9379, device='cuda:0') tensor(1.6502, device='cuda:0') tensor(-6.2779e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.085150
Average KL loss: 0.370224
Average total loss: 0.455374
tensor(-12.9391, device='cuda:0') tensor(1.6501, device='cuda:0') tensor(-1.6287e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.086251
Average KL loss: 0.370204
Average total loss: 0.456455
tensor(-12.9402, device='cuda:0') tensor(1.6499, device='cuda:0') tensor(-3.5724e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.083131
Average KL loss: 0.370174
Average total loss: 0.453305
tensor(-12.9413, device='cuda:0') tensor(1.6499, device='cuda:0') tensor(-1.2131e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.083027
Average KL loss: 0.370156
Average total loss: 0.453183
tensor(-12.9424, device='cuda:0') tensor(1.6497, device='cuda:0') tensor(1.5448e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.085874
Average KL loss: 0.370139
Average total loss: 0.456013
tensor(-12.9435, device='cuda:0') tensor(1.6496, device='cuda:0') tensor(-3.2455e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.084718
Average KL loss: 0.370118
Average total loss: 0.454836
tensor(-12.9446, device='cuda:0') tensor(1.6494, device='cuda:0') tensor(-4.9385e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.082506
Average KL loss: 0.370103
Average total loss: 0.452608
tensor(-12.9458, device='cuda:0') tensor(1.6493, device='cuda:0') tensor(-4.8612e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.084281
Average KL loss: 0.370074
Average total loss: 0.454355
tensor(-12.9469, device='cuda:0') tensor(1.6492, device='cuda:0') tensor(2.8012e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.084938
Average KL loss: 0.370050
Average total loss: 0.454988
tensor(-12.9480, device='cuda:0') tensor(1.6491, device='cuda:0') tensor(-1.3282e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.082512
Average KL loss: 0.370032
Average total loss: 0.452543
tensor(-12.9491, device='cuda:0') tensor(1.6490, device='cuda:0') tensor(-3.1047e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.084019
Average KL loss: 0.370007
Average total loss: 0.454026
tensor(-12.9502, device='cuda:0') tensor(1.6489, device='cuda:0') tensor(4.7530e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.082403
Average KL loss: 0.369977
Average total loss: 0.452379
tensor(-12.9513, device='cuda:0') tensor(1.6488, device='cuda:0') tensor(2.1781e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.083407
Average KL loss: 0.369952
Average total loss: 0.453359
tensor(-12.9524, device='cuda:0') tensor(1.6487, device='cuda:0') tensor(1.0735e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.083743
Average KL loss: 0.369928
Average total loss: 0.453671
tensor(-12.9535, device='cuda:0') tensor(1.6485, device='cuda:0') tensor(-1.3684e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.081192
Average KL loss: 0.369896
Average total loss: 0.451088
tensor(-12.9546, device='cuda:0') tensor(1.6484, device='cuda:0') tensor(-5.8193e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.083301
Average KL loss: 0.369877
Average total loss: 0.453178
tensor(-12.9557, device='cuda:0') tensor(1.6483, device='cuda:0') tensor(-1.0205e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.081649
Average KL loss: 0.369848
Average total loss: 0.451497
tensor(-12.9568, device='cuda:0') tensor(1.6482, device='cuda:0') tensor(3.2558e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.083159
Average KL loss: 0.369824
Average total loss: 0.452983
tensor(-12.9579, device='cuda:0') tensor(1.6481, device='cuda:0') tensor(8.5718e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.081644
Average KL loss: 0.369795
Average total loss: 0.451439
tensor(-12.9590, device='cuda:0') tensor(1.6480, device='cuda:0') tensor(7.1622e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.081271
Average KL loss: 0.369782
Average total loss: 0.451053
tensor(-12.9600, device='cuda:0') tensor(1.6479, device='cuda:0') tensor(-8.2526e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.081702
Average KL loss: 0.369757
Average total loss: 0.451459
tensor(-12.9611, device='cuda:0') tensor(1.6478, device='cuda:0') tensor(1.3281e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.081542
Average KL loss: 0.369736
Average total loss: 0.451278
tensor(-12.9622, device='cuda:0') tensor(1.6478, device='cuda:0') tensor(-8.1433e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.081889
Average KL loss: 0.369723
Average total loss: 0.451613
tensor(-12.9633, device='cuda:0') tensor(1.6478, device='cuda:0') tensor(-7.6609e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.080272
Average KL loss: 0.369693
Average total loss: 0.449965
tensor(-12.9644, device='cuda:0') tensor(1.6476, device='cuda:0') tensor(1.9329e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.079205
Average KL loss: 0.369669
Average total loss: 0.448874
tensor(-12.9654, device='cuda:0') tensor(1.6476, device='cuda:0') tensor(-7.4624e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.079863
Average KL loss: 0.369645
Average total loss: 0.449508
tensor(-12.9665, device='cuda:0') tensor(1.6475, device='cuda:0') tensor(-1.1580e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.080427
Average KL loss: 0.369623
Average total loss: 0.450050
tensor(-12.9676, device='cuda:0') tensor(1.6474, device='cuda:0') tensor(-2.0825e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.081104
Average KL loss: 0.369588
Average total loss: 0.450692
tensor(-12.9687, device='cuda:0') tensor(1.6474, device='cuda:0') tensor(-6.2058e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.078815
Average KL loss: 0.369553
Average total loss: 0.448368
tensor(-12.9698, device='cuda:0') tensor(1.6473, device='cuda:0') tensor(6.8095e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.077512
Average KL loss: 0.369522
Average total loss: 0.447034
tensor(-12.9708, device='cuda:0') tensor(1.6471, device='cuda:0') tensor(-1.8110e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.079865
Average KL loss: 0.369497
Average total loss: 0.449363
tensor(-12.9719, device='cuda:0') tensor(1.6471, device='cuda:0') tensor(-5.8989e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.080371
Average KL loss: 0.369475
Average total loss: 0.449846
tensor(-12.9730, device='cuda:0') tensor(1.6470, device='cuda:0') tensor(8.2397e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.078409
Average KL loss: 0.369463
Average total loss: 0.447872
tensor(-12.9740, device='cuda:0') tensor(1.6469, device='cuda:0') tensor(-1.5846e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.077500
Average KL loss: 0.369451
Average total loss: 0.446951
tensor(-12.9751, device='cuda:0') tensor(1.6469, device='cuda:0') tensor(-1.6225e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.080017
Average KL loss: 0.369451
Average total loss: 0.449468
tensor(-12.9762, device='cuda:0') tensor(1.6468, device='cuda:0') tensor(-9.2933e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.081113
Average KL loss: 0.369446
Average total loss: 0.450559
tensor(-12.9772, device='cuda:0') tensor(1.6468, device='cuda:0') tensor(-2.9938e-11, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.079548
Average KL loss: 0.369442
Average total loss: 0.448990
tensor(-12.9783, device='cuda:0') tensor(1.6468, device='cuda:0') tensor(7.2300e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.078193
Average KL loss: 0.369420
Average total loss: 0.447613
tensor(-12.9794, device='cuda:0') tensor(1.6467, device='cuda:0') tensor(-8.5167e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.077446
Average KL loss: 0.369385
Average total loss: 0.446832
tensor(-12.9804, device='cuda:0') tensor(1.6466, device='cuda:0') tensor(2.2101e-12, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.078382
Average KL loss: 0.369356
Average total loss: 0.447737
tensor(-12.9815, device='cuda:0') tensor(1.6466, device='cuda:0') tensor(1.6897e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.079178
Average KL loss: 0.369328
Average total loss: 0.448506
tensor(-12.9825, device='cuda:0') tensor(1.6465, device='cuda:0') tensor(1.8571e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.078099
Average KL loss: 0.369299
Average total loss: 0.447398
tensor(-12.9836, device='cuda:0') tensor(1.6465, device='cuda:0') tensor(-7.2501e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.075231
Average KL loss: 0.369273
Average total loss: 0.444504
tensor(-12.9847, device='cuda:0') tensor(1.6464, device='cuda:0') tensor(-1.4175e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.078022
Average KL loss: 0.369254
Average total loss: 0.447276
tensor(-12.9857, device='cuda:0') tensor(1.6464, device='cuda:0') tensor(-1.5775e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.079093
Average KL loss: 0.369243
Average total loss: 0.448336
tensor(-12.9868, device='cuda:0') tensor(1.6463, device='cuda:0') tensor(-2.5555e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.077402
Average KL loss: 0.369223
Average total loss: 0.446626
tensor(-12.9878, device='cuda:0') tensor(1.6462, device='cuda:0') tensor(1.5619e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.075102
Average KL loss: 0.369193
Average total loss: 0.444296
tensor(-12.9889, device='cuda:0') tensor(1.6461, device='cuda:0') tensor(1.0978e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.075968
Average KL loss: 0.369168
Average total loss: 0.445136
tensor(-12.9900, device='cuda:0') tensor(1.6460, device='cuda:0') tensor(9.6228e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.075366
Average KL loss: 0.369141
Average total loss: 0.444507
tensor(-12.9910, device='cuda:0') tensor(1.6459, device='cuda:0') tensor(-2.0808e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.077016
Average KL loss: 0.369103
Average total loss: 0.446120
tensor(-12.9921, device='cuda:0') tensor(1.6459, device='cuda:0') tensor(1.0865e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.075563
Average KL loss: 0.369058
Average total loss: 0.444621
 Percentile value: -3.5734286308288574
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =     950 /    1728             ( 54.98%) | total_pruned =     778 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2212 /   36864             (  6.00%) | total_pruned =   34652 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2425 /   36864             (  6.58%) | total_pruned =   34439 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2111 /   36864             (  5.73%) | total_pruned =   34753 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2058 /   36864             (  5.58%) | total_pruned =   34806 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3804 /   73728             (  5.16%) | total_pruned =   69924 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5348 /  147456             (  3.63%) | total_pruned =  142108 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1523 /    8192             ( 18.59%) | total_pruned =    6669 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3752 /  147456             (  2.54%) | total_pruned =  143704 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3496 /  147456             (  2.37%) | total_pruned =  143960 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7850 /  294912             (  2.66%) | total_pruned =  287062 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     106 /     256             ( 41.41%) | total_pruned =     150 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    9826 /  589824             (  1.67%) | total_pruned =  579998 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      85 /     256             ( 33.20%) | total_pruned =     171 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2593 /   32768             (  7.91%) | total_pruned =   30175 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3964 /  589824             (  0.67%) | total_pruned =  585860 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      50 /     256             ( 19.53%) | total_pruned =     206 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4201 /  589824             (  0.71%) | total_pruned =  585623 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      54 /     256             ( 21.09%) | total_pruned =     202 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    8158 / 1179648             (  0.69%) | total_pruned = 1171490 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     278 /     512             ( 54.30%) | total_pruned =     234 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     118 /     512             ( 23.05%) | total_pruned =     394 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    6466 / 2359296             (  0.27%) | total_pruned = 2352830 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     338 /     512             ( 66.02%) | total_pruned =     174 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     203 /     512             ( 39.65%) | total_pruned =     309 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2127 /  131072             (  1.62%) | total_pruned =  128945 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     256 /     512             ( 50.00%) | total_pruned =     256 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     176 /     512             ( 34.38%) | total_pruned =     336 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3369 / 2359296             (  0.14%) | total_pruned = 2355927 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     130 /     512             ( 25.39%) | total_pruned =     382 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    4431 / 2359296             (  0.19%) | total_pruned = 2354865 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     366 /     512             ( 71.48%) | total_pruned =     146 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
linear.weight        | nonzeros =    2141 /    5120             ( 41.82%) | total_pruned =    2979 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 26/100 Loss: 0.000844 Accuracy: 85.92 99.98 % Best test Accuracy: 86.33%
tensor(-12.9931, device='cuda:0') tensor(1.6458, device='cuda:0') tensor(-2.7838e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.308002
Average KL loss: 0.368268
Average total loss: 0.676271
tensor(-12.9964, device='cuda:0') tensor(1.6027, device='cuda:0') tensor(-1.3830e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.291287
Average KL loss: 0.367814
Average total loss: 0.659101
tensor(-12.9988, device='cuda:0') tensor(1.5797, device='cuda:0') tensor(-2.8703e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.278994
Average KL loss: 0.367690
Average total loss: 0.646684
tensor(-13.0008, device='cuda:0') tensor(1.5643, device='cuda:0') tensor(-4.2678e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.264819
Average KL loss: 0.367651
Average total loss: 0.632471
tensor(-13.0026, device='cuda:0') tensor(1.5532, device='cuda:0') tensor(-8.0548e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.253892
Average KL loss: 0.367645
Average total loss: 0.621537
tensor(-13.0044, device='cuda:0') tensor(1.5446, device='cuda:0') tensor(-6.3834e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.242422
Average KL loss: 0.367647
Average total loss: 0.610069
tensor(-13.0060, device='cuda:0') tensor(1.5378, device='cuda:0') tensor(1.9017e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.244074
Average KL loss: 0.367634
Average total loss: 0.611708
tensor(-13.0075, device='cuda:0') tensor(1.5322, device='cuda:0') tensor(-4.0288e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.233113
Average KL loss: 0.367648
Average total loss: 0.600762
tensor(-13.0090, device='cuda:0') tensor(1.5275, device='cuda:0') tensor(-3.7647e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.228075
Average KL loss: 0.367680
Average total loss: 0.595755
tensor(-13.0105, device='cuda:0') tensor(1.5233, device='cuda:0') tensor(-4.1195e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.220778
Average KL loss: 0.367723
Average total loss: 0.588501
tensor(-13.0119, device='cuda:0') tensor(1.5197, device='cuda:0') tensor(-1.3075e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.215842
Average KL loss: 0.367770
Average total loss: 0.583612
tensor(-13.0133, device='cuda:0') tensor(1.5164, device='cuda:0') tensor(-2.1309e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.219157
Average KL loss: 0.367820
Average total loss: 0.586977
tensor(-13.0147, device='cuda:0') tensor(1.5135, device='cuda:0') tensor(-3.8627e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.213908
Average KL loss: 0.367868
Average total loss: 0.581776
tensor(-13.0160, device='cuda:0') tensor(1.5108, device='cuda:0') tensor(-3.3346e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.210619
Average KL loss: 0.367916
Average total loss: 0.578535
tensor(-13.0173, device='cuda:0') tensor(1.5084, device='cuda:0') tensor(-9.1282e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.205200
Average KL loss: 0.367971
Average total loss: 0.573171
tensor(-13.0187, device='cuda:0') tensor(1.5062, device='cuda:0') tensor(-1.9547e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.201011
Average KL loss: 0.368035
Average total loss: 0.569046
tensor(-13.0199, device='cuda:0') tensor(1.5041, device='cuda:0') tensor(-4.8871e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.195375
Average KL loss: 0.368090
Average total loss: 0.563466
tensor(-13.0212, device='cuda:0') tensor(1.5023, device='cuda:0') tensor(-2.1497e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.192406
Average KL loss: 0.368141
Average total loss: 0.560547
tensor(-13.0225, device='cuda:0') tensor(1.5005, device='cuda:0') tensor(-7.1610e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.195440
Average KL loss: 0.368187
Average total loss: 0.563627
tensor(-13.0237, device='cuda:0') tensor(1.4988, device='cuda:0') tensor(-1.5904e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.192142
Average KL loss: 0.368230
Average total loss: 0.560372
tensor(-13.0250, device='cuda:0') tensor(1.4973, device='cuda:0') tensor(-2.8572e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.188870
Average KL loss: 0.368281
Average total loss: 0.557151
tensor(-13.0262, device='cuda:0') tensor(1.4958, device='cuda:0') tensor(-2.3564e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.188312
Average KL loss: 0.368327
Average total loss: 0.556639
tensor(-13.0274, device='cuda:0') tensor(1.4944, device='cuda:0') tensor(-1.6082e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.180004
Average KL loss: 0.368359
Average total loss: 0.548363
tensor(-13.0287, device='cuda:0') tensor(1.4931, device='cuda:0') tensor(-1.9699e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.182143
Average KL loss: 0.368416
Average total loss: 0.550559
tensor(-13.0299, device='cuda:0') tensor(1.4919, device='cuda:0') tensor(-1.3745e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.178955
Average KL loss: 0.368464
Average total loss: 0.547418
tensor(-13.0311, device='cuda:0') tensor(1.4907, device='cuda:0') tensor(-3.5539e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.171766
Average KL loss: 0.368505
Average total loss: 0.540271
tensor(-13.0323, device='cuda:0') tensor(1.4895, device='cuda:0') tensor(-3.7635e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.179102
Average KL loss: 0.368533
Average total loss: 0.547634
tensor(-13.0334, device='cuda:0') tensor(1.4884, device='cuda:0') tensor(-2.4170e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.178090
Average KL loss: 0.368557
Average total loss: 0.546647
tensor(-13.0346, device='cuda:0') tensor(1.4874, device='cuda:0') tensor(-1.3214e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.170311
Average KL loss: 0.368581
Average total loss: 0.538892
tensor(-13.0358, device='cuda:0') tensor(1.4864, device='cuda:0') tensor(-2.9843e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.169005
Average KL loss: 0.368605
Average total loss: 0.537610
tensor(-13.0370, device='cuda:0') tensor(1.4855, device='cuda:0') tensor(-6.9650e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.170545
Average KL loss: 0.368645
Average total loss: 0.539191
tensor(-13.0381, device='cuda:0') tensor(1.4847, device='cuda:0') tensor(-5.7447e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.167869
Average KL loss: 0.368693
Average total loss: 0.536563
tensor(-13.0393, device='cuda:0') tensor(1.4839, device='cuda:0') tensor(-3.6564e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.166658
Average KL loss: 0.368738
Average total loss: 0.535396
tensor(-13.0404, device='cuda:0') tensor(1.4832, device='cuda:0') tensor(-2.2545e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.162196
Average KL loss: 0.368778
Average total loss: 0.530973
tensor(-13.0415, device='cuda:0') tensor(1.4824, device='cuda:0') tensor(-2.9767e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.163098
Average KL loss: 0.368828
Average total loss: 0.531926
tensor(-13.0427, device='cuda:0') tensor(1.4817, device='cuda:0') tensor(-2.3367e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.164284
Average KL loss: 0.368860
Average total loss: 0.533144
tensor(-13.0438, device='cuda:0') tensor(1.4810, device='cuda:0') tensor(-3.7135e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.163144
Average KL loss: 0.368893
Average total loss: 0.532037
tensor(-13.0449, device='cuda:0') tensor(1.4803, device='cuda:0') tensor(-1.9280e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.158333
Average KL loss: 0.368923
Average total loss: 0.527256
tensor(-13.0461, device='cuda:0') tensor(1.4798, device='cuda:0') tensor(-9.7528e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.152813
Average KL loss: 0.368966
Average total loss: 0.521778
tensor(-13.0472, device='cuda:0') tensor(1.4792, device='cuda:0') tensor(-2.1600e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.158078
Average KL loss: 0.368999
Average total loss: 0.527077
tensor(-13.0483, device='cuda:0') tensor(1.4786, device='cuda:0') tensor(-1.5589e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.154867
Average KL loss: 0.369034
Average total loss: 0.523902
tensor(-13.0494, device='cuda:0') tensor(1.4780, device='cuda:0') tensor(-2.3603e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.156349
Average KL loss: 0.369075
Average total loss: 0.525424
tensor(-13.0505, device='cuda:0') tensor(1.4775, device='cuda:0') tensor(-2.2874e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.151829
Average KL loss: 0.369102
Average total loss: 0.520931
tensor(-13.0516, device='cuda:0') tensor(1.4770, device='cuda:0') tensor(-1.9075e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.149727
Average KL loss: 0.369128
Average total loss: 0.518855
tensor(-13.0527, device='cuda:0') tensor(1.4765, device='cuda:0') tensor(-9.4445e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.148939
Average KL loss: 0.369147
Average total loss: 0.518086
tensor(-13.0538, device='cuda:0') tensor(1.4761, device='cuda:0') tensor(-3.3261e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.150300
Average KL loss: 0.369176
Average total loss: 0.519477
tensor(-13.0549, device='cuda:0') tensor(1.4755, device='cuda:0') tensor(-3.0668e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.149761
Average KL loss: 0.369205
Average total loss: 0.518966
tensor(-13.0559, device='cuda:0') tensor(1.4751, device='cuda:0') tensor(7.1301e-12, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.146011
Average KL loss: 0.369230
Average total loss: 0.515242
tensor(-13.0570, device='cuda:0') tensor(1.4746, device='cuda:0') tensor(-2.6908e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.146241
Average KL loss: 0.369253
Average total loss: 0.515494
tensor(-13.0581, device='cuda:0') tensor(1.4742, device='cuda:0') tensor(-4.7506e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.147057
Average KL loss: 0.369274
Average total loss: 0.516331
tensor(-13.0592, device='cuda:0') tensor(1.4738, device='cuda:0') tensor(-3.4240e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.144761
Average KL loss: 0.369295
Average total loss: 0.514056
tensor(-13.0603, device='cuda:0') tensor(1.4734, device='cuda:0') tensor(-3.8260e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.144111
Average KL loss: 0.369322
Average total loss: 0.513434
tensor(-13.0613, device='cuda:0') tensor(1.4730, device='cuda:0') tensor(-6.2755e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.142772
Average KL loss: 0.369352
Average total loss: 0.512124
tensor(-13.0624, device='cuda:0') tensor(1.4727, device='cuda:0') tensor(-3.7691e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.141907
Average KL loss: 0.369379
Average total loss: 0.511286
tensor(-13.0635, device='cuda:0') tensor(1.4724, device='cuda:0') tensor(-1.7309e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.143283
Average KL loss: 0.369421
Average total loss: 0.512704
tensor(-13.0645, device='cuda:0') tensor(1.4721, device='cuda:0') tensor(-3.0566e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.138868
Average KL loss: 0.369457
Average total loss: 0.508325
tensor(-13.0656, device='cuda:0') tensor(1.4718, device='cuda:0') tensor(-7.7307e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.141147
Average KL loss: 0.369487
Average total loss: 0.510634
tensor(-13.0666, device='cuda:0') tensor(1.4716, device='cuda:0') tensor(-2.7945e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.139955
Average KL loss: 0.369528
Average total loss: 0.509483
tensor(-13.0677, device='cuda:0') tensor(1.4713, device='cuda:0') tensor(-2.6948e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.137097
Average KL loss: 0.369567
Average total loss: 0.506664
tensor(-13.0687, device='cuda:0') tensor(1.4711, device='cuda:0') tensor(1.1553e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.137075
Average KL loss: 0.369585
Average total loss: 0.506660
tensor(-13.0698, device='cuda:0') tensor(1.4708, device='cuda:0') tensor(-1.0130e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.137286
Average KL loss: 0.369598
Average total loss: 0.506885
tensor(-13.0709, device='cuda:0') tensor(1.4705, device='cuda:0') tensor(-4.0185e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.132144
Average KL loss: 0.369618
Average total loss: 0.501761
tensor(-13.0719, device='cuda:0') tensor(1.4702, device='cuda:0') tensor(-6.4613e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.132323
Average KL loss: 0.369627
Average total loss: 0.501950
tensor(-13.0729, device='cuda:0') tensor(1.4699, device='cuda:0') tensor(-5.3209e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.135211
Average KL loss: 0.369654
Average total loss: 0.504865
tensor(-13.0740, device='cuda:0') tensor(1.4697, device='cuda:0') tensor(-3.8395e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.130112
Average KL loss: 0.369682
Average total loss: 0.499794
tensor(-13.0750, device='cuda:0') tensor(1.4695, device='cuda:0') tensor(-6.7844e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.132678
Average KL loss: 0.369701
Average total loss: 0.502378
tensor(-13.0761, device='cuda:0') tensor(1.4693, device='cuda:0') tensor(8.9648e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.132469
Average KL loss: 0.369722
Average total loss: 0.502191
tensor(-13.0771, device='cuda:0') tensor(1.4691, device='cuda:0') tensor(-2.9787e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.132325
Average KL loss: 0.369733
Average total loss: 0.502058
tensor(-13.0781, device='cuda:0') tensor(1.4689, device='cuda:0') tensor(-7.1462e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.130030
Average KL loss: 0.369760
Average total loss: 0.499790
tensor(-13.0792, device='cuda:0') tensor(1.4688, device='cuda:0') tensor(6.9529e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.129376
Average KL loss: 0.369784
Average total loss: 0.499160
tensor(-13.0802, device='cuda:0') tensor(1.4686, device='cuda:0') tensor(-6.0865e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.130885
Average KL loss: 0.369796
Average total loss: 0.500681
tensor(-13.0812, device='cuda:0') tensor(1.4684, device='cuda:0') tensor(-5.6531e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.128249
Average KL loss: 0.369805
Average total loss: 0.498053
tensor(-13.0823, device='cuda:0') tensor(1.4682, device='cuda:0') tensor(-2.6554e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.126410
Average KL loss: 0.369830
Average total loss: 0.496240
tensor(-13.0833, device='cuda:0') tensor(1.4680, device='cuda:0') tensor(-3.0437e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.125444
Average KL loss: 0.369841
Average total loss: 0.495285
tensor(-13.0843, device='cuda:0') tensor(1.4679, device='cuda:0') tensor(1.0047e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.128741
Average KL loss: 0.369857
Average total loss: 0.498598
tensor(-13.0853, device='cuda:0') tensor(1.4679, device='cuda:0') tensor(-5.5267e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.124682
Average KL loss: 0.369881
Average total loss: 0.494563
tensor(-13.0864, device='cuda:0') tensor(1.4678, device='cuda:0') tensor(2.7483e-11, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.125402
Average KL loss: 0.369901
Average total loss: 0.495304
tensor(-13.0874, device='cuda:0') tensor(1.4677, device='cuda:0') tensor(-5.2297e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.124069
Average KL loss: 0.369915
Average total loss: 0.493983
tensor(-13.0884, device='cuda:0') tensor(1.4675, device='cuda:0') tensor(1.7140e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.121069
Average KL loss: 0.369926
Average total loss: 0.490995
tensor(-13.0894, device='cuda:0') tensor(1.4674, device='cuda:0') tensor(-5.0302e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.121925
Average KL loss: 0.369936
Average total loss: 0.491861
tensor(-13.0904, device='cuda:0') tensor(1.4673, device='cuda:0') tensor(-2.4608e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.123782
Average KL loss: 0.369956
Average total loss: 0.493737
tensor(-13.0914, device='cuda:0') tensor(1.4671, device='cuda:0') tensor(1.0559e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.122342
Average KL loss: 0.369971
Average total loss: 0.492312
tensor(-13.0924, device='cuda:0') tensor(1.4671, device='cuda:0') tensor(-1.6909e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.121009
Average KL loss: 0.369988
Average total loss: 0.490997
tensor(-13.0934, device='cuda:0') tensor(1.4670, device='cuda:0') tensor(-5.0631e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.121044
Average KL loss: 0.370000
Average total loss: 0.491044
tensor(-13.0944, device='cuda:0') tensor(1.4669, device='cuda:0') tensor(-2.0148e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.118985
Average KL loss: 0.370010
Average total loss: 0.488995
tensor(-13.0954, device='cuda:0') tensor(1.4667, device='cuda:0') tensor(-1.5768e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.120481
Average KL loss: 0.370009
Average total loss: 0.490490
tensor(-13.0964, device='cuda:0') tensor(1.4666, device='cuda:0') tensor(-4.2587e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.117945
Average KL loss: 0.370000
Average total loss: 0.487945
tensor(-13.0974, device='cuda:0') tensor(1.4665, device='cuda:0') tensor(-9.1757e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.118275
Average KL loss: 0.369998
Average total loss: 0.488273
tensor(-13.0984, device='cuda:0') tensor(1.4665, device='cuda:0') tensor(-1.3892e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.116147
Average KL loss: 0.370008
Average total loss: 0.486156
tensor(-13.0994, device='cuda:0') tensor(1.4664, device='cuda:0') tensor(-2.4517e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.119678
Average KL loss: 0.370019
Average total loss: 0.489697
tensor(-13.1004, device='cuda:0') tensor(1.4663, device='cuda:0') tensor(6.6368e-11, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.117077
Average KL loss: 0.370024
Average total loss: 0.487100
tensor(-13.1014, device='cuda:0') tensor(1.4663, device='cuda:0') tensor(-1.9492e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.116684
Average KL loss: 0.370042
Average total loss: 0.486727
tensor(-13.1024, device='cuda:0') tensor(1.4663, device='cuda:0') tensor(-2.2006e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.118010
Average KL loss: 0.370058
Average total loss: 0.488068
tensor(-13.1034, device='cuda:0') tensor(1.4662, device='cuda:0') tensor(-3.0846e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.115934
Average KL loss: 0.370063
Average total loss: 0.485997
tensor(-13.1044, device='cuda:0') tensor(1.4662, device='cuda:0') tensor(-1.6043e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.114961
Average KL loss: 0.370076
Average total loss: 0.485038
tensor(-13.1054, device='cuda:0') tensor(1.4662, device='cuda:0') tensor(-2.0448e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.116273
Average KL loss: 0.370091
Average total loss: 0.486364
tensor(-13.1064, device='cuda:0') tensor(1.4662, device='cuda:0') tensor(-4.1758e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.115256
Average KL loss: 0.370106
Average total loss: 0.485361
tensor(-13.1073, device='cuda:0') tensor(1.4662, device='cuda:0') tensor(-2.0583e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.111725
Average KL loss: 0.370113
Average total loss: 0.481838
tensor(-13.1083, device='cuda:0') tensor(1.4661, device='cuda:0') tensor(-5.9355e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.110055
Average KL loss: 0.370109
Average total loss: 0.480164
tensor(-13.1093, device='cuda:0') tensor(1.4660, device='cuda:0') tensor(5.8786e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.111666
Average KL loss: 0.370104
Average total loss: 0.481770
tensor(-13.1103, device='cuda:0') tensor(1.4660, device='cuda:0') tensor(-2.5997e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.114049
Average KL loss: 0.370108
Average total loss: 0.484158
tensor(-13.1113, device='cuda:0') tensor(1.4660, device='cuda:0') tensor(-2.5366e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.111453
Average KL loss: 0.370117
Average total loss: 0.481570
tensor(-13.1122, device='cuda:0') tensor(1.4660, device='cuda:0') tensor(-1.7303e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.109263
Average KL loss: 0.370123
Average total loss: 0.479387
tensor(-13.1132, device='cuda:0') tensor(1.4661, device='cuda:0') tensor(-8.5200e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.108696
Average KL loss: 0.370139
Average total loss: 0.478836
tensor(-13.1142, device='cuda:0') tensor(1.4660, device='cuda:0') tensor(-2.5612e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.110210
Average KL loss: 0.370143
Average total loss: 0.480352
tensor(-13.1151, device='cuda:0') tensor(1.4661, device='cuda:0') tensor(-1.1342e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.112048
Average KL loss: 0.370148
Average total loss: 0.482196
tensor(-13.1161, device='cuda:0') tensor(1.4661, device='cuda:0') tensor(-8.7768e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.110419
Average KL loss: 0.370162
Average total loss: 0.480581
tensor(-13.1171, device='cuda:0') tensor(1.4661, device='cuda:0') tensor(-2.6857e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.111173
Average KL loss: 0.370170
Average total loss: 0.481343
tensor(-13.1180, device='cuda:0') tensor(1.4661, device='cuda:0') tensor(-1.8648e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.107835
Average KL loss: 0.370181
Average total loss: 0.478016
tensor(-13.1190, device='cuda:0') tensor(1.4662, device='cuda:0') tensor(-3.4302e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.107218
Average KL loss: 0.370176
Average total loss: 0.477394
tensor(-13.1199, device='cuda:0') tensor(1.4662, device='cuda:0') tensor(-8.5234e-11, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.109236
Average KL loss: 0.370181
Average total loss: 0.479416
tensor(-13.1209, device='cuda:0') tensor(1.4662, device='cuda:0') tensor(-4.6949e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.109409
Average KL loss: 0.370185
Average total loss: 0.479594
tensor(-13.1219, device='cuda:0') tensor(1.4662, device='cuda:0') tensor(1.8618e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.109213
Average KL loss: 0.370183
Average total loss: 0.479397
tensor(-13.1228, device='cuda:0') tensor(1.4662, device='cuda:0') tensor(-4.5940e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.105943
Average KL loss: 0.370189
Average total loss: 0.476132
tensor(-13.1238, device='cuda:0') tensor(1.4663, device='cuda:0') tensor(-9.5052e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.104254
Average KL loss: 0.370188
Average total loss: 0.474442
tensor(-13.1247, device='cuda:0') tensor(1.4663, device='cuda:0') tensor(-1.1258e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.104304
Average KL loss: 0.370181
Average total loss: 0.474486
tensor(-13.1256, device='cuda:0') tensor(1.4663, device='cuda:0') tensor(-1.1049e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.104549
Average KL loss: 0.370186
Average total loss: 0.474735
tensor(-13.1266, device='cuda:0') tensor(1.4663, device='cuda:0') tensor(1.7997e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.106183
Average KL loss: 0.370198
Average total loss: 0.476381
tensor(-13.1275, device='cuda:0') tensor(1.4663, device='cuda:0') tensor(2.8561e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.104744
Average KL loss: 0.370207
Average total loss: 0.474951
tensor(-13.1285, device='cuda:0') tensor(1.4664, device='cuda:0') tensor(-1.2384e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.103341
Average KL loss: 0.370222
Average total loss: 0.473563
tensor(-13.1294, device='cuda:0') tensor(1.4664, device='cuda:0') tensor(-1.1227e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.102572
Average KL loss: 0.370228
Average total loss: 0.472800
tensor(-13.1304, device='cuda:0') tensor(1.4665, device='cuda:0') tensor(-1.0722e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.103913
Average KL loss: 0.370223
Average total loss: 0.474136
tensor(-13.1313, device='cuda:0') tensor(1.4666, device='cuda:0') tensor(-1.7221e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.103760
Average KL loss: 0.370240
Average total loss: 0.474000
tensor(-13.1322, device='cuda:0') tensor(1.4666, device='cuda:0') tensor(-1.9856e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.101650
Average KL loss: 0.370236
Average total loss: 0.471886
tensor(-13.1332, device='cuda:0') tensor(1.4666, device='cuda:0') tensor(2.0978e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.105129
Average KL loss: 0.370226
Average total loss: 0.475355
tensor(-13.1341, device='cuda:0') tensor(1.4667, device='cuda:0') tensor(-1.0846e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.099281
Average KL loss: 0.370225
Average total loss: 0.469506
tensor(-13.1351, device='cuda:0') tensor(1.4667, device='cuda:0') tensor(-4.1196e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.098996
Average KL loss: 0.370209
Average total loss: 0.469205
tensor(-13.1360, device='cuda:0') tensor(1.4667, device='cuda:0') tensor(5.0038e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.102163
Average KL loss: 0.370193
Average total loss: 0.472356
tensor(-13.1369, device='cuda:0') tensor(1.4667, device='cuda:0') tensor(6.9112e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.098206
Average KL loss: 0.370187
Average total loss: 0.468393
tensor(-13.1379, device='cuda:0') tensor(1.4667, device='cuda:0') tensor(-2.7353e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.102674
Average KL loss: 0.370186
Average total loss: 0.472860
tensor(-13.1388, device='cuda:0') tensor(1.4668, device='cuda:0') tensor(-4.3243e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.099800
Average KL loss: 0.370179
Average total loss: 0.469979
tensor(-13.1397, device='cuda:0') tensor(1.4670, device='cuda:0') tensor(-2.1409e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.097769
Average KL loss: 0.370180
Average total loss: 0.467949
tensor(-13.1407, device='cuda:0') tensor(1.4670, device='cuda:0') tensor(2.7708e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.099080
Average KL loss: 0.370179
Average total loss: 0.469259
tensor(-13.1416, device='cuda:0') tensor(1.4670, device='cuda:0') tensor(-1.4547e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.099151
Average KL loss: 0.370175
Average total loss: 0.469326
tensor(-13.1425, device='cuda:0') tensor(1.4671, device='cuda:0') tensor(-4.2241e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.097818
Average KL loss: 0.370176
Average total loss: 0.467994
tensor(-13.1435, device='cuda:0') tensor(1.4672, device='cuda:0') tensor(-1.9367e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.097687
Average KL loss: 0.370177
Average total loss: 0.467864
tensor(-13.1444, device='cuda:0') tensor(1.4673, device='cuda:0') tensor(6.1629e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.098169
Average KL loss: 0.370183
Average total loss: 0.468352
tensor(-13.1453, device='cuda:0') tensor(1.4674, device='cuda:0') tensor(-3.4213e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.097713
Average KL loss: 0.370192
Average total loss: 0.467905
tensor(-13.1462, device='cuda:0') tensor(1.4674, device='cuda:0') tensor(-1.3592e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.096098
Average KL loss: 0.370178
Average total loss: 0.466276
tensor(-13.1472, device='cuda:0') tensor(1.4674, device='cuda:0') tensor(4.8251e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.098063
Average KL loss: 0.370177
Average total loss: 0.468240
tensor(-13.1481, device='cuda:0') tensor(1.4675, device='cuda:0') tensor(-2.3394e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.098941
Average KL loss: 0.370177
Average total loss: 0.469119
tensor(-13.1490, device='cuda:0') tensor(1.4675, device='cuda:0') tensor(-1.1092e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.096546
Average KL loss: 0.370176
Average total loss: 0.466722
tensor(-13.1499, device='cuda:0') tensor(1.4676, device='cuda:0') tensor(-1.7776e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.095278
Average KL loss: 0.370166
Average total loss: 0.465444
tensor(-13.1509, device='cuda:0') tensor(1.4676, device='cuda:0') tensor(-4.6533e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.095168
Average KL loss: 0.370153
Average total loss: 0.465320
tensor(-13.1518, device='cuda:0') tensor(1.4676, device='cuda:0') tensor(-7.7452e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.095665
Average KL loss: 0.370149
Average total loss: 0.465814
tensor(-13.1527, device='cuda:0') tensor(1.4677, device='cuda:0') tensor(4.4981e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.094725
Average KL loss: 0.370136
Average total loss: 0.464861
tensor(-13.1536, device='cuda:0') tensor(1.4677, device='cuda:0') tensor(-2.1033e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.094052
Average KL loss: 0.370121
Average total loss: 0.464173
tensor(-13.1545, device='cuda:0') tensor(1.4678, device='cuda:0') tensor(-2.5460e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.095391
Average KL loss: 0.370112
Average total loss: 0.465504
tensor(-13.1555, device='cuda:0') tensor(1.4679, device='cuda:0') tensor(-1.5690e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.096552
Average KL loss: 0.370107
Average total loss: 0.466659
tensor(-13.1564, device='cuda:0') tensor(1.4679, device='cuda:0') tensor(-2.1395e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.095170
Average KL loss: 0.370107
Average total loss: 0.465278
tensor(-13.1573, device='cuda:0') tensor(1.4680, device='cuda:0') tensor(-1.1418e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.094621
Average KL loss: 0.370118
Average total loss: 0.464740
tensor(-13.1582, device='cuda:0') tensor(1.4681, device='cuda:0') tensor(-4.2501e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.095035
Average KL loss: 0.370132
Average total loss: 0.465167
tensor(-13.1591, device='cuda:0') tensor(1.4682, device='cuda:0') tensor(2.3865e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.095994
Average KL loss: 0.370131
Average total loss: 0.466125
tensor(-13.1600, device='cuda:0') tensor(1.4684, device='cuda:0') tensor(-9.5770e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.091585
Average KL loss: 0.370130
Average total loss: 0.461715
tensor(-13.1610, device='cuda:0') tensor(1.4685, device='cuda:0') tensor(1.5999e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.091010
Average KL loss: 0.370124
Average total loss: 0.461134
tensor(-13.1619, device='cuda:0') tensor(1.4685, device='cuda:0') tensor(6.4809e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.089164
Average KL loss: 0.370117
Average total loss: 0.459282
tensor(-13.1628, device='cuda:0') tensor(1.4686, device='cuda:0') tensor(-1.2708e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.093242
Average KL loss: 0.370107
Average total loss: 0.463350
tensor(-13.1637, device='cuda:0') tensor(1.4687, device='cuda:0') tensor(5.2686e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.091490
Average KL loss: 0.370100
Average total loss: 0.461590
tensor(-13.1646, device='cuda:0') tensor(1.4687, device='cuda:0') tensor(-1.3147e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.090639
Average KL loss: 0.370097
Average total loss: 0.460736
tensor(-13.1655, device='cuda:0') tensor(1.4688, device='cuda:0') tensor(-3.0768e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.093604
Average KL loss: 0.370092
Average total loss: 0.463696
tensor(-13.1664, device='cuda:0') tensor(1.4689, device='cuda:0') tensor(-5.7890e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.091263
Average KL loss: 0.370077
Average total loss: 0.461341
tensor(-13.1673, device='cuda:0') tensor(1.4690, device='cuda:0') tensor(8.2581e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.090467
Average KL loss: 0.370071
Average total loss: 0.460538
tensor(-13.1682, device='cuda:0') tensor(1.4691, device='cuda:0') tensor(1.8381e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.091572
Average KL loss: 0.370068
Average total loss: 0.461640
tensor(-13.1691, device='cuda:0') tensor(1.4693, device='cuda:0') tensor(2.2599e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.091206
Average KL loss: 0.370049
Average total loss: 0.461255
tensor(-13.1700, device='cuda:0') tensor(1.4694, device='cuda:0') tensor(3.3163e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.090760
Average KL loss: 0.370034
Average total loss: 0.460794
tensor(-13.1709, device='cuda:0') tensor(1.4695, device='cuda:0') tensor(-1.2578e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.089777
Average KL loss: 0.370019
Average total loss: 0.459796
tensor(-13.1718, device='cuda:0') tensor(1.4696, device='cuda:0') tensor(-1.0552e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.088732
Average KL loss: 0.370009
Average total loss: 0.458741
tensor(-13.1727, device='cuda:0') tensor(1.4697, device='cuda:0') tensor(1.1069e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.088587
Average KL loss: 0.370001
Average total loss: 0.458588
tensor(-13.1736, device='cuda:0') tensor(1.4697, device='cuda:0') tensor(-2.9854e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.090561
Average KL loss: 0.369987
Average total loss: 0.460548
tensor(-13.1745, device='cuda:0') tensor(1.4698, device='cuda:0') tensor(-4.6331e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.090228
Average KL loss: 0.369975
Average total loss: 0.460203
tensor(-13.1754, device='cuda:0') tensor(1.4699, device='cuda:0') tensor(1.1557e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.088570
Average KL loss: 0.369961
Average total loss: 0.458532
tensor(-13.1763, device='cuda:0') tensor(1.4699, device='cuda:0') tensor(-1.2416e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.089178
Average KL loss: 0.369947
Average total loss: 0.459125
tensor(-13.1772, device='cuda:0') tensor(1.4701, device='cuda:0') tensor(-3.7875e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.089870
Average KL loss: 0.369945
Average total loss: 0.459815
tensor(-13.1781, device='cuda:0') tensor(1.4702, device='cuda:0') tensor(1.4138e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.087603
Average KL loss: 0.369936
Average total loss: 0.457538
tensor(-13.1790, device='cuda:0') tensor(1.4704, device='cuda:0') tensor(-7.5799e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.087002
Average KL loss: 0.369935
Average total loss: 0.456937
tensor(-13.1798, device='cuda:0') tensor(1.4705, device='cuda:0') tensor(-2.2781e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.087326
Average KL loss: 0.369928
Average total loss: 0.457254
tensor(-13.1807, device='cuda:0') tensor(1.4706, device='cuda:0') tensor(-2.1744e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.088299
Average KL loss: 0.369928
Average total loss: 0.458227
tensor(-13.1816, device='cuda:0') tensor(1.4707, device='cuda:0') tensor(-5.6214e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.085428
Average KL loss: 0.369922
Average total loss: 0.455350
tensor(-13.1825, device='cuda:0') tensor(1.4708, device='cuda:0') tensor(-8.1568e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.088043
Average KL loss: 0.369919
Average total loss: 0.457961
tensor(-13.1834, device='cuda:0') tensor(1.4709, device='cuda:0') tensor(-5.8226e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.085704
Average KL loss: 0.369921
Average total loss: 0.455624
tensor(-13.1843, device='cuda:0') tensor(1.4711, device='cuda:0') tensor(-1.1621e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.086723
Average KL loss: 0.369912
Average total loss: 0.456635
tensor(-13.1851, device='cuda:0') tensor(1.4712, device='cuda:0') tensor(-1.6866e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.086350
Average KL loss: 0.369894
Average total loss: 0.456243
tensor(-13.1860, device='cuda:0') tensor(1.4712, device='cuda:0') tensor(7.4542e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.085914
Average KL loss: 0.369880
Average total loss: 0.455794
tensor(-13.1869, device='cuda:0') tensor(1.4713, device='cuda:0') tensor(-1.0372e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.086670
Average KL loss: 0.369874
Average total loss: 0.456544
tensor(-13.1878, device='cuda:0') tensor(1.4714, device='cuda:0') tensor(-2.9604e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.086015
Average KL loss: 0.369855
Average total loss: 0.455870
tensor(-13.1887, device='cuda:0') tensor(1.4715, device='cuda:0') tensor(-1.5208e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.083087
Average KL loss: 0.369833
Average total loss: 0.452920
tensor(-13.1895, device='cuda:0') tensor(1.4716, device='cuda:0') tensor(1.7084e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.083541
Average KL loss: 0.369815
Average total loss: 0.453356
tensor(-13.1904, device='cuda:0') tensor(1.4717, device='cuda:0') tensor(-1.0329e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.084809
Average KL loss: 0.369807
Average total loss: 0.454616
tensor(-13.1913, device='cuda:0') tensor(1.4718, device='cuda:0') tensor(8.2715e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.084148
Average KL loss: 0.369788
Average total loss: 0.453936
tensor(-13.1922, device='cuda:0') tensor(1.4719, device='cuda:0') tensor(-1.3833e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.085250
Average KL loss: 0.369778
Average total loss: 0.455029
tensor(-13.1930, device='cuda:0') tensor(1.4720, device='cuda:0') tensor(-2.5280e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.083876
Average KL loss: 0.369770
Average total loss: 0.453646
tensor(-13.1939, device='cuda:0') tensor(1.4721, device='cuda:0') tensor(-8.4402e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.081262
Average KL loss: 0.369765
Average total loss: 0.451027
tensor(-13.1948, device='cuda:0') tensor(1.4723, device='cuda:0') tensor(1.8705e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.084191
Average KL loss: 0.369756
Average total loss: 0.453947
tensor(-13.1956, device='cuda:0') tensor(1.4725, device='cuda:0') tensor(-1.0717e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.082035
Average KL loss: 0.369745
Average total loss: 0.451779
tensor(-13.1965, device='cuda:0') tensor(1.4726, device='cuda:0') tensor(-2.9361e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.079767
Average KL loss: 0.369723
Average total loss: 0.449489
tensor(-13.1974, device='cuda:0') tensor(1.4727, device='cuda:0') tensor(-2.9543e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.081828
Average KL loss: 0.369708
Average total loss: 0.451536
tensor(-13.1982, device='cuda:0') tensor(1.4728, device='cuda:0') tensor(-3.0972e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.082585
Average KL loss: 0.369693
Average total loss: 0.452278
tensor(-13.1991, device='cuda:0') tensor(1.4728, device='cuda:0') tensor(3.1183e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.082292
Average KL loss: 0.369672
Average total loss: 0.451965
tensor(-13.2000, device='cuda:0') tensor(1.4729, device='cuda:0') tensor(-2.4717e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.083560
Average KL loss: 0.369656
Average total loss: 0.453216
tensor(-13.2008, device='cuda:0') tensor(1.4731, device='cuda:0') tensor(-1.3060e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.080285
Average KL loss: 0.369635
Average total loss: 0.449921
 Percentile value: 5.3982932567596436
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =     878 /    1728             ( 50.81%) | total_pruned =     850 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1235 /   36864             (  3.35%) | total_pruned =   35629 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1400 /   36864             (  3.80%) | total_pruned =   35464 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1236 /   36864             (  3.35%) | total_pruned =   35628 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1182 /   36864             (  3.21%) | total_pruned =   35682 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2036 /   73728             (  2.76%) | total_pruned =   71692 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2739 /  147456             (  1.86%) | total_pruned =  144717 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1157 /    8192             ( 14.12%) | total_pruned =    7035 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1783 /  147456             (  1.21%) | total_pruned =  145673 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1679 /  147456             (  1.14%) | total_pruned =  145777 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3764 /  294912             (  1.28%) | total_pruned =  291148 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      85 /     256             ( 33.20%) | total_pruned =     171 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4393 /  589824             (  0.74%) | total_pruned =  585431 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1628 /   32768             (  4.97%) | total_pruned =   31140 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     224 /     256             ( 87.50%) | total_pruned =      32 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      57 /     256             ( 22.27%) | total_pruned =     199 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1634 /  589824             (  0.28%) | total_pruned =  588190 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1689 /  589824             (  0.29%) | total_pruned =  588135 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    3557 / 1179648             (  0.30%) | total_pruned = 1176091 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     277 /     512             ( 54.10%) | total_pruned =     235 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2523 / 2359296             (  0.11%) | total_pruned = 2356773 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     331 /     512             ( 64.65%) | total_pruned =     181 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     103 /     512             ( 20.12%) | total_pruned =     409 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1087 /  131072             (  0.83%) | total_pruned =  129985 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     256 /     512             ( 50.00%) | total_pruned =     256 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      91 /     512             ( 17.77%) | total_pruned =     421 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1255 / 2359296             (  0.05%) | total_pruned = 2358041 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     129 /     512             ( 25.20%) | total_pruned =     383 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1117 / 2359296             (  0.05%) | total_pruned = 2358179 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     362 /     512             ( 70.70%) | total_pruned =     150 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
linear.weight        | nonzeros =    1631 /    5120             ( 31.86%) | total_pruned =    3489 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 25/100 Loss: 0.018238 Accuracy: 85.33 100.00 % Best test Accuracy: 85.64%
tensor(-13.2017, device='cuda:0') tensor(1.4732, device='cuda:0') tensor(-5.8804e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.079908
Average KL loss: 0.368893
Average total loss: 0.448801
tensor(-13.2042, device='cuda:0') tensor(1.4347, device='cuda:0') tensor(-2.0469e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.077554
Average KL loss: 0.368312
Average total loss: 0.445866
tensor(-13.2062, device='cuda:0') tensor(1.4108, device='cuda:0') tensor(-1.7698e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.078192
Average KL loss: 0.368026
Average total loss: 0.446219
tensor(-13.2079, device='cuda:0') tensor(1.3938, device='cuda:0') tensor(-1.1320e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.077416
Average KL loss: 0.367852
Average total loss: 0.445268
tensor(-13.2095, device='cuda:0') tensor(1.3812, device='cuda:0') tensor(-4.1239e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.075879
Average KL loss: 0.367754
Average total loss: 0.443633
tensor(-13.2109, device='cuda:0') tensor(1.3715, device='cuda:0') tensor(-9.6307e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.073625
Average KL loss: 0.367680
Average total loss: 0.441305
tensor(-13.2123, device='cuda:0') tensor(1.3638, device='cuda:0') tensor(-6.8548e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.074947
Average KL loss: 0.367634
Average total loss: 0.442581
tensor(-13.2136, device='cuda:0') tensor(1.3575, device='cuda:0') tensor(-1.9029e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.075309
Average KL loss: 0.367608
Average total loss: 0.442917
tensor(-13.2149, device='cuda:0') tensor(1.3523, device='cuda:0') tensor(-3.6010e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.070914
Average KL loss: 0.367595
Average total loss: 0.438509
tensor(-13.2161, device='cuda:0') tensor(1.3478, device='cuda:0') tensor(-3.2458e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.065832
Average KL loss: 0.367580
Average total loss: 0.433413
tensor(-13.2173, device='cuda:0') tensor(1.3439, device='cuda:0') tensor(-3.7724e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.069124
Average KL loss: 0.367580
Average total loss: 0.436704
tensor(-13.2184, device='cuda:0') tensor(1.3406, device='cuda:0') tensor(-1.6043e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.069591
Average KL loss: 0.367592
Average total loss: 0.437183
tensor(-13.2195, device='cuda:0') tensor(1.3375, device='cuda:0') tensor(-4.1414e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.068116
Average KL loss: 0.367604
Average total loss: 0.435721
tensor(-13.2207, device='cuda:0') tensor(1.3348, device='cuda:0') tensor(-4.5645e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.069818
Average KL loss: 0.367624
Average total loss: 0.437441
tensor(-13.2217, device='cuda:0') tensor(1.3324, device='cuda:0') tensor(-2.6482e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.066348
Average KL loss: 0.367629
Average total loss: 0.433977
tensor(-13.2228, device='cuda:0') tensor(1.3302, device='cuda:0') tensor(-2.9979e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.065456
Average KL loss: 0.367633
Average total loss: 0.433089
tensor(-13.2239, device='cuda:0') tensor(1.3281, device='cuda:0') tensor(-2.4994e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.067213
Average KL loss: 0.367639
Average total loss: 0.434852
tensor(-13.2249, device='cuda:0') tensor(1.3263, device='cuda:0') tensor(-1.5598e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.061974
Average KL loss: 0.367652
Average total loss: 0.429626
tensor(-13.2260, device='cuda:0') tensor(1.3245, device='cuda:0') tensor(-1.1808e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.061059
Average KL loss: 0.367663
Average total loss: 0.428722
tensor(-13.2270, device='cuda:0') tensor(1.3229, device='cuda:0') tensor(-4.2673e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.062163
Average KL loss: 0.367683
Average total loss: 0.429846
tensor(-13.2280, device='cuda:0') tensor(1.3214, device='cuda:0') tensor(-3.0210e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.063247
Average KL loss: 0.367702
Average total loss: 0.430949
tensor(-13.2291, device='cuda:0') tensor(1.3201, device='cuda:0') tensor(-1.7626e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.059723
Average KL loss: 0.367719
Average total loss: 0.427441
tensor(-13.2301, device='cuda:0') tensor(1.3187, device='cuda:0') tensor(-3.6951e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.059733
Average KL loss: 0.367733
Average total loss: 0.427466
tensor(-13.2311, device='cuda:0') tensor(1.3176, device='cuda:0') tensor(-5.0068e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.060394
Average KL loss: 0.367750
Average total loss: 0.428145
tensor(-13.2321, device='cuda:0') tensor(1.3164, device='cuda:0') tensor(1.3522e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.055116
Average KL loss: 0.367767
Average total loss: 0.422883
tensor(-13.2330, device='cuda:0') tensor(1.3152, device='cuda:0') tensor(-2.0122e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.058423
Average KL loss: 0.367776
Average total loss: 0.426199
tensor(-13.2340, device='cuda:0') tensor(1.3142, device='cuda:0') tensor(-2.7240e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.058037
Average KL loss: 0.367795
Average total loss: 0.425832
tensor(-13.2350, device='cuda:0') tensor(1.3133, device='cuda:0') tensor(-7.0683e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.056876
Average KL loss: 0.367809
Average total loss: 0.424685
tensor(-13.2360, device='cuda:0') tensor(1.3124, device='cuda:0') tensor(-2.8618e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.055508
Average KL loss: 0.367808
Average total loss: 0.423316
tensor(-13.2369, device='cuda:0') tensor(1.3114, device='cuda:0') tensor(-2.2542e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.053150
Average KL loss: 0.367820
Average total loss: 0.420971
tensor(-13.2379, device='cuda:0') tensor(1.3106, device='cuda:0') tensor(-1.5929e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.056764
Average KL loss: 0.367835
Average total loss: 0.424599
tensor(-13.2389, device='cuda:0') tensor(1.3099, device='cuda:0') tensor(-9.6194e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.054548
Average KL loss: 0.367854
Average total loss: 0.422402
tensor(-13.2398, device='cuda:0') tensor(1.3092, device='cuda:0') tensor(-3.5945e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.055781
Average KL loss: 0.367879
Average total loss: 0.423659
tensor(-13.2408, device='cuda:0') tensor(1.3086, device='cuda:0') tensor(-2.3749e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.054452
Average KL loss: 0.367898
Average total loss: 0.422350
tensor(-13.2417, device='cuda:0') tensor(1.3079, device='cuda:0') tensor(-2.0735e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.054054
Average KL loss: 0.367913
Average total loss: 0.421967
tensor(-13.2426, device='cuda:0') tensor(1.3073, device='cuda:0') tensor(-3.3707e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.052882
Average KL loss: 0.367933
Average total loss: 0.420814
tensor(-13.2436, device='cuda:0') tensor(1.3067, device='cuda:0') tensor(-2.0060e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.051284
Average KL loss: 0.367948
Average total loss: 0.419232
tensor(-13.2445, device='cuda:0') tensor(1.3062, device='cuda:0') tensor(-8.8329e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.049747
Average KL loss: 0.367968
Average total loss: 0.417715
tensor(-13.2454, device='cuda:0') tensor(1.3057, device='cuda:0') tensor(-2.1676e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.050936
Average KL loss: 0.367975
Average total loss: 0.418911
tensor(-13.2464, device='cuda:0') tensor(1.3052, device='cuda:0') tensor(-3.8225e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.049237
Average KL loss: 0.367988
Average total loss: 0.417225
tensor(-13.2473, device='cuda:0') tensor(1.3047, device='cuda:0') tensor(-7.2368e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.051522
Average KL loss: 0.367991
Average total loss: 0.419513
tensor(-13.2482, device='cuda:0') tensor(1.3042, device='cuda:0') tensor(-3.5306e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.051346
Average KL loss: 0.368007
Average total loss: 0.419354
tensor(-13.2491, device='cuda:0') tensor(1.3038, device='cuda:0') tensor(-3.4437e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.049605
Average KL loss: 0.368020
Average total loss: 0.417624
tensor(-13.2500, device='cuda:0') tensor(1.3033, device='cuda:0') tensor(-3.4900e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.048398
Average KL loss: 0.368033
Average total loss: 0.416431
tensor(-13.2509, device='cuda:0') tensor(1.3029, device='cuda:0') tensor(-3.2440e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.048860
Average KL loss: 0.368042
Average total loss: 0.416902
tensor(-13.2519, device='cuda:0') tensor(1.3026, device='cuda:0') tensor(-1.9639e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.047859
Average KL loss: 0.368046
Average total loss: 0.415906
tensor(-13.2528, device='cuda:0') tensor(1.3023, device='cuda:0') tensor(-1.5286e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.048120
Average KL loss: 0.368044
Average total loss: 0.416164
tensor(-13.2537, device='cuda:0') tensor(1.3019, device='cuda:0') tensor(-1.8108e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.047331
Average KL loss: 0.368045
Average total loss: 0.415375
tensor(-13.2546, device='cuda:0') tensor(1.3016, device='cuda:0') tensor(8.2849e-11, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.045070
Average KL loss: 0.368060
Average total loss: 0.413131
tensor(-13.2555, device='cuda:0') tensor(1.3013, device='cuda:0') tensor(-1.2222e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.046346
Average KL loss: 0.368079
Average total loss: 0.414425
tensor(-13.2564, device='cuda:0') tensor(1.3010, device='cuda:0') tensor(-2.1647e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.046633
Average KL loss: 0.368081
Average total loss: 0.414714
tensor(-13.2573, device='cuda:0') tensor(1.3007, device='cuda:0') tensor(-1.7781e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.045641
Average KL loss: 0.368091
Average total loss: 0.413732
tensor(-13.2582, device='cuda:0') tensor(1.3004, device='cuda:0') tensor(-3.1959e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.043362
Average KL loss: 0.368107
Average total loss: 0.411469
tensor(-13.2591, device='cuda:0') tensor(1.3002, device='cuda:0') tensor(-3.1388e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.044390
Average KL loss: 0.368116
Average total loss: 0.412506
tensor(-13.2599, device='cuda:0') tensor(1.2998, device='cuda:0') tensor(-2.8932e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.045280
Average KL loss: 0.368119
Average total loss: 0.413399
tensor(-13.2608, device='cuda:0') tensor(1.2996, device='cuda:0') tensor(-1.0635e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.042944
Average KL loss: 0.368121
Average total loss: 0.411065
tensor(-13.2617, device='cuda:0') tensor(1.2993, device='cuda:0') tensor(-2.5106e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.044527
Average KL loss: 0.368118
Average total loss: 0.412645
tensor(-13.2626, device='cuda:0') tensor(1.2991, device='cuda:0') tensor(-1.7721e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.042966
Average KL loss: 0.368121
Average total loss: 0.411088
tensor(-13.2635, device='cuda:0') tensor(1.2989, device='cuda:0') tensor(-2.3084e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.043782
Average KL loss: 0.368130
Average total loss: 0.411913
tensor(-13.2644, device='cuda:0') tensor(1.2987, device='cuda:0') tensor(-1.3497e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.041905
Average KL loss: 0.368134
Average total loss: 0.410039
tensor(-13.2652, device='cuda:0') tensor(1.2985, device='cuda:0') tensor(-1.6917e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.043826
Average KL loss: 0.368133
Average total loss: 0.411959
tensor(-13.2661, device='cuda:0') tensor(1.2984, device='cuda:0') tensor(-1.5542e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.041102
Average KL loss: 0.368126
Average total loss: 0.409228
tensor(-13.2670, device='cuda:0') tensor(1.2982, device='cuda:0') tensor(-1.1526e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.042055
Average KL loss: 0.368132
Average total loss: 0.410187
tensor(-13.2679, device='cuda:0') tensor(1.2980, device='cuda:0') tensor(2.5815e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.040810
Average KL loss: 0.368138
Average total loss: 0.408948
tensor(-13.2687, device='cuda:0') tensor(1.2979, device='cuda:0') tensor(-1.0949e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.042538
Average KL loss: 0.368132
Average total loss: 0.410670
tensor(-13.2696, device='cuda:0') tensor(1.2977, device='cuda:0') tensor(-1.6965e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.041429
Average KL loss: 0.368130
Average total loss: 0.409560
tensor(-13.2705, device='cuda:0') tensor(1.2976, device='cuda:0') tensor(2.2575e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.039104
Average KL loss: 0.368135
Average total loss: 0.407239
tensor(-13.2713, device='cuda:0') tensor(1.2975, device='cuda:0') tensor(-1.0528e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.040531
Average KL loss: 0.368138
Average total loss: 0.408669
tensor(-13.2722, device='cuda:0') tensor(1.2974, device='cuda:0') tensor(-2.4168e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.038869
Average KL loss: 0.368140
Average total loss: 0.407009
tensor(-13.2730, device='cuda:0') tensor(1.2973, device='cuda:0') tensor(-1.0241e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.040711
Average KL loss: 0.368132
Average total loss: 0.408843
tensor(-13.2739, device='cuda:0') tensor(1.2972, device='cuda:0') tensor(-1.9187e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.039661
Average KL loss: 0.368125
Average total loss: 0.407787
tensor(-13.2748, device='cuda:0') tensor(1.2970, device='cuda:0') tensor(-1.6891e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.040268
Average KL loss: 0.368123
Average total loss: 0.408391
tensor(-13.2756, device='cuda:0') tensor(1.2970, device='cuda:0') tensor(-5.2124e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.038421
Average KL loss: 0.368119
Average total loss: 0.406540
tensor(-13.2765, device='cuda:0') tensor(1.2969, device='cuda:0') tensor(1.2754e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.039127
Average KL loss: 0.368111
Average total loss: 0.407238
tensor(-13.2773, device='cuda:0') tensor(1.2968, device='cuda:0') tensor(-1.3094e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.040273
Average KL loss: 0.368097
Average total loss: 0.408371
tensor(-13.2782, device='cuda:0') tensor(1.2967, device='cuda:0') tensor(-6.0520e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.040179
Average KL loss: 0.368104
Average total loss: 0.408283
tensor(-13.2790, device='cuda:0') tensor(1.2967, device='cuda:0') tensor(-3.2065e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.037591
Average KL loss: 0.368102
Average total loss: 0.405693
tensor(-13.2799, device='cuda:0') tensor(1.2967, device='cuda:0') tensor(5.7346e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.038570
Average KL loss: 0.368094
Average total loss: 0.406664
tensor(-13.2807, device='cuda:0') tensor(1.2966, device='cuda:0') tensor(-7.4315e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.037358
Average KL loss: 0.368077
Average total loss: 0.405435
tensor(-13.2816, device='cuda:0') tensor(1.2966, device='cuda:0') tensor(-1.7210e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.037502
Average KL loss: 0.368058
Average total loss: 0.405560
tensor(-13.2824, device='cuda:0') tensor(1.2965, device='cuda:0') tensor(-2.4102e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.036968
Average KL loss: 0.368039
Average total loss: 0.405007
tensor(-13.2833, device='cuda:0') tensor(1.2965, device='cuda:0') tensor(-9.5998e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.038428
Average KL loss: 0.368030
Average total loss: 0.406458
tensor(-13.2841, device='cuda:0') tensor(1.2965, device='cuda:0') tensor(-1.1295e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.037063
Average KL loss: 0.368025
Average total loss: 0.405088
tensor(-13.2849, device='cuda:0') tensor(1.2964, device='cuda:0') tensor(7.1708e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.036494
Average KL loss: 0.368026
Average total loss: 0.404521
tensor(-13.2858, device='cuda:0') tensor(1.2964, device='cuda:0') tensor(-2.8262e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.035548
Average KL loss: 0.368017
Average total loss: 0.403565
tensor(-13.2866, device='cuda:0') tensor(1.2964, device='cuda:0') tensor(-1.6346e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.037208
Average KL loss: 0.368009
Average total loss: 0.405217
tensor(-13.2874, device='cuda:0') tensor(1.2963, device='cuda:0') tensor(-1.0690e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.036651
Average KL loss: 0.367994
Average total loss: 0.404645
tensor(-13.2883, device='cuda:0') tensor(1.2963, device='cuda:0') tensor(-1.1141e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.035482
Average KL loss: 0.367975
Average total loss: 0.403457
tensor(-13.2891, device='cuda:0') tensor(1.2963, device='cuda:0') tensor(-2.1535e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.035095
Average KL loss: 0.367958
Average total loss: 0.403052
tensor(-13.2899, device='cuda:0') tensor(1.2963, device='cuda:0') tensor(-1.4156e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.034696
Average KL loss: 0.367940
Average total loss: 0.402636
tensor(-13.2908, device='cuda:0') tensor(1.2963, device='cuda:0') tensor(-2.1756e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.035255
Average KL loss: 0.367914
Average total loss: 0.403168
tensor(-13.2916, device='cuda:0') tensor(1.2962, device='cuda:0') tensor(-2.7142e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.034265
Average KL loss: 0.367908
Average total loss: 0.402173
tensor(-13.2924, device='cuda:0') tensor(1.2963, device='cuda:0') tensor(-2.5453e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.036293
Average KL loss: 0.367887
Average total loss: 0.404181
tensor(-13.2932, device='cuda:0') tensor(1.2963, device='cuda:0') tensor(-1.2006e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.034260
Average KL loss: 0.367870
Average total loss: 0.402129
tensor(-13.2941, device='cuda:0') tensor(1.2964, device='cuda:0') tensor(-1.2250e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.035777
Average KL loss: 0.367844
Average total loss: 0.403621
tensor(-13.2949, device='cuda:0') tensor(1.2965, device='cuda:0') tensor(-6.5869e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.036287
Average KL loss: 0.367816
Average total loss: 0.404103
tensor(-13.2957, device='cuda:0') tensor(1.2965, device='cuda:0') tensor(-1.4464e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.034884
Average KL loss: 0.367794
Average total loss: 0.402678
tensor(-13.2965, device='cuda:0') tensor(1.2965, device='cuda:0') tensor(-1.0790e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.034801
Average KL loss: 0.367789
Average total loss: 0.402590
tensor(-13.2973, device='cuda:0') tensor(1.2966, device='cuda:0') tensor(-1.3198e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.034644
Average KL loss: 0.367785
Average total loss: 0.402429
tensor(-13.2981, device='cuda:0') tensor(1.2966, device='cuda:0') tensor(-1.1359e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.034230
Average KL loss: 0.367771
Average total loss: 0.402000
tensor(-13.2989, device='cuda:0') tensor(1.2966, device='cuda:0') tensor(-1.4804e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.032124
Average KL loss: 0.367759
Average total loss: 0.399884
tensor(-13.2998, device='cuda:0') tensor(1.2967, device='cuda:0') tensor(-9.1447e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.032835
Average KL loss: 0.367732
Average total loss: 0.400567
tensor(-13.3006, device='cuda:0') tensor(1.2967, device='cuda:0') tensor(-3.3751e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.032959
Average KL loss: 0.367701
Average total loss: 0.400660
tensor(-13.3014, device='cuda:0') tensor(1.2967, device='cuda:0') tensor(-4.5069e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.033045
Average KL loss: 0.367677
Average total loss: 0.400722
tensor(-13.3022, device='cuda:0') tensor(1.2967, device='cuda:0') tensor(-1.9125e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.033397
Average KL loss: 0.367654
Average total loss: 0.401051
tensor(-13.3030, device='cuda:0') tensor(1.2968, device='cuda:0') tensor(-7.1469e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.032205
Average KL loss: 0.367634
Average total loss: 0.399840
tensor(-13.3038, device='cuda:0') tensor(1.2968, device='cuda:0') tensor(-1.8335e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.032059
Average KL loss: 0.367610
Average total loss: 0.399668
tensor(-13.3046, device='cuda:0') tensor(1.2968, device='cuda:0') tensor(-3.0419e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.033313
Average KL loss: 0.367594
Average total loss: 0.400907
tensor(-13.3054, device='cuda:0') tensor(1.2969, device='cuda:0') tensor(-3.7926e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.033370
Average KL loss: 0.367574
Average total loss: 0.400945
tensor(-13.3062, device='cuda:0') tensor(1.2970, device='cuda:0') tensor(-9.6098e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.031669
Average KL loss: 0.367552
Average total loss: 0.399221
tensor(-13.3070, device='cuda:0') tensor(1.2969, device='cuda:0') tensor(-1.3403e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.031849
Average KL loss: 0.367519
Average total loss: 0.399367
tensor(-13.3078, device='cuda:0') tensor(1.2970, device='cuda:0') tensor(-9.6358e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.030888
Average KL loss: 0.367500
Average total loss: 0.398389
tensor(-13.3086, device='cuda:0') tensor(1.2971, device='cuda:0') tensor(-3.4061e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.031141
Average KL loss: 0.367470
Average total loss: 0.398611
tensor(-13.3094, device='cuda:0') tensor(1.2971, device='cuda:0') tensor(-1.6687e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.030157
Average KL loss: 0.367443
Average total loss: 0.397600
tensor(-13.3102, device='cuda:0') tensor(1.2971, device='cuda:0') tensor(-1.0456e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.032688
Average KL loss: 0.367413
Average total loss: 0.400101
tensor(-13.3110, device='cuda:0') tensor(1.2972, device='cuda:0') tensor(-6.4513e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.030759
Average KL loss: 0.367387
Average total loss: 0.398146
tensor(-13.3118, device='cuda:0') tensor(1.2973, device='cuda:0') tensor(-4.8466e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.029597
Average KL loss: 0.367362
Average total loss: 0.396958
tensor(-13.3126, device='cuda:0') tensor(1.2973, device='cuda:0') tensor(-3.7827e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.029462
Average KL loss: 0.367323
Average total loss: 0.396785
tensor(-13.3134, device='cuda:0') tensor(1.2973, device='cuda:0') tensor(-9.2152e-11, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.029332
Average KL loss: 0.367301
Average total loss: 0.396633
tensor(-13.3142, device='cuda:0') tensor(1.2974, device='cuda:0') tensor(-9.8161e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.029950
Average KL loss: 0.367281
Average total loss: 0.397231
tensor(-13.3150, device='cuda:0') tensor(1.2974, device='cuda:0') tensor(-4.3157e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.029575
Average KL loss: 0.367267
Average total loss: 0.396842
tensor(-13.3158, device='cuda:0') tensor(1.2975, device='cuda:0') tensor(-1.6795e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.030412
Average KL loss: 0.367254
Average total loss: 0.397666
tensor(-13.3166, device='cuda:0') tensor(1.2976, device='cuda:0') tensor(-3.7624e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.029929
Average KL loss: 0.367230
Average total loss: 0.397159
tensor(-13.3174, device='cuda:0') tensor(1.2976, device='cuda:0') tensor(9.3657e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.029241
Average KL loss: 0.367194
Average total loss: 0.396436
tensor(-13.3182, device='cuda:0') tensor(1.2977, device='cuda:0') tensor(3.6399e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.030254
Average KL loss: 0.367159
Average total loss: 0.397414
tensor(-13.3190, device='cuda:0') tensor(1.2977, device='cuda:0') tensor(-5.7420e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.029436
Average KL loss: 0.367128
Average total loss: 0.396564
tensor(-13.3198, device='cuda:0') tensor(1.2978, device='cuda:0') tensor(-9.1493e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.031113
Average KL loss: 0.367100
Average total loss: 0.398213
tensor(-13.3206, device='cuda:0') tensor(1.2979, device='cuda:0') tensor(-5.2524e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.028119
Average KL loss: 0.367074
Average total loss: 0.395193
tensor(-13.3213, device='cuda:0') tensor(1.2979, device='cuda:0') tensor(-4.0659e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.031464
Average KL loss: 0.367040
Average total loss: 0.398504
tensor(-13.3221, device='cuda:0') tensor(1.2981, device='cuda:0') tensor(-1.4236e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.028529
Average KL loss: 0.367004
Average total loss: 0.395533
tensor(-13.3229, device='cuda:0') tensor(1.2981, device='cuda:0') tensor(-4.0068e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.029852
Average KL loss: 0.366981
Average total loss: 0.396834
tensor(-13.3237, device='cuda:0') tensor(1.2982, device='cuda:0') tensor(-5.0845e-11, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.028070
Average KL loss: 0.366964
Average total loss: 0.395034
tensor(-13.3245, device='cuda:0') tensor(1.2983, device='cuda:0') tensor(-8.7500e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.028029
Average KL loss: 0.366934
Average total loss: 0.394963
tensor(-13.3253, device='cuda:0') tensor(1.2983, device='cuda:0') tensor(1.9886e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.027222
Average KL loss: 0.366893
Average total loss: 0.394115
tensor(-13.3261, device='cuda:0') tensor(1.2984, device='cuda:0') tensor(-1.2047e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.029810
Average KL loss: 0.366856
Average total loss: 0.396666
tensor(-13.3269, device='cuda:0') tensor(1.2985, device='cuda:0') tensor(-1.5196e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.028077
Average KL loss: 0.366825
Average total loss: 0.394902
tensor(-13.3276, device='cuda:0') tensor(1.2986, device='cuda:0') tensor(3.7471e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.027673
Average KL loss: 0.366788
Average total loss: 0.394461
tensor(-13.3284, device='cuda:0') tensor(1.2987, device='cuda:0') tensor(6.3159e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.027860
Average KL loss: 0.366751
Average total loss: 0.394611
tensor(-13.3292, device='cuda:0') tensor(1.2987, device='cuda:0') tensor(-3.6281e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.027595
Average KL loss: 0.366713
Average total loss: 0.394308
tensor(-13.3300, device='cuda:0') tensor(1.2988, device='cuda:0') tensor(2.6604e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.027802
Average KL loss: 0.366678
Average total loss: 0.394479
tensor(-13.3308, device='cuda:0') tensor(1.2990, device='cuda:0') tensor(4.5145e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.028199
Average KL loss: 0.366645
Average total loss: 0.394844
tensor(-13.3316, device='cuda:0') tensor(1.2991, device='cuda:0') tensor(-2.3752e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.027048
Average KL loss: 0.366628
Average total loss: 0.393675
tensor(-13.3323, device='cuda:0') tensor(1.2992, device='cuda:0') tensor(-3.6478e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.027366
Average KL loss: 0.366600
Average total loss: 0.393966
tensor(-13.3331, device='cuda:0') tensor(1.2992, device='cuda:0') tensor(-1.0025e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.027775
Average KL loss: 0.366563
Average total loss: 0.394338
tensor(-13.3339, device='cuda:0') tensor(1.2993, device='cuda:0') tensor(-1.2360e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.027076
Average KL loss: 0.366531
Average total loss: 0.393607
tensor(-13.3347, device='cuda:0') tensor(1.2994, device='cuda:0') tensor(3.2952e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.026615
Average KL loss: 0.366497
Average total loss: 0.393112
tensor(-13.3355, device='cuda:0') tensor(1.2996, device='cuda:0') tensor(4.2290e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.026999
Average KL loss: 0.366467
Average total loss: 0.393466
tensor(-13.3362, device='cuda:0') tensor(1.2997, device='cuda:0') tensor(-5.3060e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.027235
Average KL loss: 0.366439
Average total loss: 0.393675
tensor(-13.3370, device='cuda:0') tensor(1.2998, device='cuda:0') tensor(-1.5877e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.025943
Average KL loss: 0.366402
Average total loss: 0.392346
tensor(-13.3378, device='cuda:0') tensor(1.2999, device='cuda:0') tensor(-4.5235e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.027678
Average KL loss: 0.366368
Average total loss: 0.394046
tensor(-13.3386, device='cuda:0') tensor(1.2999, device='cuda:0') tensor(-2.3053e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.026119
Average KL loss: 0.366331
Average total loss: 0.392450
tensor(-13.3394, device='cuda:0') tensor(1.3000, device='cuda:0') tensor(-1.4849e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.026479
Average KL loss: 0.366288
Average total loss: 0.392767
tensor(-13.3401, device='cuda:0') tensor(1.3000, device='cuda:0') tensor(-4.2167e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.026123
Average KL loss: 0.366243
Average total loss: 0.392366
tensor(-13.3409, device='cuda:0') tensor(1.3001, device='cuda:0') tensor(-7.5935e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.026775
Average KL loss: 0.366200
Average total loss: 0.392975
tensor(-13.3417, device='cuda:0') tensor(1.3002, device='cuda:0') tensor(-1.0636e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.027197
Average KL loss: 0.366169
Average total loss: 0.393367
tensor(-13.3425, device='cuda:0') tensor(1.3003, device='cuda:0') tensor(-1.1132e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.026682
Average KL loss: 0.366130
Average total loss: 0.392812
tensor(-13.3432, device='cuda:0') tensor(1.3004, device='cuda:0') tensor(-4.2502e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.026086
Average KL loss: 0.366098
Average total loss: 0.392184
tensor(-13.3440, device='cuda:0') tensor(1.3006, device='cuda:0') tensor(1.5402e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.025691
Average KL loss: 0.366062
Average total loss: 0.391753
tensor(-13.3448, device='cuda:0') tensor(1.3007, device='cuda:0') tensor(-3.8448e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.026143
Average KL loss: 0.366014
Average total loss: 0.392157
tensor(-13.3455, device='cuda:0') tensor(1.3008, device='cuda:0') tensor(-8.5446e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.025892
Average KL loss: 0.365976
Average total loss: 0.391868
tensor(-13.3463, device='cuda:0') tensor(1.3010, device='cuda:0') tensor(-1.8773e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.025773
Average KL loss: 0.365941
Average total loss: 0.391715
tensor(-13.3471, device='cuda:0') tensor(1.3010, device='cuda:0') tensor(-8.0259e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.025812
Average KL loss: 0.365906
Average total loss: 0.391718
tensor(-13.3479, device='cuda:0') tensor(1.3011, device='cuda:0') tensor(-2.3872e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.025656
Average KL loss: 0.365871
Average total loss: 0.391527
tensor(-13.3486, device='cuda:0') tensor(1.3012, device='cuda:0') tensor(-1.4751e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.025515
Average KL loss: 0.365841
Average total loss: 0.391356
tensor(-13.3494, device='cuda:0') tensor(1.3014, device='cuda:0') tensor(1.3445e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.024189
Average KL loss: 0.365798
Average total loss: 0.389986
tensor(-13.3502, device='cuda:0') tensor(1.3014, device='cuda:0') tensor(-7.9464e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.024864
Average KL loss: 0.365753
Average total loss: 0.390617
tensor(-13.3509, device='cuda:0') tensor(1.3016, device='cuda:0') tensor(-8.3651e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.025045
Average KL loss: 0.365716
Average total loss: 0.390761
tensor(-13.3517, device='cuda:0') tensor(1.3018, device='cuda:0') tensor(4.9210e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.025482
Average KL loss: 0.365670
Average total loss: 0.391153
tensor(-13.3524, device='cuda:0') tensor(1.3019, device='cuda:0') tensor(3.4616e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.025470
Average KL loss: 0.365632
Average total loss: 0.391103
tensor(-13.3532, device='cuda:0') tensor(1.3020, device='cuda:0') tensor(-2.9391e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.026601
Average KL loss: 0.365593
Average total loss: 0.392194
tensor(-13.3540, device='cuda:0') tensor(1.3021, device='cuda:0') tensor(6.5814e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.025922
Average KL loss: 0.365562
Average total loss: 0.391484
tensor(-13.3547, device='cuda:0') tensor(1.3023, device='cuda:0') tensor(-1.4078e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.023482
Average KL loss: 0.365516
Average total loss: 0.388999
tensor(-13.3555, device='cuda:0') tensor(1.3024, device='cuda:0') tensor(-1.4745e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.025009
Average KL loss: 0.365479
Average total loss: 0.390488
tensor(-13.3562, device='cuda:0') tensor(1.3026, device='cuda:0') tensor(-5.6061e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.025059
Average KL loss: 0.365446
Average total loss: 0.390505
tensor(-13.3570, device='cuda:0') tensor(1.3027, device='cuda:0') tensor(-7.3209e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.024000
Average KL loss: 0.365414
Average total loss: 0.389415
tensor(-13.3578, device='cuda:0') tensor(1.3028, device='cuda:0') tensor(-8.2125e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.025495
Average KL loss: 0.365373
Average total loss: 0.390868
tensor(-13.3585, device='cuda:0') tensor(1.3029, device='cuda:0') tensor(-2.7101e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.024521
Average KL loss: 0.365331
Average total loss: 0.389852
tensor(-13.3593, device='cuda:0') tensor(1.3031, device='cuda:0') tensor(-6.2101e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.024226
Average KL loss: 0.365283
Average total loss: 0.389509
tensor(-13.3600, device='cuda:0') tensor(1.3032, device='cuda:0') tensor(-1.0913e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.023787
Average KL loss: 0.365236
Average total loss: 0.389022
tensor(-13.3608, device='cuda:0') tensor(1.3033, device='cuda:0') tensor(-8.2647e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.024556
Average KL loss: 0.365197
Average total loss: 0.389753
tensor(-13.3615, device='cuda:0') tensor(1.3034, device='cuda:0') tensor(2.6220e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.024770
Average KL loss: 0.365148
Average total loss: 0.389918
tensor(-13.3623, device='cuda:0') tensor(1.3035, device='cuda:0') tensor(-1.2138e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.023191
Average KL loss: 0.365108
Average total loss: 0.388300
tensor(-13.3630, device='cuda:0') tensor(1.3036, device='cuda:0') tensor(-4.3456e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.023469
Average KL loss: 0.365086
Average total loss: 0.388555
tensor(-13.3638, device='cuda:0') tensor(1.3038, device='cuda:0') tensor(-1.6321e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.024226
Average KL loss: 0.365052
Average total loss: 0.389278
tensor(-13.3645, device='cuda:0') tensor(1.3039, device='cuda:0') tensor(-3.0713e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.023294
Average KL loss: 0.365022
Average total loss: 0.388316
tensor(-13.3653, device='cuda:0') tensor(1.3041, device='cuda:0') tensor(-1.4101e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.022565
Average KL loss: 0.364983
Average total loss: 0.387548
tensor(-13.3660, device='cuda:0') tensor(1.3043, device='cuda:0') tensor(-9.8067e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.022959
Average KL loss: 0.364945
Average total loss: 0.387904
tensor(-13.3668, device='cuda:0') tensor(1.3044, device='cuda:0') tensor(1.4303e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.023494
Average KL loss: 0.364891
Average total loss: 0.388386
tensor(-13.3675, device='cuda:0') tensor(1.3045, device='cuda:0') tensor(-3.9351e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.023080
Average KL loss: 0.364845
Average total loss: 0.387926
tensor(-13.3683, device='cuda:0') tensor(1.3047, device='cuda:0') tensor(3.2093e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.023294
Average KL loss: 0.364808
Average total loss: 0.388101
tensor(-13.3690, device='cuda:0') tensor(1.3047, device='cuda:0') tensor(7.5999e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.024746
Average KL loss: 0.364777
Average total loss: 0.389524
tensor(-13.3697, device='cuda:0') tensor(1.3048, device='cuda:0') tensor(3.8139e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.022426
Average KL loss: 0.364750
Average total loss: 0.387176
tensor(-13.3705, device='cuda:0') tensor(1.3049, device='cuda:0') tensor(-1.8753e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.023001
Average KL loss: 0.364715
Average total loss: 0.387716
tensor(-13.3712, device='cuda:0') tensor(1.3050, device='cuda:0') tensor(-6.3697e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.023329
Average KL loss: 0.364685
Average total loss: 0.388014
tensor(-13.3720, device='cuda:0') tensor(1.3052, device='cuda:0') tensor(7.6291e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.023138
Average KL loss: 0.364650
Average total loss: 0.387789
tensor(-13.3727, device='cuda:0') tensor(1.3054, device='cuda:0') tensor(-2.4709e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.022535
Average KL loss: 0.364615
Average total loss: 0.387151
tensor(-13.3734, device='cuda:0') tensor(1.3055, device='cuda:0') tensor(-1.5164e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.024407
Average KL loss: 0.364573
Average total loss: 0.388980
tensor(-13.3742, device='cuda:0') tensor(1.3057, device='cuda:0') tensor(2.1509e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.023111
Average KL loss: 0.364543
Average total loss: 0.387654
tensor(-13.3749, device='cuda:0') tensor(1.3058, device='cuda:0') tensor(-5.7828e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.023901
Average KL loss: 0.364507
Average total loss: 0.388409
tensor(-13.3756, device='cuda:0') tensor(1.3060, device='cuda:0') tensor(-7.8911e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.022682
Average KL loss: 0.364467
Average total loss: 0.387149
 Percentile value: 6.46664023399353
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =     786 /    1728             ( 45.49%) | total_pruned =     942 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     631 /   36864             (  1.71%) | total_pruned =   36233 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     745 /   36864             (  2.02%) | total_pruned =   36119 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     642 /   36864             (  1.74%) | total_pruned =   36222 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     640 /   36864             (  1.74%) | total_pruned =   36224 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     985 /   73728             (  1.34%) | total_pruned =   72743 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1300 /  147456             (  0.88%) | total_pruned =  146156 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     738 /    8192             (  9.01%) | total_pruned =    7454 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     809 /  147456             (  0.55%) | total_pruned =  146647 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     694 /  147456             (  0.47%) | total_pruned =  146762 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1593 /  294912             (  0.54%) | total_pruned =  293319 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      54 /     256             ( 21.09%) | total_pruned =     202 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1871 /  589824             (  0.32%) | total_pruned =  587953 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     845 /   32768             (  2.58%) | total_pruned =   31923 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     214 /     256             ( 83.59%) | total_pruned =      42 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     703 /  589824             (  0.12%) | total_pruned =  589121 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     591 /  589824             (  0.10%) | total_pruned =  589233 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     189 /     256             ( 73.83%) | total_pruned =      67 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1453 / 1179648             (  0.12%) | total_pruned = 1178195 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     258 /     512             ( 50.39%) | total_pruned =     254 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     967 / 2359296             (  0.04%) | total_pruned = 2358329 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     294 /     512             ( 57.42%) | total_pruned =     218 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     457 /  131072             (  0.35%) | total_pruned =  130615 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     221 /     512             ( 43.16%) | total_pruned =     291 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     559 / 2359296             (  0.02%) | total_pruned = 2358737 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     107 /     512             ( 20.90%) | total_pruned =     405 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     167 / 2359296             (  0.01%) | total_pruned = 2359129 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     316 /     512             ( 61.72%) | total_pruned =     196 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    1178 /    5120             ( 23.01%) | total_pruned =    3942 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.146435 Accuracy: 78.71 98.90 % Best test Accuracy: 80.41%
tensor(-13.3764, device='cuda:0') tensor(1.3061, device='cuda:0') tensor(-9.6451e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.087851
Average KL loss: 0.362102
Average total loss: 0.449953
tensor(-13.3784, device='cuda:0') tensor(1.2623, device='cuda:0') tensor(-2.1487e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.088044
Average KL loss: 0.356783
Average total loss: 0.444827
tensor(-13.3804, device='cuda:0') tensor(1.2211, device='cuda:0') tensor(-1.6402e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.096209
Average KL loss: 0.349666
Average total loss: 0.445875
tensor(-13.3825, device='cuda:0') tensor(1.1795, device='cuda:0') tensor(-8.9870e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.101273
Average KL loss: 0.338676
Average total loss: 0.439949
tensor(-13.3846, device='cuda:0') tensor(1.1365, device='cuda:0') tensor(-2.3154e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.103232
Average KL loss: 0.320788
Average total loss: 0.424021
tensor(-13.3868, device='cuda:0') tensor(1.0938, device='cuda:0') tensor(-1.3654e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.103247
Average KL loss: 0.294597
Average total loss: 0.397844
tensor(-13.3890, device='cuda:0') tensor(1.0551, device='cuda:0') tensor(-3.9415e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.113124
Average KL loss: 0.266343
Average total loss: 0.379467
tensor(-13.3909, device='cuda:0') tensor(1.0242, device='cuda:0') tensor(-4.0849e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.110555
Average KL loss: 0.245571
Average total loss: 0.356126
tensor(-13.3926, device='cuda:0') tensor(1.0017, device='cuda:0') tensor(-3.0944e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.106428
Average KL loss: 0.233148
Average total loss: 0.339576
tensor(-13.3940, device='cuda:0') tensor(0.9853, device='cuda:0') tensor(-2.6274e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.112089
Average KL loss: 0.225766
Average total loss: 0.337855
tensor(-13.3953, device='cuda:0') tensor(0.9729, device='cuda:0') tensor(-6.1124e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.117954
Average KL loss: 0.221168
Average total loss: 0.339121
tensor(-13.3965, device='cuda:0') tensor(0.9631, device='cuda:0') tensor(-1.2459e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.112419
Average KL loss: 0.218155
Average total loss: 0.330574
tensor(-13.3976, device='cuda:0') tensor(0.9552, device='cuda:0') tensor(-2.1499e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.103523
Average KL loss: 0.216081
Average total loss: 0.319604
tensor(-13.3987, device='cuda:0') tensor(0.9484, device='cuda:0') tensor(-4.0306e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.109265
Average KL loss: 0.214571
Average total loss: 0.323836
tensor(-13.3997, device='cuda:0') tensor(0.9426, device='cuda:0') tensor(-4.0729e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.102537
Average KL loss: 0.213421
Average total loss: 0.315959
tensor(-13.4007, device='cuda:0') tensor(0.9375, device='cuda:0') tensor(-1.0434e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.103626
Average KL loss: 0.212530
Average total loss: 0.316155
tensor(-13.4016, device='cuda:0') tensor(0.9331, device='cuda:0') tensor(-5.6097e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.109098
Average KL loss: 0.211821
Average total loss: 0.320919
tensor(-13.4026, device='cuda:0') tensor(0.9291, device='cuda:0') tensor(-6.0121e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.106385
Average KL loss: 0.211242
Average total loss: 0.317626
tensor(-13.4035, device='cuda:0') tensor(0.9254, device='cuda:0') tensor(-2.8960e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.109324
Average KL loss: 0.210756
Average total loss: 0.320080
tensor(-13.4044, device='cuda:0') tensor(0.9221, device='cuda:0') tensor(-2.4109e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.110125
Average KL loss: 0.210346
Average total loss: 0.320472
tensor(-13.4053, device='cuda:0') tensor(0.9190, device='cuda:0') tensor(-6.4501e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.105663
Average KL loss: 0.209997
Average total loss: 0.315660
tensor(-13.4062, device='cuda:0') tensor(0.9162, device='cuda:0') tensor(-2.1047e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.101610
Average KL loss: 0.209696
Average total loss: 0.311306
tensor(-13.4071, device='cuda:0') tensor(0.9135, device='cuda:0') tensor(-2.4546e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.105199
Average KL loss: 0.209436
Average total loss: 0.314635
tensor(-13.4080, device='cuda:0') tensor(0.9111, device='cuda:0') tensor(-2.7836e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.099275
Average KL loss: 0.209207
Average total loss: 0.308482
tensor(-13.4088, device='cuda:0') tensor(0.9088, device='cuda:0') tensor(-3.5233e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.098872
Average KL loss: 0.209001
Average total loss: 0.307873
tensor(-13.4097, device='cuda:0') tensor(0.9066, device='cuda:0') tensor(-3.3563e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.105413
Average KL loss: 0.208817
Average total loss: 0.314229
tensor(-13.4105, device='cuda:0') tensor(0.9046, device='cuda:0') tensor(-2.8400e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.101157
Average KL loss: 0.208651
Average total loss: 0.309809
tensor(-13.4114, device='cuda:0') tensor(0.9028, device='cuda:0') tensor(-3.0341e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.101544
Average KL loss: 0.208500
Average total loss: 0.310044
tensor(-13.4122, device='cuda:0') tensor(0.9010, device='cuda:0') tensor(-3.3637e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.099923
Average KL loss: 0.208360
Average total loss: 0.308283
tensor(-13.4131, device='cuda:0') tensor(0.8992, device='cuda:0') tensor(-2.8681e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.096223
Average KL loss: 0.208229
Average total loss: 0.304452
tensor(-13.4139, device='cuda:0') tensor(0.8976, device='cuda:0') tensor(-5.2179e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.095391
Average KL loss: 0.208108
Average total loss: 0.303498
tensor(-13.4147, device='cuda:0') tensor(0.8960, device='cuda:0') tensor(-5.8523e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.091858
Average KL loss: 0.207996
Average total loss: 0.299854
tensor(-13.4155, device='cuda:0') tensor(0.8945, device='cuda:0') tensor(-5.3908e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.095743
Average KL loss: 0.207891
Average total loss: 0.303634
tensor(-13.4164, device='cuda:0') tensor(0.8931, device='cuda:0') tensor(-3.1762e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.096798
Average KL loss: 0.207793
Average total loss: 0.304591
tensor(-13.4172, device='cuda:0') tensor(0.8917, device='cuda:0') tensor(-9.0262e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.095684
Average KL loss: 0.207702
Average total loss: 0.303386
tensor(-13.4180, device='cuda:0') tensor(0.8904, device='cuda:0') tensor(-4.6415e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.094567
Average KL loss: 0.207616
Average total loss: 0.302183
tensor(-13.4188, device='cuda:0') tensor(0.8892, device='cuda:0') tensor(-4.4258e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.093690
Average KL loss: 0.207535
Average total loss: 0.301225
tensor(-13.4196, device='cuda:0') tensor(0.8880, device='cuda:0') tensor(-2.6688e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.094367
Average KL loss: 0.207460
Average total loss: 0.301827
tensor(-13.4204, device='cuda:0') tensor(0.8868, device='cuda:0') tensor(-4.8890e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.092873
Average KL loss: 0.207388
Average total loss: 0.300261
tensor(-13.4212, device='cuda:0') tensor(0.8857, device='cuda:0') tensor(-8.1843e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.094387
Average KL loss: 0.207319
Average total loss: 0.301706
tensor(-13.4220, device='cuda:0') tensor(0.8846, device='cuda:0') tensor(-3.0893e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.094179
Average KL loss: 0.207255
Average total loss: 0.301434
tensor(-13.4228, device='cuda:0') tensor(0.8836, device='cuda:0') tensor(-2.3615e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.089951
Average KL loss: 0.207195
Average total loss: 0.297146
tensor(-13.4236, device='cuda:0') tensor(0.8826, device='cuda:0') tensor(-3.8015e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.089458
Average KL loss: 0.207137
Average total loss: 0.296594
tensor(-13.4244, device='cuda:0') tensor(0.8816, device='cuda:0') tensor(-2.5861e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.090338
Average KL loss: 0.207081
Average total loss: 0.297419
tensor(-13.4252, device='cuda:0') tensor(0.8807, device='cuda:0') tensor(-2.4722e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.088100
Average KL loss: 0.207029
Average total loss: 0.295129
tensor(-13.4260, device='cuda:0') tensor(0.8798, device='cuda:0') tensor(-4.2106e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.093441
Average KL loss: 0.206980
Average total loss: 0.300421
tensor(-13.4267, device='cuda:0') tensor(0.8789, device='cuda:0') tensor(-3.4755e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.089125
Average KL loss: 0.206934
Average total loss: 0.296059
tensor(-13.4275, device='cuda:0') tensor(0.8781, device='cuda:0') tensor(-2.6749e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.091731
Average KL loss: 0.206889
Average total loss: 0.298620
tensor(-13.4283, device='cuda:0') tensor(0.8774, device='cuda:0') tensor(-2.4048e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.088997
Average KL loss: 0.206847
Average total loss: 0.295843
tensor(-13.4291, device='cuda:0') tensor(0.8766, device='cuda:0') tensor(-3.3214e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.086851
Average KL loss: 0.206808
Average total loss: 0.293659
tensor(-13.4299, device='cuda:0') tensor(0.8758, device='cuda:0') tensor(-4.9455e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.084741
Average KL loss: 0.206769
Average total loss: 0.291511
tensor(-13.4306, device='cuda:0') tensor(0.8751, device='cuda:0') tensor(-1.5121e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.086993
Average KL loss: 0.206732
Average total loss: 0.293725
tensor(-13.4314, device='cuda:0') tensor(0.8743, device='cuda:0') tensor(-7.7461e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.088243
Average KL loss: 0.206696
Average total loss: 0.294939
tensor(-13.4322, device='cuda:0') tensor(0.8736, device='cuda:0') tensor(-2.9990e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.087046
Average KL loss: 0.206662
Average total loss: 0.293708
tensor(-13.4329, device='cuda:0') tensor(0.8729, device='cuda:0') tensor(-4.7777e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.084026
Average KL loss: 0.206628
Average total loss: 0.290653
tensor(-13.4337, device='cuda:0') tensor(0.8722, device='cuda:0') tensor(-1.7240e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.085865
Average KL loss: 0.206597
Average total loss: 0.292462
tensor(-13.4345, device='cuda:0') tensor(0.8716, device='cuda:0') tensor(-8.8139e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.087065
Average KL loss: 0.206567
Average total loss: 0.293631
tensor(-13.4353, device='cuda:0') tensor(0.8710, device='cuda:0') tensor(-3.7132e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.086411
Average KL loss: 0.206537
Average total loss: 0.292947
tensor(-13.4360, device='cuda:0') tensor(0.8704, device='cuda:0') tensor(-1.7748e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.088568
Average KL loss: 0.206506
Average total loss: 0.295073
tensor(-13.4368, device='cuda:0') tensor(0.8698, device='cuda:0') tensor(-1.3177e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.083345
Average KL loss: 0.206476
Average total loss: 0.289820
tensor(-13.4376, device='cuda:0') tensor(0.8692, device='cuda:0') tensor(-2.2802e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.084246
Average KL loss: 0.206447
Average total loss: 0.290693
tensor(-13.4383, device='cuda:0') tensor(0.8686, device='cuda:0') tensor(-2.0531e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.082322
Average KL loss: 0.206419
Average total loss: 0.288741
tensor(-13.4391, device='cuda:0') tensor(0.8681, device='cuda:0') tensor(-2.9019e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.087234
Average KL loss: 0.206388
Average total loss: 0.293622
tensor(-13.4398, device='cuda:0') tensor(0.8676, device='cuda:0') tensor(-2.3329e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.084536
Average KL loss: 0.206359
Average total loss: 0.290896
tensor(-13.4406, device='cuda:0') tensor(0.8671, device='cuda:0') tensor(-3.3084e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.088101
Average KL loss: 0.206331
Average total loss: 0.294432
tensor(-13.4414, device='cuda:0') tensor(0.8665, device='cuda:0') tensor(-3.2686e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.081576
Average KL loss: 0.206301
Average total loss: 0.287878
tensor(-13.4421, device='cuda:0') tensor(0.8660, device='cuda:0') tensor(-1.2456e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.084424
Average KL loss: 0.206273
Average total loss: 0.290697
tensor(-13.4429, device='cuda:0') tensor(0.8655, device='cuda:0') tensor(-2.4565e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.084979
Average KL loss: 0.206246
Average total loss: 0.291225
tensor(-13.4436, device='cuda:0') tensor(0.8651, device='cuda:0') tensor(-1.6113e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.082086
Average KL loss: 0.206220
Average total loss: 0.288306
tensor(-13.4444, device='cuda:0') tensor(0.8646, device='cuda:0') tensor(-1.8594e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.081042
Average KL loss: 0.206196
Average total loss: 0.287238
tensor(-13.4451, device='cuda:0') tensor(0.8642, device='cuda:0') tensor(-1.2625e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.083564
Average KL loss: 0.206172
Average total loss: 0.289736
tensor(-13.4459, device='cuda:0') tensor(0.8637, device='cuda:0') tensor(-2.1170e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.077494
Average KL loss: 0.206147
Average total loss: 0.283640
tensor(-13.4466, device='cuda:0') tensor(0.8633, device='cuda:0') tensor(-1.3973e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.078272
Average KL loss: 0.206125
Average total loss: 0.284396
tensor(-13.4474, device='cuda:0') tensor(0.8629, device='cuda:0') tensor(-1.2673e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.080078
Average KL loss: 0.206101
Average total loss: 0.286179
tensor(-13.4481, device='cuda:0') tensor(0.8625, device='cuda:0') tensor(-2.1188e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.076169
Average KL loss: 0.206078
Average total loss: 0.282247
tensor(-13.4489, device='cuda:0') tensor(0.8620, device='cuda:0') tensor(-5.1684e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.079864
Average KL loss: 0.206056
Average total loss: 0.285920
tensor(-13.4496, device='cuda:0') tensor(0.8617, device='cuda:0') tensor(-3.2650e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.083055
Average KL loss: 0.206036
Average total loss: 0.289091
tensor(-13.4504, device='cuda:0') tensor(0.8613, device='cuda:0') tensor(-1.5630e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.085533
Average KL loss: 0.206017
Average total loss: 0.291550
tensor(-13.4511, device='cuda:0') tensor(0.8609, device='cuda:0') tensor(-1.1253e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.079384
Average KL loss: 0.205996
Average total loss: 0.285381
tensor(-13.4519, device='cuda:0') tensor(0.8605, device='cuda:0') tensor(-1.6550e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.079678
Average KL loss: 0.205978
Average total loss: 0.285656
tensor(-13.4526, device='cuda:0') tensor(0.8602, device='cuda:0') tensor(-2.2208e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.078474
Average KL loss: 0.205959
Average total loss: 0.284433
tensor(-13.4534, device='cuda:0') tensor(0.8598, device='cuda:0') tensor(-1.7465e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.078856
Average KL loss: 0.205938
Average total loss: 0.284793
tensor(-13.4541, device='cuda:0') tensor(0.8594, device='cuda:0') tensor(-2.7930e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.075803
Average KL loss: 0.205917
Average total loss: 0.281720
tensor(-13.4549, device='cuda:0') tensor(0.8591, device='cuda:0') tensor(-8.8159e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.075002
Average KL loss: 0.205898
Average total loss: 0.280899
tensor(-13.4556, device='cuda:0') tensor(0.8587, device='cuda:0') tensor(-6.0770e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.075728
Average KL loss: 0.205880
Average total loss: 0.281607
tensor(-13.4563, device='cuda:0') tensor(0.8584, device='cuda:0') tensor(-1.1830e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.078430
Average KL loss: 0.205861
Average total loss: 0.284291
tensor(-13.4571, device='cuda:0') tensor(0.8581, device='cuda:0') tensor(-6.3520e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.076738
Average KL loss: 0.205841
Average total loss: 0.282578
tensor(-13.4578, device='cuda:0') tensor(0.8578, device='cuda:0') tensor(-1.2647e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.077363
Average KL loss: 0.205820
Average total loss: 0.283183
tensor(-13.4585, device='cuda:0') tensor(0.8575, device='cuda:0') tensor(-2.8834e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.077679
Average KL loss: 0.205801
Average total loss: 0.283481
tensor(-13.4593, device='cuda:0') tensor(0.8572, device='cuda:0') tensor(-3.2541e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.075912
Average KL loss: 0.205783
Average total loss: 0.281695
tensor(-13.4600, device='cuda:0') tensor(0.8568, device='cuda:0') tensor(-2.7906e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.075060
Average KL loss: 0.205763
Average total loss: 0.280823
tensor(-13.4608, device='cuda:0') tensor(0.8565, device='cuda:0') tensor(-6.0452e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.075074
Average KL loss: 0.205743
Average total loss: 0.280816
tensor(-13.4615, device='cuda:0') tensor(0.8562, device='cuda:0') tensor(-2.7158e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.076325
Average KL loss: 0.205724
Average total loss: 0.282049
tensor(-13.4622, device='cuda:0') tensor(0.8559, device='cuda:0') tensor(-5.5435e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.077586
Average KL loss: 0.205707
Average total loss: 0.283293
tensor(-13.4629, device='cuda:0') tensor(0.8556, device='cuda:0') tensor(-5.3614e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.073045
Average KL loss: 0.205690
Average total loss: 0.278735
tensor(-13.4637, device='cuda:0') tensor(0.8553, device='cuda:0') tensor(-1.3462e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.074191
Average KL loss: 0.205672
Average total loss: 0.279863
tensor(-13.4644, device='cuda:0') tensor(0.8550, device='cuda:0') tensor(-3.3637e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.075223
Average KL loss: 0.205655
Average total loss: 0.280877
tensor(-13.4651, device='cuda:0') tensor(0.8548, device='cuda:0') tensor(-4.8930e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.074222
Average KL loss: 0.205636
Average total loss: 0.279858
tensor(-13.4659, device='cuda:0') tensor(0.8545, device='cuda:0') tensor(-2.6570e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.072467
Average KL loss: 0.205619
Average total loss: 0.278086
tensor(-13.4666, device='cuda:0') tensor(0.8543, device='cuda:0') tensor(-2.6683e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.071034
Average KL loss: 0.205602
Average total loss: 0.276636
tensor(-13.4673, device='cuda:0') tensor(0.8540, device='cuda:0') tensor(-2.5160e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.069474
Average KL loss: 0.205585
Average total loss: 0.275059
tensor(-13.4680, device='cuda:0') tensor(0.8537, device='cuda:0') tensor(-8.5575e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.071655
Average KL loss: 0.205568
Average total loss: 0.277223
tensor(-13.4687, device='cuda:0') tensor(0.8535, device='cuda:0') tensor(-3.9185e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.071089
Average KL loss: 0.205554
Average total loss: 0.276643
tensor(-13.4695, device='cuda:0') tensor(0.8532, device='cuda:0') tensor(-4.5118e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.069219
Average KL loss: 0.205538
Average total loss: 0.274757
tensor(-13.4702, device='cuda:0') tensor(0.8529, device='cuda:0') tensor(-8.8911e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.073195
Average KL loss: 0.205520
Average total loss: 0.278715
tensor(-13.4709, device='cuda:0') tensor(0.8527, device='cuda:0') tensor(-1.8659e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.069923
Average KL loss: 0.205501
Average total loss: 0.275424
tensor(-13.4716, device='cuda:0') tensor(0.8525, device='cuda:0') tensor(-3.6527e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.070701
Average KL loss: 0.205483
Average total loss: 0.276184
tensor(-13.4723, device='cuda:0') tensor(0.8523, device='cuda:0') tensor(-8.5829e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.067349
Average KL loss: 0.205462
Average total loss: 0.272811
tensor(-13.4731, device='cuda:0') tensor(0.8520, device='cuda:0') tensor(-2.6524e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.072408
Average KL loss: 0.205441
Average total loss: 0.277849
tensor(-13.4738, device='cuda:0') tensor(0.8518, device='cuda:0') tensor(-9.4655e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.070153
Average KL loss: 0.205419
Average total loss: 0.275572
tensor(-13.4745, device='cuda:0') tensor(0.8516, device='cuda:0') tensor(-1.1583e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.071190
Average KL loss: 0.205397
Average total loss: 0.276587
tensor(-13.4752, device='cuda:0') tensor(0.8513, device='cuda:0') tensor(-9.6564e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.071896
Average KL loss: 0.205377
Average total loss: 0.277272
tensor(-13.4759, device='cuda:0') tensor(0.8511, device='cuda:0') tensor(-2.6077e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.069517
Average KL loss: 0.205357
Average total loss: 0.274875
tensor(-13.4766, device='cuda:0') tensor(0.8508, device='cuda:0') tensor(-2.2626e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.074322
Average KL loss: 0.205336
Average total loss: 0.279657
tensor(-13.4773, device='cuda:0') tensor(0.8507, device='cuda:0') tensor(-2.5258e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.070813
Average KL loss: 0.205315
Average total loss: 0.276128
tensor(-13.4781, device='cuda:0') tensor(0.8505, device='cuda:0') tensor(-1.8731e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.068113
Average KL loss: 0.205297
Average total loss: 0.273410
tensor(-13.4788, device='cuda:0') tensor(0.8503, device='cuda:0') tensor(-2.1963e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.069706
Average KL loss: 0.205278
Average total loss: 0.274984
tensor(-13.4795, device='cuda:0') tensor(0.8502, device='cuda:0') tensor(-1.1401e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.070344
Average KL loss: 0.205259
Average total loss: 0.275603
tensor(-13.4802, device='cuda:0') tensor(0.8500, device='cuda:0') tensor(-7.2167e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.072236
Average KL loss: 0.205242
Average total loss: 0.277478
tensor(-13.4809, device='cuda:0') tensor(0.8498, device='cuda:0') tensor(-1.2857e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.070656
Average KL loss: 0.205232
Average total loss: 0.275888
tensor(-13.4809, device='cuda:0') tensor(0.8498, device='cuda:0') tensor(-2.5582e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.072818
Average KL loss: 0.205230
Average total loss: 0.278048
tensor(-13.4810, device='cuda:0') tensor(0.8498, device='cuda:0') tensor(-5.9889e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.066843
Average KL loss: 0.205229
Average total loss: 0.272072
tensor(-13.4811, device='cuda:0') tensor(0.8497, device='cuda:0') tensor(-9.9710e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.066744
Average KL loss: 0.205227
Average total loss: 0.271971
tensor(-13.4811, device='cuda:0') tensor(0.8497, device='cuda:0') tensor(-1.6399e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.067743
Average KL loss: 0.205226
Average total loss: 0.272969
tensor(-13.4812, device='cuda:0') tensor(0.8497, device='cuda:0') tensor(-8.6986e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.068727
Average KL loss: 0.205224
Average total loss: 0.273951
tensor(-13.4813, device='cuda:0') tensor(0.8497, device='cuda:0') tensor(-4.5776e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.068567
Average KL loss: 0.205222
Average total loss: 0.273789
tensor(-13.4813, device='cuda:0') tensor(0.8496, device='cuda:0') tensor(-2.4544e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.068491
Average KL loss: 0.205221
Average total loss: 0.273712
tensor(-13.4814, device='cuda:0') tensor(0.8496, device='cuda:0') tensor(-2.7058e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.073232
Average KL loss: 0.205220
Average total loss: 0.278452
tensor(-13.4814, device='cuda:0') tensor(0.8496, device='cuda:0') tensor(-5.1763e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.068439
Average KL loss: 0.205218
Average total loss: 0.273657
tensor(-13.4815, device='cuda:0') tensor(0.8495, device='cuda:0') tensor(-3.3103e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.071558
Average KL loss: 0.205217
Average total loss: 0.276774
tensor(-13.4816, device='cuda:0') tensor(0.8495, device='cuda:0') tensor(-1.3666e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.067623
Average KL loss: 0.205215
Average total loss: 0.272838
tensor(-13.4816, device='cuda:0') tensor(0.8495, device='cuda:0') tensor(-5.1792e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.066843
Average KL loss: 0.205213
Average total loss: 0.272057
tensor(-13.4817, device='cuda:0') tensor(0.8495, device='cuda:0') tensor(-4.4215e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.073610
Average KL loss: 0.205212
Average total loss: 0.278821
tensor(-13.4818, device='cuda:0') tensor(0.8494, device='cuda:0') tensor(-1.8760e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.067652
Average KL loss: 0.205210
Average total loss: 0.272863
tensor(-13.4818, device='cuda:0') tensor(0.8494, device='cuda:0') tensor(-4.6717e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.069770
Average KL loss: 0.205209
Average total loss: 0.274979
tensor(-13.4818, device='cuda:0') tensor(0.8494, device='cuda:0') tensor(-6.3063e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.071291
Average KL loss: 0.205209
Average total loss: 0.276500
tensor(-13.4818, device='cuda:0') tensor(0.8494, device='cuda:0') tensor(-1.0533e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.068701
Average KL loss: 0.205209
Average total loss: 0.273910
tensor(-13.4818, device='cuda:0') tensor(0.8494, device='cuda:0') tensor(-1.3276e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.075445
Average KL loss: 0.205209
Average total loss: 0.280654
tensor(-13.4818, device='cuda:0') tensor(0.8494, device='cuda:0') tensor(-1.4181e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.072675
Average KL loss: 0.205209
Average total loss: 0.277884
tensor(-13.4818, device='cuda:0') tensor(0.8494, device='cuda:0') tensor(-2.8951e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.072894
Average KL loss: 0.205209
Average total loss: 0.278103
tensor(-13.4818, device='cuda:0') tensor(0.8494, device='cuda:0') tensor(-1.9517e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.070769
Average KL loss: 0.205209
Average total loss: 0.275978
tensor(-13.4818, device='cuda:0') tensor(0.8494, device='cuda:0') tensor(-7.9979e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.068762
Average KL loss: 0.205208
Average total loss: 0.273971
tensor(-13.4818, device='cuda:0') tensor(0.8494, device='cuda:0') tensor(-2.1347e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.066447
Average KL loss: 0.205208
Average total loss: 0.271655
tensor(-13.4818, device='cuda:0') tensor(0.8494, device='cuda:0') tensor(-6.0136e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.067612
Average KL loss: 0.205208
Average total loss: 0.272820
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-8.8677e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.072567
Average KL loss: 0.205208
Average total loss: 0.277775
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-1.5651e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.072557
Average KL loss: 0.205208
Average total loss: 0.277765
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-2.5762e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.071410
Average KL loss: 0.205208
Average total loss: 0.276618
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-7.6195e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.067097
Average KL loss: 0.205208
Average total loss: 0.272304
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-1.0337e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.069609
Average KL loss: 0.205207
Average total loss: 0.274816
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-1.5311e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.070846
Average KL loss: 0.205207
Average total loss: 0.276053
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-7.0514e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.067461
Average KL loss: 0.205207
Average total loss: 0.272668
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-2.2277e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.070974
Average KL loss: 0.205207
Average total loss: 0.276181
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-1.5659e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.070284
Average KL loss: 0.205207
Average total loss: 0.275490
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-2.2316e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.073243
Average KL loss: 0.205207
Average total loss: 0.278449
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-5.3635e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.069275
Average KL loss: 0.205206
Average total loss: 0.274481
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-3.2494e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.068582
Average KL loss: 0.205206
Average total loss: 0.273788
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-3.0932e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.071885
Average KL loss: 0.205206
Average total loss: 0.277091
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-2.3117e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.068398
Average KL loss: 0.205206
Average total loss: 0.273604
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-8.6063e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.069374
Average KL loss: 0.205206
Average total loss: 0.274580
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-8.3584e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.068990
Average KL loss: 0.205206
Average total loss: 0.274197
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-4.9955e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.073255
Average KL loss: 0.205206
Average total loss: 0.278461
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-2.6314e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.066666
Average KL loss: 0.205206
Average total loss: 0.271872
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-4.3586e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.069949
Average KL loss: 0.205206
Average total loss: 0.275156
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-6.1152e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.067254
Average KL loss: 0.205206
Average total loss: 0.272460
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-3.1057e-09, device='cuda:0')
 Percentile value: 7.2101898193359375
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =     620 /    1728             ( 35.88%) | total_pruned =    1108 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
bn1.bias             | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     366 /   36864             (  0.99%) | total_pruned =   36498 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     421 /   36864             (  1.14%) | total_pruned =   36443 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     357 /   36864             (  0.97%) | total_pruned =   36507 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     377 /   36864             (  1.02%) | total_pruned =   36487 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     538 /   73728             (  0.73%) | total_pruned =   73190 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     613 /  147456             (  0.42%) | total_pruned =  146843 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     380 /    8192             (  4.64%) | total_pruned =    7812 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     431 /  147456             (  0.29%) | total_pruned =  147025 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     346 /  147456             (  0.23%) | total_pruned =  147110 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     704 /  294912             (  0.24%) | total_pruned =  294208 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     703 /  589824             (  0.12%) | total_pruned =  589121 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     199 /     256             ( 77.73%) | total_pruned =      57 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     347 /   32768             (  1.06%) | total_pruned =   32421 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     317 /  589824             (  0.05%) | total_pruned =  589507 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      81 /     256             ( 31.64%) | total_pruned =     175 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     244 /  589824             (  0.04%) | total_pruned =  589580 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     504 / 1179648             (  0.04%) | total_pruned = 1179144 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     180 /     512             ( 35.16%) | total_pruned =     332 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     318 / 2359296             (  0.01%) | total_pruned = 2358978 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     158 /  131072             (  0.12%) | total_pruned =  130914 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     109 /     512             ( 21.29%) | total_pruned =     403 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     203 / 2359296             (  0.01%) | total_pruned = 2359093 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      36 /     512             (  7.03%) | total_pruned =     476 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      39 / 2359296             (  0.00%) | total_pruned = 2359257 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     517 /    5120             ( 10.10%) | total_pruned =    4603 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.777782 Accuracy: 70.51 79.94 % Best test Accuracy: 70.89%
tensor(-13.4818, device='cuda:0') tensor(0.8493, device='cuda:0') tensor(-2.2898e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.606186
Average KL loss: 0.205052
Average total loss: 0.811237
tensor(-13.4832, device='cuda:0') tensor(0.8274, device='cuda:0') tensor(-1.6604e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.605557
Average KL loss: 0.204640
Average total loss: 0.810197
tensor(-13.4846, device='cuda:0') tensor(0.8040, device='cuda:0') tensor(-2.5202e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.607258
Average KL loss: 0.203938
Average total loss: 0.811196
tensor(-13.4861, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(1.1986e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.614293
Average KL loss: 0.202528
Average total loss: 0.816822
tensor(-13.4877, device='cuda:0') tensor(0.7476, device='cuda:0') tensor(-4.8200e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.612118
Average KL loss: 0.199347
Average total loss: 0.811465
tensor(-13.4895, device='cuda:0') tensor(0.7127, device='cuda:0') tensor(-1.2690e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.620478
Average KL loss: 0.191978
Average total loss: 0.812455
tensor(-13.4915, device='cuda:0') tensor(0.6744, device='cuda:0') tensor(-6.6971e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.618744
Average KL loss: 0.176800
Average total loss: 0.795544
tensor(-13.4935, device='cuda:0') tensor(0.6361, device='cuda:0') tensor(-2.5608e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.622398
Average KL loss: 0.153713
Average total loss: 0.776110
tensor(-13.4954, device='cuda:0') tensor(0.6034, device='cuda:0') tensor(-1.3745e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.646181
Average KL loss: 0.131669
Average total loss: 0.777849
tensor(-13.4970, device='cuda:0') tensor(0.5792, device='cuda:0') tensor(7.8952e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.623025
Average KL loss: 0.117705
Average total loss: 0.740730
tensor(-13.4984, device='cuda:0') tensor(0.5622, device='cuda:0') tensor(-2.8873e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.638280
Average KL loss: 0.109791
Average total loss: 0.748071
tensor(-13.4996, device='cuda:0') tensor(0.5499, device='cuda:0') tensor(-2.7621e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.635915
Average KL loss: 0.105033
Average total loss: 0.740948
tensor(-13.5007, device='cuda:0') tensor(0.5406, device='cuda:0') tensor(-2.0980e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.630499
Average KL loss: 0.101995
Average total loss: 0.732494
tensor(-13.5018, device='cuda:0') tensor(0.5333, device='cuda:0') tensor(-2.5980e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.630001
Average KL loss: 0.100011
Average total loss: 0.730012
tensor(-13.5027, device='cuda:0') tensor(0.5273, device='cuda:0') tensor(-1.5104e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.623582
Average KL loss: 0.098667
Average total loss: 0.722249
tensor(-13.5037, device='cuda:0') tensor(0.5222, device='cuda:0') tensor(-1.4143e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.620670
Average KL loss: 0.097704
Average total loss: 0.718374
tensor(-13.5046, device='cuda:0') tensor(0.5178, device='cuda:0') tensor(-2.4506e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.621085
Average KL loss: 0.096991
Average total loss: 0.718076
tensor(-13.5055, device='cuda:0') tensor(0.5141, device='cuda:0') tensor(-1.4945e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.631126
Average KL loss: 0.096450
Average total loss: 0.727576
tensor(-13.5063, device='cuda:0') tensor(0.5107, device='cuda:0') tensor(-4.2854e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.625855
Average KL loss: 0.096018
Average total loss: 0.721873
tensor(-13.5072, device='cuda:0') tensor(0.5076, device='cuda:0') tensor(-2.5297e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.625930
Average KL loss: 0.095666
Average total loss: 0.721597
tensor(-13.5080, device='cuda:0') tensor(0.5048, device='cuda:0') tensor(-2.7624e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.625099
Average KL loss: 0.095380
Average total loss: 0.720479
tensor(-13.5089, device='cuda:0') tensor(0.5022, device='cuda:0') tensor(-5.8709e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.617609
Average KL loss: 0.095134
Average total loss: 0.712743
tensor(-13.5097, device='cuda:0') tensor(0.4998, device='cuda:0') tensor(-3.4727e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.617076
Average KL loss: 0.094921
Average total loss: 0.711997
tensor(-13.5105, device='cuda:0') tensor(0.4976, device='cuda:0') tensor(-2.2879e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.618558
Average KL loss: 0.094746
Average total loss: 0.713304
tensor(-13.5113, device='cuda:0') tensor(0.4956, device='cuda:0') tensor(-3.1147e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.619273
Average KL loss: 0.094596
Average total loss: 0.713869
tensor(-13.5121, device='cuda:0') tensor(0.4936, device='cuda:0') tensor(-2.1714e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.629501
Average KL loss: 0.094461
Average total loss: 0.723962
tensor(-13.5129, device='cuda:0') tensor(0.4917, device='cuda:0') tensor(-1.3747e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.620115
Average KL loss: 0.094340
Average total loss: 0.714455
tensor(-13.5136, device='cuda:0') tensor(0.4900, device='cuda:0') tensor(-1.9708e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.623552
Average KL loss: 0.094234
Average total loss: 0.717786
tensor(-13.5144, device='cuda:0') tensor(0.4883, device='cuda:0') tensor(-4.1202e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.621361
Average KL loss: 0.094137
Average total loss: 0.715498
tensor(-13.5152, device='cuda:0') tensor(0.4867, device='cuda:0') tensor(-4.0565e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.614646
Average KL loss: 0.094051
Average total loss: 0.708697
tensor(-13.5160, device='cuda:0') tensor(0.4852, device='cuda:0') tensor(-5.5747e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.615031
Average KL loss: 0.093972
Average total loss: 0.709002
tensor(-13.5167, device='cuda:0') tensor(0.4838, device='cuda:0') tensor(-5.0930e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.613288
Average KL loss: 0.093897
Average total loss: 0.707185
tensor(-13.5175, device='cuda:0') tensor(0.4824, device='cuda:0') tensor(-9.4997e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.613395
Average KL loss: 0.093827
Average total loss: 0.707222
tensor(-13.5182, device='cuda:0') tensor(0.4811, device='cuda:0') tensor(-2.4917e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.614038
Average KL loss: 0.093765
Average total loss: 0.707803
tensor(-13.5190, device='cuda:0') tensor(0.4798, device='cuda:0') tensor(-3.9535e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.616805
Average KL loss: 0.093705
Average total loss: 0.710511
tensor(-13.5197, device='cuda:0') tensor(0.4785, device='cuda:0') tensor(-2.6987e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.619366
Average KL loss: 0.093647
Average total loss: 0.713014
tensor(-13.5205, device='cuda:0') tensor(0.4773, device='cuda:0') tensor(-2.4554e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.620386
Average KL loss: 0.093596
Average total loss: 0.713982
tensor(-13.5212, device='cuda:0') tensor(0.4762, device='cuda:0') tensor(-4.1262e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.621594
Average KL loss: 0.093549
Average total loss: 0.715143
tensor(-13.5220, device='cuda:0') tensor(0.4750, device='cuda:0') tensor(-5.2011e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.619321
Average KL loss: 0.093502
Average total loss: 0.712823
tensor(-13.5227, device='cuda:0') tensor(0.4740, device='cuda:0') tensor(-1.7044e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.618192
Average KL loss: 0.093461
Average total loss: 0.711653
tensor(-13.5234, device='cuda:0') tensor(0.4729, device='cuda:0') tensor(-1.6702e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.614398
Average KL loss: 0.093423
Average total loss: 0.707821
tensor(-13.5242, device='cuda:0') tensor(0.4719, device='cuda:0') tensor(-3.0090e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.610264
Average KL loss: 0.093388
Average total loss: 0.703653
tensor(-13.5249, device='cuda:0') tensor(0.4710, device='cuda:0') tensor(-2.7973e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.617141
Average KL loss: 0.093353
Average total loss: 0.710493
tensor(-13.5256, device='cuda:0') tensor(0.4700, device='cuda:0') tensor(-7.5991e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.617925
Average KL loss: 0.093319
Average total loss: 0.711243
tensor(-13.5264, device='cuda:0') tensor(0.4691, device='cuda:0') tensor(-1.0164e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.619423
Average KL loss: 0.093285
Average total loss: 0.712709
tensor(-13.5271, device='cuda:0') tensor(0.4682, device='cuda:0') tensor(-8.6360e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.613525
Average KL loss: 0.093252
Average total loss: 0.706778
tensor(-13.5278, device='cuda:0') tensor(0.4673, device='cuda:0') tensor(-1.7254e-11, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.614880
Average KL loss: 0.093222
Average total loss: 0.708102
tensor(-13.5285, device='cuda:0') tensor(0.4665, device='cuda:0') tensor(-2.4682e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.614937
Average KL loss: 0.093193
Average total loss: 0.708130
tensor(-13.5293, device='cuda:0') tensor(0.4657, device='cuda:0') tensor(-1.9362e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.613490
Average KL loss: 0.093167
Average total loss: 0.706657
tensor(-13.5300, device='cuda:0') tensor(0.4649, device='cuda:0') tensor(-5.8063e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.613111
Average KL loss: 0.093139
Average total loss: 0.706250
tensor(-13.5307, device='cuda:0') tensor(0.4641, device='cuda:0') tensor(-1.3689e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.614578
Average KL loss: 0.093115
Average total loss: 0.707694
tensor(-13.5314, device='cuda:0') tensor(0.4634, device='cuda:0') tensor(-5.8437e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.613772
Average KL loss: 0.093090
Average total loss: 0.706862
tensor(-13.5321, device='cuda:0') tensor(0.4626, device='cuda:0') tensor(-3.1692e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.608827
Average KL loss: 0.093066
Average total loss: 0.701893
tensor(-13.5328, device='cuda:0') tensor(0.4619, device='cuda:0') tensor(-3.0976e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.607410
Average KL loss: 0.093041
Average total loss: 0.700451
tensor(-13.5336, device='cuda:0') tensor(0.4612, device='cuda:0') tensor(-4.3049e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.614801
Average KL loss: 0.093017
Average total loss: 0.707818
tensor(-13.5343, device='cuda:0') tensor(0.4605, device='cuda:0') tensor(-2.3031e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.613005
Average KL loss: 0.092993
Average total loss: 0.705998
tensor(-13.5350, device='cuda:0') tensor(0.4598, device='cuda:0') tensor(-2.8928e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.612823
Average KL loss: 0.092971
Average total loss: 0.705794
tensor(-13.5357, device='cuda:0') tensor(0.4591, device='cuda:0') tensor(-5.1214e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.611211
Average KL loss: 0.092950
Average total loss: 0.704161
tensor(-13.5364, device='cuda:0') tensor(0.4585, device='cuda:0') tensor(-2.4474e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.610611
Average KL loss: 0.092930
Average total loss: 0.703542
tensor(-13.5371, device='cuda:0') tensor(0.4578, device='cuda:0') tensor(-7.3314e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.610569
Average KL loss: 0.092911
Average total loss: 0.703481
tensor(-13.5378, device='cuda:0') tensor(0.4571, device='cuda:0') tensor(-2.7324e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.616394
Average KL loss: 0.092892
Average total loss: 0.709286
tensor(-13.5385, device='cuda:0') tensor(0.4565, device='cuda:0') tensor(-1.7016e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.612130
Average KL loss: 0.092874
Average total loss: 0.705004
tensor(-13.5392, device='cuda:0') tensor(0.4559, device='cuda:0') tensor(-3.9816e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.614531
Average KL loss: 0.092857
Average total loss: 0.707388
tensor(-13.5399, device='cuda:0') tensor(0.4554, device='cuda:0') tensor(-1.5709e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.610690
Average KL loss: 0.092838
Average total loss: 0.703528
tensor(-13.5406, device='cuda:0') tensor(0.4548, device='cuda:0') tensor(-1.8592e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.611418
Average KL loss: 0.092818
Average total loss: 0.704236
tensor(-13.5413, device='cuda:0') tensor(0.4542, device='cuda:0') tensor(-9.9213e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.612567
Average KL loss: 0.092807
Average total loss: 0.705374
tensor(-13.5414, device='cuda:0') tensor(0.4542, device='cuda:0') tensor(-4.0092e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.613555
Average KL loss: 0.092805
Average total loss: 0.706360
tensor(-13.5414, device='cuda:0') tensor(0.4541, device='cuda:0') tensor(-1.4736e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.606844
Average KL loss: 0.092804
Average total loss: 0.699647
tensor(-13.5415, device='cuda:0') tensor(0.4540, device='cuda:0') tensor(-1.0199e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.615959
Average KL loss: 0.092802
Average total loss: 0.708761
tensor(-13.5415, device='cuda:0') tensor(0.4540, device='cuda:0') tensor(-1.0362e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.606210
Average KL loss: 0.092800
Average total loss: 0.699010
tensor(-13.5416, device='cuda:0') tensor(0.4539, device='cuda:0') tensor(-1.2302e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.608325
Average KL loss: 0.092798
Average total loss: 0.701123
tensor(-13.5417, device='cuda:0') tensor(0.4538, device='cuda:0') tensor(-6.3857e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.611479
Average KL loss: 0.092797
Average total loss: 0.704276
tensor(-13.5417, device='cuda:0') tensor(0.4538, device='cuda:0') tensor(-4.2529e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.605639
Average KL loss: 0.092795
Average total loss: 0.698435
tensor(-13.5418, device='cuda:0') tensor(0.4537, device='cuda:0') tensor(-1.1395e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.609158
Average KL loss: 0.092794
Average total loss: 0.701952
tensor(-13.5419, device='cuda:0') tensor(0.4536, device='cuda:0') tensor(-4.5618e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.607677
Average KL loss: 0.092792
Average total loss: 0.700469
tensor(-13.5419, device='cuda:0') tensor(0.4536, device='cuda:0') tensor(-1.0333e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.613585
Average KL loss: 0.092791
Average total loss: 0.706375
tensor(-13.5420, device='cuda:0') tensor(0.4535, device='cuda:0') tensor(9.1727e-12, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.606802
Average KL loss: 0.092789
Average total loss: 0.699591
tensor(-13.5420, device='cuda:0') tensor(0.4534, device='cuda:0') tensor(-3.4375e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.617613
Average KL loss: 0.092788
Average total loss: 0.710401
tensor(-13.5421, device='cuda:0') tensor(0.4534, device='cuda:0') tensor(9.2548e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.612342
Average KL loss: 0.092786
Average total loss: 0.705129
tensor(-13.5422, device='cuda:0') tensor(0.4533, device='cuda:0') tensor(-1.3789e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.608281
Average KL loss: 0.092784
Average total loss: 0.701065
tensor(-13.5422, device='cuda:0') tensor(0.4532, device='cuda:0') tensor(-2.8984e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.605131
Average KL loss: 0.092783
Average total loss: 0.697914
tensor(-13.5423, device='cuda:0') tensor(0.4531, device='cuda:0') tensor(-7.5237e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.610051
Average KL loss: 0.092781
Average total loss: 0.702833
tensor(-13.5424, device='cuda:0') tensor(0.4531, device='cuda:0') tensor(-5.6845e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.605346
Average KL loss: 0.092780
Average total loss: 0.698126
tensor(-13.5424, device='cuda:0') tensor(0.4530, device='cuda:0') tensor(-1.3508e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.612371
Average KL loss: 0.092778
Average total loss: 0.705149
tensor(-13.5425, device='cuda:0') tensor(0.4529, device='cuda:0') tensor(-3.9790e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.608739
Average KL loss: 0.092777
Average total loss: 0.701516
tensor(-13.5426, device='cuda:0') tensor(0.4528, device='cuda:0') tensor(-2.4166e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.609440
Average KL loss: 0.092775
Average total loss: 0.702215
tensor(-13.5426, device='cuda:0') tensor(0.4527, device='cuda:0') tensor(-7.9124e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.605263
Average KL loss: 0.092774
Average total loss: 0.698037
tensor(-13.5427, device='cuda:0') tensor(0.4527, device='cuda:0') tensor(3.8831e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.610915
Average KL loss: 0.092772
Average total loss: 0.703687
tensor(-13.5427, device='cuda:0') tensor(0.4526, device='cuda:0') tensor(-3.4226e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.611058
Average KL loss: 0.092770
Average total loss: 0.703828
tensor(-13.5428, device='cuda:0') tensor(0.4525, device='cuda:0') tensor(-2.5125e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.608454
Average KL loss: 0.092769
Average total loss: 0.701223
tensor(-13.5429, device='cuda:0') tensor(0.4524, device='cuda:0') tensor(-2.3024e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.605747
Average KL loss: 0.092767
Average total loss: 0.698514
tensor(-13.5429, device='cuda:0') tensor(0.4523, device='cuda:0') tensor(-1.6918e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.607305
Average KL loss: 0.092766
Average total loss: 0.700071
tensor(-13.5430, device='cuda:0') tensor(0.4522, device='cuda:0') tensor(-2.2910e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.608110
Average KL loss: 0.092765
Average total loss: 0.700875
tensor(-13.5430, device='cuda:0') tensor(0.4522, device='cuda:0') tensor(-3.9059e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.608659
Average KL loss: 0.092765
Average total loss: 0.701424
tensor(-13.5430, device='cuda:0') tensor(0.4522, device='cuda:0') tensor(-1.5826e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.607049
Average KL loss: 0.092764
Average total loss: 0.699813
tensor(-13.5430, device='cuda:0') tensor(0.4522, device='cuda:0') tensor(-2.4779e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.609221
Average KL loss: 0.092764
Average total loss: 0.701985
tensor(-13.5430, device='cuda:0') tensor(0.4522, device='cuda:0') tensor(-4.0618e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.607790
Average KL loss: 0.092764
Average total loss: 0.700554
tensor(-13.5430, device='cuda:0') tensor(0.4522, device='cuda:0') tensor(-9.3481e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.607618
Average KL loss: 0.092764
Average total loss: 0.700382
tensor(-13.5430, device='cuda:0') tensor(0.4522, device='cuda:0') tensor(-5.0062e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.606154
Average KL loss: 0.092764
Average total loss: 0.698917
tensor(-13.5430, device='cuda:0') tensor(0.4522, device='cuda:0') tensor(-4.2625e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.610217
Average KL loss: 0.092764
Average total loss: 0.702981
tensor(-13.5430, device='cuda:0') tensor(0.4521, device='cuda:0') tensor(-4.5771e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.604772
Average KL loss: 0.092763
Average total loss: 0.697536
tensor(-13.5430, device='cuda:0') tensor(0.4521, device='cuda:0') tensor(-1.8417e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.615140
Average KL loss: 0.092763
Average total loss: 0.707903
tensor(-13.5430, device='cuda:0') tensor(0.4521, device='cuda:0') tensor(-1.0568e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.608794
Average KL loss: 0.092763
Average total loss: 0.701557
tensor(-13.5430, device='cuda:0') tensor(0.4521, device='cuda:0') tensor(-8.3229e-11, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.605781
Average KL loss: 0.092763
Average total loss: 0.698544
tensor(-13.5430, device='cuda:0') tensor(0.4521, device='cuda:0') tensor(1.5846e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.612037
Average KL loss: 0.092763
Average total loss: 0.704800
tensor(-13.5430, device='cuda:0') tensor(0.4521, device='cuda:0') tensor(-1.3071e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.611768
Average KL loss: 0.092762
Average total loss: 0.704531
tensor(-13.5430, device='cuda:0') tensor(0.4521, device='cuda:0') tensor(-2.6465e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.608380
Average KL loss: 0.092762
Average total loss: 0.701142
tensor(-13.5430, device='cuda:0') tensor(0.4521, device='cuda:0') tensor(-1.2187e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.610997
Average KL loss: 0.092762
Average total loss: 0.703759
tensor(-13.5430, device='cuda:0') tensor(0.4521, device='cuda:0') tensor(-1.7581e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.611270
Average KL loss: 0.092762
Average total loss: 0.704032
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-2.9907e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.616099
Average KL loss: 0.092762
Average total loss: 0.708861
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-3.1431e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.609793
Average KL loss: 0.092761
Average total loss: 0.702555
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(1.0469e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.610610
Average KL loss: 0.092761
Average total loss: 0.703371
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-5.9038e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.604617
Average KL loss: 0.092761
Average total loss: 0.697378
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-2.3414e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.605920
Average KL loss: 0.092761
Average total loss: 0.698681
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-7.9182e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.608837
Average KL loss: 0.092761
Average total loss: 0.701598
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-2.9965e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.605402
Average KL loss: 0.092761
Average total loss: 0.698163
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-1.8946e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.611492
Average KL loss: 0.092761
Average total loss: 0.704254
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-1.2476e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.611385
Average KL loss: 0.092761
Average total loss: 0.704146
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(7.2830e-11, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.605062
Average KL loss: 0.092761
Average total loss: 0.697823
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-1.6892e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.607262
Average KL loss: 0.092761
Average total loss: 0.700023
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-2.8979e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.612749
Average KL loss: 0.092761
Average total loss: 0.705510
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-6.3936e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.617490
Average KL loss: 0.092761
Average total loss: 0.710251
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-1.2313e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.611515
Average KL loss: 0.092761
Average total loss: 0.704276
tensor(-13.5430, device='cuda:0') tensor(0.4520, device='cuda:0') tensor(-5.5414e-10, device='cuda:0')
 Percentile value: 7.2744598388671875
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =     476 /    1728             ( 27.55%) | total_pruned =    1252 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
bn1.bias             | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     228 /   36864             (  0.62%) | total_pruned =   36636 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     241 /   36864             (  0.65%) | total_pruned =   36623 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     224 /   36864             (  0.61%) | total_pruned =   36640 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     223 /   36864             (  0.60%) | total_pruned =   36641 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     299 /   73728             (  0.41%) | total_pruned =   73429 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     315 /  147456             (  0.21%) | total_pruned =  147141 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     178 /    8192             (  2.17%) | total_pruned =    8014 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     211 /  147456             (  0.14%) | total_pruned =  147245 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     160 /  147456             (  0.11%) | total_pruned =  147296 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     321 /  294912             (  0.11%) | total_pruned =  294591 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     281 /  589824             (  0.05%) | total_pruned =  589543 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     124 /   32768             (  0.38%) | total_pruned =   32644 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     129 /  589824             (  0.02%) | total_pruned =  589695 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =      92 /  589824             (  0.02%) | total_pruned =  589732 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      56 /     256             ( 21.88%) | total_pruned =     200 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     161 / 1179648             (  0.01%) | total_pruned = 1179487 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =      94 / 2359296             (  0.00%) | total_pruned = 2359202 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      80 /     512             ( 15.62%) | total_pruned =     432 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      39 /  131072             (  0.03%) | total_pruned =  131033 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      44 /     512             (  8.59%) | total_pruned =     468 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      27 / 2359296             (  0.00%) | total_pruned = 2359269 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =       6 / 2359296             (  0.00%) | total_pruned = 2359290 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     222 /    5120             (  4.34%) | total_pruned =    4898 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 0.991373 Accuracy: 58.40 61.69 % Best test Accuracy: 58.40%
