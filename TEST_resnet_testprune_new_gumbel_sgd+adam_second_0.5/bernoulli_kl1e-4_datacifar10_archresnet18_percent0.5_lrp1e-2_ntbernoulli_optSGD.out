Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2827e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302672
Average KL loss: 0.002684
Average total loss: 2.305356
tensor(2.6577e-05, device='cuda:0') tensor(4.0590e-06, device='cuda:0') tensor(2.5648e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.302747
Average KL loss: 0.002979
Average total loss: 2.305725
tensor(1.1998e-05, device='cuda:0') tensor(5.8761e-06, device='cuda:0') tensor(-3.2052e-12, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.301992
Average KL loss: 0.003515
Average total loss: 2.305508
tensor(2.8506e-05, device='cuda:0') tensor(1.2379e-05, device='cuda:0') tensor(-3.4651e-11, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.300801
Average KL loss: 0.004661
Average total loss: 2.305462
tensor(6.8023e-05, device='cuda:0') tensor(2.7850e-05, device='cuda:0') tensor(3.0066e-13, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.296340
Average KL loss: 0.008573
Average total loss: 2.304913
tensor(0.0002, device='cuda:0') tensor(7.7966e-05, device='cuda:0') tensor(-5.9129e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.242151
Average KL loss: 0.030764
Average total loss: 2.272915
tensor(0.0009, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.3138e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.904220
Average KL loss: 0.124509
Average total loss: 2.028728
tensor(0.0026, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.4956e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.381591
Average KL loss: 0.250861
Average total loss: 1.632452
tensor(0.0031, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.8293e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.031771
Average KL loss: 0.302618
Average total loss: 1.334389
tensor(0.0030, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.9341e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.881427
Average KL loss: 0.308868
Average total loss: 1.190295
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.1496e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.798027
Average KL loss: 0.309036
Average total loss: 1.107063
tensor(0.0029, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.4536e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.754729
Average KL loss: 0.311400
Average total loss: 1.066129
tensor(0.0028, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.2742e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.695266
Average KL loss: 0.309724
Average total loss: 1.004990
tensor(0.0028, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.3761e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.644160
Average KL loss: 0.305798
Average total loss: 0.949959
tensor(0.0028, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-6.8511e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.616043
Average KL loss: 0.304813
Average total loss: 0.920857
tensor(0.0028, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.6214e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.595678
Average KL loss: 0.303582
Average total loss: 0.899260
tensor(0.0028, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.1181e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.571360
Average KL loss: 0.301201
Average total loss: 0.872560
tensor(0.0028, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.7522e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.553082
Average KL loss: 0.300057
Average total loss: 0.853139
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.0667e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.543076
Average KL loss: 0.299864
Average total loss: 0.842941
tensor(0.0028, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2289e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.520515
Average KL loss: 0.298806
Average total loss: 0.819322
tensor(0.0028, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2023e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.515513
Average KL loss: 0.299252
Average total loss: 0.814765
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2000e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.499175
Average KL loss: 0.298311
Average total loss: 0.797486
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2749e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.495127
Average KL loss: 0.301150
Average total loss: 0.796278
tensor(0.0028, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.7852e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.478750
Average KL loss: 0.299744
Average total loss: 0.778495
tensor(0.0028, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5389e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.477695
Average KL loss: 0.299493
Average total loss: 0.777188
tensor(0.0028, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.4146e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.462231
Average KL loss: 0.298533
Average total loss: 0.760764
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.1999e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.455008
Average KL loss: 0.300123
Average total loss: 0.755131
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.1936e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.454331
Average KL loss: 0.299698
Average total loss: 0.754029
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0792e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.430505
Average KL loss: 0.298222
Average total loss: 0.728727
tensor(0.0028, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.7253e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.441425
Average KL loss: 0.299654
Average total loss: 0.741079
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2778e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.429539
Average KL loss: 0.299546
Average total loss: 0.729085
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3964e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.421279
Average KL loss: 0.299815
Average total loss: 0.721094
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.1763e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.418745
Average KL loss: 0.299948
Average total loss: 0.718693
tensor(0.0029, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3651e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.417771
Average KL loss: 0.301744
Average total loss: 0.719515
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.0321e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.408453
Average KL loss: 0.301415
Average total loss: 0.709869
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2605e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.406461
Average KL loss: 0.302058
Average total loss: 0.708519
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2266e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.400730
Average KL loss: 0.301606
Average total loss: 0.702336
tensor(0.0029, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.6823e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.397688
Average KL loss: 0.301894
Average total loss: 0.699583
tensor(0.0029, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.6183e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.390997
Average KL loss: 0.302276
Average total loss: 0.693273
tensor(0.0029, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.5471e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.396720
Average KL loss: 0.303744
Average total loss: 0.700464
tensor(0.0029, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.4151e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.384471
Average KL loss: 0.303673
Average total loss: 0.688143
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.6547e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.383196
Average KL loss: 0.303071
Average total loss: 0.686267
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3213e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.378353
Average KL loss: 0.302777
Average total loss: 0.681130
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.0410e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.382397
Average KL loss: 0.304443
Average total loss: 0.686840
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.0742e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.372872
Average KL loss: 0.303917
Average total loss: 0.676789
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.8271e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.368683
Average KL loss: 0.303230
Average total loss: 0.671913
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5151e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.373898
Average KL loss: 0.304088
Average total loss: 0.677987
tensor(0.0030, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3642e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.366455
Average KL loss: 0.306385
Average total loss: 0.672841
tensor(0.0030, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.4247e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.369430
Average KL loss: 0.305466
Average total loss: 0.674896
tensor(0.0030, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.9913e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.355943
Average KL loss: 0.304933
Average total loss: 0.660876
tensor(0.0029, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.2284e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.361495
Average KL loss: 0.305657
Average total loss: 0.667152
tensor(0.0029, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.0756e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.359149
Average KL loss: 0.305430
Average total loss: 0.664579
tensor(0.0030, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.2929e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.357564
Average KL loss: 0.306753
Average total loss: 0.664317
tensor(0.0030, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-9.5667e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.352447
Average KL loss: 0.306648
Average total loss: 0.659095
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.9713e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.348188
Average KL loss: 0.305937
Average total loss: 0.654125
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-5.0642e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.350813
Average KL loss: 0.307290
Average total loss: 0.658103
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-7.4972e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.348743
Average KL loss: 0.306650
Average total loss: 0.655393
tensor(0.0030, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.5554e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.344358
Average KL loss: 0.306008
Average total loss: 0.650366
tensor(0.0030, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.8567e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.344477
Average KL loss: 0.307396
Average total loss: 0.651873
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.5832e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.347760
Average KL loss: 0.307994
Average total loss: 0.655754
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6681e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.339191
Average KL loss: 0.308534
Average total loss: 0.647725
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.7072e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.341612
Average KL loss: 0.308409
Average total loss: 0.650021
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-6.2547e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.339154
Average KL loss: 0.309087
Average total loss: 0.648240
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.9382e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.334873
Average KL loss: 0.309406
Average total loss: 0.644279
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.3912e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.334543
Average KL loss: 0.308697
Average total loss: 0.643240
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-6.5834e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.334045
Average KL loss: 0.308845
Average total loss: 0.642890
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(3.2238e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.328669
Average KL loss: 0.307674
Average total loss: 0.636343
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.1677e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.330733
Average KL loss: 0.309187
Average total loss: 0.639920
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.4925e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.330107
Average KL loss: 0.308965
Average total loss: 0.639072
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.3198e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.332467
Average KL loss: 0.310391
Average total loss: 0.642858
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1547e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.332513
Average KL loss: 0.311353
Average total loss: 0.643866
tensor(0.0030, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(4.7039e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.328166
Average KL loss: 0.311207
Average total loss: 0.639373
tensor(0.0030, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.4217e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.331470
Average KL loss: 0.311498
Average total loss: 0.642968
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1813e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.325514
Average KL loss: 0.311096
Average total loss: 0.636609
tensor(0.0030, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.6673e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.322756
Average KL loss: 0.310572
Average total loss: 0.633328
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(9.3856e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.324293
Average KL loss: 0.310967
Average total loss: 0.635261
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.8980e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.322791
Average KL loss: 0.311973
Average total loss: 0.634764
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.0939e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.322608
Average KL loss: 0.311570
Average total loss: 0.634178
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.6271e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.322892
Average KL loss: 0.313285
Average total loss: 0.636178
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(6.9156e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.320143
Average KL loss: 0.313006
Average total loss: 0.633149
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.8358e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.318661
Average KL loss: 0.313077
Average total loss: 0.631738
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.2900e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.321448
Average KL loss: 0.313067
Average total loss: 0.634515
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.8174e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.318586
Average KL loss: 0.313321
Average total loss: 0.631908
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.8857e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.318531
Average KL loss: 0.313399
Average total loss: 0.631930
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.5323e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.315570
Average KL loss: 0.313156
Average total loss: 0.628726
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.2423e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.318805
Average KL loss: 0.313512
Average total loss: 0.632317
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.7784e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.316196
Average KL loss: 0.314286
Average total loss: 0.630482
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.3620e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.314958
Average KL loss: 0.313336
Average total loss: 0.628294
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.9559e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.312144
Average KL loss: 0.313444
Average total loss: 0.625588
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-5.9755e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.315220
Average KL loss: 0.313748
Average total loss: 0.628968
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.7535e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.314807
Average KL loss: 0.314898
Average total loss: 0.629704
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-6.9040e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.311816
Average KL loss: 0.314734
Average total loss: 0.626550
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.5258e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.310645
Average KL loss: 0.314392
Average total loss: 0.625036
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.0594e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.311993
Average KL loss: 0.315058
Average total loss: 0.627051
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.6422e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.311613
Average KL loss: 0.315098
Average total loss: 0.626711
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.9490e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.309061
Average KL loss: 0.314885
Average total loss: 0.623946
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.3461e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.310720
Average KL loss: 0.315092
Average total loss: 0.625812
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.1839e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.310587
Average KL loss: 0.315305
Average total loss: 0.625891
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.7079e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.307078
Average KL loss: 0.314877
Average total loss: 0.621956
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.1982e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.310115
Average KL loss: 0.315148
Average total loss: 0.625263
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.0616e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.306154
Average KL loss: 0.314411
Average total loss: 0.620566
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(1.6405e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.308740
Average KL loss: 0.315252
Average total loss: 0.623992
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.1401e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.305619
Average KL loss: 0.315246
Average total loss: 0.620865
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.0127e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.310232
Average KL loss: 0.316691
Average total loss: 0.626922
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.4810e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.301800
Average KL loss: 0.316424
Average total loss: 0.618224
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.3429e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.303254
Average KL loss: 0.315679
Average total loss: 0.618933
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(8.2033e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.303851
Average KL loss: 0.315579
Average total loss: 0.619431
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.8590e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.306397
Average KL loss: 0.316086
Average total loss: 0.622483
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.6833e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.304565
Average KL loss: 0.317610
Average total loss: 0.622175
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.0165e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.303958
Average KL loss: 0.317102
Average total loss: 0.621061
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3028e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.302356
Average KL loss: 0.316738
Average total loss: 0.619093
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.0874e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.301272
Average KL loss: 0.317020
Average total loss: 0.618293
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5851e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.302122
Average KL loss: 0.316443
Average total loss: 0.618565
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(5.9515e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.302712
Average KL loss: 0.317099
Average total loss: 0.619811
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(6.5320e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.301318
Average KL loss: 0.317207
Average total loss: 0.618525
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(3.9346e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.303331
Average KL loss: 0.317486
Average total loss: 0.620817
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.2038e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.302171
Average KL loss: 0.311490
Average total loss: 0.613661
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3115e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.297085
Average KL loss: 0.303492
Average total loss: 0.600577
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.1054e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.296952
Average KL loss: 0.299613
Average total loss: 0.596565
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.3049e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.296429
Average KL loss: 0.297289
Average total loss: 0.593718
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(4.3097e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.303861
Average KL loss: 0.295690
Average total loss: 0.599551
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.7434e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.299297
Average KL loss: 0.294589
Average total loss: 0.593885
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.5730e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.299572
Average KL loss: 0.293731
Average total loss: 0.593302
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.6080e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.297962
Average KL loss: 0.293067
Average total loss: 0.591029
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.9358e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.300435
Average KL loss: 0.292598
Average total loss: 0.593033
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-8.4561e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.300297
Average KL loss: 0.292253
Average total loss: 0.592550
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.4206e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.303111
Average KL loss: 0.291910
Average total loss: 0.595021
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.1833e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.300009
Average KL loss: 0.291737
Average total loss: 0.591746
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.0906e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.298371
Average KL loss: 0.291403
Average total loss: 0.589775
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.0561e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.300339
Average KL loss: 0.291098
Average total loss: 0.591437
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(6.0543e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.301461
Average KL loss: 0.290967
Average total loss: 0.592428
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(6.0308e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.301101
Average KL loss: 0.290740
Average total loss: 0.591840
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(8.6308e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.299242
Average KL loss: 0.290556
Average total loss: 0.589798
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.5625e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.299013
Average KL loss: 0.290444
Average total loss: 0.589457
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.0136e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.299418
Average KL loss: 0.290282
Average total loss: 0.589700
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.3191e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.299462
Average KL loss: 0.290224
Average total loss: 0.589685
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.0240e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.300726
Average KL loss: 0.290216
Average total loss: 0.590942
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.9843e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.297846
Average KL loss: 0.290020
Average total loss: 0.587866
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.2266e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.298812
Average KL loss: 0.289880
Average total loss: 0.588692
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.3254e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.295722
Average KL loss: 0.289853
Average total loss: 0.585575
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3492e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.300447
Average KL loss: 0.289835
Average total loss: 0.590281
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.2945e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.298634
Average KL loss: 0.289771
Average total loss: 0.588405
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.8410e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.299482
Average KL loss: 0.289720
Average total loss: 0.589202
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.5690e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.298981
Average KL loss: 0.289695
Average total loss: 0.588676
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(3.3160e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.298836
Average KL loss: 0.289661
Average total loss: 0.588497
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.4229e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.298603
Average KL loss: 0.289579
Average total loss: 0.588182
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.6243e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.299793
Average KL loss: 0.289523
Average total loss: 0.589316
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6452e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.297734
Average KL loss: 0.289438
Average total loss: 0.587171
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.9939e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.295528
Average KL loss: 0.289406
Average total loss: 0.584934
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.8764e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.297291
Average KL loss: 0.289461
Average total loss: 0.586752
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3630e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.298736
Average KL loss: 0.289337
Average total loss: 0.588074
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.4711e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.298988
Average KL loss: 0.289242
Average total loss: 0.588230
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.0883e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.298516
Average KL loss: 0.289197
Average total loss: 0.587714
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.1816e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.299162
Average KL loss: 0.289323
Average total loss: 0.588485
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.6868e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.296932
Average KL loss: 0.289342
Average total loss: 0.586274
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.7322e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.294781
Average KL loss: 0.289319
Average total loss: 0.584101
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.0525e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.295517
Average KL loss: 0.289128
Average total loss: 0.584645
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0918e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.298547
Average KL loss: 0.289096
Average total loss: 0.587642
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.0567e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.301097
Average KL loss: 0.289173
Average total loss: 0.590269
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.3429e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.297061
Average KL loss: 0.289244
Average total loss: 0.586305
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.3445e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.295213
Average KL loss: 0.289223
Average total loss: 0.584436
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.4253e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.293798
Average KL loss: 0.289093
Average total loss: 0.582891
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.3094e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.295295
Average KL loss: 0.288935
Average total loss: 0.584230
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.0817e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.298816
Average KL loss: 0.288934
Average total loss: 0.587750
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0890e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.299009
Average KL loss: 0.289056
Average total loss: 0.588065
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.7580e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.299208
Average KL loss: 0.289138
Average total loss: 0.588346
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.7396e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.298439
Average KL loss: 0.289153
Average total loss: 0.587592
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.2199e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.294563
Average KL loss: 0.289111
Average total loss: 0.583674
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.1560e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.302569
Average KL loss: 0.289086
Average total loss: 0.591656
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0593e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.297357
Average KL loss: 0.289210
Average total loss: 0.586567
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.3717e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.296936
Average KL loss: 0.289177
Average total loss: 0.586114
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.8442e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.300125
Average KL loss: 0.289271
Average total loss: 0.589396
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.0999e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.299169
Average KL loss: 0.289313
Average total loss: 0.588482
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2752e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.292199
Average KL loss: 0.289241
Average total loss: 0.581441
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.8882e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.298745
Average KL loss: 0.288986
Average total loss: 0.587731
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.0302e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.298329
Average KL loss: 0.288815
Average total loss: 0.587143
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.3348e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.295989
Average KL loss: 0.288666
Average total loss: 0.584655
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.4154e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.297100
Average KL loss: 0.288538
Average total loss: 0.585638
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.6435e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.296065
Average KL loss: 0.288427
Average total loss: 0.584491
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3132e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.300114
Average KL loss: 0.288328
Average total loss: 0.588443
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.3388e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.296444
Average KL loss: 0.288237
Average total loss: 0.584681
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.5738e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.297537
Average KL loss: 0.288149
Average total loss: 0.585686
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5993e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.296707
Average KL loss: 0.288081
Average total loss: 0.584787
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2960e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.298621
Average KL loss: 0.288018
Average total loss: 0.586639
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3165e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.298793
Average KL loss: 0.287961
Average total loss: 0.586754
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6959e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.298290
Average KL loss: 0.287925
Average total loss: 0.586215
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.3860e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.298897
Average KL loss: 0.287915
Average total loss: 0.586812
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.3096e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.297919
Average KL loss: 0.287906
Average total loss: 0.585825
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.1511e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.296225
Average KL loss: 0.287897
Average total loss: 0.584122
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0544e-12, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.298449
Average KL loss: 0.287887
Average total loss: 0.586336
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.2273e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.297753
Average KL loss: 0.287879
Average total loss: 0.585631
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.9166e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.297042
Average KL loss: 0.287870
Average total loss: 0.584912
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5891e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.296852
Average KL loss: 0.287861
Average total loss: 0.584713
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.1500e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.295027
Average KL loss: 0.287853
Average total loss: 0.582880
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5896e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.294179
Average KL loss: 0.287845
Average total loss: 0.582024
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.4734e-09, device='cuda:0')
 Percentile value: 0.0013107419945299625
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =     490 /    1728             ( 28.36%) | total_pruned =    1238 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
bn1.bias             | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6700 /   36864             ( 18.17%) | total_pruned =   30164 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   16169 /   36864             ( 43.86%) | total_pruned =   20695 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   15077 /   36864             ( 40.90%) | total_pruned =   21787 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18552 /   36864             ( 50.33%) | total_pruned =   18312 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   40671 /   73728             ( 55.16%) | total_pruned =   33057 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   80388 /  147456             ( 54.52%) | total_pruned =   67068 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5018 /    8192             ( 61.25%) | total_pruned =    3174 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   72016 /  147456             ( 48.84%) | total_pruned =   75440 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   68712 /  147456             ( 46.60%) | total_pruned =   78744 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  156607 /  294912             ( 53.10%) | total_pruned =  138305 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     111 /     256             ( 43.36%) | total_pruned =     145 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  312951 /  589824             ( 53.06%) | total_pruned =  276873 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18714 /   32768             ( 57.11%) | total_pruned =   14054 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  303700 /  589824             ( 51.49%) | total_pruned =  286124 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  285481 /  589824             ( 48.40%) | total_pruned =  304343 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  593035 / 1179648             ( 50.27%) | total_pruned =  586613 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1067316 / 2359296             ( 45.24%) | total_pruned = 1291980 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     482 /     512             ( 94.14%) | total_pruned =      30 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     280 /     512             ( 54.69%) | total_pruned =     232 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   62778 /  131072             ( 47.90%) | total_pruned =   68294 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     276 /     512             ( 53.91%) | total_pruned =     236 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1073073 / 2359296             ( 45.48%) | total_pruned = 1286223 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1380153 / 2359296             ( 58.50%) | total_pruned =  979143 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5088 /    5120             ( 99.38%) | total_pruned =      32 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 68/100 Loss: 0.019035 Accuracy: 89.81 100.00 % Best test Accuracy: 89.81%
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.3315e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.992713
Average KL loss: 0.311801
Average total loss: 1.304514
tensor(0.0038, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-6.2616e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.782852
Average KL loss: 0.342140
Average total loss: 1.124992
tensor(0.0038, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-5.5433e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.713761
Average KL loss: 0.348343
Average total loss: 1.062104
tensor(0.0038, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-4.9166e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.648337
Average KL loss: 0.349239
Average total loss: 0.997576
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.9008e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.621484
Average KL loss: 0.346614
Average total loss: 0.968098
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-4.4327e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.574129
Average KL loss: 0.341132
Average total loss: 0.915261
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.3681e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.559966
Average KL loss: 0.337842
Average total loss: 0.897807
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.8520e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.548459
Average KL loss: 0.337637
Average total loss: 0.886096
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.7149e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.528425
Average KL loss: 0.337501
Average total loss: 0.865926
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.9461e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.512265
Average KL loss: 0.336330
Average total loss: 0.848595
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.6212e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.502837
Average KL loss: 0.336432
Average total loss: 0.839269
tensor(0.0035, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.5881e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.493107
Average KL loss: 0.335779
Average total loss: 0.828886
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.3610e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.488264
Average KL loss: 0.335674
Average total loss: 0.823939
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.0761e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.467886
Average KL loss: 0.335437
Average total loss: 0.803323
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-6.6294e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.465672
Average KL loss: 0.334349
Average total loss: 0.800021
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.5496e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.453049
Average KL loss: 0.334073
Average total loss: 0.787123
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.1421e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.443562
Average KL loss: 0.332523
Average total loss: 0.776085
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.2737e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.437402
Average KL loss: 0.332047
Average total loss: 0.769449
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.2806e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.433933
Average KL loss: 0.331766
Average total loss: 0.765699
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.6142e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.438547
Average KL loss: 0.332136
Average total loss: 0.770683
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-5.3939e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.426011
Average KL loss: 0.332232
Average total loss: 0.758243
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.2825e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.419009
Average KL loss: 0.332652
Average total loss: 0.751662
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.6833e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.428829
Average KL loss: 0.332171
Average total loss: 0.761000
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.5030e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.421043
Average KL loss: 0.332395
Average total loss: 0.753438
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.3527e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.416230
Average KL loss: 0.333621
Average total loss: 0.749850
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.2757e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.403648
Average KL loss: 0.332417
Average total loss: 0.736066
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.3782e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.402963
Average KL loss: 0.332621
Average total loss: 0.735584
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.3196e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.402512
Average KL loss: 0.331589
Average total loss: 0.734101
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.0333e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.397621
Average KL loss: 0.331949
Average total loss: 0.729570
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.1764e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.393430
Average KL loss: 0.331807
Average total loss: 0.725237
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-7.1488e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.395161
Average KL loss: 0.330655
Average total loss: 0.725816
tensor(0.0034, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.6324e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.390429
Average KL loss: 0.332798
Average total loss: 0.723227
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.6624e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.387807
Average KL loss: 0.332599
Average total loss: 0.720406
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.7245e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.386331
Average KL loss: 0.331901
Average total loss: 0.718232
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.0942e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.382527
Average KL loss: 0.332261
Average total loss: 0.714788
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(9.9091e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.385002
Average KL loss: 0.332374
Average total loss: 0.717376
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.1004e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.375347
Average KL loss: 0.332422
Average total loss: 0.707769
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-9.2330e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.381688
Average KL loss: 0.332395
Average total loss: 0.714083
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-8.1043e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.372447
Average KL loss: 0.332651
Average total loss: 0.705098
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.4567e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.370647
Average KL loss: 0.332238
Average total loss: 0.702884
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.0702e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.370270
Average KL loss: 0.331346
Average total loss: 0.701616
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.0591e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.371837
Average KL loss: 0.331807
Average total loss: 0.703644
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.6834e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.369304
Average KL loss: 0.332869
Average total loss: 0.702172
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.2039e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.367859
Average KL loss: 0.332780
Average total loss: 0.700639
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.8438e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.368690
Average KL loss: 0.333105
Average total loss: 0.701795
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.3781e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.370207
Average KL loss: 0.333327
Average total loss: 0.703534
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.2548e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.360307
Average KL loss: 0.333235
Average total loss: 0.693542
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.4284e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.356332
Average KL loss: 0.331953
Average total loss: 0.688285
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(4.2929e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.359295
Average KL loss: 0.332260
Average total loss: 0.691555
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.7775e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.360233
Average KL loss: 0.332807
Average total loss: 0.693040
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.2784e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.359594
Average KL loss: 0.333109
Average total loss: 0.692703
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.0321e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.354010
Average KL loss: 0.332177
Average total loss: 0.686187
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.1432e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.349762
Average KL loss: 0.332385
Average total loss: 0.682147
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.2172e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.352573
Average KL loss: 0.332016
Average total loss: 0.684588
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.4028e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.352956
Average KL loss: 0.332386
Average total loss: 0.685342
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-9.8234e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.347876
Average KL loss: 0.332986
Average total loss: 0.680861
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.3295e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.350718
Average KL loss: 0.332367
Average total loss: 0.683085
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(6.9664e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.357782
Average KL loss: 0.334069
Average total loss: 0.691850
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(4.5397e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.345095
Average KL loss: 0.334589
Average total loss: 0.679685
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1995e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.342905
Average KL loss: 0.333278
Average total loss: 0.676183
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.1448e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.350694
Average KL loss: 0.333085
Average total loss: 0.683779
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.2139e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.345691
Average KL loss: 0.332732
Average total loss: 0.678423
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.0833e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.342286
Average KL loss: 0.332747
Average total loss: 0.675033
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.8326e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.345266
Average KL loss: 0.333192
Average total loss: 0.678457
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.8219e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.343935
Average KL loss: 0.333563
Average total loss: 0.677498
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.5316e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.344767
Average KL loss: 0.333457
Average total loss: 0.678225
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.7017e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.340615
Average KL loss: 0.333927
Average total loss: 0.674542
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.4723e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.338248
Average KL loss: 0.333586
Average total loss: 0.671833
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.7098e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.337500
Average KL loss: 0.333765
Average total loss: 0.671265
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.3575e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.338281
Average KL loss: 0.333388
Average total loss: 0.671669
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(3.2896e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.341334
Average KL loss: 0.333563
Average total loss: 0.674898
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.8045e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.338032
Average KL loss: 0.335042
Average total loss: 0.673074
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.6521e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.340034
Average KL loss: 0.335043
Average total loss: 0.675077
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.1912e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.335284
Average KL loss: 0.335538
Average total loss: 0.670822
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(9.9696e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.332363
Average KL loss: 0.334884
Average total loss: 0.667247
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(5.7355e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.336298
Average KL loss: 0.334937
Average total loss: 0.671235
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.1218e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.333943
Average KL loss: 0.335058
Average total loss: 0.669002
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(6.6917e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.332238
Average KL loss: 0.334856
Average total loss: 0.667094
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.1109e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.336321
Average KL loss: 0.335148
Average total loss: 0.671469
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(3.2839e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.330519
Average KL loss: 0.335565
Average total loss: 0.666084
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(5.8961e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.332845
Average KL loss: 0.335098
Average total loss: 0.667943
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.9648e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.326298
Average KL loss: 0.334149
Average total loss: 0.660447
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(8.4171e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.331689
Average KL loss: 0.334210
Average total loss: 0.665899
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.9519e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.333789
Average KL loss: 0.334824
Average total loss: 0.668614
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.1980e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.327899
Average KL loss: 0.335353
Average total loss: 0.663252
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.2158e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.326117
Average KL loss: 0.334996
Average total loss: 0.661112
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(9.5382e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.328723
Average KL loss: 0.334975
Average total loss: 0.663698
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.1286e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.330903
Average KL loss: 0.335817
Average total loss: 0.666720
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.4915e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.329513
Average KL loss: 0.336934
Average total loss: 0.666447
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.9058e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.323629
Average KL loss: 0.335015
Average total loss: 0.658644
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.2965e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.326892
Average KL loss: 0.335809
Average total loss: 0.662701
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.4923e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.330301
Average KL loss: 0.336725
Average total loss: 0.667026
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(4.6720e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.326496
Average KL loss: 0.336475
Average total loss: 0.662971
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.0369e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.322356
Average KL loss: 0.336105
Average total loss: 0.658461
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.2653e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.324014
Average KL loss: 0.335386
Average total loss: 0.659400
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.7074e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.330095
Average KL loss: 0.336277
Average total loss: 0.666372
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.9587e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.328875
Average KL loss: 0.336922
Average total loss: 0.665798
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.5181e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.325291
Average KL loss: 0.337276
Average total loss: 0.662566
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.4865e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.325722
Average KL loss: 0.337115
Average total loss: 0.662837
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.7843e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.325305
Average KL loss: 0.337590
Average total loss: 0.662895
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(7.6463e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.322330
Average KL loss: 0.336857
Average total loss: 0.659187
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.3307e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.327421
Average KL loss: 0.337191
Average total loss: 0.664612
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.7545e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.318771
Average KL loss: 0.337702
Average total loss: 0.656472
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.0671e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.319943
Average KL loss: 0.336628
Average total loss: 0.656571
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.3825e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.324000
Average KL loss: 0.337451
Average total loss: 0.661451
tensor(0.0035, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.4105e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.317047
Average KL loss: 0.337580
Average total loss: 0.654627
tensor(0.0035, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.2536e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.325357
Average KL loss: 0.337683
Average total loss: 0.663041
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.1011e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.318274
Average KL loss: 0.337511
Average total loss: 0.655785
tensor(0.0035, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.2763e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.318567
Average KL loss: 0.336899
Average total loss: 0.655466
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.7319e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.317893
Average KL loss: 0.336678
Average total loss: 0.654571
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.8838e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.322436
Average KL loss: 0.337220
Average total loss: 0.659657
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.7342e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.318765
Average KL loss: 0.336863
Average total loss: 0.655629
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(6.4340e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.317507
Average KL loss: 0.336664
Average total loss: 0.654171
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.9019e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.319579
Average KL loss: 0.337554
Average total loss: 0.657133
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.2985e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.315765
Average KL loss: 0.337761
Average total loss: 0.653526
tensor(0.0035, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.6398e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.314307
Average KL loss: 0.337113
Average total loss: 0.651420
tensor(0.0035, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.3259e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.319332
Average KL loss: 0.336470
Average total loss: 0.655801
tensor(0.0035, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.5491e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.319247
Average KL loss: 0.337588
Average total loss: 0.656834
tensor(0.0035, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.1438e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.316900
Average KL loss: 0.338163
Average total loss: 0.655062
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.4500e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.318913
Average KL loss: 0.338008
Average total loss: 0.656921
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.7477e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.317933
Average KL loss: 0.338460
Average total loss: 0.656393
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(7.9571e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.318295
Average KL loss: 0.338464
Average total loss: 0.656759
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.4696e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.319391
Average KL loss: 0.338722
Average total loss: 0.658113
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.0246e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.313085
Average KL loss: 0.338291
Average total loss: 0.651376
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.3498e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.313477
Average KL loss: 0.338088
Average total loss: 0.651565
tensor(0.0035, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.4045e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.315050
Average KL loss: 0.338284
Average total loss: 0.653334
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.4525e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.315026
Average KL loss: 0.339550
Average total loss: 0.654576
tensor(0.0035, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.1598e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.309054
Average KL loss: 0.335708
Average total loss: 0.644762
tensor(0.0035, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-8.6568e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.310269
Average KL loss: 0.330626
Average total loss: 0.640895
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.5136e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.317684
Average KL loss: 0.327655
Average total loss: 0.645339
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-9.9968e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.312292
Average KL loss: 0.325578
Average total loss: 0.637870
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.2421e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.310871
Average KL loss: 0.324007
Average total loss: 0.634878
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.5154e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.305971
Average KL loss: 0.322576
Average total loss: 0.628547
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.7873e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.311080
Average KL loss: 0.321382
Average total loss: 0.632463
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.7748e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.312053
Average KL loss: 0.320448
Average total loss: 0.632502
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.3723e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.310612
Average KL loss: 0.319687
Average total loss: 0.630300
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.8153e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.314274
Average KL loss: 0.319076
Average total loss: 0.633350
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.5380e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.314920
Average KL loss: 0.318525
Average total loss: 0.633445
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.2485e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.311492
Average KL loss: 0.317980
Average total loss: 0.629472
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.7156e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.313019
Average KL loss: 0.317492
Average total loss: 0.630511
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.5458e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.311316
Average KL loss: 0.317124
Average total loss: 0.628440
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.0633e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.312422
Average KL loss: 0.316694
Average total loss: 0.629116
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.2128e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.311261
Average KL loss: 0.316441
Average total loss: 0.627702
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-9.7784e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.311540
Average KL loss: 0.316137
Average total loss: 0.627677
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.5776e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.314234
Average KL loss: 0.315908
Average total loss: 0.630142
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.4072e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.310314
Average KL loss: 0.315697
Average total loss: 0.626010
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.9960e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.312934
Average KL loss: 0.315419
Average total loss: 0.628354
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.2135e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.312075
Average KL loss: 0.315198
Average total loss: 0.627274
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.6897e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.309434
Average KL loss: 0.315021
Average total loss: 0.624455
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8649e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.311724
Average KL loss: 0.314792
Average total loss: 0.626516
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.7533e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.313769
Average KL loss: 0.314724
Average total loss: 0.628493
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.4513e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.313339
Average KL loss: 0.314757
Average total loss: 0.628096
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8706e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.308077
Average KL loss: 0.314557
Average total loss: 0.622633
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.5896e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.309713
Average KL loss: 0.314407
Average total loss: 0.624120
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.6431e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.311103
Average KL loss: 0.314191
Average total loss: 0.625294
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.3938e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.313131
Average KL loss: 0.314010
Average total loss: 0.627140
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.6054e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.309041
Average KL loss: 0.313931
Average total loss: 0.622972
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.1355e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.310250
Average KL loss: 0.313761
Average total loss: 0.624011
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.2703e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.313493
Average KL loss: 0.313664
Average total loss: 0.627158
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.3828e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.310539
Average KL loss: 0.313596
Average total loss: 0.624135
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.8983e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.310259
Average KL loss: 0.313520
Average total loss: 0.623779
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.7850e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.311836
Average KL loss: 0.313458
Average total loss: 0.625294
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.6161e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.311542
Average KL loss: 0.313395
Average total loss: 0.624937
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.7066e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.311129
Average KL loss: 0.313356
Average total loss: 0.624485
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.9567e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.314195
Average KL loss: 0.313264
Average total loss: 0.627458
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.5649e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.311169
Average KL loss: 0.313144
Average total loss: 0.624313
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.3356e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.310849
Average KL loss: 0.313045
Average total loss: 0.623895
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.3022e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.311994
Average KL loss: 0.312970
Average total loss: 0.624965
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(8.7822e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.314412
Average KL loss: 0.312903
Average total loss: 0.627314
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.7289e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.308779
Average KL loss: 0.312832
Average total loss: 0.621611
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.4114e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.312387
Average KL loss: 0.312765
Average total loss: 0.625152
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.6900e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.314734
Average KL loss: 0.312701
Average total loss: 0.627435
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.0106e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.311506
Average KL loss: 0.312637
Average total loss: 0.624143
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.0485e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.314708
Average KL loss: 0.312593
Average total loss: 0.627300
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.1412e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.312835
Average KL loss: 0.312552
Average total loss: 0.625388
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.0976e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.309147
Average KL loss: 0.312505
Average total loss: 0.621652
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.2240e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.314546
Average KL loss: 0.312459
Average total loss: 0.627005
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.3688e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.309937
Average KL loss: 0.312421
Average total loss: 0.622358
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6705e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.312010
Average KL loss: 0.312378
Average total loss: 0.624388
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.1770e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.309996
Average KL loss: 0.312336
Average total loss: 0.622332
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(5.5949e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.309139
Average KL loss: 0.312272
Average total loss: 0.621411
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.8076e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.310726
Average KL loss: 0.312223
Average total loss: 0.622949
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.4814e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.309964
Average KL loss: 0.312186
Average total loss: 0.622150
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8582e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.309807
Average KL loss: 0.312148
Average total loss: 0.621955
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.6380e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.311891
Average KL loss: 0.312108
Average total loss: 0.623999
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.4625e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.314762
Average KL loss: 0.312067
Average total loss: 0.626829
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6884e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.315347
Average KL loss: 0.312036
Average total loss: 0.627383
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.0516e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.310632
Average KL loss: 0.312000
Average total loss: 0.622632
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.4339e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.307607
Average KL loss: 0.311965
Average total loss: 0.619571
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(7.2087e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.313922
Average KL loss: 0.311929
Average total loss: 0.625851
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.9675e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.310357
Average KL loss: 0.311899
Average total loss: 0.622256
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.6585e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.309857
Average KL loss: 0.311869
Average total loss: 0.621726
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.3886e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.308958
Average KL loss: 0.311832
Average total loss: 0.620790
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.9280e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.315068
Average KL loss: 0.311799
Average total loss: 0.626867
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.7405e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.315732
Average KL loss: 0.311770
Average total loss: 0.627502
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.3638e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.310958
Average KL loss: 0.311754
Average total loss: 0.622712
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.9938e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.309207
Average KL loss: 0.311734
Average total loss: 0.620942
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(5.0709e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.311648
Average KL loss: 0.311719
Average total loss: 0.623366
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(7.4629e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.313092
Average KL loss: 0.311695
Average total loss: 0.624787
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.9246e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.311740
Average KL loss: 0.311679
Average total loss: 0.623419
 Percentile value: 0.0015486859483644366
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =     248 /    1728             ( 14.35%) | total_pruned =    1480 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
bn1.bias             | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1856 /   36864             (  5.03%) | total_pruned =   35008 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5954 /   36864             ( 16.15%) | total_pruned =   30910 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    5805 /   36864             ( 15.75%) | total_pruned =   31059 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9089 /   36864             ( 24.66%) | total_pruned =   27775 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   21307 /   73728             ( 28.90%) | total_pruned =   52421 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   39952 /  147456             ( 27.09%) | total_pruned =  107504 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2778 /    8192             ( 33.91%) | total_pruned =    5414 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   32522 /  147456             ( 22.06%) | total_pruned =  114934 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   29609 /  147456             ( 20.08%) | total_pruned =  117847 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   80582 /  294912             ( 27.32%) | total_pruned =  214330 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  156633 /  589824             ( 26.56%) | total_pruned =  433191 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   10154 /   32768             ( 30.99%) | total_pruned =   22614 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  150771 /  589824             ( 25.56%) | total_pruned =  439053 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  136869 /  589824             ( 23.21%) | total_pruned =  452955 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  320751 / 1179648             ( 27.19%) | total_pruned =  858897 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     485 /     512             ( 94.73%) | total_pruned =      27 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      74 /     512             ( 14.45%) | total_pruned =     438 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  553202 / 2359296             ( 23.45%) | total_pruned = 1806094 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     424 /     512             ( 82.81%) | total_pruned =      88 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     174 /     512             ( 33.98%) | total_pruned =     338 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   30898 /  131072             ( 23.57%) | total_pruned =  100174 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     426 /     512             ( 83.20%) | total_pruned =      86 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     180 /     512             ( 35.16%) | total_pruned =     332 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  455057 / 2359296             ( 19.29%) | total_pruned = 1904239 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  740213 / 2359296             ( 31.37%) | total_pruned = 1619083 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
linear.weight        | nonzeros =    4878 /    5120             ( 95.27%) | total_pruned =     242 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 54/100 Loss: 0.012940 Accuracy: 89.62 100.00 % Best test Accuracy: 89.62%
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.0173e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.613158
Average KL loss: 0.319737
Average total loss: 0.932895
tensor(0.0039, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.0757e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.499890
Average KL loss: 0.340512
Average total loss: 0.840401
tensor(0.0038, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.4630e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.465140
Average KL loss: 0.346048
Average total loss: 0.811188
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.9116e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.449223
Average KL loss: 0.347525
Average total loss: 0.796748
tensor(0.0038, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.8285e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.435174
Average KL loss: 0.347474
Average total loss: 0.782648
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.8667e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.426899
Average KL loss: 0.346371
Average total loss: 0.773270
tensor(0.0037, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.2497e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.423269
Average KL loss: 0.346429
Average total loss: 0.769699
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.2968e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.408589
Average KL loss: 0.346409
Average total loss: 0.754998
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.3058e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.408567
Average KL loss: 0.347486
Average total loss: 0.756053
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.7859e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.406680
Average KL loss: 0.348403
Average total loss: 0.755083
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.9145e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.393910
Average KL loss: 0.348621
Average total loss: 0.742531
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(2.7451e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.395726
Average KL loss: 0.348647
Average total loss: 0.744373
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.1525e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.395449
Average KL loss: 0.348952
Average total loss: 0.744401
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.1958e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.385796
Average KL loss: 0.350030
Average total loss: 0.735827
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.6334e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.386242
Average KL loss: 0.349691
Average total loss: 0.735933
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.0474e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.388720
Average KL loss: 0.349500
Average total loss: 0.738220
tensor(0.0037, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.0178e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.382852
Average KL loss: 0.349820
Average total loss: 0.732672
tensor(0.0037, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1248e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.376904
Average KL loss: 0.350147
Average total loss: 0.727051
tensor(0.0037, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.4313e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.376603
Average KL loss: 0.349757
Average total loss: 0.726360
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.2192e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.387579
Average KL loss: 0.351497
Average total loss: 0.739076
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.3883e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.369589
Average KL loss: 0.351020
Average total loss: 0.720609
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.7406e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.372866
Average KL loss: 0.350150
Average total loss: 0.723016
tensor(0.0036, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.5074e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.367175
Average KL loss: 0.349918
Average total loss: 0.717093
tensor(0.0036, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.2580e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.374510
Average KL loss: 0.350740
Average total loss: 0.725249
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.1940e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.369505
Average KL loss: 0.351569
Average total loss: 0.721074
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.2890e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.371526
Average KL loss: 0.351037
Average total loss: 0.722563
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.9692e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.368454
Average KL loss: 0.351208
Average total loss: 0.719663
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.1594e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.367325
Average KL loss: 0.350795
Average total loss: 0.718119
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.9667e-11, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.366957
Average KL loss: 0.351372
Average total loss: 0.718329
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.8612e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.365815
Average KL loss: 0.351238
Average total loss: 0.717053
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.0194e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.363969
Average KL loss: 0.351794
Average total loss: 0.715762
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(1.7627e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.362268
Average KL loss: 0.351563
Average total loss: 0.713832
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.2820e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.359493
Average KL loss: 0.351885
Average total loss: 0.711378
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(7.2562e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.359057
Average KL loss: 0.351620
Average total loss: 0.710678
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2179e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.370849
Average KL loss: 0.352313
Average total loss: 0.723162
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.3939e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.360001
Average KL loss: 0.353150
Average total loss: 0.713150
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.7434e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.353789
Average KL loss: 0.352551
Average total loss: 0.706340
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.3070e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.355100
Average KL loss: 0.351842
Average total loss: 0.706941
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(1.3688e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.359860
Average KL loss: 0.351836
Average total loss: 0.711696
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(6.5944e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.353850
Average KL loss: 0.352292
Average total loss: 0.706142
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(7.0561e-11, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.355964
Average KL loss: 0.351880
Average total loss: 0.707844
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.0895e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.357863
Average KL loss: 0.351853
Average total loss: 0.709717
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.0441e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.356166
Average KL loss: 0.351593
Average total loss: 0.707759
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5845e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.352313
Average KL loss: 0.352026
Average total loss: 0.704339
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.9704e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.360688
Average KL loss: 0.352090
Average total loss: 0.712778
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.9464e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.355985
Average KL loss: 0.354060
Average total loss: 0.710045
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6615e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.351227
Average KL loss: 0.353523
Average total loss: 0.704750
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.0310e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.351705
Average KL loss: 0.353609
Average total loss: 0.705314
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.1596e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.350531
Average KL loss: 0.353135
Average total loss: 0.703666
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.0140e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.352370
Average KL loss: 0.353787
Average total loss: 0.706157
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.9628e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.351680
Average KL loss: 0.353711
Average total loss: 0.705391
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.1770e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.348213
Average KL loss: 0.353735
Average total loss: 0.701948
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.4081e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.347105
Average KL loss: 0.353196
Average total loss: 0.700301
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(8.8033e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.347237
Average KL loss: 0.352992
Average total loss: 0.700229
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.1198e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.347669
Average KL loss: 0.353346
Average total loss: 0.701015
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.3311e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.351294
Average KL loss: 0.353801
Average total loss: 0.705095
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.7847e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.349023
Average KL loss: 0.353892
Average total loss: 0.702916
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.1800e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.345235
Average KL loss: 0.353792
Average total loss: 0.699027
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.1366e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.349193
Average KL loss: 0.354101
Average total loss: 0.703294
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.7918e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.348259
Average KL loss: 0.354200
Average total loss: 0.702459
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.7157e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.349626
Average KL loss: 0.354242
Average total loss: 0.703868
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.3144e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.345944
Average KL loss: 0.354527
Average total loss: 0.700470
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.5104e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.346292
Average KL loss: 0.354455
Average total loss: 0.700747
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.4760e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.347208
Average KL loss: 0.355035
Average total loss: 0.702243
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.2904e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.348467
Average KL loss: 0.355129
Average total loss: 0.703596
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.5056e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.343601
Average KL loss: 0.355368
Average total loss: 0.698969
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.2818e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.344697
Average KL loss: 0.354407
Average total loss: 0.699104
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.3304e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.343879
Average KL loss: 0.354758
Average total loss: 0.698638
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.8615e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.344634
Average KL loss: 0.354368
Average total loss: 0.699002
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.2432e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.341981
Average KL loss: 0.354352
Average total loss: 0.696333
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(9.6541e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.340398
Average KL loss: 0.354365
Average total loss: 0.694762
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.8412e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.344459
Average KL loss: 0.355045
Average total loss: 0.699504
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.2449e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.345375
Average KL loss: 0.354936
Average total loss: 0.700311
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(8.1161e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.342058
Average KL loss: 0.355088
Average total loss: 0.697146
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8695e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.339846
Average KL loss: 0.354766
Average total loss: 0.694612
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.9763e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.344684
Average KL loss: 0.354907
Average total loss: 0.699591
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.2818e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.337842
Average KL loss: 0.355038
Average total loss: 0.692880
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.1627e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.339800
Average KL loss: 0.355030
Average total loss: 0.694830
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-8.6042e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.341756
Average KL loss: 0.354359
Average total loss: 0.696114
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.1508e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.346700
Average KL loss: 0.355059
Average total loss: 0.701758
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.1451e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.342515
Average KL loss: 0.355094
Average total loss: 0.697610
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.0888e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.340038
Average KL loss: 0.354600
Average total loss: 0.694639
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.7073e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.343970
Average KL loss: 0.354996
Average total loss: 0.698966
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.3991e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.340003
Average KL loss: 0.355364
Average total loss: 0.695367
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.2211e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.341644
Average KL loss: 0.355413
Average total loss: 0.697057
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.3629e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.343463
Average KL loss: 0.355998
Average total loss: 0.699460
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.3050e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.339177
Average KL loss: 0.356011
Average total loss: 0.695188
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.9239e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.338700
Average KL loss: 0.354916
Average total loss: 0.693615
tensor(0.0037, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.0060e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.339296
Average KL loss: 0.353266
Average total loss: 0.692562
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(8.7799e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.337215
Average KL loss: 0.349819
Average total loss: 0.687034
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.3297e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.336762
Average KL loss: 0.347448
Average total loss: 0.684210
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.6380e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.337545
Average KL loss: 0.345682
Average total loss: 0.683227
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.1755e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.336690
Average KL loss: 0.344352
Average total loss: 0.681043
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.5022e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.336063
Average KL loss: 0.343168
Average total loss: 0.679231
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.2646e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.337490
Average KL loss: 0.342262
Average total loss: 0.679752
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.0054e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.341334
Average KL loss: 0.341398
Average total loss: 0.682732
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(8.4128e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.339481
Average KL loss: 0.340670
Average total loss: 0.680152
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-7.5965e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.336563
Average KL loss: 0.340000
Average total loss: 0.676563
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.3159e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.342081
Average KL loss: 0.339483
Average total loss: 0.681565
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.3234e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.340193
Average KL loss: 0.338953
Average total loss: 0.679147
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.3556e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.338165
Average KL loss: 0.338450
Average total loss: 0.676615
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.5181e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.337999
Average KL loss: 0.337980
Average total loss: 0.675979
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.0857e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.337604
Average KL loss: 0.337582
Average total loss: 0.675186
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(5.9762e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.340667
Average KL loss: 0.337132
Average total loss: 0.677799
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.3855e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.337485
Average KL loss: 0.336823
Average total loss: 0.674308
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1162e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.337692
Average KL loss: 0.336557
Average total loss: 0.674249
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.8024e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.337228
Average KL loss: 0.336282
Average total loss: 0.673510
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.7304e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.332587
Average KL loss: 0.336116
Average total loss: 0.668703
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.0907e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.346724
Average KL loss: 0.335826
Average total loss: 0.682550
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.8982e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.337583
Average KL loss: 0.335610
Average total loss: 0.673193
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.4540e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.337398
Average KL loss: 0.335311
Average total loss: 0.672709
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.5875e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.332270
Average KL loss: 0.335108
Average total loss: 0.667378
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(6.2122e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.340367
Average KL loss: 0.334889
Average total loss: 0.675256
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.7563e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.336034
Average KL loss: 0.334719
Average total loss: 0.670753
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.0878e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.340493
Average KL loss: 0.334566
Average total loss: 0.675059
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(6.0866e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.337218
Average KL loss: 0.334386
Average total loss: 0.671605
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.9662e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.336111
Average KL loss: 0.334254
Average total loss: 0.670365
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.1105e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.338089
Average KL loss: 0.334127
Average total loss: 0.672216
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.1109e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.337412
Average KL loss: 0.333985
Average total loss: 0.671397
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.9586e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.340824
Average KL loss: 0.333938
Average total loss: 0.674762
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.4348e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.337620
Average KL loss: 0.333897
Average total loss: 0.671518
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.8017e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.338132
Average KL loss: 0.333796
Average total loss: 0.671929
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.4509e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.338233
Average KL loss: 0.333617
Average total loss: 0.671850
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-9.8319e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.341655
Average KL loss: 0.333511
Average total loss: 0.675166
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.7725e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.335500
Average KL loss: 0.333441
Average total loss: 0.668940
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.1504e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.338877
Average KL loss: 0.333361
Average total loss: 0.672238
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.5703e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.338382
Average KL loss: 0.333284
Average total loss: 0.671666
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(6.4693e-11, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.338922
Average KL loss: 0.333221
Average total loss: 0.672143
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.7107e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.336399
Average KL loss: 0.333172
Average total loss: 0.669571
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(5.1902e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.339517
Average KL loss: 0.333116
Average total loss: 0.672633
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.3165e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.337181
Average KL loss: 0.333061
Average total loss: 0.670241
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(9.5120e-11, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.335501
Average KL loss: 0.333016
Average total loss: 0.668517
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(6.3754e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.336869
Average KL loss: 0.332965
Average total loss: 0.669834
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.9111e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.336465
Average KL loss: 0.332916
Average total loss: 0.669381
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-7.8369e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.335943
Average KL loss: 0.332887
Average total loss: 0.668829
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.9680e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.340055
Average KL loss: 0.332881
Average total loss: 0.672936
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.2632e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.338709
Average KL loss: 0.332876
Average total loss: 0.671584
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.4819e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.332329
Average KL loss: 0.332870
Average total loss: 0.665198
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.1451e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.337890
Average KL loss: 0.332865
Average total loss: 0.670755
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-9.3033e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.335295
Average KL loss: 0.332860
Average total loss: 0.668154
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.1627e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.336541
Average KL loss: 0.332854
Average total loss: 0.669395
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.0750e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.341313
Average KL loss: 0.332848
Average total loss: 0.674161
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.9416e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.339078
Average KL loss: 0.332844
Average total loss: 0.671922
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.0403e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.338172
Average KL loss: 0.332839
Average total loss: 0.671011
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.1655e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.341052
Average KL loss: 0.332834
Average total loss: 0.673886
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-7.5697e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.340411
Average KL loss: 0.332829
Average total loss: 0.673240
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.3438e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.334861
Average KL loss: 0.332825
Average total loss: 0.667685
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(4.6108e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.340935
Average KL loss: 0.332821
Average total loss: 0.673757
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.2413e-09, device='cuda:0')
 Percentile value: 0.004428365034982562
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =     163 /    1728             (  9.43%) | total_pruned =    1565 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     841 /   36864             (  2.28%) | total_pruned =   36023 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2604 /   36864             (  7.06%) | total_pruned =   34260 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1898 /   36864             (  5.15%) | total_pruned =   34966 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3495 /   36864             (  9.48%) | total_pruned =   33369 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   11997 /   73728             ( 16.27%) | total_pruned =   61731 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   22572 /  147456             ( 15.31%) | total_pruned =  124884 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1597 /    8192             ( 19.49%) | total_pruned =    6595 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   16979 /  147456             ( 11.51%) | total_pruned =  130477 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   13756 /  147456             (  9.33%) | total_pruned =  133700 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   47117 /  294912             ( 15.98%) | total_pruned =  247795 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   86166 /  589824             ( 14.61%) | total_pruned =  503658 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5985 /   32768             ( 18.26%) | total_pruned =   26783 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     202 /     256             ( 78.91%) | total_pruned =      54 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   77366 /  589824             ( 13.12%) | total_pruned =  512458 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   58513 /  589824             (  9.92%) | total_pruned =  531311 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  171915 / 1179648             ( 14.57%) | total_pruned = 1007733 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     472 /     512             ( 92.19%) | total_pruned =      40 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  243281 / 2359296             ( 10.31%) | total_pruned = 2116015 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     355 /     512             ( 69.34%) | total_pruned =     157 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     154 /     512             ( 30.08%) | total_pruned =     358 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   11680 /  131072             (  8.91%) | total_pruned =  119392 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     333 /     512             ( 65.04%) | total_pruned =     179 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  191727 / 2359296             (  8.13%) | total_pruned = 2167569 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     378 /     512             ( 73.83%) | total_pruned =     134 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  418163 / 2359296             ( 17.72%) | total_pruned = 1941133 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     472 /     512             ( 92.19%) | total_pruned =      40 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     469 /     512             ( 91.60%) | total_pruned =      43 | shape = torch.Size([512])
linear.weight        | nonzeros =    4632 /    5120             ( 90.47%) | total_pruned =     488 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 63/100 Loss: 0.024489 Accuracy: 89.63 100.00 % Best test Accuracy: 89.63%
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-7.9826e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.674449
Average KL loss: 0.330061
Average total loss: 1.004511
tensor(0.0039, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.0908e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.556908
Average KL loss: 0.350139
Average total loss: 0.907047
tensor(0.0038, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.6640e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.512851
Average KL loss: 0.357126
Average total loss: 0.869977
tensor(0.0038, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.6491e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.503710
Average KL loss: 0.360335
Average total loss: 0.864045
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.3076e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.492228
Average KL loss: 0.362067
Average total loss: 0.854295
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.2033e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.479827
Average KL loss: 0.363240
Average total loss: 0.843067
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.5257e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.464867
Average KL loss: 0.363312
Average total loss: 0.828179
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.3797e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.462172
Average KL loss: 0.363847
Average total loss: 0.826019
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.7032e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.452782
Average KL loss: 0.365162
Average total loss: 0.817944
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-9.4389e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.449199
Average KL loss: 0.365244
Average total loss: 0.814443
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.0148e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.452156
Average KL loss: 0.366486
Average total loss: 0.818642
tensor(0.0036, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.5177e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.440846
Average KL loss: 0.367149
Average total loss: 0.807995
tensor(0.0036, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-8.4218e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.434469
Average KL loss: 0.367210
Average total loss: 0.801678
tensor(0.0036, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.2621e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.437355
Average KL loss: 0.367642
Average total loss: 0.804996
tensor(0.0036, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.2991e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.429052
Average KL loss: 0.368355
Average total loss: 0.797407
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.4976e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.430285
Average KL loss: 0.368820
Average total loss: 0.799105
tensor(0.0036, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.8199e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.425554
Average KL loss: 0.368575
Average total loss: 0.794130
tensor(0.0036, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.3191e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.423323
Average KL loss: 0.369307
Average total loss: 0.792629
tensor(0.0036, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.4149e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.422128
Average KL loss: 0.369278
Average total loss: 0.791407
tensor(0.0036, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.0134e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.416618
Average KL loss: 0.369152
Average total loss: 0.785770
tensor(0.0036, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.9389e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.415638
Average KL loss: 0.369618
Average total loss: 0.785257
tensor(0.0036, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.1268e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.414392
Average KL loss: 0.369497
Average total loss: 0.783890
tensor(0.0036, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.7422e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.418495
Average KL loss: 0.370955
Average total loss: 0.789450
tensor(0.0036, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.4435e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.411379
Average KL loss: 0.370934
Average total loss: 0.782313
tensor(0.0036, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.5334e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.409517
Average KL loss: 0.370651
Average total loss: 0.780168
tensor(0.0036, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.6075e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.414637
Average KL loss: 0.370966
Average total loss: 0.785603
tensor(0.0036, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.4602e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.408510
Average KL loss: 0.372097
Average total loss: 0.780607
tensor(0.0036, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.3066e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.411973
Average KL loss: 0.372385
Average total loss: 0.784358
tensor(0.0036, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.1261e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.405920
Average KL loss: 0.371855
Average total loss: 0.777776
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.1792e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.403361
Average KL loss: 0.372220
Average total loss: 0.775581
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.4504e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.403671
Average KL loss: 0.371545
Average total loss: 0.775215
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.4911e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.406769
Average KL loss: 0.372023
Average total loss: 0.778792
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.9668e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.402220
Average KL loss: 0.372274
Average total loss: 0.774494
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-9.1694e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.396937
Average KL loss: 0.372163
Average total loss: 0.769101
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.0053e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.400618
Average KL loss: 0.371858
Average total loss: 0.772476
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.0580e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.399652
Average KL loss: 0.371865
Average total loss: 0.771517
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.6963e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.397264
Average KL loss: 0.371817
Average total loss: 0.769081
tensor(0.0036, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.4525e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.396970
Average KL loss: 0.371185
Average total loss: 0.768155
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.2464e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.395835
Average KL loss: 0.371999
Average total loss: 0.767834
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.0037e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.398634
Average KL loss: 0.372237
Average total loss: 0.770872
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4550e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.399574
Average KL loss: 0.373462
Average total loss: 0.773036
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.4667e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.391016
Average KL loss: 0.372629
Average total loss: 0.763645
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(4.2388e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.391278
Average KL loss: 0.372009
Average total loss: 0.763287
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(7.7018e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.393706
Average KL loss: 0.372458
Average total loss: 0.766164
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.8885e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.394884
Average KL loss: 0.372592
Average total loss: 0.767476
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.4600e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.391509
Average KL loss: 0.372370
Average total loss: 0.763879
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.2906e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.393677
Average KL loss: 0.371983
Average total loss: 0.765660
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.4051e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.391314
Average KL loss: 0.372552
Average total loss: 0.763866
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.5527e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.387054
Average KL loss: 0.372466
Average total loss: 0.759520
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.2277e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.390963
Average KL loss: 0.373080
Average total loss: 0.764042
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.8453e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.394456
Average KL loss: 0.373271
Average total loss: 0.767728
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.1556e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.387256
Average KL loss: 0.373219
Average total loss: 0.760476
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.1741e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.386815
Average KL loss: 0.372865
Average total loss: 0.759680
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.7458e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.389416
Average KL loss: 0.373098
Average total loss: 0.762514
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.9092e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.392269
Average KL loss: 0.373240
Average total loss: 0.765510
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.9743e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.389149
Average KL loss: 0.373275
Average total loss: 0.762424
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.5110e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.387353
Average KL loss: 0.372947
Average total loss: 0.760300
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.1463e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.392606
Average KL loss: 0.373837
Average total loss: 0.766443
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.7472e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.382552
Average KL loss: 0.373749
Average total loss: 0.756301
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.5113e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.392021
Average KL loss: 0.373268
Average total loss: 0.765289
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.0626e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.384280
Average KL loss: 0.373784
Average total loss: 0.758064
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.9236e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.384446
Average KL loss: 0.373102
Average total loss: 0.757548
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.2166e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.383915
Average KL loss: 0.373880
Average total loss: 0.757795
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.2332e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.382448
Average KL loss: 0.373513
Average total loss: 0.755962
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6651e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.388753
Average KL loss: 0.373581
Average total loss: 0.762334
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.1082e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.382171
Average KL loss: 0.374148
Average total loss: 0.756319
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.8275e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.380869
Average KL loss: 0.373352
Average total loss: 0.754222
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.7418e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.378335
Average KL loss: 0.373466
Average total loss: 0.751802
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.0480e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.383478
Average KL loss: 0.372947
Average total loss: 0.756425
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.8575e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.381398
Average KL loss: 0.373256
Average total loss: 0.754654
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.7338e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.380902
Average KL loss: 0.373255
Average total loss: 0.754157
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.7447e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.382977
Average KL loss: 0.373867
Average total loss: 0.756844
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(7.4730e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.380863
Average KL loss: 0.373965
Average total loss: 0.754828
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.4217e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.383040
Average KL loss: 0.373019
Average total loss: 0.756059
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.0022e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.384480
Average KL loss: 0.373613
Average total loss: 0.758093
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(7.1770e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.380721
Average KL loss: 0.374062
Average total loss: 0.754783
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.2593e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.379642
Average KL loss: 0.373942
Average total loss: 0.753584
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.0322e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.380734
Average KL loss: 0.373823
Average total loss: 0.754557
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.0439e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.383525
Average KL loss: 0.374157
Average total loss: 0.757682
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.4791e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.379526
Average KL loss: 0.372642
Average total loss: 0.752168
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.2981e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.380010
Average KL loss: 0.370318
Average total loss: 0.750328
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.5546e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.375174
Average KL loss: 0.368633
Average total loss: 0.743808
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.9595e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.378662
Average KL loss: 0.367151
Average total loss: 0.745813
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.2342e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.381431
Average KL loss: 0.365957
Average total loss: 0.747389
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.1847e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.376572
Average KL loss: 0.365004
Average total loss: 0.741576
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.7947e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.381123
Average KL loss: 0.364066
Average total loss: 0.745190
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.6797e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.380095
Average KL loss: 0.363363
Average total loss: 0.743458
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1725e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.376528
Average KL loss: 0.362649
Average total loss: 0.739177
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.0613e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.374469
Average KL loss: 0.361952
Average total loss: 0.736422
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.6156e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.374181
Average KL loss: 0.361326
Average total loss: 0.735508
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.7208e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.380219
Average KL loss: 0.360753
Average total loss: 0.740972
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.6988e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.381087
Average KL loss: 0.360367
Average total loss: 0.741454
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.1041e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.377662
Average KL loss: 0.359950
Average total loss: 0.737612
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.0398e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.373997
Average KL loss: 0.359495
Average total loss: 0.733493
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.1990e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.378479
Average KL loss: 0.359052
Average total loss: 0.737531
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.2817e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.377686
Average KL loss: 0.358710
Average total loss: 0.736395
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.0461e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.377202
Average KL loss: 0.358431
Average total loss: 0.735633
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.5907e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.379095
Average KL loss: 0.358252
Average total loss: 0.737347
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.1234e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.372721
Average KL loss: 0.358013
Average total loss: 0.730734
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(7.2624e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.377261
Average KL loss: 0.357676
Average total loss: 0.734937
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.2600e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.377094
Average KL loss: 0.357426
Average total loss: 0.734520
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.2153e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.377196
Average KL loss: 0.357104
Average total loss: 0.734301
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(9.2805e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.381546
Average KL loss: 0.356814
Average total loss: 0.738360
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.7382e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.378477
Average KL loss: 0.356610
Average total loss: 0.735087
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.4327e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.372154
Average KL loss: 0.356482
Average total loss: 0.728636
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(7.0187e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.378185
Average KL loss: 0.356196
Average total loss: 0.734381
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.4495e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.375746
Average KL loss: 0.355914
Average total loss: 0.731660
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.4656e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.380693
Average KL loss: 0.355701
Average total loss: 0.736393
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.5471e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.375967
Average KL loss: 0.355556
Average total loss: 0.731523
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.7218e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.382307
Average KL loss: 0.355413
Average total loss: 0.737720
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.7786e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.372681
Average KL loss: 0.355263
Average total loss: 0.727944
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.5742e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.377883
Average KL loss: 0.355103
Average total loss: 0.732986
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.0452e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.377566
Average KL loss: 0.355038
Average total loss: 0.732604
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.9377e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.377790
Average KL loss: 0.354929
Average total loss: 0.732719
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.5487e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.378085
Average KL loss: 0.354851
Average total loss: 0.732936
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.8298e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.373917
Average KL loss: 0.354663
Average total loss: 0.728580
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.3217e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.374062
Average KL loss: 0.354652
Average total loss: 0.728714
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.3859e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.379553
Average KL loss: 0.354640
Average total loss: 0.734193
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.9178e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.378064
Average KL loss: 0.354544
Average total loss: 0.732607
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.4249e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.374338
Average KL loss: 0.354451
Average total loss: 0.728788
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.0952e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.380910
Average KL loss: 0.354326
Average total loss: 0.735236
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.5888e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.377917
Average KL loss: 0.354221
Average total loss: 0.732138
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.9030e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.374180
Average KL loss: 0.354174
Average total loss: 0.728353
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.0930e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.378248
Average KL loss: 0.354124
Average total loss: 0.732372
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.4353e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.380504
Average KL loss: 0.354080
Average total loss: 0.734584
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.7663e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.378126
Average KL loss: 0.354037
Average total loss: 0.732162
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.4919e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.381649
Average KL loss: 0.354002
Average total loss: 0.735651
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.3764e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.378108
Average KL loss: 0.353966
Average total loss: 0.732074
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.6274e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.375905
Average KL loss: 0.353927
Average total loss: 0.729832
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.4013e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.380629
Average KL loss: 0.353898
Average total loss: 0.734527
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.1106e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.378122
Average KL loss: 0.353877
Average total loss: 0.731999
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.4897e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.378214
Average KL loss: 0.353854
Average total loss: 0.732069
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1015e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.370932
Average KL loss: 0.353833
Average total loss: 0.724765
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.8059e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.373870
Average KL loss: 0.353798
Average total loss: 0.727668
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.3024e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.380599
Average KL loss: 0.353763
Average total loss: 0.734362
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.3784e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.381416
Average KL loss: 0.353740
Average total loss: 0.735156
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(7.8814e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.376872
Average KL loss: 0.353701
Average total loss: 0.730573
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.9129e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.377934
Average KL loss: 0.353662
Average total loss: 0.731597
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.8679e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.380876
Average KL loss: 0.353633
Average total loss: 0.734508
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.0300e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.378095
Average KL loss: 0.353616
Average total loss: 0.731711
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.5126e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.377940
Average KL loss: 0.353589
Average total loss: 0.731529
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.9366e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.379071
Average KL loss: 0.353557
Average total loss: 0.732628
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.6196e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.375553
Average KL loss: 0.353529
Average total loss: 0.729082
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.8672e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.377083
Average KL loss: 0.353502
Average total loss: 0.730585
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.9015e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.376632
Average KL loss: 0.353490
Average total loss: 0.730122
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.1805e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.376714
Average KL loss: 0.353488
Average total loss: 0.730202
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.7310e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.378244
Average KL loss: 0.353485
Average total loss: 0.731728
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.8738e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.381345
Average KL loss: 0.353484
Average total loss: 0.734828
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.0809e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.378881
Average KL loss: 0.353482
Average total loss: 0.732362
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.0376e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.373734
Average KL loss: 0.353479
Average total loss: 0.727213
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.2344e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.377277
Average KL loss: 0.353476
Average total loss: 0.730753
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.5827e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.375397
Average KL loss: 0.353474
Average total loss: 0.728871
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.8769e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.378204
Average KL loss: 0.353471
Average total loss: 0.731675
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.1722e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.373947
Average KL loss: 0.353468
Average total loss: 0.727415
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.8829e-09, device='cuda:0')
 Percentile value: 0.012392844073474407
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =     132 /    1728             (  7.64%) | total_pruned =    1596 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     402 /   36864             (  1.09%) | total_pruned =   36462 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1000 /   36864             (  2.71%) | total_pruned =   35864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     820 /   36864             (  2.22%) | total_pruned =   36044 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1532 /   36864             (  4.16%) | total_pruned =   35332 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    6857 /   73728             (  9.30%) | total_pruned =   66871 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   12994 /  147456             (  8.81%) | total_pruned =  134462 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     916 /    8192             ( 11.18%) | total_pruned =    7276 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    9468 /  147456             (  6.42%) | total_pruned =  137988 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    6963 /  147456             (  4.72%) | total_pruned =  140493 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   28330 /  294912             (  9.61%) | total_pruned =  266582 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   49531 /  589824             (  8.40%) | total_pruned =  540293 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3440 /   32768             ( 10.50%) | total_pruned =   29328 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     184 /     256             ( 71.88%) | total_pruned =      72 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   41223 /  589824             (  6.99%) | total_pruned =  548601 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   27008 /  589824             (  4.58%) | total_pruned =  562816 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   91323 / 1179648             (  7.74%) | total_pruned = 1088325 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     457 /     512             ( 89.26%) | total_pruned =      55 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      35 /     512             (  6.84%) | total_pruned =     477 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  108524 / 2359296             (  4.60%) | total_pruned = 2250772 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     316 /     512             ( 61.72%) | total_pruned =     196 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     140 /     512             ( 27.34%) | total_pruned =     372 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4408 /  131072             (  3.36%) | total_pruned =  126664 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     245 /     512             ( 47.85%) | total_pruned =     267 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     146 /     512             ( 28.52%) | total_pruned =     366 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   84292 / 2359296             (  3.57%) | total_pruned = 2275004 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     294 /     512             ( 57.42%) | total_pruned =     218 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  211031 / 2359296             (  8.94%) | total_pruned = 2148265 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     437 /     512             ( 85.35%) | total_pruned =      75 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     428 /     512             ( 83.59%) | total_pruned =      84 | shape = torch.Size([512])
linear.weight        | nonzeros =    4119 /    5120             ( 80.45%) | total_pruned =    1001 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 70/100 Loss: 0.016733 Accuracy: 88.91 100.00 % Best test Accuracy: 88.95%
tensor(0.0037, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.1107e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.652380
Average KL loss: 0.336612
Average total loss: 0.988992
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.0378e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.573860
Average KL loss: 0.346469
Average total loss: 0.920329
tensor(0.0036, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1700e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.528444
Average KL loss: 0.353253
Average total loss: 0.881697
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.0197e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.514878
Average KL loss: 0.357253
Average total loss: 0.872131
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.0299e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.501749
Average KL loss: 0.359067
Average total loss: 0.860816
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-8.0228e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.489858
Average KL loss: 0.360203
Average total loss: 0.850062
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.7959e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.486066
Average KL loss: 0.361779
Average total loss: 0.847846
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.9837e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.477719
Average KL loss: 0.362976
Average total loss: 0.840694
tensor(0.0034, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.5690e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.468892
Average KL loss: 0.364073
Average total loss: 0.832965
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.5499e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.461488
Average KL loss: 0.365108
Average total loss: 0.826596
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.1965e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.463728
Average KL loss: 0.365221
Average total loss: 0.828950
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.1570e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.461452
Average KL loss: 0.365936
Average total loss: 0.827387
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.6630e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.457622
Average KL loss: 0.367067
Average total loss: 0.824689
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.1256e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.453837
Average KL loss: 0.368074
Average total loss: 0.821911
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.9103e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.446378
Average KL loss: 0.368294
Average total loss: 0.814671
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(5.0032e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.441224
Average KL loss: 0.368228
Average total loss: 0.809452
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.6269e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.443975
Average KL loss: 0.368494
Average total loss: 0.812469
tensor(0.0034, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.6896e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.437586
Average KL loss: 0.369369
Average total loss: 0.806955
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.8637e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.438851
Average KL loss: 0.369269
Average total loss: 0.808120
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(1.3700e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.440222
Average KL loss: 0.369632
Average total loss: 0.809854
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.8325e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.437847
Average KL loss: 0.370551
Average total loss: 0.808398
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(2.4326e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.436121
Average KL loss: 0.370713
Average total loss: 0.806835
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(1.6623e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.437977
Average KL loss: 0.371260
Average total loss: 0.809238
tensor(0.0034, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.7723e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.435128
Average KL loss: 0.371414
Average total loss: 0.806541
tensor(0.0034, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.9187e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.428823
Average KL loss: 0.371936
Average total loss: 0.800759
tensor(0.0034, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(8.1210e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.423529
Average KL loss: 0.371834
Average total loss: 0.795363
tensor(0.0034, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.0477e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.426355
Average KL loss: 0.370837
Average total loss: 0.797191
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.1269e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.432329
Average KL loss: 0.372087
Average total loss: 0.804416
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.8082e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.430518
Average KL loss: 0.372606
Average total loss: 0.803124
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.0789e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.434441
Average KL loss: 0.373318
Average total loss: 0.807760
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(4.5812e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.426669
Average KL loss: 0.373690
Average total loss: 0.800359
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(4.2446e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.420257
Average KL loss: 0.373188
Average total loss: 0.793445
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.2018e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.423005
Average KL loss: 0.372417
Average total loss: 0.795422
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.2770e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.423828
Average KL loss: 0.372946
Average total loss: 0.796774
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.8289e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.419132
Average KL loss: 0.373261
Average total loss: 0.792393
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.6509e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.430028
Average KL loss: 0.373215
Average total loss: 0.803242
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.4513e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.426760
Average KL loss: 0.374192
Average total loss: 0.800953
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(5.8773e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.423559
Average KL loss: 0.374177
Average total loss: 0.797736
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.4911e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.422153
Average KL loss: 0.373844
Average total loss: 0.795997
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.2707e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.421806
Average KL loss: 0.374081
Average total loss: 0.795887
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.4983e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.419623
Average KL loss: 0.374537
Average total loss: 0.794160
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.3130e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.418111
Average KL loss: 0.373879
Average total loss: 0.791990
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.5339e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.417396
Average KL loss: 0.373861
Average total loss: 0.791257
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(9.2340e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.417725
Average KL loss: 0.373657
Average total loss: 0.791382
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.0469e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.414711
Average KL loss: 0.373414
Average total loss: 0.788125
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.3091e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.414946
Average KL loss: 0.373843
Average total loss: 0.788789
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.4368e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.414391
Average KL loss: 0.373702
Average total loss: 0.788093
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(2.2788e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.413489
Average KL loss: 0.373908
Average total loss: 0.787396
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(4.3108e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.415665
Average KL loss: 0.373882
Average total loss: 0.789547
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.1828e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.414980
Average KL loss: 0.374496
Average total loss: 0.789476
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(9.9719e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.419483
Average KL loss: 0.374592
Average total loss: 0.794074
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3178e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.418339
Average KL loss: 0.375048
Average total loss: 0.793387
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.7891e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.417632
Average KL loss: 0.375659
Average total loss: 0.793291
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(6.2636e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.415978
Average KL loss: 0.374647
Average total loss: 0.790625
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.5023e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.417981
Average KL loss: 0.374979
Average total loss: 0.792960
tensor(0.0034, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.6433e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.410924
Average KL loss: 0.374994
Average total loss: 0.785918
tensor(0.0034, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.3948e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.415067
Average KL loss: 0.374867
Average total loss: 0.789933
tensor(0.0034, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.5975e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.408446
Average KL loss: 0.375082
Average total loss: 0.783528
tensor(0.0034, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.6045e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.414816
Average KL loss: 0.375634
Average total loss: 0.790451
tensor(0.0034, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-9.1895e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.416419
Average KL loss: 0.375802
Average total loss: 0.792221
tensor(0.0034, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0769e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.410999
Average KL loss: 0.375953
Average total loss: 0.786953
tensor(0.0034, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.7635e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.415620
Average KL loss: 0.375710
Average total loss: 0.791330
tensor(0.0034, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.6650e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.410528
Average KL loss: 0.375507
Average total loss: 0.786035
tensor(0.0034, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6619e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.411688
Average KL loss: 0.375603
Average total loss: 0.787292
tensor(0.0034, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.0764e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.414768
Average KL loss: 0.375442
Average total loss: 0.790209
tensor(0.0034, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.7007e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.410651
Average KL loss: 0.375872
Average total loss: 0.786523
tensor(0.0034, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.5350e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.417563
Average KL loss: 0.376442
Average total loss: 0.794005
tensor(0.0034, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.3630e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.410376
Average KL loss: 0.376363
Average total loss: 0.786739
tensor(0.0034, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.5382e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.406462
Average KL loss: 0.376796
Average total loss: 0.783258
tensor(0.0034, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.4795e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.411629
Average KL loss: 0.376558
Average total loss: 0.788187
tensor(0.0034, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.9071e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.406550
Average KL loss: 0.376414
Average total loss: 0.782964
tensor(0.0034, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.4580e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.413667
Average KL loss: 0.376610
Average total loss: 0.790277
tensor(0.0034, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.1854e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.409915
Average KL loss: 0.377405
Average total loss: 0.787320
tensor(0.0034, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(7.3067e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.404671
Average KL loss: 0.377283
Average total loss: 0.781955
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.0716e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.410077
Average KL loss: 0.377420
Average total loss: 0.787497
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.1775e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.412574
Average KL loss: 0.377027
Average total loss: 0.789602
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.3973e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.408258
Average KL loss: 0.376981
Average total loss: 0.785239
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.6943e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.407650
Average KL loss: 0.376662
Average total loss: 0.784312
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.4131e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.409293
Average KL loss: 0.377182
Average total loss: 0.786475
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.0255e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.407943
Average KL loss: 0.376588
Average total loss: 0.784532
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.7959e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.404268
Average KL loss: 0.377095
Average total loss: 0.781363
tensor(0.0035, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.8174e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.406305
Average KL loss: 0.376546
Average total loss: 0.782851
tensor(0.0035, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.2666e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.406665
Average KL loss: 0.376310
Average total loss: 0.782975
tensor(0.0035, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.7071e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.406229
Average KL loss: 0.376582
Average total loss: 0.782811
tensor(0.0035, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6963e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.406498
Average KL loss: 0.376595
Average total loss: 0.783093
tensor(0.0035, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(7.4868e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.406342
Average KL loss: 0.376522
Average total loss: 0.782864
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.5411e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.405669
Average KL loss: 0.377104
Average total loss: 0.782774
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.1043e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.410992
Average KL loss: 0.377473
Average total loss: 0.788465
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.1315e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.405523
Average KL loss: 0.377987
Average total loss: 0.783509
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.1412e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.407341
Average KL loss: 0.377750
Average total loss: 0.785092
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(8.5415e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.406456
Average KL loss: 0.378055
Average total loss: 0.784512
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(5.4716e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.402390
Average KL loss: 0.377072
Average total loss: 0.779461
tensor(0.0035, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.8071e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.403696
Average KL loss: 0.377427
Average total loss: 0.781123
tensor(0.0035, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.5875e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.411658
Average KL loss: 0.378004
Average total loss: 0.789662
tensor(0.0035, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.7939e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.405380
Average KL loss: 0.377953
Average total loss: 0.783333
tensor(0.0035, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.1144e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.409079
Average KL loss: 0.377748
Average total loss: 0.786827
tensor(0.0035, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.4931e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.400580
Average KL loss: 0.377417
Average total loss: 0.777997
tensor(0.0035, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.6510e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.399903
Average KL loss: 0.377870
Average total loss: 0.777773
tensor(0.0035, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.7320e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.404839
Average KL loss: 0.377930
Average total loss: 0.782769
tensor(0.0035, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.8317e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.402489
Average KL loss: 0.377893
Average total loss: 0.780382
tensor(0.0035, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.0095e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.405696
Average KL loss: 0.377636
Average total loss: 0.783333
tensor(0.0035, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.4097e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.403908
Average KL loss: 0.377306
Average total loss: 0.781213
tensor(0.0035, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.7190e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.405913
Average KL loss: 0.377040
Average total loss: 0.782954
tensor(0.0035, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(6.7388e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.400657
Average KL loss: 0.376755
Average total loss: 0.777412
tensor(0.0035, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(4.6240e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.401119
Average KL loss: 0.376876
Average total loss: 0.777995
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.5207e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.403022
Average KL loss: 0.376741
Average total loss: 0.779763
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.3052e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.407015
Average KL loss: 0.377175
Average total loss: 0.784190
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.6739e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.400606
Average KL loss: 0.377017
Average total loss: 0.777623
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8007e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.401200
Average KL loss: 0.377501
Average total loss: 0.778701
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.8160e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.403738
Average KL loss: 0.377677
Average total loss: 0.781415
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(4.7711e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.401739
Average KL loss: 0.377058
Average total loss: 0.778797
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.9877e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.405975
Average KL loss: 0.377668
Average total loss: 0.783643
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-6.6756e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.402135
Average KL loss: 0.378028
Average total loss: 0.780163
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.6621e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.404140
Average KL loss: 0.378475
Average total loss: 0.782615
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.1537e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.401848
Average KL loss: 0.379028
Average total loss: 0.780876
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.6273e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.402972
Average KL loss: 0.378061
Average total loss: 0.781033
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(2.8218e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.400186
Average KL loss: 0.376447
Average total loss: 0.776633
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.7901e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.399938
Average KL loss: 0.375113
Average total loss: 0.775051
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.8274e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.396165
Average KL loss: 0.374057
Average total loss: 0.770222
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.2930e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.400711
Average KL loss: 0.373163
Average total loss: 0.773874
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.1243e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.399422
Average KL loss: 0.372424
Average total loss: 0.771845
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-7.9003e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.399250
Average KL loss: 0.371704
Average total loss: 0.770955
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.4730e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.399167
Average KL loss: 0.371030
Average total loss: 0.770196
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(4.9266e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.397436
Average KL loss: 0.370377
Average total loss: 0.767813
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.1123e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.399071
Average KL loss: 0.369739
Average total loss: 0.768810
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-6.6881e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.401283
Average KL loss: 0.369176
Average total loss: 0.770459
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.3634e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.401263
Average KL loss: 0.368667
Average total loss: 0.769930
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(4.0483e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.399200
Average KL loss: 0.368225
Average total loss: 0.767425
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.9334e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.399956
Average KL loss: 0.367830
Average total loss: 0.767786
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.4690e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.398590
Average KL loss: 0.367481
Average total loss: 0.766071
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.3385e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.403764
Average KL loss: 0.367099
Average total loss: 0.770862
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.3981e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.399979
Average KL loss: 0.366726
Average total loss: 0.766705
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.2264e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.401084
Average KL loss: 0.366393
Average total loss: 0.767477
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.4549e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.397664
Average KL loss: 0.366065
Average total loss: 0.763729
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8195e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.399727
Average KL loss: 0.365789
Average total loss: 0.765516
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.2415e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.396809
Average KL loss: 0.365551
Average total loss: 0.762360
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.3856e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.402566
Average KL loss: 0.365328
Average total loss: 0.767894
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.3619e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.403889
Average KL loss: 0.365083
Average total loss: 0.768972
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.6016e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.399827
Average KL loss: 0.364901
Average total loss: 0.764728
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.0741e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.403344
Average KL loss: 0.364619
Average total loss: 0.767963
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.7507e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.402747
Average KL loss: 0.364362
Average total loss: 0.767109
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.0885e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.401127
Average KL loss: 0.364223
Average total loss: 0.765350
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(8.5886e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.401735
Average KL loss: 0.364005
Average total loss: 0.765740
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.1400e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.398362
Average KL loss: 0.363853
Average total loss: 0.762215
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(4.3521e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.400079
Average KL loss: 0.363613
Average total loss: 0.763692
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(4.7622e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.401614
Average KL loss: 0.363439
Average total loss: 0.765053
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.0740e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.398653
Average KL loss: 0.363278
Average total loss: 0.761931
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.4414e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.400615
Average KL loss: 0.363070
Average total loss: 0.763685
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.7682e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.397924
Average KL loss: 0.362929
Average total loss: 0.760853
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.6721e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.400257
Average KL loss: 0.362839
Average total loss: 0.763096
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.1495e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.401186
Average KL loss: 0.362736
Average total loss: 0.763922
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.6568e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.400854
Average KL loss: 0.362557
Average total loss: 0.763412
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.4804e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.396119
Average KL loss: 0.362386
Average total loss: 0.758505
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8189e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.404969
Average KL loss: 0.362284
Average total loss: 0.767253
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.2533e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.398282
Average KL loss: 0.362079
Average total loss: 0.760361
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.6112e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.397544
Average KL loss: 0.361960
Average total loss: 0.759504
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.3838e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.402350
Average KL loss: 0.361914
Average total loss: 0.764264
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.7895e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.397862
Average KL loss: 0.361759
Average total loss: 0.759622
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.8352e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.402982
Average KL loss: 0.361632
Average total loss: 0.764614
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.7016e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.403309
Average KL loss: 0.361622
Average total loss: 0.764931
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.9585e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.395432
Average KL loss: 0.361461
Average total loss: 0.756893
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(4.3847e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.398724
Average KL loss: 0.361281
Average total loss: 0.760005
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.9218e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.404517
Average KL loss: 0.361162
Average total loss: 0.765679
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.0028e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.398813
Average KL loss: 0.361087
Average total loss: 0.759901
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(4.9967e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.401741
Average KL loss: 0.360924
Average total loss: 0.762665
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.2985e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.402829
Average KL loss: 0.360862
Average total loss: 0.763691
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0039e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.403027
Average KL loss: 0.360842
Average total loss: 0.763869
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.0900e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.396751
Average KL loss: 0.360745
Average total loss: 0.757496
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.2958e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.393784
Average KL loss: 0.360597
Average total loss: 0.754381
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(5.3444e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.399454
Average KL loss: 0.360472
Average total loss: 0.759926
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.5875e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.401540
Average KL loss: 0.360348
Average total loss: 0.761887
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.8971e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.400335
Average KL loss: 0.360306
Average total loss: 0.760640
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(4.7534e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.397821
Average KL loss: 0.360257
Average total loss: 0.758078
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8305e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.398790
Average KL loss: 0.360129
Average total loss: 0.758919
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.6939e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.400607
Average KL loss: 0.360058
Average total loss: 0.760665
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.6605e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.402727
Average KL loss: 0.359987
Average total loss: 0.762713
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.8493e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.399557
Average KL loss: 0.359964
Average total loss: 0.759521
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.3472e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.396950
Average KL loss: 0.359926
Average total loss: 0.756877
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8817e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.397834
Average KL loss: 0.359879
Average total loss: 0.757713
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8663e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.399064
Average KL loss: 0.359834
Average total loss: 0.758898
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(4.0675e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.400543
Average KL loss: 0.359804
Average total loss: 0.760348
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.9999e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.399522
Average KL loss: 0.359780
Average total loss: 0.759302
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0118e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.397003
Average KL loss: 0.359748
Average total loss: 0.756752
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.5545e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.399476
Average KL loss: 0.359717
Average total loss: 0.759193
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.2711e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.401195
Average KL loss: 0.359688
Average total loss: 0.760884
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.0793e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.401510
Average KL loss: 0.359660
Average total loss: 0.761170
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.4020e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.398093
Average KL loss: 0.359637
Average total loss: 0.757730
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.2829e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.400843
Average KL loss: 0.359615
Average total loss: 0.760457
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.5546e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.403264
Average KL loss: 0.359591
Average total loss: 0.762855
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.6318e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.396480
Average KL loss: 0.359572
Average total loss: 0.756052
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.4306e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.401350
Average KL loss: 0.359550
Average total loss: 0.760900
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.7085e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.401916
Average KL loss: 0.359542
Average total loss: 0.761459
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.1589e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.397455
Average KL loss: 0.359540
Average total loss: 0.756995
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.3781e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.401978
Average KL loss: 0.359537
Average total loss: 0.761515
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.2755e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.397227
Average KL loss: 0.359535
Average total loss: 0.756762
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.0616e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.400559
Average KL loss: 0.359533
Average total loss: 0.760092
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.6662e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.397938
Average KL loss: 0.359531
Average total loss: 0.757469
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.7040e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.397395
Average KL loss: 0.359529
Average total loss: 0.756924
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.2954e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.402186
Average KL loss: 0.359527
Average total loss: 0.761713
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.0198e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.402924
Average KL loss: 0.359525
Average total loss: 0.762449
 Percentile value: 0.028203004971146584
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =     109 /    1728             (  6.31%) | total_pruned =    1619 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     211 /   36864             (  0.57%) | total_pruned =   36653 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     547 /   36864             (  1.48%) | total_pruned =   36317 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     482 /   36864             (  1.31%) | total_pruned =   36382 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     972 /   36864             (  2.64%) | total_pruned =   35892 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4548 /   73728             (  6.17%) | total_pruned =   69180 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    8364 /  147456             (  5.67%) | total_pruned =  139092 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     614 /    8192             (  7.50%) | total_pruned =    7578 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    5699 /  147456             (  3.86%) | total_pruned =  141757 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4195 /  147456             (  2.84%) | total_pruned =  143261 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   17905 /  294912             (  6.07%) | total_pruned =  277007 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   29203 /  589824             (  4.95%) | total_pruned =  560621 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2144 /   32768             (  6.54%) | total_pruned =   30624 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     170 /     256             ( 66.41%) | total_pruned =      86 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   22712 /  589824             (  3.85%) | total_pruned =  567112 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   13779 /  589824             (  2.34%) | total_pruned =  576045 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   48248 / 1179648             (  4.09%) | total_pruned = 1131400 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     441 /     512             ( 86.13%) | total_pruned =      71 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   50904 / 2359296             (  2.16%) | total_pruned = 2308392 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     277 /     512             ( 54.10%) | total_pruned =     235 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1768 /  131072             (  1.35%) | total_pruned =  129304 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     172 /     512             ( 33.59%) | total_pruned =     340 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     118 /     512             ( 23.05%) | total_pruned =     394 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   35394 / 2359296             (  1.50%) | total_pruned = 2323902 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     224 /     512             ( 43.75%) | total_pruned =     288 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   94551 / 2359296             (  4.01%) | total_pruned = 2264745 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     369 /     512             ( 72.07%) | total_pruned =     143 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     346 /     512             ( 67.58%) | total_pruned =     166 | shape = torch.Size([512])
linear.weight        | nonzeros =    3177 /    5120             ( 62.05%) | total_pruned =    1943 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 59/100 Loss: 0.020624 Accuracy: 87.87 100.00 % Best test Accuracy: 88.00%
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.3347e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.718729
Average KL loss: 0.336331
Average total loss: 1.055060
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.2091e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.640845
Average KL loss: 0.336231
Average total loss: 0.977076
tensor(0.0033, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.3257e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.607130
Average KL loss: 0.340933
Average total loss: 0.948063
tensor(0.0032, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.4262e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.581028
Average KL loss: 0.344441
Average total loss: 0.925469
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.1446e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.571861
Average KL loss: 0.346596
Average total loss: 0.918457
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.6361e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.554732
Average KL loss: 0.347663
Average total loss: 0.902395
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.5598e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.544478
Average KL loss: 0.348603
Average total loss: 0.893081
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-8.1547e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.530173
Average KL loss: 0.350104
Average total loss: 0.880277
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0202e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.525458
Average KL loss: 0.352031
Average total loss: 0.877489
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0077e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.515807
Average KL loss: 0.353775
Average total loss: 0.869583
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0944e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.518281
Average KL loss: 0.355522
Average total loss: 0.873803
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.3859e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.516776
Average KL loss: 0.356634
Average total loss: 0.873410
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.4938e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.503744
Average KL loss: 0.357301
Average total loss: 0.861045
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.4773e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.500766
Average KL loss: 0.358453
Average total loss: 0.859219
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.5264e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.500663
Average KL loss: 0.359349
Average total loss: 0.860012
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.7667e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.489677
Average KL loss: 0.360300
Average total loss: 0.849977
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.8900e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.496991
Average KL loss: 0.361052
Average total loss: 0.858043
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.3318e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.487138
Average KL loss: 0.362103
Average total loss: 0.849242
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.1074e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.485003
Average KL loss: 0.362712
Average total loss: 0.847715
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.1486e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.486413
Average KL loss: 0.363176
Average total loss: 0.849589
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.7207e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.483753
Average KL loss: 0.363672
Average total loss: 0.847425
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.8148e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.488099
Average KL loss: 0.364309
Average total loss: 0.852408
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.0205e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.481708
Average KL loss: 0.364977
Average total loss: 0.846685
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.1728e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.483148
Average KL loss: 0.365071
Average total loss: 0.848220
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.9409e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.481627
Average KL loss: 0.365936
Average total loss: 0.847563
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.1978e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.469350
Average KL loss: 0.366073
Average total loss: 0.835423
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.6470e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.473828
Average KL loss: 0.366128
Average total loss: 0.839956
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.7336e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.472044
Average KL loss: 0.366256
Average total loss: 0.838300
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.9177e-11, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.477863
Average KL loss: 0.366644
Average total loss: 0.844507
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.8503e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.473294
Average KL loss: 0.367012
Average total loss: 0.840306
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(2.1564e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.465748
Average KL loss: 0.366977
Average total loss: 0.832725
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.3395e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.472251
Average KL loss: 0.366615
Average total loss: 0.838866
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1007e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.465793
Average KL loss: 0.366848
Average total loss: 0.832641
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.5993e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.471198
Average KL loss: 0.367860
Average total loss: 0.839059
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.3311e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.469279
Average KL loss: 0.368775
Average total loss: 0.838054
tensor(0.0031, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-7.3491e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.463008
Average KL loss: 0.369235
Average total loss: 0.832244
tensor(0.0031, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.4361e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.460948
Average KL loss: 0.369733
Average total loss: 0.830681
tensor(0.0031, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.5962e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.460581
Average KL loss: 0.369277
Average total loss: 0.829858
tensor(0.0031, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(4.0422e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.462236
Average KL loss: 0.369365
Average total loss: 0.831600
tensor(0.0031, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.1826e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.466354
Average KL loss: 0.369982
Average total loss: 0.836336
tensor(0.0031, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.9377e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.463491
Average KL loss: 0.370285
Average total loss: 0.833776
tensor(0.0031, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.6012e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.459157
Average KL loss: 0.370300
Average total loss: 0.829457
tensor(0.0031, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.8811e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.462611
Average KL loss: 0.370352
Average total loss: 0.832963
tensor(0.0031, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.3283e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.459632
Average KL loss: 0.370758
Average total loss: 0.830390
tensor(0.0031, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.6433e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.459757
Average KL loss: 0.371343
Average total loss: 0.831100
tensor(0.0031, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(6.7153e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.459415
Average KL loss: 0.371367
Average total loss: 0.830782
tensor(0.0031, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.4229e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.455090
Average KL loss: 0.371700
Average total loss: 0.826790
tensor(0.0031, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(1.5354e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.458055
Average KL loss: 0.371819
Average total loss: 0.829874
tensor(0.0031, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.1858e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.453916
Average KL loss: 0.372360
Average total loss: 0.826276
tensor(0.0031, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.0551e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.458435
Average KL loss: 0.372095
Average total loss: 0.830531
tensor(0.0031, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.1624e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.456034
Average KL loss: 0.371974
Average total loss: 0.828008
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.8127e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.451796
Average KL loss: 0.371691
Average total loss: 0.823488
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.7054e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.453104
Average KL loss: 0.371789
Average total loss: 0.824893
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(5.6037e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.449758
Average KL loss: 0.371372
Average total loss: 0.821131
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.7797e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.450146
Average KL loss: 0.371198
Average total loss: 0.821344
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(5.4834e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.458378
Average KL loss: 0.371121
Average total loss: 0.829499
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.6439e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.452637
Average KL loss: 0.371448
Average total loss: 0.824085
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.0972e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.450249
Average KL loss: 0.371947
Average total loss: 0.822196
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(2.8884e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.450425
Average KL loss: 0.371998
Average total loss: 0.822422
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.4015e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.450902
Average KL loss: 0.371929
Average total loss: 0.822831
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.0987e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.457105
Average KL loss: 0.372546
Average total loss: 0.829651
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.1794e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.449797
Average KL loss: 0.372569
Average total loss: 0.822366
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.7442e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.451353
Average KL loss: 0.372186
Average total loss: 0.823540
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0502e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.445448
Average KL loss: 0.372226
Average total loss: 0.817674
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(8.7142e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.450099
Average KL loss: 0.372861
Average total loss: 0.822960
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.3182e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.446137
Average KL loss: 0.373169
Average total loss: 0.819306
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.9629e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.447363
Average KL loss: 0.373520
Average total loss: 0.820883
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6343e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.455157
Average KL loss: 0.373418
Average total loss: 0.828574
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.2941e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.445073
Average KL loss: 0.373544
Average total loss: 0.818617
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.5960e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.446426
Average KL loss: 0.373126
Average total loss: 0.819552
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.0428e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.447579
Average KL loss: 0.373729
Average total loss: 0.821308
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.9866e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.450293
Average KL loss: 0.373769
Average total loss: 0.824062
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.1125e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.449270
Average KL loss: 0.373959
Average total loss: 0.823229
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.5708e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.445575
Average KL loss: 0.373791
Average total loss: 0.819366
tensor(0.0032, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(8.3351e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.444435
Average KL loss: 0.373531
Average total loss: 0.817966
tensor(0.0032, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.1762e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.446930
Average KL loss: 0.373109
Average total loss: 0.820038
tensor(0.0032, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3401e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.449120
Average KL loss: 0.372180
Average total loss: 0.821300
tensor(0.0032, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0149e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.445940
Average KL loss: 0.371420
Average total loss: 0.817359
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.3021e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.446117
Average KL loss: 0.370748
Average total loss: 0.816865
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(9.7869e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.441693
Average KL loss: 0.370110
Average total loss: 0.811802
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.5516e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.446459
Average KL loss: 0.369536
Average total loss: 0.815994
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.0585e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.443693
Average KL loss: 0.369044
Average total loss: 0.812736
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-8.6077e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.445903
Average KL loss: 0.368645
Average total loss: 0.814548
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.0299e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.441359
Average KL loss: 0.368226
Average total loss: 0.809585
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.8847e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.445323
Average KL loss: 0.367828
Average total loss: 0.813151
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.9328e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.446387
Average KL loss: 0.367518
Average total loss: 0.813905
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.1511e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.442687
Average KL loss: 0.367216
Average total loss: 0.809903
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.8558e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.440142
Average KL loss: 0.366857
Average total loss: 0.806999
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(4.2302e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.440041
Average KL loss: 0.366508
Average total loss: 0.806549
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.7602e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.445174
Average KL loss: 0.366221
Average total loss: 0.811395
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6718e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.445154
Average KL loss: 0.365881
Average total loss: 0.811035
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.4517e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.445553
Average KL loss: 0.365640
Average total loss: 0.811193
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.1857e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.451630
Average KL loss: 0.365350
Average total loss: 0.816980
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.8559e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.440598
Average KL loss: 0.365106
Average total loss: 0.805704
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.9920e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.447209
Average KL loss: 0.364837
Average total loss: 0.812046
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.4256e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.440121
Average KL loss: 0.364610
Average total loss: 0.804730
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.1251e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.443177
Average KL loss: 0.364365
Average total loss: 0.807542
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.8941e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.448237
Average KL loss: 0.364167
Average total loss: 0.812404
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.7960e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.444724
Average KL loss: 0.363952
Average total loss: 0.808676
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.3265e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.439515
Average KL loss: 0.363730
Average total loss: 0.803245
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.2219e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.437921
Average KL loss: 0.363545
Average total loss: 0.801466
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.4444e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.447319
Average KL loss: 0.363326
Average total loss: 0.810644
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.6893e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.441725
Average KL loss: 0.363143
Average total loss: 0.804868
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(7.0746e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.439289
Average KL loss: 0.362965
Average total loss: 0.802254
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.2171e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.435699
Average KL loss: 0.362792
Average total loss: 0.798491
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.7348e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.442067
Average KL loss: 0.362581
Average total loss: 0.804648
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(6.0793e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.444651
Average KL loss: 0.362389
Average total loss: 0.807040
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.9200e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.437344
Average KL loss: 0.362240
Average total loss: 0.799584
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.2158e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.436800
Average KL loss: 0.362106
Average total loss: 0.798907
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.7382e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.440919
Average KL loss: 0.361953
Average total loss: 0.802872
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.7139e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.445197
Average KL loss: 0.361841
Average total loss: 0.807038
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.5862e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.443606
Average KL loss: 0.361696
Average total loss: 0.805302
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(6.0868e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.440906
Average KL loss: 0.361566
Average total loss: 0.802472
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(4.4188e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.443115
Average KL loss: 0.361427
Average total loss: 0.804542
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.8880e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.445349
Average KL loss: 0.361323
Average total loss: 0.806671
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(5.1203e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.442328
Average KL loss: 0.361189
Average total loss: 0.803518
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.5751e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.444588
Average KL loss: 0.361123
Average total loss: 0.805710
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.2651e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.442979
Average KL loss: 0.361106
Average total loss: 0.804085
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.9506e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.440059
Average KL loss: 0.361088
Average total loss: 0.801147
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.7276e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.441459
Average KL loss: 0.361062
Average total loss: 0.802521
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(4.8063e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.442486
Average KL loss: 0.361031
Average total loss: 0.803516
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.0662e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.439599
Average KL loss: 0.361008
Average total loss: 0.800608
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(5.3079e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.437233
Average KL loss: 0.360987
Average total loss: 0.798220
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6802e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.441062
Average KL loss: 0.360963
Average total loss: 0.802025
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.8278e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.442134
Average KL loss: 0.360941
Average total loss: 0.803075
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.1348e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.443651
Average KL loss: 0.360917
Average total loss: 0.804567
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.6900e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.448506
Average KL loss: 0.360901
Average total loss: 0.809407
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.3823e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.441249
Average KL loss: 0.360889
Average total loss: 0.802138
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.4491e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.440346
Average KL loss: 0.360873
Average total loss: 0.801220
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(4.8729e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.440219
Average KL loss: 0.360847
Average total loss: 0.801066
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.4882e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.445464
Average KL loss: 0.360831
Average total loss: 0.806295
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.5989e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.447179
Average KL loss: 0.360813
Average total loss: 0.807992
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.4505e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.443674
Average KL loss: 0.360792
Average total loss: 0.804466
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.3168e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.437592
Average KL loss: 0.360771
Average total loss: 0.798364
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.5082e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.444134
Average KL loss: 0.360759
Average total loss: 0.804894
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.6335e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.440567
Average KL loss: 0.360757
Average total loss: 0.801324
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.7192e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.444485
Average KL loss: 0.360756
Average total loss: 0.805241
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.0591e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.442058
Average KL loss: 0.360754
Average total loss: 0.802813
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(7.2754e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.443461
Average KL loss: 0.360752
Average total loss: 0.804213
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.7985e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.447937
Average KL loss: 0.360751
Average total loss: 0.808688
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.6882e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.440475
Average KL loss: 0.360749
Average total loss: 0.801224
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.5027e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.441941
Average KL loss: 0.360747
Average total loss: 0.802687
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.4745e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.445114
Average KL loss: 0.360744
Average total loss: 0.805858
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(4.8379e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.438660
Average KL loss: 0.360742
Average total loss: 0.799402
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.7529e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.435667
Average KL loss: 0.360740
Average total loss: 0.796406
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1117e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.439547
Average KL loss: 0.360737
Average total loss: 0.800284
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.2930e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.441471
Average KL loss: 0.360735
Average total loss: 0.802206
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.6464e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.440081
Average KL loss: 0.360733
Average total loss: 0.800813
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.3941e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.440842
Average KL loss: 0.360730
Average total loss: 0.801572
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.4682e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.435915
Average KL loss: 0.360728
Average total loss: 0.796644
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.1567e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.442565
Average KL loss: 0.360726
Average total loss: 0.803291
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.3226e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.445942
Average KL loss: 0.360724
Average total loss: 0.806666
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.9852e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.442486
Average KL loss: 0.360723
Average total loss: 0.803209
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.4089e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.440573
Average KL loss: 0.360721
Average total loss: 0.801294
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.5007e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.443362
Average KL loss: 0.360719
Average total loss: 0.804081
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.5230e-09, device='cuda:0')
 Percentile value: 0.06341907382011414
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =     104 /    1728             (  6.02%) | total_pruned =    1624 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     139 /   36864             (  0.38%) | total_pruned =   36725 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     227 /   36864             (  0.62%) | total_pruned =   36637 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     298 /   36864             (  0.81%) | total_pruned =   36566 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     629 /   36864             (  1.71%) | total_pruned =   36235 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2733 /   73728             (  3.71%) | total_pruned =   70995 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5396 /  147456             (  3.66%) | total_pruned =  142060 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     378 /    8192             (  4.61%) | total_pruned =    7814 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3465 /  147456             (  2.35%) | total_pruned =  143991 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2566 /  147456             (  1.74%) | total_pruned =  144890 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   11315 /  294912             (  3.84%) | total_pruned =  283597 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     214 /     256             ( 83.59%) | total_pruned =      42 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   17731 /  589824             (  3.01%) | total_pruned =  572093 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1354 /   32768             (  4.13%) | total_pruned =   31414 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   12325 /  589824             (  2.09%) | total_pruned =  577499 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    7351 /  589824             (  1.25%) | total_pruned =  582473 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     136 /     256             ( 53.12%) | total_pruned =     120 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   24874 / 1179648             (  2.11%) | total_pruned = 1154774 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     425 /     512             ( 83.01%) | total_pruned =      87 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   23711 / 2359296             (  1.01%) | total_pruned = 2335585 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     222 /     512             ( 43.36%) | total_pruned =     290 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      90 /     512             ( 17.58%) | total_pruned =     422 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     688 /  131072             (  0.52%) | total_pruned =  130384 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     105 /     512             ( 20.51%) | total_pruned =     407 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   15583 / 2359296             (  0.66%) | total_pruned = 2343713 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     168 /     512             ( 32.81%) | total_pruned =     344 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   38314 / 2359296             (  1.62%) | total_pruned = 2320982 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     291 /     512             ( 56.84%) | total_pruned =     221 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     257 /     512             ( 50.20%) | total_pruned =     255 | shape = torch.Size([512])
linear.weight        | nonzeros =    2212 /    5120             ( 43.20%) | total_pruned =    2908 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 66/100 Loss: 0.028982 Accuracy: 87.11 100.00 % Best test Accuracy: 87.24%
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.3567e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.813834
Average KL loss: 0.335938
Average total loss: 1.149772
tensor(0.0031, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.9429e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.714207
Average KL loss: 0.331079
Average total loss: 1.045287
tensor(0.0030, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.9243e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.687295
Average KL loss: 0.333727
Average total loss: 1.021022
tensor(0.0030, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.5651e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.650930
Average KL loss: 0.336857
Average total loss: 0.987788
tensor(0.0029, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.0697e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.632570
Average KL loss: 0.339092
Average total loss: 0.971662
tensor(0.0029, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.0839e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.623543
Average KL loss: 0.340995
Average total loss: 0.964538
tensor(0.0029, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.1097e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.598214
Average KL loss: 0.342388
Average total loss: 0.940602
tensor(0.0029, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.4665e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.591897
Average KL loss: 0.344571
Average total loss: 0.936467
tensor(0.0029, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.4275e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.584822
Average KL loss: 0.346524
Average total loss: 0.931346
tensor(0.0029, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.6065e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.567973
Average KL loss: 0.348694
Average total loss: 0.916667
tensor(0.0028, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.5483e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.564130
Average KL loss: 0.350252
Average total loss: 0.914382
tensor(0.0028, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.3520e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.557622
Average KL loss: 0.351813
Average total loss: 0.909435
tensor(0.0028, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-3.2806e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.556447
Average KL loss: 0.352853
Average total loss: 0.909301
tensor(0.0028, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-7.5393e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.549504
Average KL loss: 0.354000
Average total loss: 0.903504
tensor(0.0028, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.5624e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.552400
Average KL loss: 0.355255
Average total loss: 0.907655
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.9075e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.537477
Average KL loss: 0.355798
Average total loss: 0.893275
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-5.1921e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.546181
Average KL loss: 0.356676
Average total loss: 0.902856
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.5819e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.534991
Average KL loss: 0.357949
Average total loss: 0.892940
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-9.2358e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.533347
Average KL loss: 0.359109
Average total loss: 0.892455
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.2305e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.527542
Average KL loss: 0.359397
Average total loss: 0.886940
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.0569e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.525971
Average KL loss: 0.359544
Average total loss: 0.885515
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.3300e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.528880
Average KL loss: 0.360436
Average total loss: 0.889317
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.9873e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.527538
Average KL loss: 0.361163
Average total loss: 0.888700
tensor(0.0028, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.5733e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.515207
Average KL loss: 0.362142
Average total loss: 0.877350
tensor(0.0028, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.8800e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.510991
Average KL loss: 0.362626
Average total loss: 0.873617
tensor(0.0028, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.9802e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.516642
Average KL loss: 0.362734
Average total loss: 0.879376
tensor(0.0028, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.2026e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.510038
Average KL loss: 0.363043
Average total loss: 0.873081
tensor(0.0028, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-8.3559e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.505992
Average KL loss: 0.363422
Average total loss: 0.869414
tensor(0.0028, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.8401e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.508609
Average KL loss: 0.363906
Average total loss: 0.872515
tensor(0.0028, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(9.5816e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.510131
Average KL loss: 0.364777
Average total loss: 0.874909
tensor(0.0028, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.2414e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.499212
Average KL loss: 0.365278
Average total loss: 0.864491
tensor(0.0028, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.2921e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.500852
Average KL loss: 0.365904
Average total loss: 0.866756
tensor(0.0028, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.0696e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.508532
Average KL loss: 0.366325
Average total loss: 0.874857
tensor(0.0028, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.4242e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.503573
Average KL loss: 0.366492
Average total loss: 0.870065
tensor(0.0028, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.7484e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.499365
Average KL loss: 0.367032
Average total loss: 0.866397
tensor(0.0028, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.7106e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.496421
Average KL loss: 0.367818
Average total loss: 0.864239
tensor(0.0028, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.2084e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.487534
Average KL loss: 0.368173
Average total loss: 0.855707
tensor(0.0028, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.2321e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.498202
Average KL loss: 0.367743
Average total loss: 0.865944
tensor(0.0028, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.3650e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.501230
Average KL loss: 0.368077
Average total loss: 0.869307
tensor(0.0028, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(3.4082e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.492870
Average KL loss: 0.368358
Average total loss: 0.861227
tensor(0.0028, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.2071e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.500445
Average KL loss: 0.368656
Average total loss: 0.869101
tensor(0.0028, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(3.2978e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.485611
Average KL loss: 0.368650
Average total loss: 0.854261
tensor(0.0029, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1497e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.494387
Average KL loss: 0.368759
Average total loss: 0.863146
tensor(0.0029, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(2.4887e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.484755
Average KL loss: 0.369233
Average total loss: 0.853988
tensor(0.0029, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.2981e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.487484
Average KL loss: 0.369413
Average total loss: 0.856897
tensor(0.0029, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.8108e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.484160
Average KL loss: 0.370164
Average total loss: 0.854323
tensor(0.0029, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.4509e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.492025
Average KL loss: 0.370399
Average total loss: 0.862424
tensor(0.0029, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(3.8710e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.487335
Average KL loss: 0.371021
Average total loss: 0.858356
tensor(0.0029, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.7782e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.483822
Average KL loss: 0.371343
Average total loss: 0.855166
tensor(0.0029, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.2165e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.481259
Average KL loss: 0.371483
Average total loss: 0.852743
tensor(0.0029, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.6329e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.487290
Average KL loss: 0.371424
Average total loss: 0.858714
tensor(0.0029, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(3.1086e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.483308
Average KL loss: 0.371703
Average total loss: 0.855011
tensor(0.0029, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.4185e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.475087
Average KL loss: 0.372189
Average total loss: 0.847276
tensor(0.0029, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.3546e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.482023
Average KL loss: 0.372066
Average total loss: 0.854089
tensor(0.0029, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-9.3542e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.481589
Average KL loss: 0.372250
Average total loss: 0.853840
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.7414e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.481131
Average KL loss: 0.372223
Average total loss: 0.853354
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.5277e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.476565
Average KL loss: 0.372221
Average total loss: 0.848786
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.6462e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.477861
Average KL loss: 0.372448
Average total loss: 0.850309
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.5908e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.475071
Average KL loss: 0.373068
Average total loss: 0.848139
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.7610e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.483420
Average KL loss: 0.373464
Average total loss: 0.856884
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.3559e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.479256
Average KL loss: 0.373573
Average total loss: 0.852829
tensor(0.0029, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(4.4379e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.477302
Average KL loss: 0.373671
Average total loss: 0.850973
tensor(0.0029, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(1.0445e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.472203
Average KL loss: 0.374373
Average total loss: 0.846577
tensor(0.0029, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.1028e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.473104
Average KL loss: 0.374644
Average total loss: 0.847748
tensor(0.0029, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.9827e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.466358
Average KL loss: 0.374355
Average total loss: 0.840713
tensor(0.0029, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(3.5608e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.479417
Average KL loss: 0.374580
Average total loss: 0.853997
tensor(0.0029, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.1357e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.471897
Average KL loss: 0.375353
Average total loss: 0.847250
tensor(0.0029, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.0442e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.475848
Average KL loss: 0.375467
Average total loss: 0.851315
tensor(0.0029, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.0268e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.467643
Average KL loss: 0.374939
Average total loss: 0.842582
tensor(0.0029, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.4963e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.473910
Average KL loss: 0.374945
Average total loss: 0.848855
tensor(0.0029, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(6.7052e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.477459
Average KL loss: 0.375286
Average total loss: 0.852745
tensor(0.0029, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.6367e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.465271
Average KL loss: 0.375095
Average total loss: 0.840366
tensor(0.0029, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.9479e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.470587
Average KL loss: 0.375513
Average total loss: 0.846101
tensor(0.0029, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(4.2988e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.468023
Average KL loss: 0.375873
Average total loss: 0.843896
tensor(0.0029, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.9433e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.472438
Average KL loss: 0.376278
Average total loss: 0.848717
tensor(0.0029, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(2.5321e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.473134
Average KL loss: 0.376639
Average total loss: 0.849773
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.6806e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.463478
Average KL loss: 0.376980
Average total loss: 0.840458
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.0572e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.462800
Average KL loss: 0.376730
Average total loss: 0.839529
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.6139e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.469987
Average KL loss: 0.376698
Average total loss: 0.846685
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.0595e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.469702
Average KL loss: 0.376726
Average total loss: 0.846428
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.1439e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.471178
Average KL loss: 0.376507
Average total loss: 0.847685
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.0289e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.464999
Average KL loss: 0.376751
Average total loss: 0.841749
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.9936e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.468445
Average KL loss: 0.376576
Average total loss: 0.845021
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(5.9230e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.467005
Average KL loss: 0.376322
Average total loss: 0.843327
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.6578e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.466726
Average KL loss: 0.376577
Average total loss: 0.843303
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.1587e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.467206
Average KL loss: 0.377189
Average total loss: 0.844395
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.7288e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.460546
Average KL loss: 0.377586
Average total loss: 0.838133
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.9186e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.461417
Average KL loss: 0.377697
Average total loss: 0.839114
tensor(0.0029, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.8897e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.466414
Average KL loss: 0.377651
Average total loss: 0.844065
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.6954e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.461367
Average KL loss: 0.378015
Average total loss: 0.839383
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4674e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.462643
Average KL loss: 0.377964
Average total loss: 0.840606
tensor(0.0029, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.5239e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.462219
Average KL loss: 0.377998
Average total loss: 0.840217
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.5915e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.456371
Average KL loss: 0.378020
Average total loss: 0.834391
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.8354e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.463508
Average KL loss: 0.378015
Average total loss: 0.841522
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.5689e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.459918
Average KL loss: 0.378468
Average total loss: 0.838386
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(5.2550e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.457025
Average KL loss: 0.378799
Average total loss: 0.835824
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(5.0334e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.462886
Average KL loss: 0.378500
Average total loss: 0.841387
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.7836e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.456535
Average KL loss: 0.378246
Average total loss: 0.834781
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.5059e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.457941
Average KL loss: 0.377946
Average total loss: 0.835886
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.2672e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.457589
Average KL loss: 0.377963
Average total loss: 0.835551
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.4408e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.466021
Average KL loss: 0.378241
Average total loss: 0.844262
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.8095e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.462610
Average KL loss: 0.378541
Average total loss: 0.841150
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.3985e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.464992
Average KL loss: 0.378459
Average total loss: 0.843451
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.7249e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.457463
Average KL loss: 0.378434
Average total loss: 0.835897
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.9370e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.462430
Average KL loss: 0.378192
Average total loss: 0.840621
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.3977e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.464946
Average KL loss: 0.377752
Average total loss: 0.842698
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.5483e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.453258
Average KL loss: 0.377352
Average total loss: 0.830610
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.6905e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.457760
Average KL loss: 0.376949
Average total loss: 0.834710
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.0952e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.462477
Average KL loss: 0.376620
Average total loss: 0.839096
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.5525e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.464857
Average KL loss: 0.376321
Average total loss: 0.841178
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.5565e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.461659
Average KL loss: 0.376028
Average total loss: 0.837686
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.3212e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.463355
Average KL loss: 0.375682
Average total loss: 0.839036
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.8652e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.463029
Average KL loss: 0.375403
Average total loss: 0.838432
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.3121e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.458846
Average KL loss: 0.375149
Average total loss: 0.833995
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(7.4272e-11, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.457895
Average KL loss: 0.374880
Average total loss: 0.832775
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.7778e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.459860
Average KL loss: 0.374641
Average total loss: 0.834500
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.5068e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.453614
Average KL loss: 0.374416
Average total loss: 0.828030
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.4809e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.464156
Average KL loss: 0.374181
Average total loss: 0.838338
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3810e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.455177
Average KL loss: 0.373984
Average total loss: 0.829160
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.0356e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.461103
Average KL loss: 0.373794
Average total loss: 0.834897
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.6055e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.457220
Average KL loss: 0.373595
Average total loss: 0.830815
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.6622e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.458029
Average KL loss: 0.373337
Average total loss: 0.831365
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.8963e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.462649
Average KL loss: 0.373127
Average total loss: 0.835775
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.2315e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.456852
Average KL loss: 0.372937
Average total loss: 0.829789
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.6457e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.458790
Average KL loss: 0.372747
Average total loss: 0.831537
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.2293e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.463950
Average KL loss: 0.372534
Average total loss: 0.836484
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.5118e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.456100
Average KL loss: 0.372379
Average total loss: 0.828479
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.3111e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.451169
Average KL loss: 0.372145
Average total loss: 0.823314
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.4849e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.458184
Average KL loss: 0.371938
Average total loss: 0.830121
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(9.4789e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.459485
Average KL loss: 0.371805
Average total loss: 0.831290
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.1060e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.457135
Average KL loss: 0.371614
Average total loss: 0.828749
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.7401e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.462567
Average KL loss: 0.371416
Average total loss: 0.833983
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.1008e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.457514
Average KL loss: 0.371313
Average total loss: 0.828828
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.2240e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.455281
Average KL loss: 0.371144
Average total loss: 0.826425
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.8240e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.462069
Average KL loss: 0.371029
Average total loss: 0.833098
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.0413e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.456206
Average KL loss: 0.370938
Average total loss: 0.827144
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.0727e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.458657
Average KL loss: 0.370850
Average total loss: 0.829507
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.4716e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.464773
Average KL loss: 0.370754
Average total loss: 0.835528
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.1703e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.456858
Average KL loss: 0.370622
Average total loss: 0.827480
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.2711e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.456892
Average KL loss: 0.370557
Average total loss: 0.827449
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.0317e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.456103
Average KL loss: 0.370540
Average total loss: 0.826642
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.2652e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.458838
Average KL loss: 0.370523
Average total loss: 0.829361
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.2106e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.455492
Average KL loss: 0.370505
Average total loss: 0.825997
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.9230e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.451786
Average KL loss: 0.370485
Average total loss: 0.822271
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.6210e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.461735
Average KL loss: 0.370465
Average total loss: 0.832200
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.5384e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.457284
Average KL loss: 0.370443
Average total loss: 0.827728
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.7620e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.459346
Average KL loss: 0.370427
Average total loss: 0.829772
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.2977e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.457195
Average KL loss: 0.370410
Average total loss: 0.827605
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.4346e-11, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.457526
Average KL loss: 0.370393
Average total loss: 0.827919
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.8790e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.453145
Average KL loss: 0.370376
Average total loss: 0.823521
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(8.2746e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.458319
Average KL loss: 0.370357
Average total loss: 0.828677
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.2878e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.452034
Average KL loss: 0.370335
Average total loss: 0.822369
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.2318e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.453778
Average KL loss: 0.370313
Average total loss: 0.824092
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.5773e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.455514
Average KL loss: 0.370295
Average total loss: 0.825809
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.3266e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.457980
Average KL loss: 0.370284
Average total loss: 0.828264
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.1128e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.461151
Average KL loss: 0.370276
Average total loss: 0.831427
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.2415e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.459789
Average KL loss: 0.370274
Average total loss: 0.830062
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.9640e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.460030
Average KL loss: 0.370272
Average total loss: 0.830303
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(8.0423e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.457618
Average KL loss: 0.370271
Average total loss: 0.827888
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.7695e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.458139
Average KL loss: 0.370270
Average total loss: 0.828408
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.9102e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.457074
Average KL loss: 0.370268
Average total loss: 0.827342
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.1539e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.457689
Average KL loss: 0.370266
Average total loss: 0.827955
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.5022e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.459400
Average KL loss: 0.370264
Average total loss: 0.829665
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.0054e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.461370
Average KL loss: 0.370262
Average total loss: 0.831632
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.1307e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.457219
Average KL loss: 0.370260
Average total loss: 0.827479
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.7739e-10, device='cuda:0')
 Percentile value: 0.14114651083946228
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =     101 /    1728             (  5.84%) | total_pruned =    1627 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      78 /   36864             (  0.21%) | total_pruned =   36786 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     108 /   36864             (  0.29%) | total_pruned =   36756 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     179 /   36864             (  0.49%) | total_pruned =   36685 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     348 /   36864             (  0.94%) | total_pruned =   36516 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1572 /   73728             (  2.13%) | total_pruned =   72156 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3434 /  147456             (  2.33%) | total_pruned =  144022 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     217 /    8192             (  2.65%) | total_pruned =    7975 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2158 /  147456             (  1.46%) | total_pruned =  145298 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1660 /  147456             (  1.13%) | total_pruned =  145796 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7230 /  294912             (  2.45%) | total_pruned =  287682 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   10830 /  589824             (  1.84%) | total_pruned =  578994 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     202 /     256             ( 78.91%) | total_pruned =      54 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     800 /   32768             (  2.44%) | total_pruned =   31968 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     133 /     256             ( 51.95%) | total_pruned =     123 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6762 /  589824             (  1.15%) | total_pruned =  583062 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     183 /     256             ( 71.48%) | total_pruned =      73 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3997 /  589824             (  0.68%) | total_pruned =  585827 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12579 / 1179648             (  1.07%) | total_pruned = 1167069 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     398 /     512             ( 77.73%) | total_pruned =     114 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   11120 / 2359296             (  0.47%) | total_pruned = 2348176 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     181 /     512             ( 35.35%) | total_pruned =     331 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     277 /  131072             (  0.21%) | total_pruned =  130795 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    6709 / 2359296             (  0.28%) | total_pruned = 2352587 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     133 /     512             ( 25.98%) | total_pruned =     379 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   13345 / 2359296             (  0.57%) | total_pruned = 2345951 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     187 /     512             ( 36.52%) | total_pruned =     325 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     151 /     512             ( 29.49%) | total_pruned =     361 | shape = torch.Size([512])
linear.weight        | nonzeros =    1143 /    5120             ( 22.32%) | total_pruned =    3977 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 74/100 Loss: 0.024740 Accuracy: 86.15 99.98 % Best test Accuracy: 86.43%
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.8674e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.846235
Average KL loss: 0.346281
Average total loss: 1.192517
tensor(0.0029, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.4772e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.766042
Average KL loss: 0.337827
Average total loss: 1.103869
tensor(0.0028, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.6928e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.718102
Average KL loss: 0.338348
Average total loss: 1.056450
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.3466e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.696061
Average KL loss: 0.339600
Average total loss: 1.035661
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.7770e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.670600
Average KL loss: 0.340816
Average total loss: 1.011416
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2033e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.655532
Average KL loss: 0.341783
Average total loss: 0.997315
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.2098e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.638104
Average KL loss: 0.342779
Average total loss: 0.980883
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.3806e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.629854
Average KL loss: 0.344206
Average total loss: 0.974060
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.4679e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.615350
Average KL loss: 0.345856
Average total loss: 0.961206
tensor(0.0027, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.0308e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.610941
Average KL loss: 0.348061
Average total loss: 0.959002
tensor(0.0027, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-7.2838e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.602488
Average KL loss: 0.349928
Average total loss: 0.952416
tensor(0.0027, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.6204e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.599790
Average KL loss: 0.351429
Average total loss: 0.951219
tensor(0.0026, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.2837e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.583486
Average KL loss: 0.352728
Average total loss: 0.936213
tensor(0.0026, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.1686e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.570758
Average KL loss: 0.353886
Average total loss: 0.924644
tensor(0.0026, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(4.0234e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.575662
Average KL loss: 0.355015
Average total loss: 0.930677
tensor(0.0026, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.7373e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.567441
Average KL loss: 0.355947
Average total loss: 0.923388
tensor(0.0026, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.9542e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.573310
Average KL loss: 0.356847
Average total loss: 0.930158
tensor(0.0026, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.7640e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.566810
Average KL loss: 0.358121
Average total loss: 0.924932
tensor(0.0026, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.0133e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.564885
Average KL loss: 0.359067
Average total loss: 0.923952
tensor(0.0026, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.2374e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.548097
Average KL loss: 0.360181
Average total loss: 0.908278
tensor(0.0026, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.8387e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.542985
Average KL loss: 0.360890
Average total loss: 0.903875
tensor(0.0026, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-6.6456e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.543506
Average KL loss: 0.361327
Average total loss: 0.904833
tensor(0.0026, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.6976e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.548713
Average KL loss: 0.362001
Average total loss: 0.910714
tensor(0.0026, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.6002e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.552982
Average KL loss: 0.362700
Average total loss: 0.915682
tensor(0.0026, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.3134e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.544949
Average KL loss: 0.363442
Average total loss: 0.908391
tensor(0.0026, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.2415e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.545328
Average KL loss: 0.364225
Average total loss: 0.909554
tensor(0.0026, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.6948e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.537188
Average KL loss: 0.364709
Average total loss: 0.901897
tensor(0.0026, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.1025e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.542755
Average KL loss: 0.365233
Average total loss: 0.907988
tensor(0.0026, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.8377e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.534095
Average KL loss: 0.365553
Average total loss: 0.899648
tensor(0.0026, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.9053e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.530811
Average KL loss: 0.366208
Average total loss: 0.897019
tensor(0.0026, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(4.2575e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.532142
Average KL loss: 0.366522
Average total loss: 0.898664
tensor(0.0026, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.8773e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.524496
Average KL loss: 0.366901
Average total loss: 0.891397
tensor(0.0026, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.7026e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.525527
Average KL loss: 0.367357
Average total loss: 0.892884
tensor(0.0026, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.6952e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.537757
Average KL loss: 0.368057
Average total loss: 0.905814
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(1.9135e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.527081
Average KL loss: 0.368573
Average total loss: 0.895654
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.8925e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.514782
Average KL loss: 0.369490
Average total loss: 0.884272
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.6189e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.521117
Average KL loss: 0.369991
Average total loss: 0.891108
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-8.1080e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.524767
Average KL loss: 0.370160
Average total loss: 0.894927
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.8151e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.520504
Average KL loss: 0.370686
Average total loss: 0.891190
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.8096e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.518977
Average KL loss: 0.370948
Average total loss: 0.889925
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.3856e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.516670
Average KL loss: 0.371043
Average total loss: 0.887713
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.8425e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.509873
Average KL loss: 0.370974
Average total loss: 0.880847
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.2938e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.512616
Average KL loss: 0.371047
Average total loss: 0.883663
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.2306e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.515792
Average KL loss: 0.371704
Average total loss: 0.887496
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(3.0831e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.514232
Average KL loss: 0.372199
Average total loss: 0.886431
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.6792e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.510902
Average KL loss: 0.372576
Average total loss: 0.883478
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.4243e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.512833
Average KL loss: 0.373175
Average total loss: 0.886008
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(7.2542e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.507770
Average KL loss: 0.373730
Average total loss: 0.881500
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.7222e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.505657
Average KL loss: 0.374000
Average total loss: 0.879657
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.1465e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.510284
Average KL loss: 0.374448
Average total loss: 0.884732
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(6.9565e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.503967
Average KL loss: 0.374709
Average total loss: 0.878676
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.2363e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.497346
Average KL loss: 0.374962
Average total loss: 0.872308
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.1489e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.506861
Average KL loss: 0.375224
Average total loss: 0.882085
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.4740e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.502409
Average KL loss: 0.375519
Average total loss: 0.877927
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.9471e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.505703
Average KL loss: 0.375849
Average total loss: 0.881552
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(7.2828e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.495578
Average KL loss: 0.375963
Average total loss: 0.871541
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.1234e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.494130
Average KL loss: 0.376075
Average total loss: 0.870205
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(8.7695e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.505114
Average KL loss: 0.376288
Average total loss: 0.881401
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.4487e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.499922
Average KL loss: 0.376684
Average total loss: 0.876606
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.4485e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.498171
Average KL loss: 0.377001
Average total loss: 0.875172
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.7685e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.501819
Average KL loss: 0.377125
Average total loss: 0.878944
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.3237e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.498450
Average KL loss: 0.377319
Average total loss: 0.875769
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(4.7253e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.491966
Average KL loss: 0.377187
Average total loss: 0.869153
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.1999e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.491009
Average KL loss: 0.376978
Average total loss: 0.867987
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.5184e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.488596
Average KL loss: 0.377320
Average total loss: 0.865915
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(6.0039e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.490239
Average KL loss: 0.377447
Average total loss: 0.867686
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.9676e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.487551
Average KL loss: 0.377188
Average total loss: 0.864738
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.6405e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.489291
Average KL loss: 0.377131
Average total loss: 0.866422
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6270e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.488646
Average KL loss: 0.377341
Average total loss: 0.865987
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5297e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.491083
Average KL loss: 0.377340
Average total loss: 0.868422
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.5490e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.488471
Average KL loss: 0.378227
Average total loss: 0.866697
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.9423e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.490260
Average KL loss: 0.378618
Average total loss: 0.868878
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.2184e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.487161
Average KL loss: 0.378719
Average total loss: 0.865880
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.5892e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.487599
Average KL loss: 0.378874
Average total loss: 0.866473
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.7110e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.487559
Average KL loss: 0.379277
Average total loss: 0.866836
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.8313e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.482324
Average KL loss: 0.379242
Average total loss: 0.861566
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.3693e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.485833
Average KL loss: 0.379150
Average total loss: 0.864983
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.5676e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.488398
Average KL loss: 0.379306
Average total loss: 0.867704
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.3636e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.487935
Average KL loss: 0.379134
Average total loss: 0.867069
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0105e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.488242
Average KL loss: 0.379479
Average total loss: 0.867721
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.1871e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.495214
Average KL loss: 0.379623
Average total loss: 0.874837
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6392e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.483047
Average KL loss: 0.380036
Average total loss: 0.863083
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4431e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.485149
Average KL loss: 0.379773
Average total loss: 0.864923
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.7343e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.479724
Average KL loss: 0.379989
Average total loss: 0.859712
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.1156e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.489580
Average KL loss: 0.380246
Average total loss: 0.869826
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.7451e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.489169
Average KL loss: 0.380575
Average total loss: 0.869744
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.1385e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.482238
Average KL loss: 0.380343
Average total loss: 0.862582
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.0113e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.490084
Average KL loss: 0.380407
Average total loss: 0.870491
tensor(0.0028, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.2065e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.481140
Average KL loss: 0.380948
Average total loss: 0.862088
tensor(0.0028, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.0522e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.483840
Average KL loss: 0.381428
Average total loss: 0.865268
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.7311e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.485904
Average KL loss: 0.381767
Average total loss: 0.867670
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.7014e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.485999
Average KL loss: 0.381760
Average total loss: 0.867759
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.9316e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.485299
Average KL loss: 0.381950
Average total loss: 0.867249
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.4142e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.479087
Average KL loss: 0.382255
Average total loss: 0.861342
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.4774e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.476984
Average KL loss: 0.382178
Average total loss: 0.859162
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.1617e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.483313
Average KL loss: 0.382180
Average total loss: 0.865493
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.6155e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.481802
Average KL loss: 0.382495
Average total loss: 0.864297
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.0661e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.484528
Average KL loss: 0.382667
Average total loss: 0.867196
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.4244e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.484185
Average KL loss: 0.382663
Average total loss: 0.866848
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.7510e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.478848
Average KL loss: 0.382697
Average total loss: 0.861545
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.9994e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.485315
Average KL loss: 0.382496
Average total loss: 0.867811
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.0289e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.472546
Average KL loss: 0.382613
Average total loss: 0.855159
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.3977e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.482233
Average KL loss: 0.382295
Average total loss: 0.864528
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1401e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.476899
Average KL loss: 0.382531
Average total loss: 0.859430
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.5546e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.470492
Average KL loss: 0.382979
Average total loss: 0.853470
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.5165e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.478779
Average KL loss: 0.383186
Average total loss: 0.861965
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.2578e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.479797
Average KL loss: 0.383544
Average total loss: 0.863341
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(7.0140e-11, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.478829
Average KL loss: 0.383998
Average total loss: 0.862827
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.6457e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.471656
Average KL loss: 0.384006
Average total loss: 0.855663
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(6.0569e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.477303
Average KL loss: 0.383936
Average total loss: 0.861239
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.5315e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.473294
Average KL loss: 0.384000
Average total loss: 0.857294
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.3893e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.469978
Average KL loss: 0.383862
Average total loss: 0.853840
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.8918e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.474130
Average KL loss: 0.383904
Average total loss: 0.858034
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.3900e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.473109
Average KL loss: 0.384247
Average total loss: 0.857356
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.5193e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.473090
Average KL loss: 0.384333
Average total loss: 0.857424
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.3286e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.476672
Average KL loss: 0.384345
Average total loss: 0.861017
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.7888e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.474645
Average KL loss: 0.384326
Average total loss: 0.858971
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.0563e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.469147
Average KL loss: 0.384056
Average total loss: 0.853203
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.6831e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.478792
Average KL loss: 0.383811
Average total loss: 0.862602
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.8197e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.470561
Average KL loss: 0.383601
Average total loss: 0.854162
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.1068e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.473908
Average KL loss: 0.383399
Average total loss: 0.857308
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.2721e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.480992
Average KL loss: 0.383217
Average total loss: 0.864209
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.8672e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.473117
Average KL loss: 0.383029
Average total loss: 0.856146
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.3744e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.476676
Average KL loss: 0.382803
Average total loss: 0.859480
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.0365e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.474657
Average KL loss: 0.382667
Average total loss: 0.857325
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.2938e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.475016
Average KL loss: 0.382512
Average total loss: 0.857528
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.9316e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.472303
Average KL loss: 0.382347
Average total loss: 0.854651
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.5543e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.472760
Average KL loss: 0.382240
Average total loss: 0.854999
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.0751e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.481805
Average KL loss: 0.382125
Average total loss: 0.863930
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.6055e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.468689
Average KL loss: 0.382060
Average total loss: 0.850749
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.4936e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.471378
Average KL loss: 0.382039
Average total loss: 0.853416
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-8.3977e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.473813
Average KL loss: 0.382021
Average total loss: 0.855834
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.1207e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.473674
Average KL loss: 0.382006
Average total loss: 0.855680
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.1646e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.474187
Average KL loss: 0.381989
Average total loss: 0.856177
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.3488e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.473956
Average KL loss: 0.381973
Average total loss: 0.855929
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(7.0795e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.470925
Average KL loss: 0.381953
Average total loss: 0.852878
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.4271e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.469373
Average KL loss: 0.381932
Average total loss: 0.851305
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.7111e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.473137
Average KL loss: 0.381917
Average total loss: 0.855053
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.7112e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.471389
Average KL loss: 0.381898
Average total loss: 0.853287
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(8.3332e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.468571
Average KL loss: 0.381879
Average total loss: 0.850450
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.6663e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.472297
Average KL loss: 0.381859
Average total loss: 0.854156
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.1686e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.467126
Average KL loss: 0.381844
Average total loss: 0.848969
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.3736e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.489768
Average KL loss: 0.381828
Average total loss: 0.871596
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.7808e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.473862
Average KL loss: 0.381814
Average total loss: 0.855676
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.2757e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.476215
Average KL loss: 0.381796
Average total loss: 0.858011
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.8588e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.478937
Average KL loss: 0.381781
Average total loss: 0.860718
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.4344e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.469574
Average KL loss: 0.381763
Average total loss: 0.851337
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.8681e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.472928
Average KL loss: 0.381744
Average total loss: 0.854672
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.2800e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.469682
Average KL loss: 0.381729
Average total loss: 0.851411
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.1991e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.468105
Average KL loss: 0.381711
Average total loss: 0.849815
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.7778e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.474840
Average KL loss: 0.381693
Average total loss: 0.856533
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(9.2043e-11, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.472260
Average KL loss: 0.381675
Average total loss: 0.853935
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.0474e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.466695
Average KL loss: 0.381655
Average total loss: 0.848351
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.4463e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.476487
Average KL loss: 0.381636
Average total loss: 0.858123
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.1143e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.472552
Average KL loss: 0.381616
Average total loss: 0.854168
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.0228e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.474962
Average KL loss: 0.381599
Average total loss: 0.856561
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.4698e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.471837
Average KL loss: 0.381585
Average total loss: 0.853422
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.2715e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.472692
Average KL loss: 0.381570
Average total loss: 0.854262
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.6862e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.467685
Average KL loss: 0.381553
Average total loss: 0.849238
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.2197e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.469105
Average KL loss: 0.381536
Average total loss: 0.850641
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.9150e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.466971
Average KL loss: 0.381519
Average total loss: 0.848490
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.5472e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.477987
Average KL loss: 0.381502
Average total loss: 0.859489
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.4210e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.467124
Average KL loss: 0.381484
Average total loss: 0.848608
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.1842e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.472216
Average KL loss: 0.381466
Average total loss: 0.853681
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.0269e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.470161
Average KL loss: 0.381456
Average total loss: 0.851617
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.6111e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.473235
Average KL loss: 0.381454
Average total loss: 0.854689
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.5922e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.476559
Average KL loss: 0.381452
Average total loss: 0.858011
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.1476e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.474732
Average KL loss: 0.381450
Average total loss: 0.856182
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.5973e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.476672
Average KL loss: 0.381449
Average total loss: 0.858121
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.3415e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.468838
Average KL loss: 0.381447
Average total loss: 0.850285
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.3701e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.462367
Average KL loss: 0.381445
Average total loss: 0.843811
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(6.2893e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.469562
Average KL loss: 0.381443
Average total loss: 0.851005
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.4323e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.471084
Average KL loss: 0.381441
Average total loss: 0.852525
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(7.0252e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.472727
Average KL loss: 0.381439
Average total loss: 0.854166
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.7731e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.468766
Average KL loss: 0.381437
Average total loss: 0.850203
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.5464e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.475110
Average KL loss: 0.381436
Average total loss: 0.856546
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(7.1104e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.476828
Average KL loss: 0.381434
Average total loss: 0.858262
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.8655e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.478837
Average KL loss: 0.381433
Average total loss: 0.860270
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.7427e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.480286
Average KL loss: 0.381431
Average total loss: 0.861717
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.5298e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.474610
Average KL loss: 0.381430
Average total loss: 0.856040
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(6.2221e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.466108
Average KL loss: 0.381428
Average total loss: 0.847535
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.6307e-09, device='cuda:0')
 Percentile value: 0.3236047923564911
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =      98 /    1728             (  5.67%) | total_pruned =    1630 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      52 /   36864             (  0.14%) | total_pruned =   36812 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      46 /   36864             (  0.12%) | total_pruned =   36818 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     116 /   36864             (  0.31%) | total_pruned =   36748 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     239 /   36864             (  0.65%) | total_pruned =   36625 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1015 /   73728             (  1.38%) | total_pruned =   72713 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2113 /  147456             (  1.43%) | total_pruned =  145343 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     147 /    8192             (  1.79%) | total_pruned =    8045 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1370 /  147456             (  0.93%) | total_pruned =  146086 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1103 /  147456             (  0.75%) | total_pruned =  146353 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    4558 /  294912             (  1.55%) | total_pruned =  290354 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    6651 /  589824             (  1.13%) | total_pruned =  583173 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     472 /   32768             (  1.44%) | total_pruned =   32296 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3696 /  589824             (  0.63%) | total_pruned =  586128 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2177 /  589824             (  0.37%) | total_pruned =  587647 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    5748 / 1179648             (  0.49%) | total_pruned = 1173900 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     346 /     512             ( 67.58%) | total_pruned =     166 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4743 / 2359296             (  0.20%) | total_pruned = 2354553 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     134 /     512             ( 26.17%) | total_pruned =     378 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     127 /  131072             (  0.10%) | total_pruned =  130945 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      34 /     512             (  6.64%) | total_pruned =     478 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      37 /     512             (  7.23%) | total_pruned =     475 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2686 / 2359296             (  0.11%) | total_pruned = 2356610 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    3753 / 2359296             (  0.16%) | total_pruned = 2355543 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      97 /     512             ( 18.95%) | total_pruned =     415 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      79 /     512             ( 15.43%) | total_pruned =     433 | shape = torch.Size([512])
linear.weight        | nonzeros =     568 /    5120             ( 11.09%) | total_pruned =    4552 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 72/100 Loss: 0.056999 Accuracy: 84.79 99.97 % Best test Accuracy: 85.90%
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.5423e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.796779
Average KL loss: 0.361275
Average total loss: 1.158055
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-7.8102e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.731060
Average KL loss: 0.353081
Average total loss: 1.084140
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.2648e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.707209
Average KL loss: 0.353033
Average total loss: 1.060242
tensor(0.0026, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.5016e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.685271
Average KL loss: 0.354682
Average total loss: 1.039954
tensor(0.0026, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.9794e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.664285
Average KL loss: 0.356911
Average total loss: 1.021196
tensor(0.0026, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.1785e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.660903
Average KL loss: 0.358906
Average total loss: 1.019809
tensor(0.0026, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.4859e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.647832
Average KL loss: 0.361044
Average total loss: 1.008876
tensor(0.0026, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.5005e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.619606
Average KL loss: 0.363443
Average total loss: 0.983049
tensor(0.0026, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.8760e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.621089
Average KL loss: 0.365250
Average total loss: 0.986339
tensor(0.0026, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.6759e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.604900
Average KL loss: 0.366974
Average total loss: 0.971874
tensor(0.0026, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.5966e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.593690
Average KL loss: 0.369067
Average total loss: 0.962756
tensor(0.0026, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.5705e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.602437
Average KL loss: 0.370700
Average total loss: 0.973137
tensor(0.0026, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.8518e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.588924
Average KL loss: 0.372467
Average total loss: 0.961391
tensor(0.0026, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.3549e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.587348
Average KL loss: 0.374261
Average total loss: 0.961610
tensor(0.0026, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.7652e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.578032
Average KL loss: 0.375644
Average total loss: 0.953677
tensor(0.0026, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.9236e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.589463
Average KL loss: 0.376735
Average total loss: 0.966198
tensor(0.0026, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.4223e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.579547
Average KL loss: 0.377640
Average total loss: 0.957187
tensor(0.0026, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.5205e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.572142
Average KL loss: 0.378674
Average total loss: 0.950816
tensor(0.0026, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.0955e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.563583
Average KL loss: 0.379785
Average total loss: 0.943368
tensor(0.0026, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.8908e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.561166
Average KL loss: 0.380540
Average total loss: 0.941706
tensor(0.0026, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.4265e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.550696
Average KL loss: 0.381381
Average total loss: 0.932078
tensor(0.0026, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.3770e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.556205
Average KL loss: 0.382496
Average total loss: 0.938701
tensor(0.0026, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.4179e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.560339
Average KL loss: 0.383656
Average total loss: 0.943995
tensor(0.0026, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.7518e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.553281
Average KL loss: 0.384580
Average total loss: 0.937860
tensor(0.0026, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-9.4875e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.545768
Average KL loss: 0.385169
Average total loss: 0.930937
tensor(0.0026, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.9355e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.546436
Average KL loss: 0.385420
Average total loss: 0.931856
tensor(0.0026, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.8350e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.538669
Average KL loss: 0.386179
Average total loss: 0.924848
tensor(0.0026, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.8414e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.545199
Average KL loss: 0.386665
Average total loss: 0.931864
tensor(0.0026, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.0296e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.540946
Average KL loss: 0.387494
Average total loss: 0.928440
tensor(0.0026, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.0417e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.533337
Average KL loss: 0.388473
Average total loss: 0.921809
tensor(0.0026, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-7.9524e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.536300
Average KL loss: 0.389058
Average total loss: 0.925358
tensor(0.0026, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.6180e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.535345
Average KL loss: 0.389453
Average total loss: 0.924798
tensor(0.0026, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.5503e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.533523
Average KL loss: 0.389772
Average total loss: 0.923295
tensor(0.0026, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.8161e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.527834
Average KL loss: 0.390136
Average total loss: 0.917970
tensor(0.0026, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.9333e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.528064
Average KL loss: 0.390329
Average total loss: 0.918393
tensor(0.0026, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.3617e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.536861
Average KL loss: 0.390820
Average total loss: 0.927682
tensor(0.0026, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.3766e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.525827
Average KL loss: 0.390841
Average total loss: 0.916669
tensor(0.0026, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5184e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.524622
Average KL loss: 0.391186
Average total loss: 0.915808
tensor(0.0026, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6897e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.525596
Average KL loss: 0.391622
Average total loss: 0.917218
tensor(0.0026, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.1866e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.528411
Average KL loss: 0.392142
Average total loss: 0.920553
tensor(0.0026, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.3523e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.524423
Average KL loss: 0.392992
Average total loss: 0.917416
tensor(0.0026, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6037e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.523596
Average KL loss: 0.393513
Average total loss: 0.917109
tensor(0.0026, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.8147e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.516855
Average KL loss: 0.393683
Average total loss: 0.910538
tensor(0.0026, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.3203e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.524478
Average KL loss: 0.393935
Average total loss: 0.918413
tensor(0.0026, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.2561e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.517873
Average KL loss: 0.394297
Average total loss: 0.912170
tensor(0.0026, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3724e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.514392
Average KL loss: 0.394659
Average total loss: 0.909051
tensor(0.0026, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.7397e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.510585
Average KL loss: 0.395097
Average total loss: 0.905682
tensor(0.0026, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.4104e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.507172
Average KL loss: 0.395185
Average total loss: 0.902357
tensor(0.0026, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.3775e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.516824
Average KL loss: 0.395582
Average total loss: 0.912406
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.4478e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.516246
Average KL loss: 0.395988
Average total loss: 0.912234
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.2375e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.511793
Average KL loss: 0.396512
Average total loss: 0.908305
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.8032e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.507110
Average KL loss: 0.397104
Average total loss: 0.904215
tensor(0.0027, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.3134e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.504597
Average KL loss: 0.397376
Average total loss: 0.901973
tensor(0.0027, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.7289e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.511066
Average KL loss: 0.397254
Average total loss: 0.908320
tensor(0.0027, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.1964e-13, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.510021
Average KL loss: 0.397676
Average total loss: 0.907697
tensor(0.0027, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.1614e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.507930
Average KL loss: 0.398096
Average total loss: 0.906026
tensor(0.0027, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.4536e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.508919
Average KL loss: 0.398721
Average total loss: 0.907639
tensor(0.0027, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.5164e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.506801
Average KL loss: 0.399099
Average total loss: 0.905899
tensor(0.0027, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.6543e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.498595
Average KL loss: 0.398947
Average total loss: 0.897543
tensor(0.0027, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.1757e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.506787
Average KL loss: 0.398951
Average total loss: 0.905738
tensor(0.0027, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.7541e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.496575
Average KL loss: 0.399410
Average total loss: 0.895986
tensor(0.0027, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6402e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.498670
Average KL loss: 0.399560
Average total loss: 0.898229
tensor(0.0027, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.1080e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.502128
Average KL loss: 0.399638
Average total loss: 0.901766
tensor(0.0027, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.4780e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.496305
Average KL loss: 0.400054
Average total loss: 0.896358
tensor(0.0027, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.2969e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.492866
Average KL loss: 0.400358
Average total loss: 0.893223
tensor(0.0027, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.5877e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.491321
Average KL loss: 0.400325
Average total loss: 0.891646
tensor(0.0027, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.7827e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.504442
Average KL loss: 0.400234
Average total loss: 0.904676
tensor(0.0027, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.5039e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.491862
Average KL loss: 0.400390
Average total loss: 0.892253
tensor(0.0027, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.2103e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.492118
Average KL loss: 0.400787
Average total loss: 0.892905
tensor(0.0027, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.1906e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.491234
Average KL loss: 0.400992
Average total loss: 0.892226
tensor(0.0027, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.1126e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.491270
Average KL loss: 0.401181
Average total loss: 0.892451
tensor(0.0027, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.7884e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.494652
Average KL loss: 0.401311
Average total loss: 0.895963
tensor(0.0027, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.8900e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.496278
Average KL loss: 0.401966
Average total loss: 0.898244
tensor(0.0027, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.8866e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.491086
Average KL loss: 0.402503
Average total loss: 0.893589
tensor(0.0027, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.2268e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.494983
Average KL loss: 0.402591
Average total loss: 0.897573
tensor(0.0027, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.7788e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.487391
Average KL loss: 0.402564
Average total loss: 0.889956
tensor(0.0027, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.2595e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.493909
Average KL loss: 0.402442
Average total loss: 0.896351
tensor(0.0027, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.9767e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.488763
Average KL loss: 0.402681
Average total loss: 0.891444
tensor(0.0027, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.3152e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.492106
Average KL loss: 0.403132
Average total loss: 0.895238
tensor(0.0027, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.8644e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.486690
Average KL loss: 0.403550
Average total loss: 0.890240
tensor(0.0027, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.3524e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.495781
Average KL loss: 0.403745
Average total loss: 0.899526
tensor(0.0027, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(6.9655e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.490612
Average KL loss: 0.403739
Average total loss: 0.894351
tensor(0.0027, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.4642e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.495405
Average KL loss: 0.404229
Average total loss: 0.899635
tensor(0.0027, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.2150e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.493296
Average KL loss: 0.404672
Average total loss: 0.897968
tensor(0.0027, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.7011e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.491064
Average KL loss: 0.405028
Average total loss: 0.896092
tensor(0.0027, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.7735e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.482417
Average KL loss: 0.405436
Average total loss: 0.887853
tensor(0.0027, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(2.2666e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.487536
Average KL loss: 0.405436
Average total loss: 0.892972
tensor(0.0027, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.8281e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.482592
Average KL loss: 0.405437
Average total loss: 0.888029
tensor(0.0027, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(5.1212e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.481290
Average KL loss: 0.405378
Average total loss: 0.886669
tensor(0.0027, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.6258e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.492799
Average KL loss: 0.405639
Average total loss: 0.898438
tensor(0.0027, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.9500e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.486718
Average KL loss: 0.405921
Average total loss: 0.892640
tensor(0.0027, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.6676e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.481988
Average KL loss: 0.406461
Average total loss: 0.888449
tensor(0.0027, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.6002e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.485591
Average KL loss: 0.406800
Average total loss: 0.892391
tensor(0.0027, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.0641e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.479171
Average KL loss: 0.407000
Average total loss: 0.886171
tensor(0.0028, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-7.3637e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.485101
Average KL loss: 0.407569
Average total loss: 0.892670
tensor(0.0028, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.5704e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.479542
Average KL loss: 0.407938
Average total loss: 0.887480
tensor(0.0028, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-4.1947e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.477147
Average KL loss: 0.408130
Average total loss: 0.885276
tensor(0.0028, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.5659e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.477671
Average KL loss: 0.408286
Average total loss: 0.885957
tensor(0.0028, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(3.2853e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.482034
Average KL loss: 0.408468
Average total loss: 0.890502
tensor(0.0028, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.4197e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.476650
Average KL loss: 0.408411
Average total loss: 0.885061
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.1964e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.483759
Average KL loss: 0.408188
Average total loss: 0.891947
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(4.2446e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.477805
Average KL loss: 0.408234
Average total loss: 0.886039
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-5.2865e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.479737
Average KL loss: 0.408508
Average total loss: 0.888246
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(3.6638e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.478463
Average KL loss: 0.408612
Average total loss: 0.887075
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-5.4934e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.476442
Average KL loss: 0.408530
Average total loss: 0.884972
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-9.1938e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.481427
Average KL loss: 0.408521
Average total loss: 0.889948
tensor(0.0028, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-5.4449e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.475023
Average KL loss: 0.408624
Average total loss: 0.883648
tensor(0.0028, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.2994e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.479183
Average KL loss: 0.409049
Average total loss: 0.888232
tensor(0.0028, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(2.3771e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.479897
Average KL loss: 0.409360
Average total loss: 0.889257
tensor(0.0028, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-5.8561e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.478535
Average KL loss: 0.409664
Average total loss: 0.888198
tensor(0.0028, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.5750e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.478231
Average KL loss: 0.410104
Average total loss: 0.888335
tensor(0.0028, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.5948e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.477764
Average KL loss: 0.410643
Average total loss: 0.888408
tensor(0.0028, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.3890e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.477234
Average KL loss: 0.411189
Average total loss: 0.888423
tensor(0.0028, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.7290e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.479360
Average KL loss: 0.411239
Average total loss: 0.890599
tensor(0.0028, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-6.2152e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.474032
Average KL loss: 0.411251
Average total loss: 0.885283
tensor(0.0028, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-6.8685e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.478544
Average KL loss: 0.411256
Average total loss: 0.889799
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-6.3241e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.472319
Average KL loss: 0.411378
Average total loss: 0.883697
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.5362e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.467067
Average KL loss: 0.411436
Average total loss: 0.878503
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-2.6762e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.473321
Average KL loss: 0.411451
Average total loss: 0.884772
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-5.7360e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.476087
Average KL loss: 0.411794
Average total loss: 0.887881
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.3267e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.476550
Average KL loss: 0.412066
Average total loss: 0.888616
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-7.5033e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.474061
Average KL loss: 0.412315
Average total loss: 0.886376
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.6156e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.472330
Average KL loss: 0.412719
Average total loss: 0.885049
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(3.9776e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.466459
Average KL loss: 0.412995
Average total loss: 0.879455
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-3.2809e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.474001
Average KL loss: 0.412981
Average total loss: 0.886982
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-6.9516e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.467072
Average KL loss: 0.413086
Average total loss: 0.880159
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-8.4004e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.467615
Average KL loss: 0.413300
Average total loss: 0.880915
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-5.1356e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.469055
Average KL loss: 0.412863
Average total loss: 0.881918
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(3.7766e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.474487
Average KL loss: 0.413189
Average total loss: 0.887676
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.5022e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.478488
Average KL loss: 0.413454
Average total loss: 0.891942
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.7311e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.471673
Average KL loss: 0.413327
Average total loss: 0.885001
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.0174e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.466495
Average KL loss: 0.413233
Average total loss: 0.879728
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.7739e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.473566
Average KL loss: 0.413114
Average total loss: 0.886680
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(3.4846e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.471008
Average KL loss: 0.412989
Average total loss: 0.883996
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(3.5315e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.470656
Average KL loss: 0.412861
Average total loss: 0.883518
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(8.6535e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.467303
Average KL loss: 0.412704
Average total loss: 0.880008
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.0313e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.476542
Average KL loss: 0.412580
Average total loss: 0.889122
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(4.7650e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.468394
Average KL loss: 0.412478
Average total loss: 0.880871
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.4815e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.471322
Average KL loss: 0.412384
Average total loss: 0.883706
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(3.2292e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.468949
Average KL loss: 0.412287
Average total loss: 0.881237
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.9733e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.470291
Average KL loss: 0.412230
Average total loss: 0.882522
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.5800e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.471997
Average KL loss: 0.412220
Average total loss: 0.884218
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.2821e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.474358
Average KL loss: 0.412212
Average total loss: 0.886569
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.8124e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.473024
Average KL loss: 0.412202
Average total loss: 0.885226
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.4954e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.472924
Average KL loss: 0.412193
Average total loss: 0.885116
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.7212e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.469490
Average KL loss: 0.412178
Average total loss: 0.881668
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.0285e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.469284
Average KL loss: 0.412168
Average total loss: 0.881452
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.4227e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.474456
Average KL loss: 0.412159
Average total loss: 0.886615
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.7629e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.481222
Average KL loss: 0.412149
Average total loss: 0.893371
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.0444e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.474925
Average KL loss: 0.412138
Average total loss: 0.887063
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.2276e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.471476
Average KL loss: 0.412127
Average total loss: 0.883603
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.4722e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.471688
Average KL loss: 0.412120
Average total loss: 0.883808
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(6.4316e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.471393
Average KL loss: 0.412119
Average total loss: 0.883512
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.1069e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.469220
Average KL loss: 0.412118
Average total loss: 0.881337
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.7273e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.479166
Average KL loss: 0.412117
Average total loss: 0.891283
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(5.7786e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.462553
Average KL loss: 0.412116
Average total loss: 0.874669
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.0749e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.468868
Average KL loss: 0.412115
Average total loss: 0.880982
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.6145e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.465749
Average KL loss: 0.412113
Average total loss: 0.877863
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.5488e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.469721
Average KL loss: 0.412112
Average total loss: 0.881834
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.0093e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.468330
Average KL loss: 0.412111
Average total loss: 0.880441
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.1903e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.466334
Average KL loss: 0.412110
Average total loss: 0.878443
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.0502e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.471953
Average KL loss: 0.412109
Average total loss: 0.884062
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.2749e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.470564
Average KL loss: 0.412108
Average total loss: 0.882672
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.8485e-11, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.482638
Average KL loss: 0.412106
Average total loss: 0.894744
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.0550e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.471677
Average KL loss: 0.412105
Average total loss: 0.883783
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.2740e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.469227
Average KL loss: 0.412104
Average total loss: 0.881331
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.2608e-09, device='cuda:0')
 Percentile value: 0.7979684174060822
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =      96 /    1728             (  5.56%) | total_pruned =    1632 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      36 /   36864             (  0.10%) | total_pruned =   36828 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      41 /   36864             (  0.11%) | total_pruned =   36823 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      97 /   36864             (  0.26%) | total_pruned =   36767 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     190 /   36864             (  0.52%) | total_pruned =   36674 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     732 /   73728             (  0.99%) | total_pruned =   72996 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1332 /  147456             (  0.90%) | total_pruned =  146124 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     111 /    8192             (  1.35%) | total_pruned =    8081 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     833 /  147456             (  0.56%) | total_pruned =  146623 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     717 /  147456             (  0.49%) | total_pruned =  146739 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2668 /  294912             (  0.90%) | total_pruned =  292244 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     205 /     256             ( 80.08%) | total_pruned =      51 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3657 /  589824             (  0.62%) | total_pruned =  586167 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     235 /   32768             (  0.72%) | total_pruned =   32533 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1933 /  589824             (  0.33%) | total_pruned =  587891 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     152 /     256             ( 59.38%) | total_pruned =     104 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1203 /  589824             (  0.20%) | total_pruned =  588621 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      84 /     256             ( 32.81%) | total_pruned =     172 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2290 / 1179648             (  0.19%) | total_pruned = 1177358 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     279 /     512             ( 54.49%) | total_pruned =     233 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1749 / 2359296             (  0.07%) | total_pruned = 2357547 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     109 /     512             ( 21.29%) | total_pruned =     403 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      44 /  131072             (  0.03%) | total_pruned =  131028 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     866 / 2359296             (  0.04%) | total_pruned = 2358430 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      76 /     512             ( 14.84%) | total_pruned =     436 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     894 / 2359296             (  0.04%) | total_pruned = 2358402 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
linear.weight        | nonzeros =     231 /    5120             (  4.51%) | total_pruned =    4889 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.107522 Accuracy: 83.05 98.34 % Best test Accuracy: 84.70%
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.9971e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.797423
Average KL loss: 0.391727
Average total loss: 1.189150
tensor(0.0027, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.2867e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.766597
Average KL loss: 0.378464
Average total loss: 1.145061
tensor(0.0026, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4661e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.733006
Average KL loss: 0.373653
Average total loss: 1.106659
tensor(0.0025, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.5667e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.712318
Average KL loss: 0.370954
Average total loss: 1.083272
tensor(0.0025, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.4097e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.724235
Average KL loss: 0.369317
Average total loss: 1.093552
tensor(0.0025, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.0788e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.694018
Average KL loss: 0.368315
Average total loss: 1.062333
tensor(0.0025, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.8467e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.673600
Average KL loss: 0.368090
Average total loss: 1.041691
tensor(0.0025, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.3056e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.668875
Average KL loss: 0.368723
Average total loss: 1.037599
tensor(0.0025, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.9886e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.663621
Average KL loss: 0.369934
Average total loss: 1.033554
tensor(0.0025, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.6252e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.648034
Average KL loss: 0.371249
Average total loss: 1.019282
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.4249e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.640428
Average KL loss: 0.372849
Average total loss: 1.013277
tensor(0.0025, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.5475e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.634424
Average KL loss: 0.374240
Average total loss: 1.008665
tensor(0.0025, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.1684e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.630272
Average KL loss: 0.375495
Average total loss: 1.005767
tensor(0.0025, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.2259e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.624622
Average KL loss: 0.376414
Average total loss: 1.001037
tensor(0.0025, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.5678e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.610620
Average KL loss: 0.377524
Average total loss: 0.988144
tensor(0.0025, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.6924e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.606343
Average KL loss: 0.378632
Average total loss: 0.984975
tensor(0.0025, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.8630e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.602715
Average KL loss: 0.379633
Average total loss: 0.982348
tensor(0.0025, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.8904e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.604269
Average KL loss: 0.380750
Average total loss: 0.985019
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.5622e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.601810
Average KL loss: 0.381781
Average total loss: 0.983592
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.5924e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.587459
Average KL loss: 0.382684
Average total loss: 0.970144
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.4000e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.579933
Average KL loss: 0.383520
Average total loss: 0.963454
tensor(0.0025, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.9464e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.586039
Average KL loss: 0.384326
Average total loss: 0.970365
tensor(0.0025, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(8.0879e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.571160
Average KL loss: 0.384981
Average total loss: 0.956141
tensor(0.0025, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.0756e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.570248
Average KL loss: 0.385430
Average total loss: 0.955678
tensor(0.0025, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.2323e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.584297
Average KL loss: 0.385802
Average total loss: 0.970099
tensor(0.0025, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.3970e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.569966
Average KL loss: 0.386408
Average total loss: 0.956374
tensor(0.0025, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3631e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.573820
Average KL loss: 0.387309
Average total loss: 0.961129
tensor(0.0025, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.4613e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.554460
Average KL loss: 0.388180
Average total loss: 0.942641
tensor(0.0025, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.1265e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.570238
Average KL loss: 0.388739
Average total loss: 0.958977
tensor(0.0025, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.8358e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.551631
Average KL loss: 0.389386
Average total loss: 0.941017
tensor(0.0025, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.6011e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.561301
Average KL loss: 0.390195
Average total loss: 0.951496
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.0566e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.554293
Average KL loss: 0.390938
Average total loss: 0.945231
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.1451e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.544507
Average KL loss: 0.391529
Average total loss: 0.936036
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.5215e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.537782
Average KL loss: 0.392353
Average total loss: 0.930135
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.4465e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.540739
Average KL loss: 0.393001
Average total loss: 0.933740
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.0021e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.545391
Average KL loss: 0.393384
Average total loss: 0.938776
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.0029e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.539500
Average KL loss: 0.393863
Average total loss: 0.933363
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.4365e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.539151
Average KL loss: 0.394400
Average total loss: 0.933551
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.1811e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.534947
Average KL loss: 0.394810
Average total loss: 0.929756
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.4303e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.536447
Average KL loss: 0.395240
Average total loss: 0.931687
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.3785e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.541647
Average KL loss: 0.395731
Average total loss: 0.937379
tensor(0.0025, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.1854e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.531817
Average KL loss: 0.396114
Average total loss: 0.927930
tensor(0.0025, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.7372e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.533528
Average KL loss: 0.396620
Average total loss: 0.930148
tensor(0.0025, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.3844e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.537470
Average KL loss: 0.397061
Average total loss: 0.934531
tensor(0.0025, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.5027e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.530097
Average KL loss: 0.397410
Average total loss: 0.927507
tensor(0.0025, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.6823e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.524313
Average KL loss: 0.397772
Average total loss: 0.922085
tensor(0.0025, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.4994e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.529149
Average KL loss: 0.398040
Average total loss: 0.927190
tensor(0.0025, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.0525e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.513512
Average KL loss: 0.398524
Average total loss: 0.912036
tensor(0.0025, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.8269e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.520767
Average KL loss: 0.398941
Average total loss: 0.919708
tensor(0.0025, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.7847e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.527684
Average KL loss: 0.399395
Average total loss: 0.927079
tensor(0.0025, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.4016e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.522382
Average KL loss: 0.399927
Average total loss: 0.922308
tensor(0.0025, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-7.0645e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.514729
Average KL loss: 0.400192
Average total loss: 0.914921
tensor(0.0025, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.9269e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.511466
Average KL loss: 0.400709
Average total loss: 0.912175
tensor(0.0025, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.6124e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.517049
Average KL loss: 0.400956
Average total loss: 0.918005
tensor(0.0026, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.5942e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.513521
Average KL loss: 0.401344
Average total loss: 0.914865
tensor(0.0026, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.9248e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.513784
Average KL loss: 0.401778
Average total loss: 0.915563
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-6.4860e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.518769
Average KL loss: 0.402213
Average total loss: 0.920982
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-8.5193e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.519605
Average KL loss: 0.402712
Average total loss: 0.922317
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.6229e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.503989
Average KL loss: 0.403316
Average total loss: 0.907305
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-9.9449e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.513267
Average KL loss: 0.403512
Average total loss: 0.916779
tensor(0.0026, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(3.8041e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.508765
Average KL loss: 0.403596
Average total loss: 0.912361
tensor(0.0026, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.3562e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.510804
Average KL loss: 0.403995
Average total loss: 0.914799
tensor(0.0026, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-8.7103e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.508895
Average KL loss: 0.404567
Average total loss: 0.913463
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.4687e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.507524
Average KL loss: 0.404818
Average total loss: 0.912342
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.3337e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.507784
Average KL loss: 0.404820
Average total loss: 0.912604
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.2238e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.503659
Average KL loss: 0.405099
Average total loss: 0.908759
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-4.2760e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.495096
Average KL loss: 0.405591
Average total loss: 0.900686
tensor(0.0026, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.3725e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.498342
Average KL loss: 0.406245
Average total loss: 0.904587
tensor(0.0026, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-3.6030e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.504859
Average KL loss: 0.406790
Average total loss: 0.911649
tensor(0.0026, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.4506e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.492445
Average KL loss: 0.407190
Average total loss: 0.899635
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(2.7494e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.489824
Average KL loss: 0.407500
Average total loss: 0.897324
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(1.0604e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.495192
Average KL loss: 0.407778
Average total loss: 0.902970
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.2121e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.493564
Average KL loss: 0.408291
Average total loss: 0.901855
tensor(0.0026, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-4.0689e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.492601
Average KL loss: 0.408774
Average total loss: 0.901375
tensor(0.0026, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.7266e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.486131
Average KL loss: 0.409354
Average total loss: 0.895485
tensor(0.0026, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.4945e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.496186
Average KL loss: 0.409681
Average total loss: 0.905867
tensor(0.0026, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.1956e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.492973
Average KL loss: 0.409946
Average total loss: 0.902919
tensor(0.0026, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-4.5354e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.489689
Average KL loss: 0.410208
Average total loss: 0.899898
tensor(0.0026, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.4041e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.484184
Average KL loss: 0.410622
Average total loss: 0.894806
tensor(0.0026, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(5.3846e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.496331
Average KL loss: 0.411106
Average total loss: 0.907437
tensor(0.0026, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-5.4398e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.495178
Average KL loss: 0.411730
Average total loss: 0.906907
tensor(0.0026, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-6.5206e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.485755
Average KL loss: 0.411894
Average total loss: 0.897648
tensor(0.0026, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-2.6754e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.492464
Average KL loss: 0.411925
Average total loss: 0.904389
tensor(0.0026, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(2.0338e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.484095
Average KL loss: 0.412269
Average total loss: 0.896364
tensor(0.0026, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-6.4864e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.483020
Average KL loss: 0.412708
Average total loss: 0.895728
tensor(0.0026, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.6661e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.482181
Average KL loss: 0.412965
Average total loss: 0.895146
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.6961e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.479536
Average KL loss: 0.413197
Average total loss: 0.892733
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.8761e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.479927
Average KL loss: 0.413610
Average total loss: 0.893537
tensor(0.0027, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.6668e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.479927
Average KL loss: 0.413861
Average total loss: 0.893788
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.8390e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.478705
Average KL loss: 0.413956
Average total loss: 0.892662
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(6.0609e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.474575
Average KL loss: 0.414048
Average total loss: 0.888623
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-4.4507e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.476814
Average KL loss: 0.414475
Average total loss: 0.891289
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.1549e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.482777
Average KL loss: 0.414832
Average total loss: 0.897609
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-6.1079e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.494794
Average KL loss: 0.415182
Average total loss: 0.909976
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-3.7631e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.478274
Average KL loss: 0.415424
Average total loss: 0.893698
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-8.3255e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.483684
Average KL loss: 0.415608
Average total loss: 0.899292
tensor(0.0027, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.4812e-11, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.472910
Average KL loss: 0.415835
Average total loss: 0.888745
tensor(0.0027, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(7.5339e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.473372
Average KL loss: 0.416146
Average total loss: 0.889517
tensor(0.0027, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.6154e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.480878
Average KL loss: 0.416695
Average total loss: 0.897573
tensor(0.0027, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(1.0501e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.480943
Average KL loss: 0.417112
Average total loss: 0.898055
tensor(0.0027, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.1054e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.470041
Average KL loss: 0.417466
Average total loss: 0.887507
tensor(0.0027, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.6913e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.487415
Average KL loss: 0.417842
Average total loss: 0.905257
tensor(0.0027, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(3.8636e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.467879
Average KL loss: 0.418351
Average total loss: 0.886231
tensor(0.0027, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.9947e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.470083
Average KL loss: 0.418702
Average total loss: 0.888785
tensor(0.0027, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.4454e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.465859
Average KL loss: 0.418798
Average total loss: 0.884657
tensor(0.0027, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-2.7749e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.466621
Average KL loss: 0.418838
Average total loss: 0.885459
tensor(0.0027, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.5801e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.466635
Average KL loss: 0.419027
Average total loss: 0.885662
tensor(0.0027, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-5.3007e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.468506
Average KL loss: 0.419479
Average total loss: 0.887985
tensor(0.0027, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-8.8365e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.462626
Average KL loss: 0.419708
Average total loss: 0.882334
tensor(0.0027, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-7.1027e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.465986
Average KL loss: 0.419797
Average total loss: 0.885784
tensor(0.0027, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.6056e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.467426
Average KL loss: 0.420127
Average total loss: 0.887553
tensor(0.0027, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.5448e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.465795
Average KL loss: 0.420369
Average total loss: 0.886163
tensor(0.0027, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(9.1323e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.470657
Average KL loss: 0.420421
Average total loss: 0.891078
tensor(0.0027, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.1995e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.461670
Average KL loss: 0.420579
Average total loss: 0.882249
tensor(0.0027, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-3.5429e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.464898
Average KL loss: 0.421118
Average total loss: 0.886016
tensor(0.0027, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(8.0820e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.454007
Average KL loss: 0.421501
Average total loss: 0.875508
tensor(0.0027, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.7536e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.465910
Average KL loss: 0.421779
Average total loss: 0.887689
tensor(0.0027, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.1872e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.465439
Average KL loss: 0.421881
Average total loss: 0.887320
tensor(0.0027, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-3.3199e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.467489
Average KL loss: 0.422158
Average total loss: 0.889647
tensor(0.0027, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-6.2917e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.458786
Average KL loss: 0.422320
Average total loss: 0.881106
tensor(0.0027, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(3.8457e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.462942
Average KL loss: 0.422306
Average total loss: 0.885248
tensor(0.0027, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.0163e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.463384
Average KL loss: 0.422621
Average total loss: 0.886005
tensor(0.0028, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.6749e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.461447
Average KL loss: 0.423053
Average total loss: 0.884500
tensor(0.0028, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.7324e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.455945
Average KL loss: 0.423506
Average total loss: 0.879451
tensor(0.0028, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-3.2550e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.454012
Average KL loss: 0.423836
Average total loss: 0.877847
tensor(0.0028, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(2.0449e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.454171
Average KL loss: 0.423852
Average total loss: 0.878023
tensor(0.0028, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-6.7395e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.461737
Average KL loss: 0.423901
Average total loss: 0.885638
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.9289e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.454563
Average KL loss: 0.423992
Average total loss: 0.878555
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.5903e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.455596
Average KL loss: 0.423983
Average total loss: 0.879579
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.8446e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.457246
Average KL loss: 0.423929
Average total loss: 0.881174
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-3.6311e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.455850
Average KL loss: 0.423873
Average total loss: 0.879723
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-3.2846e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.460115
Average KL loss: 0.423862
Average total loss: 0.883977
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.6758e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.455700
Average KL loss: 0.423847
Average total loss: 0.879547
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(1.5631e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.463210
Average KL loss: 0.423825
Average total loss: 0.887036
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.5297e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.461906
Average KL loss: 0.423798
Average total loss: 0.885703
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-3.0560e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.460061
Average KL loss: 0.423757
Average total loss: 0.883818
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.5215e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.457124
Average KL loss: 0.423734
Average total loss: 0.880858
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.0887e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.460512
Average KL loss: 0.423723
Average total loss: 0.884235
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.8368e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.453403
Average KL loss: 0.423711
Average total loss: 0.877114
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.8067e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.458110
Average KL loss: 0.423708
Average total loss: 0.881818
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(4.1890e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.463852
Average KL loss: 0.423707
Average total loss: 0.887559
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-5.2548e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.451340
Average KL loss: 0.423705
Average total loss: 0.875045
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-5.6365e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.456168
Average KL loss: 0.423703
Average total loss: 0.879871
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-3.9766e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.457216
Average KL loss: 0.423700
Average total loss: 0.880917
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.2036e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.451875
Average KL loss: 0.423698
Average total loss: 0.875573
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.9808e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.463315
Average KL loss: 0.423695
Average total loss: 0.887010
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(1.3129e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.453585
Average KL loss: 0.423694
Average total loss: 0.877279
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.6420e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.462869
Average KL loss: 0.423691
Average total loss: 0.886560
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(4.0584e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.465140
Average KL loss: 0.423688
Average total loss: 0.888828
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(3.3851e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.455741
Average KL loss: 0.423685
Average total loss: 0.879427
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.4705e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.459993
Average KL loss: 0.423684
Average total loss: 0.883677
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(1.0043e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.460763
Average KL loss: 0.423682
Average total loss: 0.884446
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.7143e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.455693
Average KL loss: 0.423680
Average total loss: 0.879373
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.4932e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.455756
Average KL loss: 0.423679
Average total loss: 0.879435
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.5596e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.451810
Average KL loss: 0.423678
Average total loss: 0.875489
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(6.3985e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.454137
Average KL loss: 0.423678
Average total loss: 0.877815
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-5.4609e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.453579
Average KL loss: 0.423678
Average total loss: 0.877257
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.6063e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.463327
Average KL loss: 0.423678
Average total loss: 0.887005
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(3.2975e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.452771
Average KL loss: 0.423678
Average total loss: 0.876449
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-7.3240e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.469429
Average KL loss: 0.423678
Average total loss: 0.893106
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.5818e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.455615
Average KL loss: 0.423677
Average total loss: 0.879293
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(9.5746e-11, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.457794
Average KL loss: 0.423677
Average total loss: 0.881471
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.2065e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.455611
Average KL loss: 0.423677
Average total loss: 0.879289
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.6768e-09, device='cuda:0')
 Percentile value: 2.145552158355713
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =      90 /    1728             (  5.21%) | total_pruned =    1638 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      29 /   36864             (  0.08%) | total_pruned =   36835 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      30 /   36864             (  0.08%) | total_pruned =   36834 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      76 /   36864             (  0.21%) | total_pruned =   36788 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     127 /   36864             (  0.34%) | total_pruned =   36737 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     487 /   73728             (  0.66%) | total_pruned =   73241 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     767 /  147456             (  0.52%) | total_pruned =  146689 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      72 /    8192             (  0.88%) | total_pruned =    8120 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     501 /  147456             (  0.34%) | total_pruned =  146955 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     434 /  147456             (  0.29%) | total_pruned =  147022 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1314 /  294912             (  0.45%) | total_pruned =  293598 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1687 /  589824             (  0.29%) | total_pruned =  588137 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      96 /   32768             (  0.29%) | total_pruned =   32672 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     983 /  589824             (  0.17%) | total_pruned =  588841 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     674 /  589824             (  0.11%) | total_pruned =  589150 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      65 /     256             ( 25.39%) | total_pruned =     191 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     818 / 1179648             (  0.07%) | total_pruned = 1178830 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     184 /     512             ( 35.94%) | total_pruned =     328 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     597 / 2359296             (  0.03%) | total_pruned = 2358699 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      81 /     512             ( 15.82%) | total_pruned =     431 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      13 /  131072             (  0.01%) | total_pruned =  131059 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     315 / 2359296             (  0.01%) | total_pruned = 2358981 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     240 / 2359296             (  0.01%) | total_pruned = 2359056 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
linear.weight        | nonzeros =     104 /    5120             (  2.03%) | total_pruned =    5016 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.659863 Accuracy: 73.41 81.66 % Best test Accuracy: 73.72%
tensor(0.0028, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.2801e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.140824
Average KL loss: 0.397185
Average total loss: 1.538009
tensor(0.0025, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.1580e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.119850
Average KL loss: 0.365491
Average total loss: 1.485342
tensor(0.0022, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.2753e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.055211
Average KL loss: 0.344099
Average total loss: 1.399310
tensor(0.0021, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.5879e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.065621
Average KL loss: 0.325969
Average total loss: 1.391590
tensor(0.0020, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.2436e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.036903
Average KL loss: 0.310194
Average total loss: 1.347097
tensor(0.0019, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.1875e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.042615
Average KL loss: 0.297163
Average total loss: 1.339779
tensor(0.0018, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.3568e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.002942
Average KL loss: 0.288099
Average total loss: 1.291041
tensor(0.0018, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.4762e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.004644
Average KL loss: 0.283383
Average total loss: 1.288027
tensor(0.0018, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.0935e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.977122
Average KL loss: 0.281198
Average total loss: 1.258319
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.5680e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.967938
Average KL loss: 0.279772
Average total loss: 1.247710
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.6728e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.979679
Average KL loss: 0.278627
Average total loss: 1.258306
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.1657e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.953721
Average KL loss: 0.277538
Average total loss: 1.231259
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.7899e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.937641
Average KL loss: 0.276562
Average total loss: 1.214204
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-5.0597e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.946141
Average KL loss: 0.275736
Average total loss: 1.221877
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.4285e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.935381
Average KL loss: 0.275012
Average total loss: 1.210393
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.1558e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.927378
Average KL loss: 0.274291
Average total loss: 1.201669
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.3276e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.908564
Average KL loss: 0.273567
Average total loss: 1.182131
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.3789e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.920250
Average KL loss: 0.273014
Average total loss: 1.193264
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-8.3679e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.916505
Average KL loss: 0.272533
Average total loss: 1.189039
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.1177e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.911492
Average KL loss: 0.272150
Average total loss: 1.183642
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.2947e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.888559
Average KL loss: 0.271737
Average total loss: 1.160297
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.0240e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.906683
Average KL loss: 0.271282
Average total loss: 1.177964
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.5736e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.885358
Average KL loss: 0.270918
Average total loss: 1.156276
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-8.1326e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.873028
Average KL loss: 0.270620
Average total loss: 1.143648
tensor(0.0017, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.2462e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.879279
Average KL loss: 0.270318
Average total loss: 1.149598
tensor(0.0017, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.2587e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.876178
Average KL loss: 0.270074
Average total loss: 1.146252
tensor(0.0017, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.0456e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.865556
Average KL loss: 0.269949
Average total loss: 1.135506
tensor(0.0017, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.4522e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.861005
Average KL loss: 0.269760
Average total loss: 1.130764
tensor(0.0017, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-5.8915e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.850570
Average KL loss: 0.269559
Average total loss: 1.120129
tensor(0.0017, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.0003e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.839739
Average KL loss: 0.269448
Average total loss: 1.109186
tensor(0.0017, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.7048e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.848605
Average KL loss: 0.269423
Average total loss: 1.118028
tensor(0.0017, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.2665e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.848989
Average KL loss: 0.269245
Average total loss: 1.118233
tensor(0.0017, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.0215e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.837770
Average KL loss: 0.269120
Average total loss: 1.106890
tensor(0.0017, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.5837e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.832452
Average KL loss: 0.269116
Average total loss: 1.101568
tensor(0.0017, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.4451e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.833435
Average KL loss: 0.269122
Average total loss: 1.102556
tensor(0.0017, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.7561e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.824909
Average KL loss: 0.269008
Average total loss: 1.093918
tensor(0.0017, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.1086e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.832338
Average KL loss: 0.269004
Average total loss: 1.101343
tensor(0.0017, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.5631e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.837953
Average KL loss: 0.268951
Average total loss: 1.106904
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.2926e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.818784
Average KL loss: 0.269052
Average total loss: 1.087836
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.2344e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.821118
Average KL loss: 0.269029
Average total loss: 1.090147
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.4965e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.827621
Average KL loss: 0.269051
Average total loss: 1.096672
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.2532e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.815058
Average KL loss: 0.269065
Average total loss: 1.084124
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.4220e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.815253
Average KL loss: 0.269013
Average total loss: 1.084266
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.2127e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.819770
Average KL loss: 0.269073
Average total loss: 1.088843
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.8239e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.814837
Average KL loss: 0.269075
Average total loss: 1.083912
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.3496e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.799452
Average KL loss: 0.269019
Average total loss: 1.068471
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.4235e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.805043
Average KL loss: 0.269092
Average total loss: 1.074135
tensor(0.0017, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-9.0426e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.803309
Average KL loss: 0.269089
Average total loss: 1.072398
tensor(0.0017, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.0946e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.791217
Average KL loss: 0.269156
Average total loss: 1.060374
tensor(0.0017, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.4922e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.808579
Average KL loss: 0.269205
Average total loss: 1.077784
tensor(0.0017, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.3370e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.801445
Average KL loss: 0.269302
Average total loss: 1.070747
tensor(0.0017, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.5518e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.792612
Average KL loss: 0.269433
Average total loss: 1.062045
tensor(0.0017, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.1965e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.803010
Average KL loss: 0.269491
Average total loss: 1.072501
tensor(0.0017, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.0276e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.801203
Average KL loss: 0.269468
Average total loss: 1.070671
tensor(0.0017, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.1711e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.792443
Average KL loss: 0.269531
Average total loss: 1.061974
tensor(0.0017, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.6561e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.791232
Average KL loss: 0.269649
Average total loss: 1.060881
tensor(0.0017, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.2846e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.780503
Average KL loss: 0.269801
Average total loss: 1.050304
tensor(0.0017, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.3228e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.770380
Average KL loss: 0.269833
Average total loss: 1.040213
tensor(0.0017, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.8717e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.788957
Average KL loss: 0.269856
Average total loss: 1.058813
tensor(0.0017, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.4122e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.768751
Average KL loss: 0.269926
Average total loss: 1.038676
tensor(0.0017, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.7629e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.780718
Average KL loss: 0.270018
Average total loss: 1.050736
tensor(0.0017, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.8106e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.768336
Average KL loss: 0.269989
Average total loss: 1.038325
tensor(0.0017, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.6152e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.774120
Average KL loss: 0.270129
Average total loss: 1.044248
tensor(0.0017, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.3346e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.775943
Average KL loss: 0.270358
Average total loss: 1.046301
tensor(0.0017, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.9008e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.771263
Average KL loss: 0.270566
Average total loss: 1.041829
tensor(0.0017, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.4402e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.769452
Average KL loss: 0.270708
Average total loss: 1.040160
tensor(0.0017, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.4812e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.774624
Average KL loss: 0.270882
Average total loss: 1.045506
tensor(0.0017, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.3083e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.759414
Average KL loss: 0.271061
Average total loss: 1.030475
tensor(0.0017, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.0902e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.769953
Average KL loss: 0.271242
Average total loss: 1.041195
tensor(0.0017, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.2451e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.760625
Average KL loss: 0.271405
Average total loss: 1.032030
tensor(0.0017, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.3825e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.763613
Average KL loss: 0.271579
Average total loss: 1.035192
tensor(0.0018, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.5936e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.761219
Average KL loss: 0.271854
Average total loss: 1.033072
tensor(0.0018, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.0382e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.762544
Average KL loss: 0.272016
Average total loss: 1.034560
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.4134e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.762475
Average KL loss: 0.272248
Average total loss: 1.034722
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.8214e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.755622
Average KL loss: 0.272459
Average total loss: 1.028081
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.5007e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.758964
Average KL loss: 0.272643
Average total loss: 1.031607
tensor(0.0018, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.8983e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.755132
Average KL loss: 0.272877
Average total loss: 1.028009
tensor(0.0018, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.7976e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.763769
Average KL loss: 0.273052
Average total loss: 1.036821
tensor(0.0018, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.1315e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.757862
Average KL loss: 0.273281
Average total loss: 1.031143
tensor(0.0018, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.9032e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.765924
Average KL loss: 0.273444
Average total loss: 1.039368
tensor(0.0018, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.1285e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.755262
Average KL loss: 0.273602
Average total loss: 1.028864
tensor(0.0018, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.5781e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.762567
Average KL loss: 0.273808
Average total loss: 1.036375
tensor(0.0018, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.9758e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.743562
Average KL loss: 0.273981
Average total loss: 1.017543
tensor(0.0018, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.9477e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.747977
Average KL loss: 0.274145
Average total loss: 1.022123
tensor(0.0018, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4321e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.742175
Average KL loss: 0.274281
Average total loss: 1.016456
tensor(0.0018, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.5034e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.758160
Average KL loss: 0.274429
Average total loss: 1.032589
tensor(0.0018, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4548e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.749200
Average KL loss: 0.274626
Average total loss: 1.023826
tensor(0.0018, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.1950e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.736896
Average KL loss: 0.274871
Average total loss: 1.011766
tensor(0.0018, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.9099e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.755378
Average KL loss: 0.275035
Average total loss: 1.030412
tensor(0.0018, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9568e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.764395
Average KL loss: 0.275243
Average total loss: 1.039637
tensor(0.0018, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.6097e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.742991
Average KL loss: 0.275441
Average total loss: 1.018431
tensor(0.0018, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.2398e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.737657
Average KL loss: 0.275660
Average total loss: 1.013317
tensor(0.0018, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.6952e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.732748
Average KL loss: 0.275811
Average total loss: 1.008559
tensor(0.0018, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.1124e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.739759
Average KL loss: 0.275933
Average total loss: 1.015693
tensor(0.0018, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.3886e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.746826
Average KL loss: 0.276164
Average total loss: 1.022990
tensor(0.0018, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.0934e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.732953
Average KL loss: 0.276413
Average total loss: 1.009366
tensor(0.0018, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.5435e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.734962
Average KL loss: 0.276646
Average total loss: 1.011608
tensor(0.0018, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1084e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.741627
Average KL loss: 0.276827
Average total loss: 1.018455
tensor(0.0018, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.1394e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.737310
Average KL loss: 0.277100
Average total loss: 1.014410
tensor(0.0018, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.1152e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.741362
Average KL loss: 0.277184
Average total loss: 1.018546
tensor(0.0018, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.7920e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.734568
Average KL loss: 0.277338
Average total loss: 1.011906
tensor(0.0018, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.6531e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.737145
Average KL loss: 0.277566
Average total loss: 1.014711
tensor(0.0018, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.0904e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.732443
Average KL loss: 0.277826
Average total loss: 1.010268
tensor(0.0019, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.2839e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.734583
Average KL loss: 0.278033
Average total loss: 1.012615
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.1562e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.720814
Average KL loss: 0.278133
Average total loss: 0.998947
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.2754e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.722949
Average KL loss: 0.278138
Average total loss: 1.001087
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.6654e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.727251
Average KL loss: 0.278142
Average total loss: 1.005393
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.6477e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.733893
Average KL loss: 0.278140
Average total loss: 1.012033
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.3032e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.730761
Average KL loss: 0.278140
Average total loss: 1.008901
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.7856e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.721147
Average KL loss: 0.278149
Average total loss: 0.999296
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.9004e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.724512
Average KL loss: 0.278154
Average total loss: 1.002667
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.6190e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.728302
Average KL loss: 0.278161
Average total loss: 1.006463
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.0518e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.733319
Average KL loss: 0.278176
Average total loss: 1.011494
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.1352e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.730289
Average KL loss: 0.278182
Average total loss: 1.008471
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.3245e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.731508
Average KL loss: 0.278187
Average total loss: 1.009695
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.7954e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.727666
Average KL loss: 0.278192
Average total loss: 1.005857
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.2665e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.727562
Average KL loss: 0.278192
Average total loss: 1.005754
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.5406e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.728091
Average KL loss: 0.278193
Average total loss: 1.006284
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.8200e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.731206
Average KL loss: 0.278194
Average total loss: 1.009400
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.6835e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.744870
Average KL loss: 0.278195
Average total loss: 1.023066
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.5682e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.738014
Average KL loss: 0.278197
Average total loss: 1.016211
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.7231e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.730551
Average KL loss: 0.278197
Average total loss: 1.008748
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.4131e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.732064
Average KL loss: 0.278197
Average total loss: 1.010261
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.1267e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.734018
Average KL loss: 0.278196
Average total loss: 1.012214
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.8489e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.722053
Average KL loss: 0.278197
Average total loss: 1.000250
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.6855e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.728279
Average KL loss: 0.278198
Average total loss: 1.006476
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.6188e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.735652
Average KL loss: 0.278199
Average total loss: 1.013850
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.4987e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.717289
Average KL loss: 0.278198
Average total loss: 0.995487
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.3584e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.725705
Average KL loss: 0.278198
Average total loss: 1.003903
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.1697e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.729528
Average KL loss: 0.278198
Average total loss: 1.007726
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.8612e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.720201
Average KL loss: 0.278198
Average total loss: 0.998399
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.2907e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.730237
Average KL loss: 0.278199
Average total loss: 1.008436
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.2295e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.732731
Average KL loss: 0.278199
Average total loss: 1.010929
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.6887e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.728765
Average KL loss: 0.278199
Average total loss: 1.006964
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.5697e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.724957
Average KL loss: 0.278199
Average total loss: 1.003155
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.7405e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.737874
Average KL loss: 0.278199
Average total loss: 1.016072
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.3754e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.724556
Average KL loss: 0.278199
Average total loss: 1.002755
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.1098e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.724094
Average KL loss: 0.278199
Average total loss: 1.002293
tensor(0.0019, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.2635e-09, device='cuda:0')
 Percentile value: 3.7491354942321777
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =      85 /    1728             (  4.92%) | total_pruned =    1643 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      25 /   36864             (  0.07%) | total_pruned =   36839 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      23 /   36864             (  0.06%) | total_pruned =   36841 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      47 /   36864             (  0.13%) | total_pruned =   36817 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      65 /   36864             (  0.18%) | total_pruned =   36799 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     264 /   73728             (  0.36%) | total_pruned =   73464 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     415 /  147456             (  0.28%) | total_pruned =  147041 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      29 /    8192             (  0.35%) | total_pruned =    8163 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     293 /  147456             (  0.20%) | total_pruned =  147163 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     263 /  147456             (  0.18%) | total_pruned =  147193 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     633 /  294912             (  0.21%) | total_pruned =  294279 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     766 /  589824             (  0.13%) | total_pruned =  589058 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      27 /   32768             (  0.08%) | total_pruned =   32741 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     419 /  589824             (  0.07%) | total_pruned =  589405 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      88 /     256             ( 34.38%) | total_pruned =     168 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     266 /  589824             (  0.05%) | total_pruned =  589558 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     277 / 1179648             (  0.02%) | total_pruned = 1179371 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     231 / 2359296             (  0.01%) | total_pruned = 2359065 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       7 /  131072             (  0.01%) | total_pruned =  131065 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     161 / 2359296             (  0.01%) | total_pruned = 2359135 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      31 /     512             (  6.05%) | total_pruned =     481 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     125 / 2359296             (  0.01%) | total_pruned = 2359171 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
linear.weight        | nonzeros =      80 /    5120             (  1.56%) | total_pruned =    5040 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 0.856262 Accuracy: 70.92 75.48 % Best test Accuracy: 71.12%
