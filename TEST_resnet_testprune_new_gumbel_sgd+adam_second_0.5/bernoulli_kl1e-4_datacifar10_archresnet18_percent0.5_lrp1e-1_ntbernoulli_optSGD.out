Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2827e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.289188
Average KL loss: 0.040061
Average total loss: 2.329249
tensor(-0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.6375e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.145351
Average KL loss: 0.716112
Average total loss: 1.861463
tensor(0.0026, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.6987e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.520145
Average KL loss: 0.869078
Average total loss: 1.389222
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4203e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.436012
Average KL loss: 0.737531
Average total loss: 1.173542
tensor(0.0030, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.0514e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.393579
Average KL loss: 0.672284
Average total loss: 1.065863
tensor(0.0030, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.8618e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.365791
Average KL loss: 0.643880
Average total loss: 1.009672
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.7083e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.349812
Average KL loss: 0.624357
Average total loss: 0.974169
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.1316e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.342791
Average KL loss: 0.614731
Average total loss: 0.957521
tensor(0.0031, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.0130e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.327976
Average KL loss: 0.607370
Average total loss: 0.935346
tensor(0.0032, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(6.2776e-11, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.322113
Average KL loss: 0.592123
Average total loss: 0.914237
tensor(0.0032, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.1023e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.315495
Average KL loss: 0.601501
Average total loss: 0.916996
tensor(0.0032, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-7.9388e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.316939
Average KL loss: 0.601162
Average total loss: 0.918102
tensor(0.0033, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(7.5680e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.311040
Average KL loss: 0.594276
Average total loss: 0.905316
tensor(0.0032, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.6640e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.305348
Average KL loss: 0.592750
Average total loss: 0.898098
tensor(0.0033, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.2241e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.303044
Average KL loss: 0.591958
Average total loss: 0.895001
tensor(0.0033, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-6.2300e-11, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.300768
Average KL loss: 0.592118
Average total loss: 0.892886
tensor(0.0034, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.1005e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.298350
Average KL loss: 0.591008
Average total loss: 0.889358
tensor(0.0033, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.3174e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.296021
Average KL loss: 0.590456
Average total loss: 0.886477
tensor(0.0033, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(3.2389e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.296012
Average KL loss: 0.587378
Average total loss: 0.883390
tensor(0.0034, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.5852e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.293133
Average KL loss: 0.586416
Average total loss: 0.879549
tensor(0.0034, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.9136e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.294510
Average KL loss: 0.598474
Average total loss: 0.892984
tensor(0.0035, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(3.4036e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.291490
Average KL loss: 0.590085
Average total loss: 0.881575
tensor(0.0034, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-6.5500e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.292926
Average KL loss: 0.597935
Average total loss: 0.890861
tensor(0.0034, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(1.2215e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.293196
Average KL loss: 0.602090
Average total loss: 0.895286
tensor(0.0034, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-8.1202e-11, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.289223
Average KL loss: 0.591562
Average total loss: 0.880785
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.1455e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.287915
Average KL loss: 0.590299
Average total loss: 0.878213
tensor(0.0034, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.7765e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.287750
Average KL loss: 0.593464
Average total loss: 0.881214
tensor(0.0035, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.4809e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.287398
Average KL loss: 0.599637
Average total loss: 0.887035
tensor(0.0035, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.1226e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.288272
Average KL loss: 0.592196
Average total loss: 0.880468
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.3782e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.288941
Average KL loss: 0.603572
Average total loss: 0.892513
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(1.8468e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.285232
Average KL loss: 0.591297
Average total loss: 0.876529
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6707e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.283630
Average KL loss: 0.594906
Average total loss: 0.878536
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.7173e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.282637
Average KL loss: 0.597022
Average total loss: 0.879659
tensor(0.0035, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-9.3485e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.284345
Average KL loss: 0.603096
Average total loss: 0.887441
tensor(0.0036, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.4137e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.283552
Average KL loss: 0.601586
Average total loss: 0.885138
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.3543e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.280423
Average KL loss: 0.596371
Average total loss: 0.876794
tensor(0.0035, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.8968e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.279555
Average KL loss: 0.595641
Average total loss: 0.875196
tensor(0.0035, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.3612e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.281942
Average KL loss: 0.591345
Average total loss: 0.873286
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.7419e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.280336
Average KL loss: 0.596158
Average total loss: 0.876494
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-7.4728e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.279741
Average KL loss: 0.600794
Average total loss: 0.880535
tensor(0.0035, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.8782e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.281878
Average KL loss: 0.607070
Average total loss: 0.888948
tensor(0.0036, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.8576e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.280916
Average KL loss: 0.608459
Average total loss: 0.889376
tensor(0.0036, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.1440e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.279586
Average KL loss: 0.596571
Average total loss: 0.876157
tensor(0.0036, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.1439e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.279823
Average KL loss: 0.605538
Average total loss: 0.885361
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(2.6532e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.280433
Average KL loss: 0.601775
Average total loss: 0.882209
tensor(0.0036, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.0647e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.278471
Average KL loss: 0.597348
Average total loss: 0.875819
tensor(0.0036, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(3.8983e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.282639
Average KL loss: 0.606591
Average total loss: 0.889230
tensor(0.0036, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.4308e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.279193
Average KL loss: 0.606841
Average total loss: 0.886035
tensor(0.0037, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.6042e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.277485
Average KL loss: 0.600798
Average total loss: 0.878282
tensor(0.0037, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-6.4209e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.271894
Average KL loss: 0.449773
Average total loss: 0.721667
tensor(0.0036, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(9.4432e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.271184
Average KL loss: 0.363186
Average total loss: 0.634370
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.7844e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.269213
Average KL loss: 0.351980
Average total loss: 0.621193
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.7114e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.272578
Average KL loss: 0.347834
Average total loss: 0.620412
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.4718e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.271190
Average KL loss: 0.346398
Average total loss: 0.617588
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.0560e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.268221
Average KL loss: 0.344081
Average total loss: 0.612302
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6163e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.271276
Average KL loss: 0.343967
Average total loss: 0.615243
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.5653e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.269132
Average KL loss: 0.342558
Average total loss: 0.611690
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(4.2396e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.268553
Average KL loss: 0.340537
Average total loss: 0.609090
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.5950e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.271110
Average KL loss: 0.341577
Average total loss: 0.612687
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.6712e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.272191
Average KL loss: 0.341310
Average total loss: 0.613501
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.4696e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.271219
Average KL loss: 0.340490
Average total loss: 0.611709
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.7576e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.271893
Average KL loss: 0.340622
Average total loss: 0.612514
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.5418e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.268789
Average KL loss: 0.339926
Average total loss: 0.608715
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.4118e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.271087
Average KL loss: 0.339647
Average total loss: 0.610734
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(7.1512e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.268659
Average KL loss: 0.338979
Average total loss: 0.607638
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.6156e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.270476
Average KL loss: 0.338504
Average total loss: 0.608981
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.3648e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.268464
Average KL loss: 0.337886
Average total loss: 0.606351
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.7964e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.270993
Average KL loss: 0.338341
Average total loss: 0.609335
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.0074e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.269026
Average KL loss: 0.337357
Average total loss: 0.606382
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(9.9147e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.272694
Average KL loss: 0.338395
Average total loss: 0.611088
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.4319e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.270672
Average KL loss: 0.338209
Average total loss: 0.608881
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(5.5886e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.271898
Average KL loss: 0.337798
Average total loss: 0.609696
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(4.0450e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.270949
Average KL loss: 0.338143
Average total loss: 0.609092
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.7193e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.272001
Average KL loss: 0.337458
Average total loss: 0.609460
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.5165e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.272469
Average KL loss: 0.337656
Average total loss: 0.610125
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.5301e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.272097
Average KL loss: 0.337488
Average total loss: 0.609585
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.4703e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.272357
Average KL loss: 0.338043
Average total loss: 0.610401
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-8.1203e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.271037
Average KL loss: 0.337406
Average total loss: 0.608443
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.1240e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.269141
Average KL loss: 0.331855
Average total loss: 0.600997
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.5418e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.272343
Average KL loss: 0.324463
Average total loss: 0.596806
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.6435e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.272154
Average KL loss: 0.320922
Average total loss: 0.593077
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.7165e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.271464
Average KL loss: 0.318787
Average total loss: 0.590251
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(8.9344e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.271010
Average KL loss: 0.317344
Average total loss: 0.588354
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(9.7046e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.270711
Average KL loss: 0.316216
Average total loss: 0.586928
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-8.8630e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.268705
Average KL loss: 0.315405
Average total loss: 0.584109
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.5717e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.268831
Average KL loss: 0.314690
Average total loss: 0.583521
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.3749e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.270702
Average KL loss: 0.314149
Average total loss: 0.584850
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(6.8923e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.269703
Average KL loss: 0.313709
Average total loss: 0.583412
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-5.0028e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.269508
Average KL loss: 0.313398
Average total loss: 0.582906
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.6536e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.271513
Average KL loss: 0.313109
Average total loss: 0.584622
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.2293e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.271181
Average KL loss: 0.312880
Average total loss: 0.584061
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.5348e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.270304
Average KL loss: 0.312716
Average total loss: 0.583020
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.4021e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.270426
Average KL loss: 0.312437
Average total loss: 0.582863
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.1796e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.269492
Average KL loss: 0.312280
Average total loss: 0.581773
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.6573e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.269992
Average KL loss: 0.312101
Average total loss: 0.582094
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.1592e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.269585
Average KL loss: 0.311951
Average total loss: 0.581536
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.8611e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.272320
Average KL loss: 0.311872
Average total loss: 0.584192
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.0375e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.269830
Average KL loss: 0.311840
Average total loss: 0.581670
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.5501e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.269908
Average KL loss: 0.311730
Average total loss: 0.581637
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(6.4544e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.273199
Average KL loss: 0.311605
Average total loss: 0.584804
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.6949e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.269257
Average KL loss: 0.311460
Average total loss: 0.580717
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.8166e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.270426
Average KL loss: 0.311352
Average total loss: 0.581778
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.8417e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.269905
Average KL loss: 0.311301
Average total loss: 0.581206
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.3467e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.272018
Average KL loss: 0.311317
Average total loss: 0.583335
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.5260e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.269081
Average KL loss: 0.311327
Average total loss: 0.580407
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.9533e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.268958
Average KL loss: 0.311220
Average total loss: 0.580178
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.2278e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.268912
Average KL loss: 0.311117
Average total loss: 0.580029
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.8627e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.271023
Average KL loss: 0.311031
Average total loss: 0.582054
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.2708e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.271030
Average KL loss: 0.311067
Average total loss: 0.582096
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.7226e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.269253
Average KL loss: 0.310970
Average total loss: 0.580223
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.6293e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.267037
Average KL loss: 0.310789
Average total loss: 0.577826
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.4764e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.268357
Average KL loss: 0.310750
Average total loss: 0.579107
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(9.5635e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.270859
Average KL loss: 0.310715
Average total loss: 0.581574
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(5.3577e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.270783
Average KL loss: 0.310747
Average total loss: 0.581530
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-6.7875e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.270188
Average KL loss: 0.310722
Average total loss: 0.580909
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.9149e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.270247
Average KL loss: 0.310667
Average total loss: 0.580914
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.5039e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.270168
Average KL loss: 0.310562
Average total loss: 0.580730
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.7820e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.270089
Average KL loss: 0.310509
Average total loss: 0.580598
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.1400e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.268962
Average KL loss: 0.310455
Average total loss: 0.579418
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.3080e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.270493
Average KL loss: 0.310471
Average total loss: 0.580965
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.9410e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.273030
Average KL loss: 0.310421
Average total loss: 0.583451
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(7.8842e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.270977
Average KL loss: 0.310405
Average total loss: 0.581383
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.1945e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.272283
Average KL loss: 0.310283
Average total loss: 0.582566
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.3879e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.269290
Average KL loss: 0.310063
Average total loss: 0.579353
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.2730e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.271862
Average KL loss: 0.309897
Average total loss: 0.581759
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.0235e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.272585
Average KL loss: 0.309776
Average total loss: 0.582361
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.5149e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.271462
Average KL loss: 0.309671
Average total loss: 0.581133
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.5447e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.270280
Average KL loss: 0.309575
Average total loss: 0.579856
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.5462e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.271030
Average KL loss: 0.309481
Average total loss: 0.580511
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.1861e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.272432
Average KL loss: 0.309397
Average total loss: 0.581829
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.5286e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.271936
Average KL loss: 0.309329
Average total loss: 0.581265
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.0925e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.272890
Average KL loss: 0.309259
Average total loss: 0.582149
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.5547e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.271467
Average KL loss: 0.309186
Average total loss: 0.580652
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.6767e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.270396
Average KL loss: 0.309148
Average total loss: 0.579544
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.2447e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.271227
Average KL loss: 0.309139
Average total loss: 0.580366
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.7773e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.270415
Average KL loss: 0.309130
Average total loss: 0.579545
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.0413e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.272176
Average KL loss: 0.309121
Average total loss: 0.581297
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.9457e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.270587
Average KL loss: 0.309112
Average total loss: 0.579698
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.3219e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.270174
Average KL loss: 0.309102
Average total loss: 0.579276
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(7.2867e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.270311
Average KL loss: 0.309094
Average total loss: 0.579406
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.8223e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.270129
Average KL loss: 0.309086
Average total loss: 0.579215
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.4316e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.271030
Average KL loss: 0.309078
Average total loss: 0.580109
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.0891e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.273179
Average KL loss: 0.309071
Average total loss: 0.582250
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.0499e-09, device='cuda:0')
 Percentile value: 0.001269784290343523
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =     467 /    1728             ( 27.03%) | total_pruned =    1261 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6498 /   36864             ( 17.63%) | total_pruned =   30366 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   15815 /   36864             ( 42.90%) | total_pruned =   21049 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   15178 /   36864             ( 41.17%) | total_pruned =   21686 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18304 /   36864             ( 49.65%) | total_pruned =   18560 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   40747 /   73728             ( 55.27%) | total_pruned =   32981 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   80271 /  147456             ( 54.44%) | total_pruned =   67185 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5005 /    8192             ( 61.10%) | total_pruned =    3187 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   71417 /  147456             ( 48.43%) | total_pruned =   76039 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   68657 /  147456             ( 46.56%) | total_pruned =   78799 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  156893 /  294912             ( 53.20%) | total_pruned =  138019 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     139 /     256             ( 54.30%) | total_pruned =     117 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  313377 /  589824             ( 53.13%) | total_pruned =  276447 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18700 /   32768             ( 57.07%) | total_pruned =   14068 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  304401 /  589824             ( 51.61%) | total_pruned =  285423 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  283527 /  589824             ( 48.07%) | total_pruned =  306297 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  593297 / 1179648             ( 50.29%) | total_pruned =  586351 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      90 /     512             ( 17.58%) | total_pruned =     422 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1062730 / 2359296             ( 45.04%) | total_pruned = 1296566 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     486 /     512             ( 94.92%) | total_pruned =      26 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   62646 /  131072             ( 47.80%) | total_pruned =   68426 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     275 /     512             ( 53.71%) | total_pruned =     237 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1074466 / 2359296             ( 45.54%) | total_pruned = 1284830 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1385155 / 2359296             ( 58.71%) | total_pruned =  974141 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5090 /    5120             ( 99.41%) | total_pruned =      30 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 49/100 Loss: 0.017126 Accuracy: 89.13 100.00 % Best test Accuracy: 89.31%
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.2914e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.580949
Average KL loss: 0.733212
Average total loss: 1.314160
tensor(0.0038, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.6749e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.528402
Average KL loss: 0.678459
Average total loss: 1.206861
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.3426e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.449819
Average KL loss: 0.658508
Average total loss: 1.108326
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.3440e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.398045
Average KL loss: 0.621810
Average total loss: 1.019855
tensor(0.0035, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.5680e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.383917
Average KL loss: 0.622290
Average total loss: 1.006208
tensor(0.0035, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(8.5693e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.369993
Average KL loss: 0.614882
Average total loss: 0.984874
tensor(0.0036, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(3.6378e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.361059
Average KL loss: 0.620634
Average total loss: 0.981692
tensor(0.0037, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(9.6502e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.346304
Average KL loss: 0.612726
Average total loss: 0.959030
tensor(0.0037, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.5103e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.345357
Average KL loss: 0.604939
Average total loss: 0.950296
tensor(0.0036, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(4.5151e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.343573
Average KL loss: 0.613968
Average total loss: 0.957540
tensor(0.0037, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(2.7533e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.341153
Average KL loss: 0.621340
Average total loss: 0.962493
tensor(0.0037, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-2.0775e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.333081
Average KL loss: 0.613224
Average total loss: 0.946305
tensor(0.0037, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(1.0802e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.334082
Average KL loss: 0.615491
Average total loss: 0.949573
tensor(0.0037, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.2958e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.326726
Average KL loss: 0.615473
Average total loss: 0.942198
tensor(0.0037, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-6.2106e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.322860
Average KL loss: 0.613128
Average total loss: 0.935988
tensor(0.0037, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.3519e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.327820
Average KL loss: 0.607443
Average total loss: 0.935263
tensor(0.0036, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-7.8191e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.323809
Average KL loss: 0.625182
Average total loss: 0.948991
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.0091e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.319746
Average KL loss: 0.612867
Average total loss: 0.932613
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.4080e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.318430
Average KL loss: 0.619396
Average total loss: 0.937826
tensor(0.0038, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.0787e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.316880
Average KL loss: 0.607835
Average total loss: 0.924714
tensor(0.0038, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.2386e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.315505
Average KL loss: 0.608534
Average total loss: 0.924039
tensor(0.0038, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.8037e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.318286
Average KL loss: 0.618706
Average total loss: 0.936991
tensor(0.0038, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.8394e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.311982
Average KL loss: 0.611050
Average total loss: 0.923032
tensor(0.0038, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(3.7899e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.314229
Average KL loss: 0.614063
Average total loss: 0.928293
tensor(0.0039, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.9929e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.315544
Average KL loss: 0.622649
Average total loss: 0.938193
tensor(0.0038, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.4206e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.308917
Average KL loss: 0.610376
Average total loss: 0.919293
tensor(0.0038, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(5.0885e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.312389
Average KL loss: 0.614666
Average total loss: 0.927055
tensor(0.0039, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.1620e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.309864
Average KL loss: 0.617050
Average total loss: 0.926914
tensor(0.0039, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.8390e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.313854
Average KL loss: 0.619607
Average total loss: 0.933461
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(3.8760e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.309311
Average KL loss: 0.619022
Average total loss: 0.928333
tensor(0.0039, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.9682e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.309701
Average KL loss: 0.617169
Average total loss: 0.926870
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.6751e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.309211
Average KL loss: 0.622004
Average total loss: 0.931215
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-4.7562e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.310012
Average KL loss: 0.622413
Average total loss: 0.932425
tensor(0.0040, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.8767e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.307012
Average KL loss: 0.618526
Average total loss: 0.925538
tensor(0.0040, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.8414e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.307814
Average KL loss: 0.617976
Average total loss: 0.925791
tensor(0.0039, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.1594e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.307580
Average KL loss: 0.616288
Average total loss: 0.923868
tensor(0.0039, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-3.8798e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.303997
Average KL loss: 0.611213
Average total loss: 0.915210
tensor(0.0039, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.1320e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.306513
Average KL loss: 0.618903
Average total loss: 0.925416
tensor(0.0040, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.8693e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.304160
Average KL loss: 0.618445
Average total loss: 0.922605
tensor(0.0040, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.3583e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.307162
Average KL loss: 0.620983
Average total loss: 0.928145
tensor(0.0040, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-5.0450e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.302541
Average KL loss: 0.617963
Average total loss: 0.920504
tensor(0.0040, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(4.5453e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.307385
Average KL loss: 0.622147
Average total loss: 0.929533
tensor(0.0040, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(2.8649e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.305990
Average KL loss: 0.623696
Average total loss: 0.929686
tensor(0.0040, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-3.6261e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.306458
Average KL loss: 0.620261
Average total loss: 0.926719
tensor(0.0041, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(3.4413e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.304169
Average KL loss: 0.621530
Average total loss: 0.925699
tensor(0.0040, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-5.4415e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.302947
Average KL loss: 0.620296
Average total loss: 0.923242
tensor(0.0041, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-2.8230e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.303586
Average KL loss: 0.622667
Average total loss: 0.926253
tensor(0.0040, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-2.8634e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.301786
Average KL loss: 0.619089
Average total loss: 0.920875
tensor(0.0040, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(3.2319e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.295074
Average KL loss: 0.508579
Average total loss: 0.803654
tensor(0.0040, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(3.6303e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.289362
Average KL loss: 0.414815
Average total loss: 0.704177
tensor(0.0040, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(5.7625e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.293744
Average KL loss: 0.389216
Average total loss: 0.682960
tensor(0.0040, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.1585e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.292714
Average KL loss: 0.379331
Average total loss: 0.672045
tensor(0.0040, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-5.7331e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.294055
Average KL loss: 0.373485
Average total loss: 0.667540
tensor(0.0040, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(9.4462e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.292563
Average KL loss: 0.369722
Average total loss: 0.662285
tensor(0.0040, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(2.5806e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.291805
Average KL loss: 0.366595
Average total loss: 0.658400
tensor(0.0040, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.0480e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.292050
Average KL loss: 0.364766
Average total loss: 0.656816
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.4077e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.290989
Average KL loss: 0.363624
Average total loss: 0.654614
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.5527e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.297130
Average KL loss: 0.361688
Average total loss: 0.658818
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.7940e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.292444
Average KL loss: 0.361017
Average total loss: 0.653461
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.2860e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.292101
Average KL loss: 0.360160
Average total loss: 0.652261
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.6470e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.294664
Average KL loss: 0.359781
Average total loss: 0.654446
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.0870e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.296946
Average KL loss: 0.358876
Average total loss: 0.655822
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-9.4026e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.295852
Average KL loss: 0.358842
Average total loss: 0.654694
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(5.7845e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.296488
Average KL loss: 0.358703
Average total loss: 0.655190
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(7.5797e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.296193
Average KL loss: 0.358280
Average total loss: 0.654473
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.3529e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.294128
Average KL loss: 0.357146
Average total loss: 0.651274
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(3.0469e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.293574
Average KL loss: 0.356722
Average total loss: 0.650296
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.3419e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.296106
Average KL loss: 0.356711
Average total loss: 0.652818
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(2.3713e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.296210
Average KL loss: 0.356504
Average total loss: 0.652713
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-5.6306e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.294840
Average KL loss: 0.356632
Average total loss: 0.651472
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(5.5702e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.297170
Average KL loss: 0.357156
Average total loss: 0.654326
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(2.1651e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.294808
Average KL loss: 0.356378
Average total loss: 0.651187
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-6.5566e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.295426
Average KL loss: 0.355360
Average total loss: 0.650786
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(3.4406e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.295874
Average KL loss: 0.355674
Average total loss: 0.651549
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-4.6123e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.296248
Average KL loss: 0.355524
Average total loss: 0.651772
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-8.5814e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.297873
Average KL loss: 0.355317
Average total loss: 0.653190
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.1089e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.295015
Average KL loss: 0.355482
Average total loss: 0.650497
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.2555e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.296859
Average KL loss: 0.355295
Average total loss: 0.652154
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(3.0000e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.296158
Average KL loss: 0.352306
Average total loss: 0.648464
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-8.1128e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.295449
Average KL loss: 0.347288
Average total loss: 0.642738
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(1.5330e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.296635
Average KL loss: 0.344309
Average total loss: 0.640944
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.0714e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.296724
Average KL loss: 0.342166
Average total loss: 0.638890
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(1.3491e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.294179
Average KL loss: 0.340548
Average total loss: 0.634727
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-4.4208e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.292244
Average KL loss: 0.339191
Average total loss: 0.631436
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.1894e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.295228
Average KL loss: 0.338140
Average total loss: 0.633368
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(2.8810e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.296619
Average KL loss: 0.337293
Average total loss: 0.633911
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-4.7998e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.293990
Average KL loss: 0.336589
Average total loss: 0.630579
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.5712e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.293329
Average KL loss: 0.335996
Average total loss: 0.629325
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(2.7348e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.294548
Average KL loss: 0.335441
Average total loss: 0.629989
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.6847e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.295161
Average KL loss: 0.334826
Average total loss: 0.629986
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.6390e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.294129
Average KL loss: 0.334358
Average total loss: 0.628488
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.8312e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.296537
Average KL loss: 0.333993
Average total loss: 0.630530
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-7.5817e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.295059
Average KL loss: 0.333577
Average total loss: 0.628636
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.2506e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.297796
Average KL loss: 0.333214
Average total loss: 0.631010
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(8.4291e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.295562
Average KL loss: 0.332966
Average total loss: 0.628528
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(3.0854e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.296040
Average KL loss: 0.332647
Average total loss: 0.628687
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.9954e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.292607
Average KL loss: 0.332257
Average total loss: 0.624864
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.3450e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.296219
Average KL loss: 0.332063
Average total loss: 0.628282
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.5528e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.293488
Average KL loss: 0.331995
Average total loss: 0.625482
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.8964e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.293231
Average KL loss: 0.331717
Average total loss: 0.624948
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.7050e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.293028
Average KL loss: 0.331466
Average total loss: 0.624495
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.8746e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.293829
Average KL loss: 0.331358
Average total loss: 0.625187
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.2314e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.292924
Average KL loss: 0.331191
Average total loss: 0.624114
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.6311e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.295320
Average KL loss: 0.330985
Average total loss: 0.626305
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.3012e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.294378
Average KL loss: 0.330849
Average total loss: 0.625227
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.6620e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.297685
Average KL loss: 0.330734
Average total loss: 0.628419
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.9113e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.292719
Average KL loss: 0.330694
Average total loss: 0.623412
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.8801e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.292092
Average KL loss: 0.330574
Average total loss: 0.622665
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(3.6173e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.296216
Average KL loss: 0.330428
Average total loss: 0.626644
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.2658e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.296562
Average KL loss: 0.330322
Average total loss: 0.626884
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.4257e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.291047
Average KL loss: 0.330254
Average total loss: 0.621301
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-5.7966e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.293385
Average KL loss: 0.330074
Average total loss: 0.623459
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.3493e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.294491
Average KL loss: 0.330021
Average total loss: 0.624511
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.9979e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.294509
Average KL loss: 0.329978
Average total loss: 0.624487
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(3.4227e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.294525
Average KL loss: 0.329869
Average total loss: 0.624394
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-4.6435e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.294071
Average KL loss: 0.329760
Average total loss: 0.623831
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.5868e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.293085
Average KL loss: 0.329573
Average total loss: 0.622658
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(4.7477e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.294152
Average KL loss: 0.329400
Average total loss: 0.623551
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.5071e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.296552
Average KL loss: 0.329429
Average total loss: 0.625981
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.2957e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.292379
Average KL loss: 0.329481
Average total loss: 0.621860
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.4193e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.292813
Average KL loss: 0.329424
Average total loss: 0.622237
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.7207e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.296763
Average KL loss: 0.329382
Average total loss: 0.626145
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.8976e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.292495
Average KL loss: 0.329277
Average total loss: 0.621772
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.6964e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.292429
Average KL loss: 0.329148
Average total loss: 0.621578
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.6521e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.292396
Average KL loss: 0.329036
Average total loss: 0.621432
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(4.3184e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.294019
Average KL loss: 0.328948
Average total loss: 0.622966
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(4.8818e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.296351
Average KL loss: 0.328876
Average total loss: 0.625228
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.1408e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.297389
Average KL loss: 0.328810
Average total loss: 0.626199
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(5.1000e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.295795
Average KL loss: 0.328753
Average total loss: 0.624549
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-9.8817e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.294861
Average KL loss: 0.328694
Average total loss: 0.623554
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.5858e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.296962
Average KL loss: 0.328641
Average total loss: 0.625602
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(5.4843e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.295424
Average KL loss: 0.328591
Average total loss: 0.624016
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3053e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.295809
Average KL loss: 0.328539
Average total loss: 0.624347
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.7935e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.291827
Average KL loss: 0.328505
Average total loss: 0.620332
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(3.0577e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.290984
Average KL loss: 0.328497
Average total loss: 0.619481
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.2406e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.292776
Average KL loss: 0.328490
Average total loss: 0.621266
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.0561e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.291656
Average KL loss: 0.328484
Average total loss: 0.620139
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.0940e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.291674
Average KL loss: 0.328476
Average total loss: 0.620151
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.6593e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.293622
Average KL loss: 0.328469
Average total loss: 0.622091
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.7589e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.295699
Average KL loss: 0.328462
Average total loss: 0.624162
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3358e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.294983
Average KL loss: 0.328457
Average total loss: 0.623440
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.0025e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.293472
Average KL loss: 0.328451
Average total loss: 0.621923
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.2230e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.296532
Average KL loss: 0.328443
Average total loss: 0.624976
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.1724e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.299742
Average KL loss: 0.328439
Average total loss: 0.628181
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.3743e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.298771
Average KL loss: 0.328434
Average total loss: 0.627204
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(3.0403e-10, device='cuda:0')
 Percentile value: 0.002070772461593151
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =     213 /    1728             ( 12.33%) | total_pruned =    1515 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
bn1.bias             | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1582 /   36864             (  4.29%) | total_pruned =   35282 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5516 /   36864             ( 14.96%) | total_pruned =   31348 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4661 /   36864             ( 12.64%) | total_pruned =   32203 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    6658 /   36864             ( 18.06%) | total_pruned =   30206 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   21005 /   73728             ( 28.49%) | total_pruned =   52723 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   39736 /  147456             ( 26.95%) | total_pruned =  107720 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2747 /    8192             ( 33.53%) | total_pruned =    5445 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   33164 /  147456             ( 22.49%) | total_pruned =  114292 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   30153 /  147456             ( 20.45%) | total_pruned =  117303 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   80749 /  294912             ( 27.38%) | total_pruned =  214163 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      88 /     256             ( 34.38%) | total_pruned =     168 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  156457 /  589824             ( 26.53%) | total_pruned =  433367 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   10435 /   32768             ( 31.85%) | total_pruned =   22333 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  139103 /  589824             ( 23.58%) | total_pruned =  450721 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  112224 /  589824             ( 19.03%) | total_pruned =  477600 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  308672 / 1179648             ( 26.17%) | total_pruned =  870976 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      65 /     512             ( 12.70%) | total_pruned =     447 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  500290 / 2359296             ( 21.21%) | total_pruned = 1859006 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     446 /     512             ( 87.11%) | total_pruned =      66 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     186 /     512             ( 36.33%) | total_pruned =     326 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   26383 /  131072             ( 20.13%) | total_pruned =  104689 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     444 /     512             ( 86.72%) | total_pruned =      68 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     181 /     512             ( 35.35%) | total_pruned =     331 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  480397 / 2359296             ( 20.36%) | total_pruned = 1878899 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  823838 / 2359296             ( 34.92%) | total_pruned = 1535458 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
linear.weight        | nonzeros =    4968 /    5120             ( 97.03%) | total_pruned =     152 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 72/100 Loss: 0.019407 Accuracy: 89.09 100.00 % Best test Accuracy: 89.16%
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.2598e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.615039
Average KL loss: 0.667597
Average total loss: 1.282636
tensor(0.0021, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.2428e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.558741
Average KL loss: 0.642175
Average total loss: 1.200916
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.8771e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.471257
Average KL loss: 0.626092
Average total loss: 1.097349
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.1969e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.432934
Average KL loss: 0.613144
Average total loss: 1.046078
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.9081e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.414942
Average KL loss: 0.605674
Average total loss: 1.020615
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.5373e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.406991
Average KL loss: 0.606213
Average total loss: 1.013204
tensor(0.0037, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.4858e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.391560
Average KL loss: 0.609670
Average total loss: 1.001230
tensor(0.0037, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.0190e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.381246
Average KL loss: 0.601408
Average total loss: 0.982654
tensor(0.0037, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(3.2475e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.378227
Average KL loss: 0.608602
Average total loss: 0.986830
tensor(0.0038, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-4.9589e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.374130
Average KL loss: 0.607345
Average total loss: 0.981475
tensor(0.0038, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.4678e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.372052
Average KL loss: 0.608616
Average total loss: 0.980668
tensor(0.0038, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-4.0998e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.366086
Average KL loss: 0.606956
Average total loss: 0.973042
tensor(0.0038, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-6.0099e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.370401
Average KL loss: 0.613155
Average total loss: 0.983556
tensor(0.0038, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(2.7157e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.363700
Average KL loss: 0.614048
Average total loss: 0.977748
tensor(0.0038, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(2.9737e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.362855
Average KL loss: 0.614410
Average total loss: 0.977265
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(2.3598e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.360981
Average KL loss: 0.611696
Average total loss: 0.972677
tensor(-0.0005, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.1323e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.358455
Average KL loss: 0.613497
Average total loss: 0.971952
tensor(0.0043, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.1919e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.354833
Average KL loss: 0.612963
Average total loss: 0.967795
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.2523e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.351858
Average KL loss: 0.609747
Average total loss: 0.961605
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.8130e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.351463
Average KL loss: 0.612778
Average total loss: 0.964240
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.5064e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.352041
Average KL loss: 0.613170
Average total loss: 0.965211
tensor(0.0047, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.6593e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.351041
Average KL loss: 0.611854
Average total loss: 0.962895
tensor(0.0039, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.1603e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.349781
Average KL loss: 0.609817
Average total loss: 0.959599
tensor(0.0040, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.2493e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.351433
Average KL loss: 0.615098
Average total loss: 0.966531
tensor(0.0040, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.2201e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.347617
Average KL loss: 0.616239
Average total loss: 0.963856
tensor(0.0013, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-6.6742e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.352010
Average KL loss: 0.616632
Average total loss: 0.968642
tensor(0.0044, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(7.5169e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.354598
Average KL loss: 0.624305
Average total loss: 0.978904
tensor(0.0040, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(1.3658e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.349007
Average KL loss: 0.618211
Average total loss: 0.967218
tensor(0.0041, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.4514e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.348184
Average KL loss: 0.614046
Average total loss: 0.962230
tensor(0.0033, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.8819e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.343025
Average KL loss: 0.615221
Average total loss: 0.958246
tensor(0.0041, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(9.5308e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.346312
Average KL loss: 0.615794
Average total loss: 0.962106
tensor(0.0041, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.0149e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.346598
Average KL loss: 0.619884
Average total loss: 0.966482
tensor(0.0041, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(6.2660e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.343821
Average KL loss: 0.620035
Average total loss: 0.963857
tensor(0.0041, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(3.0137e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.343013
Average KL loss: 0.621478
Average total loss: 0.964490
tensor(0.0041, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(4.0032e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.346522
Average KL loss: 0.621041
Average total loss: 0.967563
tensor(0.0021, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-4.8929e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.342648
Average KL loss: 0.616622
Average total loss: 0.959270
tensor(0.0043, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(3.6859e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.344534
Average KL loss: 0.626552
Average total loss: 0.971087
tensor(0.0041, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.0754e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.344699
Average KL loss: 0.622111
Average total loss: 0.966810
tensor(0.0041, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.8847e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.351465
Average KL loss: 0.626797
Average total loss: 0.978262
tensor(0.0039, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-7.8251e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.343291
Average KL loss: 0.627965
Average total loss: 0.971257
tensor(0.0039, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-3.3014e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.343050
Average KL loss: 0.621111
Average total loss: 0.964160
tensor(0.0043, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(1.3507e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.331015
Average KL loss: 0.542230
Average total loss: 0.873245
tensor(0.0042, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(6.2031e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.329966
Average KL loss: 0.455340
Average total loss: 0.785306
tensor(0.0042, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.3677e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.329237
Average KL loss: 0.426179
Average total loss: 0.755416
tensor(0.0041, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-4.8383e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.330368
Average KL loss: 0.411431
Average total loss: 0.741799
tensor(0.0041, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.4586e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.331984
Average KL loss: 0.402844
Average total loss: 0.734828
tensor(0.0041, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-7.7540e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.332888
Average KL loss: 0.396547
Average total loss: 0.729435
tensor(0.0041, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(3.2480e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.329376
Average KL loss: 0.392157
Average total loss: 0.721533
tensor(0.0041, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.9198e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.330476
Average KL loss: 0.389232
Average total loss: 0.719707
tensor(0.0041, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(4.8384e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.331700
Average KL loss: 0.386806
Average total loss: 0.718506
tensor(0.0041, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(2.0377e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.333406
Average KL loss: 0.385046
Average total loss: 0.718452
tensor(0.0041, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(4.7995e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.329491
Average KL loss: 0.383633
Average total loss: 0.713124
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.8669e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.336613
Average KL loss: 0.382477
Average total loss: 0.719090
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.8785e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.335795
Average KL loss: 0.382225
Average total loss: 0.718021
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-7.9342e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.334548
Average KL loss: 0.381269
Average total loss: 0.715817
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.6730e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.335966
Average KL loss: 0.379860
Average total loss: 0.715827
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.6279e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.330693
Average KL loss: 0.379376
Average total loss: 0.710069
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.3579e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.330735
Average KL loss: 0.378687
Average total loss: 0.709422
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.6381e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.331900
Average KL loss: 0.377796
Average total loss: 0.709695
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.8782e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.332486
Average KL loss: 0.377594
Average total loss: 0.710080
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-3.3753e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.334634
Average KL loss: 0.377159
Average total loss: 0.711793
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(7.4485e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.335941
Average KL loss: 0.376674
Average total loss: 0.712615
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-5.9929e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.336564
Average KL loss: 0.376842
Average total loss: 0.713405
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(2.3330e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.336944
Average KL loss: 0.376545
Average total loss: 0.713488
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.1143e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.330340
Average KL loss: 0.375332
Average total loss: 0.705671
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(5.3246e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.336430
Average KL loss: 0.374820
Average total loss: 0.711250
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.2899e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.334464
Average KL loss: 0.374806
Average total loss: 0.709270
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.3829e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.334197
Average KL loss: 0.374445
Average total loss: 0.708643
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.9874e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.336451
Average KL loss: 0.374281
Average total loss: 0.710732
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.0106e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.336430
Average KL loss: 0.374843
Average total loss: 0.711273
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(4.5834e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.334475
Average KL loss: 0.373507
Average total loss: 0.707982
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.7666e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.337195
Average KL loss: 0.373306
Average total loss: 0.710502
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.9144e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.334060
Average KL loss: 0.373461
Average total loss: 0.707521
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.6380e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.335417
Average KL loss: 0.372977
Average total loss: 0.708394
tensor(0.0040, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-4.7503e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.335872
Average KL loss: 0.372138
Average total loss: 0.708010
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.5862e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.334495
Average KL loss: 0.372651
Average total loss: 0.707146
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-4.8348e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.334120
Average KL loss: 0.370600
Average total loss: 0.704720
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(3.8024e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.338614
Average KL loss: 0.367158
Average total loss: 0.705772
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.7094e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.333373
Average KL loss: 0.364866
Average total loss: 0.698239
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-4.3517e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.334398
Average KL loss: 0.363126
Average total loss: 0.697524
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(3.5556e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.335968
Average KL loss: 0.361741
Average total loss: 0.697709
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.6972e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.333695
Average KL loss: 0.360590
Average total loss: 0.694285
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(3.2405e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.336577
Average KL loss: 0.359637
Average total loss: 0.696214
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(3.8921e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.334628
Average KL loss: 0.358739
Average total loss: 0.693367
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(1.7010e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.334800
Average KL loss: 0.358009
Average total loss: 0.692809
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(7.8035e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.331464
Average KL loss: 0.357321
Average total loss: 0.688785
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-7.0191e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.335392
Average KL loss: 0.356716
Average total loss: 0.692108
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-5.1420e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.335025
Average KL loss: 0.356161
Average total loss: 0.691186
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(5.5373e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.334250
Average KL loss: 0.355639
Average total loss: 0.689889
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(2.5393e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.333538
Average KL loss: 0.355144
Average total loss: 0.688682
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.2074e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.334153
Average KL loss: 0.354757
Average total loss: 0.688909
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-5.0802e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.337639
Average KL loss: 0.354371
Average total loss: 0.692010
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.8838e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.333597
Average KL loss: 0.353992
Average total loss: 0.687589
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(4.4295e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.330836
Average KL loss: 0.353685
Average total loss: 0.684522
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(3.1621e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.334105
Average KL loss: 0.353297
Average total loss: 0.687402
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(3.1865e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.333659
Average KL loss: 0.352995
Average total loss: 0.686654
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-4.4985e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.330901
Average KL loss: 0.352789
Average total loss: 0.683689
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(1.7246e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.335786
Average KL loss: 0.352567
Average total loss: 0.688352
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-9.9329e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.332094
Average KL loss: 0.352303
Average total loss: 0.684398
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.2507e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.335123
Average KL loss: 0.352037
Average total loss: 0.687159
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.5706e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.335876
Average KL loss: 0.351868
Average total loss: 0.687744
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(5.6884e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.337720
Average KL loss: 0.351686
Average total loss: 0.689406
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.3429e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.338039
Average KL loss: 0.351518
Average total loss: 0.689557
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(3.2181e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.337326
Average KL loss: 0.351383
Average total loss: 0.688709
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-7.5120e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.337692
Average KL loss: 0.351340
Average total loss: 0.689031
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(3.6181e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.332484
Average KL loss: 0.351166
Average total loss: 0.683650
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-6.2101e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.338267
Average KL loss: 0.351035
Average total loss: 0.689302
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(5.1287e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.334390
Average KL loss: 0.350975
Average total loss: 0.685366
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(4.3204e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.336048
Average KL loss: 0.350873
Average total loss: 0.686922
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.5726e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.335444
Average KL loss: 0.350792
Average total loss: 0.686236
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(4.1680e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.333318
Average KL loss: 0.350715
Average total loss: 0.684033
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-9.8194e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.332325
Average KL loss: 0.350645
Average total loss: 0.682970
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(5.6667e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.336440
Average KL loss: 0.350589
Average total loss: 0.687029
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.2198e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.334389
Average KL loss: 0.350527
Average total loss: 0.684916
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.3145e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.337746
Average KL loss: 0.350473
Average total loss: 0.688219
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.2932e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.334393
Average KL loss: 0.350431
Average total loss: 0.684825
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.0401e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.333696
Average KL loss: 0.350373
Average total loss: 0.684069
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-4.8355e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.334921
Average KL loss: 0.350318
Average total loss: 0.685239
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.1291e-11, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.333572
Average KL loss: 0.350278
Average total loss: 0.683851
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.5576e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.333983
Average KL loss: 0.350243
Average total loss: 0.684226
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-4.0262e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.331981
Average KL loss: 0.350200
Average total loss: 0.682180
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.3492e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.336484
Average KL loss: 0.350155
Average total loss: 0.686639
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.3045e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.335661
Average KL loss: 0.350113
Average total loss: 0.685774
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.2754e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.335022
Average KL loss: 0.350076
Average total loss: 0.685098
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-4.0111e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.335895
Average KL loss: 0.350045
Average total loss: 0.685941
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(4.4365e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.335430
Average KL loss: 0.350003
Average total loss: 0.685433
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.4301e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.330546
Average KL loss: 0.349967
Average total loss: 0.680513
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(3.6030e-11, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.336870
Average KL loss: 0.349927
Average total loss: 0.686797
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.3134e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.334851
Average KL loss: 0.349891
Average total loss: 0.684742
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.0959e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.335688
Average KL loss: 0.349860
Average total loss: 0.685548
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.3423e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.334971
Average KL loss: 0.349832
Average total loss: 0.684804
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.0483e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.334194
Average KL loss: 0.349804
Average total loss: 0.683998
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.3453e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.334894
Average KL loss: 0.349778
Average total loss: 0.684672
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(8.2384e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.334484
Average KL loss: 0.349741
Average total loss: 0.684225
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-7.2750e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.335418
Average KL loss: 0.349712
Average total loss: 0.685130
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.6316e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.334698
Average KL loss: 0.349677
Average total loss: 0.684375
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.0840e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.334693
Average KL loss: 0.349645
Average total loss: 0.684338
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.8973e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.335466
Average KL loss: 0.349612
Average total loss: 0.685078
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.6571e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.334935
Average KL loss: 0.349596
Average total loss: 0.684531
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(3.5338e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.333475
Average KL loss: 0.349591
Average total loss: 0.683066
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(6.8656e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.337814
Average KL loss: 0.349588
Average total loss: 0.687402
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-8.4917e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.336631
Average KL loss: 0.349585
Average total loss: 0.686216
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-4.5132e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.336728
Average KL loss: 0.349582
Average total loss: 0.686311
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.2273e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.330713
Average KL loss: 0.349579
Average total loss: 0.680291
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.0371e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.334911
Average KL loss: 0.349575
Average total loss: 0.684486
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-9.6407e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.337290
Average KL loss: 0.349572
Average total loss: 0.686862
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.1637e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.338539
Average KL loss: 0.349569
Average total loss: 0.688109
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-4.2081e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.334191
Average KL loss: 0.349566
Average total loss: 0.683756
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.0553e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.334981
Average KL loss: 0.349562
Average total loss: 0.684544
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.8249e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.333800
Average KL loss: 0.349557
Average total loss: 0.683357
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-7.4419e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.333740
Average KL loss: 0.349554
Average total loss: 0.683294
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.0029e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.335795
Average KL loss: 0.349550
Average total loss: 0.685345
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.8108e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.333572
Average KL loss: 0.349546
Average total loss: 0.683118
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(3.5951e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.330097
Average KL loss: 0.349542
Average total loss: 0.679639
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.5774e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.334541
Average KL loss: 0.349538
Average total loss: 0.684079
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.7693e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.338233
Average KL loss: 0.349534
Average total loss: 0.687767
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.8647e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.335474
Average KL loss: 0.349531
Average total loss: 0.685005
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(5.3798e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.337462
Average KL loss: 0.349528
Average total loss: 0.686990
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.9211e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.336569
Average KL loss: 0.349526
Average total loss: 0.686095
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.0238e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.331715
Average KL loss: 0.349523
Average total loss: 0.681238
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-8.9146e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.336589
Average KL loss: 0.349520
Average total loss: 0.686108
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.3009e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.334096
Average KL loss: 0.349516
Average total loss: 0.683612
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(7.1921e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.329600
Average KL loss: 0.349512
Average total loss: 0.679112
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.6879e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.334972
Average KL loss: 0.349508
Average total loss: 0.684480
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-7.2595e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.335451
Average KL loss: 0.349505
Average total loss: 0.684957
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(4.3423e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.335185
Average KL loss: 0.349503
Average total loss: 0.684688
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(4.4283e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.334950
Average KL loss: 0.349499
Average total loss: 0.684449
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-5.7319e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.334642
Average KL loss: 0.349496
Average total loss: 0.684138
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-5.5620e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.335023
Average KL loss: 0.349493
Average total loss: 0.684516
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.1595e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.337752
Average KL loss: 0.349489
Average total loss: 0.687241
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(3.7594e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.335474
Average KL loss: 0.349485
Average total loss: 0.684959
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(4.3311e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.334930
Average KL loss: 0.349482
Average total loss: 0.684412
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.8861e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.338118
Average KL loss: 0.349479
Average total loss: 0.687597
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.4253e-09, device='cuda:0')
 Percentile value: 0.004304881207644939
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =     130 /    1728             (  7.52%) | total_pruned =    1598 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     621 /   36864             (  1.68%) | total_pruned =   36243 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2386 /   36864             (  6.47%) | total_pruned =   34478 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1857 /   36864             (  5.04%) | total_pruned =   35007 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3176 /   36864             (  8.62%) | total_pruned =   33688 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   11276 /   73728             ( 15.29%) | total_pruned =   62452 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   21126 /  147456             ( 14.33%) | total_pruned =  126330 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1632 /    8192             ( 19.92%) | total_pruned =    6560 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   17688 /  147456             ( 12.00%) | total_pruned =  129768 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   14991 /  147456             ( 10.17%) | total_pruned =  132465 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   46394 /  294912             ( 15.73%) | total_pruned =  248518 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      63 /     256             ( 24.61%) | total_pruned =     193 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   85100 /  589824             ( 14.43%) | total_pruned =  504724 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      41 /     256             ( 16.02%) | total_pruned =     215 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6003 /   32768             ( 18.32%) | total_pruned =   26765 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   72065 /  589824             ( 12.22%) | total_pruned =  517759 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   53725 /  589824             (  9.11%) | total_pruned =  536099 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  168357 / 1179648             ( 14.27%) | total_pruned = 1011291 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     481 /     512             ( 93.95%) | total_pruned =      31 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  252714 / 2359296             ( 10.71%) | total_pruned = 2106582 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     380 /     512             ( 74.22%) | total_pruned =     132 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     154 /     512             ( 30.08%) | total_pruned =     358 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   11483 /  131072             (  8.76%) | total_pruned =  119589 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     312 /     512             ( 60.94%) | total_pruned =     200 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     155 /     512             ( 30.27%) | total_pruned =     357 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  193339 / 2359296             (  8.19%) | total_pruned = 2165957 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     414 /     512             ( 80.86%) | total_pruned =      98 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  423712 / 2359296             ( 17.96%) | total_pruned = 1935584 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     464 /     512             ( 90.62%) | total_pruned =      48 | shape = torch.Size([512])
linear.weight        | nonzeros =    4612 /    5120             ( 90.08%) | total_pruned =     508 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 56/100 Loss: 0.022760 Accuracy: 89.51 100.00 % Best test Accuracy: 89.51%
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-7.0490e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.570914
Average KL loss: 0.601328
Average total loss: 1.172242
tensor(0.0014, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.9441e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.578298
Average KL loss: 0.623708
Average total loss: 1.202006
tensor(0.0034, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0742e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.496942
Average KL loss: 0.622694
Average total loss: 1.119636
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.0384e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.467343
Average KL loss: 0.619302
Average total loss: 1.086646
tensor(0.0037, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(5.0521e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.454081
Average KL loss: 0.617520
Average total loss: 1.071601
tensor(0.0037, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.6673e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.434039
Average KL loss: 0.613048
Average total loss: 1.047087
tensor(0.0037, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-3.7591e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.422992
Average KL loss: 0.608194
Average total loss: 1.031186
tensor(0.0037, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.4223e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.424927
Average KL loss: 0.613911
Average total loss: 1.038837
tensor(0.0038, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(1.1378e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.420411
Average KL loss: 0.615459
Average total loss: 1.035871
tensor(0.0038, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.1546e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.414840
Average KL loss: 0.624133
Average total loss: 1.038973
tensor(0.0038, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.2331e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.411753
Average KL loss: 0.621918
Average total loss: 1.033672
tensor(0.0039, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.8401e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.405185
Average KL loss: 0.621027
Average total loss: 1.026212
tensor(0.0038, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-5.6449e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.397201
Average KL loss: 0.620319
Average total loss: 1.017520
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-7.2317e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.398162
Average KL loss: 0.622700
Average total loss: 1.020862
tensor(0.0040, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.0321e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.399490
Average KL loss: 0.620032
Average total loss: 1.019522
tensor(0.0040, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.8562e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.396576
Average KL loss: 0.619262
Average total loss: 1.015838
tensor(-0.0025, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.6381e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.391417
Average KL loss: 0.620858
Average total loss: 1.012275
tensor(0.0044, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(1.2651e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.394403
Average KL loss: 0.620225
Average total loss: 1.014629
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1176e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.395272
Average KL loss: 0.623668
Average total loss: 1.018941
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.5404e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.392554
Average KL loss: 0.626348
Average total loss: 1.018901
tensor(0.0046, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.7226e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.389587
Average KL loss: 0.623633
Average total loss: 1.013220
tensor(0.0049, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(2.4852e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.387480
Average KL loss: 0.622392
Average total loss: 1.009871
tensor(0.0040, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-4.8799e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.389387
Average KL loss: 0.625978
Average total loss: 1.015365
tensor(0.0040, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-8.2185e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.384570
Average KL loss: 0.620267
Average total loss: 1.004837
tensor(0.0036, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-6.9847e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.390586
Average KL loss: 0.627755
Average total loss: 1.018342
tensor(0.0007, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-8.5998e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.391983
Average KL loss: 0.626577
Average total loss: 1.018560
tensor(0.0044, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(1.1273e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.387562
Average KL loss: 0.624989
Average total loss: 1.012550
tensor(0.0041, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-5.0138e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.386117
Average KL loss: 0.625540
Average total loss: 1.011657
tensor(0.0047, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(2.1039e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.386025
Average KL loss: 0.625617
Average total loss: 1.011642
tensor(0.0032, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.3849e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.382923
Average KL loss: 0.624934
Average total loss: 1.007857
tensor(0.0042, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(8.1871e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.385067
Average KL loss: 0.622727
Average total loss: 1.007794
tensor(0.0042, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(8.1629e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.387959
Average KL loss: 0.628366
Average total loss: 1.016325
tensor(0.0042, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(2.6029e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.384249
Average KL loss: 0.623831
Average total loss: 1.008080
tensor(0.0044, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(5.8057e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.382368
Average KL loss: 0.628681
Average total loss: 1.011049
tensor(0.0042, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-4.7959e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.380501
Average KL loss: 0.627568
Average total loss: 1.008069
tensor(0.0016, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-6.2568e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.374640
Average KL loss: 0.570513
Average total loss: 0.945153
tensor(0.0041, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(4.6804e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.372514
Average KL loss: 0.497885
Average total loss: 0.870399
tensor(0.0041, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.4859e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.371913
Average KL loss: 0.467235
Average total loss: 0.839149
tensor(0.0041, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.5410e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.370275
Average KL loss: 0.449798
Average total loss: 0.820073
tensor(0.0041, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.8233e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.365137
Average KL loss: 0.438892
Average total loss: 0.804029
tensor(0.0041, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(3.4526e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.372318
Average KL loss: 0.430945
Average total loss: 0.803264
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.7542e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.369027
Average KL loss: 0.425353
Average total loss: 0.794380
tensor(0.0041, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-3.6078e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.373071
Average KL loss: 0.421211
Average total loss: 0.794281
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.6977e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.373517
Average KL loss: 0.417945
Average total loss: 0.791462
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(4.2543e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.365385
Average KL loss: 0.415032
Average total loss: 0.780417
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-4.6802e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.367183
Average KL loss: 0.412122
Average total loss: 0.779305
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.0184e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.373624
Average KL loss: 0.411127
Average total loss: 0.784751
tensor(0.0041, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(3.4504e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.371678
Average KL loss: 0.409629
Average total loss: 0.781307
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.3656e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.371664
Average KL loss: 0.407931
Average total loss: 0.779595
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(4.6519e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.374538
Average KL loss: 0.407018
Average total loss: 0.781556
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(3.9837e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.373636
Average KL loss: 0.406429
Average total loss: 0.780065
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(2.6262e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.375778
Average KL loss: 0.405342
Average total loss: 0.781121
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(1.0327e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.374318
Average KL loss: 0.404539
Average total loss: 0.778858
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.9037e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.378025
Average KL loss: 0.403548
Average total loss: 0.781573
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.6205e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.370486
Average KL loss: 0.403033
Average total loss: 0.773519
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-3.1078e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.375253
Average KL loss: 0.402168
Average total loss: 0.777420
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(3.8027e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.370071
Average KL loss: 0.402027
Average total loss: 0.772097
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-3.3139e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.376303
Average KL loss: 0.401329
Average total loss: 0.777632
tensor(0.0041, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-3.7252e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.374101
Average KL loss: 0.400298
Average total loss: 0.774399
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(6.8543e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.379371
Average KL loss: 0.399471
Average total loss: 0.778842
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.4937e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.373098
Average KL loss: 0.399260
Average total loss: 0.772358
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.5653e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.373925
Average KL loss: 0.398918
Average total loss: 0.772844
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(4.6758e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.377977
Average KL loss: 0.398473
Average total loss: 0.776450
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(3.5947e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.377256
Average KL loss: 0.398469
Average total loss: 0.775725
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-5.7416e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.377468
Average KL loss: 0.398972
Average total loss: 0.776440
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-8.7951e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.376056
Average KL loss: 0.398286
Average total loss: 0.774342
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.8331e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.375390
Average KL loss: 0.397531
Average total loss: 0.772921
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.6102e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.374807
Average KL loss: 0.397542
Average total loss: 0.772348
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-7.7442e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.369616
Average KL loss: 0.395876
Average total loss: 0.765492
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.6174e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.371904
Average KL loss: 0.393478
Average total loss: 0.765382
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(4.2846e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.375730
Average KL loss: 0.391722
Average total loss: 0.767452
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.0910e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.372558
Average KL loss: 0.390493
Average total loss: 0.763051
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.1052e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.372916
Average KL loss: 0.389389
Average total loss: 0.762305
tensor(0.0041, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.5655e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.370254
Average KL loss: 0.388420
Average total loss: 0.758674
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.5886e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.373355
Average KL loss: 0.387506
Average total loss: 0.760861
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(5.1480e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.377619
Average KL loss: 0.386729
Average total loss: 0.764348
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(7.1801e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.372423
Average KL loss: 0.386107
Average total loss: 0.758531
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(6.4590e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.374048
Average KL loss: 0.385535
Average total loss: 0.759583
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-4.4182e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.376815
Average KL loss: 0.385007
Average total loss: 0.761822
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.5426e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.375405
Average KL loss: 0.384455
Average total loss: 0.759860
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-4.0442e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.374671
Average KL loss: 0.383921
Average total loss: 0.758592
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(2.5955e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.369719
Average KL loss: 0.383498
Average total loss: 0.753218
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(6.2202e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.373298
Average KL loss: 0.383044
Average total loss: 0.756342
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(5.8263e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.372315
Average KL loss: 0.382622
Average total loss: 0.754937
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.7552e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.371641
Average KL loss: 0.382258
Average total loss: 0.753899
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(5.6295e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.377448
Average KL loss: 0.381906
Average total loss: 0.759354
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.2628e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.375138
Average KL loss: 0.381538
Average total loss: 0.756675
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.3938e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.373129
Average KL loss: 0.381203
Average total loss: 0.754332
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.4798e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.374173
Average KL loss: 0.380847
Average total loss: 0.755020
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(3.8579e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.372428
Average KL loss: 0.380594
Average total loss: 0.753022
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-4.6537e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.380372
Average KL loss: 0.380428
Average total loss: 0.760800
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.4084e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.373151
Average KL loss: 0.380188
Average total loss: 0.753339
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(1.2117e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.370890
Average KL loss: 0.379921
Average total loss: 0.750812
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-2.7864e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.374092
Average KL loss: 0.379681
Average total loss: 0.753773
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(3.3089e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.375173
Average KL loss: 0.379447
Average total loss: 0.754619
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-4.0172e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.375911
Average KL loss: 0.379209
Average total loss: 0.755120
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(2.3327e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.376382
Average KL loss: 0.378983
Average total loss: 0.755365
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(3.0711e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.377195
Average KL loss: 0.378845
Average total loss: 0.756041
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-5.3591e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.375070
Average KL loss: 0.378715
Average total loss: 0.753785
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.2559e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.372924
Average KL loss: 0.378541
Average total loss: 0.751465
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.2316e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.373916
Average KL loss: 0.378395
Average total loss: 0.752310
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(5.1062e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.370693
Average KL loss: 0.378217
Average total loss: 0.748910
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.3708e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.375297
Average KL loss: 0.378082
Average total loss: 0.753379
tensor(0.0041, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(6.7800e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.373300
Average KL loss: 0.377944
Average total loss: 0.751244
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.9160e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.373934
Average KL loss: 0.377787
Average total loss: 0.751721
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.1136e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.372474
Average KL loss: 0.377624
Average total loss: 0.750099
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.0911e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.375125
Average KL loss: 0.377413
Average total loss: 0.752538
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.9351e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.374718
Average KL loss: 0.377236
Average total loss: 0.751955
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.0218e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.370734
Average KL loss: 0.377098
Average total loss: 0.747832
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.2696e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.374828
Average KL loss: 0.376886
Average total loss: 0.751714
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.6802e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.375310
Average KL loss: 0.376786
Average total loss: 0.752096
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.4121e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.376677
Average KL loss: 0.376791
Average total loss: 0.753468
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.7325e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.374046
Average KL loss: 0.376730
Average total loss: 0.750776
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.5437e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.374884
Average KL loss: 0.376601
Average total loss: 0.751485
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.9723e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.374818
Average KL loss: 0.376465
Average total loss: 0.751283
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.9962e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.374916
Average KL loss: 0.376451
Average total loss: 0.751367
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(4.5433e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.374953
Average KL loss: 0.376332
Average total loss: 0.751285
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-7.2030e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.372322
Average KL loss: 0.376252
Average total loss: 0.748575
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(6.5902e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.372540
Average KL loss: 0.376099
Average total loss: 0.748639
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.8760e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.378255
Average KL loss: 0.375936
Average total loss: 0.754191
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.2741e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.372707
Average KL loss: 0.375885
Average total loss: 0.748592
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.8495e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.374412
Average KL loss: 0.375841
Average total loss: 0.750253
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.5057e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.369839
Average KL loss: 0.375792
Average total loss: 0.745632
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.5382e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.376860
Average KL loss: 0.375759
Average total loss: 0.752619
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.1821e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.378022
Average KL loss: 0.375731
Average total loss: 0.753753
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(7.4406e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.371975
Average KL loss: 0.375703
Average total loss: 0.747679
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(4.0849e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.374909
Average KL loss: 0.375665
Average total loss: 0.750574
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.7017e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.377799
Average KL loss: 0.375629
Average total loss: 0.753428
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(4.4039e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.377275
Average KL loss: 0.375598
Average total loss: 0.752873
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(9.8188e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.368233
Average KL loss: 0.375562
Average total loss: 0.743794
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-3.5487e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.373655
Average KL loss: 0.375528
Average total loss: 0.749183
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.5615e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.373253
Average KL loss: 0.375491
Average total loss: 0.748744
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-8.2617e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.370979
Average KL loss: 0.375459
Average total loss: 0.746438
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(5.4631e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.377561
Average KL loss: 0.375430
Average total loss: 0.752991
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(4.0943e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.374972
Average KL loss: 0.375401
Average total loss: 0.750373
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.1801e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.370688
Average KL loss: 0.375381
Average total loss: 0.746069
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.0632e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.374709
Average KL loss: 0.375348
Average total loss: 0.750057
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-7.5265e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.377131
Average KL loss: 0.375317
Average total loss: 0.752448
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(5.7012e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.371459
Average KL loss: 0.375288
Average total loss: 0.746746
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.4902e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.375040
Average KL loss: 0.375255
Average total loss: 0.750295
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-3.2702e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.376284
Average KL loss: 0.375235
Average total loss: 0.751519
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.8320e-11, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.375286
Average KL loss: 0.375227
Average total loss: 0.750513
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.8901e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.370830
Average KL loss: 0.375224
Average total loss: 0.746054
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(5.0703e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.373200
Average KL loss: 0.375222
Average total loss: 0.748422
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-4.4811e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.374817
Average KL loss: 0.375220
Average total loss: 0.750037
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.0384e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.377993
Average KL loss: 0.375217
Average total loss: 0.753210
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.9612e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.377449
Average KL loss: 0.375215
Average total loss: 0.752664
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.7516e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.372419
Average KL loss: 0.375212
Average total loss: 0.747630
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(9.5220e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.374113
Average KL loss: 0.375208
Average total loss: 0.749321
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.9802e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.375550
Average KL loss: 0.375205
Average total loss: 0.750755
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.7405e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.375222
Average KL loss: 0.375203
Average total loss: 0.750425
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.0038e-09, device='cuda:0')
 Percentile value: 0.011991006322205067
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =     101 /    1728             (  5.84%) | total_pruned =    1627 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     321 /   36864             (  0.87%) | total_pruned =   36543 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1025 /   36864             (  2.78%) | total_pruned =   35839 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     944 /   36864             (  2.56%) | total_pruned =   35920 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1693 /   36864             (  4.59%) | total_pruned =   35171 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    6508 /   73728             (  8.83%) | total_pruned =   67220 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   12424 /  147456             (  8.43%) | total_pruned =  135032 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     986 /    8192             ( 12.04%) | total_pruned =    7206 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    9927 /  147456             (  6.73%) | total_pruned =  137529 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    8066 /  147456             (  5.47%) | total_pruned =  139390 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   28285 /  294912             (  9.59%) | total_pruned =  266627 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   48452 /  589824             (  8.21%) | total_pruned =  541372 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3471 /   32768             ( 10.59%) | total_pruned =   29297 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     181 /     256             ( 70.70%) | total_pruned =      75 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   38725 /  589824             (  6.57%) | total_pruned =  551099 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   25917 /  589824             (  4.39%) | total_pruned =  563907 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     170 /     256             ( 66.41%) | total_pruned =      86 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   86839 / 1179648             (  7.36%) | total_pruned = 1092809 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  108639 / 2359296             (  4.60%) | total_pruned = 2250657 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     330 /     512             ( 64.45%) | total_pruned =     182 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     137 /     512             ( 26.76%) | total_pruned =     375 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4013 /  131072             (  3.06%) | total_pruned =  127059 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     246 /     512             ( 48.05%) | total_pruned =     266 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     140 /     512             ( 27.34%) | total_pruned =     372 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   84756 / 2359296             (  3.59%) | total_pruned = 2274540 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     308 /     512             ( 60.16%) | total_pruned =     204 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  219019 / 2359296             (  9.28%) | total_pruned = 2140277 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     435 /     512             ( 84.96%) | total_pruned =      77 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     428 /     512             ( 83.59%) | total_pruned =      84 | shape = torch.Size([512])
linear.weight        | nonzeros =    4130 /    5120             ( 80.66%) | total_pruned =     990 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 61/100 Loss: 0.015097 Accuracy: 88.43 100.00 % Best test Accuracy: 88.52%
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.9163e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.642904
Average KL loss: 0.558176
Average total loss: 1.201081
tensor(0.0007, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.0690e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.621706
Average KL loss: 0.582026
Average total loss: 1.203732
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.6814e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.551020
Average KL loss: 0.579056
Average total loss: 1.130075
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.3101e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.499582
Average KL loss: 0.575573
Average total loss: 1.075155
tensor(0.0034, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.3854e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.487318
Average KL loss: 0.578375
Average total loss: 1.065693
tensor(0.0034, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(9.6694e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.469975
Average KL loss: 0.579437
Average total loss: 1.049412
tensor(0.0034, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.3468e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.457553
Average KL loss: 0.579502
Average total loss: 1.037056
tensor(0.0034, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.3319e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.448513
Average KL loss: 0.579787
Average total loss: 1.028300
tensor(0.0035, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.0111e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.450887
Average KL loss: 0.587294
Average total loss: 1.038181
tensor(0.0035, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-4.2943e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.447548
Average KL loss: 0.588612
Average total loss: 1.036160
tensor(0.0035, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-3.5074e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.437167
Average KL loss: 0.592004
Average total loss: 1.029171
tensor(0.0036, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.2348e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.432454
Average KL loss: 0.585356
Average total loss: 1.017811
tensor(0.0036, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(1.2660e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.431359
Average KL loss: 0.589142
Average total loss: 1.020502
tensor(0.0036, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(1.3736e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.429039
Average KL loss: 0.592282
Average total loss: 1.021321
tensor(0.0036, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(5.4708e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.432416
Average KL loss: 0.596566
Average total loss: 1.028982
tensor(0.0037, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-9.9869e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.424601
Average KL loss: 0.601067
Average total loss: 1.025668
tensor(-0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.8618e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.421537
Average KL loss: 0.596625
Average total loss: 1.018162
tensor(0.0043, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.0709e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.424722
Average KL loss: 0.598295
Average total loss: 1.023017
tensor(0.0037, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-6.0922e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.417893
Average KL loss: 0.594933
Average total loss: 1.012826
tensor(0.0037, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.3559e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.418058
Average KL loss: 0.593817
Average total loss: 1.011875
tensor(0.0038, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.6838e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.416448
Average KL loss: 0.603339
Average total loss: 1.019787
tensor(0.0050, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.8748e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.423014
Average KL loss: 0.598765
Average total loss: 1.021780
tensor(0.0038, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.4871e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.417355
Average KL loss: 0.599425
Average total loss: 1.016780
tensor(0.0038, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-7.0048e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.413236
Average KL loss: 0.597831
Average total loss: 1.011068
tensor(0.0037, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.6024e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.418241
Average KL loss: 0.601355
Average total loss: 1.019597
tensor(-0.0006, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.1328e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.415670
Average KL loss: 0.604928
Average total loss: 1.020598
tensor(0.0042, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(4.3894e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.413333
Average KL loss: 0.603441
Average total loss: 1.016774
tensor(0.0038, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(3.2741e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.410601
Average KL loss: 0.603430
Average total loss: 1.014031
tensor(0.0040, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(4.1661e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.408506
Average KL loss: 0.601903
Average total loss: 1.010409
tensor(0.0026, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.9868e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.411406
Average KL loss: 0.604440
Average total loss: 1.015846
tensor(0.0040, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.7721e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.408615
Average KL loss: 0.601950
Average total loss: 1.010565
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.4831e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.409802
Average KL loss: 0.601966
Average total loss: 1.011768
tensor(0.0039, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.9192e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.407495
Average KL loss: 0.602341
Average total loss: 1.009836
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(5.4269e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.408374
Average KL loss: 0.606185
Average total loss: 1.014559
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.2936e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.408166
Average KL loss: 0.609943
Average total loss: 1.018109
tensor(0.0006, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-8.6297e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.412438
Average KL loss: 0.608199
Average total loss: 1.020637
tensor(0.0043, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.0333e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.405246
Average KL loss: 0.607866
Average total loss: 1.013112
tensor(0.0040, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(6.5596e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.408829
Average KL loss: 0.609465
Average total loss: 1.018294
tensor(0.0040, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-8.2674e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.407060
Average KL loss: 0.608144
Average total loss: 1.015204
tensor(0.0035, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.0299e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.404789
Average KL loss: 0.610404
Average total loss: 1.015193
tensor(0.0035, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.4901e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.405950
Average KL loss: 0.607808
Average total loss: 1.013758
tensor(0.0042, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(5.6640e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.404753
Average KL loss: 0.601693
Average total loss: 1.006446
tensor(0.0040, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(7.1270e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.406866
Average KL loss: 0.603375
Average total loss: 1.010241
tensor(0.0040, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-7.4250e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.402662
Average KL loss: 0.610069
Average total loss: 1.012731
tensor(0.0122, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.9918e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.410517
Average KL loss: 0.614347
Average total loss: 1.024863
tensor(0.0048, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(2.4965e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.411010
Average KL loss: 0.615590
Average total loss: 1.026600
tensor(0.0037, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-4.7589e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.405274
Average KL loss: 0.607138
Average total loss: 1.012412
tensor(0.0040, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-2.7369e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.401380
Average KL loss: 0.610641
Average total loss: 1.012021
tensor(0.0045, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(1.3775e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.404366
Average KL loss: 0.613768
Average total loss: 1.018134
tensor(0.0043, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.4024e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.402080
Average KL loss: 0.608892
Average total loss: 1.010972
tensor(0.0039, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-2.1810e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.403291
Average KL loss: 0.611805
Average total loss: 1.015096
tensor(0.0040, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-1.9830e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.404546
Average KL loss: 0.608493
Average total loss: 1.013040
tensor(0.0039, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-7.9430e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.402342
Average KL loss: 0.609876
Average total loss: 1.012218
tensor(0.0062, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(4.8561e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.396620
Average KL loss: 0.569133
Average total loss: 0.965753
tensor(0.0042, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(1.0626e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.390132
Average KL loss: 0.513683
Average total loss: 0.903815
tensor(0.0040, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(1.6782e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.392429
Average KL loss: 0.485545
Average total loss: 0.877974
tensor(0.0040, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(6.0166e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.392743
Average KL loss: 0.467349
Average total loss: 0.860093
tensor(0.0040, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.9031e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.386336
Average KL loss: 0.455650
Average total loss: 0.841987
tensor(0.0040, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.0613e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.388814
Average KL loss: 0.446759
Average total loss: 0.835574
tensor(0.0040, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.9784e-11, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.395807
Average KL loss: 0.439342
Average total loss: 0.835148
tensor(0.0040, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(8.8845e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.393925
Average KL loss: 0.433936
Average total loss: 0.827862
tensor(0.0040, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.3976e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.392407
Average KL loss: 0.429608
Average total loss: 0.822015
tensor(0.0040, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-5.7358e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.394268
Average KL loss: 0.425857
Average total loss: 0.820124
tensor(0.0040, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(4.0716e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.385773
Average KL loss: 0.422574
Average total loss: 0.808347
tensor(0.0040, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(6.8967e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.393869
Average KL loss: 0.419626
Average total loss: 0.813494
tensor(0.0040, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.1703e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.392360
Average KL loss: 0.417622
Average total loss: 0.809982
tensor(0.0040, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.7458e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.396497
Average KL loss: 0.415956
Average total loss: 0.812454
tensor(0.0040, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(9.9889e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.395191
Average KL loss: 0.414428
Average total loss: 0.809620
tensor(0.0040, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.0435e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.394879
Average KL loss: 0.412957
Average total loss: 0.807836
tensor(0.0040, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.2231e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.397152
Average KL loss: 0.411781
Average total loss: 0.808934
tensor(0.0040, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(5.1868e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.394859
Average KL loss: 0.410034
Average total loss: 0.804893
tensor(0.0040, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(3.2699e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.395088
Average KL loss: 0.409098
Average total loss: 0.804186
tensor(0.0040, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(2.4172e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.396590
Average KL loss: 0.408400
Average total loss: 0.804990
tensor(0.0040, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(5.1547e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.398186
Average KL loss: 0.407434
Average total loss: 0.805619
tensor(0.0040, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(7.3441e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.402080
Average KL loss: 0.406220
Average total loss: 0.808300
tensor(0.0039, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(2.1773e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.394891
Average KL loss: 0.405176
Average total loss: 0.800066
tensor(0.0039, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.6898e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.396825
Average KL loss: 0.404551
Average total loss: 0.801376
tensor(0.0039, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.0836e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.393440
Average KL loss: 0.403796
Average total loss: 0.797236
tensor(0.0039, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-3.4213e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.396515
Average KL loss: 0.403397
Average total loss: 0.799912
tensor(0.0039, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.1626e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.394228
Average KL loss: 0.403447
Average total loss: 0.797675
tensor(0.0039, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(5.1380e-11, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.394615
Average KL loss: 0.402365
Average total loss: 0.796979
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(4.0924e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.398024
Average KL loss: 0.402092
Average total loss: 0.800116
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.1930e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.403503
Average KL loss: 0.401513
Average total loss: 0.805016
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(2.5894e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.397227
Average KL loss: 0.401207
Average total loss: 0.798435
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.4666e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.396285
Average KL loss: 0.400217
Average total loss: 0.796503
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.5296e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.398916
Average KL loss: 0.400123
Average total loss: 0.799038
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-4.8254e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.399435
Average KL loss: 0.400095
Average total loss: 0.799530
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-3.1168e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.396890
Average KL loss: 0.399839
Average total loss: 0.796729
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.4439e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.399946
Average KL loss: 0.399028
Average total loss: 0.798974
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(9.0839e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.396932
Average KL loss: 0.398471
Average total loss: 0.795402
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.4252e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.399338
Average KL loss: 0.397808
Average total loss: 0.797146
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.7441e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.406829
Average KL loss: 0.397954
Average total loss: 0.804783
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(9.4505e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.400059
Average KL loss: 0.398275
Average total loss: 0.798334
tensor(0.0039, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-6.1006e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.401901
Average KL loss: 0.397990
Average total loss: 0.799892
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(8.2970e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.398627
Average KL loss: 0.397457
Average total loss: 0.796083
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.2215e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.395269
Average KL loss: 0.397497
Average total loss: 0.792766
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(8.6001e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.392548
Average KL loss: 0.396619
Average total loss: 0.789167
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(9.2417e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.401250
Average KL loss: 0.396851
Average total loss: 0.798101
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(4.8082e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.400682
Average KL loss: 0.396778
Average total loss: 0.797459
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.5242e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.406843
Average KL loss: 0.396652
Average total loss: 0.803495
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(4.5279e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.396221
Average KL loss: 0.396426
Average total loss: 0.792647
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.5165e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.402945
Average KL loss: 0.395552
Average total loss: 0.798496
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(2.7193e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.398544
Average KL loss: 0.395489
Average total loss: 0.794033
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-3.6048e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.400899
Average KL loss: 0.395520
Average total loss: 0.796419
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.2871e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.401329
Average KL loss: 0.395605
Average total loss: 0.796934
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(6.9742e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.398577
Average KL loss: 0.395141
Average total loss: 0.793717
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.1135e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.402644
Average KL loss: 0.395368
Average total loss: 0.798012
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(2.5725e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.401878
Average KL loss: 0.395645
Average total loss: 0.797523
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-4.4077e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.399950
Average KL loss: 0.394960
Average total loss: 0.794910
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(2.8275e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.400696
Average KL loss: 0.393380
Average total loss: 0.794076
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(1.3796e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.401746
Average KL loss: 0.392195
Average total loss: 0.793942
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(3.8459e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.397414
Average KL loss: 0.391208
Average total loss: 0.788622
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.0340e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.401904
Average KL loss: 0.390289
Average total loss: 0.792193
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.5798e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.399227
Average KL loss: 0.389451
Average total loss: 0.788678
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.2648e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.399075
Average KL loss: 0.388716
Average total loss: 0.787792
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.0229e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.395965
Average KL loss: 0.387996
Average total loss: 0.783961
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(4.6974e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.398901
Average KL loss: 0.387314
Average total loss: 0.786215
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.1998e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.400430
Average KL loss: 0.386760
Average total loss: 0.787190
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(6.9774e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.400550
Average KL loss: 0.386263
Average total loss: 0.786813
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.2520e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.399083
Average KL loss: 0.385880
Average total loss: 0.784963
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-4.9671e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.399396
Average KL loss: 0.385454
Average total loss: 0.784849
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-4.1256e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.396366
Average KL loss: 0.385024
Average total loss: 0.781390
tensor(0.0039, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.9841e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.400446
Average KL loss: 0.384647
Average total loss: 0.785093
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.5724e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.401339
Average KL loss: 0.384281
Average total loss: 0.785620
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.8461e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.399221
Average KL loss: 0.383990
Average total loss: 0.783212
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(7.7104e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.403127
Average KL loss: 0.383696
Average total loss: 0.786823
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.7152e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.401258
Average KL loss: 0.383398
Average total loss: 0.784656
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.5316e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.397887
Average KL loss: 0.383100
Average total loss: 0.780987
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.3722e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.396235
Average KL loss: 0.382816
Average total loss: 0.779050
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.5289e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.393540
Average KL loss: 0.382527
Average total loss: 0.776067
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.6366e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.397395
Average KL loss: 0.382198
Average total loss: 0.779593
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-5.0679e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.398796
Average KL loss: 0.381937
Average total loss: 0.780733
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.8748e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.398572
Average KL loss: 0.381692
Average total loss: 0.780264
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.5863e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.394746
Average KL loss: 0.381402
Average total loss: 0.776148
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.3446e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.404490
Average KL loss: 0.381200
Average total loss: 0.785691
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.9676e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.399751
Average KL loss: 0.380917
Average total loss: 0.780669
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.4494e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.397294
Average KL loss: 0.380710
Average total loss: 0.778004
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.2047e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.399414
Average KL loss: 0.380516
Average total loss: 0.779930
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.8021e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.397812
Average KL loss: 0.380314
Average total loss: 0.778126
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.6534e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.395979
Average KL loss: 0.380085
Average total loss: 0.776063
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.5282e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.396190
Average KL loss: 0.379910
Average total loss: 0.776100
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(7.4586e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.402788
Average KL loss: 0.379814
Average total loss: 0.782601
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(5.0271e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.395844
Average KL loss: 0.379773
Average total loss: 0.775617
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(9.2538e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.395977
Average KL loss: 0.379732
Average total loss: 0.775708
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.8682e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.403152
Average KL loss: 0.379694
Average total loss: 0.782846
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.1088e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.399071
Average KL loss: 0.379661
Average total loss: 0.778732
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.9282e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.396681
Average KL loss: 0.379627
Average total loss: 0.776308
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.0434e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.402967
Average KL loss: 0.379588
Average total loss: 0.782556
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.8936e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.398273
Average KL loss: 0.379562
Average total loss: 0.777835
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.4506e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.399821
Average KL loss: 0.379530
Average total loss: 0.779352
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.2778e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.402067
Average KL loss: 0.379510
Average total loss: 0.781577
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.6139e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.398451
Average KL loss: 0.379478
Average total loss: 0.777929
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.1565e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.398626
Average KL loss: 0.379447
Average total loss: 0.778073
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.7543e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.398073
Average KL loss: 0.379419
Average total loss: 0.777493
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.6517e-11, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.397673
Average KL loss: 0.379406
Average total loss: 0.777078
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(7.2481e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.399720
Average KL loss: 0.379402
Average total loss: 0.779122
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.3619e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.399309
Average KL loss: 0.379399
Average total loss: 0.778708
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.0027e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.401463
Average KL loss: 0.379395
Average total loss: 0.780858
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-8.2207e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.395660
Average KL loss: 0.379391
Average total loss: 0.775051
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.1641e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.398612
Average KL loss: 0.379387
Average total loss: 0.777999
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-9.4136e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.400562
Average KL loss: 0.379384
Average total loss: 0.779946
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.0853e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.396949
Average KL loss: 0.379380
Average total loss: 0.776329
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-5.5104e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.397084
Average KL loss: 0.379377
Average total loss: 0.776460
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.5614e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.398179
Average KL loss: 0.379373
Average total loss: 0.777552
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.6990e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.400058
Average KL loss: 0.379370
Average total loss: 0.779428
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.6823e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.400426
Average KL loss: 0.379366
Average total loss: 0.779792
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-5.8413e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.400514
Average KL loss: 0.379362
Average total loss: 0.779876
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.8113e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.398620
Average KL loss: 0.379359
Average total loss: 0.777979
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.5367e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.403181
Average KL loss: 0.379356
Average total loss: 0.782537
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.4740e-10, device='cuda:0')
 Percentile value: 0.026309702545404434
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =      78 /    1728             (  4.51%) | total_pruned =    1650 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     161 /   36864             (  0.44%) | total_pruned =   36703 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     495 /   36864             (  1.34%) | total_pruned =   36369 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     551 /   36864             (  1.49%) | total_pruned =   36313 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     940 /   36864             (  2.55%) | total_pruned =   35924 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3624 /   73728             (  4.92%) | total_pruned =   70104 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    7364 /  147456             (  4.99%) | total_pruned =  140092 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     589 /    8192             (  7.19%) | total_pruned =    7603 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    5602 /  147456             (  3.80%) | total_pruned =  141854 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4402 /  147456             (  2.99%) | total_pruned =  143054 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   17295 /  294912             (  5.86%) | total_pruned =  277617 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   27444 /  589824             (  4.65%) | total_pruned =  562380 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2068 /   32768             (  6.31%) | total_pruned =   30700 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   20809 /  589824             (  3.53%) | total_pruned =  569015 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   13786 /  589824             (  2.34%) | total_pruned =  576038 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     157 /     256             ( 61.33%) | total_pruned =      99 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   44573 / 1179648             (  3.78%) | total_pruned = 1135075 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     451 /     512             ( 88.09%) | total_pruned =      61 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   49852 / 2359296             (  2.11%) | total_pruned = 2309444 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     286 /     512             ( 55.86%) | total_pruned =     226 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     120 /     512             ( 23.44%) | total_pruned =     392 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1578 /  131072             (  1.20%) | total_pruned =  129494 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     163 /     512             ( 31.84%) | total_pruned =     349 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     124 /     512             ( 24.22%) | total_pruned =     388 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   36301 / 2359296             (  1.54%) | total_pruned = 2322995 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     234 /     512             ( 45.70%) | total_pruned =     278 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  104530 / 2359296             (  4.43%) | total_pruned = 2254766 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     385 /     512             ( 75.20%) | total_pruned =     127 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     368 /     512             ( 71.88%) | total_pruned =     144 | shape = torch.Size([512])
linear.weight        | nonzeros =    3401 /    5120             ( 66.43%) | total_pruned =    1719 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 73/100 Loss: 0.012747 Accuracy: 88.10 100.00 % Best test Accuracy: 88.38%
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.8694e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.666072
Average KL loss: 0.501227
Average total loss: 1.167299
tensor(6.5628e-05, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-9.3984e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.686720
Average KL loss: 0.530495
Average total loss: 1.217215
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.9641e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.581632
Average KL loss: 0.541540
Average total loss: 1.123171
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.7734e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.554082
Average KL loss: 0.543889
Average total loss: 1.097971
tensor(0.0030, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.1219e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.534764
Average KL loss: 0.547635
Average total loss: 1.082399
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.2213e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.511160
Average KL loss: 0.549765
Average total loss: 1.060924
tensor(0.0031, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.2912e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.499005
Average KL loss: 0.554876
Average total loss: 1.053881
tensor(0.0032, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.7281e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.483461
Average KL loss: 0.556728
Average total loss: 1.040190
tensor(0.0032, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(1.9971e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.471686
Average KL loss: 0.560964
Average total loss: 1.032649
tensor(0.0032, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-5.9358e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.466971
Average KL loss: 0.558844
Average total loss: 1.025815
tensor(0.0032, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-4.1983e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.456994
Average KL loss: 0.561683
Average total loss: 1.018677
tensor(0.0033, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-3.2542e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.450884
Average KL loss: 0.565514
Average total loss: 1.016398
tensor(0.0033, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(4.0040e-11, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.448696
Average KL loss: 0.563608
Average total loss: 1.012304
tensor(0.0033, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.0356e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.444100
Average KL loss: 0.563979
Average total loss: 1.008079
tensor(0.0034, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-2.3919e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.447892
Average KL loss: 0.564431
Average total loss: 1.012324
tensor(0.0034, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(6.3996e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.442696
Average KL loss: 0.567290
Average total loss: 1.009986
tensor(-0.0048, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.0517e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.436070
Average KL loss: 0.567876
Average total loss: 1.003946
tensor(0.0041, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(9.2369e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.430569
Average KL loss: 0.567897
Average total loss: 0.998465
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.8012e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.434962
Average KL loss: 0.567860
Average total loss: 1.002823
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.3974e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.432976
Average KL loss: 0.569488
Average total loss: 1.002464
tensor(0.0035, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-3.0003e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.434765
Average KL loss: 0.572214
Average total loss: 1.006979
tensor(0.0049, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.8335e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.433756
Average KL loss: 0.574253
Average total loss: 1.008010
tensor(0.0035, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-6.5887e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.429215
Average KL loss: 0.570320
Average total loss: 0.999535
tensor(0.0035, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.9488e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.428945
Average KL loss: 0.573492
Average total loss: 1.002438
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.7280e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.426772
Average KL loss: 0.577257
Average total loss: 1.004029
tensor(-0.0013, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2235e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.427091
Average KL loss: 0.572400
Average total loss: 0.999491
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.8509e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.425247
Average KL loss: 0.572385
Average total loss: 0.997632
tensor(0.0035, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.3948e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.431866
Average KL loss: 0.575039
Average total loss: 1.006905
tensor(0.0036, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.2725e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.429648
Average KL loss: 0.579425
Average total loss: 1.009073
tensor(0.0022, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-3.1823e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.431500
Average KL loss: 0.580922
Average total loss: 1.012423
tensor(0.0037, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.8747e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.427680
Average KL loss: 0.578838
Average total loss: 1.006519
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.3138e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.420327
Average KL loss: 0.577408
Average total loss: 0.997735
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.3246e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.425472
Average KL loss: 0.578751
Average total loss: 1.004224
tensor(0.0036, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(2.5467e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.418222
Average KL loss: 0.577252
Average total loss: 0.995475
tensor(0.0036, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.7245e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.418896
Average KL loss: 0.580750
Average total loss: 0.999646
tensor(1.8353e-05, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-9.0619e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.425848
Average KL loss: 0.582881
Average total loss: 1.008730
tensor(0.0041, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(6.2089e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.426153
Average KL loss: 0.579785
Average total loss: 1.005938
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.5594e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.422273
Average KL loss: 0.579893
Average total loss: 1.002166
tensor(0.0037, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-5.5611e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.417703
Average KL loss: 0.582007
Average total loss: 0.999710
tensor(0.0032, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-9.3922e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.424378
Average KL loss: 0.583781
Average total loss: 1.008159
tensor(0.0032, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.4138e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.419412
Average KL loss: 0.582945
Average total loss: 1.002358
tensor(0.0039, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(5.2573e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.418941
Average KL loss: 0.585422
Average total loss: 1.004363
tensor(0.0037, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-5.6483e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.420080
Average KL loss: 0.585597
Average total loss: 1.005677
tensor(0.0037, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.0473e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.414463
Average KL loss: 0.583701
Average total loss: 0.998164
tensor(0.0127, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(2.2223e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.416499
Average KL loss: 0.585454
Average total loss: 1.001953
tensor(0.0046, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(2.2749e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.410561
Average KL loss: 0.562399
Average total loss: 0.972960
tensor(0.0038, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(1.2122e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.403763
Average KL loss: 0.521658
Average total loss: 0.925422
tensor(0.0037, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-5.2653e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.403284
Average KL loss: 0.497496
Average total loss: 0.900780
tensor(0.0037, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.9700e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.400194
Average KL loss: 0.481081
Average total loss: 0.881274
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.3380e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.402948
Average KL loss: 0.469210
Average total loss: 0.872158
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(1.5647e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.402064
Average KL loss: 0.460014
Average total loss: 0.862078
tensor(0.0037, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(6.7370e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.402534
Average KL loss: 0.452129
Average total loss: 0.854664
tensor(0.0037, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(5.3625e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.401595
Average KL loss: 0.446188
Average total loss: 0.847783
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.9180e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.407367
Average KL loss: 0.441019
Average total loss: 0.848385
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(5.3527e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.403101
Average KL loss: 0.436832
Average total loss: 0.839933
tensor(0.0036, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(5.1155e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.407330
Average KL loss: 0.433280
Average total loss: 0.840610
tensor(0.0036, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.3766e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.404561
Average KL loss: 0.430416
Average total loss: 0.834977
tensor(0.0036, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.9327e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.406139
Average KL loss: 0.427085
Average total loss: 0.833224
tensor(0.0036, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.4053e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.407587
Average KL loss: 0.424376
Average total loss: 0.831963
tensor(0.0036, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(3.1103e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.404316
Average KL loss: 0.422236
Average total loss: 0.826551
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.2500e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.407174
Average KL loss: 0.420459
Average total loss: 0.827633
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(4.3932e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.408836
Average KL loss: 0.418709
Average total loss: 0.827545
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.9143e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.411986
Average KL loss: 0.417667
Average total loss: 0.829653
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(8.4881e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.409492
Average KL loss: 0.416199
Average total loss: 0.825691
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.1433e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.404941
Average KL loss: 0.414348
Average total loss: 0.819289
tensor(0.0036, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(1.3885e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.407194
Average KL loss: 0.412724
Average total loss: 0.819918
tensor(0.0036, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.7692e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.412657
Average KL loss: 0.411692
Average total loss: 0.824350
tensor(0.0036, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.8727e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.411149
Average KL loss: 0.410846
Average total loss: 0.821995
tensor(0.0036, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(4.0224e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.409261
Average KL loss: 0.409590
Average total loss: 0.818851
tensor(0.0036, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(2.0646e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.413195
Average KL loss: 0.408955
Average total loss: 0.822150
tensor(0.0036, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-4.4348e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.409573
Average KL loss: 0.408578
Average total loss: 0.818151
tensor(0.0036, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(5.8103e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.410740
Average KL loss: 0.407794
Average total loss: 0.818534
tensor(0.0036, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(3.8086e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.407479
Average KL loss: 0.407179
Average total loss: 0.814658
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(3.9263e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.408403
Average KL loss: 0.406517
Average total loss: 0.814919
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(8.2535e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.413928
Average KL loss: 0.405340
Average total loss: 0.819267
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-6.6145e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.416908
Average KL loss: 0.404605
Average total loss: 0.821513
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.0681e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.406149
Average KL loss: 0.404066
Average total loss: 0.810215
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-8.7720e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.415231
Average KL loss: 0.403601
Average total loss: 0.818833
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.6816e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.406551
Average KL loss: 0.403163
Average total loss: 0.809714
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.4532e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.410357
Average KL loss: 0.402507
Average total loss: 0.812864
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(4.7983e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.412563
Average KL loss: 0.401650
Average total loss: 0.814213
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.4792e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.411831
Average KL loss: 0.401298
Average total loss: 0.813130
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.1238e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.411531
Average KL loss: 0.400789
Average total loss: 0.812320
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-4.0373e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.412028
Average KL loss: 0.400202
Average total loss: 0.812230
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-5.8736e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.412369
Average KL loss: 0.399878
Average total loss: 0.812247
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.5992e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.410372
Average KL loss: 0.399232
Average total loss: 0.809603
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(6.6521e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.414125
Average KL loss: 0.399392
Average total loss: 0.813517
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-2.5043e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.412412
Average KL loss: 0.399376
Average total loss: 0.811788
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.1376e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.415017
Average KL loss: 0.399141
Average total loss: 0.814157
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-7.0589e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.414273
Average KL loss: 0.398905
Average total loss: 0.813178
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(8.2972e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.413276
Average KL loss: 0.398498
Average total loss: 0.811774
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.5166e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.418639
Average KL loss: 0.398089
Average total loss: 0.816729
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(4.6174e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.417611
Average KL loss: 0.397752
Average total loss: 0.815363
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(1.5498e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.414925
Average KL loss: 0.397280
Average total loss: 0.812206
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(4.0746e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.411386
Average KL loss: 0.396725
Average total loss: 0.808111
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(5.7119e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.410570
Average KL loss: 0.395757
Average total loss: 0.806327
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.9061e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.416477
Average KL loss: 0.395974
Average total loss: 0.812451
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.5441e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.418557
Average KL loss: 0.395707
Average total loss: 0.814265
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.6768e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.414647
Average KL loss: 0.395742
Average total loss: 0.810389
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(4.1445e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.415692
Average KL loss: 0.396229
Average total loss: 0.811921
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.3320e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.418866
Average KL loss: 0.395686
Average total loss: 0.814552
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.1858e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.411722
Average KL loss: 0.395946
Average total loss: 0.807668
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.7909e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.416987
Average KL loss: 0.396063
Average total loss: 0.813050
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-6.0376e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.414995
Average KL loss: 0.396034
Average total loss: 0.811030
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-8.6206e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.418739
Average KL loss: 0.395369
Average total loss: 0.814108
tensor(0.0035, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.6098e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.417008
Average KL loss: 0.395485
Average total loss: 0.812494
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(6.2402e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.411740
Average KL loss: 0.395096
Average total loss: 0.806836
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.7067e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.417704
Average KL loss: 0.394380
Average total loss: 0.812085
tensor(0.0036, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.6687e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.419638
Average KL loss: 0.393478
Average total loss: 0.813115
tensor(0.0036, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(2.4812e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.420285
Average KL loss: 0.392692
Average total loss: 0.812976
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.6632e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.416257
Average KL loss: 0.391973
Average total loss: 0.808230
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-5.1177e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.417723
Average KL loss: 0.391379
Average total loss: 0.809102
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.7195e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.415055
Average KL loss: 0.390836
Average total loss: 0.805891
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-4.6322e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.413603
Average KL loss: 0.390283
Average total loss: 0.803885
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(4.0404e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.417457
Average KL loss: 0.389770
Average total loss: 0.807227
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(5.5406e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.409818
Average KL loss: 0.389310
Average total loss: 0.799129
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1922e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.413091
Average KL loss: 0.388839
Average total loss: 0.801930
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.8764e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.412998
Average KL loss: 0.388451
Average total loss: 0.801449
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(8.5872e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.412397
Average KL loss: 0.388125
Average total loss: 0.800523
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(5.8576e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.413709
Average KL loss: 0.387778
Average total loss: 0.801487
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-4.5100e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.417275
Average KL loss: 0.387472
Average total loss: 0.804747
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.5194e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.414736
Average KL loss: 0.387173
Average total loss: 0.801909
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-6.0942e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.416450
Average KL loss: 0.386954
Average total loss: 0.803404
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(4.8962e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.414225
Average KL loss: 0.386698
Average total loss: 0.800923
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-7.9137e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.414953
Average KL loss: 0.386352
Average total loss: 0.801304
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-5.4757e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.416684
Average KL loss: 0.386097
Average total loss: 0.802781
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.8283e-11, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.414941
Average KL loss: 0.385851
Average total loss: 0.800792
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.7094e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.415073
Average KL loss: 0.385729
Average total loss: 0.800802
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.9784e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.416244
Average KL loss: 0.385690
Average total loss: 0.801934
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.6112e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.413355
Average KL loss: 0.385656
Average total loss: 0.799011
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.7995e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.417199
Average KL loss: 0.385626
Average total loss: 0.802825
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(5.4570e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.421535
Average KL loss: 0.385603
Average total loss: 0.807137
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.8806e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.413018
Average KL loss: 0.385568
Average total loss: 0.798586
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.5494e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.418842
Average KL loss: 0.385530
Average total loss: 0.804372
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(8.4863e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.412227
Average KL loss: 0.385494
Average total loss: 0.797721
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-4.1828e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.413644
Average KL loss: 0.385463
Average total loss: 0.799108
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(3.1961e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.415880
Average KL loss: 0.385428
Average total loss: 0.801308
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(5.0586e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.414911
Average KL loss: 0.385399
Average total loss: 0.800310
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0947e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.407155
Average KL loss: 0.385371
Average total loss: 0.792526
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.0286e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.416260
Average KL loss: 0.385339
Average total loss: 0.801599
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.7141e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.410972
Average KL loss: 0.385299
Average total loss: 0.796271
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1830e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.417193
Average KL loss: 0.385264
Average total loss: 0.802457
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(6.8609e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.417391
Average KL loss: 0.385237
Average total loss: 0.802628
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(7.7364e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.411207
Average KL loss: 0.385202
Average total loss: 0.796409
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.8006e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.418588
Average KL loss: 0.385169
Average total loss: 0.803757
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(4.8662e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.416947
Average KL loss: 0.385138
Average total loss: 0.802086
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(2.1197e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.413989
Average KL loss: 0.385107
Average total loss: 0.799096
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-9.1654e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.410859
Average KL loss: 0.385075
Average total loss: 0.795935
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-6.3715e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.414639
Average KL loss: 0.385045
Average total loss: 0.799684
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.3721e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.417729
Average KL loss: 0.385012
Average total loss: 0.802742
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-4.2161e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.414852
Average KL loss: 0.384998
Average total loss: 0.799850
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(4.0573e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.412648
Average KL loss: 0.384995
Average total loss: 0.797642
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.8760e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.416321
Average KL loss: 0.384991
Average total loss: 0.801313
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.3555e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.410179
Average KL loss: 0.384988
Average total loss: 0.795167
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.0557e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.416526
Average KL loss: 0.384984
Average total loss: 0.801510
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.8689e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.414613
Average KL loss: 0.384982
Average total loss: 0.799594
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.6376e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.414650
Average KL loss: 0.384978
Average total loss: 0.799629
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.5869e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.411189
Average KL loss: 0.384975
Average total loss: 0.796165
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.4432e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.415197
Average KL loss: 0.384972
Average total loss: 0.800169
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(3.0352e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.412392
Average KL loss: 0.384969
Average total loss: 0.797361
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.8833e-09, device='cuda:0')
 Percentile value: 0.0544605553150177
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =      74 /    1728             (  4.28%) | total_pruned =    1654 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     107 /   36864             (  0.29%) | total_pruned =   36757 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     281 /   36864             (  0.76%) | total_pruned =   36583 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     353 /   36864             (  0.96%) | total_pruned =   36511 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     622 /   36864             (  1.69%) | total_pruned =   36242 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2194 /   73728             (  2.98%) | total_pruned =   71534 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4468 /  147456             (  3.03%) | total_pruned =  142988 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     386 /    8192             (  4.71%) | total_pruned =    7806 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3382 /  147456             (  2.29%) | total_pruned =  144074 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2758 /  147456             (  1.87%) | total_pruned =  144698 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   10909 /  294912             (  3.70%) | total_pruned =  284003 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   16321 /  589824             (  2.77%) | total_pruned =  573503 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     200 /     256             ( 78.12%) | total_pruned =      56 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1295 /   32768             (  3.95%) | total_pruned =   31473 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     150 /     256             ( 58.59%) | total_pruned =     106 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   11261 /  589824             (  1.91%) | total_pruned =  578563 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     189 /     256             ( 73.83%) | total_pruned =      67 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    7335 /  589824             (  1.24%) | total_pruned =  582489 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     133 /     256             ( 51.95%) | total_pruned =     123 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   23003 / 1179648             (  1.95%) | total_pruned = 1156645 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     406 /     512             ( 79.30%) | total_pruned =     106 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   24805 / 2359296             (  1.05%) | total_pruned = 2334491 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     229 /     512             ( 44.73%) | total_pruned =     283 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      85 /     512             ( 16.60%) | total_pruned =     427 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     710 /  131072             (  0.54%) | total_pruned =  130362 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     105 /     512             ( 20.51%) | total_pruned =     407 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      90 /     512             ( 17.58%) | total_pruned =     422 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   16227 / 2359296             (  0.69%) | total_pruned = 2343069 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   42703 / 2359296             (  1.81%) | total_pruned = 2316593 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     290 /     512             ( 56.64%) | total_pruned =     222 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     250 /     512             ( 48.83%) | total_pruned =     262 | shape = torch.Size([512])
linear.weight        | nonzeros =    2229 /    5120             ( 43.54%) | total_pruned =    2891 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 57/100 Loss: 0.050048 Accuracy: 87.63 100.00 % Best test Accuracy: 87.97%
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-4.7834e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.680309
Average KL loss: 0.454906
Average total loss: 1.135215
tensor(-0.0002, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.0463e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.710086
Average KL loss: 0.496782
Average total loss: 1.206867
tensor(0.0025, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.0827e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.607578
Average KL loss: 0.512404
Average total loss: 1.119982
tensor(0.0028, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.1627e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.557462
Average KL loss: 0.516790
Average total loss: 1.074252
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-8.2293e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.533432
Average KL loss: 0.522128
Average total loss: 1.055561
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.5224e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.513408
Average KL loss: 0.527674
Average total loss: 1.041082
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.4763e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.496183
Average KL loss: 0.528227
Average total loss: 1.024410
tensor(0.0030, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.8410e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.487381
Average KL loss: 0.533311
Average total loss: 1.020692
tensor(0.0030, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-6.0729e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.483626
Average KL loss: 0.538947
Average total loss: 1.022574
tensor(0.0031, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.4139e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.472441
Average KL loss: 0.542850
Average total loss: 1.015291
tensor(0.0031, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-2.8472e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.463009
Average KL loss: 0.539024
Average total loss: 1.002033
tensor(0.0031, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-7.0231e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.465112
Average KL loss: 0.543460
Average total loss: 1.008572
tensor(0.0032, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-3.5652e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.452841
Average KL loss: 0.544901
Average total loss: 0.997742
tensor(0.0032, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.9865e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.454337
Average KL loss: 0.542581
Average total loss: 0.996918
tensor(0.0032, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(7.9353e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.451554
Average KL loss: 0.545891
Average total loss: 0.997445
tensor(0.0032, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.0986e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.444608
Average KL loss: 0.549723
Average total loss: 0.994332
tensor(-0.0033, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.7034e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.448941
Average KL loss: 0.551076
Average total loss: 1.000017
tensor(0.0029, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.3002e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.443984
Average KL loss: 0.557496
Average total loss: 1.001480
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.9239e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.443753
Average KL loss: 0.557545
Average total loss: 1.001298
tensor(0.0034, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-7.6112e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.437900
Average KL loss: 0.557610
Average total loss: 0.995510
tensor(0.0092, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.4759e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.440222
Average KL loss: 0.562236
Average total loss: 1.002458
tensor(0.0029, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.6296e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.436255
Average KL loss: 0.561387
Average total loss: 0.997642
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.4894e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.438798
Average KL loss: 0.561670
Average total loss: 1.000468
tensor(0.0034, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.5973e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.432947
Average KL loss: 0.565376
Average total loss: 0.998323
tensor(-0.0003, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-9.5230e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.435854
Average KL loss: 0.563856
Average total loss: 0.999710
tensor(0.0031, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.1512e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.429683
Average KL loss: 0.565873
Average total loss: 0.995556
tensor(0.0035, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.5817e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.434552
Average KL loss: 0.569287
Average total loss: 1.003839
tensor(0.0034, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-3.4818e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.424602
Average KL loss: 0.554584
Average total loss: 0.979186
tensor(0.0035, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(3.1393e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.417612
Average KL loss: 0.527850
Average total loss: 0.945461
tensor(0.0034, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.5242e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.421152
Average KL loss: 0.510149
Average total loss: 0.931300
tensor(0.0034, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(4.7392e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.415849
Average KL loss: 0.496735
Average total loss: 0.912583
tensor(0.0034, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.9503e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.414439
Average KL loss: 0.485810
Average total loss: 0.900249
tensor(0.0034, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.6412e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.417310
Average KL loss: 0.477563
Average total loss: 0.894873
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.0075e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.416475
Average KL loss: 0.470817
Average total loss: 0.887292
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.2749e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.413814
Average KL loss: 0.464538
Average total loss: 0.878352
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.4950e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.418073
Average KL loss: 0.459510
Average total loss: 0.877583
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.1080e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.417776
Average KL loss: 0.455478
Average total loss: 0.873255
tensor(0.0034, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(7.8979e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.417695
Average KL loss: 0.451944
Average total loss: 0.869639
tensor(0.0034, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.0117e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.419855
Average KL loss: 0.448328
Average total loss: 0.868183
tensor(0.0034, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-5.8886e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.414521
Average KL loss: 0.445506
Average total loss: 0.860027
tensor(0.0034, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.0572e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.416709
Average KL loss: 0.442666
Average total loss: 0.859374
tensor(0.0034, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.8330e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.419418
Average KL loss: 0.439887
Average total loss: 0.859305
tensor(0.0034, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.7505e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.421644
Average KL loss: 0.437464
Average total loss: 0.859108
tensor(0.0034, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-6.7592e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.422461
Average KL loss: 0.435265
Average total loss: 0.857726
tensor(0.0034, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(4.9907e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.419920
Average KL loss: 0.433643
Average total loss: 0.853564
tensor(0.0034, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.7971e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.415895
Average KL loss: 0.431859
Average total loss: 0.847754
tensor(0.0034, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.7805e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.419768
Average KL loss: 0.430065
Average total loss: 0.849833
tensor(0.0034, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.7644e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.421856
Average KL loss: 0.428645
Average total loss: 0.850500
tensor(0.0033, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.4906e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.425667
Average KL loss: 0.427352
Average total loss: 0.853018
tensor(0.0033, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(2.1152e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.423462
Average KL loss: 0.426688
Average total loss: 0.850150
tensor(0.0033, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.2032e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.421604
Average KL loss: 0.425540
Average total loss: 0.847144
tensor(0.0033, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(1.4803e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.419518
Average KL loss: 0.424551
Average total loss: 0.844069
tensor(0.0033, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-5.2172e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.420304
Average KL loss: 0.422872
Average total loss: 0.843176
tensor(0.0033, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-7.6145e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.428515
Average KL loss: 0.422214
Average total loss: 0.850728
tensor(0.0033, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.2657e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.425612
Average KL loss: 0.421399
Average total loss: 0.847011
tensor(0.0033, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(4.5080e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.417903
Average KL loss: 0.420461
Average total loss: 0.838364
tensor(0.0033, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(1.5791e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.415765
Average KL loss: 0.419255
Average total loss: 0.835019
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.8884e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.420223
Average KL loss: 0.418066
Average total loss: 0.838290
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.4910e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.429046
Average KL loss: 0.417556
Average total loss: 0.846601
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(4.0807e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.423444
Average KL loss: 0.417502
Average total loss: 0.840946
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(4.9085e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.417529
Average KL loss: 0.416602
Average total loss: 0.834131
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-5.1529e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.421617
Average KL loss: 0.415757
Average total loss: 0.837374
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(4.5688e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.424612
Average KL loss: 0.414961
Average total loss: 0.839573
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.2313e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.425657
Average KL loss: 0.414361
Average total loss: 0.840018
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(7.5096e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.421877
Average KL loss: 0.413764
Average total loss: 0.835640
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(8.3152e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.426790
Average KL loss: 0.413202
Average total loss: 0.839993
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-5.7283e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.425246
Average KL loss: 0.413067
Average total loss: 0.838314
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(2.9765e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.430128
Average KL loss: 0.412640
Average total loss: 0.842768
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(3.8034e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.419558
Average KL loss: 0.411954
Average total loss: 0.831512
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(4.2339e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.429407
Average KL loss: 0.411738
Average total loss: 0.841144
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(5.2196e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.431898
Average KL loss: 0.411439
Average total loss: 0.843337
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(3.0728e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.422213
Average KL loss: 0.410473
Average total loss: 0.832686
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.4669e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.425213
Average KL loss: 0.410184
Average total loss: 0.835397
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(4.3433e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.424453
Average KL loss: 0.409850
Average total loss: 0.834303
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.9251e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.426128
Average KL loss: 0.409453
Average total loss: 0.835581
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.0079e-12, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.427701
Average KL loss: 0.409186
Average total loss: 0.836887
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(6.7399e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.425337
Average KL loss: 0.408746
Average total loss: 0.834083
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.9395e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.427322
Average KL loss: 0.408557
Average total loss: 0.835879
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.2889e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.423498
Average KL loss: 0.408019
Average total loss: 0.831517
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.9655e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.428086
Average KL loss: 0.407463
Average total loss: 0.835548
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-5.7895e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.427791
Average KL loss: 0.407092
Average total loss: 0.834884
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.5724e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.422091
Average KL loss: 0.406520
Average total loss: 0.828612
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.3631e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.422887
Average KL loss: 0.405983
Average total loss: 0.828869
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.2836e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.429385
Average KL loss: 0.405520
Average total loss: 0.834905
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.1071e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.425919
Average KL loss: 0.405082
Average total loss: 0.831001
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(2.5749e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.425149
Average KL loss: 0.404642
Average total loss: 0.829792
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(3.3154e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.419888
Average KL loss: 0.404263
Average total loss: 0.824151
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.9702e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.421207
Average KL loss: 0.403900
Average total loss: 0.825106
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.6260e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.426487
Average KL loss: 0.403558
Average total loss: 0.830045
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(3.1126e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.426479
Average KL loss: 0.403253
Average total loss: 0.829732
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(5.6516e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.429882
Average KL loss: 0.402948
Average total loss: 0.832830
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.5135e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.424115
Average KL loss: 0.402655
Average total loss: 0.826770
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.0372e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.424035
Average KL loss: 0.402350
Average total loss: 0.826385
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(5.6132e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.424902
Average KL loss: 0.402023
Average total loss: 0.826925
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.0327e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.428529
Average KL loss: 0.401756
Average total loss: 0.830284
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(8.0302e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.423795
Average KL loss: 0.401498
Average total loss: 0.825293
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.2663e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.426160
Average KL loss: 0.401231
Average total loss: 0.827390
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.9472e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.423864
Average KL loss: 0.401015
Average total loss: 0.824879
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.0819e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.426472
Average KL loss: 0.400916
Average total loss: 0.827389
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.7315e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.426648
Average KL loss: 0.400886
Average total loss: 0.827534
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.6506e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.427015
Average KL loss: 0.400863
Average total loss: 0.827878
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.2684e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.429001
Average KL loss: 0.400838
Average total loss: 0.829838
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(5.4418e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.425263
Average KL loss: 0.400810
Average total loss: 0.826073
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-5.0968e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.425647
Average KL loss: 0.400779
Average total loss: 0.826426
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(2.8686e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.421038
Average KL loss: 0.400746
Average total loss: 0.821783
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(8.2569e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.427066
Average KL loss: 0.400715
Average total loss: 0.827781
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-4.4722e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.426555
Average KL loss: 0.400688
Average total loss: 0.827243
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-5.4391e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.430349
Average KL loss: 0.400664
Average total loss: 0.831013
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(2.9780e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.426159
Average KL loss: 0.400638
Average total loss: 0.826797
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-9.9715e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.424070
Average KL loss: 0.400611
Average total loss: 0.824681
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.3187e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.426817
Average KL loss: 0.400580
Average total loss: 0.827398
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.0657e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.428501
Average KL loss: 0.400552
Average total loss: 0.829053
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.7621e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.424744
Average KL loss: 0.400521
Average total loss: 0.825265
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(3.3937e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.423757
Average KL loss: 0.400494
Average total loss: 0.824251
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(4.4843e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.421719
Average KL loss: 0.400468
Average total loss: 0.822186
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.2935e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.431634
Average KL loss: 0.400445
Average total loss: 0.832078
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.7720e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.425678
Average KL loss: 0.400435
Average total loss: 0.826112
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.6937e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.425254
Average KL loss: 0.400432
Average total loss: 0.825686
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(9.7580e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.424190
Average KL loss: 0.400429
Average total loss: 0.824619
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(5.4808e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.428465
Average KL loss: 0.400427
Average total loss: 0.828892
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(5.0111e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.425075
Average KL loss: 0.400425
Average total loss: 0.825500
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.5848e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.422694
Average KL loss: 0.400423
Average total loss: 0.823117
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.2162e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.434307
Average KL loss: 0.400420
Average total loss: 0.834727
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(8.0534e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.426317
Average KL loss: 0.400417
Average total loss: 0.826734
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(5.7587e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.423701
Average KL loss: 0.400414
Average total loss: 0.824115
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.0331e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.425986
Average KL loss: 0.400411
Average total loss: 0.826397
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(5.2178e-09, device='cuda:0')
 Percentile value: 0.13652832806110382
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =      71 /    1728             (  4.11%) | total_pruned =    1657 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      89 /   36864             (  0.24%) | total_pruned =   36775 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     202 /   36864             (  0.55%) | total_pruned =   36662 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     211 /   36864             (  0.57%) | total_pruned =   36653 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     362 /   36864             (  0.98%) | total_pruned =   36502 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1367 /   73728             (  1.85%) | total_pruned =   72361 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2898 /  147456             (  1.97%) | total_pruned =  144558 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     249 /    8192             (  3.04%) | total_pruned =    7943 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2181 /  147456             (  1.48%) | total_pruned =  145275 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1896 /  147456             (  1.29%) | total_pruned =  145560 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7075 /  294912             (  2.40%) | total_pruned =  287837 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   10187 /  589824             (  1.73%) | total_pruned =  579637 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     800 /   32768             (  2.44%) | total_pruned =   31968 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     136 /     256             ( 53.12%) | total_pruned =     120 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6611 /  589824             (  1.12%) | total_pruned =  583213 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     183 /     256             ( 71.48%) | total_pruned =      73 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4217 /  589824             (  0.71%) | total_pruned =  585607 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     124 /     256             ( 48.44%) | total_pruned =     132 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12028 / 1179648             (  1.02%) | total_pruned = 1167620 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     391 /     512             ( 76.37%) | total_pruned =     121 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   12090 / 2359296             (  0.51%) | total_pruned = 2347206 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     192 /     512             ( 37.50%) | total_pruned =     320 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     325 /  131072             (  0.25%) | total_pruned =  130747 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      51 /     512             (  9.96%) | total_pruned =     461 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    7067 / 2359296             (  0.30%) | total_pruned = 2352229 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     139 /     512             ( 27.15%) | total_pruned =     373 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   13365 / 2359296             (  0.57%) | total_pruned = 2345931 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     199 /     512             ( 38.87%) | total_pruned =     313 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
linear.weight        | nonzeros =    1282 /    5120             ( 25.04%) | total_pruned =    3838 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 62/100 Loss: 0.019984 Accuracy: 86.19 99.99 % Best test Accuracy: 86.59%
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-4.8596e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.943069
Average KL loss: 0.412480
Average total loss: 1.355549
tensor(-0.0007, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.2287e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.876643
Average KL loss: 0.442183
Average total loss: 1.318827
tensor(0.0020, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.6761e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.755117
Average KL loss: 0.463189
Average total loss: 1.218306
tensor(0.0023, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.8256e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.687579
Average KL loss: 0.472855
Average total loss: 1.160434
tensor(0.0024, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.5829e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.624841
Average KL loss: 0.475779
Average total loss: 1.100620
tensor(0.0025, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.0867e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.607205
Average KL loss: 0.478438
Average total loss: 1.085643
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1751e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.595588
Average KL loss: 0.486139
Average total loss: 1.081727
tensor(0.0026, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.8153e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.575466
Average KL loss: 0.492534
Average total loss: 1.068000
tensor(0.0027, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.9763e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.560838
Average KL loss: 0.499917
Average total loss: 1.060755
tensor(0.0027, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.2558e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.550993
Average KL loss: 0.502680
Average total loss: 1.053673
tensor(0.0027, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-4.4034e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.535491
Average KL loss: 0.507681
Average total loss: 1.043172
tensor(0.0028, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.3514e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.526852
Average KL loss: 0.509601
Average total loss: 1.036454
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.5091e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.517715
Average KL loss: 0.514653
Average total loss: 1.032367
tensor(0.0029, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-7.0895e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.510232
Average KL loss: 0.518504
Average total loss: 1.028736
tensor(0.0029, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-5.4080e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.503363
Average KL loss: 0.521595
Average total loss: 1.024958
tensor(0.0030, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(5.0088e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.504349
Average KL loss: 0.525360
Average total loss: 1.029709
tensor(-0.0056, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.1987e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.492630
Average KL loss: 0.525274
Average total loss: 1.017904
tensor(0.0037, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.2756e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.491774
Average KL loss: 0.522102
Average total loss: 1.013876
tensor(0.0029, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.8155e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.489849
Average KL loss: 0.526834
Average total loss: 1.016682
tensor(0.0030, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.0709e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.480171
Average KL loss: 0.530006
Average total loss: 1.010177
tensor(0.0030, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-2.3124e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.484347
Average KL loss: 0.536850
Average total loss: 1.021198
tensor(0.0046, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.6303e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.484796
Average KL loss: 0.536998
Average total loss: 1.021794
tensor(0.0031, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.8886e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.473126
Average KL loss: 0.537029
Average total loss: 1.010156
tensor(0.0031, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.4791e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.468803
Average KL loss: 0.537228
Average total loss: 1.006031
tensor(0.0032, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.2622e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.473117
Average KL loss: 0.541343
Average total loss: 1.014460
tensor(-0.0019, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.3209e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.469120
Average KL loss: 0.542292
Average total loss: 1.011412
tensor(0.0036, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(7.6741e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.461800
Average KL loss: 0.545126
Average total loss: 1.006926
tensor(0.0032, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(8.0190e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.463158
Average KL loss: 0.546027
Average total loss: 1.009185
tensor(0.0033, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.2978e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.458198
Average KL loss: 0.545950
Average total loss: 1.004148
tensor(0.0018, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-4.0513e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.462877
Average KL loss: 0.550217
Average total loss: 1.013094
tensor(0.0034, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(7.4596e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.459091
Average KL loss: 0.546593
Average total loss: 1.005685
tensor(0.0033, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.7305e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.461034
Average KL loss: 0.548195
Average total loss: 1.009229
tensor(0.0033, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(4.2739e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.453335
Average KL loss: 0.546627
Average total loss: 0.999962
tensor(0.0033, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.8079e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.459428
Average KL loss: 0.551666
Average total loss: 1.011094
tensor(0.0033, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.2110e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.462558
Average KL loss: 0.559518
Average total loss: 1.022076
tensor(-0.0005, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-9.9824e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.455767
Average KL loss: 0.555436
Average total loss: 1.011203
tensor(0.0038, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(8.7523e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.456016
Average KL loss: 0.553448
Average total loss: 1.009464
tensor(0.0034, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-4.8798e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.451048
Average KL loss: 0.553643
Average total loss: 1.004691
tensor(0.0034, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-5.6049e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.449898
Average KL loss: 0.553840
Average total loss: 1.003738
tensor(0.0028, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.5192e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.457206
Average KL loss: 0.557755
Average total loss: 1.014961
tensor(0.0029, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.6065e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.444727
Average KL loss: 0.554212
Average total loss: 0.998939
tensor(0.0036, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.3065e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.454632
Average KL loss: 0.557788
Average total loss: 1.012420
tensor(0.0034, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-8.6095e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.443203
Average KL loss: 0.560599
Average total loss: 1.003802
tensor(0.0034, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-2.3115e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.447488
Average KL loss: 0.561008
Average total loss: 1.008496
tensor(0.0131, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(2.3620e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.447767
Average KL loss: 0.564140
Average total loss: 1.011907
tensor(0.0044, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(2.3699e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.440360
Average KL loss: 0.559605
Average total loss: 0.999965
tensor(0.0035, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-3.4359e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.444470
Average KL loss: 0.560328
Average total loss: 1.004797
tensor(0.0035, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.9243e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.441104
Average KL loss: 0.559763
Average total loss: 1.000867
tensor(0.0041, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(1.1997e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.445354
Average KL loss: 0.563215
Average total loss: 1.008569
tensor(0.0038, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(7.1786e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.447064
Average KL loss: 0.563989
Average total loss: 1.011053
tensor(0.0034, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-2.3167e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.446111
Average KL loss: 0.562314
Average total loss: 1.008425
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(7.4927e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.448825
Average KL loss: 0.563431
Average total loss: 1.012256
tensor(0.0034, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.9041e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.440800
Average KL loss: 0.556442
Average total loss: 0.997242
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(2.5076e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.437635
Average KL loss: 0.540620
Average total loss: 0.978255
tensor(0.0035, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(4.0090e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.433295
Average KL loss: 0.528649
Average total loss: 0.961944
tensor(0.0035, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-1.6172e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.428994
Average KL loss: 0.519342
Average total loss: 0.948335
tensor(0.0035, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-1.2857e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.424588
Average KL loss: 0.511376
Average total loss: 0.935964
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.1431e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.433630
Average KL loss: 0.504836
Average total loss: 0.938466
tensor(0.0035, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(4.8648e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.427845
Average KL loss: 0.499286
Average total loss: 0.927131
tensor(0.0035, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(2.0196e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.433478
Average KL loss: 0.494521
Average total loss: 0.927999
tensor(0.0035, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.2247e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.432821
Average KL loss: 0.490316
Average total loss: 0.923138
tensor(0.0035, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-4.9505e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.436225
Average KL loss: 0.486598
Average total loss: 0.922823
tensor(0.0035, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(7.1889e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.428209
Average KL loss: 0.483182
Average total loss: 0.911392
tensor(0.0035, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(2.1898e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.428648
Average KL loss: 0.479904
Average total loss: 0.908552
tensor(0.0035, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-1.4305e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.432648
Average KL loss: 0.476833
Average total loss: 0.909481
tensor(0.0035, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(2.9224e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.431986
Average KL loss: 0.474359
Average total loss: 0.906345
tensor(0.0035, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(1.2729e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.430671
Average KL loss: 0.471901
Average total loss: 0.902572
tensor(0.0035, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-3.0350e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.432898
Average KL loss: 0.469834
Average total loss: 0.902732
tensor(0.0035, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.0289e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.431472
Average KL loss: 0.467809
Average total loss: 0.899281
tensor(0.0035, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(6.4196e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.426882
Average KL loss: 0.466023
Average total loss: 0.892904
tensor(0.0035, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.3385e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.434307
Average KL loss: 0.463952
Average total loss: 0.898259
tensor(0.0035, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.8180e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.430255
Average KL loss: 0.462080
Average total loss: 0.892334
tensor(0.0035, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.2518e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.434123
Average KL loss: 0.460519
Average total loss: 0.894643
tensor(0.0034, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-6.0562e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.435342
Average KL loss: 0.458905
Average total loss: 0.894247
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(5.7672e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.431573
Average KL loss: 0.457475
Average total loss: 0.889047
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(4.4404e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.433759
Average KL loss: 0.456435
Average total loss: 0.890194
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.3553e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.436194
Average KL loss: 0.455686
Average total loss: 0.891880
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.2088e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.436258
Average KL loss: 0.454454
Average total loss: 0.890712
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.7095e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.435424
Average KL loss: 0.453514
Average total loss: 0.888938
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-6.4599e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.437613
Average KL loss: 0.452622
Average total loss: 0.890235
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.2970e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.433868
Average KL loss: 0.451639
Average total loss: 0.885507
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.7580e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.435675
Average KL loss: 0.450872
Average total loss: 0.886547
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(3.7152e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.438693
Average KL loss: 0.449702
Average total loss: 0.888395
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.7152e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.436495
Average KL loss: 0.448769
Average total loss: 0.885264
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.1484e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.438991
Average KL loss: 0.447763
Average total loss: 0.886754
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-3.2894e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.437026
Average KL loss: 0.447183
Average total loss: 0.884209
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(3.2895e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.447718
Average KL loss: 0.446720
Average total loss: 0.894438
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.6841e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.432891
Average KL loss: 0.445815
Average total loss: 0.878706
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-3.5489e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.435153
Average KL loss: 0.445174
Average total loss: 0.880326
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.2453e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.435943
Average KL loss: 0.444402
Average total loss: 0.880345
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(2.4971e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.441751
Average KL loss: 0.443451
Average total loss: 0.885202
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.8460e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.436127
Average KL loss: 0.442624
Average total loss: 0.878751
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.0104e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.440632
Average KL loss: 0.442030
Average total loss: 0.882662
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-7.5415e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.438173
Average KL loss: 0.441390
Average total loss: 0.879563
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.9608e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.438319
Average KL loss: 0.440835
Average total loss: 0.879154
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(4.4012e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.436308
Average KL loss: 0.440168
Average total loss: 0.876477
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.7712e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.441994
Average KL loss: 0.439745
Average total loss: 0.881739
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-7.6711e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.440170
Average KL loss: 0.439441
Average total loss: 0.879611
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.3796e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.441032
Average KL loss: 0.438942
Average total loss: 0.879974
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.0127e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.436468
Average KL loss: 0.438545
Average total loss: 0.875013
tensor(0.0034, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(3.4263e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.436687
Average KL loss: 0.438060
Average total loss: 0.874747
tensor(0.0034, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9300e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.441878
Average KL loss: 0.437529
Average total loss: 0.879407
tensor(0.0034, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-3.9541e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.441921
Average KL loss: 0.436958
Average total loss: 0.878879
tensor(0.0034, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(1.5988e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.436191
Average KL loss: 0.436389
Average total loss: 0.872580
tensor(0.0034, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.0019e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.442295
Average KL loss: 0.436058
Average total loss: 0.878353
tensor(0.0034, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(3.6831e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.436428
Average KL loss: 0.435611
Average total loss: 0.872040
tensor(0.0034, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.0568e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.440766
Average KL loss: 0.435344
Average total loss: 0.876111
tensor(0.0034, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(8.8893e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.446159
Average KL loss: 0.435025
Average total loss: 0.881184
tensor(0.0034, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-6.5475e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.438218
Average KL loss: 0.434696
Average total loss: 0.872914
tensor(0.0034, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(3.3375e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.439063
Average KL loss: 0.434302
Average total loss: 0.873364
tensor(0.0034, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.6530e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.440484
Average KL loss: 0.433672
Average total loss: 0.874156
tensor(0.0034, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-6.5955e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.448071
Average KL loss: 0.433408
Average total loss: 0.881479
tensor(0.0034, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(2.9294e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.443984
Average KL loss: 0.433210
Average total loss: 0.877194
tensor(0.0033, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(4.8482e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.441729
Average KL loss: 0.432744
Average total loss: 0.874473
tensor(0.0033, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.8675e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.445249
Average KL loss: 0.432308
Average total loss: 0.877557
tensor(0.0033, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-8.8504e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.445184
Average KL loss: 0.432180
Average total loss: 0.877364
tensor(0.0033, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.5672e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.445806
Average KL loss: 0.432168
Average total loss: 0.877975
tensor(0.0033, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.1702e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.441655
Average KL loss: 0.431981
Average total loss: 0.873636
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(7.5731e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.444872
Average KL loss: 0.431699
Average total loss: 0.876571
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-6.6302e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.441783
Average KL loss: 0.431405
Average total loss: 0.873188
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.8882e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.443025
Average KL loss: 0.431115
Average total loss: 0.874140
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.2187e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.442908
Average KL loss: 0.430877
Average total loss: 0.873785
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.7704e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.444395
Average KL loss: 0.430645
Average total loss: 0.875040
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.9774e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.438004
Average KL loss: 0.430389
Average total loss: 0.868393
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(5.0568e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.443198
Average KL loss: 0.430164
Average total loss: 0.873363
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(5.8840e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.441913
Average KL loss: 0.429974
Average total loss: 0.871887
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(2.8471e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.441762
Average KL loss: 0.429768
Average total loss: 0.871530
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.5383e-11, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.439736
Average KL loss: 0.429537
Average total loss: 0.869273
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(4.0706e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.442014
Average KL loss: 0.429357
Average total loss: 0.871371
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.3463e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.438860
Average KL loss: 0.429152
Average total loss: 0.868012
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.8482e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.443720
Average KL loss: 0.428941
Average total loss: 0.872661
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.7825e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.443257
Average KL loss: 0.428762
Average total loss: 0.872019
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-5.9109e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.442216
Average KL loss: 0.428585
Average total loss: 0.870801
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(2.6620e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.436718
Average KL loss: 0.428419
Average total loss: 0.865137
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.3047e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.441859
Average KL loss: 0.428244
Average total loss: 0.870103
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.7142e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.444412
Average KL loss: 0.428101
Average total loss: 0.872512
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-4.8874e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.443812
Average KL loss: 0.427920
Average total loss: 0.871731
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(9.9354e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.441782
Average KL loss: 0.427769
Average total loss: 0.869551
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(9.7545e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.442093
Average KL loss: 0.427605
Average total loss: 0.869699
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(2.2254e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.437386
Average KL loss: 0.427433
Average total loss: 0.864819
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-5.4357e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.442253
Average KL loss: 0.427277
Average total loss: 0.869530
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-6.9251e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.442686
Average KL loss: 0.427122
Average total loss: 0.869809
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.5399e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.443587
Average KL loss: 0.426971
Average total loss: 0.870559
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.0780e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.447627
Average KL loss: 0.426856
Average total loss: 0.874483
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(2.8627e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.442710
Average KL loss: 0.426728
Average total loss: 0.869438
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.2538e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.443258
Average KL loss: 0.426597
Average total loss: 0.869855
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-3.0995e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.441781
Average KL loss: 0.426480
Average total loss: 0.868261
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-6.3425e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.443123
Average KL loss: 0.426344
Average total loss: 0.869468
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(2.3165e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.437613
Average KL loss: 0.426221
Average total loss: 0.863834
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.1482e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.447362
Average KL loss: 0.426104
Average total loss: 0.873466
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-4.1189e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.443002
Average KL loss: 0.426016
Average total loss: 0.869018
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.8535e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.442194
Average KL loss: 0.425905
Average total loss: 0.868099
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.5024e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.440877
Average KL loss: 0.425807
Average total loss: 0.866684
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.8463e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.440219
Average KL loss: 0.425700
Average total loss: 0.865920
tensor(0.0033, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.5604e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.443124
Average KL loss: 0.425593
Average total loss: 0.868717
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.3508e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.440181
Average KL loss: 0.425495
Average total loss: 0.865677
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-5.4800e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.440874
Average KL loss: 0.425397
Average total loss: 0.866271
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.1590e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.444190
Average KL loss: 0.425296
Average total loss: 0.869486
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.1806e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.440282
Average KL loss: 0.425171
Average total loss: 0.865452
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.0584e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.444672
Average KL loss: 0.425069
Average total loss: 0.869741
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.3383e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.444339
Average KL loss: 0.425019
Average total loss: 0.869359
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.8313e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.441736
Average KL loss: 0.425006
Average total loss: 0.866742
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-4.1405e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.438744
Average KL loss: 0.424992
Average total loss: 0.863736
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(3.2993e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.442373
Average KL loss: 0.424980
Average total loss: 0.867353
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(9.5103e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.443710
Average KL loss: 0.424968
Average total loss: 0.868678
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(2.6131e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.436174
Average KL loss: 0.424955
Average total loss: 0.861129
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-6.2013e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.435927
Average KL loss: 0.424940
Average total loss: 0.860867
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-3.8082e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.442845
Average KL loss: 0.424927
Average total loss: 0.867772
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.2786e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.440211
Average KL loss: 0.424911
Average total loss: 0.865122
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.3509e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.443615
Average KL loss: 0.424899
Average total loss: 0.868514
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-4.6534e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.441284
Average KL loss: 0.424887
Average total loss: 0.866171
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.0149e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.443069
Average KL loss: 0.424876
Average total loss: 0.867945
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(3.0889e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.441779
Average KL loss: 0.424861
Average total loss: 0.866640
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.4182e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.439009
Average KL loss: 0.424851
Average total loss: 0.863859
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(3.2291e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.446159
Average KL loss: 0.424840
Average total loss: 0.870999
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(4.9013e-11, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.438642
Average KL loss: 0.424826
Average total loss: 0.863467
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.3224e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.444840
Average KL loss: 0.424814
Average total loss: 0.869654
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(7.1907e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.444841
Average KL loss: 0.424802
Average total loss: 0.869643
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.2434e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.443292
Average KL loss: 0.424797
Average total loss: 0.868089
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(3.1967e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.444601
Average KL loss: 0.424796
Average total loss: 0.869397
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(4.2722e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.439240
Average KL loss: 0.424795
Average total loss: 0.864035
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.1315e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.443725
Average KL loss: 0.424793
Average total loss: 0.868518
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-3.0224e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.444202
Average KL loss: 0.424792
Average total loss: 0.868994
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.4817e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.439497
Average KL loss: 0.424791
Average total loss: 0.864288
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.4150e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.445037
Average KL loss: 0.424790
Average total loss: 0.869827
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.9032e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.440310
Average KL loss: 0.424789
Average total loss: 0.865099
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-4.5822e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.441523
Average KL loss: 0.424788
Average total loss: 0.866311
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-4.6340e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.445748
Average KL loss: 0.424786
Average total loss: 0.870534
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.3446e-09, device='cuda:0')
 Percentile value: 0.29433366656303406
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =      70 /    1728             (  4.05%) | total_pruned =    1658 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      66 /   36864             (  0.18%) | total_pruned =   36798 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     118 /   36864             (  0.32%) | total_pruned =   36746 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     128 /   36864             (  0.35%) | total_pruned =   36736 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     212 /   36864             (  0.58%) | total_pruned =   36652 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     798 /   73728             (  1.08%) | total_pruned =   72930 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1689 /  147456             (  1.15%) | total_pruned =  145767 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     150 /    8192             (  1.83%) | total_pruned =    8042 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1313 /  147456             (  0.89%) | total_pruned =  146143 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1226 /  147456             (  0.83%) | total_pruned =  146230 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    4338 /  294912             (  1.47%) | total_pruned =  290574 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5984 /  589824             (  1.01%) | total_pruned =  583840 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     429 /   32768             (  1.31%) | total_pruned =   32339 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     109 /     256             ( 42.58%) | total_pruned =     147 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3686 /  589824             (  0.62%) | total_pruned =  586138 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2519 /  589824             (  0.43%) | total_pruned =  587305 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    5861 / 1179648             (  0.50%) | total_pruned = 1173787 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     328 /     512             ( 64.06%) | total_pruned =     184 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    5492 / 2359296             (  0.23%) | total_pruned = 2353804 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     147 /     512             ( 28.71%) | total_pruned =     365 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      28 /     512             (  5.47%) | total_pruned =     484 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     142 /  131072             (  0.11%) | total_pruned =  130930 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3032 / 2359296             (  0.13%) | total_pruned = 2356264 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     107 /     512             ( 20.90%) | total_pruned =     405 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    3633 / 2359296             (  0.15%) | total_pruned = 2355663 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     116 /     512             ( 22.66%) | total_pruned =     396 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      81 /     512             ( 15.82%) | total_pruned =     431 | shape = torch.Size([512])
linear.weight        | nonzeros =     557 /    5120             ( 10.88%) | total_pruned =    4563 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 99/100 Loss: 0.072279 Accuracy: 83.56 99.95 % Best test Accuracy: 85.59%
tensor(0.0033, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-3.7441e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.913376
Average KL loss: 0.403011
Average total loss: 1.316387
tensor(-0.0007, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.0089e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.975071
Average KL loss: 0.406417
Average total loss: 1.381488
tensor(0.0019, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.6384e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.821630
Average KL loss: 0.431352
Average total loss: 1.252982
tensor(0.0022, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.0568e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.750487
Average KL loss: 0.446504
Average total loss: 1.196991
tensor(0.0023, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.6086e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.689315
Average KL loss: 0.456159
Average total loss: 1.145474
tensor(0.0024, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.2508e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.652717
Average KL loss: 0.466367
Average total loss: 1.119085
tensor(0.0024, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6572e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.628144
Average KL loss: 0.472027
Average total loss: 1.100172
tensor(0.0025, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.2636e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.605059
Average KL loss: 0.476082
Average total loss: 1.081142
tensor(0.0025, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.3004e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.590229
Average KL loss: 0.481428
Average total loss: 1.071657
tensor(0.0026, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-7.8305e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.581781
Average KL loss: 0.486899
Average total loss: 1.068679
tensor(0.0026, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-6.8508e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.570536
Average KL loss: 0.491460
Average total loss: 1.061995
tensor(0.0027, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-3.2635e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.562104
Average KL loss: 0.496877
Average total loss: 1.058981
tensor(0.0027, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(3.9769e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.551490
Average KL loss: 0.501015
Average total loss: 1.052505
tensor(0.0028, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-4.4297e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.548630
Average KL loss: 0.504452
Average total loss: 1.053082
tensor(0.0028, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-3.8689e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.532215
Average KL loss: 0.506890
Average total loss: 1.039105
tensor(0.0028, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.2030e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.525556
Average KL loss: 0.509989
Average total loss: 1.035546
tensor(-0.0057, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.1448e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.521199
Average KL loss: 0.511692
Average total loss: 1.032890
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.7398e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.518472
Average KL loss: 0.515702
Average total loss: 1.034173
tensor(0.0029, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-6.6103e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.514114
Average KL loss: 0.517761
Average total loss: 1.031875
tensor(0.0030, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.1856e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.502043
Average KL loss: 0.519052
Average total loss: 1.021095
tensor(0.0030, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.7207e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.510501
Average KL loss: 0.526470
Average total loss: 1.036971
tensor(0.0045, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(3.8719e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.506965
Average KL loss: 0.527306
Average total loss: 1.034270
tensor(0.0031, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-3.0874e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.493136
Average KL loss: 0.531192
Average total loss: 1.024328
tensor(0.0031, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.7370e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.491133
Average KL loss: 0.531883
Average total loss: 1.023016
tensor(0.0031, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.6714e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.490967
Average KL loss: 0.535757
Average total loss: 1.026725
tensor(-0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.3267e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.484325
Average KL loss: 0.536899
Average total loss: 1.021224
tensor(0.0036, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(5.9073e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.478874
Average KL loss: 0.534980
Average total loss: 1.013854
tensor(0.0032, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(5.6416e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.477374
Average KL loss: 0.537612
Average total loss: 1.014987
tensor(0.0033, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.7563e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.472663
Average KL loss: 0.540678
Average total loss: 1.013341
tensor(0.0018, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.8477e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.468408
Average KL loss: 0.546244
Average total loss: 1.014652
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-6.6221e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.471238
Average KL loss: 0.544339
Average total loss: 1.015576
tensor(0.0033, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.7329e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.473731
Average KL loss: 0.545062
Average total loss: 1.018792
tensor(0.0033, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(7.4609e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.464087
Average KL loss: 0.545542
Average total loss: 1.009629
tensor(0.0033, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-3.1418e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.462509
Average KL loss: 0.547063
Average total loss: 1.009572
tensor(0.0034, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-4.8223e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.461955
Average KL loss: 0.553023
Average total loss: 1.014978
tensor(-0.0005, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-9.9996e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.460634
Average KL loss: 0.551653
Average total loss: 1.012287
tensor(0.0039, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(1.2299e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.458322
Average KL loss: 0.553038
Average total loss: 1.011360
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(3.1731e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.458072
Average KL loss: 0.553791
Average total loss: 1.011863
tensor(0.0034, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(1.7331e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.456065
Average KL loss: 0.552876
Average total loss: 1.008941
tensor(0.0029, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-1.4738e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.454839
Average KL loss: 0.556620
Average total loss: 1.011459
tensor(0.0029, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.5715e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.451776
Average KL loss: 0.555810
Average total loss: 1.007585
tensor(0.0037, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(3.8193e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.452781
Average KL loss: 0.554941
Average total loss: 1.007722
tensor(0.0035, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-7.8106e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.451727
Average KL loss: 0.556690
Average total loss: 1.008417
tensor(0.0035, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(5.3490e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.453322
Average KL loss: 0.557441
Average total loss: 1.010763
tensor(0.0132, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(2.4106e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.448480
Average KL loss: 0.561246
Average total loss: 1.009726
tensor(0.0045, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(2.1992e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.452164
Average KL loss: 0.560137
Average total loss: 1.012301
tensor(0.0035, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.3080e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.447521
Average KL loss: 0.561592
Average total loss: 1.009113
tensor(0.0036, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-2.3487e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.449501
Average KL loss: 0.563028
Average total loss: 1.012529
tensor(0.0042, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(1.3497e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.445703
Average KL loss: 0.566622
Average total loss: 1.012326
tensor(0.0039, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(6.5292e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.441236
Average KL loss: 0.564768
Average total loss: 1.006005
tensor(0.0035, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-4.2185e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.443503
Average KL loss: 0.564023
Average total loss: 1.007526
tensor(0.0036, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-6.5338e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.445251
Average KL loss: 0.565024
Average total loss: 1.010274
tensor(0.0035, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.3090e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.450248
Average KL loss: 0.569453
Average total loss: 1.019701
tensor(0.0062, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(7.2007e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.441735
Average KL loss: 0.567986
Average total loss: 1.009721
tensor(0.0038, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(4.7166e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.444526
Average KL loss: 0.568985
Average total loss: 1.013511
tensor(0.0037, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(1.4321e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.442741
Average KL loss: 0.569982
Average total loss: 1.012723
tensor(0.0037, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(4.1879e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.445123
Average KL loss: 0.569265
Average total loss: 1.014389
tensor(0.0098, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.5311e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.442710
Average KL loss: 0.571815
Average total loss: 1.014525
tensor(0.0028, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-2.6078e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.438359
Average KL loss: 0.570126
Average total loss: 1.008484
tensor(0.0038, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(1.7453e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.438275
Average KL loss: 0.571144
Average total loss: 1.009418
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.0748e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.433893
Average KL loss: 0.570321
Average total loss: 1.004214
tensor(0.0046, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(1.8781e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.435275
Average KL loss: 0.574204
Average total loss: 1.009479
tensor(0.0046, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.8953e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.438389
Average KL loss: 0.572131
Average total loss: 1.010520
tensor(0.0038, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(2.8185e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.444827
Average KL loss: 0.572160
Average total loss: 1.016987
tensor(0.0038, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-2.3002e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.434832
Average KL loss: 0.573152
Average total loss: 1.007984
tensor(0.0038, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-4.3051e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.435845
Average KL loss: 0.575261
Average total loss: 1.011106
tensor(-0.0032, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-1.7872e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.435162
Average KL loss: 0.576275
Average total loss: 1.011436
tensor(0.0036, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-7.3341e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.430665
Average KL loss: 0.574532
Average total loss: 1.005197
tensor(0.0039, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-2.7990e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.429625
Average KL loss: 0.574826
Average total loss: 1.004451
tensor(0.0038, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-4.9138e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.430806
Average KL loss: 0.575162
Average total loss: 1.005968
tensor(0.0046, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(1.8686e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.435303
Average KL loss: 0.576846
Average total loss: 1.012149
tensor(0.0056, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(4.2217e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.431934
Average KL loss: 0.575898
Average total loss: 1.007832
tensor(0.0039, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-7.5158e-11, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.424650
Average KL loss: 0.572676
Average total loss: 0.997326
tensor(0.0039, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.6288e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.426081
Average KL loss: 0.564643
Average total loss: 0.990724
tensor(0.0039, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(1.3100e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.423743
Average KL loss: 0.558317
Average total loss: 0.982060
tensor(0.0039, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.0410e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.421252
Average KL loss: 0.552983
Average total loss: 0.974235
tensor(0.0039, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(1.4090e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.415805
Average KL loss: 0.548148
Average total loss: 0.963952
tensor(0.0039, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-2.4800e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.419660
Average KL loss: 0.543912
Average total loss: 0.963572
tensor(0.0039, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(2.6537e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.421637
Average KL loss: 0.540407
Average total loss: 0.962044
tensor(0.0039, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-4.8739e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.416382
Average KL loss: 0.537033
Average total loss: 0.953415
tensor(0.0038, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-2.5005e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.416743
Average KL loss: 0.533909
Average total loss: 0.950652
tensor(0.0038, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(1.2926e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.420868
Average KL loss: 0.531476
Average total loss: 0.952344
tensor(0.0038, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(6.9488e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.420079
Average KL loss: 0.528866
Average total loss: 0.948945
tensor(0.0038, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(2.2302e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.420536
Average KL loss: 0.526334
Average total loss: 0.946870
tensor(0.0038, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-4.3034e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.413705
Average KL loss: 0.524138
Average total loss: 0.937843
tensor(0.0038, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(1.9966e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.417383
Average KL loss: 0.521997
Average total loss: 0.939381
tensor(0.0038, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(4.5814e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.426938
Average KL loss: 0.520126
Average total loss: 0.947064
tensor(0.0038, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-2.5437e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.420113
Average KL loss: 0.518367
Average total loss: 0.938480
tensor(0.0038, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(3.6475e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.421415
Average KL loss: 0.516512
Average total loss: 0.937927
tensor(0.0038, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(4.3441e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.424557
Average KL loss: 0.515017
Average total loss: 0.939574
tensor(0.0038, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(5.6230e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.420474
Average KL loss: 0.513630
Average total loss: 0.934105
tensor(0.0038, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-3.4553e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.420570
Average KL loss: 0.512104
Average total loss: 0.932674
tensor(0.0038, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(4.6801e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.422274
Average KL loss: 0.510857
Average total loss: 0.933131
tensor(0.0038, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-4.6196e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.418957
Average KL loss: 0.509784
Average total loss: 0.928740
tensor(0.0038, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-1.4782e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.417434
Average KL loss: 0.508127
Average total loss: 0.925561
tensor(0.0038, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(2.7778e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.418935
Average KL loss: 0.506673
Average total loss: 0.925608
tensor(0.0038, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-1.6870e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.422955
Average KL loss: 0.505440
Average total loss: 0.928395
tensor(0.0038, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-3.5098e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.432476
Average KL loss: 0.504454
Average total loss: 0.936930
tensor(0.0038, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(3.6683e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.424884
Average KL loss: 0.503755
Average total loss: 0.928639
tensor(0.0038, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-5.6627e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.427751
Average KL loss: 0.502777
Average total loss: 0.930528
tensor(0.0038, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-5.4788e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.424102
Average KL loss: 0.502128
Average total loss: 0.926230
tensor(0.0038, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(3.4719e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.416472
Average KL loss: 0.501173
Average total loss: 0.917646
tensor(0.0038, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-4.3407e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.425707
Average KL loss: 0.500302
Average total loss: 0.926009
tensor(0.0038, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(4.2413e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.418005
Average KL loss: 0.499252
Average total loss: 0.917257
tensor(0.0038, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.7533e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.422077
Average KL loss: 0.498449
Average total loss: 0.920526
tensor(0.0038, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.9287e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.415914
Average KL loss: 0.497589
Average total loss: 0.913502
tensor(0.0038, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(4.0037e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.424034
Average KL loss: 0.496756
Average total loss: 0.920790
tensor(0.0038, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-3.9748e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.423806
Average KL loss: 0.496133
Average total loss: 0.919940
tensor(0.0037, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-5.8407e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.425458
Average KL loss: 0.495559
Average total loss: 0.921017
tensor(0.0037, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.3405e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.423442
Average KL loss: 0.494686
Average total loss: 0.918127
tensor(0.0037, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.2289e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.421830
Average KL loss: 0.494023
Average total loss: 0.915854
tensor(0.0037, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(2.1951e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.426050
Average KL loss: 0.493284
Average total loss: 0.919334
tensor(0.0037, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(1.4426e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.425506
Average KL loss: 0.492433
Average total loss: 0.917939
tensor(0.0037, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(9.9421e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.421896
Average KL loss: 0.491680
Average total loss: 0.913576
tensor(0.0037, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.9079e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.423207
Average KL loss: 0.491163
Average total loss: 0.914370
tensor(0.0037, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(1.9633e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.423183
Average KL loss: 0.490614
Average total loss: 0.913797
tensor(0.0037, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(4.9103e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.424591
Average KL loss: 0.489939
Average total loss: 0.914529
tensor(0.0037, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(4.1617e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.424793
Average KL loss: 0.489432
Average total loss: 0.914225
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-7.9594e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.423287
Average KL loss: 0.489231
Average total loss: 0.912517
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(3.4182e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.421722
Average KL loss: 0.489028
Average total loss: 0.910750
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(2.0648e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.427638
Average KL loss: 0.488853
Average total loss: 0.916491
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-3.0286e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.420492
Average KL loss: 0.488674
Average total loss: 0.909166
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-7.6998e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.426489
Average KL loss: 0.488501
Average total loss: 0.914990
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(8.1994e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.426303
Average KL loss: 0.488337
Average total loss: 0.914640
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(1.8476e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.421991
Average KL loss: 0.488159
Average total loss: 0.910150
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-7.9819e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.425967
Average KL loss: 0.488000
Average total loss: 0.913967
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(2.8933e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.430792
Average KL loss: 0.487854
Average total loss: 0.918646
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-7.7039e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.429040
Average KL loss: 0.487710
Average total loss: 0.916750
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(3.2569e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.424306
Average KL loss: 0.487538
Average total loss: 0.911844
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(3.6199e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.421874
Average KL loss: 0.487383
Average total loss: 0.909257
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(3.1432e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.427011
Average KL loss: 0.487258
Average total loss: 0.914269
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(3.8121e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.423056
Average KL loss: 0.487110
Average total loss: 0.910166
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(2.3087e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.422042
Average KL loss: 0.486971
Average total loss: 0.909012
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(2.8451e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.431692
Average KL loss: 0.486842
Average total loss: 0.918534
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(4.7779e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.420582
Average KL loss: 0.486730
Average total loss: 0.907312
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.8139e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.426285
Average KL loss: 0.486571
Average total loss: 0.912857
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(7.6885e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.427099
Average KL loss: 0.486434
Average total loss: 0.913533
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-4.7963e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.433140
Average KL loss: 0.486296
Average total loss: 0.919436
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(1.2448e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.421126
Average KL loss: 0.486139
Average total loss: 0.907265
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-9.2237e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.425489
Average KL loss: 0.486009
Average total loss: 0.911498
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.5581e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.426154
Average KL loss: 0.485867
Average total loss: 0.912022
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(1.2073e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.426093
Average KL loss: 0.485725
Average total loss: 0.911818
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.7825e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.431325
Average KL loss: 0.485582
Average total loss: 0.916907
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.5551e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.426138
Average KL loss: 0.485467
Average total loss: 0.911605
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.0957e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.427575
Average KL loss: 0.485338
Average total loss: 0.912914
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-3.8628e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.427056
Average KL loss: 0.485234
Average total loss: 0.912291
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(1.5025e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.428168
Average KL loss: 0.485176
Average total loss: 0.913344
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-4.8197e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.426630
Average KL loss: 0.485164
Average total loss: 0.911795
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-4.2444e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.426482
Average KL loss: 0.485152
Average total loss: 0.911633
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(4.4477e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.423253
Average KL loss: 0.485138
Average total loss: 0.908391
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(3.0647e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.427984
Average KL loss: 0.485124
Average total loss: 0.913108
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-8.7268e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.426867
Average KL loss: 0.485115
Average total loss: 0.911982
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-4.4116e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.423720
Average KL loss: 0.485105
Average total loss: 0.908825
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-5.2462e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.425209
Average KL loss: 0.485094
Average total loss: 0.910302
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-4.6806e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.419462
Average KL loss: 0.485082
Average total loss: 0.904544
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.5499e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.424567
Average KL loss: 0.485069
Average total loss: 0.909636
tensor(0.0037, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(5.3428e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.421225
Average KL loss: 0.485058
Average total loss: 0.906283
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(3.8791e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.425418
Average KL loss: 0.485048
Average total loss: 0.910466
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-5.3371e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.425374
Average KL loss: 0.485038
Average total loss: 0.910412
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-2.0509e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.429599
Average KL loss: 0.485026
Average total loss: 0.914625
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-6.0669e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.421182
Average KL loss: 0.485015
Average total loss: 0.906197
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(4.5508e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.424769
Average KL loss: 0.485002
Average total loss: 0.909771
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(1.7197e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.420323
Average KL loss: 0.484989
Average total loss: 0.905312
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(4.8900e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.429187
Average KL loss: 0.484976
Average total loss: 0.914163
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.2832e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.424503
Average KL loss: 0.484964
Average total loss: 0.909466
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(1.5929e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.429577
Average KL loss: 0.484952
Average total loss: 0.914529
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(3.6441e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.422090
Average KL loss: 0.484946
Average total loss: 0.907036
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(1.5663e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.430382
Average KL loss: 0.484945
Average total loss: 0.915327
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-3.8154e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.429855
Average KL loss: 0.484944
Average total loss: 0.914798
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(3.4258e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.435426
Average KL loss: 0.484942
Average total loss: 0.920368
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.1624e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.425831
Average KL loss: 0.484941
Average total loss: 0.910772
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(3.6727e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.429119
Average KL loss: 0.484940
Average total loss: 0.914059
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(1.2875e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.419092
Average KL loss: 0.484939
Average total loss: 0.904031
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(1.4818e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.425040
Average KL loss: 0.484938
Average total loss: 0.909977
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(2.7768e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.424138
Average KL loss: 0.484937
Average total loss: 0.909074
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(3.0775e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.419347
Average KL loss: 0.484935
Average total loss: 0.904282
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-6.7133e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.425606
Average KL loss: 0.484934
Average total loss: 0.910540
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-6.8467e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.423068
Average KL loss: 0.484933
Average total loss: 0.908001
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(9.3747e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.427843
Average KL loss: 0.484932
Average total loss: 0.912774
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(3.4397e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.423475
Average KL loss: 0.484930
Average total loss: 0.908405
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-2.3703e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.421992
Average KL loss: 0.484929
Average total loss: 0.906921
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-3.4804e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.428567
Average KL loss: 0.484928
Average total loss: 0.913495
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-2.9178e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.425979
Average KL loss: 0.484927
Average total loss: 0.910906
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(4.0026e-09, device='cuda:0')
 Percentile value: 0.7916526198387146
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =      66 /    1728             (  3.82%) | total_pruned =    1662 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      58 /   36864             (  0.16%) | total_pruned =   36806 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      87 /   36864             (  0.24%) | total_pruned =   36777 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      97 /   36864             (  0.26%) | total_pruned =   36767 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     132 /   36864             (  0.36%) | total_pruned =   36732 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     497 /   73728             (  0.67%) | total_pruned =   73231 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1027 /  147456             (  0.70%) | total_pruned =  146429 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     100 /    8192             (  1.22%) | total_pruned =    8092 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     841 /  147456             (  0.57%) | total_pruned =  146615 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     813 /  147456             (  0.55%) | total_pruned =  146643 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2463 /  294912             (  0.84%) | total_pruned =  292449 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3309 /  589824             (  0.56%) | total_pruned =  586515 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     227 /   32768             (  0.69%) | total_pruned =   32541 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2070 /  589824             (  0.35%) | total_pruned =  587754 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     157 /     256             ( 61.33%) | total_pruned =      99 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1440 /  589824             (  0.24%) | total_pruned =  588384 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      92 /     256             ( 35.94%) | total_pruned =     164 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2483 / 1179648             (  0.21%) | total_pruned = 1177165 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     267 /     512             ( 52.15%) | total_pruned =     245 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2147 / 2359296             (  0.09%) | total_pruned = 2357149 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     121 /     512             ( 23.63%) | total_pruned =     391 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      56 /  131072             (  0.04%) | total_pruned =  131016 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1011 / 2359296             (  0.04%) | total_pruned = 2358285 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      73 /     512             ( 14.26%) | total_pruned =     439 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     879 / 2359296             (  0.04%) | total_pruned = 2358417 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      47 /     512             (  9.18%) | total_pruned =     465 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
linear.weight        | nonzeros =     242 /    5120             (  4.73%) | total_pruned =    4878 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.339166 Accuracy: 77.61 91.85 % Best test Accuracy: 79.37%
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-5.3837e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.277283
Average KL loss: 0.397023
Average total loss: 1.674306
tensor(-0.0010, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.0154e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.288599
Average KL loss: 0.318716
Average total loss: 1.607315
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.4768e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.121552
Average KL loss: 0.319869
Average total loss: 1.441422
tensor(0.0017, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.6944e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.009316
Average KL loss: 0.321599
Average total loss: 1.330915
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.4222e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.953657
Average KL loss: 0.325576
Average total loss: 1.279233
tensor(0.0017, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.9830e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.911436
Average KL loss: 0.331183
Average total loss: 1.242619
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.2920e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.851019
Average KL loss: 0.336336
Average total loss: 1.187355
tensor(0.0018, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.9397e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.818326
Average KL loss: 0.340266
Average total loss: 1.158591
tensor(0.0018, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0819e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.797077
Average KL loss: 0.343250
Average total loss: 1.140327
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.8522e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.783694
Average KL loss: 0.346155
Average total loss: 1.129849
tensor(0.0019, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.9800e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.783160
Average KL loss: 0.350612
Average total loss: 1.133772
tensor(0.0019, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.2192e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.748465
Average KL loss: 0.353766
Average total loss: 1.102231
tensor(0.0020, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.9018e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.742204
Average KL loss: 0.356660
Average total loss: 1.098864
tensor(0.0020, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.6116e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.730681
Average KL loss: 0.360032
Average total loss: 1.090713
tensor(0.0020, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-9.3740e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.713973
Average KL loss: 0.363881
Average total loss: 1.077854
tensor(0.0021, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-5.0170e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.706023
Average KL loss: 0.369126
Average total loss: 1.075149
tensor(-0.0066, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.2260e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.698216
Average KL loss: 0.370835
Average total loss: 1.069051
tensor(0.0029, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.0154e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.687325
Average KL loss: 0.373185
Average total loss: 1.060510
tensor(0.0021, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.1034e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.689464
Average KL loss: 0.374478
Average total loss: 1.063942
tensor(0.0022, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-6.5365e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.675803
Average KL loss: 0.378495
Average total loss: 1.054299
tensor(0.0022, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.4056e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.674569
Average KL loss: 0.383498
Average total loss: 1.058068
tensor(0.0037, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(3.6759e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.674542
Average KL loss: 0.383453
Average total loss: 1.057995
tensor(0.0023, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-3.0187e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.669059
Average KL loss: 0.387254
Average total loss: 1.056314
tensor(0.0023, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-5.2918e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.663105
Average KL loss: 0.389893
Average total loss: 1.052999
tensor(0.0024, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-5.9318e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.650073
Average KL loss: 0.395482
Average total loss: 1.045556
tensor(-0.0028, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.3252e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.651090
Average KL loss: 0.395412
Average total loss: 1.046502
tensor(0.0028, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(4.8380e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.637833
Average KL loss: 0.395882
Average total loss: 1.033715
tensor(0.0025, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.5012e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.645027
Average KL loss: 0.398060
Average total loss: 1.043087
tensor(0.0025, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.1982e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.647758
Average KL loss: 0.401184
Average total loss: 1.048942
tensor(0.0010, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.6178e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.634431
Average KL loss: 0.408190
Average total loss: 1.042621
tensor(0.0027, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(2.1996e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.632896
Average KL loss: 0.405372
Average total loss: 1.038268
tensor(0.0026, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.9652e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.624675
Average KL loss: 0.408056
Average total loss: 1.032731
tensor(0.0026, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.2516e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.618275
Average KL loss: 0.408879
Average total loss: 1.027154
tensor(0.0026, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-5.2394e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.619482
Average KL loss: 0.411430
Average total loss: 1.030912
tensor(0.0026, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.7395e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.613380
Average KL loss: 0.414877
Average total loss: 1.028257
tensor(-0.0012, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-9.9918e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.610439
Average KL loss: 0.414649
Average total loss: 1.025089
tensor(0.0031, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(9.2958e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.610471
Average KL loss: 0.416179
Average total loss: 1.026649
tensor(0.0027, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.7554e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.607462
Average KL loss: 0.418635
Average total loss: 1.026097
tensor(0.0027, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.1807e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.604931
Average KL loss: 0.419516
Average total loss: 1.024448
tensor(0.0022, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.6470e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.602141
Average KL loss: 0.424493
Average total loss: 1.026634
tensor(0.0023, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-1.4712e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.602710
Average KL loss: 0.422910
Average total loss: 1.025620
tensor(0.0030, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(1.3921e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.594362
Average KL loss: 0.424342
Average total loss: 1.018704
tensor(0.0028, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-3.5995e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.599066
Average KL loss: 0.424360
Average total loss: 1.023426
tensor(0.0029, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(3.7621e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.591547
Average KL loss: 0.425482
Average total loss: 1.017029
tensor(0.0126, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(2.4091e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.589571
Average KL loss: 0.428521
Average total loss: 1.018092
tensor(0.0038, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(2.6458e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.589438
Average KL loss: 0.426743
Average total loss: 1.016181
tensor(0.0029, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-1.3935e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.593632
Average KL loss: 0.428260
Average total loss: 1.021892
tensor(0.0029, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-5.5981e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.585988
Average KL loss: 0.430868
Average total loss: 1.016856
tensor(0.0036, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(1.3358e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.588268
Average KL loss: 0.435378
Average total loss: 1.023646
tensor(0.0033, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.1461e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.585975
Average KL loss: 0.434193
Average total loss: 1.020167
tensor(0.0028, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.4172e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.583143
Average KL loss: 0.435019
Average total loss: 1.018162
tensor(0.0030, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-7.3037e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.586188
Average KL loss: 0.436033
Average total loss: 1.022220
tensor(0.0029, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-2.7753e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.575102
Average KL loss: 0.440018
Average total loss: 1.015120
tensor(0.0057, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(6.4081e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.579056
Average KL loss: 0.438579
Average total loss: 1.017635
tensor(0.0032, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(5.2335e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.575506
Average KL loss: 0.440688
Average total loss: 1.016195
tensor(0.0031, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(1.6974e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.573727
Average KL loss: 0.440941
Average total loss: 1.014668
tensor(0.0031, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-2.7155e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.572154
Average KL loss: 0.442642
Average total loss: 1.014796
tensor(0.0093, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.5215e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.571505
Average KL loss: 0.445475
Average total loss: 1.016980
tensor(0.0022, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.6849e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.568540
Average KL loss: 0.443948
Average total loss: 1.012488
tensor(0.0033, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(2.1781e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.567927
Average KL loss: 0.444851
Average total loss: 1.012777
tensor(0.0032, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-4.2166e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.566666
Average KL loss: 0.446280
Average total loss: 1.012946
tensor(0.0041, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(2.3456e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.566817
Average KL loss: 0.450315
Average total loss: 1.017132
tensor(0.0041, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(1.9864e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.568651
Average KL loss: 0.448259
Average total loss: 1.016909
tensor(0.0033, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.6525e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.559091
Average KL loss: 0.449519
Average total loss: 1.008610
tensor(0.0033, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(2.4778e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.558842
Average KL loss: 0.450237
Average total loss: 1.009079
tensor(0.0033, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.9167e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.562818
Average KL loss: 0.453237
Average total loss: 1.016055
tensor(-0.0038, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-1.8202e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.553273
Average KL loss: 0.453825
Average total loss: 1.007098
tensor(0.0031, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-1.0500e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.554950
Average KL loss: 0.453819
Average total loss: 1.008770
tensor(0.0034, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-2.0482e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.552900
Average KL loss: 0.455756
Average total loss: 1.008656
tensor(0.0034, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-3.2984e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.552154
Average KL loss: 0.456296
Average total loss: 1.008450
tensor(0.0041, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(2.1859e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.548098
Average KL loss: 0.461088
Average total loss: 1.009186
tensor(0.0051, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(4.4073e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.557034
Average KL loss: 0.458257
Average total loss: 1.015291
tensor(0.0034, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-8.2150e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.550687
Average KL loss: 0.458730
Average total loss: 1.009417
tensor(0.0034, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-3.5856e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.547913
Average KL loss: 0.459860
Average total loss: 1.007772
tensor(0.0034, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-3.3415e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.540677
Average KL loss: 0.463538
Average total loss: 1.004215
tensor(0.0039, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(9.6022e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.547694
Average KL loss: 0.462537
Average total loss: 1.010230
tensor(0.0042, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(2.0069e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.546611
Average KL loss: 0.462397
Average total loss: 1.009008
tensor(0.0035, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-4.2936e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.546447
Average KL loss: 0.463274
Average total loss: 1.009721
tensor(0.0035, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-4.7036e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.540095
Average KL loss: 0.462528
Average total loss: 1.002623
tensor(0.0035, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(1.6677e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.542700
Average KL loss: 0.463132
Average total loss: 1.005833
tensor(0.0026, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-2.2644e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.540841
Average KL loss: 0.466486
Average total loss: 1.007327
tensor(0.0023, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-3.1268e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.540539
Average KL loss: 0.463941
Average total loss: 1.004480
tensor(0.0037, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(4.0094e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.545088
Average KL loss: 0.464664
Average total loss: 1.009752
tensor(0.0035, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-1.8227e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.538702
Average KL loss: 0.465279
Average total loss: 1.003981
tensor(0.0034, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-8.1672e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.541370
Average KL loss: 0.468357
Average total loss: 1.009727
tensor(0.0037, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(1.2756e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.540988
Average KL loss: 0.467050
Average total loss: 1.008038
tensor(0.0034, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-7.8216e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.538008
Average KL loss: 0.467576
Average total loss: 1.005584
tensor(0.0036, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-8.2317e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.538604
Average KL loss: 0.469103
Average total loss: 1.007707
tensor(0.0036, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-3.1234e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.537670
Average KL loss: 0.472678
Average total loss: 1.010348
tensor(0.0078, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(1.0268e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.539368
Average KL loss: 0.470995
Average total loss: 1.010363
tensor(0.0039, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(5.1228e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.530949
Average KL loss: 0.469049
Average total loss: 0.999998
tensor(0.0037, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.5968e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.533115
Average KL loss: 0.466104
Average total loss: 0.999219
tensor(0.0036, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.2043e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.531133
Average KL loss: 0.463676
Average total loss: 0.994809
tensor(0.0036, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(6.6854e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.528068
Average KL loss: 0.461645
Average total loss: 0.989713
tensor(0.0036, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-9.7338e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.523819
Average KL loss: 0.459978
Average total loss: 0.983797
tensor(0.0036, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(4.2879e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.526462
Average KL loss: 0.458476
Average total loss: 0.984938
tensor(0.0036, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.8319e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.524306
Average KL loss: 0.457122
Average total loss: 0.981428
tensor(0.0036, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.9740e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.523190
Average KL loss: 0.455918
Average total loss: 0.979108
tensor(0.0036, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-2.6522e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.525330
Average KL loss: 0.454792
Average total loss: 0.980122
tensor(0.0036, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.1608e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.525903
Average KL loss: 0.453708
Average total loss: 0.979611
tensor(0.0036, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(2.2637e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.527574
Average KL loss: 0.452748
Average total loss: 0.980322
tensor(0.0036, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(4.7449e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.529839
Average KL loss: 0.451693
Average total loss: 0.981532
tensor(0.0036, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.8493e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.526907
Average KL loss: 0.450836
Average total loss: 0.977743
tensor(0.0036, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-4.5661e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.524892
Average KL loss: 0.450053
Average total loss: 0.974945
tensor(0.0036, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(1.5010e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.522183
Average KL loss: 0.449229
Average total loss: 0.971411
tensor(0.0036, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-5.4293e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.526018
Average KL loss: 0.448472
Average total loss: 0.974491
tensor(0.0036, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.6346e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.524476
Average KL loss: 0.447710
Average total loss: 0.972186
tensor(0.0036, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(1.1914e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.523610
Average KL loss: 0.446909
Average total loss: 0.970519
tensor(0.0036, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-3.6339e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.527533
Average KL loss: 0.446304
Average total loss: 0.973837
tensor(0.0036, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(1.8108e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.520460
Average KL loss: 0.445839
Average total loss: 0.966299
tensor(0.0036, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(1.3831e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.526323
Average KL loss: 0.445141
Average total loss: 0.971464
tensor(0.0036, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-2.2381e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.534097
Average KL loss: 0.444599
Average total loss: 0.978696
tensor(0.0036, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-7.0992e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.532287
Average KL loss: 0.444080
Average total loss: 0.976367
tensor(0.0036, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-5.4701e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.524541
Average KL loss: 0.443553
Average total loss: 0.968094
tensor(0.0036, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-2.8484e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.527435
Average KL loss: 0.443197
Average total loss: 0.970631
tensor(0.0036, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(3.1478e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.526263
Average KL loss: 0.442727
Average total loss: 0.968990
tensor(0.0036, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(4.3788e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.529448
Average KL loss: 0.442329
Average total loss: 0.971777
tensor(0.0036, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-2.0020e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.524057
Average KL loss: 0.441777
Average total loss: 0.965834
tensor(0.0036, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.3670e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.522902
Average KL loss: 0.441203
Average total loss: 0.964105
tensor(0.0036, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(1.5894e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.527630
Average KL loss: 0.440807
Average total loss: 0.968437
tensor(0.0036, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(1.3724e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.525313
Average KL loss: 0.440418
Average total loss: 0.965731
tensor(0.0036, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(9.1714e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.525883
Average KL loss: 0.439948
Average total loss: 0.965831
tensor(0.0036, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.3774e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.529009
Average KL loss: 0.439508
Average total loss: 0.968516
tensor(0.0036, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.2259e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.530416
Average KL loss: 0.439132
Average total loss: 0.969549
tensor(0.0036, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(1.0086e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.532361
Average KL loss: 0.438796
Average total loss: 0.971156
tensor(0.0036, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(4.9257e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.528117
Average KL loss: 0.438337
Average total loss: 0.966455
tensor(0.0036, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(2.5316e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.526807
Average KL loss: 0.437943
Average total loss: 0.964750
tensor(0.0036, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.2978e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.523848
Average KL loss: 0.437510
Average total loss: 0.961358
tensor(0.0036, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-2.1487e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.528499
Average KL loss: 0.437196
Average total loss: 0.965695
tensor(0.0036, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(6.9731e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.527076
Average KL loss: 0.436890
Average total loss: 0.963965
tensor(0.0036, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(4.5546e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.525009
Average KL loss: 0.436490
Average total loss: 0.961499
tensor(0.0036, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-2.9438e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.528429
Average KL loss: 0.436129
Average total loss: 0.964558
tensor(0.0036, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-5.4791e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.528175
Average KL loss: 0.435865
Average total loss: 0.964040
tensor(0.0036, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(2.6997e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.529106
Average KL loss: 0.435480
Average total loss: 0.964586
tensor(0.0036, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-3.6863e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.530396
Average KL loss: 0.435172
Average total loss: 0.965568
tensor(0.0036, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(1.3582e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.529148
Average KL loss: 0.434841
Average total loss: 0.963989
tensor(0.0036, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-3.9911e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.533828
Average KL loss: 0.434531
Average total loss: 0.968359
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-2.2118e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.530791
Average KL loss: 0.434347
Average total loss: 0.965138
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-5.4332e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.529105
Average KL loss: 0.434068
Average total loss: 0.963174
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-2.3763e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.526969
Average KL loss: 0.433897
Average total loss: 0.960866
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.5389e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.532830
Average KL loss: 0.433822
Average total loss: 0.966652
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(2.6495e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.529537
Average KL loss: 0.433754
Average total loss: 0.963291
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(6.3642e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.524275
Average KL loss: 0.433696
Average total loss: 0.957970
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(7.2098e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.528642
Average KL loss: 0.433620
Average total loss: 0.962262
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-6.3360e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.526656
Average KL loss: 0.433555
Average total loss: 0.960212
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(1.4582e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.529096
Average KL loss: 0.433494
Average total loss: 0.962590
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-6.0386e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.527346
Average KL loss: 0.433416
Average total loss: 0.960761
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(9.7090e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.532582
Average KL loss: 0.433352
Average total loss: 0.965934
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.8058e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.528121
Average KL loss: 0.433295
Average total loss: 0.961416
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(7.6274e-12, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.528848
Average KL loss: 0.433225
Average total loss: 0.962073
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(4.5531e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.531605
Average KL loss: 0.433158
Average total loss: 0.964763
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-5.4586e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.530482
Average KL loss: 0.433102
Average total loss: 0.963585
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(1.5066e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.528099
Average KL loss: 0.433041
Average total loss: 0.961139
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(5.3224e-11, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.529523
Average KL loss: 0.432973
Average total loss: 0.962496
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(2.7158e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.527316
Average KL loss: 0.432936
Average total loss: 0.960252
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(2.4877e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.525582
Average KL loss: 0.432929
Average total loss: 0.958511
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(7.3121e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.524434
Average KL loss: 0.432923
Average total loss: 0.957357
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-8.5580e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.526851
Average KL loss: 0.432917
Average total loss: 0.959768
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(1.1655e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.524165
Average KL loss: 0.432910
Average total loss: 0.957075
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-4.5062e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.523777
Average KL loss: 0.432903
Average total loss: 0.956679
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.3321e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.530228
Average KL loss: 0.432898
Average total loss: 0.963126
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(1.3975e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.527350
Average KL loss: 0.432893
Average total loss: 0.960243
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-2.9975e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.526964
Average KL loss: 0.432887
Average total loss: 0.959851
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(1.8216e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.525782
Average KL loss: 0.432881
Average total loss: 0.958664
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(4.3391e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.531171
Average KL loss: 0.432874
Average total loss: 0.964045
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(1.7447e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.524899
Average KL loss: 0.432868
Average total loss: 0.957767
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(3.6325e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.531553
Average KL loss: 0.432862
Average total loss: 0.964415
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(2.5440e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.535840
Average KL loss: 0.432856
Average total loss: 0.968696
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(1.9862e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.529065
Average KL loss: 0.432851
Average total loss: 0.961916
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-7.8930e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.527629
Average KL loss: 0.432846
Average total loss: 0.960474
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(7.2941e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.524418
Average KL loss: 0.432840
Average total loss: 0.957258
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(2.5532e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.525868
Average KL loss: 0.432837
Average total loss: 0.958705
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-5.3845e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.526605
Average KL loss: 0.432836
Average total loss: 0.959441
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-5.4994e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.525711
Average KL loss: 0.432836
Average total loss: 0.958546
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-6.6126e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.530046
Average KL loss: 0.432835
Average total loss: 0.962881
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-3.1581e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.527780
Average KL loss: 0.432835
Average total loss: 0.960615
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.0032e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.526639
Average KL loss: 0.432834
Average total loss: 0.959473
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.2041e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.532197
Average KL loss: 0.432834
Average total loss: 0.965031
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(1.2137e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.535044
Average KL loss: 0.432833
Average total loss: 0.967877
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-4.2840e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.525065
Average KL loss: 0.432833
Average total loss: 0.957898
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-2.6383e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.529081
Average KL loss: 0.432832
Average total loss: 0.961913
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.9089e-09, device='cuda:0')
 Percentile value: 2.670258045196533
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =      61 /    1728             (  3.53%) | total_pruned =    1667 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      42 /   36864             (  0.11%) | total_pruned =   36822 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      63 /   36864             (  0.17%) | total_pruned =   36801 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      56 /   36864             (  0.15%) | total_pruned =   36808 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      85 /   36864             (  0.23%) | total_pruned =   36779 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     305 /   73728             (  0.41%) | total_pruned =   73423 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     571 /  147456             (  0.39%) | total_pruned =  146885 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      57 /    8192             (  0.70%) | total_pruned =    8135 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     501 /  147456             (  0.34%) | total_pruned =  146955 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     487 /  147456             (  0.33%) | total_pruned =  146969 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1300 /  294912             (  0.44%) | total_pruned =  293612 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1647 /  589824             (  0.28%) | total_pruned =  588177 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     120 /   32768             (  0.37%) | total_pruned =   32648 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     970 /  589824             (  0.16%) | total_pruned =  588854 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     638 /  589824             (  0.11%) | total_pruned =  589186 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     951 / 1179648             (  0.08%) | total_pruned = 1178697 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     171 /     512             ( 33.40%) | total_pruned =     341 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     852 / 2359296             (  0.04%) | total_pruned = 2358444 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      80 /     512             ( 15.62%) | total_pruned =     432 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      12 /  131072             (  0.01%) | total_pruned =  131060 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     406 / 2359296             (  0.02%) | total_pruned = 2358890 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      50 /     512             (  9.77%) | total_pruned =     462 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     360 / 2359296             (  0.02%) | total_pruned = 2358936 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
linear.weight        | nonzeros =     134 /    5120             (  2.62%) | total_pruned =    4986 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.838494 Accuracy: 70.75 78.47 % Best test Accuracy: 71.48%
tensor(0.0036, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.4286e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.168398
Average KL loss: 0.365019
Average total loss: 1.533417
tensor(-0.0012, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.1850e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.342519
Average KL loss: 0.252319
Average total loss: 1.594838
tensor(0.0012, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.4017e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.170577
Average KL loss: 0.245973
Average total loss: 1.416550
tensor(0.0014, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.3972e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.093888
Average KL loss: 0.246669
Average total loss: 1.340557
tensor(0.0014, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.3051e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.043949
Average KL loss: 0.248211
Average total loss: 1.292160
tensor(0.0014, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.3938e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.996210
Average KL loss: 0.250348
Average total loss: 1.246557
tensor(0.0014, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.2055e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.972764
Average KL loss: 0.252379
Average total loss: 1.225143
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.4053e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.955173
Average KL loss: 0.254194
Average total loss: 1.209367
tensor(0.0015, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-8.3750e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.948815
Average KL loss: 0.256047
Average total loss: 1.204862
tensor(0.0015, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.2090e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.928347
Average KL loss: 0.257823
Average total loss: 1.186169
tensor(0.0015, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.0653e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.917663
Average KL loss: 0.260027
Average total loss: 1.177690
tensor(0.0016, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-7.5168e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.895684
Average KL loss: 0.262200
Average total loss: 1.157884
tensor(0.0016, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.1894e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.880190
Average KL loss: 0.263979
Average total loss: 1.144168
tensor(0.0016, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1426e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.880413
Average KL loss: 0.264827
Average total loss: 1.145240
tensor(0.0016, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.2342e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.875667
Average KL loss: 0.265485
Average total loss: 1.141152
tensor(0.0017, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.7550e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.853404
Average KL loss: 0.268932
Average total loss: 1.122336
tensor(-0.0070, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.1804e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.842578
Average KL loss: 0.270791
Average total loss: 1.113370
tensor(0.0025, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.4575e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.866095
Average KL loss: 0.271702
Average total loss: 1.137798
tensor(0.0017, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.4650e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.839905
Average KL loss: 0.274022
Average total loss: 1.113927
tensor(0.0018, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.8971e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.842359
Average KL loss: 0.275085
Average total loss: 1.117444
tensor(0.0017, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-3.6706e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.827199
Average KL loss: 0.279011
Average total loss: 1.106210
tensor(0.0033, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(3.3699e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.839422
Average KL loss: 0.277394
Average total loss: 1.116816
tensor(0.0019, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.5164e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.832089
Average KL loss: 0.279070
Average total loss: 1.111160
tensor(0.0018, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.6234e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.819020
Average KL loss: 0.279871
Average total loss: 1.098891
tensor(0.0019, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.4361e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.811881
Average KL loss: 0.283933
Average total loss: 1.095814
tensor(-0.0033, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.3015e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.808417
Average KL loss: 0.283274
Average total loss: 1.091691
tensor(0.0023, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(5.1770e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.802579
Average KL loss: 0.284719
Average total loss: 1.087299
tensor(0.0019, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.9106e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.801765
Average KL loss: 0.285985
Average total loss: 1.087750
tensor(0.0020, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.8939e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.797376
Average KL loss: 0.287667
Average total loss: 1.085044
tensor(0.0005, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-4.2423e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.807183
Average KL loss: 0.293456
Average total loss: 1.100639
tensor(0.0022, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(1.8267e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.784114
Average KL loss: 0.290317
Average total loss: 1.074431
tensor(0.0021, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(7.0471e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.792125
Average KL loss: 0.291443
Average total loss: 1.083568
tensor(0.0020, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.4514e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.795439
Average KL loss: 0.291992
Average total loss: 1.087431
tensor(0.0021, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.6744e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.785449
Average KL loss: 0.293432
Average total loss: 1.078881
tensor(0.0021, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.9459e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.786225
Average KL loss: 0.297352
Average total loss: 1.083577
tensor(-0.0018, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-9.6919e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.781380
Average KL loss: 0.297241
Average total loss: 1.078622
tensor(0.0026, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.1290e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.783338
Average KL loss: 0.297844
Average total loss: 1.081182
tensor(0.0021, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.9499e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.774050
Average KL loss: 0.298126
Average total loss: 1.072175
tensor(0.0022, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.6879e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.771429
Average KL loss: 0.298850
Average total loss: 1.070280
tensor(0.0016, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.5112e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.768517
Average KL loss: 0.303229
Average total loss: 1.071746
tensor(0.0016, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.1103e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.767664
Average KL loss: 0.300988
Average total loss: 1.068653
tensor(0.0024, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(4.5363e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.774713
Average KL loss: 0.302740
Average total loss: 1.077453
tensor(0.0022, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.4532e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.772418
Average KL loss: 0.303595
Average total loss: 1.076013
tensor(0.0022, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.0111e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.775955
Average KL loss: 0.305737
Average total loss: 1.081691
tensor(0.0120, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(2.4292e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.770870
Average KL loss: 0.309520
Average total loss: 1.080389
tensor(0.0032, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.2309e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.770825
Average KL loss: 0.308367
Average total loss: 1.079191
tensor(0.0023, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.2969e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.758652
Average KL loss: 0.308678
Average total loss: 1.067330
tensor(0.0023, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-7.3357e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.760369
Average KL loss: 0.309079
Average total loss: 1.069448
tensor(0.0029, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.6084e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.751976
Average KL loss: 0.313304
Average total loss: 1.065281
tensor(0.0026, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(7.1328e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.749304
Average KL loss: 0.311551
Average total loss: 1.060855
tensor(0.0022, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.9444e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.752669
Average KL loss: 0.312425
Average total loss: 1.065093
tensor(0.0024, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4989e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.754544
Average KL loss: 0.312879
Average total loss: 1.067423
tensor(0.0023, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.8598e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.749107
Average KL loss: 0.316721
Average total loss: 1.065829
tensor(0.0050, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(6.5471e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.750179
Average KL loss: 0.313943
Average total loss: 1.064122
tensor(0.0026, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(1.2833e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.749013
Average KL loss: 0.315238
Average total loss: 1.064251
tensor(0.0024, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.8308e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.748844
Average KL loss: 0.316115
Average total loss: 1.064959
tensor(0.0024, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-8.6564e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.744127
Average KL loss: 0.317111
Average total loss: 1.061238
tensor(0.0086, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(1.5191e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.740104
Average KL loss: 0.320633
Average total loss: 1.060737
tensor(0.0016, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-2.4194e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.753767
Average KL loss: 0.318025
Average total loss: 1.071793
tensor(0.0026, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(1.4585e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.750262
Average KL loss: 0.317558
Average total loss: 1.067819
tensor(0.0025, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-2.3045e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.744639
Average KL loss: 0.317981
Average total loss: 1.062621
tensor(0.0034, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(1.9881e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.738409
Average KL loss: 0.322477
Average total loss: 1.060885
tensor(0.0034, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(1.8783e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.740468
Average KL loss: 0.319833
Average total loss: 1.060301
tensor(0.0026, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(2.8742e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.743156
Average KL loss: 0.321266
Average total loss: 1.064422
tensor(0.0026, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-1.8403e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.732113
Average KL loss: 0.322511
Average total loss: 1.054624
tensor(0.0026, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(2.0891e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.735348
Average KL loss: 0.326224
Average total loss: 1.061572
tensor(-0.0045, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.7973e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.736082
Average KL loss: 0.324968
Average total loss: 1.061050
tensor(0.0023, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-7.4818e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.731506
Average KL loss: 0.323910
Average total loss: 1.055416
tensor(0.0026, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(2.6297e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.733501
Average KL loss: 0.324070
Average total loss: 1.057571
tensor(0.0026, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-2.5646e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.728698
Average KL loss: 0.324454
Average total loss: 1.053152
tensor(0.0034, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(1.8575e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.731319
Average KL loss: 0.328335
Average total loss: 1.059654
tensor(0.0044, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(4.2986e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.730200
Average KL loss: 0.325947
Average total loss: 1.056147
tensor(0.0027, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-3.6281e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.733813
Average KL loss: 0.326281
Average total loss: 1.060094
tensor(0.0027, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-9.9754e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.734382
Average KL loss: 0.327104
Average total loss: 1.061486
tensor(0.0027, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-5.2369e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.724538
Average KL loss: 0.331463
Average total loss: 1.056001
tensor(0.0032, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(1.3664e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.726442
Average KL loss: 0.330364
Average total loss: 1.056806
tensor(0.0035, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(1.4168e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.725633
Average KL loss: 0.328894
Average total loss: 1.054526
tensor(0.0027, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-1.5346e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.730339
Average KL loss: 0.329184
Average total loss: 1.059523
tensor(0.0027, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(2.5775e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.724566
Average KL loss: 0.330275
Average total loss: 1.054841
tensor(0.0027, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(1.5824e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.725552
Average KL loss: 0.330511
Average total loss: 1.056064
tensor(0.0018, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.4056e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.724740
Average KL loss: 0.333717
Average total loss: 1.058457
tensor(0.0015, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-3.1926e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.732678
Average KL loss: 0.330601
Average total loss: 1.063279
tensor(0.0027, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-2.7208e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.722558
Average KL loss: 0.329641
Average total loss: 1.052200
tensor(0.0028, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(3.5420e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.721215
Average KL loss: 0.328864
Average total loss: 1.050078
tensor(0.0028, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-3.6636e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.721407
Average KL loss: 0.328158
Average total loss: 1.049566
tensor(0.0028, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-2.4842e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.717320
Average KL loss: 0.327512
Average total loss: 1.044832
tensor(0.0028, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(2.6107e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.719599
Average KL loss: 0.326987
Average total loss: 1.046586
tensor(0.0028, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.4237e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.719374
Average KL loss: 0.326488
Average total loss: 1.045862
tensor(0.0028, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(9.2150e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.718452
Average KL loss: 0.326014
Average total loss: 1.044466
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(2.2658e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.718591
Average KL loss: 0.325616
Average total loss: 1.044208
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.3606e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.715583
Average KL loss: 0.325266
Average total loss: 1.040849
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(2.3333e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.716679
Average KL loss: 0.325035
Average total loss: 1.041714
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-7.7036e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.715064
Average KL loss: 0.324741
Average total loss: 1.039805
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-8.5529e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.715949
Average KL loss: 0.324513
Average total loss: 1.040461
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.0471e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.717889
Average KL loss: 0.324278
Average total loss: 1.042167
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.2528e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.715674
Average KL loss: 0.324081
Average total loss: 1.039755
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-5.4399e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.718604
Average KL loss: 0.323805
Average total loss: 1.042409
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-6.3903e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.714653
Average KL loss: 0.323641
Average total loss: 1.038294
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-9.5060e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.720006
Average KL loss: 0.323457
Average total loss: 1.043463
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(2.5838e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.713947
Average KL loss: 0.323260
Average total loss: 1.037208
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-6.5823e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.715112
Average KL loss: 0.322963
Average total loss: 1.038075
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.1087e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.716076
Average KL loss: 0.322806
Average total loss: 1.038881
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.2079e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.720504
Average KL loss: 0.322626
Average total loss: 1.043130
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.2086e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.716812
Average KL loss: 0.322372
Average total loss: 1.039184
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(4.2863e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.713170
Average KL loss: 0.322166
Average total loss: 1.035336
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(2.9243e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.716569
Average KL loss: 0.321933
Average total loss: 1.038502
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.1455e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.713594
Average KL loss: 0.321709
Average total loss: 1.035303
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.6363e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.716072
Average KL loss: 0.321574
Average total loss: 1.037646
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.2810e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.717489
Average KL loss: 0.321438
Average total loss: 1.038927
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.8142e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.715755
Average KL loss: 0.321281
Average total loss: 1.037036
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(2.1665e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.714707
Average KL loss: 0.321144
Average total loss: 1.035851
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-5.4664e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.714834
Average KL loss: 0.321079
Average total loss: 1.035912
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.2519e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.717452
Average KL loss: 0.320937
Average total loss: 1.038389
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.5023e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.714815
Average KL loss: 0.320735
Average total loss: 1.035550
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.7610e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.717466
Average KL loss: 0.320396
Average total loss: 1.037862
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-7.5169e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.714688
Average KL loss: 0.320145
Average total loss: 1.034833
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.7463e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.717468
Average KL loss: 0.320033
Average total loss: 1.037501
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(2.4054e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.709739
Average KL loss: 0.319871
Average total loss: 1.029610
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.9278e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.716785
Average KL loss: 0.319687
Average total loss: 1.036472
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.0417e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.716449
Average KL loss: 0.319553
Average total loss: 1.036002
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-8.8694e-11, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.717101
Average KL loss: 0.319428
Average total loss: 1.036529
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.1981e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.715708
Average KL loss: 0.319409
Average total loss: 1.035116
tensor(0.0028, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-6.7905e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.717500
Average KL loss: 0.319348
Average total loss: 1.036848
tensor(0.0028, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(9.5791e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.714523
Average KL loss: 0.319231
Average total loss: 1.033754
tensor(0.0028, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.2033e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.716534
Average KL loss: 0.319122
Average total loss: 1.035655
tensor(0.0028, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.3292e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.714578
Average KL loss: 0.319031
Average total loss: 1.033610
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.2116e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.717479
Average KL loss: 0.318932
Average total loss: 1.036411
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.8495e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.717530
Average KL loss: 0.318794
Average total loss: 1.036324
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.4043e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.715063
Average KL loss: 0.318693
Average total loss: 1.033756
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.9700e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.718519
Average KL loss: 0.318685
Average total loss: 1.037203
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.8207e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.716365
Average KL loss: 0.318666
Average total loss: 1.035031
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-4.3205e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.717241
Average KL loss: 0.318648
Average total loss: 1.035888
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.6272e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.722382
Average KL loss: 0.318621
Average total loss: 1.041003
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.0167e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.716328
Average KL loss: 0.318591
Average total loss: 1.034919
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(4.0785e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.712992
Average KL loss: 0.318564
Average total loss: 1.031556
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(9.7066e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.714982
Average KL loss: 0.318537
Average total loss: 1.033519
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.2353e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.717707
Average KL loss: 0.318516
Average total loss: 1.036223
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.6267e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.721813
Average KL loss: 0.318506
Average total loss: 1.040319
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.4196e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.716722
Average KL loss: 0.318490
Average total loss: 1.035213
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.7195e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.714098
Average KL loss: 0.318477
Average total loss: 1.032574
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-8.3510e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.714157
Average KL loss: 0.318470
Average total loss: 1.032626
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.0409e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.716850
Average KL loss: 0.318467
Average total loss: 1.035317
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.4757e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.716752
Average KL loss: 0.318464
Average total loss: 1.035216
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(3.3086e-11, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.717385
Average KL loss: 0.318462
Average total loss: 1.035846
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(2.0122e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.716529
Average KL loss: 0.318460
Average total loss: 1.034989
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(5.9711e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.712178
Average KL loss: 0.318458
Average total loss: 1.030637
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(2.9333e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.715531
Average KL loss: 0.318456
Average total loss: 1.033986
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-7.7394e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.717986
Average KL loss: 0.318453
Average total loss: 1.036440
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(3.7680e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.713103
Average KL loss: 0.318452
Average total loss: 1.031555
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.1649e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.718290
Average KL loss: 0.318450
Average total loss: 1.036740
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.6108e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.715267
Average KL loss: 0.318447
Average total loss: 1.033714
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.4783e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.717979
Average KL loss: 0.318446
Average total loss: 1.036424
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-8.6364e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.716189
Average KL loss: 0.318445
Average total loss: 1.034635
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.0956e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.715404
Average KL loss: 0.318445
Average total loss: 1.033849
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(7.5132e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.716289
Average KL loss: 0.318445
Average total loss: 1.034734
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.0526e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.716386
Average KL loss: 0.318445
Average total loss: 1.034830
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-3.4166e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.716578
Average KL loss: 0.318444
Average total loss: 1.035022
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(5.1256e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.717427
Average KL loss: 0.318444
Average total loss: 1.035871
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.0087e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.726240
Average KL loss: 0.318444
Average total loss: 1.044684
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.9794e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.723672
Average KL loss: 0.318444
Average total loss: 1.042115
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-7.2289e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.720217
Average KL loss: 0.318443
Average total loss: 1.038661
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.8709e-09, device='cuda:0')
 Percentile value: 5.836738109588623
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =      52 /    1728             (  3.01%) | total_pruned =    1676 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      33 /   36864             (  0.09%) | total_pruned =   36831 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      49 /   36864             (  0.13%) | total_pruned =   36815 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      38 /   36864             (  0.10%) | total_pruned =   36826 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      44 /   36864             (  0.12%) | total_pruned =   36820 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     176 /   73728             (  0.24%) | total_pruned =   73552 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     316 /  147456             (  0.21%) | total_pruned =  147140 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      32 /    8192             (  0.39%) | total_pruned =    8160 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     279 /  147456             (  0.19%) | total_pruned =  147177 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     263 /  147456             (  0.18%) | total_pruned =  147193 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     639 /  294912             (  0.22%) | total_pruned =  294273 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     138 /     256             ( 53.91%) | total_pruned =     118 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     777 /  589824             (  0.13%) | total_pruned =  589047 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      43 /   32768             (  0.13%) | total_pruned =   32725 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     433 /  589824             (  0.07%) | total_pruned =  589391 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     301 /  589824             (  0.05%) | total_pruned =  589523 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     346 / 1179648             (  0.03%) | total_pruned = 1179302 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      98 /     512             ( 19.14%) | total_pruned =     414 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     298 / 2359296             (  0.01%) | total_pruned = 2358998 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      56 /     512             ( 10.94%) | total_pruned =     456 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       6 /  131072             (  0.00%) | total_pruned =  131066 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     171 / 2359296             (  0.01%) | total_pruned = 2359125 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      31 /     512             (  6.05%) | total_pruned =     481 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     126 / 2359296             (  0.01%) | total_pruned = 2359170 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
linear.weight        | nonzeros =      80 /    5120             (  1.56%) | total_pruned =    5040 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 0.870911 Accuracy: 66.66 71.52 % Best test Accuracy: 66.89%
