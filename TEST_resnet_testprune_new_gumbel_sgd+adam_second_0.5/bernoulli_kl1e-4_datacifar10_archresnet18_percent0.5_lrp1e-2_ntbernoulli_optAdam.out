Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.807059
Average KL loss: 0.099185
Average total loss: 1.906244
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1158e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.536392
Average KL loss: 0.187266
Average total loss: 1.723659
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.5550e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.335482
Average KL loss: 0.203975
Average total loss: 1.539457
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.5427e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.212567
Average KL loss: 0.202521
Average total loss: 1.415087
tensor(0.0006, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.1285e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.129356
Average KL loss: 0.200126
Average total loss: 1.329483
tensor(0.0007, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-8.2994e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.053372
Average KL loss: 0.193159
Average total loss: 1.246531
tensor(0.0007, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-9.0651e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.990716
Average KL loss: 0.189515
Average total loss: 1.180231
tensor(0.0008, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-1.0346e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.936735
Average KL loss: 0.190883
Average total loss: 1.127618
tensor(0.0008, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-8.4514e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.867394
Average KL loss: 0.186818
Average total loss: 1.054212
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.5210e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.837765
Average KL loss: 0.183669
Average total loss: 1.021434
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.3236e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.803425
Average KL loss: 0.180601
Average total loss: 0.984025
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.5203e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.762233
Average KL loss: 0.181105
Average total loss: 0.943337
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.8003e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.725372
Average KL loss: 0.180500
Average total loss: 0.905872
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.2455e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.705688
Average KL loss: 0.179686
Average total loss: 0.885374
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.0426e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.676358
Average KL loss: 0.178742
Average total loss: 0.855100
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.2488e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.640558
Average KL loss: 0.178544
Average total loss: 0.819103
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.3782e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.606625
Average KL loss: 0.174541
Average total loss: 0.781166
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.9983e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.600385
Average KL loss: 0.175483
Average total loss: 0.775868
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0676e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.577382
Average KL loss: 0.176672
Average total loss: 0.754053
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.7464e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.558715
Average KL loss: 0.178658
Average total loss: 0.737373
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.1693e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.541920
Average KL loss: 0.177504
Average total loss: 0.719423
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0752e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.518534
Average KL loss: 0.178593
Average total loss: 0.697127
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.5057e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.506354
Average KL loss: 0.177409
Average total loss: 0.683763
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.3033e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.494398
Average KL loss: 0.179375
Average total loss: 0.673773
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.1493e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.476142
Average KL loss: 0.179700
Average total loss: 0.655842
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.1391e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.455866
Average KL loss: 0.178950
Average total loss: 0.634816
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.3682e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.450275
Average KL loss: 0.180364
Average total loss: 0.630638
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.0559e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.438472
Average KL loss: 0.181340
Average total loss: 0.619812
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.1282e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.428657
Average KL loss: 0.183476
Average total loss: 0.612133
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.1405e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.412652
Average KL loss: 0.184110
Average total loss: 0.596762
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.3505e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.411501
Average KL loss: 0.183051
Average total loss: 0.594552
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.9416e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.396269
Average KL loss: 0.185423
Average total loss: 0.581692
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.9326e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.382219
Average KL loss: 0.184027
Average total loss: 0.566246
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.2416e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.380810
Average KL loss: 0.185709
Average total loss: 0.566519
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.2523e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.380224
Average KL loss: 0.187513
Average total loss: 0.567737
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.7453e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.364830
Average KL loss: 0.188788
Average total loss: 0.553617
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.4571e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.365615
Average KL loss: 0.192358
Average total loss: 0.557973
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.9617e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.352055
Average KL loss: 0.192461
Average total loss: 0.544516
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.2759e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.349910
Average KL loss: 0.194233
Average total loss: 0.544143
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.6210e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.332771
Average KL loss: 0.191596
Average total loss: 0.524367
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.2670e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.322691
Average KL loss: 0.190435
Average total loss: 0.513126
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.0044e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.316701
Average KL loss: 0.192265
Average total loss: 0.508967
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.1508e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.309037
Average KL loss: 0.191794
Average total loss: 0.500831
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.1331e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.320648
Average KL loss: 0.195304
Average total loss: 0.515952
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.6913e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.307518
Average KL loss: 0.197531
Average total loss: 0.505049
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.8348e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.297495
Average KL loss: 0.195246
Average total loss: 0.492741
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.9455e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.307040
Average KL loss: 0.197189
Average total loss: 0.504229
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.2557e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.292938
Average KL loss: 0.200869
Average total loss: 0.493807
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.5634e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.277423
Average KL loss: 0.199692
Average total loss: 0.477115
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.6869e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.284466
Average KL loss: 0.200903
Average total loss: 0.485369
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.2269e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.276868
Average KL loss: 0.201698
Average total loss: 0.478566
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.1950e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.269127
Average KL loss: 0.203121
Average total loss: 0.472248
tensor(0.0015, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.7374e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.268780
Average KL loss: 0.202764
Average total loss: 0.471545
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.6602e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.266839
Average KL loss: 0.203028
Average total loss: 0.469867
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-7.5060e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.262231
Average KL loss: 0.203778
Average total loss: 0.466009
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.3536e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.258842
Average KL loss: 0.204688
Average total loss: 0.463530
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.5026e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.253502
Average KL loss: 0.205340
Average total loss: 0.458842
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.9029e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.255296
Average KL loss: 0.208157
Average total loss: 0.463453
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.4473e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.247212
Average KL loss: 0.207342
Average total loss: 0.454555
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.4583e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.240889
Average KL loss: 0.208367
Average total loss: 0.449256
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.1806e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.237087
Average KL loss: 0.207449
Average total loss: 0.444536
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.7222e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.236286
Average KL loss: 0.207388
Average total loss: 0.443674
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.0600e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.240660
Average KL loss: 0.211750
Average total loss: 0.452409
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2634e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.232147
Average KL loss: 0.210598
Average total loss: 0.442745
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.0407e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.224523
Average KL loss: 0.209690
Average total loss: 0.434213
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-8.1484e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.235560
Average KL loss: 0.211457
Average total loss: 0.447017
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.2632e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.217586
Average KL loss: 0.212457
Average total loss: 0.430043
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2295e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.225713
Average KL loss: 0.213914
Average total loss: 0.439627
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.6760e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.229061
Average KL loss: 0.213877
Average total loss: 0.442938
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.1710e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.219295
Average KL loss: 0.215570
Average total loss: 0.434865
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.7053e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.221248
Average KL loss: 0.215788
Average total loss: 0.437036
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.6463e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.217305
Average KL loss: 0.216244
Average total loss: 0.433549
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.4341e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.210955
Average KL loss: 0.215536
Average total loss: 0.426492
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-7.9265e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.216271
Average KL loss: 0.218344
Average total loss: 0.434615
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(3.7528e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.202925
Average KL loss: 0.216895
Average total loss: 0.419820
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.0934e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.212403
Average KL loss: 0.218813
Average total loss: 0.431216
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.0850e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.210299
Average KL loss: 0.220755
Average total loss: 0.431053
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.6704e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.205627
Average KL loss: 0.219302
Average total loss: 0.424929
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.9027e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.202450
Average KL loss: 0.221513
Average total loss: 0.423963
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.3602e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.198652
Average KL loss: 0.219973
Average total loss: 0.418625
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-8.6931e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.195221
Average KL loss: 0.219281
Average total loss: 0.414501
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.8131e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.198325
Average KL loss: 0.219646
Average total loss: 0.417971
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-6.4182e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.192492
Average KL loss: 0.219272
Average total loss: 0.411764
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-5.9062e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.196327
Average KL loss: 0.220652
Average total loss: 0.416979
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.3770e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.190611
Average KL loss: 0.222206
Average total loss: 0.412817
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-8.9424e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.197929
Average KL loss: 0.223260
Average total loss: 0.421189
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.7825e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.188567
Average KL loss: 0.222689
Average total loss: 0.411255
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.3350e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.185629
Average KL loss: 0.222791
Average total loss: 0.408420
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.6804e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.183710
Average KL loss: 0.221060
Average total loss: 0.404769
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-9.8454e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.188986
Average KL loss: 0.224582
Average total loss: 0.413568
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1714e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.187043
Average KL loss: 0.224000
Average total loss: 0.411043
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.0405e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.183116
Average KL loss: 0.225752
Average total loss: 0.408868
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(3.6225e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.187383
Average KL loss: 0.225236
Average total loss: 0.412619
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-5.0871e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.176161
Average KL loss: 0.225162
Average total loss: 0.401323
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(4.1458e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.185668
Average KL loss: 0.226110
Average total loss: 0.411777
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1823e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.175576
Average KL loss: 0.227127
Average total loss: 0.402703
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-9.4672e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.176807
Average KL loss: 0.224252
Average total loss: 0.401058
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.5301e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.179821
Average KL loss: 0.227517
Average total loss: 0.407337
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.0387e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.171994
Average KL loss: 0.226376
Average total loss: 0.398370
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.1696e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.182151
Average KL loss: 0.227728
Average total loss: 0.409879
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.7677e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.168456
Average KL loss: 0.227924
Average total loss: 0.396380
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.8047e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.175817
Average KL loss: 0.225758
Average total loss: 0.401575
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.4577e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.171529
Average KL loss: 0.230236
Average total loss: 0.401765
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.2269e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.169237
Average KL loss: 0.227331
Average total loss: 0.396568
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.3344e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.169595
Average KL loss: 0.227030
Average total loss: 0.396625
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.8767e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.164188
Average KL loss: 0.227564
Average total loss: 0.391752
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.0248e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.168932
Average KL loss: 0.228591
Average total loss: 0.397523
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.6000e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.165910
Average KL loss: 0.229551
Average total loss: 0.395460
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.3244e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.164127
Average KL loss: 0.226335
Average total loss: 0.390462
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.8939e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.167070
Average KL loss: 0.227716
Average total loss: 0.394786
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.0560e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.170337
Average KL loss: 0.230945
Average total loss: 0.401282
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-6.6526e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.161741
Average KL loss: 0.229987
Average total loss: 0.391728
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-9.2412e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.163254
Average KL loss: 0.229954
Average total loss: 0.393207
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(2.0527e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.163210
Average KL loss: 0.230847
Average total loss: 0.394057
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-7.3006e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.158021
Average KL loss: 0.229052
Average total loss: 0.387073
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(1.1930e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.166417
Average KL loss: 0.229697
Average total loss: 0.396114
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.5153e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.165748
Average KL loss: 0.233115
Average total loss: 0.398863
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-4.6513e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.165887
Average KL loss: 0.233430
Average total loss: 0.399317
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(3.2160e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.157928
Average KL loss: 0.231227
Average total loss: 0.389155
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(6.8215e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.154485
Average KL loss: 0.229284
Average total loss: 0.383769
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-7.6395e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.155625
Average KL loss: 0.229152
Average total loss: 0.384777
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(2.5944e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.158604
Average KL loss: 0.229032
Average total loss: 0.387637
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.1190e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.157715
Average KL loss: 0.232058
Average total loss: 0.389772
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.8133e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.157833
Average KL loss: 0.231639
Average total loss: 0.389472
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.3500e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.153189
Average KL loss: 0.230401
Average total loss: 0.383589
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.6304e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.159175
Average KL loss: 0.235594
Average total loss: 0.394768
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(5.4253e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.157668
Average KL loss: 0.233618
Average total loss: 0.391286
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-9.6045e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.159794
Average KL loss: 0.234932
Average total loss: 0.394727
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.0774e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.160614
Average KL loss: 0.234984
Average total loss: 0.395598
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.1610e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.154253
Average KL loss: 0.233846
Average total loss: 0.388099
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-8.6472e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.157686
Average KL loss: 0.235569
Average total loss: 0.393255
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-4.8835e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.154858
Average KL loss: 0.232819
Average total loss: 0.387678
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.5621e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.149807
Average KL loss: 0.234041
Average total loss: 0.383848
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(8.9533e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.152601
Average KL loss: 0.233083
Average total loss: 0.385684
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.0672e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.154026
Average KL loss: 0.234128
Average total loss: 0.388154
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-4.7850e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.159618
Average KL loss: 0.238231
Average total loss: 0.397849
tensor(0.0016, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.8592e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.142910
Average KL loss: 0.227620
Average total loss: 0.370530
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(9.2778e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.151309
Average KL loss: 0.212144
Average total loss: 0.363453
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(2.4408e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.147320
Average KL loss: 0.204227
Average total loss: 0.351547
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(7.5886e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.148397
Average KL loss: 0.198986
Average total loss: 0.347383
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(7.3057e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.150280
Average KL loss: 0.195374
Average total loss: 0.345654
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(6.1297e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.155224
Average KL loss: 0.192704
Average total loss: 0.347928
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.8799e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.145883
Average KL loss: 0.190539
Average total loss: 0.336422
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.5059e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.145148
Average KL loss: 0.188691
Average total loss: 0.333838
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-9.6645e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.153055
Average KL loss: 0.187313
Average total loss: 0.340368
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.2114e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.148332
Average KL loss: 0.186243
Average total loss: 0.334576
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.1194e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.148167
Average KL loss: 0.185169
Average total loss: 0.333336
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.5450e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.148688
Average KL loss: 0.184380
Average total loss: 0.333068
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.9628e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.149513
Average KL loss: 0.183687
Average total loss: 0.333199
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.5904e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.146320
Average KL loss: 0.182995
Average total loss: 0.329316
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3732e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.151292
Average KL loss: 0.182332
Average total loss: 0.333624
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.7288e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.149852
Average KL loss: 0.181943
Average total loss: 0.331795
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.0082e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.148049
Average KL loss: 0.181506
Average total loss: 0.329555
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.1388e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.150221
Average KL loss: 0.181241
Average total loss: 0.331462
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.4935e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.149710
Average KL loss: 0.180978
Average total loss: 0.330688
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.9497e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.145694
Average KL loss: 0.180661
Average total loss: 0.326354
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.2410e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.148091
Average KL loss: 0.180261
Average total loss: 0.328352
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(7.6919e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.143940
Average KL loss: 0.179923
Average total loss: 0.323863
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.4525e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.149216
Average KL loss: 0.179591
Average total loss: 0.328807
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1190e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.146853
Average KL loss: 0.179376
Average total loss: 0.326229
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.8073e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.146650
Average KL loss: 0.179159
Average total loss: 0.325809
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.4381e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.148533
Average KL loss: 0.179077
Average total loss: 0.327609
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(5.0903e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.150763
Average KL loss: 0.178985
Average total loss: 0.329748
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3397e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.144303
Average KL loss: 0.178709
Average total loss: 0.323012
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.6915e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.147804
Average KL loss: 0.178494
Average total loss: 0.326298
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.8366e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.147946
Average KL loss: 0.178427
Average total loss: 0.326374
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.1850e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.150105
Average KL loss: 0.178309
Average total loss: 0.328413
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.3981e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.149309
Average KL loss: 0.178257
Average total loss: 0.327566
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-6.0313e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.148691
Average KL loss: 0.178164
Average total loss: 0.326855
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.7121e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.150380
Average KL loss: 0.178037
Average total loss: 0.328417
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.7112e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.152333
Average KL loss: 0.178050
Average total loss: 0.330383
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.2672e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.151242
Average KL loss: 0.178058
Average total loss: 0.329300
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1964e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.153341
Average KL loss: 0.178049
Average total loss: 0.331390
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(5.8018e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.150486
Average KL loss: 0.177973
Average total loss: 0.328459
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(4.8043e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.148168
Average KL loss: 0.177822
Average total loss: 0.325990
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.1695e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.148577
Average KL loss: 0.177577
Average total loss: 0.326154
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5610e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.152439
Average KL loss: 0.177205
Average total loss: 0.329644
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.9239e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.148372
Average KL loss: 0.176907
Average total loss: 0.325279
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-6.5382e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.148874
Average KL loss: 0.176661
Average total loss: 0.325535
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.9526e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.144449
Average KL loss: 0.176428
Average total loss: 0.320877
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.8556e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.145889
Average KL loss: 0.176222
Average total loss: 0.322112
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1828e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.150094
Average KL loss: 0.176039
Average total loss: 0.326133
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.3502e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.145606
Average KL loss: 0.175870
Average total loss: 0.321477
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.0667e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.147988
Average KL loss: 0.175722
Average total loss: 0.323710
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.3835e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.148484
Average KL loss: 0.175585
Average total loss: 0.324070
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.8706e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.146919
Average KL loss: 0.175458
Average total loss: 0.322377
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5113e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.143155
Average KL loss: 0.175330
Average total loss: 0.318485
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.3377e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.144687
Average KL loss: 0.175210
Average total loss: 0.319897
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.6213e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.146123
Average KL loss: 0.175092
Average total loss: 0.321215
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3516e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.149649
Average KL loss: 0.174986
Average total loss: 0.324635
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(9.0040e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.142598
Average KL loss: 0.174888
Average total loss: 0.317485
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.1123e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.149470
Average KL loss: 0.174792
Average total loss: 0.324262
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.1113e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.144864
Average KL loss: 0.174701
Average total loss: 0.319565
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.3838e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.144288
Average KL loss: 0.174614
Average total loss: 0.318902
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.8579e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.151849
Average KL loss: 0.174537
Average total loss: 0.326386
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.7433e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.148325
Average KL loss: 0.174455
Average total loss: 0.322780
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(4.5472e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.147037
Average KL loss: 0.174380
Average total loss: 0.321418
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.7694e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.144989
Average KL loss: 0.174305
Average total loss: 0.319295
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.2202e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.150460
Average KL loss: 0.174233
Average total loss: 0.324694
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5892e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.143727
Average KL loss: 0.174164
Average total loss: 0.317891
 Percentile value: 0.0010590582387521863
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =    1305 /    1728             ( 75.52%) | total_pruned =     423 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   19724 /   36864             ( 53.50%) | total_pruned =   17140 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   20277 /   36864             ( 55.00%) | total_pruned =   16587 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   20191 /   36864             ( 54.77%) | total_pruned =   16673 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   19947 /   36864             ( 54.11%) | total_pruned =   16917 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   39960 /   73728             ( 54.20%) | total_pruned =   33768 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   78544 /  147456             ( 53.27%) | total_pruned =   68912 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5316 /    8192             ( 64.89%) | total_pruned =    2876 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   76626 /  147456             ( 51.97%) | total_pruned =   70830 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   76119 /  147456             ( 51.62%) | total_pruned =   71337 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  156021 /  294912             ( 52.90%) | total_pruned =  138891 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     237 /     256             ( 92.58%) | total_pruned =      19 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  308829 /  589824             ( 52.36%) | total_pruned =  280995 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19537 /   32768             ( 59.62%) | total_pruned =   13231 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  299073 /  589824             ( 50.71%) | total_pruned =  290751 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  294680 /  589824             ( 49.96%) | total_pruned =  295144 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  607291 / 1179648             ( 51.48%) | total_pruned =  572357 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1180114 / 2359296             ( 50.02%) | total_pruned = 1179182 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     402 /     512             ( 78.52%) | total_pruned =     110 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   70347 /  131072             ( 53.67%) | total_pruned =   60725 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     405 /     512             ( 79.10%) | total_pruned =     107 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1152368 / 2359296             ( 48.84%) | total_pruned = 1206928 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     405 /     512             ( 79.10%) | total_pruned =     107 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1130516 / 2359296             ( 47.92%) | total_pruned = 1228780 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     133 /     512             ( 25.98%) | total_pruned =     379 | shape = torch.Size([512])
linear.weight        | nonzeros =    4292 /    5120             ( 83.83%) | total_pruned =     828 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 36/100 Loss: 0.000182 Accuracy: 86.93 100.00 % Best test Accuracy: 86.95%
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.9376e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.287578
Average KL loss: 0.206940
Average total loss: 0.494518
tensor(0.0018, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.4128e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.270387
Average KL loss: 0.236278
Average total loss: 0.506664
tensor(0.0019, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.4047e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.266919
Average KL loss: 0.242548
Average total loss: 0.509468
tensor(0.0019, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.6062e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.248270
Average KL loss: 0.246693
Average total loss: 0.494963
tensor(0.0020, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.6634e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.236044
Average KL loss: 0.245953
Average total loss: 0.481997
tensor(0.0019, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.5667e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.243203
Average KL loss: 0.247228
Average total loss: 0.490432
tensor(0.0019, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.5462e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.232646
Average KL loss: 0.250561
Average total loss: 0.483207
tensor(0.0019, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-5.0518e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.228162
Average KL loss: 0.249397
Average total loss: 0.477559
tensor(0.0020, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-7.2768e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.235500
Average KL loss: 0.252209
Average total loss: 0.487709
tensor(0.0020, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.5323e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.231960
Average KL loss: 0.254246
Average total loss: 0.486206
tensor(0.0020, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-3.0880e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.219960
Average KL loss: 0.254569
Average total loss: 0.474529
tensor(0.0020, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-5.5610e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.226799
Average KL loss: 0.253410
Average total loss: 0.480209
tensor(0.0020, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(2.4837e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.221245
Average KL loss: 0.254690
Average total loss: 0.475935
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-5.8744e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.222172
Average KL loss: 0.256917
Average total loss: 0.479089
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(1.2844e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.223508
Average KL loss: 0.257313
Average total loss: 0.480821
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(1.4951e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.214091
Average KL loss: 0.257539
Average total loss: 0.471630
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.8757e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.219683
Average KL loss: 0.256969
Average total loss: 0.476652
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.8980e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.218298
Average KL loss: 0.259248
Average total loss: 0.477546
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.1736e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.214157
Average KL loss: 0.259991
Average total loss: 0.474148
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.7251e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.214881
Average KL loss: 0.259321
Average total loss: 0.474202
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.7156e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.206433
Average KL loss: 0.257328
Average total loss: 0.463761
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-8.0628e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.218416
Average KL loss: 0.260327
Average total loss: 0.478743
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(1.7687e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.204752
Average KL loss: 0.259951
Average total loss: 0.464703
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.1993e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.205976
Average KL loss: 0.258220
Average total loss: 0.464196
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(2.0161e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.209127
Average KL loss: 0.260419
Average total loss: 0.469546
tensor(0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.5566e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.200589
Average KL loss: 0.259697
Average total loss: 0.460287
tensor(0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0471e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.209083
Average KL loss: 0.261801
Average total loss: 0.470884
tensor(0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.5624e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.204094
Average KL loss: 0.261737
Average total loss: 0.465831
tensor(0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.7949e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.200152
Average KL loss: 0.261601
Average total loss: 0.461754
tensor(0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.8424e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.202720
Average KL loss: 0.260717
Average total loss: 0.463437
tensor(0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(7.4650e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.193587
Average KL loss: 0.260260
Average total loss: 0.453847
tensor(0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.9091e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.197390
Average KL loss: 0.260088
Average total loss: 0.457479
tensor(0.0019, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9599e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.204584
Average KL loss: 0.262802
Average total loss: 0.467386
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.8521e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.206103
Average KL loss: 0.265050
Average total loss: 0.471154
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.0989e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.200326
Average KL loss: 0.265285
Average total loss: 0.465611
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.0929e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.199263
Average KL loss: 0.265374
Average total loss: 0.464637
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.4789e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.197083
Average KL loss: 0.264589
Average total loss: 0.461673
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(7.0999e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.196944
Average KL loss: 0.264458
Average total loss: 0.461402
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(2.7144e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.191474
Average KL loss: 0.264674
Average total loss: 0.456148
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.6542e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.197968
Average KL loss: 0.264455
Average total loss: 0.462424
tensor(0.0020, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.7117e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.195433
Average KL loss: 0.265624
Average total loss: 0.461057
tensor(0.0020, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-8.4780e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.191496
Average KL loss: 0.265029
Average total loss: 0.456525
tensor(0.0020, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.2492e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.193859
Average KL loss: 0.259109
Average total loss: 0.452968
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.3404e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.194393
Average KL loss: 0.247574
Average total loss: 0.441967
tensor(0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.0395e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.188662
Average KL loss: 0.240175
Average total loss: 0.428837
tensor(0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.2487e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.194635
Average KL loss: 0.234844
Average total loss: 0.429479
tensor(0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.8459e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.196123
Average KL loss: 0.230889
Average total loss: 0.427013
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.6381e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.187344
Average KL loss: 0.227630
Average total loss: 0.414974
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.4229e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.184981
Average KL loss: 0.224953
Average total loss: 0.409935
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-5.7653e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.188433
Average KL loss: 0.222753
Average total loss: 0.411185
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.4585e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.189799
Average KL loss: 0.220883
Average total loss: 0.410682
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.2276e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.186399
Average KL loss: 0.219272
Average total loss: 0.405671
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-6.7319e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.192529
Average KL loss: 0.217845
Average total loss: 0.410374
tensor(0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(6.2980e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.189622
Average KL loss: 0.216635
Average total loss: 0.406258
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(9.5233e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.188801
Average KL loss: 0.215629
Average total loss: 0.404430
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(6.8907e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.184745
Average KL loss: 0.214697
Average total loss: 0.399442
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-6.9200e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.187665
Average KL loss: 0.213860
Average total loss: 0.401525
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.5895e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.190872
Average KL loss: 0.213166
Average total loss: 0.404038
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.1146e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.191419
Average KL loss: 0.212415
Average total loss: 0.403834
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-5.9052e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.188856
Average KL loss: 0.211845
Average total loss: 0.400701
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-5.6998e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.195974
Average KL loss: 0.211357
Average total loss: 0.407331
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.1717e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.184419
Average KL loss: 0.210858
Average total loss: 0.395278
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.0470e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.185610
Average KL loss: 0.210331
Average total loss: 0.395940
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(7.5819e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.193734
Average KL loss: 0.209874
Average total loss: 0.403608
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-6.8540e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.188139
Average KL loss: 0.209514
Average total loss: 0.397654
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.4710e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.184845
Average KL loss: 0.209173
Average total loss: 0.394018
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.3070e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.192543
Average KL loss: 0.208813
Average total loss: 0.401357
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.0503e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.188764
Average KL loss: 0.208594
Average total loss: 0.397358
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(3.0610e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.190838
Average KL loss: 0.208326
Average total loss: 0.399164
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.3956e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.186561
Average KL loss: 0.208113
Average total loss: 0.394673
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(7.6706e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.193135
Average KL loss: 0.207873
Average total loss: 0.401008
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(1.4127e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.188561
Average KL loss: 0.207665
Average total loss: 0.396226
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-7.3166e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.190028
Average KL loss: 0.207458
Average total loss: 0.397486
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.9336e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.187917
Average KL loss: 0.207248
Average total loss: 0.395164
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(9.4142e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.189406
Average KL loss: 0.207213
Average total loss: 0.396618
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.6380e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.182861
Average KL loss: 0.206997
Average total loss: 0.389858
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-5.4535e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.188084
Average KL loss: 0.206759
Average total loss: 0.394843
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.6400e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.188390
Average KL loss: 0.206550
Average total loss: 0.394940
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(4.3571e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.187670
Average KL loss: 0.206431
Average total loss: 0.394101
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.2723e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.187835
Average KL loss: 0.206369
Average total loss: 0.394204
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.5998e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.186749
Average KL loss: 0.206217
Average total loss: 0.392965
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.6986e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.194278
Average KL loss: 0.206127
Average total loss: 0.400404
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.5635e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.185336
Average KL loss: 0.206016
Average total loss: 0.391352
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.0096e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.187514
Average KL loss: 0.205817
Average total loss: 0.393331
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.1534e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.192587
Average KL loss: 0.205671
Average total loss: 0.398259
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.0796e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.188082
Average KL loss: 0.205554
Average total loss: 0.393636
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(5.4730e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.189617
Average KL loss: 0.205510
Average total loss: 0.395128
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(2.0727e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.187770
Average KL loss: 0.205404
Average total loss: 0.393175
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.7383e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.189133
Average KL loss: 0.205179
Average total loss: 0.394312
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(1.9272e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.191593
Average KL loss: 0.204975
Average total loss: 0.396568
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.5224e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.189155
Average KL loss: 0.204795
Average total loss: 0.393950
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(2.1843e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.191107
Average KL loss: 0.204630
Average total loss: 0.395737
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.3147e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.189162
Average KL loss: 0.204473
Average total loss: 0.393636
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(2.0642e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.186609
Average KL loss: 0.204329
Average total loss: 0.390938
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(2.3083e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.190175
Average KL loss: 0.204192
Average total loss: 0.394367
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.1196e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.188184
Average KL loss: 0.204072
Average total loss: 0.392256
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(8.1918e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.185528
Average KL loss: 0.203956
Average total loss: 0.389485
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.8317e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.188000
Average KL loss: 0.203842
Average total loss: 0.391841
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(1.3387e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.191530
Average KL loss: 0.203728
Average total loss: 0.395258
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-6.4288e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.191059
Average KL loss: 0.203625
Average total loss: 0.394684
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(1.0085e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.187512
Average KL loss: 0.203519
Average total loss: 0.391031
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(3.9591e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.185590
Average KL loss: 0.203417
Average total loss: 0.389007
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(5.4966e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.194506
Average KL loss: 0.203325
Average total loss: 0.397831
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(3.4583e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.183513
Average KL loss: 0.203244
Average total loss: 0.386757
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(3.2629e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.183260
Average KL loss: 0.203156
Average total loss: 0.386416
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(5.5480e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.186247
Average KL loss: 0.203070
Average total loss: 0.389317
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-8.4518e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.181590
Average KL loss: 0.202987
Average total loss: 0.384578
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.9331e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.193613
Average KL loss: 0.202905
Average total loss: 0.396518
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-5.0794e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.181104
Average KL loss: 0.202833
Average total loss: 0.383936
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(8.8926e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.186271
Average KL loss: 0.202761
Average total loss: 0.389031
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-5.6960e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.190805
Average KL loss: 0.202683
Average total loss: 0.393488
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.1255e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.179975
Average KL loss: 0.202615
Average total loss: 0.382590
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.1376e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.184583
Average KL loss: 0.202540
Average total loss: 0.387123
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.8722e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.185005
Average KL loss: 0.202470
Average total loss: 0.387475
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.8504e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.188724
Average KL loss: 0.202407
Average total loss: 0.391131
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(5.8027e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.184628
Average KL loss: 0.202350
Average total loss: 0.386978
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.1566e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.191450
Average KL loss: 0.202285
Average total loss: 0.393734
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.2088e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.186074
Average KL loss: 0.202227
Average total loss: 0.388301
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-7.7897e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.185755
Average KL loss: 0.202167
Average total loss: 0.387922
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.0465e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.188412
Average KL loss: 0.202111
Average total loss: 0.390524
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(1.2117e-11, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.195005
Average KL loss: 0.202058
Average total loss: 0.397063
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-6.2581e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.189246
Average KL loss: 0.202010
Average total loss: 0.391256
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.4601e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.187545
Average KL loss: 0.201964
Average total loss: 0.389509
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-8.7432e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.186741
Average KL loss: 0.201935
Average total loss: 0.388676
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-5.8505e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.190112
Average KL loss: 0.201928
Average total loss: 0.392040
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.4661e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.185506
Average KL loss: 0.201920
Average total loss: 0.387426
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.3874e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.191577
Average KL loss: 0.201913
Average total loss: 0.393490
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-5.6019e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.190576
Average KL loss: 0.201906
Average total loss: 0.392482
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.9637e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.185260
Average KL loss: 0.201900
Average total loss: 0.387160
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(2.3959e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.185659
Average KL loss: 0.201892
Average total loss: 0.387551
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.8784e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.193223
Average KL loss: 0.201885
Average total loss: 0.395109
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.8225e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.185930
Average KL loss: 0.201879
Average total loss: 0.387809
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(3.1697e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.185294
Average KL loss: 0.201872
Average total loss: 0.387167
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(1.2445e-09, device='cuda:0')
 Percentile value: 0.0021673128940165043
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =    1113 /    1728             ( 64.41%) | total_pruned =     615 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   11217 /   36864             ( 30.43%) | total_pruned =   25647 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   11915 /   36864             ( 32.32%) | total_pruned =   24949 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   11588 /   36864             ( 31.43%) | total_pruned =   25276 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   11523 /   36864             ( 31.26%) | total_pruned =   25341 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   22835 /   73728             ( 30.97%) | total_pruned =   50893 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   44033 /  147456             ( 29.86%) | total_pruned =  103423 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3643 /    8192             ( 44.47%) | total_pruned =    4549 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   40570 /  147456             ( 27.51%) | total_pruned =  106886 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   40233 /  147456             ( 27.28%) | total_pruned =  107223 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   87137 /  294912             ( 29.55%) | total_pruned =  207775 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  168880 /  589824             ( 28.63%) | total_pruned =  420944 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   12500 /   32768             ( 38.15%) | total_pruned =   20268 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     204 /     256             ( 79.69%) | total_pruned =      52 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  144091 /  589824             ( 24.43%) | total_pruned =  445733 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     187 /     256             ( 73.05%) | total_pruned =      69 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  143123 /  589824             ( 24.27%) | total_pruned =  446701 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  322185 / 1179648             ( 27.31%) | total_pruned =  857463 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     407 /     512             ( 79.49%) | total_pruned =     105 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  602243 / 2359296             ( 25.53%) | total_pruned = 1757053 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     354 /     512             ( 69.14%) | total_pruned =     158 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   38831 /  131072             ( 29.63%) | total_pruned =   92241 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     477 /     512             ( 93.16%) | total_pruned =      35 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     361 /     512             ( 70.51%) | total_pruned =     151 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  536452 / 2359296             ( 22.74%) | total_pruned = 1822844 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     404 /     512             ( 78.91%) | total_pruned =     108 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     305 /     512             ( 59.57%) | total_pruned =     207 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  529392 / 2359296             ( 22.44%) | total_pruned = 1829904 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      75 /     512             ( 14.65%) | total_pruned =     437 | shape = torch.Size([512])
linear.weight        | nonzeros =    3569 /    5120             ( 69.71%) | total_pruned =    1551 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 36/100 Loss: 0.000034 Accuracy: 87.34 100.00 % Best test Accuracy: 87.43%
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.3876e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.353885
Average KL loss: 0.221978
Average total loss: 0.575863
tensor(0.0022, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.5575e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.331767
Average KL loss: 0.248662
Average total loss: 0.580429
tensor(0.0023, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.6353e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.306256
Average KL loss: 0.260101
Average total loss: 0.566357
tensor(0.0023, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0087e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.311490
Average KL loss: 0.264737
Average total loss: 0.576227
tensor(0.0023, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.1175e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.300881
Average KL loss: 0.270247
Average total loss: 0.571128
tensor(0.0023, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.2099e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.290631
Average KL loss: 0.273141
Average total loss: 0.563772
tensor(0.0024, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.3583e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.281802
Average KL loss: 0.272980
Average total loss: 0.554781
tensor(0.0024, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0596e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.280929
Average KL loss: 0.272972
Average total loss: 0.553901
tensor(0.0024, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4825e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.295480
Average KL loss: 0.276423
Average total loss: 0.571903
tensor(0.0023, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4983e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.285783
Average KL loss: 0.280133
Average total loss: 0.565916
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-8.6772e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.276554
Average KL loss: 0.280238
Average total loss: 0.556791
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(4.1699e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.273517
Average KL loss: 0.279541
Average total loss: 0.553058
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.6198e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.274912
Average KL loss: 0.279086
Average total loss: 0.553998
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.3017e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.279619
Average KL loss: 0.280969
Average total loss: 0.560588
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.8940e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.272190
Average KL loss: 0.282238
Average total loss: 0.554427
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(1.9921e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.260873
Average KL loss: 0.281310
Average total loss: 0.542183
tensor(0.0023, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1068e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.263148
Average KL loss: 0.281823
Average total loss: 0.544971
tensor(0.0023, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.0555e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.265194
Average KL loss: 0.282039
Average total loss: 0.547233
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.5616e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.265375
Average KL loss: 0.283964
Average total loss: 0.549339
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.6263e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.258698
Average KL loss: 0.284027
Average total loss: 0.542726
tensor(0.0023, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.8331e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.257461
Average KL loss: 0.284251
Average total loss: 0.541712
tensor(0.0023, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.5994e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.262045
Average KL loss: 0.285519
Average total loss: 0.547564
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(2.0269e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.258545
Average KL loss: 0.285873
Average total loss: 0.544417
tensor(0.0023, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.3178e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.259840
Average KL loss: 0.285260
Average total loss: 0.545100
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.3642e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.257259
Average KL loss: 0.288739
Average total loss: 0.545997
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-6.7601e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.255382
Average KL loss: 0.288000
Average total loss: 0.543383
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-9.1863e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.251476
Average KL loss: 0.288604
Average total loss: 0.540080
tensor(0.0023, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(2.2089e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.254300
Average KL loss: 0.287600
Average total loss: 0.541900
tensor(0.0023, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.8727e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.258644
Average KL loss: 0.289579
Average total loss: 0.548222
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-4.9339e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.258069
Average KL loss: 0.289666
Average total loss: 0.547735
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.4758e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.253028
Average KL loss: 0.291002
Average total loss: 0.544030
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.5333e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.252146
Average KL loss: 0.290463
Average total loss: 0.542609
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.9637e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.251107
Average KL loss: 0.291155
Average total loss: 0.542262
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.3937e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.256902
Average KL loss: 0.292131
Average total loss: 0.549033
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.0205e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.250823
Average KL loss: 0.293982
Average total loss: 0.544805
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.6920e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.250045
Average KL loss: 0.292550
Average total loss: 0.542594
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.5274e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.250029
Average KL loss: 0.293231
Average total loss: 0.543260
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(3.8668e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.247466
Average KL loss: 0.293568
Average total loss: 0.541033
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0791e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.242389
Average KL loss: 0.289752
Average total loss: 0.532142
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.1601e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.239936
Average KL loss: 0.281758
Average total loss: 0.521694
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(2.7351e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.241728
Average KL loss: 0.275815
Average total loss: 0.517543
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-9.1654e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.244358
Average KL loss: 0.271250
Average total loss: 0.515608
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-4.9015e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.247632
Average KL loss: 0.267545
Average total loss: 0.515177
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-3.5768e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.241417
Average KL loss: 0.264400
Average total loss: 0.505817
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-6.3448e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.254778
Average KL loss: 0.261814
Average total loss: 0.516592
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(3.1763e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.247429
Average KL loss: 0.259627
Average total loss: 0.507056
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(4.8284e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.246754
Average KL loss: 0.257623
Average total loss: 0.504377
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(2.8600e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.244390
Average KL loss: 0.255910
Average total loss: 0.500300
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(1.2915e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.247640
Average KL loss: 0.254389
Average total loss: 0.502029
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2249e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.240631
Average KL loss: 0.252952
Average total loss: 0.493583
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(1.8664e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.245623
Average KL loss: 0.251622
Average total loss: 0.497245
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.2208e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.250425
Average KL loss: 0.250495
Average total loss: 0.500920
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.0051e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.245171
Average KL loss: 0.249496
Average total loss: 0.494667
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.5969e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.252075
Average KL loss: 0.248534
Average total loss: 0.500609
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.9666e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.253567
Average KL loss: 0.247695
Average total loss: 0.501262
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3869e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.238659
Average KL loss: 0.246911
Average total loss: 0.485570
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(2.1751e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.241196
Average KL loss: 0.246106
Average total loss: 0.487303
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.7063e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.237062
Average KL loss: 0.245326
Average total loss: 0.482388
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(3.0102e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.243035
Average KL loss: 0.244600
Average total loss: 0.487634
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3761e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.246055
Average KL loss: 0.243955
Average total loss: 0.490010
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-8.4325e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.242935
Average KL loss: 0.243399
Average total loss: 0.486334
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.6235e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.242214
Average KL loss: 0.242882
Average total loss: 0.485096
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(1.3299e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.238574
Average KL loss: 0.242364
Average total loss: 0.480938
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1275e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.235329
Average KL loss: 0.241864
Average total loss: 0.477193
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.3838e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.243627
Average KL loss: 0.241392
Average total loss: 0.485019
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.2767e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.242277
Average KL loss: 0.240984
Average total loss: 0.483261
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-8.2187e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.250852
Average KL loss: 0.240587
Average total loss: 0.491439
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(6.1152e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.242940
Average KL loss: 0.240355
Average total loss: 0.483295
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.3711e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.238949
Average KL loss: 0.240054
Average total loss: 0.479003
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(4.2756e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.243683
Average KL loss: 0.239701
Average total loss: 0.483384
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.6486e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.238394
Average KL loss: 0.239395
Average total loss: 0.477789
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(2.9319e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.242968
Average KL loss: 0.239109
Average total loss: 0.482077
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.8175e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.245229
Average KL loss: 0.238909
Average total loss: 0.484138
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(4.6324e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.239085
Average KL loss: 0.238659
Average total loss: 0.477744
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(2.3167e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.247992
Average KL loss: 0.238416
Average total loss: 0.486408
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.7116e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.243565
Average KL loss: 0.238255
Average total loss: 0.481820
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(1.8929e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.242962
Average KL loss: 0.238116
Average total loss: 0.481078
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(1.9705e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.240725
Average KL loss: 0.237980
Average total loss: 0.478705
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(3.3070e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.248953
Average KL loss: 0.237856
Average total loss: 0.486809
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.8878e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.240780
Average KL loss: 0.237744
Average total loss: 0.478524
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.3007e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.241649
Average KL loss: 0.237624
Average total loss: 0.479274
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.7923e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.242199
Average KL loss: 0.237506
Average total loss: 0.479705
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.9799e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.243980
Average KL loss: 0.237393
Average total loss: 0.481372
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.0975e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.247069
Average KL loss: 0.237293
Average total loss: 0.484362
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(9.7630e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.236601
Average KL loss: 0.237195
Average total loss: 0.473797
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(2.0781e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.244652
Average KL loss: 0.237095
Average total loss: 0.481747
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.2272e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.241289
Average KL loss: 0.237011
Average total loss: 0.478299
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(2.2247e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.240777
Average KL loss: 0.236924
Average total loss: 0.477701
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(2.0401e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.245299
Average KL loss: 0.236838
Average total loss: 0.482137
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(1.8587e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.244847
Average KL loss: 0.236753
Average total loss: 0.481599
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.5663e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.244860
Average KL loss: 0.236667
Average total loss: 0.481527
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.5802e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.247133
Average KL loss: 0.236583
Average total loss: 0.483716
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(6.2584e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.242716
Average KL loss: 0.236505
Average total loss: 0.479221
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.9684e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.249449
Average KL loss: 0.236428
Average total loss: 0.485877
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.2650e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.245371
Average KL loss: 0.236353
Average total loss: 0.481724
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.0533e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.244996
Average KL loss: 0.236272
Average total loss: 0.481268
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(5.3345e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.244229
Average KL loss: 0.236227
Average total loss: 0.480455
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.9470e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.241667
Average KL loss: 0.236218
Average total loss: 0.477885
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.0359e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.247632
Average KL loss: 0.236210
Average total loss: 0.483842
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.3768e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.245253
Average KL loss: 0.236201
Average total loss: 0.481454
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-8.0358e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.247961
Average KL loss: 0.236192
Average total loss: 0.484153
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(4.1488e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.247214
Average KL loss: 0.236184
Average total loss: 0.483398
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.0179e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.237435
Average KL loss: 0.236176
Average total loss: 0.473611
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.3205e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.232994
Average KL loss: 0.236167
Average total loss: 0.469161
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-8.3647e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.241044
Average KL loss: 0.236158
Average total loss: 0.477202
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(1.7673e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.248198
Average KL loss: 0.236149
Average total loss: 0.484348
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(1.6622e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.241730
Average KL loss: 0.236141
Average total loss: 0.477872
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(3.8854e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.248960
Average KL loss: 0.236133
Average total loss: 0.485093
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.1983e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.237236
Average KL loss: 0.236124
Average total loss: 0.473360
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.4718e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.236193
Average KL loss: 0.236115
Average total loss: 0.472308
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(6.3744e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.236200
Average KL loss: 0.236106
Average total loss: 0.472306
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.0711e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.243877
Average KL loss: 0.236097
Average total loss: 0.479974
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(6.2239e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.241894
Average KL loss: 0.236089
Average total loss: 0.477983
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(1.8932e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.240677
Average KL loss: 0.236081
Average total loss: 0.476758
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.5441e-09, device='cuda:0')
 Percentile value: 0.0062159583903849125
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =     984 /    1728             ( 56.94%) | total_pruned =     744 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6889 /   36864             ( 18.69%) | total_pruned =   29975 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    7521 /   36864             ( 20.40%) | total_pruned =   29343 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    7262 /   36864             ( 19.70%) | total_pruned =   29602 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    7052 /   36864             ( 19.13%) | total_pruned =   29812 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13897 /   73728             ( 18.85%) | total_pruned =   59831 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   26240 /  147456             ( 17.80%) | total_pruned =  121216 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2703 /    8192             ( 33.00%) | total_pruned =    5489 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   22149 /  147456             ( 15.02%) | total_pruned =  125307 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   22196 /  147456             ( 15.05%) | total_pruned =  125260 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   51210 /  294912             ( 17.36%) | total_pruned =  243702 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   96333 /  589824             ( 16.33%) | total_pruned =  493491 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    8500 /   32768             ( 25.94%) | total_pruned =   24268 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   68746 /  589824             ( 11.66%) | total_pruned =  521078 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     110 /     256             ( 42.97%) | total_pruned =     146 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   69144 /  589824             ( 11.72%) | total_pruned =  520680 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  177340 / 1179648             ( 15.03%) | total_pruned = 1002308 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     331 /     512             ( 64.65%) | total_pruned =     181 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  309500 / 2359296             ( 13.12%) | total_pruned = 2049796 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     315 /     512             ( 61.52%) | total_pruned =     197 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   21771 /  131072             ( 16.61%) | total_pruned =  109301 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     453 /     512             ( 88.48%) | total_pruned =      59 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     326 /     512             ( 63.67%) | total_pruned =     186 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  236299 / 2359296             ( 10.02%) | total_pruned = 2122997 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     404 /     512             ( 78.91%) | total_pruned =     108 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     229 /     512             ( 44.73%) | total_pruned =     283 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  231642 / 2359296             (  9.82%) | total_pruned = 2127654 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
linear.weight        | nonzeros =    2952 /    5120             ( 57.66%) | total_pruned =    2168 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 32/100 Loss: 0.001246 Accuracy: 87.01 100.00 % Best test Accuracy: 87.30%
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.3352e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.466789
Average KL loss: 0.242564
Average total loss: 0.709353
tensor(0.0027, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.1812e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.434675
Average KL loss: 0.269249
Average total loss: 0.703924
tensor(0.0027, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.0471e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.425728
Average KL loss: 0.283710
Average total loss: 0.709438
tensor(0.0028, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.0420e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.402825
Average KL loss: 0.292195
Average total loss: 0.695020
tensor(0.0028, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.2117e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.398741
Average KL loss: 0.296606
Average total loss: 0.695347
tensor(0.0028, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(5.2487e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.379495
Average KL loss: 0.300895
Average total loss: 0.680391
tensor(0.0028, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.6929e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.388988
Average KL loss: 0.303404
Average total loss: 0.692392
tensor(0.0028, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.3134e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.378370
Average KL loss: 0.306477
Average total loss: 0.684847
tensor(0.0028, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(6.1457e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.369699
Average KL loss: 0.307774
Average total loss: 0.677473
tensor(0.0028, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4906e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.376982
Average KL loss: 0.309545
Average total loss: 0.686527
tensor(0.0028, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.5938e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.365266
Average KL loss: 0.312775
Average total loss: 0.678041
tensor(0.0028, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(2.2503e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.368413
Average KL loss: 0.313369
Average total loss: 0.681782
tensor(0.0028, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.2891e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.362939
Average KL loss: 0.314050
Average total loss: 0.676989
tensor(0.0028, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.5847e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.370532
Average KL loss: 0.315331
Average total loss: 0.685863
tensor(0.0028, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.4364e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.362123
Average KL loss: 0.317284
Average total loss: 0.679407
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(2.9925e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.354461
Average KL loss: 0.317479
Average total loss: 0.671939
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.5778e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.363004
Average KL loss: 0.318062
Average total loss: 0.681067
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.7905e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.361869
Average KL loss: 0.319153
Average total loss: 0.681021
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.7271e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.354266
Average KL loss: 0.320470
Average total loss: 0.674736
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.5278e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.352938
Average KL loss: 0.320403
Average total loss: 0.673340
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.1263e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.340467
Average KL loss: 0.319767
Average total loss: 0.660234
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.0825e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.351143
Average KL loss: 0.320033
Average total loss: 0.671177
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.0123e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.353929
Average KL loss: 0.321391
Average total loss: 0.675320
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.6343e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.343042
Average KL loss: 0.322334
Average total loss: 0.665376
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(1.6433e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.346423
Average KL loss: 0.322665
Average total loss: 0.669089
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.0476e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.350696
Average KL loss: 0.322698
Average total loss: 0.673393
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(1.0923e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.343179
Average KL loss: 0.323950
Average total loss: 0.667129
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.9902e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.348196
Average KL loss: 0.324399
Average total loss: 0.672596
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-7.9787e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.345503
Average KL loss: 0.325256
Average total loss: 0.670758
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(4.6949e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.346527
Average KL loss: 0.326441
Average total loss: 0.672968
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-8.7754e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.340242
Average KL loss: 0.325704
Average total loss: 0.665946
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(2.5638e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.347634
Average KL loss: 0.326757
Average total loss: 0.674390
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(9.5796e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.340715
Average KL loss: 0.324859
Average total loss: 0.665575
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.4680e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.344288
Average KL loss: 0.319863
Average total loss: 0.664151
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(5.1838e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.334007
Average KL loss: 0.315697
Average total loss: 0.649704
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(7.2081e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.333815
Average KL loss: 0.312128
Average total loss: 0.645943
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.5613e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.337256
Average KL loss: 0.309176
Average total loss: 0.646432
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(6.3295e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.325859
Average KL loss: 0.306503
Average total loss: 0.632362
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(7.6794e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.332046
Average KL loss: 0.304079
Average total loss: 0.636124
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.0154e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.342553
Average KL loss: 0.301946
Average total loss: 0.644499
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.8266e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.333259
Average KL loss: 0.300067
Average total loss: 0.633326
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(6.3255e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.337801
Average KL loss: 0.298290
Average total loss: 0.636090
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(1.3340e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.332943
Average KL loss: 0.296704
Average total loss: 0.629647
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.5699e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.343677
Average KL loss: 0.295236
Average total loss: 0.638914
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.9848e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.335156
Average KL loss: 0.293935
Average total loss: 0.629091
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.0164e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.343710
Average KL loss: 0.292710
Average total loss: 0.636420
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(2.0634e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.341259
Average KL loss: 0.291616
Average total loss: 0.632876
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(4.4611e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.336065
Average KL loss: 0.290535
Average total loss: 0.626600
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.3964e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.327181
Average KL loss: 0.289492
Average total loss: 0.616673
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(4.1902e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.336841
Average KL loss: 0.288468
Average total loss: 0.625309
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.7104e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.343811
Average KL loss: 0.287605
Average total loss: 0.631417
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.9614e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.348235
Average KL loss: 0.286815
Average total loss: 0.635050
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.7439e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.337873
Average KL loss: 0.286118
Average total loss: 0.623991
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.5512e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.333707
Average KL loss: 0.285407
Average total loss: 0.619114
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(2.4887e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.326347
Average KL loss: 0.284659
Average total loss: 0.611005
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(9.6195e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.336390
Average KL loss: 0.284035
Average total loss: 0.620424
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(5.3923e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.335396
Average KL loss: 0.283502
Average total loss: 0.618898
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(8.5156e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.335012
Average KL loss: 0.282937
Average total loss: 0.617949
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.0966e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.332982
Average KL loss: 0.282339
Average total loss: 0.615321
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.1873e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.330046
Average KL loss: 0.281780
Average total loss: 0.611826
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.2580e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.325129
Average KL loss: 0.281205
Average total loss: 0.606334
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(8.4789e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.333905
Average KL loss: 0.280696
Average total loss: 0.614602
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(5.7710e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.335332
Average KL loss: 0.280270
Average total loss: 0.615602
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(4.3252e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.342119
Average KL loss: 0.279870
Average total loss: 0.621989
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.6667e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.338335
Average KL loss: 0.279586
Average total loss: 0.617921
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(5.4512e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.329030
Average KL loss: 0.279212
Average total loss: 0.608242
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(6.1566e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.334981
Average KL loss: 0.278902
Average total loss: 0.613883
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.5944e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.335928
Average KL loss: 0.278641
Average total loss: 0.614568
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(3.6561e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.334798
Average KL loss: 0.278256
Average total loss: 0.613054
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.0334e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.328193
Average KL loss: 0.277893
Average total loss: 0.606086
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.7621e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.335762
Average KL loss: 0.277573
Average total loss: 0.613335
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(5.0022e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.328432
Average KL loss: 0.277225
Average total loss: 0.605657
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(5.5009e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.329653
Average KL loss: 0.276991
Average total loss: 0.606644
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.5656e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.331475
Average KL loss: 0.276701
Average total loss: 0.608175
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.6435e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.337275
Average KL loss: 0.276531
Average total loss: 0.613806
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(7.7852e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.324242
Average KL loss: 0.276309
Average total loss: 0.600550
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(2.5493e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.339011
Average KL loss: 0.276064
Average total loss: 0.615075
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(2.0935e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.327838
Average KL loss: 0.275839
Average total loss: 0.603677
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(7.2245e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.334503
Average KL loss: 0.275602
Average total loss: 0.610105
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(6.1310e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.333642
Average KL loss: 0.275415
Average total loss: 0.609057
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.9269e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.322347
Average KL loss: 0.275239
Average total loss: 0.597586
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.6640e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.337871
Average KL loss: 0.275032
Average total loss: 0.612904
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(4.6063e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.325486
Average KL loss: 0.274831
Average total loss: 0.600317
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.9781e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.337308
Average KL loss: 0.274600
Average total loss: 0.611907
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.2668e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.342270
Average KL loss: 0.274454
Average total loss: 0.616724
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(6.8955e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.336701
Average KL loss: 0.274358
Average total loss: 0.611059
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(7.8648e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.334346
Average KL loss: 0.274272
Average total loss: 0.608617
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.9916e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.330172
Average KL loss: 0.274156
Average total loss: 0.604328
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.1334e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.332224
Average KL loss: 0.274008
Average total loss: 0.606232
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(6.2806e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.335537
Average KL loss: 0.273864
Average total loss: 0.609401
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(3.7370e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.334360
Average KL loss: 0.273718
Average total loss: 0.608078
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(4.3526e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.323722
Average KL loss: 0.273559
Average total loss: 0.597280
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(4.8381e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.322955
Average KL loss: 0.273404
Average total loss: 0.596359
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.3103e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.331614
Average KL loss: 0.273290
Average total loss: 0.604904
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.5232e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.337252
Average KL loss: 0.273238
Average total loss: 0.610491
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.2354e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.332028
Average KL loss: 0.273210
Average total loss: 0.605238
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(8.5930e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.341341
Average KL loss: 0.273169
Average total loss: 0.614510
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(6.6132e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.333403
Average KL loss: 0.273137
Average total loss: 0.606540
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(9.7297e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.330273
Average KL loss: 0.273077
Average total loss: 0.603350
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(3.4328e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.333071
Average KL loss: 0.272919
Average total loss: 0.605990
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.3737e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.328350
Average KL loss: 0.272813
Average total loss: 0.601163
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3334e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.325801
Average KL loss: 0.272652
Average total loss: 0.598453
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.4918e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.334265
Average KL loss: 0.272537
Average total loss: 0.606801
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.5353e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.334807
Average KL loss: 0.272511
Average total loss: 0.607318
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.2361e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.327354
Average KL loss: 0.272441
Average total loss: 0.599795
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.3238e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.321555
Average KL loss: 0.272364
Average total loss: 0.593919
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.1871e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.339032
Average KL loss: 0.272287
Average total loss: 0.611319
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.4371e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.322383
Average KL loss: 0.272220
Average total loss: 0.594603
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(7.1437e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.330804
Average KL loss: 0.272149
Average total loss: 0.602953
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(4.4018e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.317674
Average KL loss: 0.272081
Average total loss: 0.589754
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.6724e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.338113
Average KL loss: 0.272010
Average total loss: 0.610123
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.6310e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.333829
Average KL loss: 0.271948
Average total loss: 0.605777
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0260e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.325699
Average KL loss: 0.271893
Average total loss: 0.597592
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.3841e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.326114
Average KL loss: 0.271830
Average total loss: 0.597944
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(5.2025e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.328384
Average KL loss: 0.271775
Average total loss: 0.600158
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.6267e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.331580
Average KL loss: 0.271721
Average total loss: 0.603301
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(3.3430e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.333498
Average KL loss: 0.271666
Average total loss: 0.605163
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.0920e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.323371
Average KL loss: 0.271610
Average total loss: 0.594981
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(3.7931e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.321393
Average KL loss: 0.271548
Average total loss: 0.592941
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.3922e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.337483
Average KL loss: 0.271493
Average total loss: 0.608976
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(7.5123e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.329616
Average KL loss: 0.271441
Average total loss: 0.601057
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.5159e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.328223
Average KL loss: 0.271413
Average total loss: 0.599635
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.2541e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.326058
Average KL loss: 0.271407
Average total loss: 0.597465
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(7.1770e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.327155
Average KL loss: 0.271400
Average total loss: 0.598554
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(5.2066e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.331047
Average KL loss: 0.271393
Average total loss: 0.602440
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.3464e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.329073
Average KL loss: 0.271388
Average total loss: 0.600461
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.4347e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.329199
Average KL loss: 0.271381
Average total loss: 0.600580
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.4740e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.333767
Average KL loss: 0.271375
Average total loss: 0.605142
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(3.6365e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.326580
Average KL loss: 0.271369
Average total loss: 0.597949
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.4525e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.323439
Average KL loss: 0.271363
Average total loss: 0.594803
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.5596e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.333241
Average KL loss: 0.271358
Average total loss: 0.604598
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(4.7503e-09, device='cuda:0')
 Percentile value: 0.018254660069942474
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =     896 /    1728             ( 51.85%) | total_pruned =     832 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4545 /   36864             ( 12.33%) | total_pruned =   32319 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5100 /   36864             ( 13.83%) | total_pruned =   31764 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4851 /   36864             ( 13.16%) | total_pruned =   32013 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4635 /   36864             ( 12.57%) | total_pruned =   32229 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    9023 /   73728             ( 12.24%) | total_pruned =   64705 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   16173 /  147456             ( 10.97%) | total_pruned =  131283 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2133 /    8192             ( 26.04%) | total_pruned =    6059 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   12549 /  147456             (  8.51%) | total_pruned =  134907 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   12631 /  147456             (  8.57%) | total_pruned =  134825 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   31511 /  294912             ( 10.68%) | total_pruned =  263401 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     147 /     256             ( 57.42%) | total_pruned =     109 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   56074 /  589824             (  9.51%) | total_pruned =  533750 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     152 /     256             ( 59.38%) | total_pruned =     104 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6147 /   32768             ( 18.76%) | total_pruned =   26621 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   35297 /  589824             (  5.98%) | total_pruned =  554527 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   35630 /  589824             (  6.04%) | total_pruned =  554194 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   97626 / 1179648             (  8.28%) | total_pruned = 1082022 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     275 /     512             ( 53.71%) | total_pruned =     237 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  150470 / 2359296             (  6.38%) | total_pruned = 2208826 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     294 /     512             ( 57.42%) | total_pruned =     218 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   12504 /  131072             (  9.54%) | total_pruned =  118568 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     421 /     512             ( 82.23%) | total_pruned =      91 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     314 /     512             ( 61.33%) | total_pruned =     198 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  104849 / 2359296             (  4.44%) | total_pruned = 2254447 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     396 /     512             ( 77.34%) | total_pruned =     116 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     192 /     512             ( 37.50%) | total_pruned =     320 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   87046 / 2359296             (  3.69%) | total_pruned = 2272250 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      47 /     512             (  9.18%) | total_pruned =     465 | shape = torch.Size([512])
linear.weight        | nonzeros =    2391 /    5120             ( 46.70%) | total_pruned =    2729 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 30/100 Loss: 0.000094 Accuracy: 87.06 100.00 % Best test Accuracy: 87.38%
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.3288e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.587842
Average KL loss: 0.266387
Average total loss: 0.854229
tensor(0.0031, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.3218e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.544906
Average KL loss: 0.286050
Average total loss: 0.830957
tensor(0.0031, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.7998e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.521669
Average KL loss: 0.299921
Average total loss: 0.821590
tensor(0.0031, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.2429e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.530768
Average KL loss: 0.310726
Average total loss: 0.841494
tensor(0.0032, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.6987e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.514937
Average KL loss: 0.320599
Average total loss: 0.835536
tensor(0.0032, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(3.3257e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.499090
Average KL loss: 0.326900
Average total loss: 0.825990
tensor(0.0032, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-7.1263e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.504497
Average KL loss: 0.331481
Average total loss: 0.835978
tensor(0.0032, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.2620e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.501502
Average KL loss: 0.336127
Average total loss: 0.837629
tensor(0.0032, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.5359e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.478566
Average KL loss: 0.339826
Average total loss: 0.818392
tensor(0.0032, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.3355e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.479670
Average KL loss: 0.341508
Average total loss: 0.821178
tensor(0.0032, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-2.9597e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.479087
Average KL loss: 0.343196
Average total loss: 0.822283
tensor(0.0032, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.4562e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.490700
Average KL loss: 0.345386
Average total loss: 0.836086
tensor(0.0032, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(4.0756e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.477262
Average KL loss: 0.348210
Average total loss: 0.825473
tensor(0.0032, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-5.8321e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.455893
Average KL loss: 0.349622
Average total loss: 0.805515
tensor(0.0032, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(5.2728e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.462378
Average KL loss: 0.348707
Average total loss: 0.811085
tensor(0.0032, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-5.0308e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.451911
Average KL loss: 0.349534
Average total loss: 0.801445
tensor(0.0032, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.0997e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.462951
Average KL loss: 0.350996
Average total loss: 0.813947
tensor(0.0032, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(3.3317e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.456989
Average KL loss: 0.352043
Average total loss: 0.809032
tensor(0.0032, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-4.0466e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.451337
Average KL loss: 0.352501
Average total loss: 0.803838
tensor(0.0032, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.9997e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.446744
Average KL loss: 0.353281
Average total loss: 0.800025
tensor(0.0032, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(2.9716e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.437500
Average KL loss: 0.353667
Average total loss: 0.791167
tensor(0.0032, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.8800e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.453484
Average KL loss: 0.354112
Average total loss: 0.807595
tensor(0.0032, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.0533e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.457254
Average KL loss: 0.355891
Average total loss: 0.813145
tensor(0.0032, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-7.1227e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.458080
Average KL loss: 0.357380
Average total loss: 0.815460
tensor(0.0032, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-5.4760e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.447486
Average KL loss: 0.357822
Average total loss: 0.805308
tensor(0.0032, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.7536e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.452442
Average KL loss: 0.358102
Average total loss: 0.810545
tensor(0.0032, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(2.0495e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.441722
Average KL loss: 0.359198
Average total loss: 0.800921
tensor(0.0032, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.0380e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.432252
Average KL loss: 0.359005
Average total loss: 0.791257
tensor(0.0032, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(6.5014e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.437032
Average KL loss: 0.358110
Average total loss: 0.795142
tensor(0.0032, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.3265e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.450503
Average KL loss: 0.359711
Average total loss: 0.810214
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.0634e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.446994
Average KL loss: 0.361985
Average total loss: 0.808979
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(2.7730e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.417664
Average KL loss: 0.360592
Average total loss: 0.778257
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.1006e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.430300
Average KL loss: 0.359718
Average total loss: 0.790018
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-5.8886e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.438474
Average KL loss: 0.359730
Average total loss: 0.798204
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-9.8857e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.433193
Average KL loss: 0.360779
Average total loss: 0.793971
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8528e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.449693
Average KL loss: 0.362325
Average total loss: 0.812018
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.8174e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.433129
Average KL loss: 0.363748
Average total loss: 0.796877
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.3103e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.435322
Average KL loss: 0.362923
Average total loss: 0.798244
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(2.1579e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.442931
Average KL loss: 0.364215
Average total loss: 0.807147
tensor(0.0032, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(6.8516e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.420726
Average KL loss: 0.364996
Average total loss: 0.785722
tensor(0.0032, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.6498e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.437249
Average KL loss: 0.363665
Average total loss: 0.800914
tensor(0.0032, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(1.2751e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.423759
Average KL loss: 0.365383
Average total loss: 0.789142
tensor(0.0032, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(6.5278e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.434983
Average KL loss: 0.365000
Average total loss: 0.799983
tensor(0.0032, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(4.6234e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.432930
Average KL loss: 0.364731
Average total loss: 0.797661
tensor(0.0032, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(2.5202e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.433260
Average KL loss: 0.361948
Average total loss: 0.795208
tensor(0.0032, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.7248e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.418573
Average KL loss: 0.359431
Average total loss: 0.778004
tensor(0.0032, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(1.8597e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.415601
Average KL loss: 0.357119
Average total loss: 0.772720
tensor(0.0032, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.9977e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.414535
Average KL loss: 0.354955
Average total loss: 0.769490
tensor(0.0032, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.1000e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.429645
Average KL loss: 0.353073
Average total loss: 0.782718
tensor(0.0032, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.0212e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.413443
Average KL loss: 0.351340
Average total loss: 0.764784
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(3.6791e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.411508
Average KL loss: 0.349617
Average total loss: 0.761124
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.5997e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.421066
Average KL loss: 0.348014
Average total loss: 0.769080
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.1517e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.424430
Average KL loss: 0.346572
Average total loss: 0.771002
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.0371e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.414415
Average KL loss: 0.345263
Average total loss: 0.759678
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.3199e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.437691
Average KL loss: 0.343983
Average total loss: 0.781674
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.9519e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.427112
Average KL loss: 0.342956
Average total loss: 0.770068
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(2.0117e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.409594
Average KL loss: 0.341807
Average total loss: 0.751401
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3635e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.418493
Average KL loss: 0.340680
Average total loss: 0.759173
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0547e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.414544
Average KL loss: 0.339693
Average total loss: 0.754238
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.3534e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.431859
Average KL loss: 0.338805
Average total loss: 0.770664
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.5374e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.420008
Average KL loss: 0.337925
Average total loss: 0.757934
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.9354e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.422828
Average KL loss: 0.337083
Average total loss: 0.759910
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.5996e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.422192
Average KL loss: 0.336244
Average total loss: 0.758436
tensor(0.0032, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(7.0086e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.420963
Average KL loss: 0.335486
Average total loss: 0.756448
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(2.9008e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.423496
Average KL loss: 0.334818
Average total loss: 0.758314
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(4.1618e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.408202
Average KL loss: 0.334111
Average total loss: 0.742313
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(7.4711e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.418309
Average KL loss: 0.333383
Average total loss: 0.751692
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.1031e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.401368
Average KL loss: 0.332708
Average total loss: 0.734076
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.3718e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.413652
Average KL loss: 0.332014
Average total loss: 0.745666
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(3.9790e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.415723
Average KL loss: 0.331350
Average total loss: 0.747072
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.3555e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.418195
Average KL loss: 0.330815
Average total loss: 0.749010
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.4258e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.421676
Average KL loss: 0.330284
Average total loss: 0.751959
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(5.2554e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.425243
Average KL loss: 0.329829
Average total loss: 0.755072
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(3.5427e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.422223
Average KL loss: 0.329364
Average total loss: 0.751586
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(1.1295e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.418323
Average KL loss: 0.328907
Average total loss: 0.747230
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(2.0711e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.423554
Average KL loss: 0.328367
Average total loss: 0.751921
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(7.6103e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.417031
Average KL loss: 0.327957
Average total loss: 0.744988
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.3325e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.427333
Average KL loss: 0.327587
Average total loss: 0.754920
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(6.1916e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.414255
Average KL loss: 0.327173
Average total loss: 0.741428
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.8665e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.421281
Average KL loss: 0.326959
Average total loss: 0.748240
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-6.9268e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.421661
Average KL loss: 0.326885
Average total loss: 0.748546
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.3761e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.417900
Average KL loss: 0.326817
Average total loss: 0.744717
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(2.3323e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.413742
Average KL loss: 0.326742
Average total loss: 0.740484
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.8798e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.422444
Average KL loss: 0.326666
Average total loss: 0.749109
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(1.0258e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.427811
Average KL loss: 0.326604
Average total loss: 0.754414
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.9073e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.421017
Average KL loss: 0.326534
Average total loss: 0.747551
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.4024e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.412467
Average KL loss: 0.326456
Average total loss: 0.738923
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.0287e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.418260
Average KL loss: 0.326380
Average total loss: 0.744641
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(2.2244e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.415556
Average KL loss: 0.326311
Average total loss: 0.741867
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(9.8035e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.420139
Average KL loss: 0.326242
Average total loss: 0.746381
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-5.7841e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.421452
Average KL loss: 0.326206
Average total loss: 0.747658
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(4.0124e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.418821
Average KL loss: 0.326199
Average total loss: 0.745020
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(8.3894e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.422256
Average KL loss: 0.326192
Average total loss: 0.748447
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.6303e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.420443
Average KL loss: 0.326185
Average total loss: 0.746628
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-8.5966e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.425541
Average KL loss: 0.326178
Average total loss: 0.751719
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(5.2385e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.424268
Average KL loss: 0.326172
Average total loss: 0.750439
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(5.9075e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.412340
Average KL loss: 0.326164
Average total loss: 0.738504
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.9492e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.415863
Average KL loss: 0.326157
Average total loss: 0.742021
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(6.9607e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.409542
Average KL loss: 0.326150
Average total loss: 0.735692
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(6.9867e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.416741
Average KL loss: 0.326143
Average total loss: 0.742884
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.1503e-09, device='cuda:0')
 Percentile value: 0.04742341861128807
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =     828 /    1728             ( 47.92%) | total_pruned =     900 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    3072 /   36864             (  8.33%) | total_pruned =   33792 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    3622 /   36864             (  9.83%) | total_pruned =   33242 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3263 /   36864             (  8.85%) | total_pruned =   33601 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3159 /   36864             (  8.57%) | total_pruned =   33705 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    6041 /   73728             (  8.19%) | total_pruned =   67687 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   10392 /  147456             (  7.05%) | total_pruned =  137064 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1717 /    8192             ( 20.96%) | total_pruned =    6475 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    7130 /  147456             (  4.84%) | total_pruned =  140326 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    7160 /  147456             (  4.86%) | total_pruned =  140296 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   19617 /  294912             (  6.65%) | total_pruned =  275295 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   32700 /  589824             (  5.54%) | total_pruned =  557124 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4432 /   32768             ( 13.53%) | total_pruned =   28336 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   17434 /  589824             (  2.96%) | total_pruned =  572390 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   17450 /  589824             (  2.96%) | total_pruned =  572374 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   53139 / 1179648             (  4.50%) | total_pruned = 1126509 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     222 /     512             ( 43.36%) | total_pruned =     290 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   69766 / 2359296             (  2.96%) | total_pruned = 2289530 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     271 /     512             ( 52.93%) | total_pruned =     241 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    6989 /  131072             (  5.33%) | total_pruned =  124083 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     284 /     512             ( 55.47%) | total_pruned =     228 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   43074 / 2359296             (  1.83%) | total_pruned = 2316222 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     393 /     512             ( 76.76%) | total_pruned =     119 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     148 /     512             ( 28.91%) | total_pruned =     364 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   30359 / 2359296             (  1.29%) | total_pruned = 2328937 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([512])
linear.weight        | nonzeros =    1921 /    5120             ( 37.52%) | total_pruned =    3199 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 29/100 Loss: 0.000042 Accuracy: 86.61 100.00 % Best test Accuracy: 87.19%
tensor(0.0032, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-5.3568e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.819000
Average KL loss: 0.310592
Average total loss: 1.129592
tensor(0.0036, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.0838e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.790932
Average KL loss: 0.326371
Average total loss: 1.117303
tensor(0.0036, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-4.9047e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.733715
Average KL loss: 0.342227
Average total loss: 1.075942
tensor(0.0036, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.5826e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.719613
Average KL loss: 0.354385
Average total loss: 1.073998
tensor(0.0037, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.7047e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.698485
Average KL loss: 0.365125
Average total loss: 1.063610
tensor(0.0037, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.2558e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.694700
Average KL loss: 0.374195
Average total loss: 1.068895
tensor(0.0037, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(6.8876e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.660799
Average KL loss: 0.380882
Average total loss: 1.041680
tensor(0.0037, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.6684e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.663905
Average KL loss: 0.386034
Average total loss: 1.049939
tensor(0.0037, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.5723e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.624153
Average KL loss: 0.390445
Average total loss: 1.014598
tensor(0.0037, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.6399e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.635277
Average KL loss: 0.393486
Average total loss: 1.028763
tensor(0.0037, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(9.7560e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.634701
Average KL loss: 0.396681
Average total loss: 1.031382
tensor(0.0037, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(1.1541e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.630392
Average KL loss: 0.400234
Average total loss: 1.030626
tensor(0.0037, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.7604e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.643045
Average KL loss: 0.403599
Average total loss: 1.046645
tensor(0.0037, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(6.2445e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.630306
Average KL loss: 0.407272
Average total loss: 1.037578
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.8787e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.617402
Average KL loss: 0.409725
Average total loss: 1.027127
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(9.6324e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.615755
Average KL loss: 0.411585
Average total loss: 1.027340
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-3.3234e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.629475
Average KL loss: 0.413320
Average total loss: 1.042795
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.4025e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.612894
Average KL loss: 0.415943
Average total loss: 1.028837
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.6456e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.603671
Average KL loss: 0.416624
Average total loss: 1.020295
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(6.4977e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.601226
Average KL loss: 0.418001
Average total loss: 1.019227
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.3301e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.610430
Average KL loss: 0.418337
Average total loss: 1.028767
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-3.3800e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.590687
Average KL loss: 0.417105
Average total loss: 1.007792
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.0682e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.603793
Average KL loss: 0.415866
Average total loss: 1.019659
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-5.7096e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.590654
Average KL loss: 0.414736
Average total loss: 1.005390
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(6.3460e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.583085
Average KL loss: 0.413580
Average total loss: 0.996665
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-7.6635e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.595006
Average KL loss: 0.412471
Average total loss: 1.007477
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.0865e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.600248
Average KL loss: 0.411475
Average total loss: 1.011723
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.4562e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.590271
Average KL loss: 0.410534
Average total loss: 1.000805
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(1.1799e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.577318
Average KL loss: 0.409594
Average total loss: 0.986912
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.7191e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.595601
Average KL loss: 0.408659
Average total loss: 1.004260
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.1633e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.594851
Average KL loss: 0.407776
Average total loss: 1.002627
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-8.9784e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.598634
Average KL loss: 0.407014
Average total loss: 1.005648
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(3.5600e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.601780
Average KL loss: 0.406300
Average total loss: 1.008080
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.3161e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.558111
Average KL loss: 0.405605
Average total loss: 0.963716
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(5.4612e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.591052
Average KL loss: 0.404796
Average total loss: 0.995848
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.0270e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.591430
Average KL loss: 0.404076
Average total loss: 0.995506
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-8.5323e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.583641
Average KL loss: 0.403409
Average total loss: 0.987050
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(3.0381e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.592640
Average KL loss: 0.402723
Average total loss: 0.995363
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.9314e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.576220
Average KL loss: 0.402099
Average total loss: 0.978319
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(2.5014e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.582114
Average KL loss: 0.401346
Average total loss: 0.983460
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(9.2294e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.594723
Average KL loss: 0.400682
Average total loss: 0.995405
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.4264e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.590773
Average KL loss: 0.400204
Average total loss: 0.990977
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-8.0205e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.595157
Average KL loss: 0.399720
Average total loss: 0.994877
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.7983e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.598307
Average KL loss: 0.399225
Average total loss: 0.997532
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.0683e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.579177
Average KL loss: 0.398683
Average total loss: 0.977859
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.0489e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.582575
Average KL loss: 0.398365
Average total loss: 0.980939
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.1474e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.591093
Average KL loss: 0.398300
Average total loss: 0.989393
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.4446e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.574709
Average KL loss: 0.398234
Average total loss: 0.972943
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.5200e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.587456
Average KL loss: 0.398166
Average total loss: 0.985622
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.4451e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.583212
Average KL loss: 0.398100
Average total loss: 0.981312
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.5895e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.594766
Average KL loss: 0.398032
Average total loss: 0.992798
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.4525e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.581491
Average KL loss: 0.397970
Average total loss: 0.979462
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(2.8932e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.603693
Average KL loss: 0.397909
Average total loss: 1.001602
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-6.1074e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.593459
Average KL loss: 0.397853
Average total loss: 0.991312
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.3130e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.583281
Average KL loss: 0.397793
Average total loss: 0.981074
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.5693e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.578035
Average KL loss: 0.397725
Average total loss: 0.975760
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.0318e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.593363
Average KL loss: 0.397688
Average total loss: 0.991051
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(8.9416e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.582728
Average KL loss: 0.397682
Average total loss: 0.980410
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.1971e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.581186
Average KL loss: 0.397676
Average total loss: 0.978862
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.8049e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.588509
Average KL loss: 0.397670
Average total loss: 0.986179
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-6.6334e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.585543
Average KL loss: 0.397664
Average total loss: 0.983206
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.6109e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.607584
Average KL loss: 0.397657
Average total loss: 1.005241
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.6546e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.585837
Average KL loss: 0.397651
Average total loss: 0.983488
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.8156e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.582961
Average KL loss: 0.397645
Average total loss: 0.980606
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.0612e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.590112
Average KL loss: 0.397638
Average total loss: 0.987750
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(3.2791e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.599327
Average KL loss: 0.397632
Average total loss: 0.996959
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(7.5872e-09, device='cuda:0')
 Percentile value: 0.1419481784105301
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =     774 /    1728             ( 44.79%) | total_pruned =     954 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2159 /   36864             (  5.86%) | total_pruned =   34705 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2609 /   36864             (  7.08%) | total_pruned =   34255 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2315 /   36864             (  6.28%) | total_pruned =   34549 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2204 /   36864             (  5.98%) | total_pruned =   34660 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4105 /   73728             (  5.57%) | total_pruned =   69623 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6699 /  147456             (  4.54%) | total_pruned =  140757 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1368 /    8192             ( 16.70%) | total_pruned =    6824 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3964 /  147456             (  2.69%) | total_pruned =  143492 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3852 /  147456             (  2.61%) | total_pruned =  143604 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   11999 /  294912             (  4.07%) | total_pruned =  282913 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      94 /     256             ( 36.72%) | total_pruned =     162 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   18561 /  589824             (  3.15%) | total_pruned =  571263 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3206 /   32768             (  9.78%) | total_pruned =   29562 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     103 /     256             ( 40.23%) | total_pruned =     153 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    8123 /  589824             (  1.38%) | total_pruned =  581701 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    8028 /  589824             (  1.36%) | total_pruned =  581796 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   27716 / 1179648             (  2.35%) | total_pruned = 1151932 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     176 /     512             ( 34.38%) | total_pruned =     336 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   29804 / 2359296             (  1.26%) | total_pruned = 2329492 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     248 /     512             ( 48.44%) | total_pruned =     264 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3676 /  131072             (  2.80%) | total_pruned =  127396 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     347 /     512             ( 67.77%) | total_pruned =     165 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     261 /     512             ( 50.98%) | total_pruned =     251 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   16625 / 2359296             (  0.70%) | total_pruned = 2342671 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    9621 / 2359296             (  0.41%) | total_pruned = 2349675 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     375 /     512             ( 73.24%) | total_pruned =     137 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
linear.weight        | nonzeros =    1584 /    5120             ( 30.94%) | total_pruned =    3536 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 25/100 Loss: 0.000984 Accuracy: 86.03 100.00 % Best test Accuracy: 86.30%
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-6.6138e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.213690
Average KL loss: 0.371651
Average total loss: 1.585341
tensor(0.0040, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.4388e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.134679
Average KL loss: 0.379317
Average total loss: 1.513996
tensor(0.0040, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1038e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.036532
Average KL loss: 0.392939
Average total loss: 1.429470
tensor(0.0041, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.1323e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.036323
Average KL loss: 0.404508
Average total loss: 1.440831
tensor(0.0041, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-7.6685e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.013273
Average KL loss: 0.415868
Average total loss: 1.429141
tensor(0.0041, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.0263e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.947453
Average KL loss: 0.424838
Average total loss: 1.372291
tensor(0.0041, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.6634e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.940746
Average KL loss: 0.431977
Average total loss: 1.372723
tensor(0.0041, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.3973e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.946852
Average KL loss: 0.439321
Average total loss: 1.386174
tensor(0.0041, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.0748e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.923061
Average KL loss: 0.446111
Average total loss: 1.369171
tensor(0.0041, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.2555e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.919242
Average KL loss: 0.451493
Average total loss: 1.370735
tensor(0.0041, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(3.3920e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.887339
Average KL loss: 0.456615
Average total loss: 1.343955
tensor(0.0041, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.5792e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.865990
Average KL loss: 0.461180
Average total loss: 1.327170
tensor(0.0041, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.4878e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.903858
Average KL loss: 0.465648
Average total loss: 1.369507
tensor(0.0041, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(2.3903e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.852573
Average KL loss: 0.469773
Average total loss: 1.322347
tensor(0.0041, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(8.6087e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.889826
Average KL loss: 0.473206
Average total loss: 1.363032
tensor(0.0041, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.1558e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.862838
Average KL loss: 0.477213
Average total loss: 1.340051
tensor(0.0041, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.1485e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.823015
Average KL loss: 0.480429
Average total loss: 1.303444
tensor(0.0041, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.0457e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.833688
Average KL loss: 0.481689
Average total loss: 1.315377
tensor(0.0041, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.6384e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.841015
Average KL loss: 0.484158
Average total loss: 1.325173
tensor(0.0041, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.8257e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.856731
Average KL loss: 0.486608
Average total loss: 1.343338
tensor(0.0041, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.9740e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.840544
Average KL loss: 0.490368
Average total loss: 1.330913
tensor(0.0041, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.8232e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.826450
Average KL loss: 0.492347
Average total loss: 1.318796
tensor(0.0041, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.5749e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.815448
Average KL loss: 0.494952
Average total loss: 1.310400
tensor(0.0041, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.1785e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.803792
Average KL loss: 0.495692
Average total loss: 1.299484
tensor(0.0041, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.2573e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.792274
Average KL loss: 0.496793
Average total loss: 1.289067
tensor(0.0041, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.4467e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.793208
Average KL loss: 0.496843
Average total loss: 1.290052
tensor(0.0041, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.7851e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.798077
Average KL loss: 0.498292
Average total loss: 1.296370
tensor(0.0041, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.8498e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.796904
Average KL loss: 0.499395
Average total loss: 1.296299
tensor(0.0041, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.7148e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.785045
Average KL loss: 0.501157
Average total loss: 1.286202
tensor(0.0041, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.5631e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.794622
Average KL loss: 0.501731
Average total loss: 1.296352
tensor(0.0041, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.9277e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.804191
Average KL loss: 0.503588
Average total loss: 1.307779
tensor(0.0041, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.5524e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.770433
Average KL loss: 0.505355
Average total loss: 1.275787
tensor(0.0041, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(3.0480e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.804374
Average KL loss: 0.506357
Average total loss: 1.310731
tensor(0.0041, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(9.5521e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.756224
Average KL loss: 0.508528
Average total loss: 1.264752
tensor(0.0041, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.9654e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.786059
Average KL loss: 0.509131
Average total loss: 1.295190
tensor(0.0041, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.4111e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.787397
Average KL loss: 0.510218
Average total loss: 1.297615
tensor(0.0041, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(6.4746e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.761349
Average KL loss: 0.511125
Average total loss: 1.272474
tensor(0.0041, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(3.0281e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.764142
Average KL loss: 0.511419
Average total loss: 1.275562
tensor(0.0041, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.8800e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.774347
Average KL loss: 0.511725
Average total loss: 1.286072
tensor(0.0040, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.3286e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.754923
Average KL loss: 0.512786
Average total loss: 1.267709
tensor(0.0041, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.0473e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.754677
Average KL loss: 0.513650
Average total loss: 1.268327
tensor(0.0040, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.7198e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.767496
Average KL loss: 0.514011
Average total loss: 1.281507
tensor(0.0040, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.1641e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.742647
Average KL loss: 0.514473
Average total loss: 1.257120
tensor(0.0040, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.3912e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.760352
Average KL loss: 0.514637
Average total loss: 1.274989
tensor(0.0040, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(8.1545e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.753228
Average KL loss: 0.515038
Average total loss: 1.268265
tensor(0.0040, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(8.2015e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.755442
Average KL loss: 0.515590
Average total loss: 1.271032
tensor(0.0040, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.0708e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.743827
Average KL loss: 0.515713
Average total loss: 1.259540
tensor(0.0040, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.1612e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.751622
Average KL loss: 0.516633
Average total loss: 1.268255
tensor(0.0040, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.3362e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.742600
Average KL loss: 0.517016
Average total loss: 1.259615
tensor(0.0040, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.2876e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.739010
Average KL loss: 0.517474
Average total loss: 1.256483
tensor(0.0040, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(9.9699e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.767063
Average KL loss: 0.517557
Average total loss: 1.284620
tensor(0.0040, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.2622e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.737946
Average KL loss: 0.518587
Average total loss: 1.256533
tensor(0.0040, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.6432e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.744281
Average KL loss: 0.518167
Average total loss: 1.262448
tensor(0.0040, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.4283e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.735630
Average KL loss: 0.518169
Average total loss: 1.253799
tensor(0.0040, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.5332e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.755965
Average KL loss: 0.518588
Average total loss: 1.274553
tensor(0.0040, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(1.0409e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.741728
Average KL loss: 0.519024
Average total loss: 1.260752
tensor(0.0040, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-8.5102e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.725400
Average KL loss: 0.519091
Average total loss: 1.244491
tensor(0.0040, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.8551e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.735067
Average KL loss: 0.519333
Average total loss: 1.254400
tensor(0.0040, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6882e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.743929
Average KL loss: 0.520313
Average total loss: 1.264242
tensor(0.0040, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.8777e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.746188
Average KL loss: 0.520907
Average total loss: 1.267095
tensor(0.0040, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(8.1346e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.700704
Average KL loss: 0.520531
Average total loss: 1.221236
tensor(0.0040, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1354e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.739565
Average KL loss: 0.519916
Average total loss: 1.259481
tensor(0.0040, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0976e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.716834
Average KL loss: 0.520665
Average total loss: 1.237498
tensor(0.0040, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(7.7399e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.735724
Average KL loss: 0.521078
Average total loss: 1.256802
tensor(0.0040, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.9973e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.727873
Average KL loss: 0.521283
Average total loss: 1.249156
tensor(0.0040, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.4388e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.705869
Average KL loss: 0.521542
Average total loss: 1.227411
tensor(0.0040, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.6603e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.738206
Average KL loss: 0.521788
Average total loss: 1.259995
tensor(0.0040, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.4938e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.708964
Average KL loss: 0.522076
Average total loss: 1.231040
tensor(0.0040, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.4741e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.725511
Average KL loss: 0.522198
Average total loss: 1.247709
tensor(0.0040, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.7091e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.691064
Average KL loss: 0.522484
Average total loss: 1.213548
tensor(0.0040, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.2760e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.718558
Average KL loss: 0.521856
Average total loss: 1.240414
tensor(0.0040, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.6234e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.710512
Average KL loss: 0.522120
Average total loss: 1.232632
tensor(0.0040, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.2280e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.708918
Average KL loss: 0.522476
Average total loss: 1.231394
tensor(0.0040, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.6208e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.714058
Average KL loss: 0.522648
Average total loss: 1.236706
tensor(0.0040, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.4811e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.722405
Average KL loss: 0.522792
Average total loss: 1.245197
tensor(0.0040, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.8875e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.708468
Average KL loss: 0.523209
Average total loss: 1.231677
tensor(0.0040, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.8745e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.733629
Average KL loss: 0.523680
Average total loss: 1.257309
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.6742e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.705097
Average KL loss: 0.524675
Average total loss: 1.229773
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.2680e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.712053
Average KL loss: 0.524914
Average total loss: 1.236967
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.8836e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.702334
Average KL loss: 0.524572
Average total loss: 1.226907
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.5153e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.701208
Average KL loss: 0.524302
Average total loss: 1.225510
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.7768e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.694518
Average KL loss: 0.523841
Average total loss: 1.218359
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.7218e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.708151
Average KL loss: 0.523167
Average total loss: 1.231317
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.9413e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.706879
Average KL loss: 0.522527
Average total loss: 1.229406
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3316e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.716868
Average KL loss: 0.521970
Average total loss: 1.238838
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.5664e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.702924
Average KL loss: 0.521390
Average total loss: 1.224314
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(7.2488e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.701242
Average KL loss: 0.520803
Average total loss: 1.222045
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(8.1324e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.709463
Average KL loss: 0.520209
Average total loss: 1.229671
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.5011e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.705458
Average KL loss: 0.519675
Average total loss: 1.225133
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(6.2932e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.706257
Average KL loss: 0.519160
Average total loss: 1.225416
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.4135e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.712859
Average KL loss: 0.518615
Average total loss: 1.231474
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.1357e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.694405
Average KL loss: 0.518085
Average total loss: 1.212490
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.1844e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.705723
Average KL loss: 0.517562
Average total loss: 1.223285
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.0484e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.694421
Average KL loss: 0.517048
Average total loss: 1.211470
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.4171e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.713108
Average KL loss: 0.516549
Average total loss: 1.229657
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.9280e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.712040
Average KL loss: 0.516090
Average total loss: 1.228130
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.0912e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.697371
Average KL loss: 0.515640
Average total loss: 1.213011
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.1092e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.722572
Average KL loss: 0.515227
Average total loss: 1.237800
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.4306e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.698321
Average KL loss: 0.514773
Average total loss: 1.213094
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.7656e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.693323
Average KL loss: 0.514250
Average total loss: 1.207573
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.5878e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.693616
Average KL loss: 0.513730
Average total loss: 1.207346
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.4551e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.704040
Average KL loss: 0.513234
Average total loss: 1.217274
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.0847e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.682828
Average KL loss: 0.512823
Average total loss: 1.195651
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.8403e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.695123
Average KL loss: 0.512346
Average total loss: 1.207469
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.2578e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.692358
Average KL loss: 0.511903
Average total loss: 1.204261
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(6.5225e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.688890
Average KL loss: 0.511403
Average total loss: 1.200293
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.8490e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.685095
Average KL loss: 0.510905
Average total loss: 1.196000
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.3202e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.685323
Average KL loss: 0.510507
Average total loss: 1.195829
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.5248e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.708799
Average KL loss: 0.510064
Average total loss: 1.218862
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.5843e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.677622
Average KL loss: 0.509740
Average total loss: 1.187362
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.9280e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.687904
Average KL loss: 0.509372
Average total loss: 1.197275
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.2114e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.713667
Average KL loss: 0.508985
Average total loss: 1.222652
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.5216e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.708047
Average KL loss: 0.508666
Average total loss: 1.216713
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.4002e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.702942
Average KL loss: 0.508326
Average total loss: 1.211268
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.4866e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.704216
Average KL loss: 0.507969
Average total loss: 1.212185
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.3472e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.684256
Average KL loss: 0.507624
Average total loss: 1.191880
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.8844e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.681164
Average KL loss: 0.507274
Average total loss: 1.188438
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(6.8874e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.709091
Average KL loss: 0.506925
Average total loss: 1.216016
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.0444e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.715069
Average KL loss: 0.506684
Average total loss: 1.221754
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.4959e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.707652
Average KL loss: 0.506479
Average total loss: 1.214131
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.6770e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.682142
Average KL loss: 0.506246
Average total loss: 1.188388
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.7049e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.715030
Average KL loss: 0.506055
Average total loss: 1.221085
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.6123e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.683636
Average KL loss: 0.506016
Average total loss: 1.189652
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(7.4653e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.699041
Average KL loss: 0.505970
Average total loss: 1.205011
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(9.4250e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.691878
Average KL loss: 0.505927
Average total loss: 1.197805
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.1293e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.696616
Average KL loss: 0.505890
Average total loss: 1.202506
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.3287e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.705907
Average KL loss: 0.505855
Average total loss: 1.211761
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.0741e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.715783
Average KL loss: 0.505821
Average total loss: 1.221604
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.3651e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.704658
Average KL loss: 0.505782
Average total loss: 1.210441
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(7.4948e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.698202
Average KL loss: 0.505742
Average total loss: 1.203944
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.2240e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.708909
Average KL loss: 0.505707
Average total loss: 1.214616
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(6.8908e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.665334
Average KL loss: 0.505669
Average total loss: 1.171002
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.9833e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.690466
Average KL loss: 0.505618
Average total loss: 1.196083
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.5793e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.680535
Average KL loss: 0.505573
Average total loss: 1.186108
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.2798e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.690862
Average KL loss: 0.505526
Average total loss: 1.196388
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.3304e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.693149
Average KL loss: 0.505487
Average total loss: 1.198636
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.6887e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.704688
Average KL loss: 0.505441
Average total loss: 1.210129
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.4766e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.677330
Average KL loss: 0.505396
Average total loss: 1.182725
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.0265e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.697983
Average KL loss: 0.505353
Average total loss: 1.203337
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.2798e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.680457
Average KL loss: 0.505307
Average total loss: 1.185764
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.4786e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.684658
Average KL loss: 0.505264
Average total loss: 1.189922
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.1605e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.675508
Average KL loss: 0.505220
Average total loss: 1.180729
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.0765e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.701986
Average KL loss: 0.505174
Average total loss: 1.207160
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.2519e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.684288
Average KL loss: 0.505151
Average total loss: 1.189440
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.3412e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.685533
Average KL loss: 0.505146
Average total loss: 1.190679
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.0865e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.689785
Average KL loss: 0.505141
Average total loss: 1.194926
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.4000e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.685735
Average KL loss: 0.505137
Average total loss: 1.190872
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.1171e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.706804
Average KL loss: 0.505133
Average total loss: 1.211937
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.4471e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.697767
Average KL loss: 0.505130
Average total loss: 1.202896
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.7187e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.706183
Average KL loss: 0.505126
Average total loss: 1.211309
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.4929e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.692683
Average KL loss: 0.505122
Average total loss: 1.197805
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.9685e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.679332
Average KL loss: 0.505117
Average total loss: 1.184449
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.7183e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.694732
Average KL loss: 0.505113
Average total loss: 1.199846
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.9411e-10, device='cuda:0')
 Percentile value: 0.29896822571754456
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =     704 /    1728             ( 40.74%) | total_pruned =    1024 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1449 /   36864             (  3.93%) | total_pruned =   35415 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1814 /   36864             (  4.92%) | total_pruned =   35050 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1532 /   36864             (  4.16%) | total_pruned =   35332 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1515 /   36864             (  4.11%) | total_pruned =   35349 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2737 /   73728             (  3.71%) | total_pruned =   70991 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4061 /  147456             (  2.75%) | total_pruned =  143395 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1088 /    8192             ( 13.28%) | total_pruned =    7104 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2167 /  147456             (  1.47%) | total_pruned =  145289 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1989 /  147456             (  1.35%) | total_pruned =  145467 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7039 /  294912             (  2.39%) | total_pruned =  287873 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      72 /     256             ( 28.12%) | total_pruned =     184 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    9879 /  589824             (  1.67%) | total_pruned =  579945 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      68 /     256             ( 26.56%) | total_pruned =     188 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2181 /   32768             (  6.66%) | total_pruned =   30587 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3505 /  589824             (  0.59%) | total_pruned =  586319 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     200 /     256             ( 78.12%) | total_pruned =      56 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3368 /  589824             (  0.57%) | total_pruned =  586456 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   13151 / 1179648             (  1.11%) | total_pruned = 1166497 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     113 /     512             ( 22.07%) | total_pruned =     399 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   11823 / 2359296             (  0.50%) | total_pruned = 2347473 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     466 /     512             ( 91.02%) | total_pruned =      46 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     220 /     512             ( 42.97%) | total_pruned =     292 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1846 /  131072             (  1.41%) | total_pruned =  129226 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     289 /     512             ( 56.45%) | total_pruned =     223 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     228 /     512             ( 44.53%) | total_pruned =     284 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    6083 / 2359296             (  0.26%) | total_pruned = 2353213 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     361 /     512             ( 70.51%) | total_pruned =     151 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    3200 / 2359296             (  0.14%) | total_pruned = 2356096 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     225 /     512             ( 43.95%) | total_pruned =     287 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
linear.weight        | nonzeros =    1158 /    5120             ( 22.62%) | total_pruned =    3962 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 30/100 Loss: 0.007031 Accuracy: 84.68 100.00 % Best test Accuracy: 85.21%
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.5593e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.554712
Average KL loss: 0.474593
Average total loss: 2.029305
tensor(0.0041, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.3111e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.513356
Average KL loss: 0.472178
Average total loss: 1.985534
tensor(0.0041, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.9879e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.384298
Average KL loss: 0.481705
Average total loss: 1.866003
tensor(0.0042, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.8546e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.328496
Average KL loss: 0.491780
Average total loss: 1.820276
tensor(0.0042, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.9750e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.308749
Average KL loss: 0.501585
Average total loss: 1.810334
tensor(0.0042, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.5049e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.294485
Average KL loss: 0.511249
Average total loss: 1.805735
tensor(0.0043, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.8761e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.259446
Average KL loss: 0.520751
Average total loss: 1.780197
tensor(0.0043, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.8273e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.220894
Average KL loss: 0.529234
Average total loss: 1.750128
tensor(0.0043, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.7393e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.187116
Average KL loss: 0.537314
Average total loss: 1.724430
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.6007e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.218176
Average KL loss: 0.543846
Average total loss: 1.762023
tensor(0.0043, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.8648e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.123985
Average KL loss: 0.550597
Average total loss: 1.674582
tensor(0.0043, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.0661e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.137435
Average KL loss: 0.556337
Average total loss: 1.693772
tensor(0.0044, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.6958e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.100970
Average KL loss: 0.561637
Average total loss: 1.662607
tensor(0.0044, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.2691e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.091532
Average KL loss: 0.566406
Average total loss: 1.657938
tensor(0.0044, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.3968e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.105758
Average KL loss: 0.571489
Average total loss: 1.677247
tensor(0.0044, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.9343e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.112144
Average KL loss: 0.576865
Average total loss: 1.689010
tensor(0.0044, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.9008e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.061899
Average KL loss: 0.581794
Average total loss: 1.643693
tensor(0.0044, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.1178e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.051907
Average KL loss: 0.585839
Average total loss: 1.637745
tensor(0.0044, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.0822e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.060752
Average KL loss: 0.589205
Average total loss: 1.649957
tensor(0.0044, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.9485e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.044792
Average KL loss: 0.592630
Average total loss: 1.637422
tensor(0.0044, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.3143e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.019294
Average KL loss: 0.595502
Average total loss: 1.614796
tensor(0.0044, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.7496e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.028505
Average KL loss: 0.598663
Average total loss: 1.627168
tensor(0.0044, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.3845e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.994496
Average KL loss: 0.601919
Average total loss: 1.596415
tensor(0.0044, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.9333e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.006144
Average KL loss: 0.605029
Average total loss: 1.611173
tensor(0.0044, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-8.8219e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.988029
Average KL loss: 0.607787
Average total loss: 1.595815
tensor(0.0044, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(3.4234e-11, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.981860
Average KL loss: 0.610183
Average total loss: 1.592043
tensor(0.0044, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.2940e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.980615
Average KL loss: 0.612138
Average total loss: 1.592753
tensor(0.0044, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-4.5409e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.991638
Average KL loss: 0.614331
Average total loss: 1.605968
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.4431e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.970362
Average KL loss: 0.616642
Average total loss: 1.587004
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-3.0845e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.985124
Average KL loss: 0.619225
Average total loss: 1.604350
tensor(0.0044, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.8530e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.959911
Average KL loss: 0.621264
Average total loss: 1.581176
tensor(0.0044, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.8905e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.935734
Average KL loss: 0.623207
Average total loss: 1.558942
tensor(0.0045, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(2.2002e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.971218
Average KL loss: 0.624618
Average total loss: 1.595837
tensor(0.0045, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(3.0746e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.912873
Average KL loss: 0.625958
Average total loss: 1.538831
tensor(0.0044, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(1.9835e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.950205
Average KL loss: 0.627004
Average total loss: 1.577209
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-3.4603e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.922241
Average KL loss: 0.628219
Average total loss: 1.550460
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-3.9974e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.935002
Average KL loss: 0.629158
Average total loss: 1.564160
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(2.1662e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.956758
Average KL loss: 0.630841
Average total loss: 1.587599
tensor(0.0044, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.3860e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.948750
Average KL loss: 0.633772
Average total loss: 1.582522
tensor(0.0045, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.0247e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.903402
Average KL loss: 0.635559
Average total loss: 1.538961
tensor(0.0045, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.4669e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.899526
Average KL loss: 0.636690
Average total loss: 1.536216
tensor(0.0045, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.6517e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.903569
Average KL loss: 0.637611
Average total loss: 1.541180
tensor(0.0045, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.3764e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.909584
Average KL loss: 0.638148
Average total loss: 1.547732
tensor(0.0045, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-9.7104e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.897191
Average KL loss: 0.639506
Average total loss: 1.536698
tensor(0.0045, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.3135e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.893839
Average KL loss: 0.640624
Average total loss: 1.534463
tensor(0.0045, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-9.4213e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.889839
Average KL loss: 0.641563
Average total loss: 1.531402
tensor(0.0045, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.6087e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.903630
Average KL loss: 0.642319
Average total loss: 1.545950
tensor(0.0045, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.1565e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.907284
Average KL loss: 0.643697
Average total loss: 1.550981
tensor(0.0045, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.4256e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.927590
Average KL loss: 0.645139
Average total loss: 1.572729
tensor(0.0045, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(1.8377e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.907134
Average KL loss: 0.646637
Average total loss: 1.553771
tensor(0.0045, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.4295e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.872281
Average KL loss: 0.647117
Average total loss: 1.519397
tensor(0.0045, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.7030e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.885208
Average KL loss: 0.648003
Average total loss: 1.533212
tensor(0.0045, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(8.7693e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.878285
Average KL loss: 0.648678
Average total loss: 1.526963
tensor(0.0045, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(1.4421e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.853601
Average KL loss: 0.649588
Average total loss: 1.503190
tensor(0.0045, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.9003e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.859851
Average KL loss: 0.650030
Average total loss: 1.509881
tensor(0.0045, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(7.3572e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.867853
Average KL loss: 0.650420
Average total loss: 1.518273
tensor(0.0045, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.4458e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.890217
Average KL loss: 0.651084
Average total loss: 1.541301
tensor(0.0045, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-8.6396e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.858568
Average KL loss: 0.652674
Average total loss: 1.511242
tensor(0.0045, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.2632e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.868951
Average KL loss: 0.653402
Average total loss: 1.522353
tensor(0.0045, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.9596e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.855683
Average KL loss: 0.653549
Average total loss: 1.509232
tensor(0.0045, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.0638e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.848708
Average KL loss: 0.653648
Average total loss: 1.502356
tensor(0.0045, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.4661e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.861302
Average KL loss: 0.654907
Average total loss: 1.516210
tensor(0.0045, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(5.0661e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.884871
Average KL loss: 0.655959
Average total loss: 1.540831
tensor(0.0045, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-5.1887e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.866904
Average KL loss: 0.657348
Average total loss: 1.524251
tensor(0.0045, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(1.9046e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.828475
Average KL loss: 0.658215
Average total loss: 1.486691
tensor(0.0045, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-2.4980e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.843478
Average KL loss: 0.658157
Average total loss: 1.501635
tensor(0.0045, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(1.5804e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.846192
Average KL loss: 0.658295
Average total loss: 1.504488
tensor(0.0045, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(2.0898e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.848390
Average KL loss: 0.659697
Average total loss: 1.508087
tensor(0.0045, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-4.3445e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.817748
Average KL loss: 0.660003
Average total loss: 1.477751
tensor(0.0045, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-3.6500e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.842562
Average KL loss: 0.659350
Average total loss: 1.501912
tensor(0.0045, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(2.2541e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.798821
Average KL loss: 0.659805
Average total loss: 1.458626
tensor(0.0045, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-8.9131e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.831286
Average KL loss: 0.659538
Average total loss: 1.490824
tensor(0.0044, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(1.7508e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.847178
Average KL loss: 0.659246
Average total loss: 1.506425
tensor(0.0044, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(2.5497e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.843154
Average KL loss: 0.660125
Average total loss: 1.503278
tensor(0.0044, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.5800e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.811401
Average KL loss: 0.661172
Average total loss: 1.472573
tensor(0.0045, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-7.7151e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.802675
Average KL loss: 0.661792
Average total loss: 1.464466
tensor(0.0044, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-5.8304e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.838973
Average KL loss: 0.661370
Average total loss: 1.500343
tensor(0.0044, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.1981e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.810592
Average KL loss: 0.661337
Average total loss: 1.471929
tensor(0.0044, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(7.9028e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.823944
Average KL loss: 0.661785
Average total loss: 1.485729
tensor(0.0044, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(2.5071e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.813111
Average KL loss: 0.662001
Average total loss: 1.475112
tensor(0.0044, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-4.3117e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.816922
Average KL loss: 0.662027
Average total loss: 1.478949
tensor(0.0044, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-9.8849e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.818095
Average KL loss: 0.662160
Average total loss: 1.480255
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(5.7377e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.806075
Average KL loss: 0.662592
Average total loss: 1.468667
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.7017e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.819652
Average KL loss: 0.662274
Average total loss: 1.481926
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.2565e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.812978
Average KL loss: 0.661944
Average total loss: 1.474921
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(2.5606e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.839878
Average KL loss: 0.661693
Average total loss: 1.501571
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.3584e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.835560
Average KL loss: 0.661537
Average total loss: 1.497097
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.2905e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.799755
Average KL loss: 0.661349
Average total loss: 1.461104
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(8.6553e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.812002
Average KL loss: 0.661082
Average total loss: 1.473084
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(7.0687e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.824297
Average KL loss: 0.660836
Average total loss: 1.485134
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.5359e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.789987
Average KL loss: 0.660599
Average total loss: 1.450586
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-5.6171e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.819541
Average KL loss: 0.660316
Average total loss: 1.479857
tensor(0.0044, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-6.2136e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.839756
Average KL loss: 0.660090
Average total loss: 1.499846
tensor(0.0044, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-9.3382e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.810042
Average KL loss: 0.659889
Average total loss: 1.469931
tensor(0.0044, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.6329e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.814365
Average KL loss: 0.659693
Average total loss: 1.474058
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-5.8758e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.822744
Average KL loss: 0.659514
Average total loss: 1.482258
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-7.9535e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.808713
Average KL loss: 0.659342
Average total loss: 1.468055
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.1780e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.794717
Average KL loss: 0.659104
Average total loss: 1.453821
tensor(0.0044, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(1.5466e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.799374
Average KL loss: 0.658882
Average total loss: 1.458256
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.7329e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.819137
Average KL loss: 0.658676
Average total loss: 1.477813
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-4.4250e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.787554
Average KL loss: 0.658542
Average total loss: 1.446096
tensor(0.0044, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.6424e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.809888
Average KL loss: 0.658292
Average total loss: 1.468180
tensor(0.0044, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(7.9008e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.800938
Average KL loss: 0.658066
Average total loss: 1.459004
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-6.1268e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.817231
Average KL loss: 0.657918
Average total loss: 1.475148
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-5.2193e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.810819
Average KL loss: 0.657776
Average total loss: 1.468595
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.3396e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.810372
Average KL loss: 0.657573
Average total loss: 1.467945
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.9079e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.840913
Average KL loss: 0.657386
Average total loss: 1.498299
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.1775e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.806944
Average KL loss: 0.657268
Average total loss: 1.464212
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.1821e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.790969
Average KL loss: 0.657082
Average total loss: 1.448051
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-4.1227e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.820170
Average KL loss: 0.656861
Average total loss: 1.477031
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(9.9562e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.817596
Average KL loss: 0.656721
Average total loss: 1.474317
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.2606e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.835034
Average KL loss: 0.656593
Average total loss: 1.491628
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.2482e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.806077
Average KL loss: 0.656492
Average total loss: 1.462568
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-8.0082e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.816982
Average KL loss: 0.656473
Average total loss: 1.473455
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(9.4645e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.781416
Average KL loss: 0.656453
Average total loss: 1.437869
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.7822e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.819893
Average KL loss: 0.656427
Average total loss: 1.476321
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.8967e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.804851
Average KL loss: 0.656412
Average total loss: 1.461263
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-7.6796e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.811998
Average KL loss: 0.656388
Average total loss: 1.468386
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-6.2208e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.810686
Average KL loss: 0.656367
Average total loss: 1.467054
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.8452e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.794459
Average KL loss: 0.656345
Average total loss: 1.450804
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.2172e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.805161
Average KL loss: 0.656329
Average total loss: 1.461490
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.5274e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.798240
Average KL loss: 0.656309
Average total loss: 1.454549
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.1730e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.790909
Average KL loss: 0.656289
Average total loss: 1.447198
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(2.4832e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.793650
Average KL loss: 0.656269
Average total loss: 1.449919
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-9.6773e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.797232
Average KL loss: 0.656245
Average total loss: 1.453477
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(7.1500e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.799751
Average KL loss: 0.656224
Average total loss: 1.455975
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.5966e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.812790
Average KL loss: 0.656212
Average total loss: 1.469002
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-9.5749e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.788420
Average KL loss: 0.656209
Average total loss: 1.444629
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(6.9894e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.805902
Average KL loss: 0.656207
Average total loss: 1.462109
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.9004e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.797045
Average KL loss: 0.656205
Average total loss: 1.453250
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(6.7853e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.819182
Average KL loss: 0.656202
Average total loss: 1.475384
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.4994e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.805603
Average KL loss: 0.656200
Average total loss: 1.461804
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(6.0337e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.798607
Average KL loss: 0.656199
Average total loss: 1.454805
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-4.3067e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.817504
Average KL loss: 0.656197
Average total loss: 1.473701
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.8861e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.815015
Average KL loss: 0.656194
Average total loss: 1.471210
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(5.8999e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.791568
Average KL loss: 0.656192
Average total loss: 1.447760
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.1136e-08, device='cuda:0')
 Percentile value: 0.7446130514144897
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =     639 /    1728             ( 36.98%) | total_pruned =    1089 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     962 /   36864             (  2.61%) | total_pruned =   35902 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1210 /   36864             (  3.28%) | total_pruned =   35654 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     980 /   36864             (  2.66%) | total_pruned =   35884 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     981 /   36864             (  2.66%) | total_pruned =   35883 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1733 /   73728             (  2.35%) | total_pruned =   71995 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2347 /  147456             (  1.59%) | total_pruned =  145109 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     842 /    8192             ( 10.28%) | total_pruned =    7350 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1123 /  147456             (  0.76%) | total_pruned =  146333 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1015 /  147456             (  0.69%) | total_pruned =  146441 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3808 /  294912             (  1.29%) | total_pruned =  291104 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      57 /     256             ( 22.27%) | total_pruned =     199 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4765 /  589824             (  0.81%) | total_pruned =  585059 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1337 /   32768             (  4.08%) | total_pruned =   31431 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1416 /  589824             (  0.24%) | total_pruned =  588408 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1411 /  589824             (  0.24%) | total_pruned =  588413 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    5572 / 1179648             (  0.47%) | total_pruned = 1174076 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      71 /     512             ( 13.87%) | total_pruned =     441 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4479 / 2359296             (  0.19%) | total_pruned = 2354817 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     423 /     512             ( 82.62%) | total_pruned =      89 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     163 /     512             ( 31.84%) | total_pruned =     349 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     756 /  131072             (  0.58%) | total_pruned =  130316 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     232 /     512             ( 45.31%) | total_pruned =     280 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     166 /     512             ( 32.42%) | total_pruned =     346 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2126 / 2359296             (  0.09%) | total_pruned = 2357170 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     295 /     512             ( 57.62%) | total_pruned =     217 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      37 /     512             (  7.23%) | total_pruned =     475 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     962 / 2359296             (  0.04%) | total_pruned = 2358334 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     124 /     512             ( 24.22%) | total_pruned =     388 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     813 /    5120             ( 15.88%) | total_pruned =    4307 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 46/100 Loss: 0.008106 Accuracy: 82.91 100.00 % Best test Accuracy: 83.78%
tensor(0.0044, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.0030e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.051273
Average KL loss: 0.621699
Average total loss: 2.672972
tensor(0.0043, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.3217e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.957125
Average KL loss: 0.610022
Average total loss: 2.567147
tensor(0.0043, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.0576e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.889983
Average KL loss: 0.612615
Average total loss: 2.502598
tensor(0.0044, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.3217e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.829317
Average KL loss: 0.618269
Average total loss: 2.447586
tensor(0.0044, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.2674e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.693518
Average KL loss: 0.624432
Average total loss: 2.317950
tensor(0.0044, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-6.1103e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.658202
Average KL loss: 0.630283
Average total loss: 2.288485
tensor(0.0044, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-9.9079e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.630748
Average KL loss: 0.636190
Average total loss: 2.266938
tensor(0.0044, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.6131e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.595844
Average KL loss: 0.641932
Average total loss: 2.237776
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-4.9408e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.585336
Average KL loss: 0.647584
Average total loss: 2.232920
tensor(0.0045, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.3285e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.541869
Average KL loss: 0.653009
Average total loss: 2.194878
tensor(0.0045, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-4.8199e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.528677
Average KL loss: 0.658728
Average total loss: 2.187405
tensor(0.0045, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-7.1069e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.468120
Average KL loss: 0.664276
Average total loss: 2.132396
tensor(0.0045, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.9649e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.451396
Average KL loss: 0.668907
Average total loss: 2.120303
tensor(0.0045, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-5.1133e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.424838
Average KL loss: 0.673307
Average total loss: 2.098145
tensor(0.0045, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.2895e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.415349
Average KL loss: 0.677892
Average total loss: 2.093241
tensor(0.0045, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-3.5917e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.412591
Average KL loss: 0.682633
Average total loss: 2.095223
tensor(0.0046, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-8.3668e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.387717
Average KL loss: 0.687070
Average total loss: 2.074787
tensor(0.0046, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-7.6162e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.336458
Average KL loss: 0.691014
Average total loss: 2.027472
tensor(0.0046, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.4327e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.351804
Average KL loss: 0.694836
Average total loss: 2.046640
tensor(0.0046, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.5817e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.361758
Average KL loss: 0.698475
Average total loss: 2.060233
tensor(0.0046, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-8.2793e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.330729
Average KL loss: 0.702536
Average total loss: 2.033265
tensor(0.0046, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.5039e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.312889
Average KL loss: 0.706124
Average total loss: 2.019013
tensor(0.0046, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.6666e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.286793
Average KL loss: 0.709941
Average total loss: 1.996734
tensor(0.0046, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-6.3643e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.303162
Average KL loss: 0.713411
Average total loss: 2.016573
tensor(0.0046, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-3.7519e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.270797
Average KL loss: 0.716905
Average total loss: 1.987702
tensor(0.0047, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.7733e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.297213
Average KL loss: 0.720135
Average total loss: 2.017349
tensor(0.0047, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.9816e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.238747
Average KL loss: 0.723137
Average total loss: 1.961884
tensor(0.0047, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.0386e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.247957
Average KL loss: 0.725784
Average total loss: 1.973741
tensor(0.0047, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.1716e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.219243
Average KL loss: 0.728387
Average total loss: 1.947631
tensor(0.0047, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.4301e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.197303
Average KL loss: 0.731244
Average total loss: 1.928548
tensor(0.0047, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.6406e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.226324
Average KL loss: 0.734033
Average total loss: 1.960357
tensor(0.0047, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.7813e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.223666
Average KL loss: 0.737357
Average total loss: 1.961023
tensor(0.0047, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.4401e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.178734
Average KL loss: 0.740420
Average total loss: 1.919154
tensor(0.0047, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.1684e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.177674
Average KL loss: 0.742709
Average total loss: 1.920383
tensor(0.0047, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.8825e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.149408
Average KL loss: 0.745039
Average total loss: 1.894447
tensor(0.0047, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.8937e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.171085
Average KL loss: 0.746857
Average total loss: 1.917942
tensor(0.0047, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.6986e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.144186
Average KL loss: 0.749031
Average total loss: 1.893217
tensor(0.0047, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.6882e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.166300
Average KL loss: 0.751242
Average total loss: 1.917542
tensor(0.0047, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.1492e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.156698
Average KL loss: 0.753294
Average total loss: 1.909992
tensor(0.0048, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.3377e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.139242
Average KL loss: 0.755534
Average total loss: 1.894777
tensor(0.0048, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.5953e-11, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.123872
Average KL loss: 0.757758
Average total loss: 1.881631
tensor(0.0048, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-5.3283e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.130910
Average KL loss: 0.759929
Average total loss: 1.890839
tensor(0.0048, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.8913e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.105009
Average KL loss: 0.762109
Average total loss: 1.867118
tensor(0.0048, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.7362e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.076261
Average KL loss: 0.763812
Average total loss: 1.840073
tensor(0.0048, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.3041e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.099307
Average KL loss: 0.765870
Average total loss: 1.865177
tensor(0.0048, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(4.0564e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.081958
Average KL loss: 0.767535
Average total loss: 1.849493
tensor(0.0048, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.7139e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.096960
Average KL loss: 0.769702
Average total loss: 1.866662
tensor(0.0048, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-4.6337e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.086225
Average KL loss: 0.771551
Average total loss: 1.857776
tensor(0.0048, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.1095e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.063818
Average KL loss: 0.773318
Average total loss: 1.837136
tensor(0.0048, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.1791e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.076996
Average KL loss: 0.774830
Average total loss: 1.851825
tensor(0.0048, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.1372e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.059859
Average KL loss: 0.776506
Average total loss: 1.836366
tensor(0.0048, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(9.3032e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.033947
Average KL loss: 0.777895
Average total loss: 1.811842
tensor(0.0048, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.7766e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.020875
Average KL loss: 0.779200
Average total loss: 1.800075
tensor(0.0048, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-7.2550e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.029755
Average KL loss: 0.780426
Average total loss: 1.810181
tensor(0.0048, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.6951e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.047979
Average KL loss: 0.782100
Average total loss: 1.830079
tensor(0.0048, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.4524e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.012791
Average KL loss: 0.783040
Average total loss: 1.795830
tensor(0.0048, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.0886e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.027057
Average KL loss: 0.784129
Average total loss: 1.811185
tensor(0.0048, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-4.4463e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.018410
Average KL loss: 0.785260
Average total loss: 1.803670
tensor(0.0049, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-7.5377e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.009811
Average KL loss: 0.786617
Average total loss: 1.796428
tensor(0.0049, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-5.0637e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.005875
Average KL loss: 0.787474
Average total loss: 1.793350
tensor(0.0049, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.9069e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.012917
Average KL loss: 0.788497
Average total loss: 1.801414
tensor(0.0049, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.1296e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.012848
Average KL loss: 0.789715
Average total loss: 1.802563
tensor(0.0049, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.1557e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.006030
Average KL loss: 0.791428
Average total loss: 1.797457
tensor(0.0049, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.6368e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.015872
Average KL loss: 0.792666
Average total loss: 1.808538
tensor(0.0049, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-7.0392e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.004790
Average KL loss: 0.793839
Average total loss: 1.798630
tensor(0.0049, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-9.4851e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.989899
Average KL loss: 0.795139
Average total loss: 1.785038
tensor(0.0049, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.2595e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.978478
Average KL loss: 0.796541
Average total loss: 1.775019
tensor(0.0049, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-5.0658e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.989442
Average KL loss: 0.797683
Average total loss: 1.787125
tensor(0.0049, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.9961e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.959704
Average KL loss: 0.798517
Average total loss: 1.758221
tensor(0.0049, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.3883e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.988063
Average KL loss: 0.799722
Average total loss: 1.787784
tensor(0.0049, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.8012e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.958520
Average KL loss: 0.800792
Average total loss: 1.759312
tensor(0.0049, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.9712e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.946097
Average KL loss: 0.801570
Average total loss: 1.747667
tensor(0.0049, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-5.0988e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.957132
Average KL loss: 0.802469
Average total loss: 1.759601
tensor(0.0049, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(8.7158e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.941357
Average KL loss: 0.803092
Average total loss: 1.744448
tensor(0.0049, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.0408e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.952483
Average KL loss: 0.804275
Average total loss: 1.756758
tensor(0.0049, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-5.2499e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.935342
Average KL loss: 0.805180
Average total loss: 1.740521
tensor(0.0049, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.2890e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.931399
Average KL loss: 0.806188
Average total loss: 1.737587
tensor(0.0049, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-3.3551e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.930474
Average KL loss: 0.806871
Average total loss: 1.737345
tensor(0.0049, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.7454e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.950429
Average KL loss: 0.807851
Average total loss: 1.758280
tensor(0.0049, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.3917e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.917994
Average KL loss: 0.808493
Average total loss: 1.726487
tensor(0.0049, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.7650e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.936958
Average KL loss: 0.809166
Average total loss: 1.746124
tensor(0.0049, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.9585e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.943458
Average KL loss: 0.810381
Average total loss: 1.753839
tensor(0.0049, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.8420e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.943353
Average KL loss: 0.811454
Average total loss: 1.754808
tensor(0.0049, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.1760e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.934242
Average KL loss: 0.812675
Average total loss: 1.746917
tensor(0.0050, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.0310e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.924664
Average KL loss: 0.813409
Average total loss: 1.738073
tensor(0.0050, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.1983e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.924769
Average KL loss: 0.814581
Average total loss: 1.739350
tensor(0.0050, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.2709e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.949612
Average KL loss: 0.815569
Average total loss: 1.765181
tensor(0.0050, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.6568e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.915855
Average KL loss: 0.816363
Average total loss: 1.732219
tensor(0.0050, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-7.7490e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.918253
Average KL loss: 0.817045
Average total loss: 1.735298
tensor(0.0050, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.5130e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.909133
Average KL loss: 0.817875
Average total loss: 1.727008
tensor(0.0050, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-4.0717e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.900250
Average KL loss: 0.818549
Average total loss: 1.718799
tensor(0.0050, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4083e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.888458
Average KL loss: 0.818725
Average total loss: 1.707183
tensor(0.0050, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-4.8158e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.874882
Average KL loss: 0.819042
Average total loss: 1.693924
tensor(0.0050, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.7339e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.890760
Average KL loss: 0.819363
Average total loss: 1.710123
tensor(0.0050, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.7618e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.929514
Average KL loss: 0.820355
Average total loss: 1.749869
tensor(0.0050, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.2028e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.902162
Average KL loss: 0.821319
Average total loss: 1.723481
tensor(0.0050, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(9.3020e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.883443
Average KL loss: 0.822107
Average total loss: 1.705550
tensor(0.0050, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.0796e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.889112
Average KL loss: 0.822412
Average total loss: 1.711524
tensor(0.0050, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-4.0501e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.877905
Average KL loss: 0.823111
Average total loss: 1.701016
tensor(0.0050, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-1.5639e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.889609
Average KL loss: 0.824006
Average total loss: 1.713614
tensor(0.0050, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-1.8383e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.868188
Average KL loss: 0.824644
Average total loss: 1.692832
tensor(0.0050, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-2.2304e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.861101
Average KL loss: 0.825153
Average total loss: 1.686254
tensor(0.0050, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(6.1115e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.861844
Average KL loss: 0.825580
Average total loss: 1.687424
tensor(0.0050, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-2.2506e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.846213
Average KL loss: 0.826134
Average total loss: 1.672347
tensor(0.0050, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-8.0613e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.873298
Average KL loss: 0.826607
Average total loss: 1.699905
tensor(0.0050, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(2.3025e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.866353
Average KL loss: 0.827135
Average total loss: 1.693487
tensor(0.0050, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-2.4837e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.853717
Average KL loss: 0.827560
Average total loss: 1.681277
tensor(0.0050, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-8.1536e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.858984
Average KL loss: 0.828104
Average total loss: 1.687088
tensor(0.0050, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(3.8407e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.844457
Average KL loss: 0.828438
Average total loss: 1.672895
tensor(0.0050, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-2.0915e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.849380
Average KL loss: 0.828722
Average total loss: 1.678102
tensor(0.0050, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(2.5336e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.854755
Average KL loss: 0.829379
Average total loss: 1.684134
tensor(0.0050, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.2815e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.854462
Average KL loss: 0.830111
Average total loss: 1.684573
tensor(0.0050, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(2.2001e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.858940
Average KL loss: 0.830374
Average total loss: 1.689315
tensor(0.0050, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(3.5608e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.826192
Average KL loss: 0.830523
Average total loss: 1.656715
tensor(0.0050, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(6.3651e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.845450
Average KL loss: 0.831046
Average total loss: 1.676496
tensor(0.0050, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-4.0421e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.841888
Average KL loss: 0.831848
Average total loss: 1.673737
tensor(0.0050, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-9.3829e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.834638
Average KL loss: 0.832328
Average total loss: 1.666966
tensor(0.0050, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-3.1443e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.834808
Average KL loss: 0.832759
Average total loss: 1.667568
tensor(0.0050, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-9.2150e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.819255
Average KL loss: 0.833223
Average total loss: 1.652477
tensor(0.0050, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-3.4484e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.839367
Average KL loss: 0.833535
Average total loss: 1.672902
tensor(0.0051, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-7.3725e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.820343
Average KL loss: 0.834236
Average total loss: 1.654579
tensor(0.0051, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-2.3335e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.831622
Average KL loss: 0.834538
Average total loss: 1.666160
tensor(0.0051, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-9.4696e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.824833
Average KL loss: 0.834897
Average total loss: 1.659731
tensor(0.0051, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-1.7697e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.836504
Average KL loss: 0.835669
Average total loss: 1.672172
tensor(0.0051, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-8.5887e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.831634
Average KL loss: 0.836003
Average total loss: 1.667638
tensor(0.0051, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.7461e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.815626
Average KL loss: 0.836317
Average total loss: 1.651944
tensor(0.0051, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(3.7579e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.813790
Average KL loss: 0.836548
Average total loss: 1.650338
tensor(0.0051, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(6.0216e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.816452
Average KL loss: 0.836564
Average total loss: 1.653016
tensor(0.0051, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-4.6379e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.797753
Average KL loss: 0.836770
Average total loss: 1.634523
tensor(0.0051, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-5.2159e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.825024
Average KL loss: 0.836980
Average total loss: 1.662004
tensor(0.0051, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(1.5270e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.820548
Average KL loss: 0.837123
Average total loss: 1.657670
tensor(0.0051, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-2.1251e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.817887
Average KL loss: 0.837821
Average total loss: 1.655708
tensor(0.0051, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-1.1608e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.797817
Average KL loss: 0.838223
Average total loss: 1.636040
tensor(0.0051, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-1.2260e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.808082
Average KL loss: 0.838410
Average total loss: 1.646492
tensor(0.0051, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-3.5722e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.805930
Average KL loss: 0.839000
Average total loss: 1.644929
tensor(0.0051, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-1.2621e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.782649
Average KL loss: 0.839272
Average total loss: 1.621921
tensor(0.0051, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-1.4165e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.797531
Average KL loss: 0.839380
Average total loss: 1.636910
tensor(0.0051, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-1.4958e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.795779
Average KL loss: 0.839939
Average total loss: 1.635718
tensor(0.0051, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(3.2534e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.808526
Average KL loss: 0.840383
Average total loss: 1.648909
tensor(0.0051, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-8.5807e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.808746
Average KL loss: 0.841135
Average total loss: 1.649881
tensor(0.0051, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.0410e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.790560
Average KL loss: 0.841488
Average total loss: 1.632048
tensor(0.0051, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.2651e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.770090
Average KL loss: 0.841696
Average total loss: 1.611787
tensor(0.0051, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-9.1142e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.801985
Average KL loss: 0.841904
Average total loss: 1.643889
tensor(0.0051, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.7184e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.788806
Average KL loss: 0.842254
Average total loss: 1.631060
tensor(0.0051, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-4.6108e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.782103
Average KL loss: 0.842799
Average total loss: 1.624902
tensor(0.0051, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(7.1392e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.787179
Average KL loss: 0.842956
Average total loss: 1.630135
tensor(0.0051, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.1842e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.792213
Average KL loss: 0.843685
Average total loss: 1.635898
tensor(0.0051, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-6.0147e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.796873
Average KL loss: 0.844225
Average total loss: 1.641097
tensor(0.0051, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(3.1278e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.776202
Average KL loss: 0.844593
Average total loss: 1.620795
tensor(0.0051, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.1400e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.773477
Average KL loss: 0.844850
Average total loss: 1.618327
tensor(0.0051, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.7529e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.773543
Average KL loss: 0.845214
Average total loss: 1.618757
tensor(0.0051, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.0808e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.775425
Average KL loss: 0.845569
Average total loss: 1.620994
tensor(0.0051, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.1025e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.778378
Average KL loss: 0.846025
Average total loss: 1.624403
tensor(0.0051, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-2.6379e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.769363
Average KL loss: 0.846069
Average total loss: 1.615433
tensor(0.0051, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.0000e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.770912
Average KL loss: 0.846023
Average total loss: 1.616934
tensor(0.0051, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-2.7107e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.770039
Average KL loss: 0.845964
Average total loss: 1.616002
tensor(0.0051, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.7911e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.764837
Average KL loss: 0.845893
Average total loss: 1.610729
tensor(0.0051, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.6289e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.770644
Average KL loss: 0.845794
Average total loss: 1.616437
tensor(0.0051, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-6.0688e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.774378
Average KL loss: 0.845723
Average total loss: 1.620101
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.8931e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.762680
Average KL loss: 0.845669
Average total loss: 1.608349
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-7.9103e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.784507
Average KL loss: 0.845592
Average total loss: 1.630099
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.4635e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.766158
Average KL loss: 0.845519
Average total loss: 1.611677
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(1.6263e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.759158
Average KL loss: 0.845450
Average total loss: 1.604608
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(3.5321e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.766065
Average KL loss: 0.845394
Average total loss: 1.611458
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(3.9108e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.774007
Average KL loss: 0.845335
Average total loss: 1.619342
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.0660e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.778934
Average KL loss: 0.845229
Average total loss: 1.624163
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(5.9187e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.772187
Average KL loss: 0.845175
Average total loss: 1.617362
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-6.2418e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.767347
Average KL loss: 0.845127
Average total loss: 1.612475
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(1.0247e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.756089
Average KL loss: 0.845075
Average total loss: 1.601163
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-7.6808e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.760669
Average KL loss: 0.845010
Average total loss: 1.605679
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-6.4284e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.769811
Average KL loss: 0.844946
Average total loss: 1.614757
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.2166e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.781082
Average KL loss: 0.844890
Average total loss: 1.625971
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-5.9326e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.779893
Average KL loss: 0.844840
Average total loss: 1.624733
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-7.2252e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.753693
Average KL loss: 0.844794
Average total loss: 1.598487
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(5.2651e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.787048
Average KL loss: 0.844755
Average total loss: 1.631803
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-7.4625e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.775331
Average KL loss: 0.844709
Average total loss: 1.620040
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.9655e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.765498
Average KL loss: 0.844633
Average total loss: 1.610131
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-9.8334e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.754259
Average KL loss: 0.844578
Average total loss: 1.598837
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.0573e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.747059
Average KL loss: 0.844484
Average total loss: 1.591542
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(9.2901e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.758130
Average KL loss: 0.844401
Average total loss: 1.602531
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(8.8325e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.756307
Average KL loss: 0.844358
Average total loss: 1.600665
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.4874e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.757071
Average KL loss: 0.844321
Average total loss: 1.601393
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-4.8888e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.758314
Average KL loss: 0.844254
Average total loss: 1.602568
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(5.9849e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.765755
Average KL loss: 0.844201
Average total loss: 1.609956
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-4.7763e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.759288
Average KL loss: 0.844161
Average total loss: 1.603449
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-7.8778e-11, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.759314
Average KL loss: 0.844119
Average total loss: 1.603433
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-6.9373e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.758276
Average KL loss: 0.844059
Average total loss: 1.602335
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.1522e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.768379
Average KL loss: 0.844011
Average total loss: 1.612389
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.0535e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.763041
Average KL loss: 0.843987
Average total loss: 1.607028
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(9.1298e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.750456
Average KL loss: 0.843910
Average total loss: 1.594366
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(5.5031e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.760508
Average KL loss: 0.843873
Average total loss: 1.604381
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.1023e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.755734
Average KL loss: 0.843866
Average total loss: 1.599600
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(6.3804e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.771913
Average KL loss: 0.843860
Average total loss: 1.615773
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(6.2825e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.766717
Average KL loss: 0.843854
Average total loss: 1.610570
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.2613e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.759637
Average KL loss: 0.843844
Average total loss: 1.603481
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.3536e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.768699
Average KL loss: 0.843837
Average total loss: 1.612536
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.0627e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.759918
Average KL loss: 0.843829
Average total loss: 1.603747
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-9.1236e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.766804
Average KL loss: 0.843821
Average total loss: 1.610625
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(4.1957e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.758253
Average KL loss: 0.843814
Average total loss: 1.602067
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(7.2117e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.761362
Average KL loss: 0.843803
Average total loss: 1.605165
 Percentile value: 2.0419222116470337
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =     576 /    1728             ( 33.33%) | total_pruned =    1152 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     589 /   36864             (  1.60%) | total_pruned =   36275 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     754 /   36864             (  2.05%) | total_pruned =   36110 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     589 /   36864             (  1.60%) | total_pruned =   36275 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     624 /   36864             (  1.69%) | total_pruned =   36240 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1026 /   73728             (  1.39%) | total_pruned =   72702 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1215 /  147456             (  0.82%) | total_pruned =  146241 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     572 /    8192             (  6.98%) | total_pruned =    7620 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     604 /  147456             (  0.41%) | total_pruned =  146852 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     528 /  147456             (  0.36%) | total_pruned =  146928 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1844 /  294912             (  0.63%) | total_pruned =  293068 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2034 /  589824             (  0.34%) | total_pruned =  587790 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     696 /   32768             (  2.12%) | total_pruned =   32072 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     570 /  589824             (  0.10%) | total_pruned =  589254 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     145 /     256             ( 56.64%) | total_pruned =     111 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     547 /  589824             (  0.09%) | total_pruned =  589277 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     184 /     256             ( 71.88%) | total_pruned =      72 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2077 / 1179648             (  0.18%) | total_pruned = 1177571 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     444 /     512             ( 86.72%) | total_pruned =      68 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      37 /     512             (  7.23%) | total_pruned =     475 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1547 / 2359296             (  0.07%) | total_pruned = 2357749 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     342 /     512             ( 66.80%) | total_pruned =     170 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      78 /     512             ( 15.23%) | total_pruned =     434 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     299 /  131072             (  0.23%) | total_pruned =  130773 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     150 /     512             ( 29.30%) | total_pruned =     362 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      79 /     512             ( 15.43%) | total_pruned =     433 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     716 / 2359296             (  0.03%) | total_pruned = 2358580 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     208 /     512             ( 40.62%) | total_pruned =     304 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     354 / 2359296             (  0.02%) | total_pruned = 2358942 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      77 /     512             ( 15.04%) | total_pruned =     435 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     501 /    5120             (  9.79%) | total_pruned =    4619 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.212555 Accuracy: 78.95 98.83 % Best test Accuracy: 80.84%
tensor(0.0051, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-6.2193e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.471554
Average KL loss: 0.798875
Average total loss: 2.270429
tensor(0.0047, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-8.8976e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.471064
Average KL loss: 0.766563
Average total loss: 2.237627
tensor(0.0046, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-9.3976e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.430294
Average KL loss: 0.759050
Average total loss: 2.189344
tensor(0.0046, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-4.4167e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.429876
Average KL loss: 0.756624
Average total loss: 2.186500
tensor(0.0046, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.3586e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.375666
Average KL loss: 0.756569
Average total loss: 2.132234
tensor(0.0046, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-8.8505e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.371597
Average KL loss: 0.757861
Average total loss: 2.129459
tensor(0.0046, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-5.9713e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.344881
Average KL loss: 0.759775
Average total loss: 2.104656
tensor(0.0046, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-6.3721e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.332717
Average KL loss: 0.762222
Average total loss: 2.094939
tensor(0.0046, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-5.7625e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.283039
Average KL loss: 0.764673
Average total loss: 2.047712
tensor(0.0046, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-5.2794e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.288621
Average KL loss: 0.766986
Average total loss: 2.055607
tensor(0.0046, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-6.1864e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.258341
Average KL loss: 0.769633
Average total loss: 2.027974
tensor(0.0046, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-7.1153e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.239547
Average KL loss: 0.771862
Average total loss: 2.011408
tensor(0.0047, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-6.5099e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.215530
Average KL loss: 0.773775
Average total loss: 1.989304
tensor(0.0047, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-4.9696e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.184821
Average KL loss: 0.775806
Average total loss: 1.960627
tensor(0.0047, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-4.6518e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.188847
Average KL loss: 0.777777
Average total loss: 1.966625
tensor(0.0047, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-3.6102e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.178928
Average KL loss: 0.779704
Average total loss: 1.958633
tensor(0.0047, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-3.1002e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.171975
Average KL loss: 0.781876
Average total loss: 1.953851
tensor(0.0047, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-5.4307e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.136968
Average KL loss: 0.783847
Average total loss: 1.920815
tensor(0.0047, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-4.4151e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.116731
Average KL loss: 0.785865
Average total loss: 1.902596
tensor(0.0047, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-2.3752e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.133479
Average KL loss: 0.787979
Average total loss: 1.921458
tensor(0.0047, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-3.3218e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.106534
Average KL loss: 0.789913
Average total loss: 1.896447
tensor(0.0048, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-6.1163e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.100961
Average KL loss: 0.791846
Average total loss: 1.892808
tensor(0.0048, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-5.7102e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.087387
Average KL loss: 0.793739
Average total loss: 1.881126
tensor(0.0048, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-1.8193e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.069027
Average KL loss: 0.795478
Average total loss: 1.864505
tensor(0.0048, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-5.8578e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.049185
Average KL loss: 0.797246
Average total loss: 1.846431
tensor(0.0048, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-4.0541e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.056004
Average KL loss: 0.799069
Average total loss: 1.855072
tensor(0.0048, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-3.9926e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.024772
Average KL loss: 0.800786
Average total loss: 1.825558
tensor(0.0048, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-2.4217e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.006145
Average KL loss: 0.802411
Average total loss: 1.808556
tensor(0.0048, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-4.5343e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.012049
Average KL loss: 0.804092
Average total loss: 1.816141
tensor(0.0048, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-4.4990e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.012580
Average KL loss: 0.805879
Average total loss: 1.818459
tensor(0.0049, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-4.4501e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.023169
Average KL loss: 0.807513
Average total loss: 1.830682
tensor(0.0049, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-5.0595e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.998472
Average KL loss: 0.809040
Average total loss: 1.807512
tensor(0.0049, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.9541e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.997592
Average KL loss: 0.810572
Average total loss: 1.808165
tensor(0.0049, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-2.3248e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.971277
Average KL loss: 0.812115
Average total loss: 1.783392
tensor(0.0049, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-4.4224e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.999173
Average KL loss: 0.813701
Average total loss: 1.812874
tensor(0.0049, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-3.5892e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.948079
Average KL loss: 0.815270
Average total loss: 1.763350
tensor(0.0049, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.5906e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.954505
Average KL loss: 0.816844
Average total loss: 1.771348
tensor(0.0049, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.8120e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.928576
Average KL loss: 0.818247
Average total loss: 1.746822
tensor(0.0049, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-9.1144e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.961046
Average KL loss: 0.819780
Average total loss: 1.780826
tensor(0.0049, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-3.2444e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.931202
Average KL loss: 0.821227
Average total loss: 1.752430
tensor(0.0049, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-2.0057e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.920178
Average KL loss: 0.822674
Average total loss: 1.742852
tensor(0.0050, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-2.7839e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.933878
Average KL loss: 0.823942
Average total loss: 1.757820
tensor(0.0050, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-3.8826e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.905699
Average KL loss: 0.825238
Average total loss: 1.730936
tensor(0.0050, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-3.1922e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.910384
Average KL loss: 0.826601
Average total loss: 1.736985
tensor(0.0050, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-4.6998e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.905570
Average KL loss: 0.828080
Average total loss: 1.733650
tensor(0.0050, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-5.3408e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.901432
Average KL loss: 0.829579
Average total loss: 1.731011
tensor(0.0050, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-3.1069e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.874630
Average KL loss: 0.830901
Average total loss: 1.705531
tensor(0.0050, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-2.9941e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.892202
Average KL loss: 0.832297
Average total loss: 1.724499
tensor(0.0050, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-3.4297e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.865915
Average KL loss: 0.833604
Average total loss: 1.699519
tensor(0.0050, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-3.4954e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.878459
Average KL loss: 0.834877
Average total loss: 1.713336
tensor(0.0050, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-2.1271e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.868273
Average KL loss: 0.836099
Average total loss: 1.704372
tensor(0.0051, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.7872e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.867771
Average KL loss: 0.837377
Average total loss: 1.705148
tensor(0.0051, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.1389e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.860751
Average KL loss: 0.838450
Average total loss: 1.699200
tensor(0.0051, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-1.9572e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.837018
Average KL loss: 0.839455
Average total loss: 1.676472
tensor(0.0051, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-3.4264e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.845135
Average KL loss: 0.840640
Average total loss: 1.685775
tensor(0.0051, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-1.8213e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.849341
Average KL loss: 0.841938
Average total loss: 1.691279
tensor(0.0051, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-7.1758e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.824673
Average KL loss: 0.843133
Average total loss: 1.667806
tensor(0.0051, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-3.7764e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.828670
Average KL loss: 0.844356
Average total loss: 1.673026
tensor(0.0051, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-4.6233e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.833394
Average KL loss: 0.845661
Average total loss: 1.679055
tensor(0.0051, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.8138e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.813597
Average KL loss: 0.846999
Average total loss: 1.660596
tensor(0.0051, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.4871e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.811293
Average KL loss: 0.848170
Average total loss: 1.659462
tensor(0.0051, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-4.1232e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.772976
Average KL loss: 0.849224
Average total loss: 1.622200
tensor(0.0052, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.2611e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.827786
Average KL loss: 0.850377
Average total loss: 1.678163
tensor(0.0052, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-5.3707e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.799137
Average KL loss: 0.851455
Average total loss: 1.650592
tensor(0.0052, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-6.4644e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.797371
Average KL loss: 0.852386
Average total loss: 1.649757
tensor(0.0052, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.2090e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.782014
Average KL loss: 0.853454
Average total loss: 1.635468
tensor(0.0052, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.4776e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.793328
Average KL loss: 0.854619
Average total loss: 1.647947
tensor(0.0052, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-4.5947e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.776784
Average KL loss: 0.855771
Average total loss: 1.632555
tensor(0.0052, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-2.8970e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.778457
Average KL loss: 0.856949
Average total loss: 1.635406
tensor(0.0052, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-3.2490e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.765616
Average KL loss: 0.858024
Average total loss: 1.623641
tensor(0.0052, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.3399e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.779484
Average KL loss: 0.859059
Average total loss: 1.638543
tensor(0.0052, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.7390e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.756672
Average KL loss: 0.859962
Average total loss: 1.616634
tensor(0.0052, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.7400e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.752296
Average KL loss: 0.861052
Average total loss: 1.613349
tensor(0.0053, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-3.3232e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.757824
Average KL loss: 0.862010
Average total loss: 1.619834
tensor(0.0053, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-1.3467e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.742872
Average KL loss: 0.863030
Average total loss: 1.605902
tensor(0.0053, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-3.9047e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.733368
Average KL loss: 0.863872
Average total loss: 1.597241
tensor(0.0053, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-3.4149e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.744423
Average KL loss: 0.864806
Average total loss: 1.609229
tensor(0.0053, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-2.2843e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.748593
Average KL loss: 0.865890
Average total loss: 1.614484
tensor(0.0053, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-2.5726e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.741068
Average KL loss: 0.866982
Average total loss: 1.608051
tensor(0.0053, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-2.6128e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.729475
Average KL loss: 0.868142
Average total loss: 1.597616
tensor(0.0053, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-3.9147e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.733615
Average KL loss: 0.868990
Average total loss: 1.602604
tensor(0.0053, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-1.8843e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.732665
Average KL loss: 0.870006
Average total loss: 1.602671
tensor(0.0053, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-2.7714e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.710353
Average KL loss: 0.871000
Average total loss: 1.581354
tensor(0.0053, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-2.8832e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.721724
Average KL loss: 0.871875
Average total loss: 1.593599
tensor(0.0053, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.9852e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.733527
Average KL loss: 0.872813
Average total loss: 1.606340
tensor(0.0054, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-2.2529e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.722853
Average KL loss: 0.873779
Average total loss: 1.596633
tensor(0.0054, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.7450e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.693598
Average KL loss: 0.874740
Average total loss: 1.568338
tensor(0.0054, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-1.6836e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.699195
Average KL loss: 0.875683
Average total loss: 1.574878
tensor(0.0054, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-2.8649e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.698803
Average KL loss: 0.876772
Average total loss: 1.575574
tensor(0.0054, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-1.6287e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.692660
Average KL loss: 0.877577
Average total loss: 1.570237
tensor(0.0054, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-2.7482e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.684135
Average KL loss: 0.878238
Average total loss: 1.562373
tensor(0.0054, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.3683e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.690147
Average KL loss: 0.879062
Average total loss: 1.569209
tensor(0.0054, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.8412e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.685701
Average KL loss: 0.880054
Average total loss: 1.565755
tensor(0.0054, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.4957e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.686351
Average KL loss: 0.881077
Average total loss: 1.567427
tensor(0.0054, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-2.1787e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.672993
Average KL loss: 0.881939
Average total loss: 1.554931
tensor(0.0054, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-4.1177e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.677135
Average KL loss: 0.882663
Average total loss: 1.559798
tensor(0.0055, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-2.1733e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.666432
Average KL loss: 0.883610
Average total loss: 1.550041
tensor(0.0055, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-1.0195e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.676775
Average KL loss: 0.884449
Average total loss: 1.561223
tensor(0.0055, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-9.2919e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.655248
Average KL loss: 0.885353
Average total loss: 1.540601
tensor(0.0055, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-3.7431e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.666071
Average KL loss: 0.886162
Average total loss: 1.552233
tensor(0.0055, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-2.3430e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.651497
Average KL loss: 0.887057
Average total loss: 1.538554
tensor(0.0055, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-2.3488e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.659699
Average KL loss: 0.887918
Average total loss: 1.547617
tensor(0.0055, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-2.4350e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.668094
Average KL loss: 0.888809
Average total loss: 1.556902
tensor(0.0055, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-2.1699e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.628553
Average KL loss: 0.889604
Average total loss: 1.518156
tensor(0.0055, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-2.5806e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.642623
Average KL loss: 0.890322
Average total loss: 1.532944
tensor(0.0055, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-9.4508e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.632746
Average KL loss: 0.891096
Average total loss: 1.523841
tensor(0.0055, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.1064e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.645013
Average KL loss: 0.891888
Average total loss: 1.536901
tensor(0.0055, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-1.2789e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.634668
Average KL loss: 0.892598
Average total loss: 1.527265
tensor(0.0056, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-2.1612e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.633038
Average KL loss: 0.893435
Average total loss: 1.526473
tensor(0.0056, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-1.7593e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.628010
Average KL loss: 0.894289
Average total loss: 1.522299
tensor(0.0056, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-2.4909e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.619609
Average KL loss: 0.894995
Average total loss: 1.514604
tensor(0.0056, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.8246e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.613499
Average KL loss: 0.895752
Average total loss: 1.509251
tensor(0.0056, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-4.5984e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.637717
Average KL loss: 0.896525
Average total loss: 1.534242
tensor(0.0056, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.9731e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.622354
Average KL loss: 0.897372
Average total loss: 1.519727
tensor(0.0056, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.1618e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.604179
Average KL loss: 0.898087
Average total loss: 1.502266
tensor(0.0056, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-3.3925e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.615378
Average KL loss: 0.898749
Average total loss: 1.514127
tensor(0.0056, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.5342e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.611356
Average KL loss: 0.899431
Average total loss: 1.510787
tensor(0.0056, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.1049e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.603703
Average KL loss: 0.900120
Average total loss: 1.503823
tensor(0.0056, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-2.8700e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.620075
Average KL loss: 0.901014
Average total loss: 1.521088
tensor(0.0056, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.7928e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.603917
Average KL loss: 0.901894
Average total loss: 1.505812
tensor(0.0057, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.8995e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.587866
Average KL loss: 0.902594
Average total loss: 1.490460
tensor(0.0057, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.1367e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.582292
Average KL loss: 0.903297
Average total loss: 1.485589
tensor(0.0057, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-2.7973e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.598948
Average KL loss: 0.903877
Average total loss: 1.502824
tensor(0.0057, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-8.4938e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.595539
Average KL loss: 0.904620
Average total loss: 1.500159
tensor(0.0057, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.3040e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.593735
Average KL loss: 0.905379
Average total loss: 1.499114
tensor(0.0057, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.0769e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.591753
Average KL loss: 0.906053
Average total loss: 1.497806
tensor(0.0057, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(1.6513e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.586665
Average KL loss: 0.906673
Average total loss: 1.493337
tensor(0.0057, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.8341e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.584575
Average KL loss: 0.907321
Average total loss: 1.491896
tensor(0.0057, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-8.0683e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.567535
Average KL loss: 0.908083
Average total loss: 1.475618
tensor(0.0057, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.0569e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.577384
Average KL loss: 0.908793
Average total loss: 1.486177
tensor(0.0057, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-6.9853e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.572733
Average KL loss: 0.909719
Average total loss: 1.482452
tensor(0.0057, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-6.5173e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.576823
Average KL loss: 0.910500
Average total loss: 1.487323
tensor(0.0057, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.5413e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.565900
Average KL loss: 0.911069
Average total loss: 1.476969
tensor(0.0058, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-9.8357e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.574776
Average KL loss: 0.911881
Average total loss: 1.486657
tensor(0.0058, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-2.2372e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.561776
Average KL loss: 0.912763
Average total loss: 1.474539
tensor(0.0058, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(2.1037e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.563704
Average KL loss: 0.913404
Average total loss: 1.477108
tensor(0.0058, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-9.8765e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.561194
Average KL loss: 0.914006
Average total loss: 1.475200
tensor(0.0058, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-2.1174e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.569370
Average KL loss: 0.914831
Average total loss: 1.484201
tensor(0.0058, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-1.7672e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.568934
Average KL loss: 0.915494
Average total loss: 1.484428
tensor(0.0058, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-3.2287e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.549555
Average KL loss: 0.916036
Average total loss: 1.465591
tensor(0.0058, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-1.7001e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.557064
Average KL loss: 0.916599
Average total loss: 1.473663
tensor(0.0058, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-1.6655e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.565414
Average KL loss: 0.917364
Average total loss: 1.482777
tensor(0.0058, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-1.7404e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.555918
Average KL loss: 0.918153
Average total loss: 1.474071
tensor(0.0058, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-1.2082e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.553974
Average KL loss: 0.918815
Average total loss: 1.472788
tensor(0.0058, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.3846e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.549622
Average KL loss: 0.919678
Average total loss: 1.469300
tensor(0.0059, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-5.8511e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.547666
Average KL loss: 0.920387
Average total loss: 1.468053
tensor(0.0059, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-1.2547e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.544650
Average KL loss: 0.920880
Average total loss: 1.465530
tensor(0.0059, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-1.3515e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.548973
Average KL loss: 0.921281
Average total loss: 1.470254
tensor(0.0059, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-1.3447e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.538869
Average KL loss: 0.921891
Average total loss: 1.460760
tensor(0.0059, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-5.8587e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.541518
Average KL loss: 0.922717
Average total loss: 1.464236
tensor(0.0059, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.3289e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.542670
Average KL loss: 0.923438
Average total loss: 1.466108
tensor(0.0059, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.1030e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.522999
Average KL loss: 0.924167
Average total loss: 1.447166
tensor(0.0059, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-7.2573e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.537876
Average KL loss: 0.924826
Average total loss: 1.462702
tensor(0.0059, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.5367e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.519664
Average KL loss: 0.925538
Average total loss: 1.445202
tensor(0.0059, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-6.0018e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.529699
Average KL loss: 0.926169
Average total loss: 1.455868
tensor(0.0059, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-7.2607e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.516365
Average KL loss: 0.926871
Average total loss: 1.443236
tensor(0.0059, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-2.5147e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.526957
Average KL loss: 0.927507
Average total loss: 1.454463
tensor(0.0060, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-2.4947e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.529336
Average KL loss: 0.928105
Average total loss: 1.457440
tensor(0.0060, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-8.4450e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.510685
Average KL loss: 0.928764
Average total loss: 1.439449
tensor(0.0060, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.3291e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.525148
Average KL loss: 0.929415
Average total loss: 1.454563
tensor(0.0060, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.0066e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.511117
Average KL loss: 0.930162
Average total loss: 1.441278
tensor(0.0060, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.3865e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.510218
Average KL loss: 0.930712
Average total loss: 1.440930
tensor(0.0060, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.7728e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.507307
Average KL loss: 0.931312
Average total loss: 1.438619
tensor(0.0060, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.9910e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.515115
Average KL loss: 0.931772
Average total loss: 1.446887
tensor(0.0060, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.4960e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.505747
Average KL loss: 0.932340
Average total loss: 1.438087
tensor(0.0060, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.4787e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.501781
Average KL loss: 0.932918
Average total loss: 1.434698
tensor(0.0060, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.2827e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.499966
Average KL loss: 0.933517
Average total loss: 1.433482
tensor(0.0060, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-5.0059e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.515513
Average KL loss: 0.934094
Average total loss: 1.449608
tensor(0.0060, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-6.6137e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.498574
Average KL loss: 0.934518
Average total loss: 1.433092
tensor(0.0060, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-1.5243e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.497228
Average KL loss: 0.935017
Average total loss: 1.432245
tensor(0.0061, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.0091e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.492497
Average KL loss: 0.935496
Average total loss: 1.427993
tensor(0.0061, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-2.4754e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.503446
Average KL loss: 0.936127
Average total loss: 1.439573
tensor(0.0061, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-7.4261e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.495471
Average KL loss: 0.936760
Average total loss: 1.432231
tensor(0.0061, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-5.5305e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.504490
Average KL loss: 0.937351
Average total loss: 1.441841
tensor(0.0061, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.1162e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.490605
Average KL loss: 0.937927
Average total loss: 1.428531
tensor(0.0061, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-1.3309e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.488883
Average KL loss: 0.938557
Average total loss: 1.427440
tensor(0.0061, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-1.6120e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.495984
Average KL loss: 0.939177
Average total loss: 1.435161
tensor(0.0061, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-9.8127e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.488066
Average KL loss: 0.939640
Average total loss: 1.427706
tensor(0.0061, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.3446e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.492007
Average KL loss: 0.940196
Average total loss: 1.432203
tensor(0.0061, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.6006e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.490037
Average KL loss: 0.940583
Average total loss: 1.430621
tensor(0.0061, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.1666e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.495019
Average KL loss: 0.941076
Average total loss: 1.436095
tensor(0.0061, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-4.5315e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.492966
Average KL loss: 0.941663
Average total loss: 1.434629
tensor(0.0061, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-8.3520e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.475175
Average KL loss: 0.942327
Average total loss: 1.417502
tensor(0.0062, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-5.7510e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.478966
Average KL loss: 0.942986
Average total loss: 1.421952
tensor(0.0062, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-1.7615e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.494335
Average KL loss: 0.943608
Average total loss: 1.437942
tensor(0.0062, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-4.5856e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.467545
Average KL loss: 0.944348
Average total loss: 1.411893
tensor(0.0062, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-5.7753e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.490171
Average KL loss: 0.944933
Average total loss: 1.435105
tensor(0.0062, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-8.2234e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.475330
Average KL loss: 0.945448
Average total loss: 1.420778
tensor(0.0062, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-9.4417e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.467902
Average KL loss: 0.946024
Average total loss: 1.413926
tensor(0.0062, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-9.8005e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.472819
Average KL loss: 0.946630
Average total loss: 1.419449
tensor(0.0062, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.8705e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.464577
Average KL loss: 0.947122
Average total loss: 1.411699
tensor(0.0062, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-1.6434e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.465564
Average KL loss: 0.947601
Average total loss: 1.413165
tensor(0.0062, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.2626e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.463955
Average KL loss: 0.948214
Average total loss: 1.412169
tensor(0.0062, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-2.6147e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.454796
Average KL loss: 0.948648
Average total loss: 1.403443
tensor(0.0062, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.0366e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.458050
Average KL loss: 0.949007
Average total loss: 1.407057
tensor(0.0062, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-2.1627e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.465888
Average KL loss: 0.949487
Average total loss: 1.415374
tensor(0.0063, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.4286e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.467082
Average KL loss: 0.950007
Average total loss: 1.417089
tensor(0.0063, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.0457e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.465154
Average KL loss: 0.950644
Average total loss: 1.415798
tensor(0.0063, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.0638e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.448643
Average KL loss: 0.951243
Average total loss: 1.399886
tensor(0.0063, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-8.3878e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.455342
Average KL loss: 0.951765
Average total loss: 1.407107
 Percentile value: 4.753040313720703
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =     515 /    1728             ( 29.80%) | total_pruned =    1213 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     349 /   36864             (  0.95%) | total_pruned =   36515 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     414 /   36864             (  1.12%) | total_pruned =   36450 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     342 /   36864             (  0.93%) | total_pruned =   36522 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     354 /   36864             (  0.96%) | total_pruned =   36510 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     462 /   73728             (  0.63%) | total_pruned =   73266 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     532 /  147456             (  0.36%) | total_pruned =  146924 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     283 /    8192             (  3.45%) | total_pruned =    7909 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     302 /  147456             (  0.20%) | total_pruned =  147154 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     241 /  147456             (  0.16%) | total_pruned =  147215 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     692 /  294912             (  0.23%) | total_pruned =  294220 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     237 /     256             ( 92.58%) | total_pruned =      19 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     719 /  589824             (  0.12%) | total_pruned =  589105 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     252 /   32768             (  0.77%) | total_pruned =   32516 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     214 /  589824             (  0.04%) | total_pruned =  589610 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     110 /     256             ( 42.97%) | total_pruned =     146 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     212 /  589824             (  0.04%) | total_pruned =  589612 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     136 /     256             ( 53.12%) | total_pruned =     120 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     689 / 1179648             (  0.06%) | total_pruned = 1178959 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     325 /     512             ( 63.48%) | total_pruned =     187 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     595 / 2359296             (  0.03%) | total_pruned = 2358701 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     266 /     512             ( 51.95%) | total_pruned =     246 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     112 /  131072             (  0.09%) | total_pruned =  130960 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     309 / 2359296             (  0.01%) | total_pruned = 2358987 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     186 / 2359296             (  0.01%) | total_pruned = 2359110 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      71 /     512             ( 13.87%) | total_pruned =     441 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     365 /    5120             (  7.13%) | total_pruned =    4755 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.496222 Accuracy: 73.36 83.29 % Best test Accuracy: 73.78%
tensor(0.0063, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(5.1815e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.655374
Average KL loss: 0.907295
Average total loss: 1.562669
tensor(0.0056, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(8.2711e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.680963
Average KL loss: 0.824177
Average total loss: 1.505141
tensor(0.0051, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-3.1600e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.696489
Average KL loss: 0.749724
Average total loss: 1.446213
tensor(0.0047, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.2731e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.744243
Average KL loss: 0.688159
Average total loss: 1.432402
tensor(0.0043, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-9.2069e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.727631
Average KL loss: 0.645574
Average total loss: 1.373205
tensor(0.0041, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-6.9810e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.747687
Average KL loss: 0.621460
Average total loss: 1.369146
tensor(0.0040, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-1.0827e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.724318
Average KL loss: 0.609983
Average total loss: 1.334301
tensor(0.0039, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-1.6032e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.739747
Average KL loss: 0.605371
Average total loss: 1.345118
tensor(0.0039, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-7.2877e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.717944
Average KL loss: 0.603302
Average total loss: 1.321246
tensor(0.0039, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-1.8231e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.720273
Average KL loss: 0.601836
Average total loss: 1.322108
tensor(0.0039, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-5.0392e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.712706
Average KL loss: 0.600581
Average total loss: 1.313287
tensor(0.0038, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-1.7335e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.717718
Average KL loss: 0.599482
Average total loss: 1.317200
tensor(0.0038, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-8.6369e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.716841
Average KL loss: 0.598452
Average total loss: 1.315293
tensor(0.0038, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-1.8152e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.727255
Average KL loss: 0.597475
Average total loss: 1.324730
tensor(0.0038, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-2.3869e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.696467
Average KL loss: 0.596564
Average total loss: 1.293030
tensor(0.0038, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-1.4720e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.727452
Average KL loss: 0.595777
Average total loss: 1.323229
tensor(0.0038, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-9.0187e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.711306
Average KL loss: 0.595003
Average total loss: 1.306309
tensor(0.0038, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-1.3278e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.697164
Average KL loss: 0.594139
Average total loss: 1.291303
tensor(0.0038, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-6.8472e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.698052
Average KL loss: 0.593303
Average total loss: 1.291354
tensor(0.0038, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-8.7501e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.697868
Average KL loss: 0.592514
Average total loss: 1.290382
tensor(0.0038, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.2945e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.696009
Average KL loss: 0.591767
Average total loss: 1.287776
tensor(0.0038, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.2760e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.688067
Average KL loss: 0.591127
Average total loss: 1.279194
tensor(0.0038, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.1603e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.699445
Average KL loss: 0.590502
Average total loss: 1.289947
tensor(0.0038, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-1.0583e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.690004
Average KL loss: 0.589868
Average total loss: 1.279872
tensor(0.0038, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-9.9294e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.695276
Average KL loss: 0.589232
Average total loss: 1.284508
tensor(0.0038, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.9863e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.686552
Average KL loss: 0.588631
Average total loss: 1.275183
tensor(0.0038, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-4.5864e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.682517
Average KL loss: 0.587994
Average total loss: 1.270510
tensor(0.0038, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-8.7343e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.691366
Average KL loss: 0.587447
Average total loss: 1.278813
tensor(0.0038, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.6337e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.698160
Average KL loss: 0.586940
Average total loss: 1.285100
tensor(0.0039, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.5434e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.677630
Average KL loss: 0.586403
Average total loss: 1.264032
tensor(0.0039, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-4.6159e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.669206
Average KL loss: 0.585826
Average total loss: 1.255033
tensor(0.0039, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.7089e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.671669
Average KL loss: 0.585310
Average total loss: 1.256979
tensor(0.0039, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-9.2955e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.675404
Average KL loss: 0.584930
Average total loss: 1.260334
tensor(0.0039, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-7.9315e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.673623
Average KL loss: 0.584478
Average total loss: 1.258101
tensor(0.0039, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-8.9060e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.659544
Average KL loss: 0.584036
Average total loss: 1.243580
tensor(0.0039, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-5.6479e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.659650
Average KL loss: 0.583663
Average total loss: 1.243313
tensor(0.0039, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-1.1289e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.658067
Average KL loss: 0.583262
Average total loss: 1.241329
tensor(0.0039, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-9.3348e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.666363
Average KL loss: 0.582896
Average total loss: 1.249259
tensor(0.0039, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-6.9286e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.659022
Average KL loss: 0.582495
Average total loss: 1.241516
tensor(0.0039, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-6.1094e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.654165
Average KL loss: 0.582160
Average total loss: 1.236324
tensor(0.0039, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-8.2297e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.665260
Average KL loss: 0.581794
Average total loss: 1.247054
tensor(0.0039, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-2.0704e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.654767
Average KL loss: 0.581416
Average total loss: 1.236183
tensor(0.0039, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-8.5445e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.664091
Average KL loss: 0.581021
Average total loss: 1.245112
tensor(0.0039, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-8.9775e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.654543
Average KL loss: 0.580640
Average total loss: 1.235183
tensor(0.0039, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-6.1069e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.655223
Average KL loss: 0.580371
Average total loss: 1.235595
tensor(0.0039, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-7.6592e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.652588
Average KL loss: 0.580082
Average total loss: 1.232670
tensor(0.0039, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.7009e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.654545
Average KL loss: 0.579808
Average total loss: 1.234353
tensor(0.0039, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-3.5633e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.657454
Average KL loss: 0.579488
Average total loss: 1.236942
tensor(0.0039, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-5.1209e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.649725
Average KL loss: 0.579200
Average total loss: 1.228925
tensor(0.0039, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-1.3678e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.650207
Average KL loss: 0.578993
Average total loss: 1.229200
tensor(0.0039, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.1570e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.651646
Average KL loss: 0.578716
Average total loss: 1.230362
tensor(0.0039, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-3.3995e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.654149
Average KL loss: 0.578442
Average total loss: 1.232591
tensor(0.0039, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-5.0496e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.645745
Average KL loss: 0.578255
Average total loss: 1.224000
tensor(0.0039, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-6.3081e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.643725
Average KL loss: 0.578044
Average total loss: 1.221769
tensor(0.0039, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.2748e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.653623
Average KL loss: 0.577760
Average total loss: 1.231383
tensor(0.0039, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.3168e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.642691
Average KL loss: 0.577468
Average total loss: 1.220159
tensor(0.0039, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-5.1772e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.632387
Average KL loss: 0.577217
Average total loss: 1.209605
tensor(0.0039, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-3.5116e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.637658
Average KL loss: 0.576957
Average total loss: 1.214615
tensor(0.0039, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-7.8065e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.640456
Average KL loss: 0.576731
Average total loss: 1.217186
tensor(0.0039, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.3685e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.636136
Average KL loss: 0.576443
Average total loss: 1.212579
tensor(0.0039, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.3515e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.639403
Average KL loss: 0.576258
Average total loss: 1.215661
tensor(0.0039, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(6.9269e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.634807
Average KL loss: 0.576043
Average total loss: 1.210850
tensor(0.0039, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-8.9889e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.632972
Average KL loss: 0.575755
Average total loss: 1.208727
tensor(0.0039, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-3.7472e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.628610
Average KL loss: 0.575501
Average total loss: 1.204112
tensor(0.0039, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-4.4787e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.638446
Average KL loss: 0.575331
Average total loss: 1.213776
tensor(0.0039, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-6.5192e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.631365
Average KL loss: 0.575123
Average total loss: 1.206488
tensor(0.0040, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-8.8716e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.631761
Average KL loss: 0.574886
Average total loss: 1.206647
tensor(0.0040, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.0902e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.630798
Average KL loss: 0.574664
Average total loss: 1.205463
tensor(0.0040, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.8813e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.627250
Average KL loss: 0.574448
Average total loss: 1.201698
tensor(0.0040, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-3.7345e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.622509
Average KL loss: 0.574315
Average total loss: 1.196824
tensor(0.0040, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(4.9258e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.627215
Average KL loss: 0.574214
Average total loss: 1.201429
tensor(0.0040, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-5.6193e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.627853
Average KL loss: 0.574115
Average total loss: 1.201968
tensor(0.0040, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-4.2250e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.627352
Average KL loss: 0.573962
Average total loss: 1.201314
tensor(0.0040, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-5.8437e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.639838
Average KL loss: 0.573805
Average total loss: 1.213643
tensor(0.0040, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-4.5330e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.634071
Average KL loss: 0.573706
Average total loss: 1.207777
tensor(0.0040, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-3.1528e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.625677
Average KL loss: 0.573564
Average total loss: 1.199240
tensor(0.0040, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-1.1730e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.623867
Average KL loss: 0.573376
Average total loss: 1.197243
tensor(0.0040, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-6.7536e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.629026
Average KL loss: 0.573231
Average total loss: 1.202257
tensor(0.0040, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-7.6445e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.635376
Average KL loss: 0.573103
Average total loss: 1.208478
tensor(0.0040, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-3.6635e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.615557
Average KL loss: 0.573021
Average total loss: 1.188578
tensor(0.0040, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-6.3073e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.618570
Average KL loss: 0.572871
Average total loss: 1.191441
tensor(0.0040, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-2.8572e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.617684
Average KL loss: 0.572718
Average total loss: 1.190402
tensor(0.0040, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(4.8813e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.616489
Average KL loss: 0.572549
Average total loss: 1.189038
tensor(0.0040, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.1223e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.615040
Average KL loss: 0.572486
Average total loss: 1.187526
tensor(0.0040, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-8.2395e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.630848
Average KL loss: 0.572428
Average total loss: 1.203276
tensor(0.0040, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.4919e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.628076
Average KL loss: 0.572309
Average total loss: 1.200386
tensor(0.0040, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.4407e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.618485
Average KL loss: 0.572205
Average total loss: 1.190690
tensor(0.0040, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-5.7320e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.610395
Average KL loss: 0.572168
Average total loss: 1.182563
tensor(0.0040, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-1.2077e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.616660
Average KL loss: 0.572056
Average total loss: 1.188716
tensor(0.0040, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-7.3441e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.619164
Average KL loss: 0.571903
Average total loss: 1.191068
tensor(0.0040, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-8.5506e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.615860
Average KL loss: 0.571819
Average total loss: 1.187679
tensor(0.0040, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-4.1913e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.610938
Average KL loss: 0.571703
Average total loss: 1.182642
tensor(0.0040, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.8359e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.619278
Average KL loss: 0.571568
Average total loss: 1.190846
tensor(0.0040, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-9.8116e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.612260
Average KL loss: 0.571397
Average total loss: 1.183656
tensor(0.0040, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(1.2125e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.620445
Average KL loss: 0.571221
Average total loss: 1.191666
tensor(0.0040, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-9.2578e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.613618
Average KL loss: 0.571148
Average total loss: 1.184766
tensor(0.0041, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(1.6312e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.610090
Average KL loss: 0.571024
Average total loss: 1.181114
tensor(0.0041, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-6.4237e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.611380
Average KL loss: 0.570887
Average total loss: 1.182267
tensor(0.0041, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-4.1923e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.607992
Average KL loss: 0.570894
Average total loss: 1.178887
tensor(0.0041, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-3.5933e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.607595
Average KL loss: 0.570866
Average total loss: 1.178461
tensor(0.0041, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-5.0989e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.612352
Average KL loss: 0.570702
Average total loss: 1.183054
tensor(0.0041, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-2.0089e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.610281
Average KL loss: 0.570656
Average total loss: 1.180937
tensor(0.0041, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-3.7599e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.606215
Average KL loss: 0.570589
Average total loss: 1.176803
tensor(0.0041, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-1.4470e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.609779
Average KL loss: 0.570504
Average total loss: 1.180283
tensor(0.0041, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-5.4341e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.608779
Average KL loss: 0.570409
Average total loss: 1.179188
tensor(0.0041, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-1.7952e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.605221
Average KL loss: 0.570299
Average total loss: 1.175520
tensor(0.0041, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-5.6501e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.605309
Average KL loss: 0.570200
Average total loss: 1.175509
tensor(0.0041, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-4.5742e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.605218
Average KL loss: 0.570138
Average total loss: 1.175356
tensor(0.0041, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-5.6527e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.608768
Average KL loss: 0.570152
Average total loss: 1.178920
tensor(0.0041, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-4.6366e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.610753
Average KL loss: 0.570133
Average total loss: 1.180886
tensor(0.0041, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-1.8543e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.611677
Average KL loss: 0.570082
Average total loss: 1.181759
tensor(0.0041, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-9.0835e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.613246
Average KL loss: 0.570038
Average total loss: 1.183283
tensor(0.0041, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-3.7446e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.607499
Average KL loss: 0.569999
Average total loss: 1.177498
tensor(0.0041, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-1.0324e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.597506
Average KL loss: 0.569937
Average total loss: 1.167443
tensor(0.0041, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-1.5876e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.598901
Average KL loss: 0.569869
Average total loss: 1.168770
tensor(0.0041, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-6.1916e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.602684
Average KL loss: 0.569839
Average total loss: 1.172524
tensor(0.0041, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.4588e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.600207
Average KL loss: 0.569837
Average total loss: 1.170043
tensor(0.0041, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-2.9717e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.598570
Average KL loss: 0.569821
Average total loss: 1.168391
tensor(0.0041, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-3.2628e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.598439
Average KL loss: 0.569816
Average total loss: 1.168255
tensor(0.0041, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-1.3040e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.601205
Average KL loss: 0.569751
Average total loss: 1.170957
tensor(0.0041, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-2.5680e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.603131
Average KL loss: 0.569751
Average total loss: 1.172882
tensor(0.0041, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-4.9330e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.601866
Average KL loss: 0.569719
Average total loss: 1.171585
tensor(0.0041, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-6.1430e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.607938
Average KL loss: 0.569706
Average total loss: 1.177644
tensor(0.0041, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-6.3749e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.597543
Average KL loss: 0.569647
Average total loss: 1.167190
tensor(0.0042, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-3.7898e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.597238
Average KL loss: 0.569524
Average total loss: 1.166762
tensor(0.0042, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-2.6668e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.593099
Average KL loss: 0.569479
Average total loss: 1.162578
tensor(0.0042, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-2.9378e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.600956
Average KL loss: 0.569427
Average total loss: 1.170383
tensor(0.0042, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-4.6506e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.596064
Average KL loss: 0.569436
Average total loss: 1.165500
tensor(0.0042, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.8488e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.596113
Average KL loss: 0.569457
Average total loss: 1.165570
tensor(0.0042, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-2.2629e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.614878
Average KL loss: 0.569472
Average total loss: 1.184350
tensor(0.0042, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-2.3683e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.596699
Average KL loss: 0.569485
Average total loss: 1.166184
tensor(0.0042, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-9.0081e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.597324
Average KL loss: 0.569446
Average total loss: 1.166771
tensor(0.0042, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.8778e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.594523
Average KL loss: 0.569351
Average total loss: 1.163874
tensor(0.0042, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-6.7547e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.594829
Average KL loss: 0.569263
Average total loss: 1.164092
tensor(0.0042, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-3.4544e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.594690
Average KL loss: 0.569294
Average total loss: 1.163984
tensor(0.0042, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-8.4017e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.593221
Average KL loss: 0.569337
Average total loss: 1.162558
tensor(0.0042, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-2.0036e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.594667
Average KL loss: 0.569338
Average total loss: 1.164005
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-4.9554e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.592653
Average KL loss: 0.569307
Average total loss: 1.161960
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-6.5859e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.597751
Average KL loss: 0.569309
Average total loss: 1.167060
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-3.7879e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.591097
Average KL loss: 0.569311
Average total loss: 1.160408
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.4016e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.589043
Average KL loss: 0.569307
Average total loss: 1.158350
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.9891e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.592791
Average KL loss: 0.569302
Average total loss: 1.162092
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.7744e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.591072
Average KL loss: 0.569299
Average total loss: 1.160371
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-6.0423e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.595067
Average KL loss: 0.569298
Average total loss: 1.164365
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-3.8738e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.602585
Average KL loss: 0.569289
Average total loss: 1.171875
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-7.7321e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.596863
Average KL loss: 0.569287
Average total loss: 1.166150
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(1.4401e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.590438
Average KL loss: 0.569277
Average total loss: 1.159715
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.8844e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.595172
Average KL loss: 0.569280
Average total loss: 1.164452
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-9.6431e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.596566
Average KL loss: 0.569277
Average total loss: 1.165843
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.1269e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.592629
Average KL loss: 0.569272
Average total loss: 1.161902
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-6.0797e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.602004
Average KL loss: 0.569266
Average total loss: 1.171270
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-3.9094e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.597832
Average KL loss: 0.569262
Average total loss: 1.167093
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(1.7985e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.593335
Average KL loss: 0.569262
Average total loss: 1.162596
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.0414e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.599901
Average KL loss: 0.569261
Average total loss: 1.169161
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-4.7682e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.593499
Average KL loss: 0.569260
Average total loss: 1.162760
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-7.7695e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.608843
Average KL loss: 0.569259
Average total loss: 1.178102
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-4.1495e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.592892
Average KL loss: 0.569258
Average total loss: 1.162150
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-8.4070e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.596923
Average KL loss: 0.569257
Average total loss: 1.166180
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-3.4635e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.595009
Average KL loss: 0.569257
Average total loss: 1.164266
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.0614e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.593162
Average KL loss: 0.569257
Average total loss: 1.162419
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.6716e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.594307
Average KL loss: 0.569257
Average total loss: 1.163564
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-4.6631e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.592631
Average KL loss: 0.569257
Average total loss: 1.161888
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.0921e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.592388
Average KL loss: 0.569257
Average total loss: 1.161645
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-7.4237e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.599459
Average KL loss: 0.569257
Average total loss: 1.168717
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.5405e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.593128
Average KL loss: 0.569257
Average total loss: 1.162385
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.7699e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.596282
Average KL loss: 0.569258
Average total loss: 1.165540
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.3202e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.597638
Average KL loss: 0.569258
Average total loss: 1.166895
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-6.9005e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.593009
Average KL loss: 0.569258
Average total loss: 1.162267
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-7.8181e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.601354
Average KL loss: 0.569258
Average total loss: 1.170612
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.7160e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.588503
Average KL loss: 0.569258
Average total loss: 1.157761
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(5.1130e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.591870
Average KL loss: 0.569258
Average total loss: 1.161127
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.4512e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.597762
Average KL loss: 0.569258
Average total loss: 1.167019
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-7.1425e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.597798
Average KL loss: 0.569258
Average total loss: 1.167055
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-4.8134e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.599017
Average KL loss: 0.569258
Average total loss: 1.168275
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.1405e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.594100
Average KL loss: 0.569258
Average total loss: 1.163357
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.5962e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.589040
Average KL loss: 0.569258
Average total loss: 1.158297
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.6983e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.594991
Average KL loss: 0.569258
Average total loss: 1.164249
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-3.4236e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.597399
Average KL loss: 0.569258
Average total loss: 1.166657
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.3600e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.599312
Average KL loss: 0.569258
Average total loss: 1.168570
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-4.4925e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.595899
Average KL loss: 0.569258
Average total loss: 1.165157
tensor(0.0042, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(1.2306e-09, device='cuda:0')
 Percentile value: 6.031443119049072
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =     424 /    1728             ( 24.54%) | total_pruned =    1304 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
bn1.bias             | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     218 /   36864             (  0.59%) | total_pruned =   36646 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     223 /   36864             (  0.60%) | total_pruned =   36641 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     206 /   36864             (  0.56%) | total_pruned =   36658 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     197 /   36864             (  0.53%) | total_pruned =   36667 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     215 /   73728             (  0.29%) | total_pruned =   73513 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     234 /  147456             (  0.16%) | total_pruned =  147222 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     102 /    8192             (  1.25%) | total_pruned =    8090 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     146 /  147456             (  0.10%) | total_pruned =  147310 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     113 /  147456             (  0.08%) | total_pruned =  147343 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     222 /  294912             (  0.08%) | total_pruned =  294690 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     150 /     256             ( 58.59%) | total_pruned =     106 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     245 /  589824             (  0.04%) | total_pruned =  589579 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     145 /     256             ( 56.64%) | total_pruned =     111 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      67 /   32768             (  0.20%) | total_pruned =   32701 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =      86 /  589824             (  0.01%) | total_pruned =  589738 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =      71 /  589824             (  0.01%) | total_pruned =  589753 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      66 /     256             ( 25.78%) | total_pruned =     190 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     191 / 1179648             (  0.02%) | total_pruned = 1179457 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     181 /     512             ( 35.35%) | total_pruned =     331 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     217 / 2359296             (  0.01%) | total_pruned = 2359079 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     161 /     512             ( 31.45%) | total_pruned =     351 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      32 /  131072             (  0.02%) | total_pruned =  131040 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     110 / 2359296             (  0.00%) | total_pruned = 2359186 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     102 / 2359296             (  0.00%) | total_pruned = 2359194 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     259 /    5120             (  5.06%) | total_pruned =    4861 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 0.968511 Accuracy: 61.61 65.68 % Best test Accuracy: 62.21%
