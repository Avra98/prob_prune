Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.4786e-05, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.940430
Average KL loss: 497.196815
Average total loss: 499.137234
tensor(-0.4495, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(2.3638e-05, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.740915
Average KL loss: 382.591252
Average total loss: 384.332157
tensor(-0.8686, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(2.0581e-05, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.593838
Average KL loss: 290.750908
Average total loss: 292.344737
tensor(-1.2452, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(1.7086e-05, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.529572
Average KL loss: 223.251627
Average total loss: 224.781195
tensor(-1.5745, device='cuda:0') tensor(0.0826, device='cuda:0') tensor(1.4049e-05, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.520300
Average KL loss: 175.320470
Average total loss: 176.840766
tensor(-1.8600, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(1.1595e-05, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.510421
Average KL loss: 141.173891
Average total loss: 142.684308
tensor(-2.1087, device='cuda:0') tensor(0.1326, device='cuda:0') tensor(9.6770e-06, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.516606
Average KL loss: 116.361584
Average total loss: 117.878188
tensor(-2.3271, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(8.2109e-06, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.524042
Average KL loss: 97.875790
Average total loss: 99.399829
tensor(-2.5210, device='cuda:0') tensor(0.1707, device='cuda:0') tensor(7.0128e-06, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.522243
Average KL loss: 83.768948
Average total loss: 85.291190
tensor(-2.6946, device='cuda:0') tensor(0.1863, device='cuda:0') tensor(6.0908e-06, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.542791
Average KL loss: 72.745819
Average total loss: 74.288609
tensor(-2.8516, device='cuda:0') tensor(0.2001, device='cuda:0') tensor(5.3918e-06, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.545880
Average KL loss: 63.955064
Average total loss: 65.500943
tensor(-2.9949, device='cuda:0') tensor(0.2124, device='cuda:0') tensor(4.7591e-06, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.572343
Average KL loss: 56.823226
Average total loss: 58.395567
tensor(-3.1262, device='cuda:0') tensor(0.2238, device='cuda:0') tensor(4.2582e-06, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.560700
Average KL loss: 50.951890
Average total loss: 52.512587
tensor(-3.2476, device='cuda:0') tensor(0.2342, device='cuda:0') tensor(3.8515e-06, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.552316
Average KL loss: 46.043240
Average total loss: 47.595555
tensor(-3.3604, device='cuda:0') tensor(0.2437, device='cuda:0') tensor(3.5095e-06, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.567541
Average KL loss: 41.887307
Average total loss: 43.454846
tensor(-3.4659, device='cuda:0') tensor(0.2526, device='cuda:0') tensor(3.1946e-06, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.571494
Average KL loss: 38.335873
Average total loss: 39.907366
tensor(-3.5647, device='cuda:0') tensor(0.2611, device='cuda:0') tensor(2.9242e-06, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.556045
Average KL loss: 35.271340
Average total loss: 36.827383
tensor(-3.6579, device='cuda:0') tensor(0.2691, device='cuda:0') tensor(2.7025e-06, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.587805
Average KL loss: 32.604979
Average total loss: 34.192782
tensor(-3.7460, device='cuda:0') tensor(0.2768, device='cuda:0') tensor(2.5103e-06, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.591291
Average KL loss: 30.269555
Average total loss: 31.860845
tensor(-3.8295, device='cuda:0') tensor(0.2842, device='cuda:0') tensor(2.3322e-06, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.580419
Average KL loss: 28.209792
Average total loss: 29.790210
tensor(-3.9088, device='cuda:0') tensor(0.2915, device='cuda:0') tensor(2.1660e-06, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.584884
Average KL loss: 26.382687
Average total loss: 27.967570
tensor(-3.9845, device='cuda:0') tensor(0.2986, device='cuda:0') tensor(2.0561e-06, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.580085
Average KL loss: 24.749367
Average total loss: 26.329452
tensor(-4.0569, device='cuda:0') tensor(0.3054, device='cuda:0') tensor(1.8867e-06, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.579630
Average KL loss: 23.284456
Average total loss: 24.864085
tensor(-4.1262, device='cuda:0') tensor(0.3121, device='cuda:0') tensor(1.8325e-06, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.587773
Average KL loss: 21.963372
Average total loss: 23.551145
tensor(-4.1928, device='cuda:0') tensor(0.3187, device='cuda:0') tensor(1.6858e-06, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.579465
Average KL loss: 20.766926
Average total loss: 22.346391
tensor(-4.2568, device='cuda:0') tensor(0.3252, device='cuda:0') tensor(1.6087e-06, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.570536
Average KL loss: 19.680012
Average total loss: 21.250548
tensor(-4.3185, device='cuda:0') tensor(0.3317, device='cuda:0') tensor(1.5143e-06, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.578422
Average KL loss: 18.689397
Average total loss: 20.267819
tensor(-4.3780, device='cuda:0') tensor(0.3380, device='cuda:0') tensor(1.4552e-06, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.568958
Average KL loss: 17.779877
Average total loss: 19.348834
tensor(-4.4356, device='cuda:0') tensor(0.3443, device='cuda:0') tensor(1.3709e-06, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.574608
Average KL loss: 16.946285
Average total loss: 18.520893
tensor(-4.4913, device='cuda:0') tensor(0.3505, device='cuda:0') tensor(1.3016e-06, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.585844
Average KL loss: 16.179137
Average total loss: 17.764980
tensor(-4.5452, device='cuda:0') tensor(0.3568, device='cuda:0') tensor(1.2468e-06, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.579765
Average KL loss: 15.470410
Average total loss: 17.050174
tensor(-4.5976, device='cuda:0') tensor(0.3629, device='cuda:0') tensor(1.1891e-06, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.565208
Average KL loss: 14.813815
Average total loss: 16.379023
tensor(-4.6485, device='cuda:0') tensor(0.3690, device='cuda:0') tensor(1.1289e-06, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.575472
Average KL loss: 14.204426
Average total loss: 15.779897
tensor(-4.6979, device='cuda:0') tensor(0.3751, device='cuda:0') tensor(1.0992e-06, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.556956
Average KL loss: 13.637322
Average total loss: 15.194278
tensor(-4.7461, device='cuda:0') tensor(0.3811, device='cuda:0') tensor(1.0640e-06, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.582010
Average KL loss: 13.107720
Average total loss: 14.689729
tensor(-4.7931, device='cuda:0') tensor(0.3871, device='cuda:0') tensor(1.0024e-06, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.577257
Average KL loss: 12.613755
Average total loss: 14.191011
tensor(-4.8390, device='cuda:0') tensor(0.3931, device='cuda:0') tensor(9.5104e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.577551
Average KL loss: 12.150977
Average total loss: 13.728528
tensor(-4.8837, device='cuda:0') tensor(0.3992, device='cuda:0') tensor(9.0284e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.563848
Average KL loss: 11.718181
Average total loss: 13.282029
tensor(-4.9274, device='cuda:0') tensor(0.4052, device='cuda:0') tensor(9.1835e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.561221
Average KL loss: 11.311717
Average total loss: 12.872938
tensor(-4.9702, device='cuda:0') tensor(0.4112, device='cuda:0') tensor(8.6293e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.546134
Average KL loss: 10.928841
Average total loss: 12.474975
tensor(-5.0120, device='cuda:0') tensor(0.4172, device='cuda:0') tensor(8.2099e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.536811
Average KL loss: 10.567259
Average total loss: 12.104069
tensor(-5.0530, device='cuda:0') tensor(0.4231, device='cuda:0') tensor(8.0922e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.541069
Average KL loss: 10.225803
Average total loss: 11.766871
tensor(-5.0932, device='cuda:0') tensor(0.4290, device='cuda:0') tensor(7.7869e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.544426
Average KL loss: 9.903213
Average total loss: 11.447639
tensor(-5.1326, device='cuda:0') tensor(0.4350, device='cuda:0') tensor(7.5688e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.550940
Average KL loss: 9.597365
Average total loss: 11.148305
tensor(-5.1713, device='cuda:0') tensor(0.4409, device='cuda:0') tensor(7.1251e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.526121
Average KL loss: 9.307832
Average total loss: 10.833953
tensor(-5.2093, device='cuda:0') tensor(0.4469, device='cuda:0') tensor(6.9853e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.528410
Average KL loss: 9.032831
Average total loss: 10.561241
tensor(-5.2467, device='cuda:0') tensor(0.4527, device='cuda:0') tensor(6.8619e-07, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.549271
Average KL loss: 8.771377
Average total loss: 10.320648
tensor(-5.2834, device='cuda:0') tensor(0.4587, device='cuda:0') tensor(6.5885e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.523916
Average KL loss: 8.522767
Average total loss: 10.046683
tensor(-5.3195, device='cuda:0') tensor(0.4646, device='cuda:0') tensor(6.6967e-07, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.511209
Average KL loss: 8.285485
Average total loss: 9.796694
tensor(-5.3551, device='cuda:0') tensor(0.4705, device='cuda:0') tensor(6.2660e-07, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.529004
Average KL loss: 8.059499
Average total loss: 9.588503
tensor(-5.3901, device='cuda:0') tensor(0.4765, device='cuda:0') tensor(5.9948e-07, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.514446
Average KL loss: 7.844027
Average total loss: 9.358473
tensor(-5.4247, device='cuda:0') tensor(0.4824, device='cuda:0') tensor(5.6387e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.499398
Average KL loss: 7.637510
Average total loss: 9.136908
tensor(-5.4587, device='cuda:0') tensor(0.4882, device='cuda:0') tensor(5.6308e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.519606
Average KL loss: 7.439900
Average total loss: 8.959506
tensor(-5.4923, device='cuda:0') tensor(0.4941, device='cuda:0') tensor(5.4653e-07, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.497700
Average KL loss: 7.250867
Average total loss: 8.748567
tensor(-5.5254, device='cuda:0') tensor(0.5000, device='cuda:0') tensor(5.3785e-07, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.490128
Average KL loss: 7.070078
Average total loss: 8.560206
tensor(-5.5581, device='cuda:0') tensor(0.5059, device='cuda:0') tensor(5.2794e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.510130
Average KL loss: 6.896487
Average total loss: 8.406617
tensor(-5.5904, device='cuda:0') tensor(0.5118, device='cuda:0') tensor(5.0188e-07, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.494731
Average KL loss: 6.729733
Average total loss: 8.224463
tensor(-5.6223, device='cuda:0') tensor(0.5177, device='cuda:0') tensor(5.1912e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.489769
Average KL loss: 6.570016
Average total loss: 8.059786
tensor(-5.6538, device='cuda:0') tensor(0.5237, device='cuda:0') tensor(5.0867e-07, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.487566
Average KL loss: 6.416513
Average total loss: 7.904079
tensor(-5.6850, device='cuda:0') tensor(0.5296, device='cuda:0') tensor(4.7016e-07, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.487336
Average KL loss: 6.268661
Average total loss: 7.755997
tensor(-5.7158, device='cuda:0') tensor(0.5355, device='cuda:0') tensor(4.6325e-07, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.490617
Average KL loss: 6.126600
Average total loss: 7.617217
tensor(-5.7463, device='cuda:0') tensor(0.5415, device='cuda:0') tensor(4.4262e-07, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.475734
Average KL loss: 5.989728
Average total loss: 7.465462
tensor(-5.7764, device='cuda:0') tensor(0.5474, device='cuda:0') tensor(4.1620e-07, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.493400
Average KL loss: 5.857685
Average total loss: 7.351085
tensor(-5.8063, device='cuda:0') tensor(0.5534, device='cuda:0') tensor(4.4399e-07, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.469716
Average KL loss: 5.730242
Average total loss: 7.199958
tensor(-5.8358, device='cuda:0') tensor(0.5593, device='cuda:0') tensor(4.2083e-07, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.462749
Average KL loss: 5.607360
Average total loss: 7.070109
tensor(-5.8651, device='cuda:0') tensor(0.5653, device='cuda:0') tensor(4.1261e-07, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.461835
Average KL loss: 5.488711
Average total loss: 6.950546
tensor(-5.8941, device='cuda:0') tensor(0.5713, device='cuda:0') tensor(3.9879e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.460109
Average KL loss: 5.373491
Average total loss: 6.833600
tensor(-5.9229, device='cuda:0') tensor(0.5772, device='cuda:0') tensor(3.8723e-07, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.457188
Average KL loss: 5.262430
Average total loss: 6.719618
tensor(-5.9514, device='cuda:0') tensor(0.5832, device='cuda:0') tensor(3.6154e-07, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.463229
Average KL loss: 5.155459
Average total loss: 6.618688
tensor(-5.9797, device='cuda:0') tensor(0.5893, device='cuda:0') tensor(3.7609e-07, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.459733
Average KL loss: 5.052136
Average total loss: 6.511869
tensor(-6.0077, device='cuda:0') tensor(0.5953, device='cuda:0') tensor(3.3512e-07, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.452112
Average KL loss: 4.952350
Average total loss: 6.404462
tensor(-6.0355, device='cuda:0') tensor(0.6014, device='cuda:0') tensor(3.5562e-07, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.439267
Average KL loss: 4.855267
Average total loss: 6.294534
tensor(-6.0630, device='cuda:0') tensor(0.6075, device='cuda:0') tensor(3.7348e-07, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.450869
Average KL loss: 4.760955
Average total loss: 6.211824
tensor(-6.0904, device='cuda:0') tensor(0.6136, device='cuda:0') tensor(3.3594e-07, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.435716
Average KL loss: 4.669782
Average total loss: 6.105498
tensor(-6.1176, device='cuda:0') tensor(0.6197, device='cuda:0') tensor(3.3689e-07, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.448750
Average KL loss: 4.581601
Average total loss: 6.030351
tensor(-6.1446, device='cuda:0') tensor(0.6258, device='cuda:0') tensor(3.4426e-07, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.441551
Average KL loss: 4.495575
Average total loss: 5.937126
tensor(-6.1714, device='cuda:0') tensor(0.6319, device='cuda:0') tensor(3.2885e-07, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.417984
Average KL loss: 4.412183
Average total loss: 5.830166
tensor(-6.1980, device='cuda:0') tensor(0.6380, device='cuda:0') tensor(3.0801e-07, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.427829
Average KL loss: 4.331180
Average total loss: 5.759009
tensor(-6.2245, device='cuda:0') tensor(0.6441, device='cuda:0') tensor(3.3006e-07, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.428890
Average KL loss: 4.252719
Average total loss: 5.681608
tensor(-6.2508, device='cuda:0') tensor(0.6503, device='cuda:0') tensor(2.8939e-07, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.416177
Average KL loss: 4.176339
Average total loss: 5.592516
tensor(-6.2769, device='cuda:0') tensor(0.6565, device='cuda:0') tensor(2.9492e-07, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.415113
Average KL loss: 4.102161
Average total loss: 5.517274
tensor(-6.3029, device='cuda:0') tensor(0.6627, device='cuda:0') tensor(2.8774e-07, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.412947
Average KL loss: 4.029691
Average total loss: 5.442639
tensor(-6.3287, device='cuda:0') tensor(0.6688, device='cuda:0') tensor(2.8346e-07, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.414844
Average KL loss: 3.959614
Average total loss: 5.374458
tensor(-6.3544, device='cuda:0') tensor(0.6751, device='cuda:0') tensor(2.9148e-07, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.409013
Average KL loss: 3.891403
Average total loss: 5.300416
tensor(-6.3799, device='cuda:0') tensor(0.6813, device='cuda:0') tensor(2.6312e-07, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.398938
Average KL loss: 3.824878
Average total loss: 5.223817
tensor(-6.4054, device='cuda:0') tensor(0.6875, device='cuda:0') tensor(2.5958e-07, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.394064
Average KL loss: 3.759690
Average total loss: 5.153755
tensor(-6.4307, device='cuda:0') tensor(0.6938, device='cuda:0') tensor(2.6650e-07, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.411548
Average KL loss: 3.696754
Average total loss: 5.108302
tensor(-6.4558, device='cuda:0') tensor(0.7001, device='cuda:0') tensor(2.5542e-07, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.390093
Average KL loss: 3.635545
Average total loss: 5.025638
tensor(-6.4809, device='cuda:0') tensor(0.7063, device='cuda:0') tensor(2.6010e-07, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.400198
Average KL loss: 3.575193
Average total loss: 4.975391
tensor(-6.5058, device='cuda:0') tensor(0.7126, device='cuda:0') tensor(2.3601e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.381594
Average KL loss: 3.516799
Average total loss: 4.898393
tensor(-6.5306, device='cuda:0') tensor(0.7190, device='cuda:0') tensor(2.3741e-07, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.384941
Average KL loss: 3.459704
Average total loss: 4.844645
tensor(-6.5553, device='cuda:0') tensor(0.7253, device='cuda:0') tensor(2.3907e-07, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.385717
Average KL loss: 3.403772
Average total loss: 4.789489
tensor(-6.5800, device='cuda:0') tensor(0.7316, device='cuda:0') tensor(2.3433e-07, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.386409
Average KL loss: 3.349192
Average total loss: 4.735601
tensor(-6.6045, device='cuda:0') tensor(0.7379, device='cuda:0') tensor(2.4686e-07, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.376168
Average KL loss: 3.296326
Average total loss: 4.672494
tensor(-6.6289, device='cuda:0') tensor(0.7443, device='cuda:0') tensor(2.3489e-07, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.377475
Average KL loss: 3.244446
Average total loss: 4.621921
tensor(-6.6532, device='cuda:0') tensor(0.7507, device='cuda:0') tensor(1.9913e-07, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.388670
Average KL loss: 3.193969
Average total loss: 4.582639
tensor(-6.6774, device='cuda:0') tensor(0.7571, device='cuda:0') tensor(2.0614e-07, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.379600
Average KL loss: 3.145048
Average total loss: 4.524649
tensor(-6.7016, device='cuda:0') tensor(0.7636, device='cuda:0') tensor(2.1460e-07, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.382124
Average KL loss: 3.097313
Average total loss: 4.479436
tensor(-6.7257, device='cuda:0') tensor(0.7701, device='cuda:0') tensor(1.9312e-07, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.373813
Average KL loss: 3.050732
Average total loss: 4.424545
tensor(-6.7496, device='cuda:0') tensor(0.7766, device='cuda:0') tensor(2.0175e-07, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.364700
Average KL loss: 3.004871
Average total loss: 4.369571
tensor(-6.7736, device='cuda:0') tensor(0.7831, device='cuda:0') tensor(2.0606e-07, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.359124
Average KL loss: 2.960021
Average total loss: 4.319145
tensor(-6.7974, device='cuda:0') tensor(0.7896, device='cuda:0') tensor(1.9031e-07, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.352006
Average KL loss: 2.916201
Average total loss: 4.268206
tensor(-6.8212, device='cuda:0') tensor(0.7961, device='cuda:0') tensor(1.7961e-07, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.361599
Average KL loss: 2.873423
Average total loss: 4.235022
tensor(-6.8448, device='cuda:0') tensor(0.8027, device='cuda:0') tensor(2.0171e-07, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.350057
Average KL loss: 2.831493
Average total loss: 4.181550
tensor(-6.8685, device='cuda:0') tensor(0.8092, device='cuda:0') tensor(1.9168e-07, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.352241
Average KL loss: 2.790439
Average total loss: 4.142680
tensor(-6.8920, device='cuda:0') tensor(0.8158, device='cuda:0') tensor(1.8576e-07, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.347856
Average KL loss: 2.750317
Average total loss: 4.098173
tensor(-6.9156, device='cuda:0') tensor(0.8223, device='cuda:0') tensor(1.7166e-07, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.351826
Average KL loss: 2.710990
Average total loss: 4.062816
tensor(-6.9390, device='cuda:0') tensor(0.8289, device='cuda:0') tensor(1.6826e-07, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.344304
Average KL loss: 2.672448
Average total loss: 4.016752
tensor(-6.9624, device='cuda:0') tensor(0.8355, device='cuda:0') tensor(1.8527e-07, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.340020
Average KL loss: 2.634711
Average total loss: 3.974731
tensor(-6.9857, device='cuda:0') tensor(0.8421, device='cuda:0') tensor(1.6175e-07, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.346052
Average KL loss: 2.597991
Average total loss: 3.944042
tensor(-7.0090, device='cuda:0') tensor(0.8488, device='cuda:0') tensor(1.5984e-07, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.333556
Average KL loss: 2.561823
Average total loss: 3.895379
tensor(-7.0322, device='cuda:0') tensor(0.8555, device='cuda:0') tensor(1.6393e-07, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.332045
Average KL loss: 2.526310
Average total loss: 3.858356
tensor(-7.0554, device='cuda:0') tensor(0.8621, device='cuda:0') tensor(1.6827e-07, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.330346
Average KL loss: 2.491791
Average total loss: 3.822137
tensor(-7.0785, device='cuda:0') tensor(0.8688, device='cuda:0') tensor(1.6414e-07, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.321500
Average KL loss: 2.457633
Average total loss: 3.779133
tensor(-7.1016, device='cuda:0') tensor(0.8755, device='cuda:0') tensor(1.6436e-07, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.332411
Average KL loss: 2.424217
Average total loss: 3.756628
tensor(-7.1247, device='cuda:0') tensor(0.8822, device='cuda:0') tensor(1.5697e-07, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.331179
Average KL loss: 2.391587
Average total loss: 3.722766
tensor(-7.1477, device='cuda:0') tensor(0.8890, device='cuda:0') tensor(1.4757e-07, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.317691
Average KL loss: 2.359699
Average total loss: 3.677390
tensor(-7.1706, device='cuda:0') tensor(0.8958, device='cuda:0') tensor(1.4625e-07, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.316484
Average KL loss: 2.328370
Average total loss: 3.644854
tensor(-7.1936, device='cuda:0') tensor(0.9025, device='cuda:0') tensor(1.5060e-07, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.313559
Average KL loss: 2.297787
Average total loss: 3.611346
tensor(-7.2164, device='cuda:0') tensor(0.9093, device='cuda:0') tensor(1.2416e-07, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.311324
Average KL loss: 2.267571
Average total loss: 3.578895
tensor(-7.2393, device='cuda:0') tensor(0.9161, device='cuda:0') tensor(1.4065e-07, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.312370
Average KL loss: 2.238117
Average total loss: 3.550487
tensor(-7.2621, device='cuda:0') tensor(0.9229, device='cuda:0') tensor(1.4876e-07, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.296377
Average KL loss: 2.209391
Average total loss: 3.505768
tensor(-7.2849, device='cuda:0') tensor(0.9297, device='cuda:0') tensor(1.3756e-07, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.302992
Average KL loss: 2.180977
Average total loss: 3.483968
tensor(-7.3076, device='cuda:0') tensor(0.9365, device='cuda:0') tensor(1.4016e-07, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.297431
Average KL loss: 2.153043
Average total loss: 3.450474
tensor(-7.3304, device='cuda:0') tensor(0.9434, device='cuda:0') tensor(1.4301e-07, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.300767
Average KL loss: 2.125673
Average total loss: 3.426440
tensor(-7.3531, device='cuda:0') tensor(0.9502, device='cuda:0') tensor(1.3386e-07, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.297690
Average KL loss: 2.098996
Average total loss: 3.396686
tensor(-7.3757, device='cuda:0') tensor(0.9571, device='cuda:0') tensor(1.2699e-07, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.293029
Average KL loss: 2.072754
Average total loss: 3.365783
tensor(-7.3984, device='cuda:0') tensor(0.9640, device='cuda:0') tensor(1.3035e-07, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.289112
Average KL loss: 2.046815
Average total loss: 3.335927
tensor(-7.4210, device='cuda:0') tensor(0.9708, device='cuda:0') tensor(1.1916e-07, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.291491
Average KL loss: 2.021397
Average total loss: 3.312888
tensor(-7.4436, device='cuda:0') tensor(0.9777, device='cuda:0') tensor(1.2732e-07, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.289855
Average KL loss: 1.996377
Average total loss: 3.286232
tensor(-7.4661, device='cuda:0') tensor(0.9846, device='cuda:0') tensor(1.1959e-07, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.287994
Average KL loss: 1.971733
Average total loss: 3.259728
tensor(-7.4887, device='cuda:0') tensor(0.9915, device='cuda:0') tensor(1.1639e-07, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.279029
Average KL loss: 1.947688
Average total loss: 3.226717
tensor(-7.5112, device='cuda:0') tensor(0.9984, device='cuda:0') tensor(1.2256e-07, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.276267
Average KL loss: 1.923976
Average total loss: 3.200243
tensor(-7.5337, device='cuda:0') tensor(1.0053, device='cuda:0') tensor(1.2381e-07, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.281280
Average KL loss: 1.900865
Average total loss: 3.182145
tensor(-7.5562, device='cuda:0') tensor(1.0123, device='cuda:0') tensor(1.1976e-07, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.274036
Average KL loss: 1.878064
Average total loss: 3.152100
tensor(-7.5786, device='cuda:0') tensor(1.0192, device='cuda:0') tensor(1.1350e-07, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.268178
Average KL loss: 1.855714
Average total loss: 3.123892
tensor(-7.6011, device='cuda:0') tensor(1.0261, device='cuda:0') tensor(1.1474e-07, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.263099
Average KL loss: 1.833744
Average total loss: 3.096844
tensor(-7.6235, device='cuda:0') tensor(1.0331, device='cuda:0') tensor(1.0422e-07, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.267380
Average KL loss: 1.812298
Average total loss: 3.079678
tensor(-7.6459, device='cuda:0') tensor(1.0401, device='cuda:0') tensor(1.1119e-07, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.264497
Average KL loss: 1.790933
Average total loss: 3.055430
tensor(-7.6684, device='cuda:0') tensor(1.0470, device='cuda:0') tensor(1.1153e-07, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.273731
Average KL loss: 1.770080
Average total loss: 3.043810
tensor(-7.6907, device='cuda:0') tensor(1.0540, device='cuda:0') tensor(1.0899e-07, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.258840
Average KL loss: 1.749805
Average total loss: 3.008646
tensor(-7.7131, device='cuda:0') tensor(1.0610, device='cuda:0') tensor(1.0274e-07, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.260984
Average KL loss: 1.729587
Average total loss: 2.990571
tensor(-7.7355, device='cuda:0') tensor(1.0679, device='cuda:0') tensor(9.9608e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.260642
Average KL loss: 1.709765
Average total loss: 2.970407
tensor(-7.7578, device='cuda:0') tensor(1.0749, device='cuda:0') tensor(1.0078e-07, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.260533
Average KL loss: 1.690173
Average total loss: 2.950706
tensor(-7.7802, device='cuda:0') tensor(1.0818, device='cuda:0') tensor(9.7399e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.250902
Average KL loss: 1.670894
Average total loss: 2.921795
tensor(-7.8025, device='cuda:0') tensor(1.0888, device='cuda:0') tensor(9.6639e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.255291
Average KL loss: 1.652152
Average total loss: 2.907443
tensor(-7.8248, device='cuda:0') tensor(1.0958, device='cuda:0') tensor(9.7757e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.245238
Average KL loss: 1.633624
Average total loss: 2.878863
tensor(-7.8471, device='cuda:0') tensor(1.1028, device='cuda:0') tensor(9.5869e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.247796
Average KL loss: 1.615393
Average total loss: 2.863189
tensor(-7.8694, device='cuda:0') tensor(1.1098, device='cuda:0') tensor(8.1961e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.246943
Average KL loss: 1.597598
Average total loss: 2.844541
tensor(-7.8917, device='cuda:0') tensor(1.1168, device='cuda:0') tensor(9.0555e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.235077
Average KL loss: 1.579789
Average total loss: 2.814865
tensor(-7.9140, device='cuda:0') tensor(1.1238, device='cuda:0') tensor(9.7662e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.238692
Average KL loss: 1.562423
Average total loss: 2.801114
tensor(-7.9362, device='cuda:0') tensor(1.1308, device='cuda:0') tensor(8.5140e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.237088
Average KL loss: 1.545341
Average total loss: 2.782429
tensor(-7.9585, device='cuda:0') tensor(1.1377, device='cuda:0') tensor(9.1277e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.247135
Average KL loss: 1.528418
Average total loss: 2.775553
tensor(-7.9807, device='cuda:0') tensor(1.1448, device='cuda:0') tensor(9.1637e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.239452
Average KL loss: 1.512086
Average total loss: 2.751537
tensor(-8.0030, device='cuda:0') tensor(1.1518, device='cuda:0') tensor(8.6652e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.236436
Average KL loss: 1.495930
Average total loss: 2.732366
tensor(-8.0252, device='cuda:0') tensor(1.1587, device='cuda:0') tensor(8.8760e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.225737
Average KL loss: 1.479978
Average total loss: 2.705716
tensor(-8.0475, device='cuda:0') tensor(1.1657, device='cuda:0') tensor(7.7059e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.237241
Average KL loss: 1.464419
Average total loss: 2.701660
tensor(-8.0697, device='cuda:0') tensor(1.1727, device='cuda:0') tensor(8.1404e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.225147
Average KL loss: 1.448962
Average total loss: 2.674108
tensor(-8.0919, device='cuda:0') tensor(1.1797, device='cuda:0') tensor(7.8849e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.222808
Average KL loss: 1.433711
Average total loss: 2.656520
tensor(-8.1142, device='cuda:0') tensor(1.1866, device='cuda:0') tensor(8.3603e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.225244
Average KL loss: 1.418697
Average total loss: 2.643941
tensor(-8.1364, device='cuda:0') tensor(1.1936, device='cuda:0') tensor(7.0832e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.222496
Average KL loss: 1.403936
Average total loss: 2.626432
tensor(-8.1586, device='cuda:0') tensor(1.2005, device='cuda:0') tensor(7.7629e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.214218
Average KL loss: 1.389418
Average total loss: 2.603636
tensor(-8.1808, device='cuda:0') tensor(1.2074, device='cuda:0') tensor(8.6912e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.220190
Average KL loss: 1.374924
Average total loss: 2.595114
tensor(-8.2030, device='cuda:0') tensor(1.2143, device='cuda:0') tensor(7.2441e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.221915
Average KL loss: 1.360653
Average total loss: 2.582569
tensor(-8.2252, device='cuda:0') tensor(1.2212, device='cuda:0') tensor(5.9957e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.211357
Average KL loss: 1.346618
Average total loss: 2.557975
tensor(-8.2474, device='cuda:0') tensor(1.2281, device='cuda:0') tensor(7.3136e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.209435
Average KL loss: 1.333033
Average total loss: 2.542468
tensor(-8.2696, device='cuda:0') tensor(1.2351, device='cuda:0') tensor(6.8708e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.213394
Average KL loss: 1.319709
Average total loss: 2.533103
tensor(-8.2918, device='cuda:0') tensor(1.2419, device='cuda:0') tensor(6.7365e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.205229
Average KL loss: 1.306604
Average total loss: 2.511833
tensor(-8.3140, device='cuda:0') tensor(1.2488, device='cuda:0') tensor(7.2894e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.204724
Average KL loss: 1.293695
Average total loss: 2.498418
tensor(-8.3362, device='cuda:0') tensor(1.2557, device='cuda:0') tensor(7.0408e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.210171
Average KL loss: 1.280964
Average total loss: 2.491135
tensor(-8.3583, device='cuda:0') tensor(1.2626, device='cuda:0') tensor(7.1049e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.204633
Average KL loss: 1.268447
Average total loss: 2.473079
tensor(-8.3805, device='cuda:0') tensor(1.2694, device='cuda:0') tensor(6.8870e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 1.202632
Average KL loss: 1.256002
Average total loss: 2.458634
tensor(-8.4027, device='cuda:0') tensor(1.2763, device='cuda:0') tensor(5.9530e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.200381
Average KL loss: 1.243784
Average total loss: 2.444165
tensor(-8.4249, device='cuda:0') tensor(1.2831, device='cuda:0') tensor(6.7841e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.200722
Average KL loss: 1.231639
Average total loss: 2.432361
tensor(-8.4470, device='cuda:0') tensor(1.2899, device='cuda:0') tensor(6.2389e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 1.200030
Average KL loss: 1.219906
Average total loss: 2.419936
tensor(-8.4692, device='cuda:0') tensor(1.2966, device='cuda:0') tensor(5.8476e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 1.188695
Average KL loss: 1.208393
Average total loss: 2.397088
tensor(-8.4914, device='cuda:0') tensor(1.3034, device='cuda:0') tensor(6.4657e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 1.193055
Average KL loss: 1.196848
Average total loss: 2.389903
tensor(-8.5135, device='cuda:0') tensor(1.3101, device='cuda:0') tensor(7.0998e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 1.190461
Average KL loss: 1.185359
Average total loss: 2.375820
tensor(-8.5357, device='cuda:0') tensor(1.3168, device='cuda:0') tensor(5.3807e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 1.188153
Average KL loss: 1.174288
Average total loss: 2.362442
tensor(-8.5578, device='cuda:0') tensor(1.3235, device='cuda:0') tensor(6.2099e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 1.188094
Average KL loss: 1.163338
Average total loss: 2.351431
tensor(-8.5800, device='cuda:0') tensor(1.3302, device='cuda:0') tensor(5.7722e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 1.184146
Average KL loss: 1.152494
Average total loss: 2.336640
tensor(-8.6021, device='cuda:0') tensor(1.3369, device='cuda:0') tensor(5.4931e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 1.182247
Average KL loss: 1.141857
Average total loss: 2.324103
tensor(-8.6243, device='cuda:0') tensor(1.3435, device='cuda:0') tensor(5.6091e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 1.185638
Average KL loss: 1.131251
Average total loss: 2.316888
tensor(-8.6464, device='cuda:0') tensor(1.3502, device='cuda:0') tensor(5.1199e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 1.183925
Average KL loss: 1.120908
Average total loss: 2.304833
tensor(-8.6686, device='cuda:0') tensor(1.3568, device='cuda:0') tensor(5.4298e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 1.182517
Average KL loss: 1.110602
Average total loss: 2.293120
tensor(-8.6907, device='cuda:0') tensor(1.3633, device='cuda:0') tensor(5.6832e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 1.185745
Average KL loss: 1.100625
Average total loss: 2.286370
tensor(-8.7129, device='cuda:0') tensor(1.3699, device='cuda:0') tensor(5.7266e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 1.173311
Average KL loss: 1.090802
Average total loss: 2.264113
tensor(-8.7350, device='cuda:0') tensor(1.3765, device='cuda:0') tensor(4.5257e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 1.176157
Average KL loss: 1.081178
Average total loss: 2.257335
tensor(-8.7571, device='cuda:0') tensor(1.3830, device='cuda:0') tensor(5.9118e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 1.172194
Average KL loss: 1.071603
Average total loss: 2.243798
tensor(-8.7792, device='cuda:0') tensor(1.3895, device='cuda:0') tensor(4.4333e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 1.172210
Average KL loss: 1.062140
Average total loss: 2.234350
tensor(-8.8014, device='cuda:0') tensor(1.3960, device='cuda:0') tensor(4.6984e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 1.169512
Average KL loss: 1.052858
Average total loss: 2.222370
tensor(-8.8235, device='cuda:0') tensor(1.4024, device='cuda:0') tensor(4.8201e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 1.170815
Average KL loss: 1.043754
Average total loss: 2.214569
tensor(-8.8456, device='cuda:0') tensor(1.4088, device='cuda:0') tensor(4.5250e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 1.169569
Average KL loss: 1.034784
Average total loss: 2.204353
tensor(-8.8677, device='cuda:0') tensor(1.4151, device='cuda:0') tensor(4.5663e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 1.165047
Average KL loss: 1.026023
Average total loss: 2.191069
tensor(-8.8898, device='cuda:0') tensor(1.4215, device='cuda:0') tensor(4.0924e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 1.161872
Average KL loss: 1.017324
Average total loss: 2.179197
tensor(-8.9119, device='cuda:0') tensor(1.4278, device='cuda:0') tensor(4.4087e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 1.167329
Average KL loss: 1.008864
Average total loss: 2.176192
tensor(-8.9340, device='cuda:0') tensor(1.4341, device='cuda:0') tensor(4.0183e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 1.158160
Average KL loss: 1.000552
Average total loss: 2.158712
tensor(-8.9561, device='cuda:0') tensor(1.4403, device='cuda:0') tensor(3.8633e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 1.162211
Average KL loss: 0.992292
Average total loss: 2.154503
tensor(-8.9782, device='cuda:0') tensor(1.4466, device='cuda:0') tensor(4.3614e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 1.157788
Average KL loss: 0.984245
Average total loss: 2.142033
tensor(-9.0003, device='cuda:0') tensor(1.4527, device='cuda:0') tensor(4.8463e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 1.158468
Average KL loss: 0.976185
Average total loss: 2.134653
 Percentile value: -8.482975006103516
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =    1716 /    1728             ( 99.31%) | total_pruned =      12 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   33991 /   36864             ( 92.21%) | total_pruned =    2873 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   34071 /   36864             ( 92.42%) | total_pruned =    2793 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   33076 /   36864             ( 89.72%) | total_pruned =    3788 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   32638 /   36864             ( 88.54%) | total_pruned =    4226 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   66040 /   73728             ( 89.57%) | total_pruned =    7688 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  124418 /  147456             ( 84.38%) | total_pruned =   23038 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7930 /    8192             ( 96.80%) | total_pruned =     262 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  118664 /  147456             ( 80.47%) | total_pruned =   28792 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  115807 /  147456             ( 78.54%) | total_pruned =   31649 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  230581 /  294912             ( 78.19%) | total_pruned =   64331 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  402509 /  589824             ( 68.24%) | total_pruned =  187315 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   29779 /   32768             ( 90.88%) | total_pruned =    2989 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  312564 /  589824             ( 52.99%) | total_pruned =  277260 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  301499 /  589824             ( 51.12%) | total_pruned =  288325 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  674980 / 1179648             ( 57.22%) | total_pruned =  504668 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1033722 / 2359296             ( 43.81%) | total_pruned = 1325574 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  107367 /  131072             ( 81.91%) | total_pruned =   23705 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  953948 / 2359296             ( 40.43%) | total_pruned = 1405348 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  959406 / 2359296             ( 40.66%) | total_pruned = 1399890 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5073 /    5120             ( 99.08%) | total_pruned =      47 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 29/100 Loss: 0.000007 Accuracy: 86.46 100.00 % Best test Accuracy: 86.52%
tensor(-9.0223, device='cuda:0') tensor(1.4589, device='cuda:0') tensor(5.3075e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.176400
Average KL loss: 0.893991
Average total loss: 2.070391
tensor(-9.2574, device='cuda:0') tensor(1.2712, device='cuda:0') tensor(3.8866e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.162891
Average KL loss: 0.797890
Average total loss: 1.960781
tensor(-9.4554, device='cuda:0') tensor(1.1530, device='cuda:0') tensor(2.5338e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.165757
Average KL loss: 0.744762
Average total loss: 1.910519
tensor(-9.6245, device='cuda:0') tensor(1.0741, device='cuda:0') tensor(2.1977e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.159253
Average KL loss: 0.710623
Average total loss: 1.869875
tensor(-9.7723, device='cuda:0') tensor(1.0183, device='cuda:0') tensor(1.7856e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.156285
Average KL loss: 0.686597
Average total loss: 1.842881
tensor(-9.9037, device='cuda:0') tensor(0.9772, device='cuda:0') tensor(2.1103e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.150134
Average KL loss: 0.668501
Average total loss: 1.818635
tensor(-10.0221, device='cuda:0') tensor(0.9459, device='cuda:0') tensor(1.8201e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.145274
Average KL loss: 0.654366
Average total loss: 1.799639
tensor(-10.1298, device='cuda:0') tensor(0.9216, device='cuda:0') tensor(2.2123e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.147112
Average KL loss: 0.642832
Average total loss: 1.789944
tensor(-10.2285, device='cuda:0') tensor(0.9023, device='cuda:0') tensor(1.1823e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.143893
Average KL loss: 0.633273
Average total loss: 1.777166
tensor(-10.3198, device='cuda:0') tensor(0.8868, device='cuda:0') tensor(1.7623e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.134662
Average KL loss: 0.625103
Average total loss: 1.759765
tensor(-10.4046, device='cuda:0') tensor(0.8741, device='cuda:0') tensor(6.0834e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.147738
Average KL loss: 0.618031
Average total loss: 1.765769
tensor(-10.4838, device='cuda:0') tensor(0.8636, device='cuda:0') tensor(1.2538e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.137216
Average KL loss: 0.611900
Average total loss: 1.749116
tensor(-10.5581, device='cuda:0') tensor(0.8550, device='cuda:0') tensor(1.6435e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.138839
Average KL loss: 0.606365
Average total loss: 1.745204
tensor(-10.6281, device='cuda:0') tensor(0.8477, device='cuda:0') tensor(7.9854e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.135329
Average KL loss: 0.601539
Average total loss: 1.736869
tensor(-10.6943, device='cuda:0') tensor(0.8416, device='cuda:0') tensor(1.2062e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.140507
Average KL loss: 0.597121
Average total loss: 1.737628
tensor(-10.7570, device='cuda:0') tensor(0.8364, device='cuda:0') tensor(1.1075e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.131154
Average KL loss: 0.592982
Average total loss: 1.724135
tensor(-10.8166, device='cuda:0') tensor(0.8319, device='cuda:0') tensor(7.9196e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.131910
Average KL loss: 0.589245
Average total loss: 1.721155
tensor(-10.8734, device='cuda:0') tensor(0.8280, device='cuda:0') tensor(9.4959e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.132213
Average KL loss: 0.585662
Average total loss: 1.717875
tensor(-10.9277, device='cuda:0') tensor(0.8247, device='cuda:0') tensor(1.4491e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.132697
Average KL loss: 0.582258
Average total loss: 1.714956
tensor(-10.9797, device='cuda:0') tensor(0.8218, device='cuda:0') tensor(9.9938e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.130221
Average KL loss: 0.579091
Average total loss: 1.709312
tensor(-11.0295, device='cuda:0') tensor(0.8193, device='cuda:0') tensor(8.3714e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.121244
Average KL loss: 0.576017
Average total loss: 1.697261
tensor(-11.0773, device='cuda:0') tensor(0.8171, device='cuda:0') tensor(1.5233e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.122613
Average KL loss: 0.573125
Average total loss: 1.695737
tensor(-11.1233, device='cuda:0') tensor(0.8151, device='cuda:0') tensor(8.6103e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.119875
Average KL loss: 0.570393
Average total loss: 1.690268
tensor(-11.1677, device='cuda:0') tensor(0.8134, device='cuda:0') tensor(8.2821e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.115027
Average KL loss: 0.567875
Average total loss: 1.682902
tensor(-11.2104, device='cuda:0') tensor(0.8119, device='cuda:0') tensor(3.1405e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.122437
Average KL loss: 0.565371
Average total loss: 1.687808
tensor(-11.2518, device='cuda:0') tensor(0.8106, device='cuda:0') tensor(1.5471e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.125726
Average KL loss: 0.562957
Average total loss: 1.688683
tensor(-11.2917, device='cuda:0') tensor(0.8094, device='cuda:0') tensor(2.3561e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.110182
Average KL loss: 0.560766
Average total loss: 1.670948
tensor(-11.3304, device='cuda:0') tensor(0.8084, device='cuda:0') tensor(9.3847e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.113534
Average KL loss: 0.558664
Average total loss: 1.672197
tensor(-11.3679, device='cuda:0') tensor(0.8074, device='cuda:0') tensor(8.9980e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.109197
Average KL loss: 0.556607
Average total loss: 1.665803
tensor(-11.4043, device='cuda:0') tensor(0.8066, device='cuda:0') tensor(9.2894e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.111649
Average KL loss: 0.554642
Average total loss: 1.666291
tensor(-11.4396, device='cuda:0') tensor(0.8058, device='cuda:0') tensor(1.3429e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.106224
Average KL loss: 0.552687
Average total loss: 1.658911
tensor(-11.4740, device='cuda:0') tensor(0.8051, device='cuda:0') tensor(1.3140e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.110867
Average KL loss: 0.550771
Average total loss: 1.661637
tensor(-11.5074, device='cuda:0') tensor(0.8045, device='cuda:0') tensor(6.6768e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.111144
Average KL loss: 0.548961
Average total loss: 1.660105
tensor(-11.5399, device='cuda:0') tensor(0.8039, device='cuda:0') tensor(4.7557e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.102659
Average KL loss: 0.547239
Average total loss: 1.649899
tensor(-11.5715, device='cuda:0') tensor(0.8033, device='cuda:0') tensor(1.2847e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.104225
Average KL loss: 0.545499
Average total loss: 1.649725
tensor(-11.6024, device='cuda:0') tensor(0.8028, device='cuda:0') tensor(4.4121e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.095550
Average KL loss: 0.543806
Average total loss: 1.639356
tensor(-11.6325, device='cuda:0') tensor(0.8023, device='cuda:0') tensor(1.0566e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.100923
Average KL loss: 0.542110
Average total loss: 1.643033
tensor(-11.6619, device='cuda:0') tensor(0.8018, device='cuda:0') tensor(5.7605e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.091967
Average KL loss: 0.540404
Average total loss: 1.632371
tensor(-11.6906, device='cuda:0') tensor(0.8013, device='cuda:0') tensor(1.0164e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.097834
Average KL loss: 0.538728
Average total loss: 1.636561
tensor(-11.7186, device='cuda:0') tensor(0.8009, device='cuda:0') tensor(9.0729e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.094174
Average KL loss: 0.536972
Average total loss: 1.631147
tensor(-11.7460, device='cuda:0') tensor(0.8004, device='cuda:0') tensor(7.7375e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.094812
Average KL loss: 0.535391
Average total loss: 1.630203
tensor(-11.7728, device='cuda:0') tensor(0.8000, device='cuda:0') tensor(2.5647e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.092668
Average KL loss: 0.533860
Average total loss: 1.626528
tensor(-11.7991, device='cuda:0') tensor(0.7997, device='cuda:0') tensor(8.0995e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.099637
Average KL loss: 0.532377
Average total loss: 1.632014
tensor(-11.8247, device='cuda:0') tensor(0.7993, device='cuda:0') tensor(7.3279e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.091131
Average KL loss: 0.530908
Average total loss: 1.622039
tensor(-11.8499, device='cuda:0') tensor(0.7989, device='cuda:0') tensor(7.0797e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.094532
Average KL loss: 0.529367
Average total loss: 1.623899
tensor(-11.8745, device='cuda:0') tensor(0.7985, device='cuda:0') tensor(2.4311e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.088545
Average KL loss: 0.528016
Average total loss: 1.616561
tensor(-11.8987, device='cuda:0') tensor(0.7981, device='cuda:0') tensor(4.5578e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.090155
Average KL loss: 0.526590
Average total loss: 1.616745
tensor(-11.9224, device='cuda:0') tensor(0.7977, device='cuda:0') tensor(1.0558e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.086454
Average KL loss: 0.525208
Average total loss: 1.611661
tensor(-11.9456, device='cuda:0') tensor(0.7973, device='cuda:0') tensor(3.4831e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.086362
Average KL loss: 0.523972
Average total loss: 1.610334
tensor(-11.9685, device='cuda:0') tensor(0.7970, device='cuda:0') tensor(9.9823e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.083034
Average KL loss: 0.522754
Average total loss: 1.605788
tensor(-11.9908, device='cuda:0') tensor(0.7966, device='cuda:0') tensor(6.9461e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.087384
Average KL loss: 0.521544
Average total loss: 1.608928
tensor(-12.0128, device='cuda:0') tensor(0.7962, device='cuda:0') tensor(1.1995e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.083478
Average KL loss: 0.520270
Average total loss: 1.603748
tensor(-12.0344, device='cuda:0') tensor(0.7958, device='cuda:0') tensor(6.1806e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.072853
Average KL loss: 0.519160
Average total loss: 1.592013
tensor(-12.0557, device='cuda:0') tensor(0.7954, device='cuda:0') tensor(7.7524e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.080127
Average KL loss: 0.517903
Average total loss: 1.598030
tensor(-12.0765, device='cuda:0') tensor(0.7950, device='cuda:0') tensor(5.7140e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.081957
Average KL loss: 0.516626
Average total loss: 1.598583
tensor(-12.0971, device='cuda:0') tensor(0.7946, device='cuda:0') tensor(6.2734e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.076948
Average KL loss: 0.515317
Average total loss: 1.592265
tensor(-12.1172, device='cuda:0') tensor(0.7941, device='cuda:0') tensor(4.6641e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.077920
Average KL loss: 0.514022
Average total loss: 1.591942
tensor(-12.1371, device='cuda:0') tensor(0.7937, device='cuda:0') tensor(1.2889e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.074398
Average KL loss: 0.512753
Average total loss: 1.587150
tensor(-12.1566, device='cuda:0') tensor(0.7932, device='cuda:0') tensor(4.8551e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.069807
Average KL loss: 0.511661
Average total loss: 1.581469
tensor(-12.1759, device='cuda:0') tensor(0.7928, device='cuda:0') tensor(7.9196e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.074332
Average KL loss: 0.510668
Average total loss: 1.585000
tensor(-12.1948, device='cuda:0') tensor(0.7924, device='cuda:0') tensor(4.5384e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.069344
Average KL loss: 0.509614
Average total loss: 1.578958
tensor(-12.2134, device='cuda:0') tensor(0.7920, device='cuda:0') tensor(6.0915e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.067517
Average KL loss: 0.508501
Average total loss: 1.576018
tensor(-12.2318, device='cuda:0') tensor(0.7915, device='cuda:0') tensor(5.8275e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.071391
Average KL loss: 0.507392
Average total loss: 1.578782
tensor(-12.2499, device='cuda:0') tensor(0.7910, device='cuda:0') tensor(9.8498e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.072764
Average KL loss: 0.506279
Average total loss: 1.579043
tensor(-12.2677, device='cuda:0') tensor(0.7905, device='cuda:0') tensor(4.4935e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.064838
Average KL loss: 0.505257
Average total loss: 1.570095
tensor(-12.2853, device='cuda:0') tensor(0.7900, device='cuda:0') tensor(2.7284e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.061847
Average KL loss: 0.504248
Average total loss: 1.566094
tensor(-12.3026, device='cuda:0') tensor(0.7895, device='cuda:0') tensor(9.4863e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.063032
Average KL loss: 0.503218
Average total loss: 1.566250
tensor(-12.3197, device='cuda:0') tensor(0.7889, device='cuda:0') tensor(8.6169e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.065988
Average KL loss: 0.502139
Average total loss: 1.568128
tensor(-12.3365, device='cuda:0') tensor(0.7884, device='cuda:0') tensor(4.7026e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.059315
Average KL loss: 0.501109
Average total loss: 1.560424
tensor(-12.3531, device='cuda:0') tensor(0.7879, device='cuda:0') tensor(1.3690e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.058687
Average KL loss: 0.500136
Average total loss: 1.558823
tensor(-12.3695, device='cuda:0') tensor(0.7873, device='cuda:0') tensor(6.7543e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.058362
Average KL loss: 0.499066
Average total loss: 1.557428
tensor(-12.3857, device='cuda:0') tensor(0.7867, device='cuda:0') tensor(6.3117e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.058030
Average KL loss: 0.497971
Average total loss: 1.556001
tensor(-12.4016, device='cuda:0') tensor(0.7861, device='cuda:0') tensor(4.7292e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.059743
Average KL loss: 0.496918
Average total loss: 1.556661
tensor(-12.4174, device='cuda:0') tensor(0.7856, device='cuda:0') tensor(7.1582e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.054591
Average KL loss: 0.495963
Average total loss: 1.550553
tensor(-12.4329, device='cuda:0') tensor(0.7850, device='cuda:0') tensor(5.4584e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.052482
Average KL loss: 0.495007
Average total loss: 1.547490
tensor(-12.4482, device='cuda:0') tensor(0.7844, device='cuda:0') tensor(2.6897e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.052189
Average KL loss: 0.494041
Average total loss: 1.546230
tensor(-12.4634, device='cuda:0') tensor(0.7838, device='cuda:0') tensor(6.4487e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.052213
Average KL loss: 0.492981
Average total loss: 1.545194
tensor(-12.4784, device='cuda:0') tensor(0.7831, device='cuda:0') tensor(2.6786e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.047482
Average KL loss: 0.492014
Average total loss: 1.539496
tensor(-12.4932, device='cuda:0') tensor(0.7825, device='cuda:0') tensor(5.8858e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.052956
Average KL loss: 0.491174
Average total loss: 1.544130
tensor(-12.5078, device='cuda:0') tensor(0.7819, device='cuda:0') tensor(5.7213e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.046587
Average KL loss: 0.490250
Average total loss: 1.536837
tensor(-12.5222, device='cuda:0') tensor(0.7812, device='cuda:0') tensor(6.9511e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.047196
Average KL loss: 0.489392
Average total loss: 1.536588
tensor(-12.5365, device='cuda:0') tensor(0.7805, device='cuda:0') tensor(9.6633e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.047493
Average KL loss: 0.488519
Average total loss: 1.536012
tensor(-12.5505, device='cuda:0') tensor(0.7798, device='cuda:0') tensor(1.0877e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.044271
Average KL loss: 0.487521
Average total loss: 1.531792
tensor(-12.5645, device='cuda:0') tensor(0.7791, device='cuda:0') tensor(4.2364e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.045032
Average KL loss: 0.486708
Average total loss: 1.531740
tensor(-12.5782, device='cuda:0') tensor(0.7784, device='cuda:0') tensor(7.0272e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.043385
Average KL loss: 0.485829
Average total loss: 1.529214
tensor(-12.5919, device='cuda:0') tensor(0.7777, device='cuda:0') tensor(3.8037e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.048375
Average KL loss: 0.485019
Average total loss: 1.533394
tensor(-12.6053, device='cuda:0') tensor(0.7770, device='cuda:0') tensor(5.2908e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.038809
Average KL loss: 0.484142
Average total loss: 1.522952
tensor(-12.6186, device='cuda:0') tensor(0.7762, device='cuda:0') tensor(1.4221e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.039874
Average KL loss: 0.483267
Average total loss: 1.523141
tensor(-12.6318, device='cuda:0') tensor(0.7755, device='cuda:0') tensor(2.6693e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.039035
Average KL loss: 0.482521
Average total loss: 1.521556
tensor(-12.6448, device='cuda:0') tensor(0.7747, device='cuda:0') tensor(6.6251e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.037066
Average KL loss: 0.481758
Average total loss: 1.518824
tensor(-12.6577, device='cuda:0') tensor(0.7740, device='cuda:0') tensor(4.1098e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.039584
Average KL loss: 0.481027
Average total loss: 1.520611
tensor(-12.6705, device='cuda:0') tensor(0.7732, device='cuda:0') tensor(3.1362e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.037194
Average KL loss: 0.480203
Average total loss: 1.517398
tensor(-12.6831, device='cuda:0') tensor(0.7724, device='cuda:0') tensor(4.0452e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.039121
Average KL loss: 0.479398
Average total loss: 1.518519
tensor(-12.6955, device='cuda:0') tensor(0.7717, device='cuda:0') tensor(4.1652e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.036227
Average KL loss: 0.478637
Average total loss: 1.514864
tensor(-12.7079, device='cuda:0') tensor(0.7709, device='cuda:0') tensor(7.3485e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.032640
Average KL loss: 0.477846
Average total loss: 1.510486
tensor(-12.7201, device='cuda:0') tensor(0.7700, device='cuda:0') tensor(5.7726e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.031943
Average KL loss: 0.477136
Average total loss: 1.509078
tensor(-12.7322, device='cuda:0') tensor(0.7692, device='cuda:0') tensor(3.7145e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.031663
Average KL loss: 0.476361
Average total loss: 1.508023
tensor(-12.7442, device='cuda:0') tensor(0.7684, device='cuda:0') tensor(3.7032e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.026620
Average KL loss: 0.475486
Average total loss: 1.502105
tensor(-12.7561, device='cuda:0') tensor(0.7675, device='cuda:0') tensor(1.0000e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.032473
Average KL loss: 0.474771
Average total loss: 1.507244
tensor(-12.7678, device='cuda:0') tensor(0.7667, device='cuda:0') tensor(7.9944e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.031205
Average KL loss: 0.473972
Average total loss: 1.505177
tensor(-12.7794, device='cuda:0') tensor(0.7658, device='cuda:0') tensor(-1.1598e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.031386
Average KL loss: 0.473136
Average total loss: 1.504521
tensor(-12.7909, device='cuda:0') tensor(0.7650, device='cuda:0') tensor(6.4400e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.025254
Average KL loss: 0.472356
Average total loss: 1.497610
tensor(-12.8023, device='cuda:0') tensor(0.7641, device='cuda:0') tensor(6.7677e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.024897
Average KL loss: 0.471631
Average total loss: 1.496528
tensor(-12.8136, device='cuda:0') tensor(0.7632, device='cuda:0') tensor(4.1852e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.028428
Average KL loss: 0.470918
Average total loss: 1.499346
tensor(-12.8248, device='cuda:0') tensor(0.7623, device='cuda:0') tensor(6.7599e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.021660
Average KL loss: 0.470233
Average total loss: 1.491893
tensor(-12.8359, device='cuda:0') tensor(0.7614, device='cuda:0') tensor(2.2544e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.022785
Average KL loss: 0.469535
Average total loss: 1.492320
tensor(-12.8469, device='cuda:0') tensor(0.7605, device='cuda:0') tensor(2.2110e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.021902
Average KL loss: 0.468812
Average total loss: 1.490713
tensor(-12.8577, device='cuda:0') tensor(0.7595, device='cuda:0') tensor(9.3440e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.020834
Average KL loss: 0.468119
Average total loss: 1.488953
tensor(-12.8685, device='cuda:0') tensor(0.7587, device='cuda:0') tensor(4.2046e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.021337
Average KL loss: 0.467459
Average total loss: 1.488796
tensor(-12.8792, device='cuda:0') tensor(0.7577, device='cuda:0') tensor(2.3284e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.022232
Average KL loss: 0.466814
Average total loss: 1.489046
tensor(-12.8898, device='cuda:0') tensor(0.7568, device='cuda:0') tensor(6.8560e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.018247
Average KL loss: 0.466067
Average total loss: 1.484313
tensor(-12.9002, device='cuda:0') tensor(0.7558, device='cuda:0') tensor(5.2388e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.019587
Average KL loss: 0.465366
Average total loss: 1.484953
tensor(-12.9106, device='cuda:0') tensor(0.7549, device='cuda:0') tensor(6.9447e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.017916
Average KL loss: 0.464663
Average total loss: 1.482579
tensor(-12.9209, device='cuda:0') tensor(0.7539, device='cuda:0') tensor(5.2271e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.013785
Average KL loss: 0.463953
Average total loss: 1.477738
tensor(-12.9311, device='cuda:0') tensor(0.7530, device='cuda:0') tensor(7.0866e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.014178
Average KL loss: 0.463240
Average total loss: 1.477417
tensor(-12.9412, device='cuda:0') tensor(0.7520, device='cuda:0') tensor(5.5719e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.016993
Average KL loss: 0.462653
Average total loss: 1.479646
tensor(-12.9513, device='cuda:0') tensor(0.7510, device='cuda:0') tensor(4.7032e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.009687
Average KL loss: 0.462041
Average total loss: 1.471729
tensor(-12.9612, device='cuda:0') tensor(0.7500, device='cuda:0') tensor(4.0300e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.011556
Average KL loss: 0.461421
Average total loss: 1.472977
tensor(-12.9711, device='cuda:0') tensor(0.7490, device='cuda:0') tensor(4.2572e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.008178
Average KL loss: 0.460838
Average total loss: 1.469015
tensor(-12.9809, device='cuda:0') tensor(0.7480, device='cuda:0') tensor(3.6540e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.009755
Average KL loss: 0.460267
Average total loss: 1.470022
tensor(-12.9906, device='cuda:0') tensor(0.7470, device='cuda:0') tensor(4.3256e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.012775
Average KL loss: 0.459815
Average total loss: 1.472590
tensor(-13.0002, device='cuda:0') tensor(0.7460, device='cuda:0') tensor(3.1512e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.011384
Average KL loss: 0.459293
Average total loss: 1.470677
tensor(-13.0097, device='cuda:0') tensor(0.7450, device='cuda:0') tensor(3.6199e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.007140
Average KL loss: 0.458745
Average total loss: 1.465885
tensor(-13.0192, device='cuda:0') tensor(0.7439, device='cuda:0') tensor(3.9092e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.009810
Average KL loss: 0.458177
Average total loss: 1.467986
tensor(-13.0286, device='cuda:0') tensor(0.7429, device='cuda:0') tensor(6.2221e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.006462
Average KL loss: 0.457476
Average total loss: 1.463938
tensor(-13.0379, device='cuda:0') tensor(0.7418, device='cuda:0') tensor(3.6375e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.007457
Average KL loss: 0.456854
Average total loss: 1.464311
tensor(-13.0471, device='cuda:0') tensor(0.7408, device='cuda:0') tensor(4.7912e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.002697
Average KL loss: 0.456220
Average total loss: 1.458917
tensor(-13.0563, device='cuda:0') tensor(0.7397, device='cuda:0') tensor(1.8132e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.002084
Average KL loss: 0.455680
Average total loss: 1.457764
tensor(-13.0654, device='cuda:0') tensor(0.7386, device='cuda:0') tensor(3.4046e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.004606
Average KL loss: 0.455012
Average total loss: 1.459619
tensor(-13.0744, device='cuda:0') tensor(0.7375, device='cuda:0') tensor(2.3763e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.001021
Average KL loss: 0.454463
Average total loss: 1.455484
tensor(-13.0833, device='cuda:0') tensor(0.7365, device='cuda:0') tensor(4.0606e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.002222
Average KL loss: 0.453911
Average total loss: 1.456133
tensor(-13.0922, device='cuda:0') tensor(0.7354, device='cuda:0') tensor(5.3368e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.002938
Average KL loss: 0.453399
Average total loss: 1.456338
tensor(-13.1010, device='cuda:0') tensor(0.7343, device='cuda:0') tensor(3.0178e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.997878
Average KL loss: 0.452855
Average total loss: 1.450733
tensor(-13.1098, device='cuda:0') tensor(0.7332, device='cuda:0') tensor(4.0353e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.997018
Average KL loss: 0.452284
Average total loss: 1.449302
tensor(-13.1184, device='cuda:0') tensor(0.7321, device='cuda:0') tensor(3.8535e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.994964
Average KL loss: 0.451716
Average total loss: 1.446680
tensor(-13.1270, device='cuda:0') tensor(0.7310, device='cuda:0') tensor(2.6466e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.998521
Average KL loss: 0.451135
Average total loss: 1.449656
tensor(-13.1356, device='cuda:0') tensor(0.7298, device='cuda:0') tensor(5.7565e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.001416
Average KL loss: 0.450565
Average total loss: 1.451981
tensor(-13.1441, device='cuda:0') tensor(0.7287, device='cuda:0') tensor(6.4202e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.994453
Average KL loss: 0.449941
Average total loss: 1.444394
tensor(-13.1525, device='cuda:0') tensor(0.7276, device='cuda:0') tensor(4.3752e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.993341
Average KL loss: 0.449410
Average total loss: 1.442751
tensor(-13.1608, device='cuda:0') tensor(0.7264, device='cuda:0') tensor(4.1001e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.997031
Average KL loss: 0.448951
Average total loss: 1.445982
tensor(-13.1691, device='cuda:0') tensor(0.7253, device='cuda:0') tensor(4.2576e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.991293
Average KL loss: 0.448440
Average total loss: 1.439733
tensor(-13.1774, device='cuda:0') tensor(0.7241, device='cuda:0') tensor(2.0528e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.992021
Average KL loss: 0.447874
Average total loss: 1.439895
tensor(-13.1856, device='cuda:0') tensor(0.7230, device='cuda:0') tensor(1.4568e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.991625
Average KL loss: 0.447385
Average total loss: 1.439010
tensor(-13.1937, device='cuda:0') tensor(0.7218, device='cuda:0') tensor(5.5142e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.991347
Average KL loss: 0.446831
Average total loss: 1.438179
tensor(-13.2017, device='cuda:0') tensor(0.7206, device='cuda:0') tensor(2.9985e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.991459
Average KL loss: 0.446318
Average total loss: 1.437777
tensor(-13.2098, device='cuda:0') tensor(0.7194, device='cuda:0') tensor(2.5752e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.990591
Average KL loss: 0.445830
Average total loss: 1.436421
tensor(-13.2177, device='cuda:0') tensor(0.7182, device='cuda:0') tensor(5.3279e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.989866
Average KL loss: 0.445369
Average total loss: 1.435235
tensor(-13.2256, device='cuda:0') tensor(0.7171, device='cuda:0') tensor(4.9589e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.984831
Average KL loss: 0.444905
Average total loss: 1.429735
tensor(-13.2334, device='cuda:0') tensor(0.7159, device='cuda:0') tensor(6.2336e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.985603
Average KL loss: 0.444390
Average total loss: 1.429993
tensor(-13.2412, device='cuda:0') tensor(0.7147, device='cuda:0') tensor(-5.8294e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.988040
Average KL loss: 0.443894
Average total loss: 1.431935
tensor(-13.2490, device='cuda:0') tensor(0.7135, device='cuda:0') tensor(4.3658e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.987378
Average KL loss: 0.443430
Average total loss: 1.430808
tensor(-13.2566, device='cuda:0') tensor(0.7124, device='cuda:0') tensor(-3.3181e-11, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.986384
Average KL loss: 0.443025
Average total loss: 1.429409
tensor(-13.2643, device='cuda:0') tensor(0.7112, device='cuda:0') tensor(3.2021e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.984668
Average KL loss: 0.442661
Average total loss: 1.427330
tensor(-13.2718, device='cuda:0') tensor(0.7100, device='cuda:0') tensor(2.0023e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.983237
Average KL loss: 0.442209
Average total loss: 1.425446
tensor(-13.2794, device='cuda:0') tensor(0.7087, device='cuda:0') tensor(2.0301e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.984245
Average KL loss: 0.441709
Average total loss: 1.425954
tensor(-13.2868, device='cuda:0') tensor(0.7075, device='cuda:0') tensor(1.5449e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.982121
Average KL loss: 0.441269
Average total loss: 1.423390
tensor(-13.2943, device='cuda:0') tensor(0.7063, device='cuda:0') tensor(1.8058e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.983518
Average KL loss: 0.440807
Average total loss: 1.424325
tensor(-13.3017, device='cuda:0') tensor(0.7051, device='cuda:0') tensor(5.3795e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.982433
Average KL loss: 0.440360
Average total loss: 1.422793
tensor(-13.3090, device='cuda:0') tensor(0.7038, device='cuda:0') tensor(5.1216e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.981638
Average KL loss: 0.439949
Average total loss: 1.421587
tensor(-13.3163, device='cuda:0') tensor(0.7026, device='cuda:0') tensor(2.6733e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.981571
Average KL loss: 0.439520
Average total loss: 1.421091
tensor(-13.3235, device='cuda:0') tensor(0.7013, device='cuda:0') tensor(4.3898e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.977940
Average KL loss: 0.439106
Average total loss: 1.417045
tensor(-13.3307, device='cuda:0') tensor(0.7001, device='cuda:0') tensor(4.1273e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.978119
Average KL loss: 0.438746
Average total loss: 1.416865
tensor(-13.3378, device='cuda:0') tensor(0.6989, device='cuda:0') tensor(2.7622e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.982023
Average KL loss: 0.438359
Average total loss: 1.420382
tensor(-13.3449, device='cuda:0') tensor(0.6977, device='cuda:0') tensor(2.1220e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.979756
Average KL loss: 0.437940
Average total loss: 1.417697
tensor(-13.3520, device='cuda:0') tensor(0.6964, device='cuda:0') tensor(3.3094e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.973687
Average KL loss: 0.437523
Average total loss: 1.411210
tensor(-13.3590, device='cuda:0') tensor(0.6952, device='cuda:0') tensor(-5.8358e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.975643
Average KL loss: 0.437074
Average total loss: 1.412717
tensor(-13.3660, device='cuda:0') tensor(0.6939, device='cuda:0') tensor(6.3373e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.978615
Average KL loss: 0.436634
Average total loss: 1.415250
tensor(-13.3729, device='cuda:0') tensor(0.6927, device='cuda:0') tensor(5.7310e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.978491
Average KL loss: 0.436224
Average total loss: 1.414715
tensor(-13.3798, device='cuda:0') tensor(0.6915, device='cuda:0') tensor(2.0867e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.971987
Average KL loss: 0.435911
Average total loss: 1.407897
tensor(-13.3866, device='cuda:0') tensor(0.6902, device='cuda:0') tensor(3.2141e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.976701
Average KL loss: 0.435488
Average total loss: 1.412189
tensor(-13.3934, device='cuda:0') tensor(0.6889, device='cuda:0') tensor(3.3647e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.972247
Average KL loss: 0.435052
Average total loss: 1.407300
tensor(-13.4002, device='cuda:0') tensor(0.6876, device='cuda:0') tensor(2.0314e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.971967
Average KL loss: 0.434647
Average total loss: 1.406614
tensor(-13.4069, device='cuda:0') tensor(0.6863, device='cuda:0') tensor(3.3277e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.973622
Average KL loss: 0.434282
Average total loss: 1.407904
tensor(-13.4136, device='cuda:0') tensor(0.6851, device='cuda:0') tensor(5.1062e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.971227
Average KL loss: 0.433950
Average total loss: 1.405178
tensor(-13.4202, device='cuda:0') tensor(0.6838, device='cuda:0') tensor(1.5632e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.972315
Average KL loss: 0.433572
Average total loss: 1.405887
tensor(-13.4268, device='cuda:0') tensor(0.6825, device='cuda:0') tensor(4.2310e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.969818
Average KL loss: 0.433262
Average total loss: 1.403079
tensor(-13.4334, device='cuda:0') tensor(0.6812, device='cuda:0') tensor(5.8696e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.969409
Average KL loss: 0.432852
Average total loss: 1.402260
tensor(-13.4399, device='cuda:0') tensor(0.6799, device='cuda:0') tensor(4.3913e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.971053
Average KL loss: 0.432433
Average total loss: 1.403486
tensor(-13.4464, device='cuda:0') tensor(0.6786, device='cuda:0') tensor(9.4256e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.968338
Average KL loss: 0.432059
Average total loss: 1.400396
tensor(-13.4528, device='cuda:0') tensor(0.6773, device='cuda:0') tensor(3.7419e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.966449
Average KL loss: 0.431653
Average total loss: 1.398102
tensor(-13.4592, device='cuda:0') tensor(0.6760, device='cuda:0') tensor(2.1023e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.968223
Average KL loss: 0.431230
Average total loss: 1.399452
tensor(-13.4656, device='cuda:0') tensor(0.6747, device='cuda:0') tensor(5.1506e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.970613
Average KL loss: 0.430882
Average total loss: 1.401494
tensor(-13.4719, device='cuda:0') tensor(0.6734, device='cuda:0') tensor(1.0471e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.967340
Average KL loss: 0.430505
Average total loss: 1.397845
tensor(-13.4782, device='cuda:0') tensor(0.6721, device='cuda:0') tensor(4.1326e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.966523
Average KL loss: 0.430094
Average total loss: 1.396617
tensor(-13.4845, device='cuda:0') tensor(0.6708, device='cuda:0') tensor(3.1484e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.964163
Average KL loss: 0.429772
Average total loss: 1.393935
tensor(-13.4907, device='cuda:0') tensor(0.6695, device='cuda:0') tensor(8.1384e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.966346
Average KL loss: 0.429491
Average total loss: 1.395837
tensor(-13.4969, device='cuda:0') tensor(0.6682, device='cuda:0') tensor(1.1540e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.965818
Average KL loss: 0.429145
Average total loss: 1.394963
tensor(-13.5031, device='cuda:0') tensor(0.6669, device='cuda:0') tensor(2.2750e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.967422
Average KL loss: 0.428803
Average total loss: 1.396225
tensor(-13.5092, device='cuda:0') tensor(0.6656, device='cuda:0') tensor(1.5151e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.962981
Average KL loss: 0.428491
Average total loss: 1.391472
tensor(-13.5153, device='cuda:0') tensor(0.6643, device='cuda:0') tensor(2.1292e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.961931
Average KL loss: 0.428157
Average total loss: 1.390088
tensor(-13.5213, device='cuda:0') tensor(0.6630, device='cuda:0') tensor(1.1042e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.966173
Average KL loss: 0.427832
Average total loss: 1.394005
tensor(-13.5274, device='cuda:0') tensor(0.6617, device='cuda:0') tensor(3.5936e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.961999
Average KL loss: 0.427505
Average total loss: 1.389504
tensor(-13.5334, device='cuda:0') tensor(0.6604, device='cuda:0') tensor(3.0842e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.960256
Average KL loss: 0.427153
Average total loss: 1.387409
tensor(-13.5393, device='cuda:0') tensor(0.6590, device='cuda:0') tensor(3.0373e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.961542
Average KL loss: 0.426821
Average total loss: 1.388362
tensor(-13.5453, device='cuda:0') tensor(0.6577, device='cuda:0') tensor(3.0916e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.960519
Average KL loss: 0.426467
Average total loss: 1.386985
tensor(-13.5512, device='cuda:0') tensor(0.6564, device='cuda:0') tensor(1.2540e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.960891
Average KL loss: 0.426159
Average total loss: 1.387050
tensor(-13.5570, device='cuda:0') tensor(0.6551, device='cuda:0') tensor(2.7244e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.962689
Average KL loss: 0.425836
Average total loss: 1.388525
tensor(-13.5629, device='cuda:0') tensor(0.6538, device='cuda:0') tensor(3.3579e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.960390
Average KL loss: 0.425532
Average total loss: 1.385921
tensor(-13.5687, device='cuda:0') tensor(0.6525, device='cuda:0') tensor(1.9319e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.960348
Average KL loss: 0.425232
Average total loss: 1.385579
tensor(-13.5744, device='cuda:0') tensor(0.6512, device='cuda:0') tensor(2.4564e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.957754
Average KL loss: 0.424910
Average total loss: 1.382664
 Percentile value: -13.556722640991211
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =    1706 /    1728             ( 98.73%) | total_pruned =      22 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   30411 /   36864             ( 82.50%) | total_pruned =    6453 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   30575 /   36864             ( 82.94%) | total_pruned =    6289 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   28417 /   36864             ( 77.09%) | total_pruned =    8447 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   27459 /   36864             ( 74.49%) | total_pruned =    9405 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   56933 /   73728             ( 77.22%) | total_pruned =   16795 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   97499 /  147456             ( 66.12%) | total_pruned =   49957 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7557 /    8192             ( 92.25%) | total_pruned =     635 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   86795 /  147456             ( 58.86%) | total_pruned =   60661 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   81645 /  147456             ( 55.37%) | total_pruned =   65811 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  158410 /  294912             ( 53.71%) | total_pruned =  136502 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  224225 /  589824             ( 38.02%) | total_pruned =  365599 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   25665 /   32768             ( 78.32%) | total_pruned =    7103 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  130185 /  589824             ( 22.07%) | total_pruned =  459639 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  127377 /  589824             ( 21.60%) | total_pruned =  462447 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  298691 / 1179648             ( 25.32%) | total_pruned =  880957 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  420119 / 2359296             ( 17.81%) | total_pruned = 1939177 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   81025 /  131072             ( 61.82%) | total_pruned =   50047 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  394736 / 2359296             ( 16.73%) | total_pruned = 1964560 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     466 /     512             ( 91.02%) | total_pruned =      46 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  470695 / 2359296             ( 19.95%) | total_pruned = 1888601 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
linear.weight        | nonzeros =    5015 /    5120             ( 97.95%) | total_pruned =     105 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 31/100 Loss: 0.000049 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(-13.5802, device='cuda:0') tensor(0.6499, device='cuda:0') tensor(3.4914e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.989011
Average KL loss: 0.419773
Average total loss: 1.408783
tensor(-13.5901, device='cuda:0') tensor(0.5992, device='cuda:0') tensor(3.1388e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.984696
Average KL loss: 0.414599
Average total loss: 1.399296
tensor(-13.5989, device='cuda:0') tensor(0.5639, device='cuda:0') tensor(3.9933e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.982206
Average KL loss: 0.411936
Average total loss: 1.394142
tensor(-13.6072, device='cuda:0') tensor(0.5374, device='cuda:0') tensor(6.0175e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.981158
Average KL loss: 0.410209
Average total loss: 1.391368
tensor(-13.6149, device='cuda:0') tensor(0.5163, device='cuda:0') tensor(2.5937e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.983000
Average KL loss: 0.408933
Average total loss: 1.391933
tensor(-13.6224, device='cuda:0') tensor(0.4991, device='cuda:0') tensor(1.8880e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.979492
Average KL loss: 0.407993
Average total loss: 1.387485
tensor(-13.6295, device='cuda:0') tensor(0.4845, device='cuda:0') tensor(3.3154e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.974849
Average KL loss: 0.407224
Average total loss: 1.382073
tensor(-13.6365, device='cuda:0') tensor(0.4718, device='cuda:0') tensor(-1.7845e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.980378
Average KL loss: 0.406537
Average total loss: 1.386915
tensor(-13.6433, device='cuda:0') tensor(0.4608, device='cuda:0') tensor(6.0461e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.976935
Average KL loss: 0.405975
Average total loss: 1.382910
tensor(-13.6500, device='cuda:0') tensor(0.4510, device='cuda:0') tensor(-2.2765e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.978077
Average KL loss: 0.405523
Average total loss: 1.383600
tensor(-13.6565, device='cuda:0') tensor(0.4422, device='cuda:0') tensor(-1.4175e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.973713
Average KL loss: 0.405129
Average total loss: 1.378842
tensor(-13.6629, device='cuda:0') tensor(0.4342, device='cuda:0') tensor(7.1049e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.971420
Average KL loss: 0.404781
Average total loss: 1.376202
tensor(-13.6692, device='cuda:0') tensor(0.4270, device='cuda:0') tensor(-1.5627e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.968293
Average KL loss: 0.404446
Average total loss: 1.372738
tensor(-13.6754, device='cuda:0') tensor(0.4205, device='cuda:0') tensor(1.0612e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.971230
Average KL loss: 0.404104
Average total loss: 1.375335
tensor(-13.6816, device='cuda:0') tensor(0.4144, device='cuda:0') tensor(-3.4591e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.969402
Average KL loss: 0.403750
Average total loss: 1.373153
tensor(-13.6876, device='cuda:0') tensor(0.4087, device='cuda:0') tensor(-1.3371e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.967221
Average KL loss: 0.403391
Average total loss: 1.370612
tensor(-13.6936, device='cuda:0') tensor(0.4035, device='cuda:0') tensor(2.4018e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.966890
Average KL loss: 0.403118
Average total loss: 1.370009
tensor(-13.6995, device='cuda:0') tensor(0.3987, device='cuda:0') tensor(-3.8782e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.964755
Average KL loss: 0.402808
Average total loss: 1.367562
tensor(-13.7053, device='cuda:0') tensor(0.3941, device='cuda:0') tensor(-1.9090e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.962976
Average KL loss: 0.402560
Average total loss: 1.365536
tensor(-13.7111, device='cuda:0') tensor(0.3899, device='cuda:0') tensor(-1.1806e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.963339
Average KL loss: 0.402296
Average total loss: 1.365635
tensor(-13.7168, device='cuda:0') tensor(0.3859, device='cuda:0') tensor(1.9631e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.965202
Average KL loss: 0.402011
Average total loss: 1.367213
tensor(-13.7225, device='cuda:0') tensor(0.3822, device='cuda:0') tensor(5.3100e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.964652
Average KL loss: 0.401836
Average total loss: 1.366488
tensor(-13.7281, device='cuda:0') tensor(0.3786, device='cuda:0') tensor(2.6841e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.958442
Average KL loss: 0.401600
Average total loss: 1.360042
tensor(-13.7337, device='cuda:0') tensor(0.3753, device='cuda:0') tensor(1.0057e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.963415
Average KL loss: 0.401389
Average total loss: 1.364804
tensor(-13.7392, device='cuda:0') tensor(0.3721, device='cuda:0') tensor(1.2767e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.963680
Average KL loss: 0.401187
Average total loss: 1.364867
tensor(-13.7447, device='cuda:0') tensor(0.3691, device='cuda:0') tensor(7.8454e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.960869
Average KL loss: 0.401015
Average total loss: 1.361884
tensor(-13.7501, device='cuda:0') tensor(0.3663, device='cuda:0') tensor(1.0001e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.959491
Average KL loss: 0.400818
Average total loss: 1.360308
tensor(-13.7555, device='cuda:0') tensor(0.3635, device='cuda:0') tensor(-2.2557e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.960012
Average KL loss: 0.400604
Average total loss: 1.360616
tensor(-13.7609, device='cuda:0') tensor(0.3610, device='cuda:0') tensor(7.7658e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.957223
Average KL loss: 0.400450
Average total loss: 1.357674
tensor(-13.7662, device='cuda:0') tensor(0.3585, device='cuda:0') tensor(-1.6322e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.955198
Average KL loss: 0.400305
Average total loss: 1.355503
tensor(-13.7715, device='cuda:0') tensor(0.3562, device='cuda:0') tensor(2.5503e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.960093
Average KL loss: 0.400106
Average total loss: 1.360199
tensor(-13.7767, device='cuda:0') tensor(0.3539, device='cuda:0') tensor(3.9870e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.953606
Average KL loss: 0.399944
Average total loss: 1.353550
tensor(-13.7819, device='cuda:0') tensor(0.3517, device='cuda:0') tensor(1.9818e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.955890
Average KL loss: 0.399726
Average total loss: 1.355616
tensor(-13.7870, device='cuda:0') tensor(0.3496, device='cuda:0') tensor(5.8519e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.955290
Average KL loss: 0.399573
Average total loss: 1.354863
tensor(-13.7922, device='cuda:0') tensor(0.3476, device='cuda:0') tensor(-3.0830e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.955244
Average KL loss: 0.399361
Average total loss: 1.354605
tensor(-13.7973, device='cuda:0') tensor(0.3457, device='cuda:0') tensor(-8.4756e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.954817
Average KL loss: 0.399191
Average total loss: 1.354008
tensor(-13.8023, device='cuda:0') tensor(0.3439, device='cuda:0') tensor(1.4640e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.951989
Average KL loss: 0.399031
Average total loss: 1.351020
tensor(-13.8074, device='cuda:0') tensor(0.3422, device='cuda:0') tensor(3.6508e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.953838
Average KL loss: 0.398857
Average total loss: 1.352695
tensor(-13.8123, device='cuda:0') tensor(0.3404, device='cuda:0') tensor(1.6993e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.952298
Average KL loss: 0.398661
Average total loss: 1.350959
tensor(-13.8173, device='cuda:0') tensor(0.3388, device='cuda:0') tensor(-5.8541e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.950950
Average KL loss: 0.398502
Average total loss: 1.349451
tensor(-13.8223, device='cuda:0') tensor(0.3372, device='cuda:0') tensor(8.6944e-12, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.950136
Average KL loss: 0.398337
Average total loss: 1.348473
tensor(-13.8272, device='cuda:0') tensor(0.3357, device='cuda:0') tensor(1.1709e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.948014
Average KL loss: 0.398162
Average total loss: 1.346175
tensor(-13.8320, device='cuda:0') tensor(0.3342, device='cuda:0') tensor(5.2791e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.950545
Average KL loss: 0.398014
Average total loss: 1.348558
tensor(-13.8369, device='cuda:0') tensor(0.3327, device='cuda:0') tensor(2.1055e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.949635
Average KL loss: 0.397861
Average total loss: 1.347496
tensor(-13.8417, device='cuda:0') tensor(0.3313, device='cuda:0') tensor(-1.2830e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.945505
Average KL loss: 0.397725
Average total loss: 1.343230
tensor(-13.8465, device='cuda:0') tensor(0.3300, device='cuda:0') tensor(-3.8818e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.951160
Average KL loss: 0.397587
Average total loss: 1.348747
tensor(-13.8513, device='cuda:0') tensor(0.3287, device='cuda:0') tensor(1.9980e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.947279
Average KL loss: 0.397439
Average total loss: 1.344718
tensor(-13.8560, device='cuda:0') tensor(0.3274, device='cuda:0') tensor(1.9293e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.946984
Average KL loss: 0.397229
Average total loss: 1.344214
tensor(-13.8607, device='cuda:0') tensor(0.3261, device='cuda:0') tensor(1.5077e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.947255
Average KL loss: 0.397034
Average total loss: 1.344289
tensor(-13.8654, device='cuda:0') tensor(0.3250, device='cuda:0') tensor(2.4166e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.946302
Average KL loss: 0.396833
Average total loss: 1.343135
tensor(-13.8701, device='cuda:0') tensor(0.3238, device='cuda:0') tensor(-4.9953e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.948167
Average KL loss: 0.396697
Average total loss: 1.344864
tensor(-13.8747, device='cuda:0') tensor(0.3226, device='cuda:0') tensor(5.7477e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.945961
Average KL loss: 0.396555
Average total loss: 1.342516
tensor(-13.8793, device='cuda:0') tensor(0.3215, device='cuda:0') tensor(4.7139e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.945471
Average KL loss: 0.396430
Average total loss: 1.341901
tensor(-13.8839, device='cuda:0') tensor(0.3205, device='cuda:0') tensor(-8.1310e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.946169
Average KL loss: 0.396291
Average total loss: 1.342460
tensor(-13.8885, device='cuda:0') tensor(0.3195, device='cuda:0') tensor(4.7953e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.947396
Average KL loss: 0.396121
Average total loss: 1.343517
tensor(-13.8930, device='cuda:0') tensor(0.3184, device='cuda:0') tensor(8.2412e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.941745
Average KL loss: 0.395956
Average total loss: 1.337702
tensor(-13.8975, device='cuda:0') tensor(0.3175, device='cuda:0') tensor(-5.9331e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.945115
Average KL loss: 0.395846
Average total loss: 1.340961
tensor(-13.9020, device='cuda:0') tensor(0.3165, device='cuda:0') tensor(4.4097e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.944438
Average KL loss: 0.395667
Average total loss: 1.340105
tensor(-13.9065, device='cuda:0') tensor(0.3156, device='cuda:0') tensor(-2.0810e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.941902
Average KL loss: 0.395523
Average total loss: 1.337425
tensor(-13.9110, device='cuda:0') tensor(0.3147, device='cuda:0') tensor(7.8667e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.942737
Average KL loss: 0.395381
Average total loss: 1.338118
tensor(-13.9154, device='cuda:0') tensor(0.3139, device='cuda:0') tensor(-7.2017e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.938738
Average KL loss: 0.395226
Average total loss: 1.333964
tensor(-13.9198, device='cuda:0') tensor(0.3130, device='cuda:0') tensor(5.6710e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.941253
Average KL loss: 0.395064
Average total loss: 1.336317
tensor(-13.9242, device='cuda:0') tensor(0.3122, device='cuda:0') tensor(1.3924e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.939948
Average KL loss: 0.394942
Average total loss: 1.334891
tensor(-13.9285, device='cuda:0') tensor(0.3113, device='cuda:0') tensor(9.7848e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.940512
Average KL loss: 0.394818
Average total loss: 1.335330
tensor(-13.9329, device='cuda:0') tensor(0.3105, device='cuda:0') tensor(1.6664e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.938670
Average KL loss: 0.394687
Average total loss: 1.333358
tensor(-13.9372, device='cuda:0') tensor(0.3098, device='cuda:0') tensor(1.5255e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.941567
Average KL loss: 0.394532
Average total loss: 1.336099
tensor(-13.9415, device='cuda:0') tensor(0.3090, device='cuda:0') tensor(-1.3817e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.941293
Average KL loss: 0.394407
Average total loss: 1.335699
tensor(-13.9458, device='cuda:0') tensor(0.3083, device='cuda:0') tensor(6.0778e-11, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.941215
Average KL loss: 0.394280
Average total loss: 1.335495
tensor(-13.9501, device='cuda:0') tensor(0.3075, device='cuda:0') tensor(-3.9616e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.938699
Average KL loss: 0.394148
Average total loss: 1.332847
tensor(-13.9543, device='cuda:0') tensor(0.3068, device='cuda:0') tensor(1.4440e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.938127
Average KL loss: 0.393993
Average total loss: 1.332120
tensor(-13.9585, device='cuda:0') tensor(0.3061, device='cuda:0') tensor(-1.0162e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.939405
Average KL loss: 0.393854
Average total loss: 1.333259
tensor(-13.9627, device='cuda:0') tensor(0.3054, device='cuda:0') tensor(1.0010e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.938255
Average KL loss: 0.393738
Average total loss: 1.331992
tensor(-13.9669, device='cuda:0') tensor(0.3048, device='cuda:0') tensor(-2.1965e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.935063
Average KL loss: 0.393612
Average total loss: 1.328674
tensor(-13.9711, device='cuda:0') tensor(0.3041, device='cuda:0') tensor(1.3972e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.933961
Average KL loss: 0.393488
Average total loss: 1.327449
tensor(-13.9753, device='cuda:0') tensor(0.3035, device='cuda:0') tensor(-1.2261e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.935073
Average KL loss: 0.393368
Average total loss: 1.328441
tensor(-13.9794, device='cuda:0') tensor(0.3029, device='cuda:0') tensor(-2.6261e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.936432
Average KL loss: 0.393247
Average total loss: 1.329680
tensor(-13.9835, device='cuda:0') tensor(0.3023, device='cuda:0') tensor(1.4957e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.935839
Average KL loss: 0.393161
Average total loss: 1.329000
tensor(-13.9876, device='cuda:0') tensor(0.3017, device='cuda:0') tensor(1.0966e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.936593
Average KL loss: 0.393038
Average total loss: 1.329630
tensor(-13.9917, device='cuda:0') tensor(0.3011, device='cuda:0') tensor(1.5130e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.936264
Average KL loss: 0.392910
Average total loss: 1.329174
tensor(-13.9957, device='cuda:0') tensor(0.3005, device='cuda:0') tensor(-5.0749e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.936727
Average KL loss: 0.392793
Average total loss: 1.329520
tensor(-13.9998, device='cuda:0') tensor(0.3000, device='cuda:0') tensor(1.6926e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.934040
Average KL loss: 0.392685
Average total loss: 1.326725
tensor(-14.0038, device='cuda:0') tensor(0.2995, device='cuda:0') tensor(-2.5066e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.935722
Average KL loss: 0.392586
Average total loss: 1.328307
tensor(-14.0078, device='cuda:0') tensor(0.2990, device='cuda:0') tensor(8.5460e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.933582
Average KL loss: 0.392460
Average total loss: 1.326042
tensor(-14.0118, device='cuda:0') tensor(0.2984, device='cuda:0') tensor(-6.8765e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.931225
Average KL loss: 0.392377
Average total loss: 1.323602
tensor(-14.0158, device='cuda:0') tensor(0.2979, device='cuda:0') tensor(-1.7112e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.932535
Average KL loss: 0.392250
Average total loss: 1.324785
tensor(-14.0197, device='cuda:0') tensor(0.2974, device='cuda:0') tensor(1.2594e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.933360
Average KL loss: 0.392130
Average total loss: 1.325490
tensor(-14.0237, device='cuda:0') tensor(0.2969, device='cuda:0') tensor(-1.8497e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.928643
Average KL loss: 0.392020
Average total loss: 1.320663
tensor(-14.0276, device='cuda:0') tensor(0.2964, device='cuda:0') tensor(-5.7348e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.929136
Average KL loss: 0.391941
Average total loss: 1.321076
tensor(-14.0315, device='cuda:0') tensor(0.2960, device='cuda:0') tensor(2.7236e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.931644
Average KL loss: 0.391888
Average total loss: 1.323532
tensor(-14.0354, device='cuda:0') tensor(0.2955, device='cuda:0') tensor(1.4887e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.927936
Average KL loss: 0.391772
Average total loss: 1.319709
tensor(-14.0393, device='cuda:0') tensor(0.2950, device='cuda:0') tensor(-9.0854e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.930626
Average KL loss: 0.391681
Average total loss: 1.322308
tensor(-14.0431, device='cuda:0') tensor(0.2946, device='cuda:0') tensor(2.4768e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.931960
Average KL loss: 0.391610
Average total loss: 1.323570
tensor(-14.0470, device='cuda:0') tensor(0.2941, device='cuda:0') tensor(-2.3079e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.929655
Average KL loss: 0.391527
Average total loss: 1.321182
tensor(-14.0508, device='cuda:0') tensor(0.2937, device='cuda:0') tensor(-8.3064e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.931821
Average KL loss: 0.391404
Average total loss: 1.323225
tensor(-14.0546, device='cuda:0') tensor(0.2933, device='cuda:0') tensor(2.7292e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.929664
Average KL loss: 0.391286
Average total loss: 1.320950
tensor(-14.0584, device='cuda:0') tensor(0.2928, device='cuda:0') tensor(2.0222e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.929732
Average KL loss: 0.391149
Average total loss: 1.320881
tensor(-14.0622, device='cuda:0') tensor(0.2924, device='cuda:0') tensor(7.8093e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.929846
Average KL loss: 0.391047
Average total loss: 1.320894
tensor(-14.0660, device='cuda:0') tensor(0.2920, device='cuda:0') tensor(1.1556e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.926718
Average KL loss: 0.390973
Average total loss: 1.317691
tensor(-14.0697, device='cuda:0') tensor(0.2916, device='cuda:0') tensor(1.2893e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.924815
Average KL loss: 0.390892
Average total loss: 1.315707
tensor(-14.0735, device='cuda:0') tensor(0.2912, device='cuda:0') tensor(2.1942e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.924534
Average KL loss: 0.390830
Average total loss: 1.315363
tensor(-14.0772, device='cuda:0') tensor(0.2908, device='cuda:0') tensor(-6.0665e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.930663
Average KL loss: 0.390724
Average total loss: 1.321387
tensor(-14.0809, device='cuda:0') tensor(0.2904, device='cuda:0') tensor(1.2178e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.927919
Average KL loss: 0.390597
Average total loss: 1.318516
tensor(-14.0846, device='cuda:0') tensor(0.2900, device='cuda:0') tensor(-9.3617e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.923465
Average KL loss: 0.390514
Average total loss: 1.313979
tensor(-14.0883, device='cuda:0') tensor(0.2896, device='cuda:0') tensor(5.8910e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.924251
Average KL loss: 0.390435
Average total loss: 1.314685
tensor(-14.0920, device='cuda:0') tensor(0.2893, device='cuda:0') tensor(-7.5954e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.928062
Average KL loss: 0.390403
Average total loss: 1.318465
tensor(-14.0956, device='cuda:0') tensor(0.2889, device='cuda:0') tensor(9.8390e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.926802
Average KL loss: 0.390317
Average total loss: 1.317119
tensor(-14.0993, device='cuda:0') tensor(0.2886, device='cuda:0') tensor(-1.3996e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.924632
Average KL loss: 0.390255
Average total loss: 1.314887
tensor(-14.1029, device='cuda:0') tensor(0.2882, device='cuda:0') tensor(-7.6849e-11, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.924099
Average KL loss: 0.390159
Average total loss: 1.314258
tensor(-14.1065, device='cuda:0') tensor(0.2879, device='cuda:0') tensor(2.4045e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.925498
Average KL loss: 0.390067
Average total loss: 1.315566
tensor(-14.1101, device='cuda:0') tensor(0.2875, device='cuda:0') tensor(1.0904e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.926009
Average KL loss: 0.389960
Average total loss: 1.315969
tensor(-14.1137, device='cuda:0') tensor(0.2872, device='cuda:0') tensor(4.7760e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.923910
Average KL loss: 0.389901
Average total loss: 1.313811
tensor(-14.1173, device='cuda:0') tensor(0.2869, device='cuda:0') tensor(2.0670e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.923770
Average KL loss: 0.389831
Average total loss: 1.313600
tensor(-14.1208, device='cuda:0') tensor(0.2865, device='cuda:0') tensor(7.1266e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.924333
Average KL loss: 0.389716
Average total loss: 1.314050
tensor(-14.1244, device='cuda:0') tensor(0.2862, device='cuda:0') tensor(-1.1776e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.923810
Average KL loss: 0.389622
Average total loss: 1.313432
tensor(-14.1279, device='cuda:0') tensor(0.2859, device='cuda:0') tensor(-1.5637e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.925279
Average KL loss: 0.389558
Average total loss: 1.314837
tensor(-14.1315, device='cuda:0') tensor(0.2856, device='cuda:0') tensor(1.8057e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.926004
Average KL loss: 0.389482
Average total loss: 1.315486
tensor(-14.1350, device='cuda:0') tensor(0.2853, device='cuda:0') tensor(-5.5706e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.923461
Average KL loss: 0.389379
Average total loss: 1.312839
tensor(-14.1385, device='cuda:0') tensor(0.2850, device='cuda:0') tensor(1.8727e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.923789
Average KL loss: 0.389300
Average total loss: 1.313088
tensor(-14.1419, device='cuda:0') tensor(0.2847, device='cuda:0') tensor(-1.4134e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.920137
Average KL loss: 0.389268
Average total loss: 1.309404
tensor(-14.1454, device='cuda:0') tensor(0.2844, device='cuda:0') tensor(1.7433e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.922727
Average KL loss: 0.389222
Average total loss: 1.311949
tensor(-14.1489, device='cuda:0') tensor(0.2841, device='cuda:0') tensor(6.7913e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.919541
Average KL loss: 0.389198
Average total loss: 1.308739
tensor(-14.1523, device='cuda:0') tensor(0.2838, device='cuda:0') tensor(2.2265e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.920476
Average KL loss: 0.389139
Average total loss: 1.309615
tensor(-14.1558, device='cuda:0') tensor(0.2835, device='cuda:0') tensor(6.1131e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.922036
Average KL loss: 0.389051
Average total loss: 1.311087
tensor(-14.1592, device='cuda:0') tensor(0.2832, device='cuda:0') tensor(2.4071e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.920576
Average KL loss: 0.388955
Average total loss: 1.309531
tensor(-14.1626, device='cuda:0') tensor(0.2829, device='cuda:0') tensor(4.0861e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.920558
Average KL loss: 0.388879
Average total loss: 1.309437
tensor(-14.1660, device='cuda:0') tensor(0.2827, device='cuda:0') tensor(-1.5591e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.919474
Average KL loss: 0.388820
Average total loss: 1.308294
tensor(-14.1694, device='cuda:0') tensor(0.2824, device='cuda:0') tensor(1.1577e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.919503
Average KL loss: 0.388758
Average total loss: 1.308261
tensor(-14.1728, device='cuda:0') tensor(0.2821, device='cuda:0') tensor(3.9325e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.920900
Average KL loss: 0.388709
Average total loss: 1.309609
tensor(-14.1761, device='cuda:0') tensor(0.2818, device='cuda:0') tensor(1.5930e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.919644
Average KL loss: 0.388669
Average total loss: 1.308313
tensor(-14.1795, device='cuda:0') tensor(0.2816, device='cuda:0') tensor(-1.6253e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.918542
Average KL loss: 0.388596
Average total loss: 1.307138
tensor(-14.1828, device='cuda:0') tensor(0.2814, device='cuda:0') tensor(-2.2035e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.918623
Average KL loss: 0.388526
Average total loss: 1.307148
tensor(-14.1862, device='cuda:0') tensor(0.2811, device='cuda:0') tensor(2.2528e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.918708
Average KL loss: 0.388481
Average total loss: 1.307189
tensor(-14.1895, device='cuda:0') tensor(0.2808, device='cuda:0') tensor(-6.0594e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.919443
Average KL loss: 0.388440
Average total loss: 1.307883
tensor(-14.1928, device='cuda:0') tensor(0.2806, device='cuda:0') tensor(1.2723e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.918674
Average KL loss: 0.388437
Average total loss: 1.307111
tensor(-14.1961, device='cuda:0') tensor(0.2804, device='cuda:0') tensor(-3.5126e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.919739
Average KL loss: 0.388379
Average total loss: 1.308117
tensor(-14.1994, device='cuda:0') tensor(0.2801, device='cuda:0') tensor(1.9270e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.916957
Average KL loss: 0.388291
Average total loss: 1.305247
tensor(-14.2027, device='cuda:0') tensor(0.2799, device='cuda:0') tensor(3.7539e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.915663
Average KL loss: 0.388221
Average total loss: 1.303884
tensor(-14.2059, device='cuda:0') tensor(0.2796, device='cuda:0') tensor(-2.0937e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.913790
Average KL loss: 0.388191
Average total loss: 1.301981
tensor(-14.2092, device='cuda:0') tensor(0.2794, device='cuda:0') tensor(-9.0144e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.918883
Average KL loss: 0.388165
Average total loss: 1.307048
tensor(-14.2124, device='cuda:0') tensor(0.2792, device='cuda:0') tensor(6.3695e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.916308
Average KL loss: 0.388124
Average total loss: 1.304432
tensor(-14.2157, device='cuda:0') tensor(0.2789, device='cuda:0') tensor(-6.3793e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.916787
Average KL loss: 0.388058
Average total loss: 1.304845
tensor(-14.2189, device='cuda:0') tensor(0.2787, device='cuda:0') tensor(-6.0965e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.914250
Average KL loss: 0.388010
Average total loss: 1.302260
tensor(-14.2221, device='cuda:0') tensor(0.2784, device='cuda:0') tensor(1.1298e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.915901
Average KL loss: 0.387909
Average total loss: 1.303811
tensor(-14.2253, device='cuda:0') tensor(0.2782, device='cuda:0') tensor(-1.8996e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.914195
Average KL loss: 0.387889
Average total loss: 1.302084
tensor(-14.2285, device='cuda:0') tensor(0.2780, device='cuda:0') tensor(1.5485e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.918380
Average KL loss: 0.387868
Average total loss: 1.306248
tensor(-14.2317, device='cuda:0') tensor(0.2778, device='cuda:0') tensor(1.2495e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.913494
Average KL loss: 0.387805
Average total loss: 1.301299
tensor(-14.2348, device='cuda:0') tensor(0.2776, device='cuda:0') tensor(-1.6280e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.914688
Average KL loss: 0.387760
Average total loss: 1.302448
tensor(-14.2380, device='cuda:0') tensor(0.2774, device='cuda:0') tensor(1.1861e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.916358
Average KL loss: 0.387710
Average total loss: 1.304069
tensor(-14.2412, device='cuda:0') tensor(0.2771, device='cuda:0') tensor(3.5750e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.912625
Average KL loss: 0.387661
Average total loss: 1.300287
tensor(-14.2443, device='cuda:0') tensor(0.2769, device='cuda:0') tensor(7.1686e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.911874
Average KL loss: 0.387639
Average total loss: 1.299513
tensor(-14.2474, device='cuda:0') tensor(0.2767, device='cuda:0') tensor(1.1508e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.913943
Average KL loss: 0.387637
Average total loss: 1.301580
tensor(-14.2506, device='cuda:0') tensor(0.2765, device='cuda:0') tensor(9.8293e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.912579
Average KL loss: 0.387615
Average total loss: 1.300193
tensor(-14.2537, device='cuda:0') tensor(0.2763, device='cuda:0') tensor(4.5672e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.913499
Average KL loss: 0.387556
Average total loss: 1.301055
tensor(-14.2568, device='cuda:0') tensor(0.2761, device='cuda:0') tensor(-1.0518e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.911924
Average KL loss: 0.387499
Average total loss: 1.299423
tensor(-14.2599, device='cuda:0') tensor(0.2759, device='cuda:0') tensor(1.5721e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.912891
Average KL loss: 0.387444
Average total loss: 1.300335
tensor(-14.2629, device='cuda:0') tensor(0.2757, device='cuda:0') tensor(1.6599e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.909965
Average KL loss: 0.387395
Average total loss: 1.297360
tensor(-14.2660, device='cuda:0') tensor(0.2755, device='cuda:0') tensor(-5.1926e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.911335
Average KL loss: 0.387317
Average total loss: 1.298652
tensor(-14.2691, device='cuda:0') tensor(0.2752, device='cuda:0') tensor(-1.7556e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.911195
Average KL loss: 0.387279
Average total loss: 1.298474
tensor(-14.2721, device='cuda:0') tensor(0.2751, device='cuda:0') tensor(8.1556e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.912320
Average KL loss: 0.387249
Average total loss: 1.299569
tensor(-14.2752, device='cuda:0') tensor(0.2749, device='cuda:0') tensor(-1.4954e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.909737
Average KL loss: 0.387196
Average total loss: 1.296933
tensor(-14.2782, device='cuda:0') tensor(0.2746, device='cuda:0') tensor(-4.5729e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.911194
Average KL loss: 0.387136
Average total loss: 1.298330
tensor(-14.2812, device='cuda:0') tensor(0.2744, device='cuda:0') tensor(7.0553e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.908008
Average KL loss: 0.387076
Average total loss: 1.295084
tensor(-14.2843, device='cuda:0') tensor(0.2742, device='cuda:0') tensor(5.8723e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.913050
Average KL loss: 0.387015
Average total loss: 1.300066
tensor(-14.2873, device='cuda:0') tensor(0.2740, device='cuda:0') tensor(-5.5648e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.909720
Average KL loss: 0.386974
Average total loss: 1.296695
tensor(-14.2903, device='cuda:0') tensor(0.2738, device='cuda:0') tensor(5.9022e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.908529
Average KL loss: 0.386908
Average total loss: 1.295437
tensor(-14.2933, device='cuda:0') tensor(0.2736, device='cuda:0') tensor(1.0520e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.908520
Average KL loss: 0.386863
Average total loss: 1.295383
tensor(-14.2962, device='cuda:0') tensor(0.2734, device='cuda:0') tensor(1.5472e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.910318
Average KL loss: 0.386796
Average total loss: 1.297114
tensor(-14.2992, device='cuda:0') tensor(0.2732, device='cuda:0') tensor(1.8019e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.908913
Average KL loss: 0.386758
Average total loss: 1.295672
tensor(-14.3022, device='cuda:0') tensor(0.2731, device='cuda:0') tensor(1.3588e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.909353
Average KL loss: 0.386720
Average total loss: 1.296072
tensor(-14.3051, device='cuda:0') tensor(0.2729, device='cuda:0') tensor(5.6757e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.910327
Average KL loss: 0.386671
Average total loss: 1.296998
tensor(-14.3081, device='cuda:0') tensor(0.2727, device='cuda:0') tensor(2.1161e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.908894
Average KL loss: 0.386640
Average total loss: 1.295533
tensor(-14.3110, device='cuda:0') tensor(0.2725, device='cuda:0') tensor(6.1155e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.908550
Average KL loss: 0.386614
Average total loss: 1.295164
tensor(-14.3139, device='cuda:0') tensor(0.2723, device='cuda:0') tensor(-1.8576e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.906215
Average KL loss: 0.386611
Average total loss: 1.292826
tensor(-14.3169, device='cuda:0') tensor(0.2721, device='cuda:0') tensor(1.8303e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.907172
Average KL loss: 0.386571
Average total loss: 1.293742
tensor(-14.3198, device='cuda:0') tensor(0.2719, device='cuda:0') tensor(4.7712e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.909095
Average KL loss: 0.386544
Average total loss: 1.295639
tensor(-14.3227, device='cuda:0') tensor(0.2717, device='cuda:0') tensor(1.6561e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.906889
Average KL loss: 0.386495
Average total loss: 1.293384
tensor(-14.3256, device='cuda:0') tensor(0.2716, device='cuda:0') tensor(1.3518e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.906880
Average KL loss: 0.386496
Average total loss: 1.293375
tensor(-14.3285, device='cuda:0') tensor(0.2714, device='cuda:0') tensor(4.3400e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.908654
Average KL loss: 0.386484
Average total loss: 1.295139
tensor(-14.3313, device='cuda:0') tensor(0.2712, device='cuda:0') tensor(1.4105e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.906002
Average KL loss: 0.386434
Average total loss: 1.292436
tensor(-14.3342, device='cuda:0') tensor(0.2710, device='cuda:0') tensor(1.7077e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.906488
Average KL loss: 0.386399
Average total loss: 1.292887
tensor(-14.3371, device='cuda:0') tensor(0.2709, device='cuda:0') tensor(-1.1798e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.907433
Average KL loss: 0.386373
Average total loss: 1.293806
tensor(-14.3399, device='cuda:0') tensor(0.2707, device='cuda:0') tensor(5.9641e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.903844
Average KL loss: 0.386331
Average total loss: 1.290176
tensor(-14.3428, device='cuda:0') tensor(0.2705, device='cuda:0') tensor(-8.1516e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.906612
Average KL loss: 0.386308
Average total loss: 1.292920
tensor(-14.3456, device='cuda:0') tensor(0.2703, device='cuda:0') tensor(3.2848e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.904224
Average KL loss: 0.386267
Average total loss: 1.290491
tensor(-14.3484, device='cuda:0') tensor(0.2702, device='cuda:0') tensor(1.2322e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.906198
Average KL loss: 0.386218
Average total loss: 1.292416
tensor(-14.3513, device='cuda:0') tensor(0.2700, device='cuda:0') tensor(1.6714e-11, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.906154
Average KL loss: 0.386190
Average total loss: 1.292344
tensor(-14.3541, device='cuda:0') tensor(0.2698, device='cuda:0') tensor(2.7970e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.904153
Average KL loss: 0.386133
Average total loss: 1.290286
tensor(-14.3569, device='cuda:0') tensor(0.2696, device='cuda:0') tensor(-1.1115e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.905238
Average KL loss: 0.386093
Average total loss: 1.291331
tensor(-14.3597, device='cuda:0') tensor(0.2694, device='cuda:0') tensor(-1.2767e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.902258
Average KL loss: 0.386063
Average total loss: 1.288321
tensor(-14.3625, device='cuda:0') tensor(0.2693, device='cuda:0') tensor(4.3041e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.904261
Average KL loss: 0.386079
Average total loss: 1.290340
tensor(-14.3652, device='cuda:0') tensor(0.2691, device='cuda:0') tensor(1.2471e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.903427
Average KL loss: 0.386068
Average total loss: 1.289495
tensor(-14.3680, device='cuda:0') tensor(0.2689, device='cuda:0') tensor(1.0951e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.903980
Average KL loss: 0.386045
Average total loss: 1.290025
tensor(-14.3708, device='cuda:0') tensor(0.2688, device='cuda:0') tensor(2.7633e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.904513
Average KL loss: 0.386023
Average total loss: 1.290536
tensor(-14.3736, device='cuda:0') tensor(0.2686, device='cuda:0') tensor(8.6348e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.902882
Average KL loss: 0.385985
Average total loss: 1.288867
tensor(-14.3763, device='cuda:0') tensor(0.2685, device='cuda:0') tensor(-2.5084e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.903274
Average KL loss: 0.385964
Average total loss: 1.289239
tensor(-14.3790, device='cuda:0') tensor(0.2683, device='cuda:0') tensor(1.2854e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.901858
Average KL loss: 0.385969
Average total loss: 1.287828
tensor(-14.3818, device='cuda:0') tensor(0.2682, device='cuda:0') tensor(3.2769e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.904882
Average KL loss: 0.385973
Average total loss: 1.290854
tensor(-14.3845, device='cuda:0') tensor(0.2680, device='cuda:0') tensor(6.7842e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.903792
Average KL loss: 0.385954
Average total loss: 1.289746
tensor(-14.3872, device='cuda:0') tensor(0.2679, device='cuda:0') tensor(-1.0409e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.902994
Average KL loss: 0.385934
Average total loss: 1.288928
tensor(-14.3899, device='cuda:0') tensor(0.2677, device='cuda:0') tensor(4.6764e-11, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.902973
Average KL loss: 0.385905
Average total loss: 1.288878
 Percentile value: -14.30615520477295
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =    1682 /    1728             ( 97.34%) | total_pruned =      46 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   26357 /   36864             ( 71.50%) | total_pruned =   10507 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   26305 /   36864             ( 71.36%) | total_pruned =   10559 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   23104 /   36864             ( 62.67%) | total_pruned =   13760 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   21639 /   36864             ( 58.70%) | total_pruned =   15225 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   46683 /   73728             ( 63.32%) | total_pruned =   27045 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   70481 /  147456             ( 47.80%) | total_pruned =   76975 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7054 /    8192             ( 86.11%) | total_pruned =    1138 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   57839 /  147456             ( 39.22%) | total_pruned =   89617 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   52045 /  147456             ( 35.30%) | total_pruned =   95411 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   95224 /  294912             ( 32.29%) | total_pruned =  199688 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  108862 /  589824             ( 18.46%) | total_pruned =  480962 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   20365 /   32768             ( 62.15%) | total_pruned =   12403 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   49524 /  589824             (  8.40%) | total_pruned =  540300 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   48781 /  589824             (  8.27%) | total_pruned =  541043 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  117842 / 1179648             (  9.99%) | total_pruned = 1061806 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  170582 / 2359296             (  7.23%) | total_pruned = 2188714 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   55495 /  131072             ( 42.34%) | total_pruned =   75577 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  159921 / 2359296             (  6.78%) | total_pruned = 2199375 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     253 /     512             ( 49.41%) | total_pruned =     259 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  223339 / 2359296             (  9.47%) | total_pruned = 2135957 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
linear.weight        | nonzeros =    4900 /    5120             ( 95.70%) | total_pruned =     220 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 29/100 Loss: 0.000026 Accuracy: 86.02 100.00 % Best test Accuracy: 86.17%
tensor(-14.3927, device='cuda:0') tensor(0.2676, device='cuda:0') tensor(1.5080e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.943757
Average KL loss: 0.384539
Average total loss: 1.328297
tensor(-14.3962, device='cuda:0') tensor(0.2538, device='cuda:0') tensor(2.5389e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.943526
Average KL loss: 0.383083
Average total loss: 1.326610
tensor(-14.3995, device='cuda:0') tensor(0.2443, device='cuda:0') tensor(-4.2512e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.940600
Average KL loss: 0.382140
Average total loss: 1.322740
tensor(-14.4026, device='cuda:0') tensor(0.2373, device='cuda:0') tensor(-3.9209e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.939812
Average KL loss: 0.381467
Average total loss: 1.321279
tensor(-14.4057, device='cuda:0') tensor(0.2323, device='cuda:0') tensor(9.3880e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.945168
Average KL loss: 0.380950
Average total loss: 1.326118
tensor(-14.4086, device='cuda:0') tensor(0.2285, device='cuda:0') tensor(6.6211e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.940562
Average KL loss: 0.380581
Average total loss: 1.321143
tensor(-14.4116, device='cuda:0') tensor(0.2256, device='cuda:0') tensor(6.8954e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.937250
Average KL loss: 0.380321
Average total loss: 1.317571
tensor(-14.4145, device='cuda:0') tensor(0.2232, device='cuda:0') tensor(-1.6656e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.941009
Average KL loss: 0.380105
Average total loss: 1.321114
tensor(-14.4173, device='cuda:0') tensor(0.2211, device='cuda:0') tensor(-4.0828e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.934856
Average KL loss: 0.379874
Average total loss: 1.314730
tensor(-14.4202, device='cuda:0') tensor(0.2192, device='cuda:0') tensor(-1.2893e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.937695
Average KL loss: 0.379684
Average total loss: 1.317379
tensor(-14.4230, device='cuda:0') tensor(0.2175, device='cuda:0') tensor(3.2589e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.933071
Average KL loss: 0.379505
Average total loss: 1.312576
tensor(-14.4257, device='cuda:0') tensor(0.2160, device='cuda:0') tensor(-1.4213e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.930661
Average KL loss: 0.379331
Average total loss: 1.309993
tensor(-14.4285, device='cuda:0') tensor(0.2147, device='cuda:0') tensor(-2.5688e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.934967
Average KL loss: 0.379156
Average total loss: 1.314123
tensor(-14.4313, device='cuda:0') tensor(0.2134, device='cuda:0') tensor(3.2266e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.930779
Average KL loss: 0.379035
Average total loss: 1.309814
tensor(-14.4340, device='cuda:0') tensor(0.2123, device='cuda:0') tensor(-1.4108e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.928953
Average KL loss: 0.378895
Average total loss: 1.307848
tensor(-14.4367, device='cuda:0') tensor(0.2112, device='cuda:0') tensor(-2.7102e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.929817
Average KL loss: 0.378780
Average total loss: 1.308597
tensor(-14.4394, device='cuda:0') tensor(0.2103, device='cuda:0') tensor(-1.4129e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.932823
Average KL loss: 0.378681
Average total loss: 1.311504
tensor(-14.4421, device='cuda:0') tensor(0.2094, device='cuda:0') tensor(1.4559e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.927010
Average KL loss: 0.378575
Average total loss: 1.305585
tensor(-14.4448, device='cuda:0') tensor(0.2085, device='cuda:0') tensor(-3.0959e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.928193
Average KL loss: 0.378504
Average total loss: 1.306697
tensor(-14.4475, device='cuda:0') tensor(0.2077, device='cuda:0') tensor(-1.9142e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.926886
Average KL loss: 0.378439
Average total loss: 1.305326
tensor(-14.4501, device='cuda:0') tensor(0.2070, device='cuda:0') tensor(7.8858e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.928486
Average KL loss: 0.378356
Average total loss: 1.306841
tensor(-14.4528, device='cuda:0') tensor(0.2063, device='cuda:0') tensor(4.2321e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.924790
Average KL loss: 0.378241
Average total loss: 1.303031
tensor(-14.4554, device='cuda:0') tensor(0.2056, device='cuda:0') tensor(-1.0076e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.925376
Average KL loss: 0.378181
Average total loss: 1.303556
tensor(-14.4580, device='cuda:0') tensor(0.2050, device='cuda:0') tensor(-8.3269e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.924812
Average KL loss: 0.378119
Average total loss: 1.302931
tensor(-14.4607, device='cuda:0') tensor(0.2044, device='cuda:0') tensor(1.7444e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.923045
Average KL loss: 0.378007
Average total loss: 1.301052
tensor(-14.4633, device='cuda:0') tensor(0.2039, device='cuda:0') tensor(-2.2990e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.921551
Average KL loss: 0.377922
Average total loss: 1.299473
tensor(-14.4659, device='cuda:0') tensor(0.2034, device='cuda:0') tensor(5.0783e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.919124
Average KL loss: 0.377877
Average total loss: 1.297000
tensor(-14.4684, device='cuda:0') tensor(0.2029, device='cuda:0') tensor(3.3824e-11, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.920347
Average KL loss: 0.377830
Average total loss: 1.298176
tensor(-14.4710, device='cuda:0') tensor(0.2024, device='cuda:0') tensor(-5.3346e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.922267
Average KL loss: 0.377786
Average total loss: 1.300053
tensor(-14.4736, device='cuda:0') tensor(0.2020, device='cuda:0') tensor(-1.6063e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.922276
Average KL loss: 0.377728
Average total loss: 1.300004
tensor(-14.4762, device='cuda:0') tensor(0.2015, device='cuda:0') tensor(-2.9907e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.920667
Average KL loss: 0.377691
Average total loss: 1.298358
tensor(-14.4787, device='cuda:0') tensor(0.2011, device='cuda:0') tensor(9.0697e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.924721
Average KL loss: 0.377613
Average total loss: 1.302334
tensor(-14.4813, device='cuda:0') tensor(0.2007, device='cuda:0') tensor(-2.0391e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.917544
Average KL loss: 0.377568
Average total loss: 1.295112
tensor(-14.4838, device='cuda:0') tensor(0.2003, device='cuda:0') tensor(-1.2485e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.919020
Average KL loss: 0.377498
Average total loss: 1.296518
tensor(-14.4863, device='cuda:0') tensor(0.2000, device='cuda:0') tensor(1.0361e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.916344
Average KL loss: 0.377450
Average total loss: 1.293794
tensor(-14.4888, device='cuda:0') tensor(0.1996, device='cuda:0') tensor(-9.6301e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.917804
Average KL loss: 0.377400
Average total loss: 1.295204
tensor(-14.4913, device='cuda:0') tensor(0.1993, device='cuda:0') tensor(-1.4873e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.914425
Average KL loss: 0.377388
Average total loss: 1.291814
tensor(-14.4938, device='cuda:0') tensor(0.1990, device='cuda:0') tensor(-8.9297e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.921460
Average KL loss: 0.377344
Average total loss: 1.298804
tensor(-14.4963, device='cuda:0') tensor(0.1987, device='cuda:0') tensor(8.1516e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.917821
Average KL loss: 0.377287
Average total loss: 1.295109
tensor(-14.4988, device='cuda:0') tensor(0.1984, device='cuda:0') tensor(-2.5115e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.913412
Average KL loss: 0.377226
Average total loss: 1.290639
tensor(-14.5013, device='cuda:0') tensor(0.1981, device='cuda:0') tensor(9.6662e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.917915
Average KL loss: 0.377213
Average total loss: 1.295128
tensor(-14.5038, device='cuda:0') tensor(0.1979, device='cuda:0') tensor(-2.1329e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.915637
Average KL loss: 0.377166
Average total loss: 1.292804
tensor(-14.5063, device='cuda:0') tensor(0.1976, device='cuda:0') tensor(1.0102e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.915065
Average KL loss: 0.377111
Average total loss: 1.292176
tensor(-14.5087, device='cuda:0') tensor(0.1973, device='cuda:0') tensor(-2.2372e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.914262
Average KL loss: 0.377087
Average total loss: 1.291349
tensor(-14.5112, device='cuda:0') tensor(0.1971, device='cuda:0') tensor(-6.8681e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.914456
Average KL loss: 0.377037
Average total loss: 1.291494
tensor(-14.5136, device='cuda:0') tensor(0.1968, device='cuda:0') tensor(-8.8445e-11, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.914804
Average KL loss: 0.376996
Average total loss: 1.291800
tensor(-14.5161, device='cuda:0') tensor(0.1966, device='cuda:0') tensor(-7.7892e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.916221
Average KL loss: 0.376964
Average total loss: 1.293185
tensor(-14.5185, device='cuda:0') tensor(0.1964, device='cuda:0') tensor(3.3194e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.915288
Average KL loss: 0.376869
Average total loss: 1.292157
tensor(-14.5209, device='cuda:0') tensor(0.1962, device='cuda:0') tensor(1.2068e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.914736
Average KL loss: 0.376837
Average total loss: 1.291573
tensor(-14.5234, device='cuda:0') tensor(0.1960, device='cuda:0') tensor(-1.2843e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.912232
Average KL loss: 0.376824
Average total loss: 1.289057
tensor(-14.5258, device='cuda:0') tensor(0.1958, device='cuda:0') tensor(-8.1402e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.910719
Average KL loss: 0.376824
Average total loss: 1.287543
tensor(-14.5282, device='cuda:0') tensor(0.1956, device='cuda:0') tensor(4.9367e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.913329
Average KL loss: 0.376785
Average total loss: 1.290114
tensor(-14.5306, device='cuda:0') tensor(0.1954, device='cuda:0') tensor(-1.5716e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.910894
Average KL loss: 0.376769
Average total loss: 1.287663
tensor(-14.5330, device='cuda:0') tensor(0.1952, device='cuda:0') tensor(-8.5667e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.913785
Average KL loss: 0.376744
Average total loss: 1.290529
tensor(-14.5353, device='cuda:0') tensor(0.1951, device='cuda:0') tensor(2.6704e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.911563
Average KL loss: 0.376708
Average total loss: 1.288271
tensor(-14.5377, device='cuda:0') tensor(0.1949, device='cuda:0') tensor(-1.5970e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.909283
Average KL loss: 0.376698
Average total loss: 1.285982
tensor(-14.5401, device='cuda:0') tensor(0.1948, device='cuda:0') tensor(-2.0039e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.911457
Average KL loss: 0.376673
Average total loss: 1.288130
tensor(-14.5425, device='cuda:0') tensor(0.1946, device='cuda:0') tensor(-5.7677e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.910661
Average KL loss: 0.376643
Average total loss: 1.287304
tensor(-14.5448, device='cuda:0') tensor(0.1945, device='cuda:0') tensor(-6.8231e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.911959
Average KL loss: 0.376561
Average total loss: 1.288520
tensor(-14.5472, device='cuda:0') tensor(0.1943, device='cuda:0') tensor(-9.0212e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.912045
Average KL loss: 0.376517
Average total loss: 1.288563
tensor(-14.5495, device='cuda:0') tensor(0.1942, device='cuda:0') tensor(-8.7612e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.909228
Average KL loss: 0.376538
Average total loss: 1.285765
tensor(-14.5519, device='cuda:0') tensor(0.1940, device='cuda:0') tensor(-8.1587e-11, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.909555
Average KL loss: 0.376469
Average total loss: 1.286024
tensor(-14.5542, device='cuda:0') tensor(0.1939, device='cuda:0') tensor(-1.1348e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.910855
Average KL loss: 0.376408
Average total loss: 1.287264
tensor(-14.5566, device='cuda:0') tensor(0.1937, device='cuda:0') tensor(-1.2547e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.907591
Average KL loss: 0.376345
Average total loss: 1.283936
tensor(-14.5589, device='cuda:0') tensor(0.1936, device='cuda:0') tensor(-2.3877e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.909490
Average KL loss: 0.376304
Average total loss: 1.285793
tensor(-14.5612, device='cuda:0') tensor(0.1935, device='cuda:0') tensor(-4.9967e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.909729
Average KL loss: 0.376267
Average total loss: 1.285996
tensor(-14.5635, device='cuda:0') tensor(0.1933, device='cuda:0') tensor(-8.8482e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.908397
Average KL loss: 0.376211
Average total loss: 1.284608
tensor(-14.5658, device='cuda:0') tensor(0.1932, device='cuda:0') tensor(7.5943e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.908661
Average KL loss: 0.376133
Average total loss: 1.284794
tensor(-14.5681, device='cuda:0') tensor(0.1931, device='cuda:0') tensor(-1.3168e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.908300
Average KL loss: 0.376077
Average total loss: 1.284377
tensor(-14.5704, device='cuda:0') tensor(0.1930, device='cuda:0') tensor(3.1816e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.907183
Average KL loss: 0.376017
Average total loss: 1.283200
tensor(-14.5727, device='cuda:0') tensor(0.1928, device='cuda:0') tensor(-7.8512e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.908499
Average KL loss: 0.375959
Average total loss: 1.284458
tensor(-14.5750, device='cuda:0') tensor(0.1928, device='cuda:0') tensor(-5.4348e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.908465
Average KL loss: 0.375905
Average total loss: 1.284370
tensor(-14.5773, device='cuda:0') tensor(0.1926, device='cuda:0') tensor(4.3042e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.906045
Average KL loss: 0.375837
Average total loss: 1.281883
tensor(-14.5796, device='cuda:0') tensor(0.1925, device='cuda:0') tensor(-1.8382e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.908798
Average KL loss: 0.375818
Average total loss: 1.284615
tensor(-14.5818, device='cuda:0') tensor(0.1924, device='cuda:0') tensor(3.0976e-11, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.909137
Average KL loss: 0.375793
Average total loss: 1.284930
tensor(-14.5841, device='cuda:0') tensor(0.1923, device='cuda:0') tensor(-2.4924e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.908560
Average KL loss: 0.375738
Average total loss: 1.284297
tensor(-14.5864, device='cuda:0') tensor(0.1922, device='cuda:0') tensor(-2.9450e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.904532
Average KL loss: 0.375683
Average total loss: 1.280215
tensor(-14.5886, device='cuda:0') tensor(0.1921, device='cuda:0') tensor(-1.4724e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.906230
Average KL loss: 0.375659
Average total loss: 1.281889
tensor(-14.5909, device='cuda:0') tensor(0.1920, device='cuda:0') tensor(-1.6073e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.906862
Average KL loss: 0.375591
Average total loss: 1.282454
tensor(-14.5931, device='cuda:0') tensor(0.1920, device='cuda:0') tensor(1.7728e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.906247
Average KL loss: 0.375544
Average total loss: 1.281790
tensor(-14.5954, device='cuda:0') tensor(0.1919, device='cuda:0') tensor(-7.1385e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.904160
Average KL loss: 0.375499
Average total loss: 1.279658
tensor(-14.5976, device='cuda:0') tensor(0.1918, device='cuda:0') tensor(1.2441e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.903318
Average KL loss: 0.375454
Average total loss: 1.278772
tensor(-14.5998, device='cuda:0') tensor(0.1917, device='cuda:0') tensor(-2.0661e-11, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.906523
Average KL loss: 0.375381
Average total loss: 1.281904
tensor(-14.6020, device='cuda:0') tensor(0.1916, device='cuda:0') tensor(-6.2140e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.905206
Average KL loss: 0.375282
Average total loss: 1.280488
tensor(-14.6042, device='cuda:0') tensor(0.1916, device='cuda:0') tensor(-1.5650e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.906190
Average KL loss: 0.375236
Average total loss: 1.281426
tensor(-14.6065, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(1.1758e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.902206
Average KL loss: 0.375201
Average total loss: 1.277407
tensor(-14.6087, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(1.3977e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.904627
Average KL loss: 0.375129
Average total loss: 1.279756
tensor(-14.6109, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-5.9223e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.903447
Average KL loss: 0.375087
Average total loss: 1.278534
tensor(-14.6131, device='cuda:0') tensor(0.1913, device='cuda:0') tensor(-1.3309e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.901867
Average KL loss: 0.375048
Average total loss: 1.276915
tensor(-14.6153, device='cuda:0') tensor(0.1912, device='cuda:0') tensor(-1.2886e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.904601
Average KL loss: 0.375032
Average total loss: 1.279633
tensor(-14.6175, device='cuda:0') tensor(0.1911, device='cuda:0') tensor(6.1207e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.905391
Average KL loss: 0.374978
Average total loss: 1.280369
tensor(-14.6196, device='cuda:0') tensor(0.1911, device='cuda:0') tensor(-2.1026e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.904203
Average KL loss: 0.374953
Average total loss: 1.279157
tensor(-14.6218, device='cuda:0') tensor(0.1910, device='cuda:0') tensor(6.3432e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.904526
Average KL loss: 0.374933
Average total loss: 1.279459
tensor(-14.6240, device='cuda:0') tensor(0.1909, device='cuda:0') tensor(4.3126e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.903376
Average KL loss: 0.374885
Average total loss: 1.278261
tensor(-14.6261, device='cuda:0') tensor(0.1909, device='cuda:0') tensor(4.0930e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.902445
Average KL loss: 0.374888
Average total loss: 1.277334
tensor(-14.6283, device='cuda:0') tensor(0.1909, device='cuda:0') tensor(3.0536e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.900010
Average KL loss: 0.374835
Average total loss: 1.274845
tensor(-14.6305, device='cuda:0') tensor(0.1908, device='cuda:0') tensor(1.6287e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.904577
Average KL loss: 0.374812
Average total loss: 1.279389
tensor(-14.6326, device='cuda:0') tensor(0.1907, device='cuda:0') tensor(-1.9947e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.902834
Average KL loss: 0.374821
Average total loss: 1.277655
tensor(-14.6348, device='cuda:0') tensor(0.1907, device='cuda:0') tensor(1.3448e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.901121
Average KL loss: 0.374783
Average total loss: 1.275904
tensor(-14.6369, device='cuda:0') tensor(0.1906, device='cuda:0') tensor(-1.0298e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.901774
Average KL loss: 0.374710
Average total loss: 1.276485
tensor(-14.6391, device='cuda:0') tensor(0.1906, device='cuda:0') tensor(-1.4831e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.902048
Average KL loss: 0.374655
Average total loss: 1.276703
tensor(-14.6412, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(8.0116e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.900550
Average KL loss: 0.374594
Average total loss: 1.275143
tensor(-14.6433, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(4.1241e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.900577
Average KL loss: 0.374550
Average total loss: 1.275127
tensor(-14.6454, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-1.1697e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.900922
Average KL loss: 0.374537
Average total loss: 1.275459
tensor(-14.6476, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(5.0890e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.900094
Average KL loss: 0.374529
Average total loss: 1.274623
tensor(-14.6497, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(2.4202e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.898596
Average KL loss: 0.374490
Average total loss: 1.273087
tensor(-14.6518, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-2.6633e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.900823
Average KL loss: 0.374470
Average total loss: 1.275293
tensor(-14.6539, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-6.3019e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.902109
Average KL loss: 0.374462
Average total loss: 1.276571
tensor(-14.6560, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-9.6375e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.901000
Average KL loss: 0.374460
Average total loss: 1.275460
tensor(-14.6581, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-4.8975e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.901431
Average KL loss: 0.374422
Average total loss: 1.275853
tensor(-14.6602, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(-7.6952e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.899638
Average KL loss: 0.374386
Average total loss: 1.274024
tensor(-14.6623, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(2.3107e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.899345
Average KL loss: 0.374346
Average total loss: 1.273691
tensor(-14.6644, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(5.6696e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.898804
Average KL loss: 0.374324
Average total loss: 1.273128
tensor(-14.6664, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(3.2352e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.897909
Average KL loss: 0.374286
Average total loss: 1.272194
tensor(-14.6685, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(6.9506e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.899137
Average KL loss: 0.374236
Average total loss: 1.273372
tensor(-14.6706, device='cuda:0') tensor(0.1899, device='cuda:0') tensor(-8.2405e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.897624
Average KL loss: 0.374194
Average total loss: 1.271818
tensor(-14.6726, device='cuda:0') tensor(0.1899, device='cuda:0') tensor(7.1971e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.898711
Average KL loss: 0.374176
Average total loss: 1.272887
tensor(-14.6747, device='cuda:0') tensor(0.1899, device='cuda:0') tensor(7.5873e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.898931
Average KL loss: 0.374169
Average total loss: 1.273099
tensor(-14.6768, device='cuda:0') tensor(0.1899, device='cuda:0') tensor(3.4395e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.899070
Average KL loss: 0.374146
Average total loss: 1.273217
tensor(-14.6788, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(1.4631e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.895544
Average KL loss: 0.374090
Average total loss: 1.269634
tensor(-14.6809, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-1.5094e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.898381
Average KL loss: 0.374024
Average total loss: 1.272405
tensor(-14.6829, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-7.7256e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.898070
Average KL loss: 0.373980
Average total loss: 1.272050
tensor(-14.6849, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(1.7901e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.896169
Average KL loss: 0.373934
Average total loss: 1.270102
tensor(-14.6870, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(1.2720e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.898282
Average KL loss: 0.373912
Average total loss: 1.272194
tensor(-14.6890, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(4.2536e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.897445
Average KL loss: 0.373879
Average total loss: 1.271323
tensor(-14.6911, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-1.7054e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.897837
Average KL loss: 0.373855
Average total loss: 1.271692
tensor(-14.6931, device='cuda:0') tensor(0.1896, device='cuda:0') tensor(-4.6085e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.895565
Average KL loss: 0.373820
Average total loss: 1.269384
tensor(-14.6951, device='cuda:0') tensor(0.1896, device='cuda:0') tensor(1.0352e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.897043
Average KL loss: 0.373791
Average total loss: 1.270833
tensor(-14.6971, device='cuda:0') tensor(0.1896, device='cuda:0') tensor(-3.4533e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.895037
Average KL loss: 0.373740
Average total loss: 1.268777
tensor(-14.6991, device='cuda:0') tensor(0.1896, device='cuda:0') tensor(-1.1623e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.896567
Average KL loss: 0.373681
Average total loss: 1.270248
tensor(-14.7011, device='cuda:0') tensor(0.1895, device='cuda:0') tensor(-9.1950e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.895194
Average KL loss: 0.373654
Average total loss: 1.268848
tensor(-14.7031, device='cuda:0') tensor(0.1895, device='cuda:0') tensor(-3.7257e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.898262
Average KL loss: 0.373653
Average total loss: 1.271915
tensor(-14.7051, device='cuda:0') tensor(0.1895, device='cuda:0') tensor(-8.1696e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.897790
Average KL loss: 0.373623
Average total loss: 1.271412
tensor(-14.7071, device='cuda:0') tensor(0.1895, device='cuda:0') tensor(4.7881e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.897387
Average KL loss: 0.373573
Average total loss: 1.270960
tensor(-14.7091, device='cuda:0') tensor(0.1895, device='cuda:0') tensor(-9.5569e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.895818
Average KL loss: 0.373546
Average total loss: 1.269363
tensor(-14.7111, device='cuda:0') tensor(0.1894, device='cuda:0') tensor(-2.4761e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.896945
Average KL loss: 0.373524
Average total loss: 1.270469
tensor(-14.7131, device='cuda:0') tensor(0.1894, device='cuda:0') tensor(-4.4588e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.894547
Average KL loss: 0.373498
Average total loss: 1.268044
tensor(-14.7151, device='cuda:0') tensor(0.1894, device='cuda:0') tensor(6.5120e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.897597
Average KL loss: 0.373491
Average total loss: 1.271088
tensor(-14.7170, device='cuda:0') tensor(0.1894, device='cuda:0') tensor(4.2176e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.895141
Average KL loss: 0.373504
Average total loss: 1.268645
tensor(-14.7190, device='cuda:0') tensor(0.1894, device='cuda:0') tensor(-1.3812e-11, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.895497
Average KL loss: 0.373475
Average total loss: 1.268972
tensor(-14.7210, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(-7.7572e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.893916
Average KL loss: 0.373436
Average total loss: 1.267351
tensor(-14.7229, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(-3.2814e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.894831
Average KL loss: 0.373385
Average total loss: 1.268216
tensor(-14.7249, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(5.9824e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.894870
Average KL loss: 0.373339
Average total loss: 1.268208
tensor(-14.7268, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(5.7719e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.894510
Average KL loss: 0.373287
Average total loss: 1.267798
tensor(-14.7288, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(-2.9599e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.894201
Average KL loss: 0.373249
Average total loss: 1.267450
tensor(-14.7307, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(-2.5483e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.896768
Average KL loss: 0.373202
Average total loss: 1.269970
tensor(-14.7327, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(2.2609e-11, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.893515
Average KL loss: 0.373150
Average total loss: 1.266665
tensor(-14.7346, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(-1.0940e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.893888
Average KL loss: 0.373140
Average total loss: 1.267027
tensor(-14.7365, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(3.8264e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.894101
Average KL loss: 0.373109
Average total loss: 1.267210
tensor(-14.7385, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(1.5466e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.894211
Average KL loss: 0.373090
Average total loss: 1.267300
tensor(-14.7404, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(-5.6530e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.893334
Average KL loss: 0.373080
Average total loss: 1.266414
tensor(-14.7423, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(-1.5327e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.891467
Average KL loss: 0.373078
Average total loss: 1.264545
tensor(-14.7443, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(1.1229e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.891204
Average KL loss: 0.373043
Average total loss: 1.264246
tensor(-14.7462, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(7.6585e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.894907
Average KL loss: 0.372999
Average total loss: 1.267906
tensor(-14.7481, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-7.6280e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.892891
Average KL loss: 0.372974
Average total loss: 1.265865
tensor(-14.7500, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-2.3441e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.893139
Average KL loss: 0.372961
Average total loss: 1.266101
tensor(-14.7519, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(9.2155e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.895602
Average KL loss: 0.372984
Average total loss: 1.268586
tensor(-14.7538, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(1.5857e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.894459
Average KL loss: 0.372975
Average total loss: 1.267435
tensor(-14.7557, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-3.5864e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.895264
Average KL loss: 0.372976
Average total loss: 1.268240
tensor(-14.7576, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-1.0756e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.892929
Average KL loss: 0.372978
Average total loss: 1.265907
tensor(-14.7595, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-1.0844e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.892992
Average KL loss: 0.372962
Average total loss: 1.265954
tensor(-14.7614, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(1.9164e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.894714
Average KL loss: 0.372961
Average total loss: 1.267675
tensor(-14.7633, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(2.4168e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.892027
Average KL loss: 0.372924
Average total loss: 1.264951
tensor(-14.7651, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(7.2226e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.892116
Average KL loss: 0.372904
Average total loss: 1.265019
tensor(-14.7670, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-1.9880e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.890940
Average KL loss: 0.372885
Average total loss: 1.263824
tensor(-14.7672, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(1.1093e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.894031
Average KL loss: 0.372884
Average total loss: 1.266915
tensor(-14.7674, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(3.5661e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.893934
Average KL loss: 0.372885
Average total loss: 1.266819
tensor(-14.7676, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(1.0777e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.892714
Average KL loss: 0.372885
Average total loss: 1.265598
tensor(-14.7678, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-6.2765e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.892215
Average KL loss: 0.372884
Average total loss: 1.265099
tensor(-14.7680, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(1.3064e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.891686
Average KL loss: 0.372882
Average total loss: 1.264568
tensor(-14.7682, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-3.9055e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.892198
Average KL loss: 0.372880
Average total loss: 1.265078
tensor(-14.7684, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-1.8806e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.893052
Average KL loss: 0.372877
Average total loss: 1.265928
tensor(-14.7685, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-1.3354e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.891206
Average KL loss: 0.372874
Average total loss: 1.264080
tensor(-14.7687, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(7.7629e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.892958
Average KL loss: 0.372875
Average total loss: 1.265833
tensor(-14.7689, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-5.4194e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.893336
Average KL loss: 0.372876
Average total loss: 1.266212
tensor(-14.7691, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-2.7572e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.893460
Average KL loss: 0.372875
Average total loss: 1.266335
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(3.5116e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.893316
Average KL loss: 0.372873
Average total loss: 1.266189
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(1.9029e-12, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.890570
Average KL loss: 0.372873
Average total loss: 1.263443
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(2.7683e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.893332
Average KL loss: 0.372873
Average total loss: 1.266205
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-5.2717e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.892091
Average KL loss: 0.372873
Average total loss: 1.264964
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-8.2523e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.890964
Average KL loss: 0.372873
Average total loss: 1.263837
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(1.2518e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.892544
Average KL loss: 0.372873
Average total loss: 1.265417
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-6.8748e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.892536
Average KL loss: 0.372873
Average total loss: 1.265409
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-1.1087e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.892687
Average KL loss: 0.372873
Average total loss: 1.265559
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-7.6595e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.893551
Average KL loss: 0.372872
Average total loss: 1.266423
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-8.7490e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.894337
Average KL loss: 0.372872
Average total loss: 1.267209
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-1.2069e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.894679
Average KL loss: 0.372872
Average total loss: 1.267551
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-1.7565e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.893572
Average KL loss: 0.372872
Average total loss: 1.266444
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(5.9433e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.891722
Average KL loss: 0.372872
Average total loss: 1.264594
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-1.2831e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.891865
Average KL loss: 0.372872
Average total loss: 1.264737
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(9.4107e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.893364
Average KL loss: 0.372872
Average total loss: 1.266236
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-1.4012e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.892883
Average KL loss: 0.372872
Average total loss: 1.265755
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-1.3664e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.892694
Average KL loss: 0.372872
Average total loss: 1.265566
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-2.5511e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.892181
Average KL loss: 0.372872
Average total loss: 1.265053
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(1.4083e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.890820
Average KL loss: 0.372872
Average total loss: 1.263691
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(3.6916e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.892838
Average KL loss: 0.372872
Average total loss: 1.265710
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(8.8430e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.890987
Average KL loss: 0.372872
Average total loss: 1.263858
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-9.2183e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.891749
Average KL loss: 0.372872
Average total loss: 1.264620
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(1.2851e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.894693
Average KL loss: 0.372872
Average total loss: 1.267564
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-1.5459e-09, device='cuda:0')
 Percentile value: -14.632458686828613
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =    1656 /    1728             ( 95.83%) | total_pruned =      72 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   21680 /   36864             ( 58.81%) | total_pruned =   15184 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   21398 /   36864             ( 58.05%) | total_pruned =   15466 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   17488 /   36864             ( 47.44%) | total_pruned =   19376 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   15628 /   36864             ( 42.39%) | total_pruned =   21236 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   35598 /   73728             ( 48.28%) | total_pruned =   38130 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   46423 /  147456             ( 31.48%) | total_pruned =  101033 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    6327 /    8192             ( 77.23%) | total_pruned =    1865 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   34371 /  147456             ( 23.31%) | total_pruned =  113085 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   28950 /  147456             ( 19.63%) | total_pruned =  118506 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   51109 /  294912             ( 17.33%) | total_pruned =  243803 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   47925 /  589824             (  8.13%) | total_pruned =  541899 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   13725 /   32768             ( 41.89%) | total_pruned =   19043 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   18003 /  589824             (  3.05%) | total_pruned =  571821 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     139 /     256             ( 54.30%) | total_pruned =     117 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   16427 /  589824             (  2.79%) | total_pruned =  573397 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   43033 / 1179648             (  3.65%) | total_pruned = 1136615 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     411 /     512             ( 80.27%) | total_pruned =     101 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   66527 / 2359296             (  2.82%) | total_pruned = 2292769 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   32391 /  131072             ( 24.71%) | total_pruned =   98681 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   66805 / 2359296             (  2.83%) | total_pruned = 2292491 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      93 /     512             ( 18.16%) | total_pruned =     419 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   99556 / 2359296             (  4.22%) | total_pruned = 2259740 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     484 /     512             ( 94.53%) | total_pruned =      28 | shape = torch.Size([512])
linear.weight        | nonzeros =    4768 /    5120             ( 93.12%) | total_pruned =     352 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 29/100 Loss: 0.000410 Accuracy: 84.94 100.00 % Best test Accuracy: 85.04%
tensor(-14.7693, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(8.7886e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.999100
Average KL loss: 0.372114
Average total loss: 1.371214
tensor(-14.7715, device='cuda:0') tensor(0.1817, device='cuda:0') tensor(-4.8681e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.996061
Average KL loss: 0.371276
Average total loss: 1.367337
tensor(-14.7736, device='cuda:0') tensor(0.1767, device='cuda:0') tensor(1.5243e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.990166
Average KL loss: 0.370691
Average total loss: 1.360858
tensor(-14.7756, device='cuda:0') tensor(0.1732, device='cuda:0') tensor(-1.2048e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.991836
Average KL loss: 0.370219
Average total loss: 1.362054
tensor(-14.7776, device='cuda:0') tensor(0.1709, device='cuda:0') tensor(-9.2157e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.992361
Average KL loss: 0.369830
Average total loss: 1.362192
tensor(-14.7795, device='cuda:0') tensor(0.1694, device='cuda:0') tensor(-5.8159e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.995531
Average KL loss: 0.369580
Average total loss: 1.365111
tensor(-14.7814, device='cuda:0') tensor(0.1684, device='cuda:0') tensor(9.7309e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.991312
Average KL loss: 0.369427
Average total loss: 1.360739
tensor(-14.7833, device='cuda:0') tensor(0.1676, device='cuda:0') tensor(-3.7626e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.986250
Average KL loss: 0.369332
Average total loss: 1.355582
tensor(-14.7852, device='cuda:0') tensor(0.1670, device='cuda:0') tensor(1.2900e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.984464
Average KL loss: 0.369230
Average total loss: 1.353693
tensor(-14.7871, device='cuda:0') tensor(0.1664, device='cuda:0') tensor(-1.6739e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.980110
Average KL loss: 0.369082
Average total loss: 1.349193
tensor(-14.7890, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(8.7450e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.977819
Average KL loss: 0.368970
Average total loss: 1.346790
tensor(-14.7909, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(-2.3262e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.977957
Average KL loss: 0.368861
Average total loss: 1.346818
tensor(-14.7928, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-1.0467e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.972589
Average KL loss: 0.368776
Average total loss: 1.341364
tensor(-14.7947, device='cuda:0') tensor(0.1649, device='cuda:0') tensor(-7.8711e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.969040
Average KL loss: 0.368696
Average total loss: 1.337736
tensor(-14.7965, device='cuda:0') tensor(0.1646, device='cuda:0') tensor(-6.0883e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.968471
Average KL loss: 0.368630
Average total loss: 1.337101
tensor(-14.7984, device='cuda:0') tensor(0.1643, device='cuda:0') tensor(-2.4743e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.967568
Average KL loss: 0.368534
Average total loss: 1.336101
tensor(-14.8002, device='cuda:0') tensor(0.1640, device='cuda:0') tensor(6.9002e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.962524
Average KL loss: 0.368439
Average total loss: 1.330963
tensor(-14.8021, device='cuda:0') tensor(0.1638, device='cuda:0') tensor(-2.8060e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.961584
Average KL loss: 0.368325
Average total loss: 1.329909
tensor(-14.8039, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(-1.9588e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.961578
Average KL loss: 0.368227
Average total loss: 1.329806
tensor(-14.8057, device='cuda:0') tensor(0.1634, device='cuda:0') tensor(5.7694e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.961061
Average KL loss: 0.368176
Average total loss: 1.329238
tensor(-14.8075, device='cuda:0') tensor(0.1632, device='cuda:0') tensor(-3.3076e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.955878
Average KL loss: 0.368107
Average total loss: 1.323985
tensor(-14.8094, device='cuda:0') tensor(0.1630, device='cuda:0') tensor(-1.1762e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.954975
Average KL loss: 0.368043
Average total loss: 1.323018
tensor(-14.8112, device='cuda:0') tensor(0.1629, device='cuda:0') tensor(3.1603e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.954921
Average KL loss: 0.368006
Average total loss: 1.322926
tensor(-14.8130, device='cuda:0') tensor(0.1628, device='cuda:0') tensor(1.1609e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.951442
Average KL loss: 0.367937
Average total loss: 1.319379
tensor(-14.8148, device='cuda:0') tensor(0.1626, device='cuda:0') tensor(-1.3568e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.952157
Average KL loss: 0.367907
Average total loss: 1.320064
tensor(-14.8166, device='cuda:0') tensor(0.1625, device='cuda:0') tensor(-2.7332e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.949146
Average KL loss: 0.367883
Average total loss: 1.317028
tensor(-14.8184, device='cuda:0') tensor(0.1624, device='cuda:0') tensor(-2.3772e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.946987
Average KL loss: 0.367831
Average total loss: 1.314818
tensor(-14.8202, device='cuda:0') tensor(0.1623, device='cuda:0') tensor(-9.4332e-11, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.951149
Average KL loss: 0.367783
Average total loss: 1.318932
tensor(-14.8220, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(-4.5369e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.946143
Average KL loss: 0.367767
Average total loss: 1.313910
tensor(-14.8238, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(-1.5896e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.945228
Average KL loss: 0.367753
Average total loss: 1.312980
tensor(-14.8256, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(-1.2494e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.949433
Average KL loss: 0.367729
Average total loss: 1.317162
tensor(-14.8274, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-1.9010e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.945412
Average KL loss: 0.367730
Average total loss: 1.313143
tensor(-14.8292, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-1.5528e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.944727
Average KL loss: 0.367697
Average total loss: 1.312424
tensor(-14.8309, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(-4.5657e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.945672
Average KL loss: 0.367694
Average total loss: 1.313367
tensor(-14.8327, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(-1.3406e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.946865
Average KL loss: 0.367665
Average total loss: 1.314530
tensor(-14.8345, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(-4.4222e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.937004
Average KL loss: 0.367637
Average total loss: 1.304641
tensor(-14.8362, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(8.5404e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.939522
Average KL loss: 0.367572
Average total loss: 1.307094
tensor(-14.8380, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(3.4776e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.939664
Average KL loss: 0.367569
Average total loss: 1.307233
tensor(-14.8398, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(4.1341e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.939110
Average KL loss: 0.367557
Average total loss: 1.306668
tensor(-14.8415, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-1.7978e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.935503
Average KL loss: 0.367520
Average total loss: 1.303023
tensor(-14.8433, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-1.4330e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.937030
Average KL loss: 0.367478
Average total loss: 1.304508
tensor(-14.8450, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-1.7956e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.940539
Average KL loss: 0.367452
Average total loss: 1.307991
tensor(-14.8468, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(3.9685e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.934358
Average KL loss: 0.367440
Average total loss: 1.301798
tensor(-14.8485, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-7.4244e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.935565
Average KL loss: 0.367431
Average total loss: 1.302996
tensor(-14.8502, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-1.6701e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.933161
Average KL loss: 0.367409
Average total loss: 1.300569
tensor(-14.8520, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-4.4577e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.931879
Average KL loss: 0.367403
Average total loss: 1.299282
tensor(-14.8537, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-9.9829e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.934637
Average KL loss: 0.367338
Average total loss: 1.301976
tensor(-14.8554, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(9.1870e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.931849
Average KL loss: 0.367297
Average total loss: 1.299146
tensor(-14.8572, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-7.7868e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.930687
Average KL loss: 0.367291
Average total loss: 1.297978
tensor(-14.8589, device='cuda:0') tensor(0.1615, device='cuda:0') tensor(-7.8721e-11, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.934407
Average KL loss: 0.367263
Average total loss: 1.301670
tensor(-14.8606, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-1.0747e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.932296
Average KL loss: 0.367268
Average total loss: 1.299563
tensor(-14.8623, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-5.2812e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.930223
Average KL loss: 0.367257
Average total loss: 1.297481
tensor(-14.8640, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-2.3809e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.930812
Average KL loss: 0.367223
Average total loss: 1.298035
tensor(-14.8657, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-1.2807e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.929875
Average KL loss: 0.367219
Average total loss: 1.297094
tensor(-14.8674, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-3.9573e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.932700
Average KL loss: 0.367222
Average total loss: 1.299922
tensor(-14.8691, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-2.1833e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.927803
Average KL loss: 0.367220
Average total loss: 1.295023
tensor(-14.8708, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-1.1420e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.927000
Average KL loss: 0.367230
Average total loss: 1.294230
tensor(-14.8725, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-8.5905e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.927067
Average KL loss: 0.367207
Average total loss: 1.294274
tensor(-14.8742, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(5.9585e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.928260
Average KL loss: 0.367195
Average total loss: 1.295455
tensor(-14.8759, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-1.0615e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.927954
Average KL loss: 0.367187
Average total loss: 1.295141
tensor(-14.8776, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-1.1501e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.926610
Average KL loss: 0.367164
Average total loss: 1.293774
tensor(-14.8793, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-1.5585e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.928440
Average KL loss: 0.367153
Average total loss: 1.295592
tensor(-14.8810, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-6.7954e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.926372
Average KL loss: 0.367126
Average total loss: 1.293499
tensor(-14.8827, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-4.8033e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.926600
Average KL loss: 0.367099
Average total loss: 1.293699
tensor(-14.8843, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-1.3961e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.927305
Average KL loss: 0.367063
Average total loss: 1.294368
tensor(-14.8860, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-8.2619e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.924750
Average KL loss: 0.367028
Average total loss: 1.291778
tensor(-14.8877, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-4.4748e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.922513
Average KL loss: 0.367051
Average total loss: 1.289564
tensor(-14.8893, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(2.9748e-11, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.925287
Average KL loss: 0.367040
Average total loss: 1.292327
tensor(-14.8910, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(7.3102e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.924921
Average KL loss: 0.367018
Average total loss: 1.291939
tensor(-14.8927, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(-2.2977e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.921571
Average KL loss: 0.367013
Average total loss: 1.288584
tensor(-14.8943, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(-1.3918e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.924610
Average KL loss: 0.367024
Average total loss: 1.291633
tensor(-14.8960, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(4.7019e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.922381
Average KL loss: 0.366996
Average total loss: 1.289377
tensor(-14.8976, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(1.1754e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.925338
Average KL loss: 0.366920
Average total loss: 1.292257
tensor(-14.8993, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(-3.8682e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.919585
Average KL loss: 0.366906
Average total loss: 1.286491
tensor(-14.9009, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(-4.6966e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.923042
Average KL loss: 0.366877
Average total loss: 1.289919
tensor(-14.9026, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(4.0372e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.920397
Average KL loss: 0.366822
Average total loss: 1.287219
tensor(-14.9042, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(-2.3178e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.920513
Average KL loss: 0.366783
Average total loss: 1.287296
tensor(-14.9058, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(1.2013e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.919952
Average KL loss: 0.366742
Average total loss: 1.286694
tensor(-14.9075, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-1.3703e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.919986
Average KL loss: 0.366722
Average total loss: 1.286708
tensor(-14.9091, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-1.2121e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.919950
Average KL loss: 0.366685
Average total loss: 1.286635
tensor(-14.9108, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(5.1142e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.921795
Average KL loss: 0.366656
Average total loss: 1.288451
tensor(-14.9124, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-1.1728e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.918646
Average KL loss: 0.366608
Average total loss: 1.285254
tensor(-14.9140, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-6.6641e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.918977
Average KL loss: 0.366597
Average total loss: 1.285573
tensor(-14.9156, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(7.7429e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.920068
Average KL loss: 0.366587
Average total loss: 1.286655
tensor(-14.9173, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(1.5653e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.918952
Average KL loss: 0.366573
Average total loss: 1.285524
tensor(-14.9189, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(-1.4158e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.916337
Average KL loss: 0.366514
Average total loss: 1.282851
tensor(-14.9205, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(1.4080e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.918286
Average KL loss: 0.366465
Average total loss: 1.284750
tensor(-14.9221, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(-1.6711e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.916646
Average KL loss: 0.366436
Average total loss: 1.283082
tensor(-14.9237, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(-7.5260e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.917978
Average KL loss: 0.366416
Average total loss: 1.284394
tensor(-14.9253, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(-3.4247e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.917266
Average KL loss: 0.366408
Average total loss: 1.283674
tensor(-14.9269, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(3.3426e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.918924
Average KL loss: 0.366397
Average total loss: 1.285321
tensor(-14.9285, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(-1.0837e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.918204
Average KL loss: 0.366366
Average total loss: 1.284570
tensor(-14.9301, device='cuda:0') tensor(0.1623, device='cuda:0') tensor(-2.4145e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.919119
Average KL loss: 0.366342
Average total loss: 1.285461
tensor(-14.9317, device='cuda:0') tensor(0.1623, device='cuda:0') tensor(-1.1198e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.916589
Average KL loss: 0.366330
Average total loss: 1.282919
tensor(-14.9333, device='cuda:0') tensor(0.1624, device='cuda:0') tensor(-4.7870e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.913945
Average KL loss: 0.366300
Average total loss: 1.280245
tensor(-14.9349, device='cuda:0') tensor(0.1624, device='cuda:0') tensor(3.5724e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.914165
Average KL loss: 0.366266
Average total loss: 1.280431
tensor(-14.9365, device='cuda:0') tensor(0.1624, device='cuda:0') tensor(-4.3770e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.918147
Average KL loss: 0.366231
Average total loss: 1.284377
tensor(-14.9381, device='cuda:0') tensor(0.1624, device='cuda:0') tensor(-1.1971e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.917453
Average KL loss: 0.366190
Average total loss: 1.283643
tensor(-14.9396, device='cuda:0') tensor(0.1625, device='cuda:0') tensor(3.3955e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.914296
Average KL loss: 0.366196
Average total loss: 1.280492
tensor(-14.9412, device='cuda:0') tensor(0.1625, device='cuda:0') tensor(-6.3757e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.916388
Average KL loss: 0.366200
Average total loss: 1.282588
tensor(-14.9428, device='cuda:0') tensor(0.1626, device='cuda:0') tensor(-1.6498e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.916993
Average KL loss: 0.366203
Average total loss: 1.283196
tensor(-14.9444, device='cuda:0') tensor(0.1626, device='cuda:0') tensor(-1.6721e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.913869
Average KL loss: 0.366167
Average total loss: 1.280036
tensor(-14.9460, device='cuda:0') tensor(0.1627, device='cuda:0') tensor(-1.0102e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.914846
Average KL loss: 0.366136
Average total loss: 1.280982
tensor(-14.9475, device='cuda:0') tensor(0.1627, device='cuda:0') tensor(-1.0110e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.917190
Average KL loss: 0.366116
Average total loss: 1.283307
tensor(-14.9491, device='cuda:0') tensor(0.1627, device='cuda:0') tensor(-1.6414e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.917161
Average KL loss: 0.366117
Average total loss: 1.283279
tensor(-14.9507, device='cuda:0') tensor(0.1628, device='cuda:0') tensor(-1.1739e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.915837
Average KL loss: 0.366112
Average total loss: 1.281949
tensor(-14.9522, device='cuda:0') tensor(0.1628, device='cuda:0') tensor(-1.5664e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.915261
Average KL loss: 0.366113
Average total loss: 1.281373
tensor(-14.9538, device='cuda:0') tensor(0.1628, device='cuda:0') tensor(-4.9940e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.914137
Average KL loss: 0.366091
Average total loss: 1.280228
tensor(-14.9553, device='cuda:0') tensor(0.1629, device='cuda:0') tensor(-6.4986e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.914190
Average KL loss: 0.366051
Average total loss: 1.280241
tensor(-14.9569, device='cuda:0') tensor(0.1629, device='cuda:0') tensor(-5.3379e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.913661
Average KL loss: 0.366028
Average total loss: 1.279689
tensor(-14.9584, device='cuda:0') tensor(0.1630, device='cuda:0') tensor(2.6890e-11, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.914086
Average KL loss: 0.366025
Average total loss: 1.280110
tensor(-14.9600, device='cuda:0') tensor(0.1630, device='cuda:0') tensor(-8.6661e-11, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.914447
Average KL loss: 0.365981
Average total loss: 1.280428
tensor(-14.9615, device='cuda:0') tensor(0.1630, device='cuda:0') tensor(7.8251e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.915189
Average KL loss: 0.365956
Average total loss: 1.281145
tensor(-14.9631, device='cuda:0') tensor(0.1631, device='cuda:0') tensor(-7.0003e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.914129
Average KL loss: 0.365905
Average total loss: 1.280034
tensor(-14.9646, device='cuda:0') tensor(0.1631, device='cuda:0') tensor(4.7629e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.913930
Average KL loss: 0.365859
Average total loss: 1.279789
tensor(-14.9661, device='cuda:0') tensor(0.1631, device='cuda:0') tensor(-1.0864e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.913449
Average KL loss: 0.365823
Average total loss: 1.279272
tensor(-14.9677, device='cuda:0') tensor(0.1632, device='cuda:0') tensor(-7.6106e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.913074
Average KL loss: 0.365786
Average total loss: 1.278860
tensor(-14.9692, device='cuda:0') tensor(0.1632, device='cuda:0') tensor(6.6994e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.912818
Average KL loss: 0.365739
Average total loss: 1.278557
tensor(-14.9708, device='cuda:0') tensor(0.1632, device='cuda:0') tensor(1.3477e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.911174
Average KL loss: 0.365706
Average total loss: 1.276880
tensor(-14.9723, device='cuda:0') tensor(0.1633, device='cuda:0') tensor(3.8554e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.915199
Average KL loss: 0.365685
Average total loss: 1.280884
tensor(-14.9738, device='cuda:0') tensor(0.1633, device='cuda:0') tensor(8.0268e-11, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.912377
Average KL loss: 0.365637
Average total loss: 1.278013
tensor(-14.9754, device='cuda:0') tensor(0.1634, device='cuda:0') tensor(1.1181e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.913533
Average KL loss: 0.365632
Average total loss: 1.279165
tensor(-14.9769, device='cuda:0') tensor(0.1634, device='cuda:0') tensor(-1.2516e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.912345
Average KL loss: 0.365623
Average total loss: 1.277968
tensor(-14.9784, device='cuda:0') tensor(0.1635, device='cuda:0') tensor(-1.0067e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.914185
Average KL loss: 0.365611
Average total loss: 1.279796
tensor(-14.9799, device='cuda:0') tensor(0.1635, device='cuda:0') tensor(-7.4538e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.911010
Average KL loss: 0.365608
Average total loss: 1.276619
tensor(-14.9814, device='cuda:0') tensor(0.1635, device='cuda:0') tensor(-9.0750e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.911176
Average KL loss: 0.365583
Average total loss: 1.276759
tensor(-14.9830, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(-1.5025e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.910871
Average KL loss: 0.365576
Average total loss: 1.276447
tensor(-14.9845, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(-9.6026e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.909640
Average KL loss: 0.365576
Average total loss: 1.275216
tensor(-14.9860, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(-3.3238e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.910971
Average KL loss: 0.365555
Average total loss: 1.276526
tensor(-14.9875, device='cuda:0') tensor(0.1637, device='cuda:0') tensor(1.0907e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.911443
Average KL loss: 0.365526
Average total loss: 1.276969
tensor(-14.9890, device='cuda:0') tensor(0.1637, device='cuda:0') tensor(8.8316e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.910852
Average KL loss: 0.365521
Average total loss: 1.276373
tensor(-14.9905, device='cuda:0') tensor(0.1638, device='cuda:0') tensor(-8.5168e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.910469
Average KL loss: 0.365479
Average total loss: 1.275948
tensor(-14.9920, device='cuda:0') tensor(0.1638, device='cuda:0') tensor(2.8809e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.910216
Average KL loss: 0.365432
Average total loss: 1.275648
tensor(-14.9935, device='cuda:0') tensor(0.1639, device='cuda:0') tensor(-1.4399e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.909567
Average KL loss: 0.365437
Average total loss: 1.275004
tensor(-14.9950, device='cuda:0') tensor(0.1639, device='cuda:0') tensor(-8.9253e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.910545
Average KL loss: 0.365423
Average total loss: 1.275967
tensor(-14.9964, device='cuda:0') tensor(0.1639, device='cuda:0') tensor(-1.5656e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.909471
Average KL loss: 0.365393
Average total loss: 1.274864
tensor(-14.9979, device='cuda:0') tensor(0.1640, device='cuda:0') tensor(-1.2279e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.910459
Average KL loss: 0.365396
Average total loss: 1.275854
tensor(-14.9994, device='cuda:0') tensor(0.1640, device='cuda:0') tensor(-5.7927e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.909299
Average KL loss: 0.365416
Average total loss: 1.274715
tensor(-15.0009, device='cuda:0') tensor(0.1641, device='cuda:0') tensor(-1.1897e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.908122
Average KL loss: 0.365420
Average total loss: 1.273542
tensor(-15.0024, device='cuda:0') tensor(0.1642, device='cuda:0') tensor(-5.5737e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.909233
Average KL loss: 0.365408
Average total loss: 1.274641
tensor(-15.0039, device='cuda:0') tensor(0.1642, device='cuda:0') tensor(-1.0076e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.909515
Average KL loss: 0.365381
Average total loss: 1.274895
tensor(-15.0054, device='cuda:0') tensor(0.1642, device='cuda:0') tensor(1.5276e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.909080
Average KL loss: 0.365367
Average total loss: 1.274447
tensor(-15.0069, device='cuda:0') tensor(0.1643, device='cuda:0') tensor(1.4651e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.909616
Average KL loss: 0.365354
Average total loss: 1.274970
tensor(-15.0083, device='cuda:0') tensor(0.1643, device='cuda:0') tensor(-1.8398e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.908628
Average KL loss: 0.365329
Average total loss: 1.273957
tensor(-15.0098, device='cuda:0') tensor(0.1644, device='cuda:0') tensor(-6.2866e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.908293
Average KL loss: 0.365315
Average total loss: 1.273608
tensor(-15.0113, device='cuda:0') tensor(0.1644, device='cuda:0') tensor(5.5534e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.907729
Average KL loss: 0.365285
Average total loss: 1.273014
tensor(-15.0128, device='cuda:0') tensor(0.1645, device='cuda:0') tensor(1.3824e-11, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.910350
Average KL loss: 0.365261
Average total loss: 1.275611
tensor(-15.0142, device='cuda:0') tensor(0.1645, device='cuda:0') tensor(-1.1790e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.907777
Average KL loss: 0.365237
Average total loss: 1.273013
tensor(-15.0157, device='cuda:0') tensor(0.1645, device='cuda:0') tensor(6.5737e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.907722
Average KL loss: 0.365217
Average total loss: 1.272940
tensor(-15.0171, device='cuda:0') tensor(0.1646, device='cuda:0') tensor(-5.3440e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.909522
Average KL loss: 0.365191
Average total loss: 1.274713
tensor(-15.0186, device='cuda:0') tensor(0.1646, device='cuda:0') tensor(-1.6996e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.906444
Average KL loss: 0.365171
Average total loss: 1.271614
tensor(-15.0201, device='cuda:0') tensor(0.1647, device='cuda:0') tensor(-9.0374e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.907547
Average KL loss: 0.365141
Average total loss: 1.272689
tensor(-15.0215, device='cuda:0') tensor(0.1647, device='cuda:0') tensor(3.0043e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.906644
Average KL loss: 0.365140
Average total loss: 1.271785
tensor(-15.0230, device='cuda:0') tensor(0.1648, device='cuda:0') tensor(6.1773e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.907305
Average KL loss: 0.365112
Average total loss: 1.272417
tensor(-15.0244, device='cuda:0') tensor(0.1648, device='cuda:0') tensor(2.4675e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.908096
Average KL loss: 0.365075
Average total loss: 1.273170
tensor(-15.0258, device='cuda:0') tensor(0.1648, device='cuda:0') tensor(-5.6461e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.906036
Average KL loss: 0.365078
Average total loss: 1.271114
tensor(-15.0273, device='cuda:0') tensor(0.1649, device='cuda:0') tensor(-9.8778e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.907390
Average KL loss: 0.365067
Average total loss: 1.272457
tensor(-15.0287, device='cuda:0') tensor(0.1649, device='cuda:0') tensor(-4.2777e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.906363
Average KL loss: 0.365038
Average total loss: 1.271401
tensor(-15.0302, device='cuda:0') tensor(0.1649, device='cuda:0') tensor(3.9201e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.906494
Average KL loss: 0.365038
Average total loss: 1.271532
tensor(-15.0316, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-4.2094e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.909961
Average KL loss: 0.365058
Average total loss: 1.275019
tensor(-15.0331, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-4.9811e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.906733
Average KL loss: 0.365036
Average total loss: 1.271770
tensor(-15.0345, device='cuda:0') tensor(0.1651, device='cuda:0') tensor(-1.0133e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.908549
Average KL loss: 0.365008
Average total loss: 1.273557
tensor(-15.0359, device='cuda:0') tensor(0.1651, device='cuda:0') tensor(-7.1045e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.907112
Average KL loss: 0.364999
Average total loss: 1.272110
tensor(-15.0374, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-6.0904e-11, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.905010
Average KL loss: 0.365003
Average total loss: 1.270012
tensor(-15.0388, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-3.9261e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.906295
Average KL loss: 0.364982
Average total loss: 1.271277
tensor(-15.0402, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(-2.8223e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.908327
Average KL loss: 0.364955
Average total loss: 1.273282
tensor(-15.0417, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(5.7543e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.904822
Average KL loss: 0.364912
Average total loss: 1.269733
tensor(-15.0431, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(-1.6606e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.904739
Average KL loss: 0.364883
Average total loss: 1.269623
tensor(-15.0445, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(5.4249e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.904738
Average KL loss: 0.364851
Average total loss: 1.269589
tensor(-15.0460, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(8.2765e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.904546
Average KL loss: 0.364827
Average total loss: 1.269373
tensor(-15.0474, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(-2.5569e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.905068
Average KL loss: 0.364781
Average total loss: 1.269849
tensor(-15.0488, device='cuda:0') tensor(0.1655, device='cuda:0') tensor(6.8957e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.905558
Average KL loss: 0.364699
Average total loss: 1.270256
tensor(-15.0502, device='cuda:0') tensor(0.1655, device='cuda:0') tensor(6.6002e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.903619
Average KL loss: 0.364637
Average total loss: 1.268256
tensor(-15.0516, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(1.8262e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.903513
Average KL loss: 0.364591
Average total loss: 1.268104
tensor(-15.0530, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(-1.0498e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.904663
Average KL loss: 0.364576
Average total loss: 1.269240
tensor(-15.0544, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(8.6411e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.905632
Average KL loss: 0.364556
Average total loss: 1.270188
tensor(-15.0558, device='cuda:0') tensor(0.1657, device='cuda:0') tensor(-1.6187e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.904119
Average KL loss: 0.364537
Average total loss: 1.268656
tensor(-15.0572, device='cuda:0') tensor(0.1657, device='cuda:0') tensor(-8.7263e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.904091
Average KL loss: 0.364538
Average total loss: 1.268629
tensor(-15.0586, device='cuda:0') tensor(0.1658, device='cuda:0') tensor(1.2489e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.907046
Average KL loss: 0.364509
Average total loss: 1.271556
tensor(-15.0600, device='cuda:0') tensor(0.1658, device='cuda:0') tensor(2.1730e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.904976
Average KL loss: 0.364506
Average total loss: 1.269482
tensor(-15.0614, device='cuda:0') tensor(0.1659, device='cuda:0') tensor(3.7422e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.905192
Average KL loss: 0.364490
Average total loss: 1.269682
tensor(-15.0628, device='cuda:0') tensor(0.1659, device='cuda:0') tensor(-9.9573e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.903171
Average KL loss: 0.364475
Average total loss: 1.267646
tensor(-15.0642, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(6.5136e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.903640
Average KL loss: 0.364455
Average total loss: 1.268095
tensor(-15.0656, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(2.1784e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.904152
Average KL loss: 0.364417
Average total loss: 1.268570
tensor(-15.0670, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(9.4356e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.903614
Average KL loss: 0.364360
Average total loss: 1.267974
tensor(-15.0684, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(1.7140e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.903394
Average KL loss: 0.364342
Average total loss: 1.267736
tensor(-15.0698, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-6.6425e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.904157
Average KL loss: 0.364318
Average total loss: 1.268475
tensor(-15.0711, device='cuda:0') tensor(0.1662, device='cuda:0') tensor(-7.5277e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.904093
Average KL loss: 0.364275
Average total loss: 1.268367
tensor(-15.0725, device='cuda:0') tensor(0.1662, device='cuda:0') tensor(-2.3256e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.903227
Average KL loss: 0.364238
Average total loss: 1.267465
tensor(-15.0739, device='cuda:0') tensor(0.1662, device='cuda:0') tensor(-1.8755e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.902542
Average KL loss: 0.364198
Average total loss: 1.266740
tensor(-15.0753, device='cuda:0') tensor(0.1663, device='cuda:0') tensor(-1.1624e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.903573
Average KL loss: 0.364164
Average total loss: 1.267738
tensor(-15.0767, device='cuda:0') tensor(0.1663, device='cuda:0') tensor(5.1694e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.904718
Average KL loss: 0.364152
Average total loss: 1.268870
tensor(-15.0781, device='cuda:0') tensor(0.1664, device='cuda:0') tensor(-2.4437e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.904277
Average KL loss: 0.364129
Average total loss: 1.268407
tensor(-15.0795, device='cuda:0') tensor(0.1664, device='cuda:0') tensor(-1.2729e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.903261
Average KL loss: 0.364109
Average total loss: 1.267370
tensor(-15.0808, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(9.5624e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.903634
Average KL loss: 0.364122
Average total loss: 1.267755
tensor(-15.0822, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-1.9389e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.901286
Average KL loss: 0.364098
Average total loss: 1.265385
tensor(-15.0836, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-2.2397e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.904622
Average KL loss: 0.364056
Average total loss: 1.268678
tensor(-15.0849, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-3.7094e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.904264
Average KL loss: 0.364067
Average total loss: 1.268331
tensor(-15.0863, device='cuda:0') tensor(0.1667, device='cuda:0') tensor(-2.4313e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.902187
Average KL loss: 0.364051
Average total loss: 1.266238
tensor(-15.0876, device='cuda:0') tensor(0.1667, device='cuda:0') tensor(4.0340e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.903173
Average KL loss: 0.364034
Average total loss: 1.267207
 Percentile value: -14.838934898376465
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =    1612 /    1728             ( 93.29%) | total_pruned =     116 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   15952 /   36864             ( 43.27%) | total_pruned =   20912 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   15482 /   36864             ( 42.00%) | total_pruned =   21382 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   11489 /   36864             ( 31.17%) | total_pruned =   25375 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9859 /   36864             ( 26.74%) | total_pruned =   27005 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   24352 /   73728             ( 33.03%) | total_pruned =   49376 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   27029 /  147456             ( 18.33%) | total_pruned =  120427 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5016 /    8192             ( 61.23%) | total_pruned =    3176 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   17226 /  147456             ( 11.68%) | total_pruned =  130230 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   12535 /  147456             (  8.50%) | total_pruned =  134921 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   25771 /  294912             (  8.74%) | total_pruned =  269141 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   20258 /  589824             (  3.43%) | total_pruned =  569566 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      81 /     256             ( 31.64%) | total_pruned =     175 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6202 /   32768             ( 18.93%) | total_pruned =   26566 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6232 /  589824             (  1.06%) | total_pruned =  583592 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4333 /  589824             (  0.73%) | total_pruned =  585491 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     111 /     256             ( 43.36%) | total_pruned =     145 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   15670 / 1179648             (  1.33%) | total_pruned = 1163978 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      82 /     512             ( 16.02%) | total_pruned =     430 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   26469 / 2359296             (  1.12%) | total_pruned = 2332827 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     480 /     512             ( 93.75%) | total_pruned =      32 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   12985 /  131072             (  9.91%) | total_pruned =  118087 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   32296 / 2359296             (  1.37%) | total_pruned = 2327000 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     481 /     512             ( 93.95%) | total_pruned =      31 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   46834 / 2359296             (  1.99%) | total_pruned = 2312462 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     312 /     512             ( 60.94%) | total_pruned =     200 | shape = torch.Size([512])
linear.weight        | nonzeros =    4459 /    5120             ( 87.09%) | total_pruned =     661 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       8 /      10             ( 80.00%) | total_pruned =       2 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 38/100 Loss: 0.000557 Accuracy: 84.11 100.00 % Best test Accuracy: 84.12%
tensor(-15.0890, device='cuda:0') tensor(0.1668, device='cuda:0') tensor(-2.1355e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.027925
Average KL loss: 0.363492
Average total loss: 1.391417
tensor(-15.0905, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(-2.4453e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.028532
Average KL loss: 0.362846
Average total loss: 1.391378
tensor(-15.0920, device='cuda:0') tensor(0.1569, device='cuda:0') tensor(-6.7424e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.028195
Average KL loss: 0.362348
Average total loss: 1.390543
tensor(-15.0935, device='cuda:0') tensor(0.1539, device='cuda:0') tensor(3.6791e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.028567
Average KL loss: 0.361866
Average total loss: 1.390433
tensor(-15.0949, device='cuda:0') tensor(0.1520, device='cuda:0') tensor(-2.0164e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.035366
Average KL loss: 0.361480
Average total loss: 1.396846
tensor(-15.0963, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(8.6693e-12, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.029040
Average KL loss: 0.361158
Average total loss: 1.390197
tensor(-15.0976, device='cuda:0') tensor(0.1504, device='cuda:0') tensor(4.5603e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.025719
Average KL loss: 0.360879
Average total loss: 1.386598
tensor(-15.0990, device='cuda:0') tensor(0.1501, device='cuda:0') tensor(-2.3078e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.020993
Average KL loss: 0.360634
Average total loss: 1.381627
tensor(-15.1004, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-1.9006e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.017658
Average KL loss: 0.360385
Average total loss: 1.378043
tensor(-15.1017, device='cuda:0') tensor(0.1496, device='cuda:0') tensor(5.7818e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.016901
Average KL loss: 0.360169
Average total loss: 1.377070
tensor(-15.1031, device='cuda:0') tensor(0.1495, device='cuda:0') tensor(9.1243e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.013852
Average KL loss: 0.359958
Average total loss: 1.373809
tensor(-15.1044, device='cuda:0') tensor(0.1493, device='cuda:0') tensor(-1.1807e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.010532
Average KL loss: 0.359752
Average total loss: 1.370284
tensor(-15.1058, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(-8.7611e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.008651
Average KL loss: 0.359576
Average total loss: 1.368227
tensor(-15.1071, device='cuda:0') tensor(0.1491, device='cuda:0') tensor(-3.9520e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.005091
Average KL loss: 0.359438
Average total loss: 1.364529
tensor(-15.1085, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(-5.1147e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.002689
Average KL loss: 0.359292
Average total loss: 1.361981
tensor(-15.1098, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(3.3448e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.999837
Average KL loss: 0.359133
Average total loss: 1.358971
tensor(-15.1112, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(1.1813e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.998769
Average KL loss: 0.359008
Average total loss: 1.357776
tensor(-15.1125, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(-1.9578e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.992439
Average KL loss: 0.358867
Average total loss: 1.351306
tensor(-15.1139, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(-1.1181e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.995109
Average KL loss: 0.358731
Average total loss: 1.353840
tensor(-15.1152, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(-8.8013e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.991780
Average KL loss: 0.358589
Average total loss: 1.350369
tensor(-15.1165, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(6.2018e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.986670
Average KL loss: 0.358416
Average total loss: 1.345086
tensor(-15.1179, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(-2.5042e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.987423
Average KL loss: 0.358276
Average total loss: 1.345698
tensor(-15.1192, device='cuda:0') tensor(0.1487, device='cuda:0') tensor(1.0826e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.986076
Average KL loss: 0.358111
Average total loss: 1.344187
tensor(-15.1205, device='cuda:0') tensor(0.1487, device='cuda:0') tensor(3.3945e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.985516
Average KL loss: 0.357952
Average total loss: 1.343468
tensor(-15.1219, device='cuda:0') tensor(0.1487, device='cuda:0') tensor(2.0978e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.982131
Average KL loss: 0.357770
Average total loss: 1.339902
tensor(-15.1232, device='cuda:0') tensor(0.1487, device='cuda:0') tensor(5.1180e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.982732
Average KL loss: 0.357638
Average total loss: 1.340369
tensor(-15.1245, device='cuda:0') tensor(0.1487, device='cuda:0') tensor(9.8330e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.982300
Average KL loss: 0.357487
Average total loss: 1.339787
tensor(-15.1258, device='cuda:0') tensor(0.1487, device='cuda:0') tensor(2.9352e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.980015
Average KL loss: 0.357347
Average total loss: 1.337362
tensor(-15.1271, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(-5.3914e-11, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.977721
Average KL loss: 0.357238
Average total loss: 1.334959
tensor(-15.1284, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(6.7046e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.978032
Average KL loss: 0.357117
Average total loss: 1.335149
tensor(-15.1297, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(-5.9428e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.974588
Average KL loss: 0.357014
Average total loss: 1.331601
tensor(-15.1310, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(-1.3208e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.976928
Average KL loss: 0.356904
Average total loss: 1.333832
tensor(-15.1323, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(2.5180e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.970807
Average KL loss: 0.356777
Average total loss: 1.327584
tensor(-15.1336, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(-3.7070e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.973108
Average KL loss: 0.356710
Average total loss: 1.329818
tensor(-15.1349, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(8.6997e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.967410
Average KL loss: 0.356625
Average total loss: 1.324035
tensor(-15.1362, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(-8.1384e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.971089
Average KL loss: 0.356502
Average total loss: 1.327591
tensor(-15.1375, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(-2.3659e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.968714
Average KL loss: 0.356408
Average total loss: 1.325122
tensor(-15.1388, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(1.4042e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.966442
Average KL loss: 0.356300
Average total loss: 1.322743
tensor(-15.1401, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(-9.9089e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.965839
Average KL loss: 0.356201
Average total loss: 1.322040
tensor(-15.1414, device='cuda:0') tensor(0.1491, device='cuda:0') tensor(-3.5199e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.967253
Average KL loss: 0.356118
Average total loss: 1.323370
tensor(-15.1427, device='cuda:0') tensor(0.1491, device='cuda:0') tensor(-1.4381e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.967586
Average KL loss: 0.356067
Average total loss: 1.323652
tensor(-15.1440, device='cuda:0') tensor(0.1491, device='cuda:0') tensor(-3.2320e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.963021
Average KL loss: 0.356004
Average total loss: 1.319025
tensor(-15.1453, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(-8.9215e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.960897
Average KL loss: 0.355908
Average total loss: 1.316805
tensor(-15.1466, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(-2.2010e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.958542
Average KL loss: 0.355827
Average total loss: 1.314370
tensor(-15.1479, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(1.9030e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.958513
Average KL loss: 0.355729
Average total loss: 1.314242
tensor(-15.1492, device='cuda:0') tensor(0.1493, device='cuda:0') tensor(-2.6232e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.962206
Average KL loss: 0.355630
Average total loss: 1.317836
tensor(-15.1504, device='cuda:0') tensor(0.1493, device='cuda:0') tensor(-1.5942e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.958571
Average KL loss: 0.355560
Average total loss: 1.314131
tensor(-15.1517, device='cuda:0') tensor(0.1494, device='cuda:0') tensor(-1.3713e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.958632
Average KL loss: 0.355498
Average total loss: 1.314131
tensor(-15.1530, device='cuda:0') tensor(0.1494, device='cuda:0') tensor(-1.6224e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.956120
Average KL loss: 0.355411
Average total loss: 1.311532
tensor(-15.1543, device='cuda:0') tensor(0.1494, device='cuda:0') tensor(-2.2283e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.958040
Average KL loss: 0.355313
Average total loss: 1.313353
tensor(-15.1556, device='cuda:0') tensor(0.1495, device='cuda:0') tensor(-8.4640e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.953133
Average KL loss: 0.355211
Average total loss: 1.308344
tensor(-15.1569, device='cuda:0') tensor(0.1495, device='cuda:0') tensor(-3.0097e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.959240
Average KL loss: 0.355119
Average total loss: 1.314359
tensor(-15.1581, device='cuda:0') tensor(0.1495, device='cuda:0') tensor(-3.5559e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.956740
Average KL loss: 0.355004
Average total loss: 1.311744
tensor(-15.1594, device='cuda:0') tensor(0.1496, device='cuda:0') tensor(3.4952e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.950592
Average KL loss: 0.354908
Average total loss: 1.305500
tensor(-15.1607, device='cuda:0') tensor(0.1496, device='cuda:0') tensor(-8.5643e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.954112
Average KL loss: 0.354829
Average total loss: 1.308941
tensor(-15.1619, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(1.7369e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.953411
Average KL loss: 0.354792
Average total loss: 1.308203
tensor(-15.1632, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(1.1880e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.949963
Average KL loss: 0.354763
Average total loss: 1.304726
tensor(-15.1645, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-1.0913e-11, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.951672
Average KL loss: 0.354694
Average total loss: 1.306366
tensor(-15.1657, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-1.2716e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.951961
Average KL loss: 0.354611
Average total loss: 1.306572
tensor(-15.1670, device='cuda:0') tensor(0.1499, device='cuda:0') tensor(-1.0129e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.953049
Average KL loss: 0.354578
Average total loss: 1.307626
tensor(-15.1682, device='cuda:0') tensor(0.1499, device='cuda:0') tensor(1.1954e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.949472
Average KL loss: 0.354521
Average total loss: 1.303994
tensor(-15.1695, device='cuda:0') tensor(0.1500, device='cuda:0') tensor(1.8579e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.950788
Average KL loss: 0.354457
Average total loss: 1.305244
tensor(-15.1707, device='cuda:0') tensor(0.1500, device='cuda:0') tensor(-1.4505e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.948232
Average KL loss: 0.354404
Average total loss: 1.302636
tensor(-15.1720, device='cuda:0') tensor(0.1501, device='cuda:0') tensor(-2.0025e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.947841
Average KL loss: 0.354377
Average total loss: 1.302218
tensor(-15.1732, device='cuda:0') tensor(0.1501, device='cuda:0') tensor(6.0666e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.947975
Average KL loss: 0.354340
Average total loss: 1.302315
tensor(-15.1745, device='cuda:0') tensor(0.1502, device='cuda:0') tensor(1.0961e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.949294
Average KL loss: 0.354262
Average total loss: 1.303555
tensor(-15.1757, device='cuda:0') tensor(0.1502, device='cuda:0') tensor(5.6753e-11, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.944669
Average KL loss: 0.354211
Average total loss: 1.298880
tensor(-15.1770, device='cuda:0') tensor(0.1503, device='cuda:0') tensor(3.2244e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.946251
Average KL loss: 0.354205
Average total loss: 1.300456
tensor(-15.1782, device='cuda:0') tensor(0.1504, device='cuda:0') tensor(-1.1940e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.948528
Average KL loss: 0.354158
Average total loss: 1.302686
tensor(-15.1795, device='cuda:0') tensor(0.1504, device='cuda:0') tensor(-5.1848e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.949408
Average KL loss: 0.354100
Average total loss: 1.303508
tensor(-15.1807, device='cuda:0') tensor(0.1505, device='cuda:0') tensor(3.9013e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.943613
Average KL loss: 0.354059
Average total loss: 1.297673
tensor(-15.1819, device='cuda:0') tensor(0.1505, device='cuda:0') tensor(5.6305e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.942531
Average KL loss: 0.354008
Average total loss: 1.296539
tensor(-15.1832, device='cuda:0') tensor(0.1506, device='cuda:0') tensor(1.4593e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.944719
Average KL loss: 0.353943
Average total loss: 1.298662
tensor(-15.1844, device='cuda:0') tensor(0.1506, device='cuda:0') tensor(-7.6229e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.943665
Average KL loss: 0.353901
Average total loss: 1.297566
tensor(-15.1857, device='cuda:0') tensor(0.1507, device='cuda:0') tensor(1.8737e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.942163
Average KL loss: 0.353847
Average total loss: 1.296010
tensor(-15.1869, device='cuda:0') tensor(0.1507, device='cuda:0') tensor(3.7272e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.942659
Average KL loss: 0.353807
Average total loss: 1.296466
tensor(-15.1881, device='cuda:0') tensor(0.1508, device='cuda:0') tensor(-1.4312e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.942312
Average KL loss: 0.353796
Average total loss: 1.296107
tensor(-15.1894, device='cuda:0') tensor(0.1508, device='cuda:0') tensor(-1.1771e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.941141
Average KL loss: 0.353742
Average total loss: 1.294883
tensor(-15.1906, device='cuda:0') tensor(0.1509, device='cuda:0') tensor(-7.8476e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.942426
Average KL loss: 0.353666
Average total loss: 1.296091
tensor(-15.1918, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(5.7276e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.941444
Average KL loss: 0.353584
Average total loss: 1.295029
tensor(-15.1931, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(-2.6927e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.942511
Average KL loss: 0.353525
Average total loss: 1.296036
tensor(-15.1943, device='cuda:0') tensor(0.1511, device='cuda:0') tensor(-1.7332e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.940324
Average KL loss: 0.353480
Average total loss: 1.293804
tensor(-15.1956, device='cuda:0') tensor(0.1511, device='cuda:0') tensor(-3.2061e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.938679
Average KL loss: 0.353430
Average total loss: 1.292109
tensor(-15.1968, device='cuda:0') tensor(0.1511, device='cuda:0') tensor(-7.4547e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.938071
Average KL loss: 0.353408
Average total loss: 1.291479
tensor(-15.1980, device='cuda:0') tensor(0.1512, device='cuda:0') tensor(8.6359e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.942865
Average KL loss: 0.353353
Average total loss: 1.296217
tensor(-15.1992, device='cuda:0') tensor(0.1513, device='cuda:0') tensor(-1.5127e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.937241
Average KL loss: 0.353324
Average total loss: 1.290565
tensor(-15.2004, device='cuda:0') tensor(0.1513, device='cuda:0') tensor(7.4762e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.937916
Average KL loss: 0.353267
Average total loss: 1.291184
tensor(-15.2016, device='cuda:0') tensor(0.1514, device='cuda:0') tensor(4.3752e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.937685
Average KL loss: 0.353209
Average total loss: 1.290894
tensor(-15.2029, device='cuda:0') tensor(0.1514, device='cuda:0') tensor(4.1449e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.939360
Average KL loss: 0.353172
Average total loss: 1.292532
tensor(-15.2041, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(-1.3131e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.941040
Average KL loss: 0.353127
Average total loss: 1.294166
tensor(-15.2053, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(-1.5050e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.937292
Average KL loss: 0.353072
Average total loss: 1.290363
tensor(-15.2065, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-4.6268e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.938806
Average KL loss: 0.353023
Average total loss: 1.291829
tensor(-15.2077, device='cuda:0') tensor(0.1517, device='cuda:0') tensor(-2.3487e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.938687
Average KL loss: 0.352967
Average total loss: 1.291654
tensor(-15.2089, device='cuda:0') tensor(0.1517, device='cuda:0') tensor(1.4859e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.938229
Average KL loss: 0.352885
Average total loss: 1.291114
tensor(-15.2101, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(3.2785e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.939406
Average KL loss: 0.352832
Average total loss: 1.292239
tensor(-15.2113, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(-4.3550e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.936721
Average KL loss: 0.352798
Average total loss: 1.289519
tensor(-15.2125, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-3.6717e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.937070
Average KL loss: 0.352752
Average total loss: 1.289822
tensor(-15.2137, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-2.5294e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.935141
Average KL loss: 0.352707
Average total loss: 1.287848
tensor(-15.2149, device='cuda:0') tensor(0.1520, device='cuda:0') tensor(7.3000e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.939059
Average KL loss: 0.352657
Average total loss: 1.291716
tensor(-15.2161, device='cuda:0') tensor(0.1520, device='cuda:0') tensor(-7.4616e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.936421
Average KL loss: 0.352604
Average total loss: 1.289025
tensor(-15.2173, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(-7.2362e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.938000
Average KL loss: 0.352549
Average total loss: 1.290550
tensor(-15.2185, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(-5.3423e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.936437
Average KL loss: 0.352480
Average total loss: 1.288918
tensor(-15.2197, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(-2.6579e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.936034
Average KL loss: 0.352430
Average total loss: 1.288465
tensor(-15.2208, device='cuda:0') tensor(0.1522, device='cuda:0') tensor(-1.0240e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.938658
Average KL loss: 0.352386
Average total loss: 1.291044
tensor(-15.2220, device='cuda:0') tensor(0.1522, device='cuda:0') tensor(-1.4629e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.933553
Average KL loss: 0.352345
Average total loss: 1.285898
tensor(-15.2232, device='cuda:0') tensor(0.1523, device='cuda:0') tensor(-7.7541e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.936524
Average KL loss: 0.352287
Average total loss: 1.288811
tensor(-15.2244, device='cuda:0') tensor(0.1523, device='cuda:0') tensor(-1.4117e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.936361
Average KL loss: 0.352253
Average total loss: 1.288614
tensor(-15.2256, device='cuda:0') tensor(0.1524, device='cuda:0') tensor(-2.7164e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.936020
Average KL loss: 0.352230
Average total loss: 1.288250
tensor(-15.2268, device='cuda:0') tensor(0.1525, device='cuda:0') tensor(7.1597e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.934993
Average KL loss: 0.352192
Average total loss: 1.287185
tensor(-15.2280, device='cuda:0') tensor(0.1525, device='cuda:0') tensor(1.9442e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.935883
Average KL loss: 0.352147
Average total loss: 1.288030
tensor(-15.2292, device='cuda:0') tensor(0.1526, device='cuda:0') tensor(2.8847e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.934554
Average KL loss: 0.352108
Average total loss: 1.286663
tensor(-15.2304, device='cuda:0') tensor(0.1526, device='cuda:0') tensor(-6.4436e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.931983
Average KL loss: 0.352078
Average total loss: 1.284061
tensor(-15.2316, device='cuda:0') tensor(0.1527, device='cuda:0') tensor(-4.2289e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.934390
Average KL loss: 0.352042
Average total loss: 1.286432
tensor(-15.2327, device='cuda:0') tensor(0.1528, device='cuda:0') tensor(-1.2834e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.936236
Average KL loss: 0.352036
Average total loss: 1.288273
tensor(-15.2339, device='cuda:0') tensor(0.1528, device='cuda:0') tensor(1.3799e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.934034
Average KL loss: 0.351993
Average total loss: 1.286027
tensor(-15.2351, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(-2.2178e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.932984
Average KL loss: 0.351934
Average total loss: 1.284917
tensor(-15.2363, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(-7.8463e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.934499
Average KL loss: 0.351886
Average total loss: 1.286384
tensor(-15.2375, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(3.2377e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.933472
Average KL loss: 0.351833
Average total loss: 1.285305
tensor(-15.2387, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(5.5573e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.931396
Average KL loss: 0.351789
Average total loss: 1.283185
tensor(-15.2398, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(6.2776e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.933063
Average KL loss: 0.351756
Average total loss: 1.284819
tensor(-15.2410, device='cuda:0') tensor(0.1531, device='cuda:0') tensor(-2.1515e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.931369
Average KL loss: 0.351701
Average total loss: 1.283070
tensor(-15.2422, device='cuda:0') tensor(0.1532, device='cuda:0') tensor(2.5355e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.929475
Average KL loss: 0.351625
Average total loss: 1.281099
tensor(-15.2433, device='cuda:0') tensor(0.1532, device='cuda:0') tensor(-8.1574e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.933094
Average KL loss: 0.351547
Average total loss: 1.284641
tensor(-15.2445, device='cuda:0') tensor(0.1532, device='cuda:0') tensor(-1.9222e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.931133
Average KL loss: 0.351494
Average total loss: 1.282627
tensor(-15.2456, device='cuda:0') tensor(0.1533, device='cuda:0') tensor(6.3295e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.931182
Average KL loss: 0.351435
Average total loss: 1.282617
tensor(-15.2468, device='cuda:0') tensor(0.1533, device='cuda:0') tensor(5.0473e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.930902
Average KL loss: 0.351374
Average total loss: 1.282276
tensor(-15.2479, device='cuda:0') tensor(0.1534, device='cuda:0') tensor(3.2939e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.933498
Average KL loss: 0.351325
Average total loss: 1.284823
tensor(-15.2491, device='cuda:0') tensor(0.1534, device='cuda:0') tensor(-4.1284e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.928980
Average KL loss: 0.351266
Average total loss: 1.280246
tensor(-15.2503, device='cuda:0') tensor(0.1535, device='cuda:0') tensor(-4.0884e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.930257
Average KL loss: 0.351220
Average total loss: 1.281477
tensor(-15.2514, device='cuda:0') tensor(0.1535, device='cuda:0') tensor(-1.0125e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.928705
Average KL loss: 0.351151
Average total loss: 1.279856
tensor(-15.2526, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(1.0120e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.929657
Average KL loss: 0.351078
Average total loss: 1.280736
tensor(-15.2537, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(-7.2445e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.931381
Average KL loss: 0.351005
Average total loss: 1.282386
tensor(-15.2548, device='cuda:0') tensor(0.1537, device='cuda:0') tensor(-1.2628e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.931032
Average KL loss: 0.350936
Average total loss: 1.281969
tensor(-15.2560, device='cuda:0') tensor(0.1537, device='cuda:0') tensor(-8.2842e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.930803
Average KL loss: 0.350893
Average total loss: 1.281696
tensor(-15.2571, device='cuda:0') tensor(0.1538, device='cuda:0') tensor(-1.3030e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.929145
Average KL loss: 0.350883
Average total loss: 1.280028
tensor(-15.2583, device='cuda:0') tensor(0.1538, device='cuda:0') tensor(-5.5756e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.927626
Average KL loss: 0.350841
Average total loss: 1.278467
tensor(-15.2594, device='cuda:0') tensor(0.1539, device='cuda:0') tensor(-4.6575e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.929670
Average KL loss: 0.350810
Average total loss: 1.280480
tensor(-15.2606, device='cuda:0') tensor(0.1539, device='cuda:0') tensor(5.4533e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.928622
Average KL loss: 0.350779
Average total loss: 1.279401
tensor(-15.2617, device='cuda:0') tensor(0.1540, device='cuda:0') tensor(-1.0293e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.928676
Average KL loss: 0.350743
Average total loss: 1.279419
tensor(-15.2629, device='cuda:0') tensor(0.1540, device='cuda:0') tensor(1.1858e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.930231
Average KL loss: 0.350698
Average total loss: 1.280929
tensor(-15.2640, device='cuda:0') tensor(0.1541, device='cuda:0') tensor(-6.7925e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.930576
Average KL loss: 0.350653
Average total loss: 1.281229
tensor(-15.2651, device='cuda:0') tensor(0.1541, device='cuda:0') tensor(-6.3805e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.927444
Average KL loss: 0.350599
Average total loss: 1.278043
tensor(-15.2663, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(2.9520e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.927299
Average KL loss: 0.350573
Average total loss: 1.277871
tensor(-15.2674, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(-1.9348e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.926722
Average KL loss: 0.350524
Average total loss: 1.277246
tensor(-15.2686, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(3.9463e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.926928
Average KL loss: 0.350464
Average total loss: 1.277392
tensor(-15.2697, device='cuda:0') tensor(0.1543, device='cuda:0') tensor(-2.4531e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.926367
Average KL loss: 0.350440
Average total loss: 1.276807
tensor(-15.2708, device='cuda:0') tensor(0.1543, device='cuda:0') tensor(-1.4812e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.927567
Average KL loss: 0.350403
Average total loss: 1.277971
tensor(-15.2720, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(7.5382e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.927183
Average KL loss: 0.350347
Average total loss: 1.277530
tensor(-15.2731, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(-1.9866e-11, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.929223
Average KL loss: 0.350318
Average total loss: 1.279542
tensor(-15.2743, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(7.7829e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.926511
Average KL loss: 0.350289
Average total loss: 1.276799
tensor(-15.2754, device='cuda:0') tensor(0.1546, device='cuda:0') tensor(-2.6983e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.928718
Average KL loss: 0.350238
Average total loss: 1.278955
tensor(-15.2765, device='cuda:0') tensor(0.1546, device='cuda:0') tensor(5.9763e-11, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.926680
Average KL loss: 0.350181
Average total loss: 1.276861
tensor(-15.2777, device='cuda:0') tensor(0.1546, device='cuda:0') tensor(-2.8086e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.924800
Average KL loss: 0.350137
Average total loss: 1.274937
tensor(-15.2788, device='cuda:0') tensor(0.1547, device='cuda:0') tensor(-6.4252e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.927009
Average KL loss: 0.350110
Average total loss: 1.277119
tensor(-15.2799, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(3.6973e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.927281
Average KL loss: 0.350059
Average total loss: 1.277339
tensor(-15.2811, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(-1.5693e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.924712
Average KL loss: 0.350005
Average total loss: 1.274718
tensor(-15.2822, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(-6.0342e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.926324
Average KL loss: 0.349970
Average total loss: 1.276294
tensor(-15.2833, device='cuda:0') tensor(0.1549, device='cuda:0') tensor(4.6756e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.928187
Average KL loss: 0.349936
Average total loss: 1.278124
tensor(-15.2844, device='cuda:0') tensor(0.1549, device='cuda:0') tensor(-1.5413e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.924887
Average KL loss: 0.349909
Average total loss: 1.274796
tensor(-15.2855, device='cuda:0') tensor(0.1550, device='cuda:0') tensor(4.4077e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.925311
Average KL loss: 0.349881
Average total loss: 1.275191
tensor(-15.2867, device='cuda:0') tensor(0.1551, device='cuda:0') tensor(-2.7384e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.924782
Average KL loss: 0.349828
Average total loss: 1.274609
tensor(-15.2878, device='cuda:0') tensor(0.1551, device='cuda:0') tensor(2.8513e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.923217
Average KL loss: 0.349806
Average total loss: 1.273023
tensor(-15.2889, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(-3.8698e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.924294
Average KL loss: 0.349779
Average total loss: 1.274072
tensor(-15.2900, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(-3.7418e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.923306
Average KL loss: 0.349769
Average total loss: 1.273074
tensor(-15.2911, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(1.1529e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.926600
Average KL loss: 0.349745
Average total loss: 1.276345
tensor(-15.2922, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(1.6514e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.924881
Average KL loss: 0.349731
Average total loss: 1.274612
tensor(-15.2933, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(9.1075e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.926087
Average KL loss: 0.349706
Average total loss: 1.275793
tensor(-15.2944, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-1.2829e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.922846
Average KL loss: 0.349681
Average total loss: 1.272527
tensor(-15.2955, device='cuda:0') tensor(0.1555, device='cuda:0') tensor(4.0553e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.927213
Average KL loss: 0.349647
Average total loss: 1.276860
tensor(-15.2966, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(-4.4345e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.925290
Average KL loss: 0.349629
Average total loss: 1.274918
tensor(-15.2977, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(1.2482e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.922983
Average KL loss: 0.349594
Average total loss: 1.272578
tensor(-15.2988, device='cuda:0') tensor(0.1557, device='cuda:0') tensor(3.0587e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.925578
Average KL loss: 0.349552
Average total loss: 1.275130
tensor(-15.2999, device='cuda:0') tensor(0.1557, device='cuda:0') tensor(-5.9994e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.922390
Average KL loss: 0.349510
Average total loss: 1.271900
tensor(-15.3010, device='cuda:0') tensor(0.1558, device='cuda:0') tensor(-8.0592e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.923744
Average KL loss: 0.349447
Average total loss: 1.273191
tensor(-15.3021, device='cuda:0') tensor(0.1558, device='cuda:0') tensor(-5.0075e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.921610
Average KL loss: 0.349402
Average total loss: 1.271011
tensor(-15.3032, device='cuda:0') tensor(0.1558, device='cuda:0') tensor(-3.0109e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.922907
Average KL loss: 0.349394
Average total loss: 1.272301
tensor(-15.3043, device='cuda:0') tensor(0.1559, device='cuda:0') tensor(-7.5468e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.920071
Average KL loss: 0.349361
Average total loss: 1.269433
tensor(-15.3054, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(9.8507e-11, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.922548
Average KL loss: 0.349333
Average total loss: 1.271881
tensor(-15.3065, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(-8.8387e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.920442
Average KL loss: 0.349318
Average total loss: 1.269759
tensor(-15.3075, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(-2.8347e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.922302
Average KL loss: 0.349288
Average total loss: 1.271589
tensor(-15.3086, device='cuda:0') tensor(0.1561, device='cuda:0') tensor(1.3238e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.921424
Average KL loss: 0.349257
Average total loss: 1.270680
tensor(-15.3097, device='cuda:0') tensor(0.1562, device='cuda:0') tensor(-1.5112e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.921419
Average KL loss: 0.349238
Average total loss: 1.270657
tensor(-15.3108, device='cuda:0') tensor(0.1562, device='cuda:0') tensor(-5.3310e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.920577
Average KL loss: 0.349221
Average total loss: 1.269798
tensor(-15.3119, device='cuda:0') tensor(0.1562, device='cuda:0') tensor(-5.8572e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.921732
Average KL loss: 0.349189
Average total loss: 1.270921
tensor(-15.3130, device='cuda:0') tensor(0.1563, device='cuda:0') tensor(-1.7029e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.922941
Average KL loss: 0.349119
Average total loss: 1.272060
tensor(-15.3141, device='cuda:0') tensor(0.1563, device='cuda:0') tensor(2.2937e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.921033
Average KL loss: 0.349080
Average total loss: 1.270113
tensor(-15.3152, device='cuda:0') tensor(0.1563, device='cuda:0') tensor(1.4629e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.919954
Average KL loss: 0.349055
Average total loss: 1.269009
tensor(-15.3163, device='cuda:0') tensor(0.1564, device='cuda:0') tensor(9.3883e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.921682
Average KL loss: 0.349008
Average total loss: 1.270690
tensor(-15.3174, device='cuda:0') tensor(0.1564, device='cuda:0') tensor(-6.2027e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.923026
Average KL loss: 0.348979
Average total loss: 1.272005
tensor(-15.3185, device='cuda:0') tensor(0.1565, device='cuda:0') tensor(-4.8880e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.921511
Average KL loss: 0.348963
Average total loss: 1.270474
tensor(-15.3195, device='cuda:0') tensor(0.1565, device='cuda:0') tensor(1.4372e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.922582
Average KL loss: 0.348917
Average total loss: 1.271498
tensor(-15.3206, device='cuda:0') tensor(0.1566, device='cuda:0') tensor(-5.4972e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.923669
Average KL loss: 0.348869
Average total loss: 1.272538
tensor(-15.3217, device='cuda:0') tensor(0.1566, device='cuda:0') tensor(-1.2715e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.920086
Average KL loss: 0.348821
Average total loss: 1.268907
tensor(-15.3228, device='cuda:0') tensor(0.1567, device='cuda:0') tensor(-2.3053e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.921859
Average KL loss: 0.348779
Average total loss: 1.270639
tensor(-15.3239, device='cuda:0') tensor(0.1567, device='cuda:0') tensor(-1.6342e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.920737
Average KL loss: 0.348739
Average total loss: 1.269476
tensor(-15.3250, device='cuda:0') tensor(0.1567, device='cuda:0') tensor(-1.3720e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.924275
Average KL loss: 0.348720
Average total loss: 1.272995
tensor(-15.3261, device='cuda:0') tensor(0.1568, device='cuda:0') tensor(-3.8845e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.922046
Average KL loss: 0.348677
Average total loss: 1.270724
tensor(-15.3271, device='cuda:0') tensor(0.1569, device='cuda:0') tensor(1.8190e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.922280
Average KL loss: 0.348630
Average total loss: 1.270910
tensor(-15.3282, device='cuda:0') tensor(0.1569, device='cuda:0') tensor(-3.8491e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.921367
Average KL loss: 0.348620
Average total loss: 1.269987
tensor(-15.3283, device='cuda:0') tensor(0.1569, device='cuda:0') tensor(-9.5597e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.920524
Average KL loss: 0.348616
Average total loss: 1.269140
 Percentile value: -15.083245277404785
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =    1487 /    1728             ( 86.05%) | total_pruned =     241 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    9531 /   36864             ( 25.85%) | total_pruned =   27333 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    9394 /   36864             ( 25.48%) | total_pruned =   27470 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    6961 /   36864             ( 18.88%) | total_pruned =   29903 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    5631 /   36864             ( 15.28%) | total_pruned =   31233 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   14663 /   73728             ( 19.89%) | total_pruned =   59065 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   14692 /  147456             (  9.96%) | total_pruned =  132764 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2933 /    8192             ( 35.80%) | total_pruned =    5259 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8515 /  147456             (  5.77%) | total_pruned =  138941 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    5529 /  147456             (  3.75%) | total_pruned =  141927 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   13559 /  294912             (  4.60%) | total_pruned =  281353 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    9987 /  589824             (  1.69%) | total_pruned =  579837 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     111 /     256             ( 43.36%) | total_pruned =     145 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2440 /   32768             (  7.45%) | total_pruned =   30328 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     107 /     256             ( 41.80%) | total_pruned =     149 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2751 /  589824             (  0.47%) | total_pruned =  587073 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1666 /  589824             (  0.28%) | total_pruned =  588158 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      61 /     256             ( 23.83%) | total_pruned =     195 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    6870 / 1179648             (  0.58%) | total_pruned = 1172778 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     126 /     512             ( 24.61%) | total_pruned =     386 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      34 /     512             (  6.64%) | total_pruned =     478 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   11559 / 2359296             (  0.49%) | total_pruned = 2347737 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     314 /     512             ( 61.33%) | total_pruned =     198 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     168 /     512             ( 32.81%) | total_pruned =     344 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4922 /  131072             (  3.76%) | total_pruned =  126150 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     297 /     512             ( 58.01%) | total_pruned =     215 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   13240 / 2359296             (  0.56%) | total_pruned = 2346056 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     195 /     512             ( 38.09%) | total_pruned =     317 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   22069 / 2359296             (  0.94%) | total_pruned = 2337227 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     129 /     512             ( 25.20%) | total_pruned =     383 | shape = torch.Size([512])
linear.weight        | nonzeros =    2587 /    5120             ( 50.53%) | total_pruned =    2533 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       7 /      10             ( 70.00%) | total_pruned =       3 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 48/100 Loss: 0.000207 Accuracy: 82.42 100.00 % Best test Accuracy: 82.67%
tensor(-15.3284, device='cuda:0') tensor(0.1569, device='cuda:0') tensor(-1.4761e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.102857
Average KL loss: 0.348146
Average total loss: 1.451003
tensor(-15.3296, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(2.3576e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.093869
Average KL loss: 0.347572
Average total loss: 1.441441
tensor(-15.3308, device='cuda:0') tensor(0.1480, device='cuda:0') tensor(6.0830e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.093268
Average KL loss: 0.347091
Average total loss: 1.440359
tensor(-15.3319, device='cuda:0') tensor(0.1454, device='cuda:0') tensor(2.2617e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.097216
Average KL loss: 0.346637
Average total loss: 1.443852
tensor(-15.3330, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(-1.4113e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.098764
Average KL loss: 0.346254
Average total loss: 1.445018
tensor(-15.3341, device='cuda:0') tensor(0.1427, device='cuda:0') tensor(1.1619e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.093564
Average KL loss: 0.345992
Average total loss: 1.439555
tensor(-15.3352, device='cuda:0') tensor(0.1423, device='cuda:0') tensor(-6.1341e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.087830
Average KL loss: 0.345777
Average total loss: 1.433607
tensor(-15.3362, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-4.6140e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.079939
Average KL loss: 0.345552
Average total loss: 1.425491
tensor(-15.3373, device='cuda:0') tensor(0.1419, device='cuda:0') tensor(2.4171e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.081891
Average KL loss: 0.345338
Average total loss: 1.427228
tensor(-15.3384, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(-2.7837e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.078938
Average KL loss: 0.345152
Average total loss: 1.424089
tensor(-15.3394, device='cuda:0') tensor(0.1417, device='cuda:0') tensor(7.8083e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.073805
Average KL loss: 0.344972
Average total loss: 1.418777
tensor(-15.3405, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(5.5737e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.069378
Average KL loss: 0.344798
Average total loss: 1.414176
tensor(-15.3415, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(1.4367e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.069871
Average KL loss: 0.344630
Average total loss: 1.414502
tensor(-15.3426, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(8.1118e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.071424
Average KL loss: 0.344493
Average total loss: 1.415917
tensor(-15.3436, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-2.3000e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.066616
Average KL loss: 0.344320
Average total loss: 1.410937
tensor(-15.3447, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(1.0920e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.062365
Average KL loss: 0.344143
Average total loss: 1.406507
tensor(-15.3457, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(1.7645e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.058575
Average KL loss: 0.343928
Average total loss: 1.402503
tensor(-15.3468, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-8.8824e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.061763
Average KL loss: 0.343737
Average total loss: 1.405499
tensor(-15.3478, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-1.3280e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.054371
Average KL loss: 0.343543
Average total loss: 1.397914
tensor(-15.3489, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-4.1656e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.053967
Average KL loss: 0.343374
Average total loss: 1.397341
tensor(-15.3499, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(9.9672e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.053779
Average KL loss: 0.343189
Average total loss: 1.396968
tensor(-15.3510, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(1.4022e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.050825
Average KL loss: 0.342985
Average total loss: 1.393809
tensor(-15.3520, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-5.5774e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.048499
Average KL loss: 0.342819
Average total loss: 1.391318
tensor(-15.3531, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-1.0691e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.047926
Average KL loss: 0.342672
Average total loss: 1.390598
tensor(-15.3541, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-7.3256e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.047765
Average KL loss: 0.342519
Average total loss: 1.390284
tensor(-15.3552, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-5.2452e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.037533
Average KL loss: 0.342356
Average total loss: 1.379889
tensor(-15.3562, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-3.9088e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.040845
Average KL loss: 0.342186
Average total loss: 1.383030
tensor(-15.3573, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-2.5544e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.035144
Average KL loss: 0.342027
Average total loss: 1.377172
tensor(-15.3583, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-9.9792e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.041950
Average KL loss: 0.341839
Average total loss: 1.383789
tensor(-15.3594, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-2.3408e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.035700
Average KL loss: 0.341679
Average total loss: 1.377379
tensor(-15.3604, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-2.2286e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.036351
Average KL loss: 0.341552
Average total loss: 1.377904
tensor(-15.3615, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-5.6093e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.038615
Average KL loss: 0.341364
Average total loss: 1.379979
tensor(-15.3625, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-6.0415e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.032727
Average KL loss: 0.341215
Average total loss: 1.373942
tensor(-15.3635, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(-1.5283e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.033528
Average KL loss: 0.341092
Average total loss: 1.374619
tensor(-15.3646, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(8.9465e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.030269
Average KL loss: 0.340953
Average total loss: 1.371223
tensor(-15.3656, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(-7.1222e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.030759
Average KL loss: 0.340804
Average total loss: 1.371563
tensor(-15.3667, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(8.2721e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.027229
Average KL loss: 0.340667
Average total loss: 1.367896
tensor(-15.3677, device='cuda:0') tensor(0.1417, device='cuda:0') tensor(-1.1668e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.029041
Average KL loss: 0.340562
Average total loss: 1.369603
tensor(-15.3687, device='cuda:0') tensor(0.1417, device='cuda:0') tensor(-1.5025e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.031547
Average KL loss: 0.340443
Average total loss: 1.371990
tensor(-15.3698, device='cuda:0') tensor(0.1417, device='cuda:0') tensor(-1.2891e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.020026
Average KL loss: 0.340327
Average total loss: 1.360353
tensor(-15.3708, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(-1.0594e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.022190
Average KL loss: 0.340206
Average total loss: 1.362396
tensor(-15.3719, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(6.7275e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.021051
Average KL loss: 0.340088
Average total loss: 1.361139
tensor(-15.3729, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(-3.8900e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.025341
Average KL loss: 0.339979
Average total loss: 1.365320
tensor(-15.3739, device='cuda:0') tensor(0.1419, device='cuda:0') tensor(9.1032e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.018245
Average KL loss: 0.339869
Average total loss: 1.358114
tensor(-15.3749, device='cuda:0') tensor(0.1419, device='cuda:0') tensor(-2.3889e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.018507
Average KL loss: 0.339765
Average total loss: 1.358272
tensor(-15.3760, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-2.8103e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.013627
Average KL loss: 0.339656
Average total loss: 1.353283
tensor(-15.3770, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-1.7180e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.019482
Average KL loss: 0.339516
Average total loss: 1.358998
tensor(-15.3780, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-3.3097e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.010740
Average KL loss: 0.339388
Average total loss: 1.350128
tensor(-15.3790, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-2.8950e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.016106
Average KL loss: 0.339262
Average total loss: 1.355368
tensor(-15.3800, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(3.1682e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.011339
Average KL loss: 0.339127
Average total loss: 1.350466
tensor(-15.3810, device='cuda:0') tensor(0.1422, device='cuda:0') tensor(3.6588e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.011701
Average KL loss: 0.339018
Average total loss: 1.350719
tensor(-15.3820, device='cuda:0') tensor(0.1422, device='cuda:0') tensor(-1.5255e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.012543
Average KL loss: 0.338930
Average total loss: 1.351473
tensor(-15.3830, device='cuda:0') tensor(0.1423, device='cuda:0') tensor(4.6865e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.006944
Average KL loss: 0.338817
Average total loss: 1.345760
tensor(-15.3841, device='cuda:0') tensor(0.1423, device='cuda:0') tensor(-2.3001e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.007369
Average KL loss: 0.338676
Average total loss: 1.346045
tensor(-15.3851, device='cuda:0') tensor(0.1423, device='cuda:0') tensor(-4.9884e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.010351
Average KL loss: 0.338530
Average total loss: 1.348881
tensor(-15.3861, device='cuda:0') tensor(0.1424, device='cuda:0') tensor(-5.5379e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.006306
Average KL loss: 0.338359
Average total loss: 1.344665
tensor(-15.3871, device='cuda:0') tensor(0.1424, device='cuda:0') tensor(2.7013e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.003817
Average KL loss: 0.338177
Average total loss: 1.341994
tensor(-15.3881, device='cuda:0') tensor(0.1424, device='cuda:0') tensor(-1.4669e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.006839
Average KL loss: 0.338008
Average total loss: 1.344847
tensor(-15.3891, device='cuda:0') tensor(0.1425, device='cuda:0') tensor(1.5252e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.003701
Average KL loss: 0.337868
Average total loss: 1.341569
tensor(-15.3901, device='cuda:0') tensor(0.1425, device='cuda:0') tensor(-6.8312e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.006068
Average KL loss: 0.337765
Average total loss: 1.343833
tensor(-15.3911, device='cuda:0') tensor(0.1426, device='cuda:0') tensor(-1.5725e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.002869
Average KL loss: 0.337646
Average total loss: 1.340516
tensor(-15.3921, device='cuda:0') tensor(0.1426, device='cuda:0') tensor(-1.8263e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.001552
Average KL loss: 0.337540
Average total loss: 1.339092
tensor(-15.3931, device='cuda:0') tensor(0.1426, device='cuda:0') tensor(-3.0450e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.999370
Average KL loss: 0.337432
Average total loss: 1.336803
tensor(-15.3941, device='cuda:0') tensor(0.1427, device='cuda:0') tensor(-2.0633e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.004682
Average KL loss: 0.337353
Average total loss: 1.342036
tensor(-15.3951, device='cuda:0') tensor(0.1428, device='cuda:0') tensor(-2.9165e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.999184
Average KL loss: 0.337256
Average total loss: 1.336441
tensor(-15.3961, device='cuda:0') tensor(0.1428, device='cuda:0') tensor(-6.5659e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.998443
Average KL loss: 0.337167
Average total loss: 1.335610
tensor(-15.3971, device='cuda:0') tensor(0.1428, device='cuda:0') tensor(1.5841e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.998793
Average KL loss: 0.337066
Average total loss: 1.335859
tensor(-15.3981, device='cuda:0') tensor(0.1429, device='cuda:0') tensor(2.1708e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.999078
Average KL loss: 0.336949
Average total loss: 1.336027
tensor(-15.3991, device='cuda:0') tensor(0.1429, device='cuda:0') tensor(-2.2015e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.007742
Average KL loss: 0.336845
Average total loss: 1.344587
tensor(-15.4001, device='cuda:0') tensor(0.1429, device='cuda:0') tensor(-1.5911e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.994538
Average KL loss: 0.336750
Average total loss: 1.331287
tensor(-15.4011, device='cuda:0') tensor(0.1430, device='cuda:0') tensor(-3.1171e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.995932
Average KL loss: 0.336665
Average total loss: 1.332597
tensor(-15.4021, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-2.8161e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.996390
Average KL loss: 0.336593
Average total loss: 1.332983
tensor(-15.4031, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-1.3044e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.996604
Average KL loss: 0.336530
Average total loss: 1.333134
tensor(-15.4040, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-1.6959e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.993683
Average KL loss: 0.336472
Average total loss: 1.330156
tensor(-15.4050, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-4.6680e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.998358
Average KL loss: 0.336411
Average total loss: 1.334769
tensor(-15.4060, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(1.7618e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.994878
Average KL loss: 0.336324
Average total loss: 1.331202
tensor(-15.4070, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-2.7190e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.992795
Average KL loss: 0.336226
Average total loss: 1.329021
tensor(-15.4080, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-1.1894e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.994156
Average KL loss: 0.336163
Average total loss: 1.330319
tensor(-15.4090, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(9.5123e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.994403
Average KL loss: 0.336088
Average total loss: 1.330491
tensor(-15.4100, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(3.0364e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.990407
Average KL loss: 0.336006
Average total loss: 1.326413
tensor(-15.4110, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(6.8756e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.995299
Average KL loss: 0.335906
Average total loss: 1.331204
tensor(-15.4120, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(1.4581e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.990522
Average KL loss: 0.335853
Average total loss: 1.326374
tensor(-15.4130, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(-1.6705e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.995269
Average KL loss: 0.335805
Average total loss: 1.331074
tensor(-15.4140, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(1.0495e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.991966
Average KL loss: 0.335725
Average total loss: 1.327691
tensor(-15.4150, device='cuda:0') tensor(0.1438, device='cuda:0') tensor(-3.2206e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.990328
Average KL loss: 0.335642
Average total loss: 1.325970
tensor(-15.4160, device='cuda:0') tensor(0.1438, device='cuda:0') tensor(3.8854e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.993633
Average KL loss: 0.335548
Average total loss: 1.329182
tensor(-15.4170, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(9.3900e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.989938
Average KL loss: 0.335486
Average total loss: 1.325424
tensor(-15.4179, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(-1.9424e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.990917
Average KL loss: 0.335426
Average total loss: 1.326343
tensor(-15.4189, device='cuda:0') tensor(0.1440, device='cuda:0') tensor(-6.2663e-12, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.989759
Average KL loss: 0.335364
Average total loss: 1.325123
tensor(-15.4199, device='cuda:0') tensor(0.1440, device='cuda:0') tensor(-8.7588e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.987733
Average KL loss: 0.335287
Average total loss: 1.323019
tensor(-15.4209, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(-2.2302e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.988072
Average KL loss: 0.335212
Average total loss: 1.323284
tensor(-15.4219, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(-4.7059e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.986670
Average KL loss: 0.335165
Average total loss: 1.321836
tensor(-15.4229, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(-2.9721e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.989043
Average KL loss: 0.335089
Average total loss: 1.324132
tensor(-15.4238, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(9.0132e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.988500
Average KL loss: 0.335023
Average total loss: 1.323523
tensor(-15.4248, device='cuda:0') tensor(0.1443, device='cuda:0') tensor(-2.2313e-11, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.988729
Average KL loss: 0.334928
Average total loss: 1.323657
tensor(-15.4258, device='cuda:0') tensor(0.1443, device='cuda:0') tensor(-6.4082e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.988597
Average KL loss: 0.334847
Average total loss: 1.323444
tensor(-15.4267, device='cuda:0') tensor(0.1444, device='cuda:0') tensor(5.5582e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.985960
Average KL loss: 0.334763
Average total loss: 1.320724
tensor(-15.4277, device='cuda:0') tensor(0.1444, device='cuda:0') tensor(-1.0863e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.984947
Average KL loss: 0.334691
Average total loss: 1.319638
tensor(-15.4287, device='cuda:0') tensor(0.1444, device='cuda:0') tensor(-3.5224e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.984313
Average KL loss: 0.334617
Average total loss: 1.318930
tensor(-15.4296, device='cuda:0') tensor(0.1445, device='cuda:0') tensor(-2.3745e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.982597
Average KL loss: 0.334534
Average total loss: 1.317132
tensor(-15.4306, device='cuda:0') tensor(0.1445, device='cuda:0') tensor(-5.2843e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.984394
Average KL loss: 0.334440
Average total loss: 1.318834
tensor(-15.4315, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(-4.3196e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.983010
Average KL loss: 0.334360
Average total loss: 1.317370
tensor(-15.4325, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(4.3814e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.982954
Average KL loss: 0.334293
Average total loss: 1.317247
tensor(-15.4335, device='cuda:0') tensor(0.1447, device='cuda:0') tensor(1.2302e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.986037
Average KL loss: 0.334218
Average total loss: 1.320255
tensor(-15.4344, device='cuda:0') tensor(0.1447, device='cuda:0') tensor(-2.5004e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.984331
Average KL loss: 0.334163
Average total loss: 1.318494
tensor(-15.4354, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(-8.3065e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.983627
Average KL loss: 0.334102
Average total loss: 1.317729
tensor(-15.4363, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(7.0773e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.985172
Average KL loss: 0.334012
Average total loss: 1.319184
tensor(-15.4373, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(-4.2553e-11, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.985443
Average KL loss: 0.333935
Average total loss: 1.319378
tensor(-15.4382, device='cuda:0') tensor(0.1449, device='cuda:0') tensor(3.8156e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.980412
Average KL loss: 0.333896
Average total loss: 1.314307
tensor(-15.4392, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-6.2572e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.977350
Average KL loss: 0.333849
Average total loss: 1.311200
tensor(-15.4401, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-9.0367e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.978821
Average KL loss: 0.333772
Average total loss: 1.312593
tensor(-15.4411, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-2.5313e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.979267
Average KL loss: 0.333697
Average total loss: 1.312964
tensor(-15.4420, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(-8.0048e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.980143
Average KL loss: 0.333652
Average total loss: 1.313794
tensor(-15.4430, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(-6.7050e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.979154
Average KL loss: 0.333608
Average total loss: 1.312762
tensor(-15.4439, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-8.9983e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.977929
Average KL loss: 0.333577
Average total loss: 1.311506
tensor(-15.4449, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(3.8003e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.979488
Average KL loss: 0.333526
Average total loss: 1.313013
tensor(-15.4458, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(-2.4343e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.978812
Average KL loss: 0.333515
Average total loss: 1.312327
tensor(-15.4468, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(4.3777e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.978141
Average KL loss: 0.333507
Average total loss: 1.311648
tensor(-15.4477, device='cuda:0') tensor(0.1454, device='cuda:0') tensor(-9.3925e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.979673
Average KL loss: 0.333492
Average total loss: 1.313165
tensor(-15.4487, device='cuda:0') tensor(0.1455, device='cuda:0') tensor(-1.0170e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.977783
Average KL loss: 0.333446
Average total loss: 1.311230
tensor(-15.4496, device='cuda:0') tensor(0.1455, device='cuda:0') tensor(3.2424e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.977340
Average KL loss: 0.333412
Average total loss: 1.310753
tensor(-15.4506, device='cuda:0') tensor(0.1456, device='cuda:0') tensor(-1.5035e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.977843
Average KL loss: 0.333370
Average total loss: 1.311213
tensor(-15.4515, device='cuda:0') tensor(0.1456, device='cuda:0') tensor(2.2431e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.976414
Average KL loss: 0.333297
Average total loss: 1.309711
tensor(-15.4525, device='cuda:0') tensor(0.1457, device='cuda:0') tensor(-2.2627e-11, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.977821
Average KL loss: 0.333250
Average total loss: 1.311070
tensor(-15.4534, device='cuda:0') tensor(0.1457, device='cuda:0') tensor(-7.6637e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.977375
Average KL loss: 0.333227
Average total loss: 1.310602
tensor(-15.4544, device='cuda:0') tensor(0.1458, device='cuda:0') tensor(-2.5793e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.977360
Average KL loss: 0.333170
Average total loss: 1.310530
tensor(-15.4553, device='cuda:0') tensor(0.1458, device='cuda:0') tensor(-1.4820e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.976869
Average KL loss: 0.333115
Average total loss: 1.309983
tensor(-15.4563, device='cuda:0') tensor(0.1459, device='cuda:0') tensor(5.3516e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.976913
Average KL loss: 0.333061
Average total loss: 1.309974
tensor(-15.4572, device='cuda:0') tensor(0.1460, device='cuda:0') tensor(7.1276e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.971423
Average KL loss: 0.333008
Average total loss: 1.304432
tensor(-15.4581, device='cuda:0') tensor(0.1460, device='cuda:0') tensor(9.5064e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.974026
Average KL loss: 0.332972
Average total loss: 1.306999
tensor(-15.4591, device='cuda:0') tensor(0.1461, device='cuda:0') tensor(-1.8583e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.973153
Average KL loss: 0.332956
Average total loss: 1.306109
tensor(-15.4600, device='cuda:0') tensor(0.1461, device='cuda:0') tensor(9.1021e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.973582
Average KL loss: 0.332936
Average total loss: 1.306518
tensor(-15.4610, device='cuda:0') tensor(0.1462, device='cuda:0') tensor(-1.4577e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.972163
Average KL loss: 0.332871
Average total loss: 1.305034
tensor(-15.4619, device='cuda:0') tensor(0.1463, device='cuda:0') tensor(1.0804e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.972117
Average KL loss: 0.332813
Average total loss: 1.304930
tensor(-15.4629, device='cuda:0') tensor(0.1463, device='cuda:0') tensor(-1.1823e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.969733
Average KL loss: 0.332773
Average total loss: 1.302506
tensor(-15.4638, device='cuda:0') tensor(0.1464, device='cuda:0') tensor(1.1272e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.973054
Average KL loss: 0.332754
Average total loss: 1.305809
tensor(-15.4647, device='cuda:0') tensor(0.1464, device='cuda:0') tensor(1.8611e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.970912
Average KL loss: 0.332712
Average total loss: 1.303623
tensor(-15.4657, device='cuda:0') tensor(0.1465, device='cuda:0') tensor(-4.8916e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.971742
Average KL loss: 0.332661
Average total loss: 1.304403
tensor(-15.4666, device='cuda:0') tensor(0.1465, device='cuda:0') tensor(2.9180e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.968709
Average KL loss: 0.332637
Average total loss: 1.301346
tensor(-15.4676, device='cuda:0') tensor(0.1466, device='cuda:0') tensor(-2.1901e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.968778
Average KL loss: 0.332628
Average total loss: 1.301405
tensor(-15.4685, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(1.0550e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.969932
Average KL loss: 0.332605
Average total loss: 1.302537
tensor(-15.4695, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-1.2724e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.969425
Average KL loss: 0.332565
Average total loss: 1.301989
tensor(-15.4704, device='cuda:0') tensor(0.1468, device='cuda:0') tensor(9.1363e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.967918
Average KL loss: 0.332503
Average total loss: 1.300421
tensor(-15.4713, device='cuda:0') tensor(0.1468, device='cuda:0') tensor(-2.0357e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.967342
Average KL loss: 0.332445
Average total loss: 1.299787
tensor(-15.4723, device='cuda:0') tensor(0.1468, device='cuda:0') tensor(-1.3477e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.968235
Average KL loss: 0.332373
Average total loss: 1.300608
tensor(-15.4732, device='cuda:0') tensor(0.1469, device='cuda:0') tensor(-3.3102e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.965759
Average KL loss: 0.332358
Average total loss: 1.298117
tensor(-15.4741, device='cuda:0') tensor(0.1469, device='cuda:0') tensor(1.5853e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.970581
Average KL loss: 0.332312
Average total loss: 1.302893
tensor(-15.4751, device='cuda:0') tensor(0.1470, device='cuda:0') tensor(-2.7958e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.967029
Average KL loss: 0.332239
Average total loss: 1.299268
tensor(-15.4760, device='cuda:0') tensor(0.1470, device='cuda:0') tensor(-2.7333e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.968172
Average KL loss: 0.332185
Average total loss: 1.300357
tensor(-15.4769, device='cuda:0') tensor(0.1471, device='cuda:0') tensor(8.8845e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.967386
Average KL loss: 0.332115
Average total loss: 1.299502
tensor(-15.4778, device='cuda:0') tensor(0.1472, device='cuda:0') tensor(-8.3975e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.965426
Average KL loss: 0.332074
Average total loss: 1.297500
tensor(-15.4787, device='cuda:0') tensor(0.1472, device='cuda:0') tensor(2.3156e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.965546
Average KL loss: 0.332019
Average total loss: 1.297565
tensor(-15.4796, device='cuda:0') tensor(0.1472, device='cuda:0') tensor(-3.6372e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.965437
Average KL loss: 0.331956
Average total loss: 1.297394
tensor(-15.4805, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(-8.6530e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.967565
Average KL loss: 0.331885
Average total loss: 1.299450
tensor(-15.4815, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(-4.0739e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.966803
Average KL loss: 0.331813
Average total loss: 1.298616
tensor(-15.4824, device='cuda:0') tensor(0.1474, device='cuda:0') tensor(6.1899e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.966518
Average KL loss: 0.331750
Average total loss: 1.298268
tensor(-15.4833, device='cuda:0') tensor(0.1474, device='cuda:0') tensor(-3.2572e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.964336
Average KL loss: 0.331692
Average total loss: 1.296027
tensor(-15.4842, device='cuda:0') tensor(0.1475, device='cuda:0') tensor(-8.2557e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.962429
Average KL loss: 0.331639
Average total loss: 1.294068
tensor(-15.4851, device='cuda:0') tensor(0.1475, device='cuda:0') tensor(-6.7035e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.966760
Average KL loss: 0.331585
Average total loss: 1.298345
tensor(-15.4860, device='cuda:0') tensor(0.1475, device='cuda:0') tensor(-6.4734e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.966746
Average KL loss: 0.331529
Average total loss: 1.298275
tensor(-15.4869, device='cuda:0') tensor(0.1476, device='cuda:0') tensor(-1.9176e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.962989
Average KL loss: 0.331458
Average total loss: 1.294447
tensor(-15.4878, device='cuda:0') tensor(0.1476, device='cuda:0') tensor(-4.8377e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.965889
Average KL loss: 0.331391
Average total loss: 1.297279
tensor(-15.4887, device='cuda:0') tensor(0.1477, device='cuda:0') tensor(7.1221e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.966502
Average KL loss: 0.331342
Average total loss: 1.297844
tensor(-15.4896, device='cuda:0') tensor(0.1477, device='cuda:0') tensor(3.8458e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.964501
Average KL loss: 0.331294
Average total loss: 1.295795
tensor(-15.4905, device='cuda:0') tensor(0.1478, device='cuda:0') tensor(-5.8872e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.963227
Average KL loss: 0.331224
Average total loss: 1.294451
tensor(-15.4914, device='cuda:0') tensor(0.1478, device='cuda:0') tensor(4.1930e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.965341
Average KL loss: 0.331129
Average total loss: 1.296470
tensor(-15.4923, device='cuda:0') tensor(0.1478, device='cuda:0') tensor(3.2501e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.963604
Average KL loss: 0.331068
Average total loss: 1.294672
tensor(-15.4932, device='cuda:0') tensor(0.1479, device='cuda:0') tensor(4.2724e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.962531
Average KL loss: 0.331008
Average total loss: 1.293539
tensor(-15.4941, device='cuda:0') tensor(0.1479, device='cuda:0') tensor(1.2711e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.964928
Average KL loss: 0.330950
Average total loss: 1.295878
tensor(-15.4950, device='cuda:0') tensor(0.1480, device='cuda:0') tensor(-1.3654e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.962346
Average KL loss: 0.330892
Average total loss: 1.293238
tensor(-15.4959, device='cuda:0') tensor(0.1480, device='cuda:0') tensor(5.5843e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.962371
Average KL loss: 0.330826
Average total loss: 1.293197
tensor(-15.4968, device='cuda:0') tensor(0.1480, device='cuda:0') tensor(2.2378e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.964408
Average KL loss: 0.330759
Average total loss: 1.295167
tensor(-15.4977, device='cuda:0') tensor(0.1481, device='cuda:0') tensor(8.2140e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.960859
Average KL loss: 0.330696
Average total loss: 1.291554
tensor(-15.4986, device='cuda:0') tensor(0.1481, device='cuda:0') tensor(-3.8649e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.962962
Average KL loss: 0.330630
Average total loss: 1.293592
tensor(-15.4995, device='cuda:0') tensor(0.1482, device='cuda:0') tensor(2.9917e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.962075
Average KL loss: 0.330573
Average total loss: 1.292648
tensor(-15.5004, device='cuda:0') tensor(0.1482, device='cuda:0') tensor(-1.2128e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.962249
Average KL loss: 0.330501
Average total loss: 1.292750
tensor(-15.5013, device='cuda:0') tensor(0.1483, device='cuda:0') tensor(-5.1817e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.961082
Average KL loss: 0.330404
Average total loss: 1.291486
tensor(-15.5022, device='cuda:0') tensor(0.1483, device='cuda:0') tensor(-2.2893e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.962003
Average KL loss: 0.330329
Average total loss: 1.292332
tensor(-15.5031, device='cuda:0') tensor(0.1483, device='cuda:0') tensor(4.1070e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.961187
Average KL loss: 0.330270
Average total loss: 1.291457
tensor(-15.5040, device='cuda:0') tensor(0.1484, device='cuda:0') tensor(-1.3980e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.961188
Average KL loss: 0.330222
Average total loss: 1.291410
tensor(-15.5049, device='cuda:0') tensor(0.1484, device='cuda:0') tensor(-1.1416e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.961233
Average KL loss: 0.330165
Average total loss: 1.291398
tensor(-15.5058, device='cuda:0') tensor(0.1485, device='cuda:0') tensor(-3.9786e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.963970
Average KL loss: 0.330107
Average total loss: 1.294078
tensor(-15.5067, device='cuda:0') tensor(0.1485, device='cuda:0') tensor(-1.8679e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.960918
Average KL loss: 0.330057
Average total loss: 1.290975
tensor(-15.5076, device='cuda:0') tensor(0.1485, device='cuda:0') tensor(-3.3985e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.958523
Average KL loss: 0.329991
Average total loss: 1.288514
tensor(-15.5085, device='cuda:0') tensor(0.1486, device='cuda:0') tensor(-2.2289e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.960469
Average KL loss: 0.329941
Average total loss: 1.290410
tensor(-15.5094, device='cuda:0') tensor(0.1486, device='cuda:0') tensor(-1.4637e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.962167
Average KL loss: 0.329895
Average total loss: 1.292062
tensor(-15.5103, device='cuda:0') tensor(0.1486, device='cuda:0') tensor(-4.8011e-11, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.958869
Average KL loss: 0.329838
Average total loss: 1.288707
tensor(-15.5112, device='cuda:0') tensor(0.1487, device='cuda:0') tensor(1.8499e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.961217
Average KL loss: 0.329777
Average total loss: 1.290993
tensor(-15.5121, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(1.1405e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.958482
Average KL loss: 0.329717
Average total loss: 1.288199
tensor(-15.5130, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(-2.7786e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.959957
Average KL loss: 0.329677
Average total loss: 1.289634
tensor(-15.5139, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(4.2878e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.958825
Average KL loss: 0.329631
Average total loss: 1.288456
tensor(-15.5148, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(-3.7328e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.956983
Average KL loss: 0.329585
Average total loss: 1.286568
tensor(-15.5157, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(2.0693e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.959217
Average KL loss: 0.329531
Average total loss: 1.288748
tensor(-15.5166, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(6.3284e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.960955
Average KL loss: 0.329481
Average total loss: 1.290436
tensor(-15.5175, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(-2.3345e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.961154
Average KL loss: 0.329450
Average total loss: 1.290604
tensor(-15.5184, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(1.0868e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.959375
Average KL loss: 0.329408
Average total loss: 1.288784
tensor(-15.5193, device='cuda:0') tensor(0.1491, device='cuda:0') tensor(-4.1848e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.956258
Average KL loss: 0.329366
Average total loss: 1.285624
tensor(-15.5202, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(2.0715e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.959446
Average KL loss: 0.329320
Average total loss: 1.288766
tensor(-15.5211, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(1.1802e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.962195
Average KL loss: 0.329296
Average total loss: 1.291491
tensor(-15.5220, device='cuda:0') tensor(0.1493, device='cuda:0') tensor(1.3442e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.958385
Average KL loss: 0.329237
Average total loss: 1.287622
 Percentile value: -15.210038185119629
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =    1299 /    1728             ( 75.17%) | total_pruned =     429 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5645 /   36864             ( 15.31%) | total_pruned =   31219 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5550 /   36864             ( 15.06%) | total_pruned =   31314 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4471 /   36864             ( 12.13%) | total_pruned =   32393 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3314 /   36864             (  8.99%) | total_pruned =   33550 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8372 /   73728             ( 11.36%) | total_pruned =   65356 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    7527 /  147456             (  5.10%) | total_pruned =  139929 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1905 /    8192             ( 23.25%) | total_pruned =    6287 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4264 /  147456             (  2.89%) | total_pruned =  143192 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2560 /  147456             (  1.74%) | total_pruned =  144896 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6739 /  294912             (  2.29%) | total_pruned =  288173 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      68 /     256             ( 26.56%) | total_pruned =     188 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5019 /  589824             (  0.85%) | total_pruned =  584805 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      69 /     256             ( 26.95%) | total_pruned =     187 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1372 /   32768             (  4.19%) | total_pruned =   31396 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      63 /     256             ( 24.61%) | total_pruned =     193 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1307 /  589824             (  0.22%) | total_pruned =  588517 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     809 /  589824             (  0.14%) | total_pruned =  589015 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    3025 / 1179648             (  0.26%) | total_pruned = 1176623 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4885 / 2359296             (  0.21%) | total_pruned = 2354411 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     175 /     512             ( 34.18%) | total_pruned =     337 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     116 /     512             ( 22.66%) | total_pruned =     396 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2523 /  131072             (  1.92%) | total_pruned =  128549 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     191 /     512             ( 37.30%) | total_pruned =     321 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    4707 / 2359296             (  0.20%) | total_pruned = 2354589 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    8060 / 2359296             (  0.34%) | total_pruned = 2351236 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     209 /     512             ( 40.82%) | total_pruned =     303 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
linear.weight        | nonzeros =    1741 /    5120             ( 34.00%) | total_pruned =    3379 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       5 /      10             ( 50.00%) | total_pruned =       5 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 59/100 Loss: 0.006479 Accuracy: 80.33 100.00 % Best test Accuracy: 80.66%
tensor(-15.5229, device='cuda:0') tensor(0.1493, device='cuda:0') tensor(5.0082e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.472543
Average KL loss: 0.328837
Average total loss: 1.801381
tensor(-15.5239, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(-1.2338e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.473391
Average KL loss: 0.328387
Average total loss: 1.801778
tensor(-15.5249, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(4.5379e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.471762
Average KL loss: 0.328005
Average total loss: 1.799767
tensor(-15.5258, device='cuda:0') tensor(0.1388, device='cuda:0') tensor(-7.6293e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.475324
Average KL loss: 0.327677
Average total loss: 1.803001
tensor(-15.5267, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-2.2906e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.455761
Average KL loss: 0.327430
Average total loss: 1.783191
tensor(-15.5276, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-1.7841e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.440919
Average KL loss: 0.327265
Average total loss: 1.768184
tensor(-15.5285, device='cuda:0') tensor(0.1365, device='cuda:0') tensor(1.2179e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.437124
Average KL loss: 0.327092
Average total loss: 1.764216
tensor(-15.5294, device='cuda:0') tensor(0.1363, device='cuda:0') tensor(-1.7177e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.432853
Average KL loss: 0.326908
Average total loss: 1.759761
tensor(-15.5303, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(4.4862e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.417403
Average KL loss: 0.326709
Average total loss: 1.744113
tensor(-15.5311, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-1.7322e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.411611
Average KL loss: 0.326529
Average total loss: 1.738140
tensor(-15.5320, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(-1.6450e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.396191
Average KL loss: 0.326351
Average total loss: 1.722542
tensor(-15.5329, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(-5.0818e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.404345
Average KL loss: 0.326219
Average total loss: 1.730565
tensor(-15.5337, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(5.1045e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.387070
Average KL loss: 0.326059
Average total loss: 1.713128
tensor(-15.5346, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(-1.2563e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.377423
Average KL loss: 0.325884
Average total loss: 1.703306
tensor(-15.5355, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(7.3799e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.368170
Average KL loss: 0.325707
Average total loss: 1.693877
tensor(-15.5364, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(3.7863e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.359266
Average KL loss: 0.325517
Average total loss: 1.684783
tensor(-15.5372, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(2.9457e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.351362
Average KL loss: 0.325317
Average total loss: 1.676679
tensor(-15.5381, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-3.4731e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.340229
Average KL loss: 0.325153
Average total loss: 1.665383
tensor(-15.5389, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(5.6725e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.335950
Average KL loss: 0.324959
Average total loss: 1.660909
tensor(-15.5398, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-5.0778e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.337958
Average KL loss: 0.324770
Average total loss: 1.662729
tensor(-15.5407, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-8.2743e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.320967
Average KL loss: 0.324573
Average total loss: 1.645540
tensor(-15.5415, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(8.5343e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.321322
Average KL loss: 0.324369
Average total loss: 1.645691
tensor(-15.5424, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(4.7123e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.311548
Average KL loss: 0.324178
Average total loss: 1.635726
tensor(-15.5432, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(1.2079e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.308364
Average KL loss: 0.323975
Average total loss: 1.632339
tensor(-15.5441, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-1.7076e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.296342
Average KL loss: 0.323752
Average total loss: 1.620094
tensor(-15.5450, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(8.2722e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.289740
Average KL loss: 0.323519
Average total loss: 1.613259
tensor(-15.5458, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(1.8693e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.290586
Average KL loss: 0.323314
Average total loss: 1.613901
tensor(-15.5467, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(4.6070e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.275030
Average KL loss: 0.323088
Average total loss: 1.598119
tensor(-15.5475, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-2.1782e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.264222
Average KL loss: 0.322852
Average total loss: 1.587073
tensor(-15.5484, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-1.8776e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.272163
Average KL loss: 0.322655
Average total loss: 1.594818
tensor(-15.5492, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-8.3713e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.270793
Average KL loss: 0.322446
Average total loss: 1.593239
tensor(-15.5501, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(2.0136e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.255403
Average KL loss: 0.322205
Average total loss: 1.577609
tensor(-15.5509, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-3.6033e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.255891
Average KL loss: 0.321967
Average total loss: 1.577858
tensor(-15.5518, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-2.7624e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.254301
Average KL loss: 0.321731
Average total loss: 1.576032
tensor(-15.5527, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(5.2230e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.251279
Average KL loss: 0.321519
Average total loss: 1.572798
tensor(-15.5535, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(-1.4395e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.250695
Average KL loss: 0.321339
Average total loss: 1.572034
tensor(-15.5544, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(3.7781e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.237573
Average KL loss: 0.321169
Average total loss: 1.558742
tensor(-15.5552, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(1.9883e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.238480
Average KL loss: 0.321019
Average total loss: 1.559499
tensor(-15.5561, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(-3.8521e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.234982
Average KL loss: 0.320878
Average total loss: 1.555860
tensor(-15.5569, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(2.0290e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.235902
Average KL loss: 0.320747
Average total loss: 1.556649
tensor(-15.5578, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(3.0248e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.230140
Average KL loss: 0.320618
Average total loss: 1.550758
tensor(-15.5586, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(7.4162e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.225133
Average KL loss: 0.320506
Average total loss: 1.545639
tensor(-15.5595, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-1.4339e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.227116
Average KL loss: 0.320364
Average total loss: 1.547480
tensor(-15.5603, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-1.8152e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.217467
Average KL loss: 0.320243
Average total loss: 1.537710
tensor(-15.5612, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(9.8331e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.214341
Average KL loss: 0.320116
Average total loss: 1.534456
tensor(-15.5620, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(4.7759e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.214790
Average KL loss: 0.319953
Average total loss: 1.534744
tensor(-15.5629, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(1.1341e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.214788
Average KL loss: 0.319809
Average total loss: 1.534596
tensor(-15.5637, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(-9.5197e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.215476
Average KL loss: 0.319673
Average total loss: 1.535149
tensor(-15.5646, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(-1.0925e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.206625
Average KL loss: 0.319521
Average total loss: 1.526146
tensor(-15.5654, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(2.1770e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.209423
Average KL loss: 0.319361
Average total loss: 1.528785
tensor(-15.5663, device='cuda:0') tensor(0.1363, device='cuda:0') tensor(3.6032e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.204753
Average KL loss: 0.319199
Average total loss: 1.523952
tensor(-15.5671, device='cuda:0') tensor(0.1363, device='cuda:0') tensor(2.1975e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.206567
Average KL loss: 0.319049
Average total loss: 1.525616
tensor(-15.5680, device='cuda:0') tensor(0.1363, device='cuda:0') tensor(6.6525e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.196229
Average KL loss: 0.318893
Average total loss: 1.515122
tensor(-15.5688, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(-6.1953e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.197330
Average KL loss: 0.318739
Average total loss: 1.516069
tensor(-15.5697, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(-3.1385e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.200418
Average KL loss: 0.318600
Average total loss: 1.519018
tensor(-15.5705, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(1.1096e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.192720
Average KL loss: 0.318464
Average total loss: 1.511184
tensor(-15.5714, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(9.9406e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.202494
Average KL loss: 0.318317
Average total loss: 1.520811
tensor(-15.5722, device='cuda:0') tensor(0.1365, device='cuda:0') tensor(-1.2683e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.183440
Average KL loss: 0.318160
Average total loss: 1.501600
tensor(-15.5731, device='cuda:0') tensor(0.1365, device='cuda:0') tensor(-3.6792e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.189064
Average KL loss: 0.318023
Average total loss: 1.507087
tensor(-15.5739, device='cuda:0') tensor(0.1365, device='cuda:0') tensor(5.2543e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.184395
Average KL loss: 0.317883
Average total loss: 1.502278
tensor(-15.5748, device='cuda:0') tensor(0.1366, device='cuda:0') tensor(2.4024e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.187031
Average KL loss: 0.317761
Average total loss: 1.504792
tensor(-15.5756, device='cuda:0') tensor(0.1366, device='cuda:0') tensor(3.3853e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.187050
Average KL loss: 0.317649
Average total loss: 1.504699
tensor(-15.5765, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(2.9976e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.183177
Average KL loss: 0.317565
Average total loss: 1.500742
tensor(-15.5773, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(1.6614e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.185668
Average KL loss: 0.317487
Average total loss: 1.503155
tensor(-15.5782, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(-1.6238e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.179700
Average KL loss: 0.317379
Average total loss: 1.497079
tensor(-15.5790, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(-9.9054e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.174310
Average KL loss: 0.317269
Average total loss: 1.491579
tensor(-15.5798, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-2.7979e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.178494
Average KL loss: 0.317181
Average total loss: 1.495675
tensor(-15.5807, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-3.2268e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.184569
Average KL loss: 0.317081
Average total loss: 1.501650
tensor(-15.5815, device='cuda:0') tensor(0.1369, device='cuda:0') tensor(-5.4477e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.171549
Average KL loss: 0.316984
Average total loss: 1.488534
tensor(-15.5824, device='cuda:0') tensor(0.1369, device='cuda:0') tensor(-8.8972e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.172012
Average KL loss: 0.316882
Average total loss: 1.488894
tensor(-15.5832, device='cuda:0') tensor(0.1369, device='cuda:0') tensor(-5.2072e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.169347
Average KL loss: 0.316786
Average total loss: 1.486132
tensor(-15.5840, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(4.6030e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.168410
Average KL loss: 0.316698
Average total loss: 1.485109
tensor(-15.5849, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(-5.6090e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.175106
Average KL loss: 0.316600
Average total loss: 1.491706
tensor(-15.5857, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(-6.4612e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.170638
Average KL loss: 0.316509
Average total loss: 1.487147
tensor(-15.5865, device='cuda:0') tensor(0.1371, device='cuda:0') tensor(-3.9683e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.169262
Average KL loss: 0.316401
Average total loss: 1.485663
tensor(-15.5873, device='cuda:0') tensor(0.1371, device='cuda:0') tensor(-7.5324e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.168422
Average KL loss: 0.316301
Average total loss: 1.484723
tensor(-15.5882, device='cuda:0') tensor(0.1372, device='cuda:0') tensor(-3.0124e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.164353
Average KL loss: 0.316200
Average total loss: 1.480553
tensor(-15.5890, device='cuda:0') tensor(0.1372, device='cuda:0') tensor(2.4868e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.163717
Average KL loss: 0.316106
Average total loss: 1.479823
tensor(-15.5898, device='cuda:0') tensor(0.1372, device='cuda:0') tensor(-6.2734e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.164010
Average KL loss: 0.315996
Average total loss: 1.480006
tensor(-15.5906, device='cuda:0') tensor(0.1372, device='cuda:0') tensor(2.5973e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.160964
Average KL loss: 0.315877
Average total loss: 1.476841
tensor(-15.5914, device='cuda:0') tensor(0.1373, device='cuda:0') tensor(-2.8564e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.164775
Average KL loss: 0.315776
Average total loss: 1.480552
tensor(-15.5923, device='cuda:0') tensor(0.1373, device='cuda:0') tensor(3.3541e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.160303
Average KL loss: 0.315661
Average total loss: 1.475964
tensor(-15.5931, device='cuda:0') tensor(0.1373, device='cuda:0') tensor(4.6890e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.154519
Average KL loss: 0.315537
Average total loss: 1.470056
tensor(-15.5939, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(-2.2530e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.155951
Average KL loss: 0.315428
Average total loss: 1.471379
tensor(-15.5947, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(-3.0965e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.159600
Average KL loss: 0.315314
Average total loss: 1.474915
tensor(-15.5955, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-1.2162e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.152500
Average KL loss: 0.315210
Average total loss: 1.467710
tensor(-15.5963, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-1.2100e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.149910
Average KL loss: 0.315092
Average total loss: 1.465002
tensor(-15.5971, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(7.5089e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.149364
Average KL loss: 0.314973
Average total loss: 1.464336
tensor(-15.5979, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-3.1076e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.152927
Average KL loss: 0.314854
Average total loss: 1.467781
tensor(-15.5987, device='cuda:0') tensor(0.1376, device='cuda:0') tensor(-2.6688e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.157752
Average KL loss: 0.314746
Average total loss: 1.472498
tensor(-15.5996, device='cuda:0') tensor(0.1376, device='cuda:0') tensor(-3.9006e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.150743
Average KL loss: 0.314648
Average total loss: 1.465391
tensor(-15.6004, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(2.0799e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.147265
Average KL loss: 0.314549
Average total loss: 1.461814
tensor(-15.6012, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-1.0423e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.144611
Average KL loss: 0.314450
Average total loss: 1.459061
tensor(-15.6020, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-3.0484e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.140362
Average KL loss: 0.314360
Average total loss: 1.454722
tensor(-15.6028, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(2.0702e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.143024
Average KL loss: 0.314257
Average total loss: 1.457282
tensor(-15.6036, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-1.4733e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.141969
Average KL loss: 0.314129
Average total loss: 1.456098
tensor(-15.6044, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-3.4180e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.140687
Average KL loss: 0.314006
Average total loss: 1.454693
tensor(-15.6052, device='cuda:0') tensor(0.1379, device='cuda:0') tensor(-1.4020e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.146565
Average KL loss: 0.313901
Average total loss: 1.460466
tensor(-15.6060, device='cuda:0') tensor(0.1379, device='cuda:0') tensor(3.3437e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.138042
Average KL loss: 0.313793
Average total loss: 1.451835
tensor(-15.6068, device='cuda:0') tensor(0.1379, device='cuda:0') tensor(1.5011e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.142796
Average KL loss: 0.313678
Average total loss: 1.456474
tensor(-15.6076, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(-1.3646e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.134547
Average KL loss: 0.313573
Average total loss: 1.448119
tensor(-15.6084, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(1.4467e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.136265
Average KL loss: 0.313430
Average total loss: 1.449695
tensor(-15.6092, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(-5.0893e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.138716
Average KL loss: 0.313324
Average total loss: 1.452040
tensor(-15.6100, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(-1.2255e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.136414
Average KL loss: 0.313216
Average total loss: 1.449630
tensor(-15.6108, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(-3.1098e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.134937
Average KL loss: 0.313122
Average total loss: 1.448059
tensor(-15.6116, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(2.2663e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.131296
Average KL loss: 0.313040
Average total loss: 1.444336
tensor(-15.6124, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(1.2941e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.132292
Average KL loss: 0.312936
Average total loss: 1.445228
tensor(-15.6133, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(-1.3049e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.130791
Average KL loss: 0.312819
Average total loss: 1.443610
tensor(-15.6141, device='cuda:0') tensor(0.1382, device='cuda:0') tensor(-1.2029e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.126311
Average KL loss: 0.312720
Average total loss: 1.439031
tensor(-15.6149, device='cuda:0') tensor(0.1382, device='cuda:0') tensor(1.1259e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.128852
Average KL loss: 0.312613
Average total loss: 1.441465
tensor(-15.6157, device='cuda:0') tensor(0.1382, device='cuda:0') tensor(5.3590e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.130945
Average KL loss: 0.312477
Average total loss: 1.443422
tensor(-15.6165, device='cuda:0') tensor(0.1382, device='cuda:0') tensor(-2.2205e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.128295
Average KL loss: 0.312317
Average total loss: 1.440612
tensor(-15.6173, device='cuda:0') tensor(0.1383, device='cuda:0') tensor(-2.2946e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.129837
Average KL loss: 0.312205
Average total loss: 1.442042
tensor(-15.6181, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(-2.2909e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.125622
Average KL loss: 0.312090
Average total loss: 1.437712
tensor(-15.6189, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(2.5704e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.125331
Average KL loss: 0.311986
Average total loss: 1.437316
tensor(-15.6197, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(-3.6061e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.124732
Average KL loss: 0.311879
Average total loss: 1.436611
tensor(-15.6205, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(-2.2109e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.125247
Average KL loss: 0.311757
Average total loss: 1.437004
tensor(-15.6213, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(2.1336e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.126019
Average KL loss: 0.311651
Average total loss: 1.437670
tensor(-15.6221, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(9.4256e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.124864
Average KL loss: 0.311593
Average total loss: 1.436457
tensor(-15.6229, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(-3.0954e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.122029
Average KL loss: 0.311520
Average total loss: 1.433549
tensor(-15.6237, device='cuda:0') tensor(0.1386, device='cuda:0') tensor(-2.7490e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.121029
Average KL loss: 0.311440
Average total loss: 1.432469
tensor(-15.6245, device='cuda:0') tensor(0.1386, device='cuda:0') tensor(1.8365e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.121963
Average KL loss: 0.311346
Average total loss: 1.433309
tensor(-15.6253, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(1.2176e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.120192
Average KL loss: 0.311262
Average total loss: 1.431454
tensor(-15.6261, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(4.4210e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.121883
Average KL loss: 0.311192
Average total loss: 1.433074
tensor(-15.6269, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(1.4140e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.120807
Average KL loss: 0.311098
Average total loss: 1.431905
tensor(-15.6277, device='cuda:0') tensor(0.1388, device='cuda:0') tensor(3.2809e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.124739
Average KL loss: 0.310998
Average total loss: 1.435738
tensor(-15.6285, device='cuda:0') tensor(0.1388, device='cuda:0') tensor(-4.6463e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.120073
Average KL loss: 0.310923
Average total loss: 1.430996
tensor(-15.6293, device='cuda:0') tensor(0.1389, device='cuda:0') tensor(-3.2926e-11, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.120094
Average KL loss: 0.310833
Average total loss: 1.430926
tensor(-15.6301, device='cuda:0') tensor(0.1389, device='cuda:0') tensor(-2.6128e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.112116
Average KL loss: 0.310730
Average total loss: 1.422846
tensor(-15.6309, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-5.0260e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.113790
Average KL loss: 0.310643
Average total loss: 1.424433
tensor(-15.6317, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-5.0807e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.112075
Average KL loss: 0.310551
Average total loss: 1.422626
tensor(-15.6325, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-2.9931e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.110586
Average KL loss: 0.310447
Average total loss: 1.421033
tensor(-15.6333, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(1.0266e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.122116
Average KL loss: 0.310324
Average total loss: 1.432440
tensor(-15.6341, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-7.4383e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.113048
Average KL loss: 0.310206
Average total loss: 1.423254
tensor(-15.6349, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-6.3948e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.113828
Average KL loss: 0.310120
Average total loss: 1.423947
tensor(-15.6357, device='cuda:0') tensor(0.1392, device='cuda:0') tensor(-4.6611e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.113164
Average KL loss: 0.310028
Average total loss: 1.423192
tensor(-15.6365, device='cuda:0') tensor(0.1392, device='cuda:0') tensor(8.0065e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.116656
Average KL loss: 0.309935
Average total loss: 1.426591
tensor(-15.6373, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-2.2530e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.109935
Average KL loss: 0.309854
Average total loss: 1.419789
tensor(-15.6381, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-1.7929e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.111318
Average KL loss: 0.309765
Average total loss: 1.421084
tensor(-15.6389, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(1.2088e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.110942
Average KL loss: 0.309670
Average total loss: 1.420613
tensor(-15.6397, device='cuda:0') tensor(0.1394, device='cuda:0') tensor(-1.3215e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.109368
Average KL loss: 0.309572
Average total loss: 1.418940
tensor(-15.6405, device='cuda:0') tensor(0.1394, device='cuda:0') tensor(-3.1818e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.109512
Average KL loss: 0.309491
Average total loss: 1.419003
tensor(-15.6413, device='cuda:0') tensor(0.1395, device='cuda:0') tensor(3.3442e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.103803
Average KL loss: 0.309423
Average total loss: 1.413225
tensor(-15.6421, device='cuda:0') tensor(0.1395, device='cuda:0') tensor(-9.6978e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.107625
Average KL loss: 0.309349
Average total loss: 1.416974
tensor(-15.6429, device='cuda:0') tensor(0.1395, device='cuda:0') tensor(1.3620e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.103368
Average KL loss: 0.309281
Average total loss: 1.412648
tensor(-15.6436, device='cuda:0') tensor(0.1396, device='cuda:0') tensor(-3.2453e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.106822
Average KL loss: 0.309235
Average total loss: 1.416056
tensor(-15.6444, device='cuda:0') tensor(0.1396, device='cuda:0') tensor(1.1270e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.103446
Average KL loss: 0.309162
Average total loss: 1.412608
tensor(-15.6452, device='cuda:0') tensor(0.1396, device='cuda:0') tensor(-5.7058e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.105014
Average KL loss: 0.309080
Average total loss: 1.414094
tensor(-15.6460, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(-8.7838e-11, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.106414
Average KL loss: 0.309000
Average total loss: 1.415413
tensor(-15.6468, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(-2.3155e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.108366
Average KL loss: 0.308936
Average total loss: 1.417302
tensor(-15.6475, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(-5.8518e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.109528
Average KL loss: 0.308873
Average total loss: 1.418401
tensor(-15.6483, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(-5.6327e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.106966
Average KL loss: 0.308800
Average total loss: 1.415766
tensor(-15.6491, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(-5.9297e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.105852
Average KL loss: 0.308720
Average total loss: 1.414571
tensor(-15.6498, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(-4.7282e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.101481
Average KL loss: 0.308645
Average total loss: 1.410126
tensor(-15.6506, device='cuda:0') tensor(0.1399, device='cuda:0') tensor(1.4936e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.104617
Average KL loss: 0.308561
Average total loss: 1.413178
tensor(-15.6514, device='cuda:0') tensor(0.1399, device='cuda:0') tensor(1.6562e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.106218
Average KL loss: 0.308501
Average total loss: 1.414719
tensor(-15.6521, device='cuda:0') tensor(0.1399, device='cuda:0') tensor(2.6107e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.099999
Average KL loss: 0.308446
Average total loss: 1.408445
tensor(-15.6529, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(2.7806e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.099284
Average KL loss: 0.308388
Average total loss: 1.407672
tensor(-15.6537, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(8.4521e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.099340
Average KL loss: 0.308350
Average total loss: 1.407690
tensor(-15.6544, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(-3.6700e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.100819
Average KL loss: 0.308315
Average total loss: 1.409135
tensor(-15.6552, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-1.6858e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.098508
Average KL loss: 0.308231
Average total loss: 1.406739
tensor(-15.6560, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(6.8722e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.097746
Average KL loss: 0.308159
Average total loss: 1.405904
tensor(-15.6567, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(1.6315e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.099443
Average KL loss: 0.308103
Average total loss: 1.407546
tensor(-15.6575, device='cuda:0') tensor(0.1402, device='cuda:0') tensor(-1.3732e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.097902
Average KL loss: 0.308049
Average total loss: 1.405951
tensor(-15.6582, device='cuda:0') tensor(0.1402, device='cuda:0') tensor(-1.1563e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.102206
Average KL loss: 0.307991
Average total loss: 1.410197
tensor(-15.6590, device='cuda:0') tensor(0.1402, device='cuda:0') tensor(3.2764e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.098359
Average KL loss: 0.307939
Average total loss: 1.406298
tensor(-15.6598, device='cuda:0') tensor(0.1403, device='cuda:0') tensor(1.5787e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.097478
Average KL loss: 0.307896
Average total loss: 1.405374
tensor(-15.6605, device='cuda:0') tensor(0.1403, device='cuda:0') tensor(2.0208e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.098017
Average KL loss: 0.307852
Average total loss: 1.405869
tensor(-15.6613, device='cuda:0') tensor(0.1404, device='cuda:0') tensor(1.6691e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.095492
Average KL loss: 0.307798
Average total loss: 1.403290
tensor(-15.6621, device='cuda:0') tensor(0.1404, device='cuda:0') tensor(-1.0889e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.101581
Average KL loss: 0.307747
Average total loss: 1.409328
tensor(-15.6628, device='cuda:0') tensor(0.1404, device='cuda:0') tensor(-2.3591e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.095211
Average KL loss: 0.307687
Average total loss: 1.402898
tensor(-15.6636, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(-3.2972e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 1.095291
Average KL loss: 0.307614
Average total loss: 1.402906
tensor(-15.6643, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(7.4472e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.093407
Average KL loss: 0.307545
Average total loss: 1.400952
tensor(-15.6651, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(-2.4985e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.093333
Average KL loss: 0.307473
Average total loss: 1.400806
tensor(-15.6658, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(5.0916e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 1.096763
Average KL loss: 0.307398
Average total loss: 1.404161
tensor(-15.6666, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(3.1471e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 1.094308
Average KL loss: 0.307312
Average total loss: 1.401619
tensor(-15.6674, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(-8.7394e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 1.097879
Average KL loss: 0.307230
Average total loss: 1.405109
tensor(-15.6681, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(-2.7296e-11, device='cuda:0')
Epoch 178
Average batch original loss after noise: 1.095572
Average KL loss: 0.307159
Average total loss: 1.402731
tensor(-15.6689, device='cuda:0') tensor(0.1407, device='cuda:0') tensor(3.7536e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 1.091304
Average KL loss: 0.307081
Average total loss: 1.398385
tensor(-15.6696, device='cuda:0') tensor(0.1407, device='cuda:0') tensor(-1.7077e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 1.093187
Average KL loss: 0.307000
Average total loss: 1.400187
tensor(-15.6704, device='cuda:0') tensor(0.1407, device='cuda:0') tensor(-1.6533e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 1.094665
Average KL loss: 0.306902
Average total loss: 1.401567
tensor(-15.6711, device='cuda:0') tensor(0.1408, device='cuda:0') tensor(-1.6396e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 1.093887
Average KL loss: 0.306823
Average total loss: 1.400710
tensor(-15.6719, device='cuda:0') tensor(0.1408, device='cuda:0') tensor(-1.0618e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 1.090844
Average KL loss: 0.306757
Average total loss: 1.397602
tensor(-15.6726, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-5.9712e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 1.091522
Average KL loss: 0.306687
Average total loss: 1.398209
tensor(-15.6734, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-1.7938e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 1.092661
Average KL loss: 0.306616
Average total loss: 1.399277
tensor(-15.6742, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-7.9586e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 1.086837
Average KL loss: 0.306545
Average total loss: 1.393382
tensor(-15.6749, device='cuda:0') tensor(0.1410, device='cuda:0') tensor(1.3397e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 1.090097
Average KL loss: 0.306485
Average total loss: 1.396582
tensor(-15.6757, device='cuda:0') tensor(0.1410, device='cuda:0') tensor(-9.0717e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 1.092880
Average KL loss: 0.306418
Average total loss: 1.399298
tensor(-15.6764, device='cuda:0') tensor(0.1410, device='cuda:0') tensor(7.2701e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 1.089885
Average KL loss: 0.306380
Average total loss: 1.396266
tensor(-15.6772, device='cuda:0') tensor(0.1411, device='cuda:0') tensor(-1.3993e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 1.094479
Average KL loss: 0.306337
Average total loss: 1.400817
tensor(-15.6779, device='cuda:0') tensor(0.1411, device='cuda:0') tensor(-2.8254e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 1.088816
Average KL loss: 0.306277
Average total loss: 1.395093
tensor(-15.6787, device='cuda:0') tensor(0.1411, device='cuda:0') tensor(-5.3591e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 1.089865
Average KL loss: 0.306217
Average total loss: 1.396082
tensor(-15.6794, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(2.6602e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 1.088902
Average KL loss: 0.306159
Average total loss: 1.395061
tensor(-15.6802, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(-7.8892e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 1.087952
Average KL loss: 0.306111
Average total loss: 1.394063
tensor(-15.6809, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(5.4884e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 1.086269
Average KL loss: 0.306057
Average total loss: 1.392326
tensor(-15.6817, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(-7.4142e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 1.087436
Average KL loss: 0.305980
Average total loss: 1.393415
tensor(-15.6825, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(1.3843e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 1.085590
Average KL loss: 0.305942
Average total loss: 1.391532
tensor(-15.6832, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(-7.2687e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 1.090332
Average KL loss: 0.305899
Average total loss: 1.396231
tensor(-15.6840, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(4.0782e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 1.089088
Average KL loss: 0.305831
Average total loss: 1.394919
tensor(-15.6847, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(5.5576e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 1.088880
Average KL loss: 0.305744
Average total loss: 1.394624
 Percentile value: -15.320315837860107
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =     966 /    1728             ( 55.90%) | total_pruned =     762 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
bn1.bias             | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2678 /   36864             (  7.26%) | total_pruned =   34186 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2694 /   36864             (  7.31%) | total_pruned =   34170 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2646 /   36864             (  7.18%) | total_pruned =   34218 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1917 /   36864             (  5.20%) | total_pruned =   34947 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4097 /   73728             (  5.56%) | total_pruned =   69631 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3621 /  147456             (  2.46%) | total_pruned =  143835 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1016 /    8192             ( 12.40%) | total_pruned =    7176 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2092 /  147456             (  1.42%) | total_pruned =  145364 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1218 /  147456             (  0.83%) | total_pruned =  146238 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3423 /  294912             (  1.16%) | total_pruned =  291489 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2779 /  589824             (  0.47%) | total_pruned =  587045 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     724 /   32768             (  2.21%) | total_pruned =   32044 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      41 /     256             ( 16.02%) | total_pruned =     215 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     713 /  589824             (  0.12%) | total_pruned =  589111 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     460 /  589824             (  0.08%) | total_pruned =  589364 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1613 / 1179648             (  0.14%) | total_pruned = 1178035 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2368 / 2359296             (  0.10%) | total_pruned = 2356928 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     102 /     512             ( 19.92%) | total_pruned =     410 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1264 /  131072             (  0.96%) | total_pruned =  129808 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     130 /     512             ( 25.39%) | total_pruned =     382 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      51 /     512             (  9.96%) | total_pruned =     461 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1882 / 2359296             (  0.08%) | total_pruned = 2357414 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      44 /     512             (  8.59%) | total_pruned =     468 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2902 / 2359296             (  0.12%) | total_pruned = 2356394 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
linear.weight        | nonzeros =    1224 /    5120             ( 23.91%) | total_pruned =    3896 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 96/100 Loss: 0.006647 Accuracy: 77.87 100.00 % Best test Accuracy: 78.94%
tensor(-15.6855, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-1.5259e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.462546
Average KL loss: 0.305360
Average total loss: 2.767906
tensor(-15.6863, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(8.0413e-13, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.451271
Average KL loss: 0.304874
Average total loss: 2.756145
tensor(-15.6872, device='cuda:0') tensor(0.1339, device='cuda:0') tensor(-9.2620e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.435900
Average KL loss: 0.304448
Average total loss: 2.740348
tensor(-15.6880, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-6.1279e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.429509
Average KL loss: 0.304070
Average total loss: 2.733579
tensor(-15.6888, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-2.9186e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.422355
Average KL loss: 0.303744
Average total loss: 2.726099
tensor(-15.6895, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(8.6954e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.389635
Average KL loss: 0.303471
Average total loss: 2.693106
tensor(-15.6903, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(8.5477e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.387167
Average KL loss: 0.303203
Average total loss: 2.690370
tensor(-15.6911, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(6.4069e-11, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.363021
Average KL loss: 0.302946
Average total loss: 2.665967
tensor(-15.6918, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(8.6158e-11, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.352490
Average KL loss: 0.302724
Average total loss: 2.655214
tensor(-15.6926, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-1.1597e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.335785
Average KL loss: 0.302537
Average total loss: 2.638322
tensor(-15.6933, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(4.5137e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.320342
Average KL loss: 0.302351
Average total loss: 2.622693
tensor(-15.6941, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(2.6218e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.305574
Average KL loss: 0.302160
Average total loss: 2.607734
tensor(-15.6948, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-7.6491e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.274733
Average KL loss: 0.301970
Average total loss: 2.576702
tensor(-15.6956, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-5.3813e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.274828
Average KL loss: 0.301736
Average total loss: 2.576564
tensor(-15.6964, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-5.4744e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.247607
Average KL loss: 0.301488
Average total loss: 2.549095
tensor(-15.6971, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-6.1232e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.234304
Average KL loss: 0.301274
Average total loss: 2.535578
tensor(-15.6979, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(2.0314e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.222233
Average KL loss: 0.301082
Average total loss: 2.523316
tensor(-15.6986, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(7.6393e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.216930
Average KL loss: 0.300835
Average total loss: 2.517765
tensor(-15.6994, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-3.4906e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.197831
Average KL loss: 0.300628
Average total loss: 2.498459
tensor(-15.7001, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-1.8543e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.169317
Average KL loss: 0.300424
Average total loss: 2.469741
tensor(-15.7009, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-1.1298e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.142055
Average KL loss: 0.300236
Average total loss: 2.442290
tensor(-15.7016, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-5.9169e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.124428
Average KL loss: 0.300028
Average total loss: 2.424456
tensor(-15.7024, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(-8.5879e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.119019
Average KL loss: 0.299802
Average total loss: 2.418821
tensor(-15.7032, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(3.1922e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.100800
Average KL loss: 0.299587
Average total loss: 2.400387
tensor(-15.7039, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(4.7065e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.080092
Average KL loss: 0.299371
Average total loss: 2.379462
tensor(-15.7047, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(1.1012e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.074624
Average KL loss: 0.299150
Average total loss: 2.373774
tensor(-15.7054, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(7.1017e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.068206
Average KL loss: 0.298928
Average total loss: 2.367133
tensor(-15.7062, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(1.5488e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.047992
Average KL loss: 0.298720
Average total loss: 2.346712
tensor(-15.7069, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(1.6243e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.027699
Average KL loss: 0.298498
Average total loss: 2.326197
tensor(-15.7076, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(1.0568e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.994955
Average KL loss: 0.298321
Average total loss: 2.293276
tensor(-15.7084, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(8.1914e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.008153
Average KL loss: 0.298145
Average total loss: 2.306298
tensor(-15.7091, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-6.7768e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.991819
Average KL loss: 0.297965
Average total loss: 2.289784
tensor(-15.7098, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-6.9431e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.994315
Average KL loss: 0.297798
Average total loss: 2.292113
tensor(-15.7106, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-3.2072e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.976539
Average KL loss: 0.297619
Average total loss: 2.274159
tensor(-15.7113, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(8.6989e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.954248
Average KL loss: 0.297446
Average total loss: 2.251694
tensor(-15.7120, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(1.3216e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.938290
Average KL loss: 0.297248
Average total loss: 2.235537
tensor(-15.7127, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(3.6782e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.952141
Average KL loss: 0.297056
Average total loss: 2.249197
tensor(-15.7135, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(8.0392e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.923528
Average KL loss: 0.296888
Average total loss: 2.220416
tensor(-15.7142, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-1.0268e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.922470
Average KL loss: 0.296699
Average total loss: 2.219169
tensor(-15.7149, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(4.5829e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.912816
Average KL loss: 0.296528
Average total loss: 2.209344
tensor(-15.7156, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-1.0134e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.911912
Average KL loss: 0.296359
Average total loss: 2.208270
tensor(-15.7163, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(8.8058e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.894697
Average KL loss: 0.296177
Average total loss: 2.190874
tensor(-15.7171, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(1.7826e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.876371
Average KL loss: 0.295952
Average total loss: 2.172324
tensor(-15.7178, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-9.2402e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.879148
Average KL loss: 0.295753
Average total loss: 2.174901
tensor(-15.7185, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-1.4494e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.873793
Average KL loss: 0.295582
Average total loss: 2.169375
tensor(-15.7192, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(3.1406e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.857974
Average KL loss: 0.295420
Average total loss: 2.153393
tensor(-15.7199, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(5.4002e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.864459
Average KL loss: 0.295265
Average total loss: 2.159724
tensor(-15.7206, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(2.5268e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.829167
Average KL loss: 0.295067
Average total loss: 2.124234
tensor(-15.7214, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-3.0849e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.829055
Average KL loss: 0.294875
Average total loss: 2.123930
tensor(-15.7221, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(1.2747e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.829792
Average KL loss: 0.294679
Average total loss: 2.124471
tensor(-15.7228, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(9.9501e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.804305
Average KL loss: 0.294489
Average total loss: 2.098793
tensor(-15.7235, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-2.0183e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.794504
Average KL loss: 0.294301
Average total loss: 2.088806
tensor(-15.7242, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(4.1311e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.793488
Average KL loss: 0.294123
Average total loss: 2.087610
tensor(-15.7249, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(1.5910e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.793510
Average KL loss: 0.293930
Average total loss: 2.087439
tensor(-15.7256, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(5.6399e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.779574
Average KL loss: 0.293754
Average total loss: 2.073328
tensor(-15.7264, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(4.3069e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.776391
Average KL loss: 0.293583
Average total loss: 2.069974
tensor(-15.7271, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(4.4163e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.762626
Average KL loss: 0.293442
Average total loss: 2.056068
tensor(-15.7278, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(4.8594e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.748354
Average KL loss: 0.293306
Average total loss: 2.041659
tensor(-15.7285, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(7.8845e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.757807
Average KL loss: 0.293130
Average total loss: 2.050937
tensor(-15.7292, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(-8.1772e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.751089
Average KL loss: 0.292985
Average total loss: 2.044073
tensor(-15.7299, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(7.0826e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.738418
Average KL loss: 0.292865
Average total loss: 2.031283
tensor(-15.7306, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(-5.6868e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.720573
Average KL loss: 0.292768
Average total loss: 2.013341
tensor(-15.7313, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(-2.1924e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.723403
Average KL loss: 0.292647
Average total loss: 2.016050
tensor(-15.7320, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(1.0537e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.734292
Average KL loss: 0.292545
Average total loss: 2.026837
tensor(-15.7328, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(2.5776e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.726802
Average KL loss: 0.292419
Average total loss: 2.019220
tensor(-15.7335, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(-1.7083e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.710811
Average KL loss: 0.292277
Average total loss: 2.003088
tensor(-15.7342, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(6.2656e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.707567
Average KL loss: 0.292131
Average total loss: 1.999698
tensor(-15.7349, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(-1.2542e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.721033
Average KL loss: 0.292017
Average total loss: 2.013049
tensor(-15.7356, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(1.3955e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.697503
Average KL loss: 0.291881
Average total loss: 1.989384
tensor(-15.7363, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(-2.6729e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.681061
Average KL loss: 0.291729
Average total loss: 1.972791
tensor(-15.7370, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(-9.5982e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.696451
Average KL loss: 0.291599
Average total loss: 1.988051
tensor(-15.7377, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(1.4459e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.683101
Average KL loss: 0.291496
Average total loss: 1.974597
tensor(-15.7384, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(1.3995e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.690297
Average KL loss: 0.291393
Average total loss: 1.981690
tensor(-15.7391, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(1.2402e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.666706
Average KL loss: 0.291256
Average total loss: 1.957962
tensor(-15.7398, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(4.6403e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.678492
Average KL loss: 0.291124
Average total loss: 1.969615
tensor(-15.7406, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-2.1685e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.665583
Average KL loss: 0.290988
Average total loss: 1.956571
tensor(-15.7413, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(6.5066e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.655694
Average KL loss: 0.290895
Average total loss: 1.946589
tensor(-15.7420, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-1.4247e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.657371
Average KL loss: 0.290810
Average total loss: 1.948181
tensor(-15.7427, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(3.7776e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.640306
Average KL loss: 0.290726
Average total loss: 1.931032
tensor(-15.7434, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-5.1081e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.649714
Average KL loss: 0.290626
Average total loss: 1.940339
tensor(-15.7441, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(4.5603e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.644766
Average KL loss: 0.290525
Average total loss: 1.935291
tensor(-15.7448, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(6.9806e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.652856
Average KL loss: 0.290401
Average total loss: 1.943257
tensor(-15.7455, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-4.5618e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.638245
Average KL loss: 0.290307
Average total loss: 1.928551
tensor(-15.7462, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(1.3745e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.635645
Average KL loss: 0.290213
Average total loss: 1.925858
tensor(-15.7469, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(4.8467e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.642816
Average KL loss: 0.290096
Average total loss: 1.932912
tensor(-15.7476, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-6.6049e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.637902
Average KL loss: 0.289986
Average total loss: 1.927888
tensor(-15.7483, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-1.8782e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.627199
Average KL loss: 0.289893
Average total loss: 1.917092
tensor(-15.7490, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-5.2654e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.626692
Average KL loss: 0.289816
Average total loss: 1.916508
tensor(-15.7497, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(5.6994e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.612327
Average KL loss: 0.289735
Average total loss: 1.902062
tensor(-15.7504, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(5.3121e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.610764
Average KL loss: 0.289638
Average total loss: 1.900402
tensor(-15.7512, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-1.7768e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.609934
Average KL loss: 0.289546
Average total loss: 1.899480
tensor(-15.7519, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-6.5848e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.610398
Average KL loss: 0.289446
Average total loss: 1.899844
tensor(-15.7526, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-8.6134e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.587271
Average KL loss: 0.289368
Average total loss: 1.876639
tensor(-15.7533, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-2.7195e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.592132
Average KL loss: 0.289256
Average total loss: 1.881388
tensor(-15.7540, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-5.8810e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 96
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 97
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 98
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 99
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 100
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 101
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 102
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 103
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 104
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 105
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 106
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 107
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 108
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 109
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 110
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 111
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 112
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 113
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 114
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 115
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 116
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 117
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 118
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 119
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 120
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 121
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 122
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 123
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 124
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 125
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 126
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 127
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 128
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 129
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 130
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 131
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 132
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 133
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 134
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 135
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 136
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     396 /  147456             (  0.27%) | total_pruned =  147060 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1218 /  147456             (  0.83%) | total_pruned =  146238 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3423 /  294912             (  1.16%) | total_pruned =  291489 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2779 /  589824             (  0.47%) | total_pruned =  587045 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     724 /   32768             (  2.21%) | total_pruned =   32044 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      41 /     256             ( 16.02%) | total_pruned =     215 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     713 /  589824             (  0.12%) | total_pruned =  589111 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     460 /  589824             (  0.08%) | total_pruned =  589364 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1613 / 1179648             (  0.14%) | total_pruned = 1178035 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2368 / 2359296             (  0.10%) | total_pruned = 2356928 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     102 /     512             ( 19.92%) | total_pruned =     410 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1264 /  131072             (  0.96%) | total_pruned =  129808 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     130 /     512             ( 25.39%) | total_pruned =     382 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      51 /     512             (  9.96%) | total_pruned =     461 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1882 / 2359296             (  0.08%) | total_pruned = 2357414 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      44 /     512             (  8.59%) | total_pruned =     468 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2902 / 2359296             (  0.12%) | total_pruned = 2356394 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
linear.weight        | nonzeros =    1224 /    5120             ( 23.91%) | total_pruned =    3896 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 45/100 Loss: 2.301910 Accuracy: 10.00 10.00 % Best test Accuracy: 10.02%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     720 / 1179648             (  0.06%) | total_pruned = 1178928 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2368 / 2359296             (  0.10%) | total_pruned = 2356928 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     102 /     512             ( 19.92%) | total_pruned =     410 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1264 /  131072             (  0.96%) | total_pruned =  129808 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     130 /     512             ( 25.39%) | total_pruned =     382 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      51 /     512             (  9.96%) | total_pruned =     461 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1882 / 2359296             (  0.08%) | total_pruned = 2357414 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      44 /     512             (  8.59%) | total_pruned =     468 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2902 / 2359296             (  0.12%) | total_pruned = 2356394 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
linear.weight        | nonzeros =    1224 /    5120             ( 23.91%) | total_pruned =    3896 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 34/100 Loss: 2.302728 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1155 / 2359296             (  0.05%) | total_pruned = 2358141 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      44 /     512             (  8.59%) | total_pruned =     468 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2902 / 2359296             (  0.12%) | total_pruned = 2356394 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
linear.weight        | nonzeros =    1224 /    5120             ( 23.91%) | total_pruned =    3896 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 34/100 Loss: 2.302297 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
