Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.2858e-06, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.427859
Average KL loss: 24.475323
Average total loss: 25.903181
tensor(-2.6658, device='cuda:0') tensor(1.0850, device='cuda:0') tensor(6.6712e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.975640
Average KL loss: 8.567855
Average total loss: 9.543495
tensor(-3.5107, device='cuda:0') tensor(1.4869, device='cuda:0') tensor(3.9976e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.801338
Average KL loss: 5.844136
Average total loss: 6.645473
tensor(-3.9914, device='cuda:0') tensor(1.6730, device='cuda:0') tensor(2.9207e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.703863
Average KL loss: 4.563307
Average total loss: 5.267170
tensor(-4.3441, device='cuda:0') tensor(1.8088, device='cuda:0') tensor(2.2821e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.644561
Average KL loss: 3.795215
Average total loss: 4.439776
tensor(-4.6254, device='cuda:0') tensor(1.9150, device='cuda:0') tensor(1.8507e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.614952
Average KL loss: 3.279434
Average total loss: 3.894386
tensor(-4.8601, device='cuda:0') tensor(2.0112, device='cuda:0') tensor(1.6363e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.578438
Average KL loss: 2.913968
Average total loss: 3.492406
tensor(-5.0623, device='cuda:0') tensor(2.0927, device='cuda:0') tensor(1.4859e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.566051
Average KL loss: 2.637422
Average total loss: 3.203473
tensor(-5.2404, device='cuda:0') tensor(2.1665, device='cuda:0') tensor(1.2723e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.529497
Average KL loss: 2.418420
Average total loss: 2.947917
tensor(-5.3997, device='cuda:0') tensor(2.2271, device='cuda:0') tensor(1.0465e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.519156
Average KL loss: 2.239531
Average total loss: 2.758687
tensor(-5.5441, device='cuda:0') tensor(2.2836, device='cuda:0') tensor(1.0450e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.496007
Average KL loss: 2.096308
Average total loss: 2.592315
tensor(-5.6761, device='cuda:0') tensor(2.3357, device='cuda:0') tensor(9.6836e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.479302
Average KL loss: 1.969824
Average total loss: 2.449126
tensor(-5.7983, device='cuda:0') tensor(2.3787, device='cuda:0') tensor(8.4402e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.465615
Average KL loss: 1.861752
Average total loss: 2.327366
tensor(-5.9116, device='cuda:0') tensor(2.4195, device='cuda:0') tensor(8.0558e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.450814
Average KL loss: 1.767076
Average total loss: 2.217891
tensor(-6.0176, device='cuda:0') tensor(2.4559, device='cuda:0') tensor(8.3224e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.447322
Average KL loss: 1.685801
Average total loss: 2.133123
tensor(-6.1174, device='cuda:0') tensor(2.4911, device='cuda:0') tensor(7.0562e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.431861
Average KL loss: 1.615296
Average total loss: 2.047156
tensor(-6.2116, device='cuda:0') tensor(2.5246, device='cuda:0') tensor(6.0537e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.420669
Average KL loss: 1.553363
Average total loss: 1.974031
tensor(-6.3007, device='cuda:0') tensor(2.5569, device='cuda:0') tensor(7.0796e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.416689
Average KL loss: 1.498437
Average total loss: 1.915125
tensor(-6.3856, device='cuda:0') tensor(2.5878, device='cuda:0') tensor(6.1953e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.404642
Average KL loss: 1.449803
Average total loss: 1.854445
tensor(-6.4666, device='cuda:0') tensor(2.6149, device='cuda:0') tensor(5.5246e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.394230
Average KL loss: 1.404339
Average total loss: 1.798569
tensor(-6.5439, device='cuda:0') tensor(2.6430, device='cuda:0') tensor(4.9728e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.376904
Average KL loss: 1.363245
Average total loss: 1.740149
tensor(-6.6182, device='cuda:0') tensor(2.6657, device='cuda:0') tensor(4.9316e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.370171
Average KL loss: 1.322524
Average total loss: 1.692696
tensor(-6.6895, device='cuda:0') tensor(2.6877, device='cuda:0') tensor(4.4392e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.363987
Average KL loss: 1.286941
Average total loss: 1.650929
tensor(-6.7579, device='cuda:0') tensor(2.7099, device='cuda:0') tensor(4.7026e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.356287
Average KL loss: 1.255571
Average total loss: 1.611858
tensor(-6.8239, device='cuda:0') tensor(2.7317, device='cuda:0') tensor(4.3283e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.351689
Average KL loss: 1.227037
Average total loss: 1.578726
tensor(-6.8876, device='cuda:0') tensor(2.7542, device='cuda:0') tensor(4.0771e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.341743
Average KL loss: 1.200454
Average total loss: 1.542197
tensor(-6.9495, device='cuda:0') tensor(2.7729, device='cuda:0') tensor(3.7488e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.329618
Average KL loss: 1.173905
Average total loss: 1.503524
tensor(-7.0093, device='cuda:0') tensor(2.7903, device='cuda:0') tensor(3.5093e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.327395
Average KL loss: 1.149217
Average total loss: 1.476612
tensor(-7.0674, device='cuda:0') tensor(2.8080, device='cuda:0') tensor(3.9677e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.318383
Average KL loss: 1.126751
Average total loss: 1.445134
tensor(-7.1237, device='cuda:0') tensor(2.8257, device='cuda:0') tensor(3.3608e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.311867
Average KL loss: 1.107716
Average total loss: 1.419583
tensor(-7.1783, device='cuda:0') tensor(2.8446, device='cuda:0') tensor(3.7653e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.314507
Average KL loss: 1.090124
Average total loss: 1.404631
tensor(-7.2316, device='cuda:0') tensor(2.8628, device='cuda:0') tensor(3.4663e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.301912
Average KL loss: 1.073376
Average total loss: 1.375288
tensor(-7.2835, device='cuda:0') tensor(2.8799, device='cuda:0') tensor(3.3503e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.295801
Average KL loss: 1.056760
Average total loss: 1.352561
tensor(-7.3343, device='cuda:0') tensor(2.8957, device='cuda:0') tensor(2.7143e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.288588
Average KL loss: 1.041291
Average total loss: 1.329879
tensor(-7.3838, device='cuda:0') tensor(2.9110, device='cuda:0') tensor(3.1174e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.279274
Average KL loss: 1.025672
Average total loss: 1.304947
tensor(-7.4323, device='cuda:0') tensor(2.9241, device='cuda:0') tensor(2.8696e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.276624
Average KL loss: 1.010266
Average total loss: 1.286890
tensor(-7.4796, device='cuda:0') tensor(2.9381, device='cuda:0') tensor(2.6649e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.276498
Average KL loss: 0.997071
Average total loss: 1.273569
tensor(-7.5259, device='cuda:0') tensor(2.9525, device='cuda:0') tensor(2.7341e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.264531
Average KL loss: 0.984780
Average total loss: 1.249311
tensor(-7.5713, device='cuda:0') tensor(2.9651, device='cuda:0') tensor(2.4011e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.261839
Average KL loss: 0.972334
Average total loss: 1.234173
tensor(-7.6157, device='cuda:0') tensor(2.9785, device='cuda:0') tensor(2.4761e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.255405
Average KL loss: 0.960781
Average total loss: 1.216186
tensor(-7.6592, device='cuda:0') tensor(2.9913, device='cuda:0') tensor(2.4778e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.250326
Average KL loss: 0.948849
Average total loss: 1.199175
tensor(-7.7019, device='cuda:0') tensor(3.0037, device='cuda:0') tensor(2.2954e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.242255
Average KL loss: 0.937579
Average total loss: 1.179835
tensor(-7.7439, device='cuda:0') tensor(3.0145, device='cuda:0') tensor(2.4111e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.242475
Average KL loss: 0.927196
Average total loss: 1.169671
tensor(-7.7852, device='cuda:0') tensor(3.0271, device='cuda:0') tensor(1.9568e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.237566
Average KL loss: 0.918372
Average total loss: 1.155938
tensor(-7.8257, device='cuda:0') tensor(3.0402, device='cuda:0') tensor(1.8565e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.231139
Average KL loss: 0.909178
Average total loss: 1.140317
tensor(-7.8657, device='cuda:0') tensor(3.0509, device='cuda:0') tensor(2.2341e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.230029
Average KL loss: 0.900959
Average total loss: 1.130988
tensor(-7.9050, device='cuda:0') tensor(3.0637, device='cuda:0') tensor(1.7827e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.222732
Average KL loss: 0.893591
Average total loss: 1.116323
tensor(-7.9436, device='cuda:0') tensor(3.0754, device='cuda:0') tensor(1.8981e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.219608
Average KL loss: 0.885450
Average total loss: 1.105058
tensor(-7.9816, device='cuda:0') tensor(3.0876, device='cuda:0') tensor(1.7393e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.218403
Average KL loss: 0.878401
Average total loss: 1.096804
tensor(-8.0191, device='cuda:0') tensor(3.0993, device='cuda:0') tensor(2.0889e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.214640
Average KL loss: 0.871187
Average total loss: 1.085827
tensor(-8.0560, device='cuda:0') tensor(3.1107, device='cuda:0') tensor(1.6254e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.208348
Average KL loss: 0.864896
Average total loss: 1.073245
tensor(-8.0924, device='cuda:0') tensor(3.1220, device='cuda:0') tensor(1.7457e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.206843
Average KL loss: 0.858217
Average total loss: 1.065060
tensor(-8.1284, device='cuda:0') tensor(3.1326, device='cuda:0') tensor(1.8687e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.203412
Average KL loss: 0.852110
Average total loss: 1.055522
tensor(-8.1639, device='cuda:0') tensor(3.1439, device='cuda:0') tensor(1.4495e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.195823
Average KL loss: 0.846795
Average total loss: 1.042618
tensor(-8.1989, device='cuda:0') tensor(3.1554, device='cuda:0') tensor(1.6222e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.190919
Average KL loss: 0.841551
Average total loss: 1.032471
tensor(-8.2334, device='cuda:0') tensor(3.1658, device='cuda:0') tensor(1.6198e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.191086
Average KL loss: 0.835999
Average total loss: 1.027085
tensor(-8.2675, device='cuda:0') tensor(3.1767, device='cuda:0') tensor(1.7072e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.185522
Average KL loss: 0.829733
Average total loss: 1.015255
tensor(-8.3013, device='cuda:0') tensor(3.1853, device='cuda:0') tensor(1.4239e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.182728
Average KL loss: 0.824259
Average total loss: 1.006987
tensor(-8.3345, device='cuda:0') tensor(3.1961, device='cuda:0') tensor(1.5898e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.176660
Average KL loss: 0.819025
Average total loss: 0.995686
tensor(-8.3674, device='cuda:0') tensor(3.2054, device='cuda:0') tensor(1.6058e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.175863
Average KL loss: 0.814106
Average total loss: 0.989969
tensor(-8.4001, device='cuda:0') tensor(3.2155, device='cuda:0') tensor(1.1990e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.169908
Average KL loss: 0.809097
Average total loss: 0.979004
tensor(-8.4323, device='cuda:0') tensor(3.2246, device='cuda:0') tensor(1.3994e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.167881
Average KL loss: 0.804506
Average total loss: 0.972387
tensor(-8.4641, device='cuda:0') tensor(3.2351, device='cuda:0') tensor(1.1096e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.167963
Average KL loss: 0.800733
Average total loss: 0.968697
tensor(-8.4956, device='cuda:0') tensor(3.2458, device='cuda:0') tensor(1.1753e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.164849
Average KL loss: 0.796947
Average total loss: 0.961797
tensor(-8.5269, device='cuda:0') tensor(3.2558, device='cuda:0') tensor(1.2795e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.164058
Average KL loss: 0.792719
Average total loss: 0.956777
tensor(-8.5577, device='cuda:0') tensor(3.2659, device='cuda:0') tensor(1.3105e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.159488
Average KL loss: 0.789211
Average total loss: 0.948699
tensor(-8.5883, device='cuda:0') tensor(3.2756, device='cuda:0') tensor(1.2144e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.151825
Average KL loss: 0.785248
Average total loss: 0.937074
tensor(-8.6185, device='cuda:0') tensor(3.2841, device='cuda:0') tensor(1.2407e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.154453
Average KL loss: 0.781465
Average total loss: 0.935918
tensor(-8.6486, device='cuda:0') tensor(3.2933, device='cuda:0') tensor(1.2391e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.149175
Average KL loss: 0.778141
Average total loss: 0.927316
tensor(-8.6784, device='cuda:0') tensor(3.3025, device='cuda:0') tensor(1.2600e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.147331
Average KL loss: 0.774754
Average total loss: 0.922085
tensor(-8.7079, device='cuda:0') tensor(3.3115, device='cuda:0') tensor(9.3331e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.142825
Average KL loss: 0.771560
Average total loss: 0.914385
tensor(-8.7371, device='cuda:0') tensor(3.3209, device='cuda:0') tensor(1.0405e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.143828
Average KL loss: 0.768036
Average total loss: 0.911864
tensor(-8.7661, device='cuda:0') tensor(3.3302, device='cuda:0') tensor(9.7146e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.139256
Average KL loss: 0.765119
Average total loss: 0.904375
tensor(-8.7947, device='cuda:0') tensor(3.3399, device='cuda:0') tensor(1.1350e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.138984
Average KL loss: 0.761811
Average total loss: 0.900795
tensor(-8.8233, device='cuda:0') tensor(3.3494, device='cuda:0') tensor(1.0335e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.136708
Average KL loss: 0.758446
Average total loss: 0.895154
tensor(-8.8516, device='cuda:0') tensor(3.3574, device='cuda:0') tensor(1.1472e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.135392
Average KL loss: 0.755418
Average total loss: 0.890810
tensor(-8.8797, device='cuda:0') tensor(3.3664, device='cuda:0') tensor(9.1829e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.131555
Average KL loss: 0.752769
Average total loss: 0.884324
tensor(-8.9076, device='cuda:0') tensor(3.3747, device='cuda:0') tensor(9.8631e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.130298
Average KL loss: 0.749783
Average total loss: 0.880082
tensor(-8.9354, device='cuda:0') tensor(3.3830, device='cuda:0') tensor(1.1978e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.128878
Average KL loss: 0.747109
Average total loss: 0.875987
tensor(-8.9629, device='cuda:0') tensor(3.3916, device='cuda:0') tensor(9.0632e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.128389
Average KL loss: 0.743997
Average total loss: 0.872386
tensor(-8.9903, device='cuda:0') tensor(3.3995, device='cuda:0') tensor(8.4263e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.123650
Average KL loss: 0.741267
Average total loss: 0.864916
tensor(-9.0173, device='cuda:0') tensor(3.4084, device='cuda:0') tensor(9.9939e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.122917
Average KL loss: 0.738660
Average total loss: 0.861578
tensor(-9.0442, device='cuda:0') tensor(3.4167, device='cuda:0') tensor(7.2708e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.121657
Average KL loss: 0.736074
Average total loss: 0.857731
tensor(-9.0709, device='cuda:0') tensor(3.4251, device='cuda:0') tensor(8.8201e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.119503
Average KL loss: 0.733479
Average total loss: 0.852981
tensor(-9.0975, device='cuda:0') tensor(3.4330, device='cuda:0') tensor(8.6908e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.116645
Average KL loss: 0.730243
Average total loss: 0.846888
tensor(-9.1239, device='cuda:0') tensor(3.4400, device='cuda:0') tensor(8.8216e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.115904
Average KL loss: 0.727561
Average total loss: 0.843465
tensor(-9.1502, device='cuda:0') tensor(3.4477, device='cuda:0') tensor(7.5549e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.111937
Average KL loss: 0.725231
Average total loss: 0.837167
tensor(-9.1762, device='cuda:0') tensor(3.4548, device='cuda:0') tensor(8.4730e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.113022
Average KL loss: 0.722908
Average total loss: 0.835929
tensor(-9.2021, device='cuda:0') tensor(3.4624, device='cuda:0') tensor(9.1949e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.107388
Average KL loss: 0.720558
Average total loss: 0.827946
tensor(-9.2279, device='cuda:0') tensor(3.4696, device='cuda:0') tensor(7.9791e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.109031
Average KL loss: 0.718294
Average total loss: 0.827325
tensor(-9.2534, device='cuda:0') tensor(3.4773, device='cuda:0') tensor(6.3037e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.107041
Average KL loss: 0.716130
Average total loss: 0.823171
tensor(-9.2788, device='cuda:0') tensor(3.4848, device='cuda:0') tensor(6.8442e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.104107
Average KL loss: 0.713867
Average total loss: 0.817974
tensor(-9.3040, device='cuda:0') tensor(3.4927, device='cuda:0') tensor(6.1214e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.101475
Average KL loss: 0.711787
Average total loss: 0.813262
tensor(-9.3291, device='cuda:0') tensor(3.5003, device='cuda:0') tensor(6.9876e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.100394
Average KL loss: 0.709635
Average total loss: 0.810029
tensor(-9.3540, device='cuda:0') tensor(3.5080, device='cuda:0') tensor(7.0000e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.098241
Average KL loss: 0.707697
Average total loss: 0.805937
tensor(-9.3788, device='cuda:0') tensor(3.5151, device='cuda:0') tensor(5.7345e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.099468
Average KL loss: 0.705778
Average total loss: 0.805246
tensor(-9.4035, device='cuda:0') tensor(3.5225, device='cuda:0') tensor(8.9757e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.099585
Average KL loss: 0.703904
Average total loss: 0.803488
tensor(-9.4280, device='cuda:0') tensor(3.5292, device='cuda:0') tensor(6.5078e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.096131
Average KL loss: 0.701818
Average total loss: 0.797949
tensor(-9.4525, device='cuda:0') tensor(3.5357, device='cuda:0') tensor(5.5981e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.094523
Average KL loss: 0.699460
Average total loss: 0.793983
tensor(-9.4768, device='cuda:0') tensor(3.5420, device='cuda:0') tensor(6.3383e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.094032
Average KL loss: 0.697608
Average total loss: 0.791640
tensor(-9.5009, device='cuda:0') tensor(3.5492, device='cuda:0') tensor(5.3630e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.093307
Average KL loss: 0.695714
Average total loss: 0.789021
tensor(-9.5249, device='cuda:0') tensor(3.5559, device='cuda:0') tensor(5.5832e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.092910
Average KL loss: 0.694028
Average total loss: 0.786938
tensor(-9.5488, device='cuda:0') tensor(3.5634, device='cuda:0') tensor(5.7115e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.089384
Average KL loss: 0.692420
Average total loss: 0.781804
tensor(-9.5726, device='cuda:0') tensor(3.5700, device='cuda:0') tensor(5.2471e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.087852
Average KL loss: 0.690526
Average total loss: 0.778379
tensor(-9.5963, device='cuda:0') tensor(3.5761, device='cuda:0') tensor(5.9356e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.088251
Average KL loss: 0.688524
Average total loss: 0.776775
tensor(-9.6199, device='cuda:0') tensor(3.5824, device='cuda:0') tensor(5.8424e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.085647
Average KL loss: 0.686745
Average total loss: 0.772392
tensor(-9.6434, device='cuda:0') tensor(3.5884, device='cuda:0') tensor(5.0897e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.086856
Average KL loss: 0.684676
Average total loss: 0.771531
tensor(-9.6667, device='cuda:0') tensor(3.5952, device='cuda:0') tensor(7.5511e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.084987
Average KL loss: 0.683173
Average total loss: 0.768160
tensor(-9.6899, device='cuda:0') tensor(3.6019, device='cuda:0') tensor(6.6901e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.084114
Average KL loss: 0.681413
Average total loss: 0.765527
tensor(-9.7130, device='cuda:0') tensor(3.6081, device='cuda:0') tensor(4.9751e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.085540
Average KL loss: 0.679477
Average total loss: 0.765017
tensor(-9.7360, device='cuda:0') tensor(3.6146, device='cuda:0') tensor(6.0626e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.083101
Average KL loss: 0.677741
Average total loss: 0.760842
tensor(-9.7589, device='cuda:0') tensor(3.6202, device='cuda:0') tensor(4.6878e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.081298
Average KL loss: 0.676115
Average total loss: 0.757414
tensor(-9.7817, device='cuda:0') tensor(3.6262, device='cuda:0') tensor(5.9859e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.080489
Average KL loss: 0.674291
Average total loss: 0.754780
tensor(-9.8044, device='cuda:0') tensor(3.6320, device='cuda:0') tensor(5.5357e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.079414
Average KL loss: 0.672820
Average total loss: 0.752234
tensor(-9.8270, device='cuda:0') tensor(3.6372, device='cuda:0') tensor(4.9812e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.080172
Average KL loss: 0.671324
Average total loss: 0.751495
tensor(-9.8495, device='cuda:0') tensor(3.6431, device='cuda:0') tensor(4.6059e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.079787
Average KL loss: 0.669669
Average total loss: 0.749456
tensor(-9.8719, device='cuda:0') tensor(3.6484, device='cuda:0') tensor(3.7666e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.079310
Average KL loss: 0.667865
Average total loss: 0.747174
tensor(-9.8943, device='cuda:0') tensor(3.6542, device='cuda:0') tensor(4.2543e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.078433
Average KL loss: 0.666438
Average total loss: 0.744871
tensor(-9.9166, device='cuda:0') tensor(3.6589, device='cuda:0') tensor(5.1719e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.076218
Average KL loss: 0.664610
Average total loss: 0.740828
tensor(-9.9388, device='cuda:0') tensor(3.6635, device='cuda:0') tensor(4.1103e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.074962
Average KL loss: 0.662954
Average total loss: 0.737916
tensor(-9.9608, device='cuda:0') tensor(3.6689, device='cuda:0') tensor(3.9024e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.074371
Average KL loss: 0.661423
Average total loss: 0.735795
tensor(-9.9828, device='cuda:0') tensor(3.6739, device='cuda:0') tensor(5.6894e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.073134
Average KL loss: 0.659597
Average total loss: 0.732732
tensor(-10.0046, device='cuda:0') tensor(3.6791, device='cuda:0') tensor(3.0541e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.073931
Average KL loss: 0.658471
Average total loss: 0.732402
tensor(-10.0263, device='cuda:0') tensor(3.6849, device='cuda:0') tensor(4.6222e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.072937
Average KL loss: 0.656972
Average total loss: 0.729910
tensor(-10.0480, device='cuda:0') tensor(3.6888, device='cuda:0') tensor(4.9806e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.071728
Average KL loss: 0.655414
Average total loss: 0.727141
tensor(-10.0696, device='cuda:0') tensor(3.6935, device='cuda:0') tensor(3.8203e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.070955
Average KL loss: 0.653989
Average total loss: 0.724944
tensor(-10.0911, device='cuda:0') tensor(3.6975, device='cuda:0') tensor(4.7765e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.069796
Average KL loss: 0.652417
Average total loss: 0.722213
tensor(-10.1124, device='cuda:0') tensor(3.7022, device='cuda:0') tensor(3.8939e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.070490
Average KL loss: 0.650955
Average total loss: 0.721445
tensor(-10.1336, device='cuda:0') tensor(3.7069, device='cuda:0') tensor(3.7164e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.068646
Average KL loss: 0.649660
Average total loss: 0.718306
tensor(-10.1547, device='cuda:0') tensor(3.7116, device='cuda:0') tensor(4.7299e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.068314
Average KL loss: 0.648208
Average total loss: 0.716522
tensor(-10.1758, device='cuda:0') tensor(3.7160, device='cuda:0') tensor(3.5691e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.067383
Average KL loss: 0.647071
Average total loss: 0.714455
tensor(-10.1968, device='cuda:0') tensor(3.7204, device='cuda:0') tensor(3.8840e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.068792
Average KL loss: 0.645799
Average total loss: 0.714592
tensor(-10.2177, device='cuda:0') tensor(3.7255, device='cuda:0') tensor(3.7164e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.067488
Average KL loss: 0.644724
Average total loss: 0.712212
tensor(-10.2386, device='cuda:0') tensor(3.7302, device='cuda:0') tensor(4.4974e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.066441
Average KL loss: 0.643047
Average total loss: 0.709488
tensor(-10.2594, device='cuda:0') tensor(3.7339, device='cuda:0') tensor(3.4156e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.067509
Average KL loss: 0.641596
Average total loss: 0.709105
tensor(-10.2800, device='cuda:0') tensor(3.7384, device='cuda:0') tensor(4.3881e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.068024
Average KL loss: 0.640653
Average total loss: 0.708676
tensor(-10.3006, device='cuda:0') tensor(3.7430, device='cuda:0') tensor(2.4641e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.066715
Average KL loss: 0.639812
Average total loss: 0.706526
tensor(-10.3212, device='cuda:0') tensor(3.7478, device='cuda:0') tensor(4.0578e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.063916
Average KL loss: 0.638820
Average total loss: 0.702736
tensor(-10.3416, device='cuda:0') tensor(3.7518, device='cuda:0') tensor(3.9978e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.063877
Average KL loss: 0.637564
Average total loss: 0.701441
tensor(-10.3619, device='cuda:0') tensor(3.7551, device='cuda:0') tensor(3.1251e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.064081
Average KL loss: 0.636390
Average total loss: 0.700471
tensor(-10.3822, device='cuda:0') tensor(3.7590, device='cuda:0') tensor(2.8793e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.064074
Average KL loss: 0.635387
Average total loss: 0.699461
tensor(-10.4023, device='cuda:0') tensor(3.7633, device='cuda:0') tensor(3.1435e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.064951
Average KL loss: 0.634385
Average total loss: 0.699336
tensor(-10.4224, device='cuda:0') tensor(3.7674, device='cuda:0') tensor(2.9993e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.063469
Average KL loss: 0.633283
Average total loss: 0.696752
tensor(-10.4424, device='cuda:0') tensor(3.7717, device='cuda:0') tensor(3.1270e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.063294
Average KL loss: 0.632554
Average total loss: 0.695848
tensor(-10.4624, device='cuda:0') tensor(3.7760, device='cuda:0') tensor(3.3336e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.062040
Average KL loss: 0.631745
Average total loss: 0.693785
tensor(-10.4822, device='cuda:0') tensor(3.7798, device='cuda:0') tensor(1.7561e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.060494
Average KL loss: 0.630566
Average total loss: 0.691060
tensor(-10.5020, device='cuda:0') tensor(3.7825, device='cuda:0') tensor(3.1267e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.061363
Average KL loss: 0.629441
Average total loss: 0.690804
tensor(-10.5218, device='cuda:0') tensor(3.7855, device='cuda:0') tensor(3.0090e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.061381
Average KL loss: 0.628633
Average total loss: 0.690014
tensor(-10.5414, device='cuda:0') tensor(3.7897, device='cuda:0') tensor(2.6519e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.060242
Average KL loss: 0.627933
Average total loss: 0.688175
tensor(-10.5610, device='cuda:0') tensor(3.7926, device='cuda:0') tensor(2.8977e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.060606
Average KL loss: 0.626629
Average total loss: 0.687235
tensor(-10.5805, device='cuda:0') tensor(3.7957, device='cuda:0') tensor(2.6826e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.060138
Average KL loss: 0.625696
Average total loss: 0.685834
tensor(-10.5999, device='cuda:0') tensor(3.7987, device='cuda:0') tensor(2.6268e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.060140
Average KL loss: 0.624781
Average total loss: 0.684921
tensor(-10.6192, device='cuda:0') tensor(3.8016, device='cuda:0') tensor(2.8269e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.058969
Average KL loss: 0.624016
Average total loss: 0.682984
tensor(-10.6385, device='cuda:0') tensor(3.8044, device='cuda:0') tensor(2.7015e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.058435
Average KL loss: 0.623122
Average total loss: 0.681557
tensor(-10.6576, device='cuda:0') tensor(3.8074, device='cuda:0') tensor(1.9974e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.058734
Average KL loss: 0.622297
Average total loss: 0.681030
tensor(-10.6767, device='cuda:0') tensor(3.8100, device='cuda:0') tensor(2.5193e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.056751
Average KL loss: 0.621328
Average total loss: 0.678078
tensor(-10.6957, device='cuda:0') tensor(3.8119, device='cuda:0') tensor(2.0492e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.057878
Average KL loss: 0.620432
Average total loss: 0.678310
tensor(-10.7146, device='cuda:0') tensor(3.8148, device='cuda:0') tensor(2.8917e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.056382
Average KL loss: 0.619759
Average total loss: 0.676141
tensor(-10.7334, device='cuda:0') tensor(3.8171, device='cuda:0') tensor(2.5462e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.056544
Average KL loss: 0.618788
Average total loss: 0.675332
tensor(-10.7523, device='cuda:0') tensor(3.8194, device='cuda:0') tensor(2.1878e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.056278
Average KL loss: 0.617916
Average total loss: 0.674194
tensor(-10.7710, device='cuda:0') tensor(3.8216, device='cuda:0') tensor(1.5195e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.056448
Average KL loss: 0.617003
Average total loss: 0.673450
tensor(-10.7896, device='cuda:0') tensor(3.8242, device='cuda:0') tensor(1.9176e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.054865
Average KL loss: 0.616004
Average total loss: 0.670869
tensor(-10.8082, device='cuda:0') tensor(3.8261, device='cuda:0') tensor(2.5714e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.055446
Average KL loss: 0.614899
Average total loss: 0.670344
tensor(-10.8266, device='cuda:0') tensor(3.8277, device='cuda:0') tensor(2.3940e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.054867
Average KL loss: 0.613993
Average total loss: 0.668860
tensor(-10.8451, device='cuda:0') tensor(3.8293, device='cuda:0') tensor(2.4847e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.054687
Average KL loss: 0.612984
Average total loss: 0.667672
tensor(-10.8634, device='cuda:0') tensor(3.8311, device='cuda:0') tensor(2.0288e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.054721
Average KL loss: 0.612128
Average total loss: 0.666849
tensor(-10.8816, device='cuda:0') tensor(3.8330, device='cuda:0') tensor(2.3911e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.055689
Average KL loss: 0.611332
Average total loss: 0.667021
tensor(-10.8998, device='cuda:0') tensor(3.8351, device='cuda:0') tensor(2.0960e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.054203
Average KL loss: 0.610766
Average total loss: 0.664969
tensor(-10.9178, device='cuda:0') tensor(3.8375, device='cuda:0') tensor(2.2535e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.055127
Average KL loss: 0.610043
Average total loss: 0.665170
tensor(-10.9359, device='cuda:0') tensor(3.8395, device='cuda:0') tensor(2.2266e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.053741
Average KL loss: 0.609363
Average total loss: 0.663104
tensor(-10.9538, device='cuda:0') tensor(3.8409, device='cuda:0') tensor(1.7414e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.053889
Average KL loss: 0.608788
Average total loss: 0.662677
tensor(-10.9717, device='cuda:0') tensor(3.8421, device='cuda:0') tensor(1.3238e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.054397
Average KL loss: 0.608170
Average total loss: 0.662567
tensor(-10.9894, device='cuda:0') tensor(3.8441, device='cuda:0') tensor(2.5522e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.053472
Average KL loss: 0.607807
Average total loss: 0.661279
tensor(-11.0072, device='cuda:0') tensor(3.8453, device='cuda:0') tensor(1.2427e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.053296
Average KL loss: 0.607094
Average total loss: 0.660390
tensor(-11.0248, device='cuda:0') tensor(3.8475, device='cuda:0') tensor(2.4546e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.053663
Average KL loss: 0.606518
Average total loss: 0.660181
tensor(-11.0423, device='cuda:0') tensor(3.8491, device='cuda:0') tensor(2.4573e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.052992
Average KL loss: 0.605896
Average total loss: 0.658888
tensor(-11.0599, device='cuda:0') tensor(3.8494, device='cuda:0') tensor(2.0498e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.052148
Average KL loss: 0.605161
Average total loss: 0.657309
tensor(-11.0773, device='cuda:0') tensor(3.8502, device='cuda:0') tensor(2.0731e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.050332
Average KL loss: 0.604346
Average total loss: 0.654678
tensor(-11.0947, device='cuda:0') tensor(3.8503, device='cuda:0') tensor(2.2147e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.050750
Average KL loss: 0.603316
Average total loss: 0.654067
tensor(-11.1120, device='cuda:0') tensor(3.8506, device='cuda:0') tensor(1.9881e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.051738
Average KL loss: 0.602512
Average total loss: 0.654250
tensor(-11.1292, device='cuda:0') tensor(3.8513, device='cuda:0') tensor(1.9192e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.052153
Average KL loss: 0.601699
Average total loss: 0.653852
tensor(-11.1463, device='cuda:0') tensor(3.8519, device='cuda:0') tensor(1.5695e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.051168
Average KL loss: 0.601068
Average total loss: 0.652236
tensor(-11.1634, device='cuda:0') tensor(3.8522, device='cuda:0') tensor(1.4442e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.051038
Average KL loss: 0.600485
Average total loss: 0.651523
tensor(-11.1804, device='cuda:0') tensor(3.8524, device='cuda:0') tensor(1.4501e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.049823
Average KL loss: 0.599672
Average total loss: 0.649495
tensor(-11.1973, device='cuda:0') tensor(3.8529, device='cuda:0') tensor(1.5218e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.049836
Average KL loss: 0.598894
Average total loss: 0.648730
tensor(-11.2142, device='cuda:0') tensor(3.8524, device='cuda:0') tensor(1.4604e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.049819
Average KL loss: 0.597987
Average total loss: 0.647806
tensor(-11.2310, device='cuda:0') tensor(3.8522, device='cuda:0') tensor(1.6903e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.050187
Average KL loss: 0.597276
Average total loss: 0.647463
tensor(-11.2477, device='cuda:0') tensor(3.8524, device='cuda:0') tensor(1.5458e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.049218
Average KL loss: 0.596622
Average total loss: 0.645840
tensor(-11.2643, device='cuda:0') tensor(3.8521, device='cuda:0') tensor(2.5535e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.050404
Average KL loss: 0.596015
Average total loss: 0.646419
tensor(-11.2809, device='cuda:0') tensor(3.8521, device='cuda:0') tensor(1.5688e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.050216
Average KL loss: 0.595344
Average total loss: 0.645561
tensor(-11.2974, device='cuda:0') tensor(3.8516, device='cuda:0') tensor(1.4328e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.049468
Average KL loss: 0.594678
Average total loss: 0.644146
tensor(-11.3138, device='cuda:0') tensor(3.8516, device='cuda:0') tensor(1.1293e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.048860
Average KL loss: 0.594163
Average total loss: 0.643023
tensor(-11.3302, device='cuda:0') tensor(3.8516, device='cuda:0') tensor(1.4296e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.049948
Average KL loss: 0.593515
Average total loss: 0.643463
tensor(-11.3464, device='cuda:0') tensor(3.8510, device='cuda:0') tensor(1.6543e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.049272
Average KL loss: 0.593029
Average total loss: 0.642300
tensor(-11.3627, device='cuda:0') tensor(3.8504, device='cuda:0') tensor(1.2376e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.050145
Average KL loss: 0.592558
Average total loss: 0.642703
tensor(-11.3787, device='cuda:0') tensor(3.8503, device='cuda:0') tensor(1.8667e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.048604
Average KL loss: 0.591985
Average total loss: 0.640589
tensor(-11.3948, device='cuda:0') tensor(3.8494, device='cuda:0') tensor(1.2072e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.048510
Average KL loss: 0.591197
Average total loss: 0.639706
tensor(-11.4107, device='cuda:0') tensor(3.8486, device='cuda:0') tensor(1.1957e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.049269
Average KL loss: 0.590502
Average total loss: 0.639771
tensor(-11.4266, device='cuda:0') tensor(3.8479, device='cuda:0') tensor(1.1664e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.048033
Average KL loss: 0.589971
Average total loss: 0.638005
tensor(-11.4425, device='cuda:0') tensor(3.8470, device='cuda:0') tensor(1.8186e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.048185
Average KL loss: 0.589490
Average total loss: 0.637675
 Percentile value: -10.876570701599121
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =    1709 /    1728             ( 98.90%) | total_pruned =      19 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   33493 /   36864             ( 90.86%) | total_pruned =    3371 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   33661 /   36864             ( 91.31%) | total_pruned =    3203 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   33167 /   36864             ( 89.97%) | total_pruned =    3697 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   32435 /   36864             ( 87.99%) | total_pruned =    4429 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   65142 /   73728             ( 88.35%) | total_pruned =    8586 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  122581 /  147456             ( 83.13%) | total_pruned =   24875 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7964 /    8192             ( 97.22%) | total_pruned =     228 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  117706 /  147456             ( 79.82%) | total_pruned =   29750 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  115670 /  147456             ( 78.44%) | total_pruned =   31786 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  237147 /  294912             ( 80.41%) | total_pruned =   57765 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  436121 /  589824             ( 73.94%) | total_pruned =  153703 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   30064 /   32768             ( 91.75%) | total_pruned =    2704 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  367156 /  589824             ( 62.25%) | total_pruned =  222668 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  356295 /  589824             ( 60.41%) | total_pruned =  233529 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  790596 / 1179648             ( 67.02%) | total_pruned =  389052 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1133431 / 2359296             ( 48.04%) | total_pruned = 1225865 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  106214 /  131072             ( 81.03%) | total_pruned =   24858 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  819742 / 2359296             ( 34.75%) | total_pruned = 1539554 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  734388 / 2359296             ( 31.13%) | total_pruned = 1624908 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 37/100 Loss: 0.000004 Accuracy: 86.65 100.00 % Best test Accuracy: 86.97%
tensor(-11.4582, device='cuda:0') tensor(3.8461, device='cuda:0') tensor(2.5211e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.194437
Average KL loss: 0.579915
Average total loss: 0.774353
tensor(-11.5800, device='cuda:0') tensor(3.0912, device='cuda:0') tensor(-3.2805e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.202192
Average KL loss: 0.566986
Average total loss: 0.769177
tensor(-11.6602, device='cuda:0') tensor(2.7417, device='cuda:0') tensor(-2.4775e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.219489
Average KL loss: 0.555787
Average total loss: 0.775276
tensor(-11.7240, device='cuda:0') tensor(2.5429, device='cuda:0') tensor(-3.2376e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.224019
Average KL loss: 0.547869
Average total loss: 0.771889
tensor(-11.7787, device='cuda:0') tensor(2.4112, device='cuda:0') tensor(-4.9099e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.225765
Average KL loss: 0.541849
Average total loss: 0.767614
tensor(-11.8273, device='cuda:0') tensor(2.3182, device='cuda:0') tensor(-6.8496e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.222931
Average KL loss: 0.537357
Average total loss: 0.760289
tensor(-11.8715, device='cuda:0') tensor(2.2483, device='cuda:0') tensor(-4.4327e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.216410
Average KL loss: 0.533714
Average total loss: 0.750124
tensor(-11.9122, device='cuda:0') tensor(2.1947, device='cuda:0') tensor(-7.6244e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.211662
Average KL loss: 0.530506
Average total loss: 0.742168
tensor(-11.9501, device='cuda:0') tensor(2.1526, device='cuda:0') tensor(-4.8730e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.205398
Average KL loss: 0.528033
Average total loss: 0.733431
tensor(-11.9857, device='cuda:0') tensor(2.1177, device='cuda:0') tensor(-3.6455e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.199144
Average KL loss: 0.525671
Average total loss: 0.724816
tensor(-12.0193, device='cuda:0') tensor(2.0902, device='cuda:0') tensor(-3.4433e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.194546
Average KL loss: 0.523730
Average total loss: 0.718275
tensor(-12.0513, device='cuda:0') tensor(2.0661, device='cuda:0') tensor(-2.8712e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.189228
Average KL loss: 0.521655
Average total loss: 0.710883
tensor(-12.0818, device='cuda:0') tensor(2.0471, device='cuda:0') tensor(-1.4826e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.189096
Average KL loss: 0.520229
Average total loss: 0.709325
tensor(-12.1109, device='cuda:0') tensor(2.0309, device='cuda:0') tensor(-3.1122e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.183495
Average KL loss: 0.518879
Average total loss: 0.702375
tensor(-12.1389, device='cuda:0') tensor(2.0178, device='cuda:0') tensor(-9.5448e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.181521
Average KL loss: 0.517810
Average total loss: 0.699331
tensor(-12.1657, device='cuda:0') tensor(2.0074, device='cuda:0') tensor(-2.0446e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.172459
Average KL loss: 0.516529
Average total loss: 0.688988
tensor(-12.1916, device='cuda:0') tensor(1.9988, device='cuda:0') tensor(-4.5081e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.167734
Average KL loss: 0.515450
Average total loss: 0.683184
tensor(-12.2167, device='cuda:0') tensor(1.9909, device='cuda:0') tensor(-1.9302e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.165616
Average KL loss: 0.514306
Average total loss: 0.679921
tensor(-12.2409, device='cuda:0') tensor(1.9848, device='cuda:0') tensor(-7.0218e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.163467
Average KL loss: 0.513400
Average total loss: 0.676867
tensor(-12.2643, device='cuda:0') tensor(1.9799, device='cuda:0') tensor(-6.1192e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.158696
Average KL loss: 0.512479
Average total loss: 0.671175
tensor(-12.2870, device='cuda:0') tensor(1.9756, device='cuda:0') tensor(-3.2676e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.153053
Average KL loss: 0.511556
Average total loss: 0.664609
tensor(-12.3091, device='cuda:0') tensor(1.9728, device='cuda:0') tensor(2.1384e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.151204
Average KL loss: 0.510677
Average total loss: 0.661881
tensor(-12.3306, device='cuda:0') tensor(1.9700, device='cuda:0') tensor(-1.5128e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.150051
Average KL loss: 0.509683
Average total loss: 0.659734
tensor(-12.3515, device='cuda:0') tensor(1.9676, device='cuda:0') tensor(-1.2126e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.149304
Average KL loss: 0.508721
Average total loss: 0.658025
tensor(-12.3718, device='cuda:0') tensor(1.9671, device='cuda:0') tensor(-3.4583e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.142808
Average KL loss: 0.507985
Average total loss: 0.650793
tensor(-12.3917, device='cuda:0') tensor(1.9664, device='cuda:0') tensor(-1.3289e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.142076
Average KL loss: 0.507265
Average total loss: 0.649341
tensor(-12.4111, device='cuda:0') tensor(1.9663, device='cuda:0') tensor(-1.8368e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.142165
Average KL loss: 0.506467
Average total loss: 0.648633
tensor(-12.4301, device='cuda:0') tensor(1.9664, device='cuda:0') tensor(-1.3464e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.137226
Average KL loss: 0.505667
Average total loss: 0.642893
tensor(-12.4487, device='cuda:0') tensor(1.9665, device='cuda:0') tensor(2.1920e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.135893
Average KL loss: 0.504937
Average total loss: 0.640830
tensor(-12.4668, device='cuda:0') tensor(1.9672, device='cuda:0') tensor(-2.7112e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.133659
Average KL loss: 0.504191
Average total loss: 0.637850
tensor(-12.4845, device='cuda:0') tensor(1.9685, device='cuda:0') tensor(-4.4477e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.131860
Average KL loss: 0.503402
Average total loss: 0.635262
tensor(-12.5020, device='cuda:0') tensor(1.9694, device='cuda:0') tensor(-9.4041e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.132371
Average KL loss: 0.502585
Average total loss: 0.634956
tensor(-12.5190, device='cuda:0') tensor(1.9708, device='cuda:0') tensor(-2.3333e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.129127
Average KL loss: 0.501849
Average total loss: 0.630975
tensor(-12.5357, device='cuda:0') tensor(1.9724, device='cuda:0') tensor(2.8663e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.127943
Average KL loss: 0.501216
Average total loss: 0.629158
tensor(-12.5521, device='cuda:0') tensor(1.9739, device='cuda:0') tensor(-1.0876e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.124961
Average KL loss: 0.500606
Average total loss: 0.625567
tensor(-12.5682, device='cuda:0') tensor(1.9759, device='cuda:0') tensor(-8.9250e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.124623
Average KL loss: 0.499908
Average total loss: 0.624531
tensor(-12.5840, device='cuda:0') tensor(1.9776, device='cuda:0') tensor(-9.7278e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.123354
Average KL loss: 0.499398
Average total loss: 0.622752
tensor(-12.5995, device='cuda:0') tensor(1.9803, device='cuda:0') tensor(-1.5234e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.122378
Average KL loss: 0.498901
Average total loss: 0.621279
tensor(-12.6147, device='cuda:0') tensor(1.9829, device='cuda:0') tensor(-6.6200e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.118335
Average KL loss: 0.498371
Average total loss: 0.616706
tensor(-12.6297, device='cuda:0') tensor(1.9855, device='cuda:0') tensor(-1.5366e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.118525
Average KL loss: 0.497835
Average total loss: 0.616360
tensor(-12.6444, device='cuda:0') tensor(1.9882, device='cuda:0') tensor(4.6662e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.119485
Average KL loss: 0.497380
Average total loss: 0.616865
tensor(-12.6589, device='cuda:0') tensor(1.9912, device='cuda:0') tensor(4.7127e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.116297
Average KL loss: 0.496822
Average total loss: 0.613119
tensor(-12.6732, device='cuda:0') tensor(1.9939, device='cuda:0') tensor(-1.4221e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.115190
Average KL loss: 0.496229
Average total loss: 0.611419
tensor(-12.6873, device='cuda:0') tensor(1.9965, device='cuda:0') tensor(6.6478e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.114812
Average KL loss: 0.495718
Average total loss: 0.610530
tensor(-12.7011, device='cuda:0') tensor(1.9998, device='cuda:0') tensor(-1.0754e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.114506
Average KL loss: 0.495237
Average total loss: 0.609743
tensor(-12.7147, device='cuda:0') tensor(2.0030, device='cuda:0') tensor(1.9623e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.110080
Average KL loss: 0.494743
Average total loss: 0.604823
tensor(-12.7281, device='cuda:0') tensor(2.0059, device='cuda:0') tensor(-8.8042e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.111266
Average KL loss: 0.494255
Average total loss: 0.605521
tensor(-12.7413, device='cuda:0') tensor(2.0091, device='cuda:0') tensor(-4.3485e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.108918
Average KL loss: 0.493735
Average total loss: 0.602652
tensor(-12.7543, device='cuda:0') tensor(2.0124, device='cuda:0') tensor(2.0233e-11, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.109294
Average KL loss: 0.493265
Average total loss: 0.602559
tensor(-12.7672, device='cuda:0') tensor(2.0160, device='cuda:0') tensor(-2.4014e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.108676
Average KL loss: 0.492855
Average total loss: 0.601531
tensor(-12.7798, device='cuda:0') tensor(2.0189, device='cuda:0') tensor(-7.3676e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.106871
Average KL loss: 0.492550
Average total loss: 0.599422
tensor(-12.7924, device='cuda:0') tensor(2.0219, device='cuda:0') tensor(-4.8247e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.106501
Average KL loss: 0.492126
Average total loss: 0.598628
tensor(-12.8047, device='cuda:0') tensor(2.0247, device='cuda:0') tensor(2.0918e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.103584
Average KL loss: 0.491685
Average total loss: 0.595269
tensor(-12.8169, device='cuda:0') tensor(2.0276, device='cuda:0') tensor(-6.0322e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.103800
Average KL loss: 0.491278
Average total loss: 0.595078
tensor(-12.8289, device='cuda:0') tensor(2.0307, device='cuda:0') tensor(1.6347e-11, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.103978
Average KL loss: 0.490896
Average total loss: 0.594874
tensor(-12.8407, device='cuda:0') tensor(2.0342, device='cuda:0') tensor(4.6413e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.102742
Average KL loss: 0.490458
Average total loss: 0.593200
tensor(-12.8524, device='cuda:0') tensor(2.0374, device='cuda:0') tensor(-4.7055e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.103368
Average KL loss: 0.489970
Average total loss: 0.593338
tensor(-12.8640, device='cuda:0') tensor(2.0407, device='cuda:0') tensor(4.3503e-11, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.101787
Average KL loss: 0.489597
Average total loss: 0.591385
tensor(-12.8754, device='cuda:0') tensor(2.0439, device='cuda:0') tensor(2.7445e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.100552
Average KL loss: 0.489070
Average total loss: 0.589622
tensor(-12.8867, device='cuda:0') tensor(2.0469, device='cuda:0') tensor(2.2926e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.099838
Average KL loss: 0.488684
Average total loss: 0.588522
tensor(-12.8979, device='cuda:0') tensor(2.0499, device='cuda:0') tensor(-1.1705e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.099490
Average KL loss: 0.488409
Average total loss: 0.587899
tensor(-12.9089, device='cuda:0') tensor(2.0533, device='cuda:0') tensor(-1.3532e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.097376
Average KL loss: 0.487973
Average total loss: 0.585349
tensor(-12.9198, device='cuda:0') tensor(2.0568, device='cuda:0') tensor(-7.3614e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.098476
Average KL loss: 0.487657
Average total loss: 0.586133
tensor(-12.9305, device='cuda:0') tensor(2.0600, device='cuda:0') tensor(-2.9796e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.097698
Average KL loss: 0.487457
Average total loss: 0.585156
tensor(-12.9411, device='cuda:0') tensor(2.0639, device='cuda:0') tensor(-1.2443e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.096961
Average KL loss: 0.487226
Average total loss: 0.584187
tensor(-12.9517, device='cuda:0') tensor(2.0674, device='cuda:0') tensor(-1.3033e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.097114
Average KL loss: 0.486941
Average total loss: 0.584054
tensor(-12.9621, device='cuda:0') tensor(2.0705, device='cuda:0') tensor(4.4886e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.096125
Average KL loss: 0.486658
Average total loss: 0.582782
tensor(-12.9724, device='cuda:0') tensor(2.0737, device='cuda:0') tensor(-3.2887e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.094799
Average KL loss: 0.486331
Average total loss: 0.581130
tensor(-12.9826, device='cuda:0') tensor(2.0770, device='cuda:0') tensor(4.4692e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.094517
Average KL loss: 0.486024
Average total loss: 0.580541
tensor(-12.9927, device='cuda:0') tensor(2.0808, device='cuda:0') tensor(4.0381e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.093520
Average KL loss: 0.485722
Average total loss: 0.579242
tensor(-13.0026, device='cuda:0') tensor(2.0842, device='cuda:0') tensor(-5.2847e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.092954
Average KL loss: 0.485384
Average total loss: 0.578338
tensor(-13.0125, device='cuda:0') tensor(2.0872, device='cuda:0') tensor(-1.0379e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.093272
Average KL loss: 0.485025
Average total loss: 0.578298
tensor(-13.0223, device='cuda:0') tensor(2.0906, device='cuda:0') tensor(-4.7004e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.093605
Average KL loss: 0.484721
Average total loss: 0.578327
tensor(-13.0320, device='cuda:0') tensor(2.0940, device='cuda:0') tensor(-2.9340e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.092723
Average KL loss: 0.484408
Average total loss: 0.577131
tensor(-13.0415, device='cuda:0') tensor(2.0972, device='cuda:0') tensor(-5.6471e-11, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.090526
Average KL loss: 0.484049
Average total loss: 0.574575
tensor(-13.0510, device='cuda:0') tensor(2.1004, device='cuda:0') tensor(-2.6617e-11, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.091429
Average KL loss: 0.483783
Average total loss: 0.575212
tensor(-13.0604, device='cuda:0') tensor(2.1038, device='cuda:0') tensor(-2.5315e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.090996
Average KL loss: 0.483518
Average total loss: 0.574515
tensor(-13.0697, device='cuda:0') tensor(2.1067, device='cuda:0') tensor(-4.2957e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.090247
Average KL loss: 0.483196
Average total loss: 0.573444
tensor(-13.0789, device='cuda:0') tensor(2.1100, device='cuda:0') tensor(4.3683e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.089737
Average KL loss: 0.482983
Average total loss: 0.572720
tensor(-13.0880, device='cuda:0') tensor(2.1138, device='cuda:0') tensor(3.3090e-11, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.088500
Average KL loss: 0.482768
Average total loss: 0.571267
tensor(-13.0971, device='cuda:0') tensor(2.1171, device='cuda:0') tensor(4.4574e-11, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.088838
Average KL loss: 0.482590
Average total loss: 0.571428
tensor(-13.1060, device='cuda:0') tensor(2.1203, device='cuda:0') tensor(3.3104e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.088738
Average KL loss: 0.482364
Average total loss: 0.571102
tensor(-13.1149, device='cuda:0') tensor(2.1235, device='cuda:0') tensor(9.8771e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.087160
Average KL loss: 0.482135
Average total loss: 0.569296
tensor(-13.1237, device='cuda:0') tensor(2.1268, device='cuda:0') tensor(8.1781e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.086948
Average KL loss: 0.481902
Average total loss: 0.568850
tensor(-13.1324, device='cuda:0') tensor(2.1300, device='cuda:0') tensor(1.7748e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.087008
Average KL loss: 0.481626
Average total loss: 0.568634
tensor(-13.1411, device='cuda:0') tensor(2.1334, device='cuda:0') tensor(-1.7497e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.086327
Average KL loss: 0.481453
Average total loss: 0.567779
tensor(-13.1496, device='cuda:0') tensor(2.1367, device='cuda:0') tensor(-4.3614e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.086043
Average KL loss: 0.481318
Average total loss: 0.567361
tensor(-13.1581, device='cuda:0') tensor(2.1403, device='cuda:0') tensor(7.0444e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.084543
Average KL loss: 0.481169
Average total loss: 0.565712
tensor(-13.1665, device='cuda:0') tensor(2.1436, device='cuda:0') tensor(-3.6984e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.084021
Average KL loss: 0.480974
Average total loss: 0.564995
tensor(-13.1749, device='cuda:0') tensor(2.1465, device='cuda:0') tensor(1.4082e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.083504
Average KL loss: 0.480775
Average total loss: 0.564279
tensor(-13.1831, device='cuda:0') tensor(2.1505, device='cuda:0') tensor(7.1272e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.084503
Average KL loss: 0.480663
Average total loss: 0.565166
tensor(-13.1913, device='cuda:0') tensor(2.1542, device='cuda:0') tensor(-1.7969e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.083717
Average KL loss: 0.480445
Average total loss: 0.564162
tensor(-13.1995, device='cuda:0') tensor(2.1574, device='cuda:0') tensor(2.6535e-11, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.083386
Average KL loss: 0.480198
Average total loss: 0.563584
tensor(-13.2075, device='cuda:0') tensor(2.1603, device='cuda:0') tensor(1.8086e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.083788
Average KL loss: 0.479985
Average total loss: 0.563773
tensor(-13.2156, device='cuda:0') tensor(2.1631, device='cuda:0') tensor(-1.4189e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.084503
Average KL loss: 0.479765
Average total loss: 0.564268
tensor(-13.2235, device='cuda:0') tensor(2.1662, device='cuda:0') tensor(-1.2602e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.083236
Average KL loss: 0.479476
Average total loss: 0.562712
tensor(-13.2314, device='cuda:0') tensor(2.1694, device='cuda:0') tensor(-1.2675e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.083710
Average KL loss: 0.479339
Average total loss: 0.563049
tensor(-13.2392, device='cuda:0') tensor(2.1729, device='cuda:0') tensor(-2.2930e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.082506
Average KL loss: 0.479175
Average total loss: 0.561681
tensor(-13.2470, device='cuda:0') tensor(2.1753, device='cuda:0') tensor(-6.7406e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.081781
Average KL loss: 0.479029
Average total loss: 0.560811
tensor(-13.2547, device='cuda:0') tensor(2.1784, device='cuda:0') tensor(2.3608e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.081296
Average KL loss: 0.478885
Average total loss: 0.560181
tensor(-13.2623, device='cuda:0') tensor(2.1811, device='cuda:0') tensor(-6.0878e-11, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.082155
Average KL loss: 0.478698
Average total loss: 0.560853
tensor(-13.2699, device='cuda:0') tensor(2.1839, device='cuda:0') tensor(-2.2223e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.082559
Average KL loss: 0.478450
Average total loss: 0.561009
tensor(-13.2774, device='cuda:0') tensor(2.1876, device='cuda:0') tensor(-9.4751e-11, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.081563
Average KL loss: 0.478311
Average total loss: 0.559874
tensor(-13.2848, device='cuda:0') tensor(2.1907, device='cuda:0') tensor(7.3185e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.081724
Average KL loss: 0.478132
Average total loss: 0.559856
tensor(-13.2922, device='cuda:0') tensor(2.1937, device='cuda:0') tensor(3.6557e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.081096
Average KL loss: 0.477973
Average total loss: 0.559069
tensor(-13.2996, device='cuda:0') tensor(2.1967, device='cuda:0') tensor(-6.1795e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.080880
Average KL loss: 0.477787
Average total loss: 0.558667
tensor(-13.3069, device='cuda:0') tensor(2.1991, device='cuda:0') tensor(-4.2085e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.081633
Average KL loss: 0.477406
Average total loss: 0.559039
tensor(-13.3141, device='cuda:0') tensor(2.2022, device='cuda:0') tensor(-1.1104e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.080394
Average KL loss: 0.477227
Average total loss: 0.557621
tensor(-13.3214, device='cuda:0') tensor(2.2051, device='cuda:0') tensor(2.3482e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.080109
Average KL loss: 0.477108
Average total loss: 0.557217
tensor(-13.3285, device='cuda:0') tensor(2.2082, device='cuda:0') tensor(-2.6898e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.079648
Average KL loss: 0.476938
Average total loss: 0.556585
tensor(-13.3356, device='cuda:0') tensor(2.2107, device='cuda:0') tensor(-9.7032e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.078912
Average KL loss: 0.476662
Average total loss: 0.555574
tensor(-13.3427, device='cuda:0') tensor(2.2130, device='cuda:0') tensor(3.8388e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.079055
Average KL loss: 0.476391
Average total loss: 0.555447
tensor(-13.3497, device='cuda:0') tensor(2.2155, device='cuda:0') tensor(5.5378e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.079052
Average KL loss: 0.476232
Average total loss: 0.555284
tensor(-13.3566, device='cuda:0') tensor(2.2179, device='cuda:0') tensor(-7.1480e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.078900
Average KL loss: 0.475942
Average total loss: 0.554842
tensor(-13.3635, device='cuda:0') tensor(2.2206, device='cuda:0') tensor(4.7915e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.078236
Average KL loss: 0.475769
Average total loss: 0.554006
tensor(-13.3704, device='cuda:0') tensor(2.2235, device='cuda:0') tensor(-2.4037e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.079092
Average KL loss: 0.475581
Average total loss: 0.554673
tensor(-13.3772, device='cuda:0') tensor(2.2261, device='cuda:0') tensor(-6.4048e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.078805
Average KL loss: 0.475373
Average total loss: 0.554178
tensor(-13.3839, device='cuda:0') tensor(2.2289, device='cuda:0') tensor(-1.3236e-12, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.077969
Average KL loss: 0.475206
Average total loss: 0.553174
tensor(-13.3906, device='cuda:0') tensor(2.2319, device='cuda:0') tensor(-7.1302e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.077891
Average KL loss: 0.475026
Average total loss: 0.552917
tensor(-13.3973, device='cuda:0') tensor(2.2350, device='cuda:0') tensor(1.7934e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.077872
Average KL loss: 0.474914
Average total loss: 0.552785
tensor(-13.4039, device='cuda:0') tensor(2.2375, device='cuda:0') tensor(-9.4251e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.078887
Average KL loss: 0.474688
Average total loss: 0.553575
tensor(-13.4105, device='cuda:0') tensor(2.2405, device='cuda:0') tensor(1.2509e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.077801
Average KL loss: 0.474483
Average total loss: 0.552285
tensor(-13.4170, device='cuda:0') tensor(2.2432, device='cuda:0') tensor(4.5605e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.077211
Average KL loss: 0.474257
Average total loss: 0.551469
tensor(-13.4235, device='cuda:0') tensor(2.2458, device='cuda:0') tensor(7.5108e-11, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.078354
Average KL loss: 0.474077
Average total loss: 0.552431
tensor(-13.4299, device='cuda:0') tensor(2.2486, device='cuda:0') tensor(-3.2115e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.077928
Average KL loss: 0.473969
Average total loss: 0.551897
tensor(-13.4363, device='cuda:0') tensor(2.2513, device='cuda:0') tensor(-2.8756e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.077696
Average KL loss: 0.473818
Average total loss: 0.551514
tensor(-13.4427, device='cuda:0') tensor(2.2537, device='cuda:0') tensor(-1.4341e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.077408
Average KL loss: 0.473660
Average total loss: 0.551068
tensor(-13.4490, device='cuda:0') tensor(2.2562, device='cuda:0') tensor(-1.0860e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.077947
Average KL loss: 0.473523
Average total loss: 0.551470
tensor(-13.4553, device='cuda:0') tensor(2.2588, device='cuda:0') tensor(1.7870e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.077010
Average KL loss: 0.473293
Average total loss: 0.550303
tensor(-13.4616, device='cuda:0') tensor(2.2613, device='cuda:0') tensor(-3.0559e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.077610
Average KL loss: 0.473074
Average total loss: 0.550684
tensor(-13.4678, device='cuda:0') tensor(2.2638, device='cuda:0') tensor(-2.7439e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.076882
Average KL loss: 0.472858
Average total loss: 0.549739
tensor(-13.4740, device='cuda:0') tensor(2.2666, device='cuda:0') tensor(5.0210e-11, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.076319
Average KL loss: 0.472741
Average total loss: 0.549061
tensor(-13.4801, device='cuda:0') tensor(2.2697, device='cuda:0') tensor(-5.4614e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.076826
Average KL loss: 0.472661
Average total loss: 0.549487
tensor(-13.4862, device='cuda:0') tensor(2.2724, device='cuda:0') tensor(1.5338e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.075684
Average KL loss: 0.472531
Average total loss: 0.548214
tensor(-13.4922, device='cuda:0') tensor(2.2749, device='cuda:0') tensor(2.9199e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.076232
Average KL loss: 0.472422
Average total loss: 0.548654
tensor(-13.4983, device='cuda:0') tensor(2.2777, device='cuda:0') tensor(-2.9868e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.076083
Average KL loss: 0.472260
Average total loss: 0.548343
tensor(-13.5042, device='cuda:0') tensor(2.2799, device='cuda:0') tensor(-8.8202e-11, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.075799
Average KL loss: 0.472106
Average total loss: 0.547905
tensor(-13.5102, device='cuda:0') tensor(2.2821, device='cuda:0') tensor(1.5470e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.075575
Average KL loss: 0.471927
Average total loss: 0.547501
tensor(-13.5161, device='cuda:0') tensor(2.2845, device='cuda:0') tensor(-2.4399e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.076057
Average KL loss: 0.471907
Average total loss: 0.547964
tensor(-13.5220, device='cuda:0') tensor(2.2874, device='cuda:0') tensor(-2.3896e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.075594
Average KL loss: 0.471809
Average total loss: 0.547402
tensor(-13.5279, device='cuda:0') tensor(2.2897, device='cuda:0') tensor(-5.5205e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.075277
Average KL loss: 0.471713
Average total loss: 0.546990
tensor(-13.5337, device='cuda:0') tensor(2.2921, device='cuda:0') tensor(-1.0719e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.074964
Average KL loss: 0.471571
Average total loss: 0.546535
tensor(-13.5395, device='cuda:0') tensor(2.2943, device='cuda:0') tensor(2.3315e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.075744
Average KL loss: 0.471436
Average total loss: 0.547179
tensor(-13.5452, device='cuda:0') tensor(2.2967, device='cuda:0') tensor(-4.0250e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.075199
Average KL loss: 0.471301
Average total loss: 0.546501
tensor(-13.5510, device='cuda:0') tensor(2.2988, device='cuda:0') tensor(1.4860e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.075212
Average KL loss: 0.471195
Average total loss: 0.546407
tensor(-13.5566, device='cuda:0') tensor(2.3012, device='cuda:0') tensor(-1.5853e-11, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.074691
Average KL loss: 0.471035
Average total loss: 0.545726
tensor(-13.5623, device='cuda:0') tensor(2.3034, device='cuda:0') tensor(2.7217e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.075480
Average KL loss: 0.470930
Average total loss: 0.546410
tensor(-13.5679, device='cuda:0') tensor(2.3055, device='cuda:0') tensor(3.3650e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.073752
Average KL loss: 0.470675
Average total loss: 0.544427
tensor(-13.5736, device='cuda:0') tensor(2.3078, device='cuda:0') tensor(2.7033e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.074615
Average KL loss: 0.470552
Average total loss: 0.545167
tensor(-13.5791, device='cuda:0') tensor(2.3103, device='cuda:0') tensor(1.8415e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.074710
Average KL loss: 0.470375
Average total loss: 0.545085
tensor(-13.5847, device='cuda:0') tensor(2.3123, device='cuda:0') tensor(6.0337e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.074651
Average KL loss: 0.470171
Average total loss: 0.544822
tensor(-13.5902, device='cuda:0') tensor(2.3142, device='cuda:0') tensor(2.8776e-11, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.073875
Average KL loss: 0.469932
Average total loss: 0.543807
tensor(-13.5957, device='cuda:0') tensor(2.3164, device='cuda:0') tensor(-5.3543e-11, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.075218
Average KL loss: 0.469773
Average total loss: 0.544991
tensor(-13.6011, device='cuda:0') tensor(2.3187, device='cuda:0') tensor(-5.5481e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.074076
Average KL loss: 0.469665
Average total loss: 0.543741
tensor(-13.6065, device='cuda:0') tensor(2.3209, device='cuda:0') tensor(-2.9281e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.073187
Average KL loss: 0.469435
Average total loss: 0.542622
tensor(-13.6119, device='cuda:0') tensor(2.3227, device='cuda:0') tensor(1.0652e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.074449
Average KL loss: 0.469287
Average total loss: 0.543736
tensor(-13.6173, device='cuda:0') tensor(2.3244, device='cuda:0') tensor(-1.6806e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.074598
Average KL loss: 0.469216
Average total loss: 0.543814
tensor(-13.6226, device='cuda:0') tensor(2.3266, device='cuda:0') tensor(1.8107e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.074287
Average KL loss: 0.469132
Average total loss: 0.543420
tensor(-13.6279, device='cuda:0') tensor(2.3294, device='cuda:0') tensor(-5.3272e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.073918
Average KL loss: 0.469075
Average total loss: 0.542994
tensor(-13.6332, device='cuda:0') tensor(2.3314, device='cuda:0') tensor(2.8160e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.072780
Average KL loss: 0.468936
Average total loss: 0.541716
tensor(-13.6385, device='cuda:0') tensor(2.3338, device='cuda:0') tensor(-4.0789e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.074209
Average KL loss: 0.468888
Average total loss: 0.543097
tensor(-13.6437, device='cuda:0') tensor(2.3363, device='cuda:0') tensor(-1.0738e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.074075
Average KL loss: 0.468732
Average total loss: 0.542807
tensor(-13.6489, device='cuda:0') tensor(2.3383, device='cuda:0') tensor(-1.4723e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.074574
Average KL loss: 0.468585
Average total loss: 0.543159
tensor(-13.6541, device='cuda:0') tensor(2.3400, device='cuda:0') tensor(3.0891e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.073265
Average KL loss: 0.468430
Average total loss: 0.541695
tensor(-13.6593, device='cuda:0') tensor(2.3419, device='cuda:0') tensor(5.7941e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.072915
Average KL loss: 0.468340
Average total loss: 0.541255
tensor(-13.6644, device='cuda:0') tensor(2.3441, device='cuda:0') tensor(-1.9657e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.074029
Average KL loss: 0.468233
Average total loss: 0.542262
tensor(-13.6695, device='cuda:0') tensor(2.3461, device='cuda:0') tensor(-5.8517e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.073976
Average KL loss: 0.468081
Average total loss: 0.542057
tensor(-13.6746, device='cuda:0') tensor(2.3480, device='cuda:0') tensor(1.7996e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.073514
Average KL loss: 0.467980
Average total loss: 0.541494
tensor(-13.6796, device='cuda:0') tensor(2.3499, device='cuda:0') tensor(-2.7414e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.073537
Average KL loss: 0.467902
Average total loss: 0.541439
tensor(-13.6846, device='cuda:0') tensor(2.3522, device='cuda:0') tensor(-1.6596e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.073802
Average KL loss: 0.467826
Average total loss: 0.541628
tensor(-13.6896, device='cuda:0') tensor(2.3542, device='cuda:0') tensor(8.6684e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.072414
Average KL loss: 0.467672
Average total loss: 0.540086
tensor(-13.6946, device='cuda:0') tensor(2.3560, device='cuda:0') tensor(-2.1601e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.073722
Average KL loss: 0.467475
Average total loss: 0.541197
tensor(-13.6996, device='cuda:0') tensor(2.3579, device='cuda:0') tensor(-5.1977e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.072752
Average KL loss: 0.467312
Average total loss: 0.540064
tensor(-13.7045, device='cuda:0') tensor(2.3598, device='cuda:0') tensor(-8.1706e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.073089
Average KL loss: 0.467082
Average total loss: 0.540171
tensor(-13.7094, device='cuda:0') tensor(2.3616, device='cuda:0') tensor(-5.5914e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.073935
Average KL loss: 0.466912
Average total loss: 0.540847
tensor(-13.7143, device='cuda:0') tensor(2.3633, device='cuda:0') tensor(-3.8407e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.073466
Average KL loss: 0.466832
Average total loss: 0.540299
tensor(-13.7191, device='cuda:0') tensor(2.3653, device='cuda:0') tensor(4.6057e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.072830
Average KL loss: 0.466747
Average total loss: 0.539578
tensor(-13.7240, device='cuda:0') tensor(2.3674, device='cuda:0') tensor(-1.2684e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.072502
Average KL loss: 0.466631
Average total loss: 0.539134
tensor(-13.7288, device='cuda:0') tensor(2.3688, device='cuda:0') tensor(6.9411e-11, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.072493
Average KL loss: 0.466513
Average total loss: 0.539006
tensor(-13.7336, device='cuda:0') tensor(2.3706, device='cuda:0') tensor(6.5795e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.073447
Average KL loss: 0.466377
Average total loss: 0.539824
tensor(-13.7384, device='cuda:0') tensor(2.3724, device='cuda:0') tensor(-1.2727e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.072528
Average KL loss: 0.466267
Average total loss: 0.538795
tensor(-13.7431, device='cuda:0') tensor(2.3744, device='cuda:0') tensor(2.3412e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.072883
Average KL loss: 0.466179
Average total loss: 0.539062
tensor(-13.7478, device='cuda:0') tensor(2.3764, device='cuda:0') tensor(-7.8723e-11, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.072929
Average KL loss: 0.466009
Average total loss: 0.538938
tensor(-13.7526, device='cuda:0') tensor(2.3781, device='cuda:0') tensor(1.1949e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.072721
Average KL loss: 0.465804
Average total loss: 0.538525
tensor(-13.7572, device='cuda:0') tensor(2.3800, device='cuda:0') tensor(8.0936e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.072852
Average KL loss: 0.465601
Average total loss: 0.538453
tensor(-13.7619, device='cuda:0') tensor(2.3813, device='cuda:0') tensor(-2.4383e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.073761
Average KL loss: 0.465422
Average total loss: 0.539182
tensor(-13.7666, device='cuda:0') tensor(2.3832, device='cuda:0') tensor(4.2352e-13, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.072464
Average KL loss: 0.465276
Average total loss: 0.537740
tensor(-13.7712, device='cuda:0') tensor(2.3843, device='cuda:0') tensor(1.2858e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.073079
Average KL loss: 0.464991
Average total loss: 0.538070
tensor(-13.7758, device='cuda:0') tensor(2.3854, device='cuda:0') tensor(1.6400e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.073562
Average KL loss: 0.464777
Average total loss: 0.538339
tensor(-13.7804, device='cuda:0') tensor(2.3873, device='cuda:0') tensor(2.6415e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.073336
Average KL loss: 0.464652
Average total loss: 0.537988
tensor(-13.7850, device='cuda:0') tensor(2.3892, device='cuda:0') tensor(-7.0263e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.073118
Average KL loss: 0.464563
Average total loss: 0.537682
tensor(-13.7895, device='cuda:0') tensor(2.3906, device='cuda:0') tensor(-1.0711e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.072555
Average KL loss: 0.464382
Average total loss: 0.536937
tensor(-13.7940, device='cuda:0') tensor(2.3922, device='cuda:0') tensor(1.5080e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.073769
Average KL loss: 0.464233
Average total loss: 0.538002
tensor(-13.7986, device='cuda:0') tensor(2.3935, device='cuda:0') tensor(3.3060e-11, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.072978
Average KL loss: 0.464123
Average total loss: 0.537101
tensor(-13.8030, device='cuda:0') tensor(2.3950, device='cuda:0') tensor(-7.0556e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.073579
Average KL loss: 0.464011
Average total loss: 0.537591
tensor(-13.8075, device='cuda:0') tensor(2.3968, device='cuda:0') tensor(1.3386e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.073051
Average KL loss: 0.463810
Average total loss: 0.536861
tensor(-13.8120, device='cuda:0') tensor(2.3977, device='cuda:0') tensor(-8.5611e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.073380
Average KL loss: 0.463690
Average total loss: 0.537070
tensor(-13.8164, device='cuda:0') tensor(2.3996, device='cuda:0') tensor(-1.9452e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.072939
Average KL loss: 0.463653
Average total loss: 0.536592
tensor(-13.8208, device='cuda:0') tensor(2.4013, device='cuda:0') tensor(-8.6099e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 200
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
 Percentile value: nan
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1125144 / 2359296             ( 47.69%) | total_pruned = 1234152 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  106214 /  131072             ( 81.03%) | total_pruned =   24858 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  819742 / 2359296             ( 34.75%) | total_pruned = 1539554 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  734388 / 2359296             ( 31.13%) | total_pruned = 1624908 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 34/100 Loss: 2.302542 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  655802 / 2359296             ( 27.80%) | total_pruned = 1703494 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  734388 / 2359296             ( 31.13%) | total_pruned = 1624908 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 34/100 Loss: 2.302696 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  692539 / 2359296             ( 29.35%) | total_pruned = 1666757 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 34/100 Loss: 2.302415 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  343203 / 2359296             ( 14.55%) | total_pruned = 2016093 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 34/100 Loss: 2.302674 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  168535 / 2359296             (  7.14%) | total_pruned = 2190761 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 34/100 Loss: 2.302404 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   81201 / 2359296             (  3.44%) | total_pruned = 2278095 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 34/100 Loss: 2.302444 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   37534 / 2359296             (  1.59%) | total_pruned = 2321762 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 34/100 Loss: 2.302669 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   15700 / 2359296             (  0.67%) | total_pruned = 2343596 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 34/100 Loss: 2.302565 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    4783 / 2359296             (  0.20%) | total_pruned = 2354513 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 34/100 Loss: 2.302577 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     347 /     512             ( 67.77%) | total_pruned =     165 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 34/100 Loss: 2.302561 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
