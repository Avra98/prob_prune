Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.4786e-05, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.905239
Average KL loss: 189.331430
Average total loss: 191.236664
tensor(-3.3396, device='cuda:0') tensor(0.2401, device='cuda:0') tensor(3.6076e-06, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.906319
Average KL loss: 28.880134
Average total loss: 30.786452
tensor(-4.2937, device='cuda:0') tensor(0.2904, device='cuda:0') tensor(1.5993e-06, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.875756
Average KL loss: 15.407740
Average total loss: 17.283495
tensor(-4.8153, device='cuda:0') tensor(0.3157, device='cuda:0') tensor(9.7388e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.834596
Average KL loss: 10.406014
Average total loss: 12.240610
tensor(-5.1971, device='cuda:0') tensor(0.3381, device='cuda:0') tensor(7.1412e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.796720
Average KL loss: 7.758653
Average total loss: 9.555373
tensor(-5.5010, device='cuda:0') tensor(0.3556, device='cuda:0') tensor(5.1645e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.767840
Average KL loss: 6.135651
Average total loss: 7.903491
tensor(-5.7541, device='cuda:0') tensor(0.3707, device='cuda:0') tensor(4.1795e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.734271
Average KL loss: 5.053933
Average total loss: 6.788204
tensor(-5.9716, device='cuda:0') tensor(0.3841, device='cuda:0') tensor(3.5295e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.703514
Average KL loss: 4.283913
Average total loss: 5.987427
tensor(-6.1625, device='cuda:0') tensor(0.3949, device='cuda:0') tensor(3.0917e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.663220
Average KL loss: 3.704771
Average total loss: 5.367990
tensor(-6.3330, device='cuda:0') tensor(0.4028, device='cuda:0') tensor(2.5516e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.636119
Average KL loss: 3.253947
Average total loss: 4.890066
tensor(-6.4872, device='cuda:0') tensor(0.4088, device='cuda:0') tensor(2.2096e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.599933
Average KL loss: 2.895501
Average total loss: 4.495434
tensor(-6.6280, device='cuda:0') tensor(0.4138, device='cuda:0') tensor(1.8756e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.580764
Average KL loss: 2.602141
Average total loss: 4.182904
tensor(-6.7578, device='cuda:0') tensor(0.4181, device='cuda:0') tensor(1.7559e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.556254
Average KL loss: 2.361804
Average total loss: 3.918057
tensor(-6.8782, device='cuda:0') tensor(0.4216, device='cuda:0') tensor(1.5672e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.520404
Average KL loss: 2.157747
Average total loss: 3.678151
tensor(-6.9907, device='cuda:0') tensor(0.4237, device='cuda:0') tensor(1.4767e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.512979
Average KL loss: 1.981513
Average total loss: 3.494492
tensor(-7.0962, device='cuda:0') tensor(0.4257, device='cuda:0') tensor(1.3272e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.480897
Average KL loss: 1.831991
Average total loss: 3.312887
tensor(-7.1957, device='cuda:0') tensor(0.4275, device='cuda:0') tensor(1.2362e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.462960
Average KL loss: 1.703001
Average total loss: 3.165961
tensor(-7.2898, device='cuda:0') tensor(0.4293, device='cuda:0') tensor(1.0072e-07, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.438812
Average KL loss: 1.592720
Average total loss: 3.031531
tensor(-7.3793, device='cuda:0') tensor(0.4311, device='cuda:0') tensor(9.8864e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.414288
Average KL loss: 1.497437
Average total loss: 2.911725
tensor(-7.4645, device='cuda:0') tensor(0.4326, device='cuda:0') tensor(8.8620e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.391189
Average KL loss: 1.411750
Average total loss: 2.802938
tensor(-7.5460, device='cuda:0') tensor(0.4339, device='cuda:0') tensor(8.2914e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.369097
Average KL loss: 1.334004
Average total loss: 2.703100
tensor(-7.6240, device='cuda:0') tensor(0.4349, device='cuda:0') tensor(7.7982e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.360217
Average KL loss: 1.265794
Average total loss: 2.626011
tensor(-7.6989, device='cuda:0') tensor(0.4361, device='cuda:0') tensor(7.1318e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.345131
Average KL loss: 1.204095
Average total loss: 2.549226
tensor(-7.7710, device='cuda:0') tensor(0.4372, device='cuda:0') tensor(7.1008e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.323609
Average KL loss: 1.148666
Average total loss: 2.472275
tensor(-7.8405, device='cuda:0') tensor(0.4380, device='cuda:0') tensor(6.0047e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.309541
Average KL loss: 1.098052
Average total loss: 2.407594
tensor(-7.9076, device='cuda:0') tensor(0.4389, device='cuda:0') tensor(5.8231e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.299030
Average KL loss: 1.052464
Average total loss: 2.351493
tensor(-7.9726, device='cuda:0') tensor(0.4400, device='cuda:0') tensor(5.3360e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.292202
Average KL loss: 1.010510
Average total loss: 2.302712
tensor(-8.0355, device='cuda:0') tensor(0.4409, device='cuda:0') tensor(4.9848e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.278181
Average KL loss: 0.971740
Average total loss: 2.249921
tensor(-8.0966, device='cuda:0') tensor(0.4419, device='cuda:0') tensor(4.8038e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.267267
Average KL loss: 0.936404
Average total loss: 2.203671
tensor(-8.1559, device='cuda:0') tensor(0.4428, device='cuda:0') tensor(4.4107e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.260538
Average KL loss: 0.903762
Average total loss: 2.164300
tensor(-8.2136, device='cuda:0') tensor(0.4440, device='cuda:0') tensor(4.3807e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.247968
Average KL loss: 0.875323
Average total loss: 2.123291
tensor(-8.2698, device='cuda:0') tensor(0.4451, device='cuda:0') tensor(4.0583e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.241842
Average KL loss: 0.848154
Average total loss: 2.089996
tensor(-8.3246, device='cuda:0') tensor(0.4462, device='cuda:0') tensor(3.9273e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.235607
Average KL loss: 0.823300
Average total loss: 2.058907
tensor(-8.3781, device='cuda:0') tensor(0.4473, device='cuda:0') tensor(3.6287e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.226160
Average KL loss: 0.801431
Average total loss: 2.027591
tensor(-8.4304, device='cuda:0') tensor(0.4486, device='cuda:0') tensor(3.3821e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.218069
Average KL loss: 0.780755
Average total loss: 1.998824
tensor(-8.4814, device='cuda:0') tensor(0.4498, device='cuda:0') tensor(3.1824e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.210077
Average KL loss: 0.761179
Average total loss: 1.971256
tensor(-8.5314, device='cuda:0') tensor(0.4510, device='cuda:0') tensor(3.1082e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.205840
Average KL loss: 0.742803
Average total loss: 1.948642
tensor(-8.5803, device='cuda:0') tensor(0.4523, device='cuda:0') tensor(2.9352e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.202312
Average KL loss: 0.726348
Average total loss: 1.928660
tensor(-8.6283, device='cuda:0') tensor(0.4536, device='cuda:0') tensor(2.7026e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.190494
Average KL loss: 0.711228
Average total loss: 1.901721
tensor(-8.6753, device='cuda:0') tensor(0.4550, device='cuda:0') tensor(2.7217e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.187695
Average KL loss: 0.697303
Average total loss: 1.884998
tensor(-8.7215, device='cuda:0') tensor(0.4562, device='cuda:0') tensor(2.5512e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.176686
Average KL loss: 0.683506
Average total loss: 1.860192
tensor(-8.7668, device='cuda:0') tensor(0.4575, device='cuda:0') tensor(2.5107e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.175481
Average KL loss: 0.670325
Average total loss: 1.845806
tensor(-8.8114, device='cuda:0') tensor(0.4587, device='cuda:0') tensor(2.4139e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.169041
Average KL loss: 0.657579
Average total loss: 1.826620
tensor(-8.8552, device='cuda:0') tensor(0.4599, device='cuda:0') tensor(2.5251e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.166719
Average KL loss: 0.645707
Average total loss: 1.812425
tensor(-8.8983, device='cuda:0') tensor(0.4612, device='cuda:0') tensor(2.0481e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.162909
Average KL loss: 0.634179
Average total loss: 1.797089
tensor(-8.9408, device='cuda:0') tensor(0.4624, device='cuda:0') tensor(2.1502e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.157473
Average KL loss: 0.623746
Average total loss: 1.781220
tensor(-8.9826, device='cuda:0') tensor(0.4637, device='cuda:0') tensor(2.2530e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.151998
Average KL loss: 0.614027
Average total loss: 1.766024
tensor(-9.0237, device='cuda:0') tensor(0.4650, device='cuda:0') tensor(2.0659e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.147020
Average KL loss: 0.605092
Average total loss: 1.752113
tensor(-9.0643, device='cuda:0') tensor(0.4663, device='cuda:0') tensor(1.9019e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.143225
Average KL loss: 0.596415
Average total loss: 1.739641
tensor(-9.1043, device='cuda:0') tensor(0.4676, device='cuda:0') tensor(2.0317e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.139519
Average KL loss: 0.588072
Average total loss: 1.727591
tensor(-9.1438, device='cuda:0') tensor(0.4689, device='cuda:0') tensor(1.7467e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.139539
Average KL loss: 0.580142
Average total loss: 1.719681
tensor(-9.1828, device='cuda:0') tensor(0.4702, device='cuda:0') tensor(1.4488e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.131051
Average KL loss: 0.573383
Average total loss: 1.704434
tensor(-9.2213, device='cuda:0') tensor(0.4714, device='cuda:0') tensor(1.8155e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.128553
Average KL loss: 0.567020
Average total loss: 1.695574
tensor(-9.2593, device='cuda:0') tensor(0.4727, device='cuda:0') tensor(1.5739e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.121612
Average KL loss: 0.561255
Average total loss: 1.682867
tensor(-9.2969, device='cuda:0') tensor(0.4739, device='cuda:0') tensor(1.4513e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.120550
Average KL loss: 0.555186
Average total loss: 1.675736
tensor(-9.3340, device='cuda:0') tensor(0.4752, device='cuda:0') tensor(1.4488e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.116764
Average KL loss: 0.548780
Average total loss: 1.665544
tensor(-9.3707, device='cuda:0') tensor(0.4764, device='cuda:0') tensor(1.3049e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.116112
Average KL loss: 0.543171
Average total loss: 1.659283
tensor(-9.4070, device='cuda:0') tensor(0.4777, device='cuda:0') tensor(1.1638e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.112064
Average KL loss: 0.537787
Average total loss: 1.649851
tensor(-9.4429, device='cuda:0') tensor(0.4789, device='cuda:0') tensor(1.4058e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.108308
Average KL loss: 0.532371
Average total loss: 1.640680
tensor(-9.4785, device='cuda:0') tensor(0.4801, device='cuda:0') tensor(1.3717e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.106107
Average KL loss: 0.527647
Average total loss: 1.633754
tensor(-9.5137, device='cuda:0') tensor(0.4814, device='cuda:0') tensor(1.2600e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.103122
Average KL loss: 0.523105
Average total loss: 1.626227
tensor(-9.5485, device='cuda:0') tensor(0.4824, device='cuda:0') tensor(1.2294e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.100168
Average KL loss: 0.518438
Average total loss: 1.618606
tensor(-9.5831, device='cuda:0') tensor(0.4834, device='cuda:0') tensor(1.1236e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.099282
Average KL loss: 0.513640
Average total loss: 1.612922
tensor(-9.6173, device='cuda:0') tensor(0.4846, device='cuda:0') tensor(1.0525e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.094907
Average KL loss: 0.509408
Average total loss: 1.604315
tensor(-9.6512, device='cuda:0') tensor(0.4857, device='cuda:0') tensor(1.0138e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.094286
Average KL loss: 0.505380
Average total loss: 1.599666
tensor(-9.6848, device='cuda:0') tensor(0.4869, device='cuda:0') tensor(9.0908e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.092716
Average KL loss: 0.501988
Average total loss: 1.594704
tensor(-9.7181, device='cuda:0') tensor(0.4882, device='cuda:0') tensor(1.1811e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.090381
Average KL loss: 0.498232
Average total loss: 1.588613
tensor(-9.7512, device='cuda:0') tensor(0.4893, device='cuda:0') tensor(1.0695e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.087773
Average KL loss: 0.494525
Average total loss: 1.582298
tensor(-9.7840, device='cuda:0') tensor(0.4905, device='cuda:0') tensor(8.5783e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.087616
Average KL loss: 0.491198
Average total loss: 1.578815
tensor(-9.8165, device='cuda:0') tensor(0.4917, device='cuda:0') tensor(9.4086e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.086917
Average KL loss: 0.488088
Average total loss: 1.575005
tensor(-9.8488, device='cuda:0') tensor(0.4929, device='cuda:0') tensor(9.2713e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.082743
Average KL loss: 0.485300
Average total loss: 1.568044
tensor(-9.8808, device='cuda:0') tensor(0.4941, device='cuda:0') tensor(9.0796e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.082419
Average KL loss: 0.482125
Average total loss: 1.564545
tensor(-9.9126, device='cuda:0') tensor(0.4952, device='cuda:0') tensor(8.7036e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.078949
Average KL loss: 0.479280
Average total loss: 1.558229
tensor(-9.9442, device='cuda:0') tensor(0.4963, device='cuda:0') tensor(7.1669e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.081620
Average KL loss: 0.476589
Average total loss: 1.558209
tensor(-9.9755, device='cuda:0') tensor(0.4976, device='cuda:0') tensor(6.9326e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.076239
Average KL loss: 0.473918
Average total loss: 1.550157
tensor(-10.0067, device='cuda:0') tensor(0.4986, device='cuda:0') tensor(8.3913e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.076299
Average KL loss: 0.471227
Average total loss: 1.547526
tensor(-10.0377, device='cuda:0') tensor(0.4996, device='cuda:0') tensor(7.7261e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.075245
Average KL loss: 0.468588
Average total loss: 1.543833
tensor(-10.0685, device='cuda:0') tensor(0.5006, device='cuda:0') tensor(6.9791e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.076281
Average KL loss: 0.466361
Average total loss: 1.542642
tensor(-10.0990, device='cuda:0') tensor(0.5018, device='cuda:0') tensor(7.6386e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.071039
Average KL loss: 0.464538
Average total loss: 1.535577
tensor(-10.1294, device='cuda:0') tensor(0.5029, device='cuda:0') tensor(6.8800e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.070867
Average KL loss: 0.462638
Average total loss: 1.533505
tensor(-10.1596, device='cuda:0') tensor(0.5040, device='cuda:0') tensor(4.9692e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.070120
Average KL loss: 0.460455
Average total loss: 1.530575
tensor(-10.1896, device='cuda:0') tensor(0.5050, device='cuda:0') tensor(6.1108e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.068878
Average KL loss: 0.458357
Average total loss: 1.527235
tensor(-10.2195, device='cuda:0') tensor(0.5061, device='cuda:0') tensor(5.0128e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.067324
Average KL loss: 0.456818
Average total loss: 1.524142
tensor(-10.2492, device='cuda:0') tensor(0.5073, device='cuda:0') tensor(6.3282e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.068275
Average KL loss: 0.455022
Average total loss: 1.523297
tensor(-10.2787, device='cuda:0') tensor(0.5083, device='cuda:0') tensor(5.8110e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.065490
Average KL loss: 0.452920
Average total loss: 1.518410
tensor(-10.3081, device='cuda:0') tensor(0.5093, device='cuda:0') tensor(5.0168e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.064127
Average KL loss: 0.451487
Average total loss: 1.515614
tensor(-10.3374, device='cuda:0') tensor(0.5104, device='cuda:0') tensor(6.0328e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.063623
Average KL loss: 0.450057
Average total loss: 1.513679
tensor(-10.3664, device='cuda:0') tensor(0.5114, device='cuda:0') tensor(4.6406e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.063823
Average KL loss: 0.448125
Average total loss: 1.511948
tensor(-10.3954, device='cuda:0') tensor(0.5123, device='cuda:0') tensor(4.5926e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.063043
Average KL loss: 0.446522
Average total loss: 1.509566
tensor(-10.4242, device='cuda:0') tensor(0.5134, device='cuda:0') tensor(5.6199e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.063632
Average KL loss: 0.445125
Average total loss: 1.508757
tensor(-10.4529, device='cuda:0') tensor(0.5144, device='cuda:0') tensor(5.3193e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.062288
Average KL loss: 0.443691
Average total loss: 1.505979
tensor(-10.4814, device='cuda:0') tensor(0.5154, device='cuda:0') tensor(4.2641e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.060590
Average KL loss: 0.442162
Average total loss: 1.502752
tensor(-10.5099, device='cuda:0') tensor(0.5163, device='cuda:0') tensor(5.0645e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.060876
Average KL loss: 0.440570
Average total loss: 1.501446
tensor(-10.5382, device='cuda:0') tensor(0.5172, device='cuda:0') tensor(4.2420e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.060219
Average KL loss: 0.439301
Average total loss: 1.499521
tensor(-10.5663, device='cuda:0') tensor(0.5181, device='cuda:0') tensor(4.2629e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.061352
Average KL loss: 0.437854
Average total loss: 1.499206
tensor(-10.5944, device='cuda:0') tensor(0.5190, device='cuda:0') tensor(4.3432e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.057720
Average KL loss: 0.436682
Average total loss: 1.494402
tensor(-10.6223, device='cuda:0') tensor(0.5201, device='cuda:0') tensor(4.2599e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.056891
Average KL loss: 0.435627
Average total loss: 1.492518
tensor(-10.6502, device='cuda:0') tensor(0.5211, device='cuda:0') tensor(3.5742e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.057933
Average KL loss: 0.434622
Average total loss: 1.492555
tensor(-10.6779, device='cuda:0') tensor(0.5221, device='cuda:0') tensor(4.2761e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.055967
Average KL loss: 0.433501
Average total loss: 1.489468
tensor(-10.7055, device='cuda:0') tensor(0.5230, device='cuda:0') tensor(3.5409e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.055582
Average KL loss: 0.432171
Average total loss: 1.487753
tensor(-10.7330, device='cuda:0') tensor(0.5239, device='cuda:0') tensor(3.0769e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.055270
Average KL loss: 0.431170
Average total loss: 1.486440
tensor(-10.7605, device='cuda:0') tensor(0.5249, device='cuda:0') tensor(3.7011e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.052141
Average KL loss: 0.430314
Average total loss: 1.482455
tensor(-10.7878, device='cuda:0') tensor(0.5258, device='cuda:0') tensor(3.6547e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.053500
Average KL loss: 0.429254
Average total loss: 1.482754
tensor(-10.8150, device='cuda:0') tensor(0.5266, device='cuda:0') tensor(3.5376e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.053806
Average KL loss: 0.428051
Average total loss: 1.481856
tensor(-10.8421, device='cuda:0') tensor(0.5276, device='cuda:0') tensor(3.3751e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.051190
Average KL loss: 0.427300
Average total loss: 1.478490
tensor(-10.8692, device='cuda:0') tensor(0.5286, device='cuda:0') tensor(2.5132e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.050930
Average KL loss: 0.426718
Average total loss: 1.477648
tensor(-10.8961, device='cuda:0') tensor(0.5295, device='cuda:0') tensor(3.1659e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.050129
Average KL loss: 0.426029
Average total loss: 1.476158
tensor(-10.9230, device='cuda:0') tensor(0.5305, device='cuda:0') tensor(3.0828e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.050647
Average KL loss: 0.425554
Average total loss: 1.476201
tensor(-10.9498, device='cuda:0') tensor(0.5314, device='cuda:0') tensor(1.8653e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.047567
Average KL loss: 0.425029
Average total loss: 1.472596
tensor(-10.9765, device='cuda:0') tensor(0.5322, device='cuda:0') tensor(5.8119e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.048377
Average KL loss: 0.424530
Average total loss: 1.472907
tensor(-11.0031, device='cuda:0') tensor(0.5331, device='cuda:0') tensor(2.5868e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.046549
Average KL loss: 0.423997
Average total loss: 1.470546
tensor(-11.0296, device='cuda:0') tensor(0.5339, device='cuda:0') tensor(2.5954e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.045846
Average KL loss: 0.423038
Average total loss: 1.468884
tensor(-11.0561, device='cuda:0') tensor(0.5346, device='cuda:0') tensor(2.6205e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.046526
Average KL loss: 0.422013
Average total loss: 1.468539
tensor(-11.0825, device='cuda:0') tensor(0.5353, device='cuda:0') tensor(2.9620e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.044416
Average KL loss: 0.421204
Average total loss: 1.465619
tensor(-11.1088, device='cuda:0') tensor(0.5361, device='cuda:0') tensor(1.9853e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.044308
Average KL loss: 0.420564
Average total loss: 1.464872
tensor(-11.1350, device='cuda:0') tensor(0.5369, device='cuda:0') tensor(2.4632e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.044869
Average KL loss: 0.419553
Average total loss: 1.464422
tensor(-11.1612, device='cuda:0') tensor(0.5377, device='cuda:0') tensor(2.0789e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.042668
Average KL loss: 0.419134
Average total loss: 1.461802
tensor(-11.1873, device='cuda:0') tensor(0.5386, device='cuda:0') tensor(2.2892e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.041838
Average KL loss: 0.418775
Average total loss: 1.460613
tensor(-11.2133, device='cuda:0') tensor(0.5394, device='cuda:0') tensor(1.8025e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.041407
Average KL loss: 0.418409
Average total loss: 1.459816
tensor(-11.2392, device='cuda:0') tensor(0.5403, device='cuda:0') tensor(1.9205e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.040035
Average KL loss: 0.417980
Average total loss: 1.458015
tensor(-11.2651, device='cuda:0') tensor(0.5410, device='cuda:0') tensor(1.7916e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.039853
Average KL loss: 0.417312
Average total loss: 1.457166
tensor(-11.2909, device='cuda:0') tensor(0.5419, device='cuda:0') tensor(1.9275e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.040144
Average KL loss: 0.416776
Average total loss: 1.456920
tensor(-11.3167, device='cuda:0') tensor(0.5427, device='cuda:0') tensor(2.6036e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.040800
Average KL loss: 0.415999
Average total loss: 1.456799
tensor(-11.3424, device='cuda:0') tensor(0.5434, device='cuda:0') tensor(1.9593e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.038888
Average KL loss: 0.415349
Average total loss: 1.454237
tensor(-11.3680, device='cuda:0') tensor(0.5441, device='cuda:0') tensor(1.3772e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.038790
Average KL loss: 0.414895
Average total loss: 1.453685
tensor(-11.3936, device='cuda:0') tensor(0.5448, device='cuda:0') tensor(2.6596e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.039956
Average KL loss: 0.414109
Average total loss: 1.454065
tensor(-11.4191, device='cuda:0') tensor(0.5455, device='cuda:0') tensor(1.8209e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.038347
Average KL loss: 0.413385
Average total loss: 1.451732
tensor(-11.4445, device='cuda:0') tensor(0.5462, device='cuda:0') tensor(2.0521e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.036704
Average KL loss: 0.413092
Average total loss: 1.449795
tensor(-11.4699, device='cuda:0') tensor(0.5469, device='cuda:0') tensor(2.2865e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.036345
Average KL loss: 0.412652
Average total loss: 1.448997
tensor(-11.4952, device='cuda:0') tensor(0.5476, device='cuda:0') tensor(1.9592e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.036420
Average KL loss: 0.412246
Average total loss: 1.448666
tensor(-11.5205, device='cuda:0') tensor(0.5482, device='cuda:0') tensor(1.5419e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.034974
Average KL loss: 0.412027
Average total loss: 1.447000
tensor(-11.5457, device='cuda:0') tensor(0.5488, device='cuda:0') tensor(1.4373e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.034925
Average KL loss: 0.411853
Average total loss: 1.446778
tensor(-11.5709, device='cuda:0') tensor(0.5495, device='cuda:0') tensor(1.6886e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.034272
Average KL loss: 0.411284
Average total loss: 1.445556
tensor(-11.5960, device='cuda:0') tensor(0.5500, device='cuda:0') tensor(2.1093e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.034978
Average KL loss: 0.410631
Average total loss: 1.445609
tensor(-11.6210, device='cuda:0') tensor(0.5506, device='cuda:0') tensor(2.1073e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.034580
Average KL loss: 0.409917
Average total loss: 1.444497
tensor(-11.6460, device='cuda:0') tensor(0.5512, device='cuda:0') tensor(1.4734e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.035459
Average KL loss: 0.409489
Average total loss: 1.444947
tensor(-11.6710, device='cuda:0') tensor(0.5519, device='cuda:0') tensor(1.0616e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.035419
Average KL loss: 0.409047
Average total loss: 1.444466
tensor(-11.6958, device='cuda:0') tensor(0.5526, device='cuda:0') tensor(1.4686e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.033370
Average KL loss: 0.408752
Average total loss: 1.442122
tensor(-11.7207, device='cuda:0') tensor(0.5533, device='cuda:0') tensor(1.6681e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.032545
Average KL loss: 0.408616
Average total loss: 1.441160
tensor(-11.7454, device='cuda:0') tensor(0.5541, device='cuda:0') tensor(4.0670e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.033754
Average KL loss: 0.408339
Average total loss: 1.442093
tensor(-11.7702, device='cuda:0') tensor(0.5546, device='cuda:0') tensor(4.9982e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.033229
Average KL loss: 0.407702
Average total loss: 1.440931
tensor(-11.7948, device='cuda:0') tensor(0.5552, device='cuda:0') tensor(1.1489e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.033212
Average KL loss: 0.407034
Average total loss: 1.440246
tensor(-11.8195, device='cuda:0') tensor(0.5558, device='cuda:0') tensor(1.0543e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.032621
Average KL loss: 0.406371
Average total loss: 1.438991
tensor(-11.8440, device='cuda:0') tensor(0.5564, device='cuda:0') tensor(8.1067e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.033187
Average KL loss: 0.405940
Average total loss: 1.439128
tensor(-11.8686, device='cuda:0') tensor(0.5568, device='cuda:0') tensor(1.3986e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.033065
Average KL loss: 0.405515
Average total loss: 1.438581
tensor(-11.8930, device='cuda:0') tensor(0.5573, device='cuda:0') tensor(1.1513e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.032888
Average KL loss: 0.405101
Average total loss: 1.437989
tensor(-11.9175, device='cuda:0') tensor(0.5578, device='cuda:0') tensor(1.6574e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.032007
Average KL loss: 0.404528
Average total loss: 1.436535
tensor(-11.9418, device='cuda:0') tensor(0.5583, device='cuda:0') tensor(8.2446e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.033074
Average KL loss: 0.404073
Average total loss: 1.437147
tensor(-11.9662, device='cuda:0') tensor(0.5589, device='cuda:0') tensor(1.8221e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.031765
Average KL loss: 0.403960
Average total loss: 1.435725
tensor(-11.9904, device='cuda:0') tensor(0.5593, device='cuda:0') tensor(9.2553e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.031738
Average KL loss: 0.403734
Average total loss: 1.435472
tensor(-12.0147, device='cuda:0') tensor(0.5597, device='cuda:0') tensor(1.5093e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.030265
Average KL loss: 0.403442
Average total loss: 1.433707
tensor(-12.0388, device='cuda:0') tensor(0.5600, device='cuda:0') tensor(1.3466e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.030325
Average KL loss: 0.403076
Average total loss: 1.433401
tensor(-12.0630, device='cuda:0') tensor(0.5603, device='cuda:0') tensor(1.4704e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.030306
Average KL loss: 0.402628
Average total loss: 1.432933
tensor(-12.0871, device='cuda:0') tensor(0.5607, device='cuda:0') tensor(1.3707e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.030536
Average KL loss: 0.402482
Average total loss: 1.433018
tensor(-12.1111, device='cuda:0') tensor(0.5611, device='cuda:0') tensor(7.3354e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.028938
Average KL loss: 0.402429
Average total loss: 1.431366
tensor(-12.1351, device='cuda:0') tensor(0.5616, device='cuda:0') tensor(7.7466e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.028100
Average KL loss: 0.402249
Average total loss: 1.430350
tensor(-12.1590, device='cuda:0') tensor(0.5619, device='cuda:0') tensor(9.7508e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.028564
Average KL loss: 0.401964
Average total loss: 1.430528
tensor(-12.1829, device='cuda:0') tensor(0.5623, device='cuda:0') tensor(-3.3007e-11, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.028211
Average KL loss: 0.401980
Average total loss: 1.430190
tensor(-12.2067, device='cuda:0') tensor(0.5627, device='cuda:0') tensor(9.8812e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.028621
Average KL loss: 0.401896
Average total loss: 1.430517
tensor(-12.2305, device='cuda:0') tensor(0.5631, device='cuda:0') tensor(3.2133e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.027582
Average KL loss: 0.401895
Average total loss: 1.429477
tensor(-12.2542, device='cuda:0') tensor(0.5635, device='cuda:0') tensor(1.1552e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.026939
Average KL loss: 0.401784
Average total loss: 1.428723
tensor(-12.2779, device='cuda:0') tensor(0.5639, device='cuda:0') tensor(1.3678e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.027327
Average KL loss: 0.401408
Average total loss: 1.428735
tensor(-12.3015, device='cuda:0') tensor(0.5642, device='cuda:0') tensor(7.4183e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.025836
Average KL loss: 0.401097
Average total loss: 1.426933
tensor(-12.3251, device='cuda:0') tensor(0.5645, device='cuda:0') tensor(9.9611e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.027662
Average KL loss: 0.401140
Average total loss: 1.428802
tensor(-12.3486, device='cuda:0') tensor(0.5648, device='cuda:0') tensor(3.6563e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.026355
Average KL loss: 0.401131
Average total loss: 1.427487
tensor(-12.3721, device='cuda:0') tensor(0.5651, device='cuda:0') tensor(9.6991e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.026456
Average KL loss: 0.400664
Average total loss: 1.427120
tensor(-12.3956, device='cuda:0') tensor(0.5652, device='cuda:0') tensor(1.0987e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.026492
Average KL loss: 0.400596
Average total loss: 1.427088
tensor(-12.4189, device='cuda:0') tensor(0.5655, device='cuda:0') tensor(-1.3096e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.024842
Average KL loss: 0.400529
Average total loss: 1.425371
tensor(-12.4423, device='cuda:0') tensor(0.5656, device='cuda:0') tensor(5.0535e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.024540
Average KL loss: 0.400201
Average total loss: 1.424742
tensor(-12.4655, device='cuda:0') tensor(0.5658, device='cuda:0') tensor(1.1435e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.026659
Average KL loss: 0.399867
Average total loss: 1.426526
tensor(-12.4888, device='cuda:0') tensor(0.5658, device='cuda:0') tensor(8.1391e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.024433
Average KL loss: 0.399589
Average total loss: 1.424022
tensor(-12.5120, device='cuda:0') tensor(0.5659, device='cuda:0') tensor(3.4614e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 1.025087
Average KL loss: 0.399240
Average total loss: 1.424327
tensor(-12.5351, device='cuda:0') tensor(0.5659, device='cuda:0') tensor(9.1280e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.024620
Average KL loss: 0.399029
Average total loss: 1.423649
tensor(-12.5582, device='cuda:0') tensor(0.5660, device='cuda:0') tensor(7.7137e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.024932
Average KL loss: 0.398581
Average total loss: 1.423514
tensor(-12.5812, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(1.0737e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 1.025728
Average KL loss: 0.398274
Average total loss: 1.424003
tensor(-12.6041, device='cuda:0') tensor(0.5660, device='cuda:0') tensor(6.6978e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 1.024904
Average KL loss: 0.397777
Average total loss: 1.422681
tensor(-12.6270, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(5.8585e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 1.026234
Average KL loss: 0.397377
Average total loss: 1.423611
tensor(-12.6499, device='cuda:0') tensor(0.5662, device='cuda:0') tensor(5.3168e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 1.026014
Average KL loss: 0.397348
Average total loss: 1.423362
tensor(-12.6727, device='cuda:0') tensor(0.5663, device='cuda:0') tensor(7.2697e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 1.026585
Average KL loss: 0.397235
Average total loss: 1.423819
tensor(-12.6954, device='cuda:0') tensor(0.5663, device='cuda:0') tensor(4.4797e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 1.024805
Average KL loss: 0.396999
Average total loss: 1.421804
tensor(-12.7181, device='cuda:0') tensor(0.5663, device='cuda:0') tensor(7.1507e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 1.024530
Average KL loss: 0.396966
Average total loss: 1.421496
tensor(-12.7408, device='cuda:0') tensor(0.5662, device='cuda:0') tensor(7.2094e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 1.025707
Average KL loss: 0.396757
Average total loss: 1.422464
tensor(-12.7633, device='cuda:0') tensor(0.5662, device='cuda:0') tensor(7.5941e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 1.026520
Average KL loss: 0.396555
Average total loss: 1.423075
tensor(-12.7859, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(3.5469e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 1.024413
Average KL loss: 0.396350
Average total loss: 1.420763
tensor(-12.8083, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(2.5803e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 1.024887
Average KL loss: 0.396262
Average total loss: 1.421149
tensor(-12.8307, device='cuda:0') tensor(0.5659, device='cuda:0') tensor(1.3641e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 1.025437
Average KL loss: 0.396286
Average total loss: 1.421723
tensor(-12.8531, device='cuda:0') tensor(0.5658, device='cuda:0') tensor(3.1525e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 1.024418
Average KL loss: 0.396236
Average total loss: 1.420653
tensor(-12.8753, device='cuda:0') tensor(0.5657, device='cuda:0') tensor(3.9494e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 1.025135
Average KL loss: 0.395995
Average total loss: 1.421130
tensor(-12.8976, device='cuda:0') tensor(0.5655, device='cuda:0') tensor(3.1674e-11, device='cuda:0')
Epoch 189
Average batch original loss after noise: 1.024948
Average KL loss: 0.395710
Average total loss: 1.420658
tensor(-12.9197, device='cuda:0') tensor(0.5653, device='cuda:0') tensor(7.8570e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 1.024555
Average KL loss: 0.395733
Average total loss: 1.420287
tensor(-12.9418, device='cuda:0') tensor(0.5652, device='cuda:0') tensor(4.1121e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 1.023229
Average KL loss: 0.395465
Average total loss: 1.418694
tensor(-12.9639, device='cuda:0') tensor(0.5650, device='cuda:0') tensor(5.1370e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 1.023501
Average KL loss: 0.395384
Average total loss: 1.418885
tensor(-12.9858, device='cuda:0') tensor(0.5648, device='cuda:0') tensor(-1.6232e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 1.024440
Average KL loss: 0.395432
Average total loss: 1.419871
tensor(-13.0078, device='cuda:0') tensor(0.5646, device='cuda:0') tensor(4.2628e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 1.022791
Average KL loss: 0.395329
Average total loss: 1.418120
tensor(-13.0296, device='cuda:0') tensor(0.5643, device='cuda:0') tensor(4.8285e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 1.023692
Average KL loss: 0.395203
Average total loss: 1.418895
tensor(-13.0514, device='cuda:0') tensor(0.5639, device='cuda:0') tensor(4.8902e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 1.023369
Average KL loss: 0.395155
Average total loss: 1.418524
tensor(-13.0731, device='cuda:0') tensor(0.5636, device='cuda:0') tensor(1.8995e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 1.022258
Average KL loss: 0.394885
Average total loss: 1.417144
tensor(-13.0948, device='cuda:0') tensor(0.5635, device='cuda:0') tensor(7.6229e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 1.023517
Average KL loss: 0.394877
Average total loss: 1.418394
tensor(-13.1164, device='cuda:0') tensor(0.5630, device='cuda:0') tensor(2.5166e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 1.022715
Average KL loss: 0.394636
Average total loss: 1.417351
tensor(-13.1379, device='cuda:0') tensor(0.5627, device='cuda:0') tensor(2.7065e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 1.021550
Average KL loss: 0.394395
Average total loss: 1.415945
 Percentile value: -13.162148475646973
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =    1717 /    1728             ( 99.36%) | total_pruned =      11 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   33779 /   36864             ( 91.63%) | total_pruned =    3085 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   34010 /   36864             ( 92.26%) | total_pruned =    2854 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   33261 /   36864             ( 90.23%) | total_pruned =    3603 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   32296 /   36864             ( 87.61%) | total_pruned =    4568 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   67063 /   73728             ( 90.96%) | total_pruned =    6665 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  123214 /  147456             ( 83.56%) | total_pruned =   24242 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7984 /    8192             ( 97.46%) | total_pruned =     208 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  120802 /  147456             ( 81.92%) | total_pruned =   26654 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  114719 /  147456             ( 77.80%) | total_pruned =   32737 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  244789 /  294912             ( 83.00%) | total_pruned =   50123 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  423542 /  589824             ( 71.81%) | total_pruned =  166282 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   30399 /   32768             ( 92.77%) | total_pruned =    2369 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  369489 /  589824             ( 62.64%) | total_pruned =  220335 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  336735 /  589824             ( 57.09%) | total_pruned =  253089 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  800332 / 1179648             ( 67.84%) | total_pruned =  379316 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1080170 / 2359296             ( 45.78%) | total_pruned = 1279126 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  108551 /  131072             ( 82.82%) | total_pruned =   22521 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  943838 / 2359296             ( 40.01%) | total_pruned = 1415458 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  668014 / 2359296             ( 28.31%) | total_pruned = 1691282 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
linear.weight        | nonzeros =    5092 /    5120             ( 99.45%) | total_pruned =      28 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 33/100 Loss: 0.000003 Accuracy: 87.00 100.00 % Best test Accuracy: 87.00%
tensor(-13.1594, device='cuda:0') tensor(0.5623, device='cuda:0') tensor(1.8277e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.077476
Average KL loss: 0.389841
Average total loss: 1.467317
tensor(-13.2719, device='cuda:0') tensor(0.3770, device='cuda:0') tensor(-2.9889e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.148348
Average KL loss: 0.370724
Average total loss: 1.519072
tensor(-13.3643, device='cuda:0') tensor(0.2946, device='cuda:0') tensor(-1.0987e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.177110
Average KL loss: 0.361422
Average total loss: 1.538532
tensor(-13.4452, device='cuda:0') tensor(0.2536, device='cuda:0') tensor(-9.6615e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.164385
Average KL loss: 0.358954
Average total loss: 1.523340
tensor(-13.5182, device='cuda:0') tensor(0.2280, device='cuda:0') tensor(-6.3494e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.140786
Average KL loss: 0.358667
Average total loss: 1.499453
tensor(-13.5852, device='cuda:0') tensor(0.2102, device='cuda:0') tensor(-4.7903e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.125926
Average KL loss: 0.358293
Average total loss: 1.484219
tensor(-13.6473, device='cuda:0') tensor(0.1974, device='cuda:0') tensor(-5.3457e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.116181
Average KL loss: 0.358373
Average total loss: 1.474553
tensor(-13.7054, device='cuda:0') tensor(0.1879, device='cuda:0') tensor(-2.9062e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.104184
Average KL loss: 0.358744
Average total loss: 1.462928
tensor(-13.7599, device='cuda:0') tensor(0.1806, device='cuda:0') tensor(-4.5292e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.098446
Average KL loss: 0.358272
Average total loss: 1.456718
tensor(-13.8113, device='cuda:0') tensor(0.1748, device='cuda:0') tensor(-2.4634e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.090991
Average KL loss: 0.357882
Average total loss: 1.448873
tensor(-13.8600, device='cuda:0') tensor(0.1704, device='cuda:0') tensor(-2.4311e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.086295
Average KL loss: 0.357612
Average total loss: 1.443907
tensor(-13.9064, device='cuda:0') tensor(0.1668, device='cuda:0') tensor(-3.5285e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.082692
Average KL loss: 0.357168
Average total loss: 1.439860
tensor(-13.9505, device='cuda:0') tensor(0.1638, device='cuda:0') tensor(-4.2689e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.081928
Average KL loss: 0.356602
Average total loss: 1.438530
tensor(-13.9927, device='cuda:0') tensor(0.1615, device='cuda:0') tensor(-1.1578e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.078129
Average KL loss: 0.356651
Average total loss: 1.434780
tensor(-14.0331, device='cuda:0') tensor(0.1598, device='cuda:0') tensor(-1.5229e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.071404
Average KL loss: 0.356427
Average total loss: 1.427831
tensor(-14.0719, device='cuda:0') tensor(0.1582, device='cuda:0') tensor(-1.2952e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.069650
Average KL loss: 0.356399
Average total loss: 1.426050
tensor(-14.1092, device='cuda:0') tensor(0.1570, device='cuda:0') tensor(-2.2349e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.066285
Average KL loss: 0.355762
Average total loss: 1.422047
tensor(-14.1451, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(-3.4189e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.065871
Average KL loss: 0.355334
Average total loss: 1.421205
tensor(-14.1797, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(-3.8455e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.065655
Average KL loss: 0.354645
Average total loss: 1.420300
tensor(-14.2132, device='cuda:0') tensor(0.1547, device='cuda:0') tensor(-2.1483e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.063536
Average KL loss: 0.354239
Average total loss: 1.417775
tensor(-14.2455, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(-9.9325e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.062013
Average KL loss: 0.354071
Average total loss: 1.416084
tensor(-14.2768, device='cuda:0') tensor(0.1540, device='cuda:0') tensor(-3.7547e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.063217
Average KL loss: 0.353777
Average total loss: 1.416995
tensor(-14.3071, device='cuda:0') tensor(0.1537, device='cuda:0') tensor(-1.9704e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.061546
Average KL loss: 0.353415
Average total loss: 1.414961
tensor(-14.3365, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(-1.7082e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.058000
Average KL loss: 0.353274
Average total loss: 1.411274
tensor(-14.3651, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(-2.9638e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.060155
Average KL loss: 0.352871
Average total loss: 1.413026
tensor(-14.3928, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(-4.2976e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.060625
Average KL loss: 0.352581
Average total loss: 1.413206
tensor(-14.4198, device='cuda:0') tensor(0.1537, device='cuda:0') tensor(-1.1733e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.056497
Average KL loss: 0.352320
Average total loss: 1.408816
tensor(-14.4461, device='cuda:0') tensor(0.1538, device='cuda:0') tensor(-3.3358e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.058474
Average KL loss: 0.351903
Average total loss: 1.410377
tensor(-14.4717, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(-9.0055e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.057790
Average KL loss: 0.351700
Average total loss: 1.409490
tensor(-14.4967, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(-4.4238e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.055601
Average KL loss: 0.351557
Average total loss: 1.407158
tensor(-14.5210, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(-2.4036e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.054455
Average KL loss: 0.351351
Average total loss: 1.405806
tensor(-14.5447, device='cuda:0') tensor(0.1551, device='cuda:0') tensor(-1.4508e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.051882
Average KL loss: 0.351265
Average total loss: 1.403147
tensor(-14.5679, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(6.3394e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.053856
Average KL loss: 0.351127
Average total loss: 1.404983
tensor(-14.5906, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(-2.9271e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.052530
Average KL loss: 0.350968
Average total loss: 1.403499
tensor(-14.6128, device='cuda:0') tensor(0.1559, device='cuda:0') tensor(1.2301e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.052573
Average KL loss: 0.350705
Average total loss: 1.403278
tensor(-14.6344, device='cuda:0') tensor(0.1563, device='cuda:0') tensor(-1.0237e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.050861
Average KL loss: 0.350711
Average total loss: 1.401572
tensor(-14.6556, device='cuda:0') tensor(0.1569, device='cuda:0') tensor(-6.3566e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.052380
Average KL loss: 0.350621
Average total loss: 1.403001
tensor(-14.6764, device='cuda:0') tensor(0.1574, device='cuda:0') tensor(-1.7032e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.050796
Average KL loss: 0.350413
Average total loss: 1.401208
tensor(-14.6968, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(-4.3904e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.050579
Average KL loss: 0.350326
Average total loss: 1.400904
tensor(-14.7167, device='cuda:0') tensor(0.1583, device='cuda:0') tensor(-5.4464e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.049283
Average KL loss: 0.350114
Average total loss: 1.399397
tensor(-14.7362, device='cuda:0') tensor(0.1587, device='cuda:0') tensor(-7.8082e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.049037
Average KL loss: 0.350019
Average total loss: 1.399055
tensor(-14.7554, device='cuda:0') tensor(0.1591, device='cuda:0') tensor(-6.7529e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.049816
Average KL loss: 0.349847
Average total loss: 1.399663
tensor(-14.7742, device='cuda:0') tensor(0.1595, device='cuda:0') tensor(-2.6739e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.048705
Average KL loss: 0.349765
Average total loss: 1.398470
tensor(-14.7927, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-3.7103e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.048380
Average KL loss: 0.349722
Average total loss: 1.398101
tensor(-14.8108, device='cuda:0') tensor(0.1605, device='cuda:0') tensor(-1.6975e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.048834
Average KL loss: 0.349514
Average total loss: 1.398348
tensor(-14.8286, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(2.2838e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.047862
Average KL loss: 0.349156
Average total loss: 1.397018
tensor(-14.8461, device='cuda:0') tensor(0.1613, device='cuda:0') tensor(-7.8750e-11, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.049783
Average KL loss: 0.348970
Average total loss: 1.398753
tensor(-14.8633, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(-4.0889e-11, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.049031
Average KL loss: 0.348710
Average total loss: 1.397741
tensor(-14.8802, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(-1.1298e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.047674
Average KL loss: 0.348554
Average total loss: 1.396227
tensor(-14.8968, device='cuda:0') tensor(0.1627, device='cuda:0') tensor(-1.0586e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.049311
Average KL loss: 0.348627
Average total loss: 1.397938
tensor(-14.9131, device='cuda:0') tensor(0.1633, device='cuda:0') tensor(-1.9659e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.047354
Average KL loss: 0.348506
Average total loss: 1.395860
tensor(-14.9292, device='cuda:0') tensor(0.1638, device='cuda:0') tensor(-6.1850e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.047607
Average KL loss: 0.348330
Average total loss: 1.395937
tensor(-14.9450, device='cuda:0') tensor(0.1643, device='cuda:0') tensor(-1.2317e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.048079
Average KL loss: 0.348205
Average total loss: 1.396284
tensor(-14.9606, device='cuda:0') tensor(0.1647, device='cuda:0') tensor(-1.0082e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.046109
Average KL loss: 0.348252
Average total loss: 1.394361
tensor(-14.9759, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-2.6635e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.048727
Average KL loss: 0.348102
Average total loss: 1.396829
tensor(-14.9910, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(1.7334e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.046897
Average KL loss: 0.348023
Average total loss: 1.394920
tensor(-15.0059, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-3.7845e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.046587
Average KL loss: 0.347983
Average total loss: 1.394570
tensor(-15.0205, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-1.5559e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.045529
Average KL loss: 0.347916
Average total loss: 1.393445
tensor(-15.0350, device='cuda:0') tensor(0.1669, device='cuda:0') tensor(-2.2225e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.047156
Average KL loss: 0.347823
Average total loss: 1.394978
tensor(-15.0492, device='cuda:0') tensor(0.1674, device='cuda:0') tensor(-2.5620e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.045919
Average KL loss: 0.347838
Average total loss: 1.393756
tensor(-15.0633, device='cuda:0') tensor(0.1679, device='cuda:0') tensor(-6.7656e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.046270
Average KL loss: 0.347828
Average total loss: 1.394099
tensor(-15.0771, device='cuda:0') tensor(0.1683, device='cuda:0') tensor(-1.9286e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.046247
Average KL loss: 0.347683
Average total loss: 1.393930
tensor(-15.0908, device='cuda:0') tensor(0.1687, device='cuda:0') tensor(-6.9045e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.046583
Average KL loss: 0.347676
Average total loss: 1.394259
tensor(-15.1042, device='cuda:0') tensor(0.1691, device='cuda:0') tensor(-2.1175e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.046759
Average KL loss: 0.347631
Average total loss: 1.394390
tensor(-15.1175, device='cuda:0') tensor(0.1697, device='cuda:0') tensor(1.1305e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.045827
Average KL loss: 0.347704
Average total loss: 1.393531
tensor(-15.1307, device='cuda:0') tensor(0.1702, device='cuda:0') tensor(5.7109e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.045550
Average KL loss: 0.347853
Average total loss: 1.393403
tensor(-15.1436, device='cuda:0') tensor(0.1706, device='cuda:0') tensor(4.1463e-11, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.046124
Average KL loss: 0.347925
Average total loss: 1.394049
tensor(-15.1564, device='cuda:0') tensor(0.1711, device='cuda:0') tensor(-2.9969e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.046244
Average KL loss: 0.347871
Average total loss: 1.394115
tensor(-15.1690, device='cuda:0') tensor(0.1716, device='cuda:0') tensor(1.5761e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.046824
Average KL loss: 0.347834
Average total loss: 1.394658
tensor(-15.1815, device='cuda:0') tensor(0.1720, device='cuda:0') tensor(-5.3379e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.044498
Average KL loss: 0.347896
Average total loss: 1.392395
tensor(-15.1827, device='cuda:0') tensor(0.1720, device='cuda:0') tensor(-3.3659e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.045103
Average KL loss: 0.347891
Average total loss: 1.392994
tensor(-15.1839, device='cuda:0') tensor(0.1721, device='cuda:0') tensor(5.1777e-11, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.044336
Average KL loss: 0.347891
Average total loss: 1.392226
tensor(-15.1852, device='cuda:0') tensor(0.1721, device='cuda:0') tensor(-2.2147e-12, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.045375
Average KL loss: 0.347877
Average total loss: 1.393253
tensor(-15.1864, device='cuda:0') tensor(0.1721, device='cuda:0') tensor(3.7227e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.046349
Average KL loss: 0.347862
Average total loss: 1.394212
tensor(-15.1876, device='cuda:0') tensor(0.1722, device='cuda:0') tensor(-1.6609e-11, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.045465
Average KL loss: 0.347873
Average total loss: 1.393339
tensor(-15.1888, device='cuda:0') tensor(0.1722, device='cuda:0') tensor(-1.1470e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.045362
Average KL loss: 0.347872
Average total loss: 1.393234
tensor(-15.1901, device='cuda:0') tensor(0.1722, device='cuda:0') tensor(-2.5028e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.046020
Average KL loss: 0.347866
Average total loss: 1.393886
tensor(-15.1913, device='cuda:0') tensor(0.1723, device='cuda:0') tensor(-3.0577e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.045297
Average KL loss: 0.347868
Average total loss: 1.393165
tensor(-15.1925, device='cuda:0') tensor(0.1723, device='cuda:0') tensor(4.6972e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.045363
Average KL loss: 0.347872
Average total loss: 1.393235
tensor(-15.1937, device='cuda:0') tensor(0.1723, device='cuda:0') tensor(-4.9519e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.044758
Average KL loss: 0.347862
Average total loss: 1.392620
tensor(-15.1949, device='cuda:0') tensor(0.1724, device='cuda:0') tensor(1.5849e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.044929
Average KL loss: 0.347854
Average total loss: 1.392783
tensor(-15.1962, device='cuda:0') tensor(0.1724, device='cuda:0') tensor(2.9163e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.044969
Average KL loss: 0.347852
Average total loss: 1.392821
tensor(-15.1974, device='cuda:0') tensor(0.1724, device='cuda:0') tensor(-4.7746e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.045576
Average KL loss: 0.347857
Average total loss: 1.393433
tensor(-15.1986, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(2.0925e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.045110
Average KL loss: 0.347856
Average total loss: 1.392965
tensor(-15.1987, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-1.5203e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.045066
Average KL loss: 0.347856
Average total loss: 1.392922
tensor(-15.1989, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-1.9819e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.044570
Average KL loss: 0.347857
Average total loss: 1.392427
tensor(-15.1990, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(9.8559e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.045002
Average KL loss: 0.347857
Average total loss: 1.392858
tensor(-15.1991, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-5.4645e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.045289
Average KL loss: 0.347857
Average total loss: 1.393146
tensor(-15.1993, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-2.9943e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.044893
Average KL loss: 0.347858
Average total loss: 1.392751
tensor(-15.1994, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-1.7818e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.044035
Average KL loss: 0.347858
Average total loss: 1.391893
tensor(-15.1996, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-1.1735e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.045260
Average KL loss: 0.347858
Average total loss: 1.393118
tensor(-15.1997, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-1.3737e-11, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.043874
Average KL loss: 0.347858
Average total loss: 1.391732
tensor(-15.1998, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-2.7646e-11, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.047073
Average KL loss: 0.347858
Average total loss: 1.394932
tensor(-15.2000, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-1.1451e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.043602
Average KL loss: 0.347860
Average total loss: 1.391461
tensor(-15.2001, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-1.5630e-11, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.045816
Average KL loss: 0.347860
Average total loss: 1.393676
tensor(-15.2003, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-3.8805e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.044525
Average KL loss: 0.347860
Average total loss: 1.392384
tensor(-15.2004, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-2.5789e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.045558
Average KL loss: 0.347859
Average total loss: 1.393416
tensor(-15.2005, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-9.1438e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.045181
Average KL loss: 0.347859
Average total loss: 1.393040
tensor(-15.2007, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(4.3652e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.044579
Average KL loss: 0.347858
Average total loss: 1.392438
tensor(-15.2008, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-2.5157e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.043896
Average KL loss: 0.347858
Average total loss: 1.391754
tensor(-15.2010, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(3.0323e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.044880
Average KL loss: 0.347859
Average total loss: 1.392739
tensor(-15.2011, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(3.4324e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.045254
Average KL loss: 0.347859
Average total loss: 1.393112
tensor(-15.2012, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-1.3699e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.044157
Average KL loss: 0.347859
Average total loss: 1.392016
tensor(-15.2014, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(5.0986e-11, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.045715
Average KL loss: 0.347858
Average total loss: 1.393573
tensor(-15.2015, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-3.6418e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.044355
Average KL loss: 0.347858
Average total loss: 1.392213
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-4.6332e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.044565
Average KL loss: 0.347859
Average total loss: 1.392423
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(1.3306e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.043908
Average KL loss: 0.347859
Average total loss: 1.391767
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-2.0496e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.043819
Average KL loss: 0.347859
Average total loss: 1.391678
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-2.9832e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.045805
Average KL loss: 0.347859
Average total loss: 1.393663
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(2.4745e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.045112
Average KL loss: 0.347859
Average total loss: 1.392971
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-5.7860e-12, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.045247
Average KL loss: 0.347859
Average total loss: 1.393106
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-7.4543e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.044929
Average KL loss: 0.347859
Average total loss: 1.392787
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-7.1500e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.045219
Average KL loss: 0.347859
Average total loss: 1.393077
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(7.1952e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.044211
Average KL loss: 0.347859
Average total loss: 1.392070
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-1.2759e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.045378
Average KL loss: 0.347859
Average total loss: 1.393237
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-7.5626e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.043988
Average KL loss: 0.347859
Average total loss: 1.391847
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-6.1118e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.043883
Average KL loss: 0.347859
Average total loss: 1.391742
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-6.4829e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.045579
Average KL loss: 0.347859
Average total loss: 1.393438
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(8.3460e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.045334
Average KL loss: 0.347859
Average total loss: 1.393193
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-1.6887e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.044351
Average KL loss: 0.347859
Average total loss: 1.392210
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-1.1174e-11, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.045337
Average KL loss: 0.347859
Average total loss: 1.393196
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-4.4969e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.045136
Average KL loss: 0.347859
Average total loss: 1.392995
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(2.4784e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.045162
Average KL loss: 0.347859
Average total loss: 1.393021
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(2.5783e-11, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.044846
Average KL loss: 0.347859
Average total loss: 1.392705
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-1.9659e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.045123
Average KL loss: 0.347859
Average total loss: 1.392982
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-9.6295e-12, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.043904
Average KL loss: 0.347859
Average total loss: 1.391763
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-6.8306e-10, device='cuda:0')
 Percentile value: -15.135664939880371
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =    1685 /    1728             ( 97.51%) | total_pruned =      43 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   29501 /   36864             ( 80.03%) | total_pruned =    7363 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   29876 /   36864             ( 81.04%) | total_pruned =    6988 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   28030 /   36864             ( 76.04%) | total_pruned =    8834 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   26428 /   36864             ( 71.69%) | total_pruned =   10436 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   56113 /   73728             ( 76.11%) | total_pruned =   17615 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   93545 /  147456             ( 63.44%) | total_pruned =   53911 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7574 /    8192             ( 92.46%) | total_pruned =     618 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   85266 /  147456             ( 57.82%) | total_pruned =   62190 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   78720 /  147456             ( 53.39%) | total_pruned =   68736 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  174232 /  294912             ( 59.08%) | total_pruned =  120680 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  262309 /  589824             ( 44.47%) | total_pruned =  327515 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   26435 /   32768             ( 80.67%) | total_pruned =    6333 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  179418 /  589824             ( 30.42%) | total_pruned =  410406 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  162459 /  589824             ( 27.54%) | total_pruned =  427365 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  418030 / 1179648             ( 35.44%) | total_pruned =  761618 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  435905 / 2359296             ( 18.48%) | total_pruned = 1923391 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   78517 /  131072             ( 59.90%) | total_pruned =   52555 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  343388 / 2359296             ( 14.55%) | total_pruned = 2015908 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     462 /     512             ( 90.23%) | total_pruned =      50 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  262714 / 2359296             ( 11.14%) | total_pruned = 2096582 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
linear.weight        | nonzeros =    5020 /    5120             ( 98.05%) | total_pruned =     100 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 35/100 Loss: 0.000018 Accuracy: 86.85 100.00 % Best test Accuracy: 86.85%
tensor(-15.2017, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-5.5212e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.153410
Average KL loss: 0.343140
Average total loss: 1.496550
tensor(-15.2149, device='cuda:0') tensor(0.1266, device='cuda:0') tensor(-9.5033e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.270776
Average KL loss: 0.325088
Average total loss: 1.595864
tensor(-15.2271, device='cuda:0') tensor(0.1183, device='cuda:0') tensor(-8.9369e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.226348
Average KL loss: 0.320834
Average total loss: 1.547182
tensor(-15.2390, device='cuda:0') tensor(0.1186, device='cuda:0') tensor(-4.2624e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.191515
Average KL loss: 0.320518
Average total loss: 1.512033
tensor(-15.2506, device='cuda:0') tensor(0.1196, device='cuda:0') tensor(-3.7659e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.174843
Average KL loss: 0.320525
Average total loss: 1.495367
tensor(-15.2622, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-7.0306e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.150535
Average KL loss: 0.320499
Average total loss: 1.471034
tensor(-15.2736, device='cuda:0') tensor(0.1222, device='cuda:0') tensor(-6.2305e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.142133
Average KL loss: 0.320758
Average total loss: 1.462890
tensor(-15.2848, device='cuda:0') tensor(0.1234, device='cuda:0') tensor(8.1460e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.136680
Average KL loss: 0.320462
Average total loss: 1.457142
tensor(-15.2959, device='cuda:0') tensor(0.1246, device='cuda:0') tensor(-3.7150e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.127424
Average KL loss: 0.320071
Average total loss: 1.447495
tensor(-15.3070, device='cuda:0') tensor(0.1257, device='cuda:0') tensor(-2.5313e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.121706
Average KL loss: 0.319979
Average total loss: 1.441685
tensor(-15.3179, device='cuda:0') tensor(0.1268, device='cuda:0') tensor(-1.5484e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.114754
Average KL loss: 0.320131
Average total loss: 1.434885
tensor(-15.3286, device='cuda:0') tensor(0.1278, device='cuda:0') tensor(-2.4290e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.108666
Average KL loss: 0.320365
Average total loss: 1.429031
tensor(-15.3393, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-1.1775e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.104871
Average KL loss: 0.320559
Average total loss: 1.425430
tensor(-15.3498, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-1.2295e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.104137
Average KL loss: 0.320434
Average total loss: 1.424570
tensor(-15.3603, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.9596e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.102505
Average KL loss: 0.320106
Average total loss: 1.422611
tensor(-15.3706, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-2.2589e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.100153
Average KL loss: 0.319731
Average total loss: 1.419884
tensor(-15.3808, device='cuda:0') tensor(0.1324, device='cuda:0') tensor(8.9825e-11, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.095116
Average KL loss: 0.319551
Average total loss: 1.414667
tensor(-15.3909, device='cuda:0') tensor(0.1330, device='cuda:0') tensor(-1.7259e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.094387
Average KL loss: 0.319354
Average total loss: 1.413742
tensor(-15.4010, device='cuda:0') tensor(0.1338, device='cuda:0') tensor(1.2400e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.091340
Average KL loss: 0.319022
Average total loss: 1.410362
tensor(-15.4109, device='cuda:0') tensor(0.1346, device='cuda:0') tensor(-1.1076e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.089158
Average KL loss: 0.318837
Average total loss: 1.407995
tensor(-15.4207, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-3.9849e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.087729
Average KL loss: 0.318574
Average total loss: 1.406304
tensor(-15.4304, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-8.4569e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.089669
Average KL loss: 0.318368
Average total loss: 1.408037
tensor(-15.4400, device='cuda:0') tensor(0.1369, device='cuda:0') tensor(-4.0923e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.087331
Average KL loss: 0.318507
Average total loss: 1.405837
tensor(-15.4496, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-4.2914e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.088359
Average KL loss: 0.318163
Average total loss: 1.406522
tensor(-15.4590, device='cuda:0') tensor(0.1382, device='cuda:0') tensor(-6.3133e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.086915
Average KL loss: 0.317967
Average total loss: 1.404881
tensor(-15.4684, device='cuda:0') tensor(0.1388, device='cuda:0') tensor(5.0295e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.085360
Average KL loss: 0.317846
Average total loss: 1.403207
tensor(-15.4777, device='cuda:0') tensor(0.1394, device='cuda:0') tensor(-1.6896e-11, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.083432
Average KL loss: 0.317477
Average total loss: 1.400910
tensor(-15.4869, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(-1.8116e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.084164
Average KL loss: 0.317426
Average total loss: 1.401590
tensor(-15.4960, device='cuda:0') tensor(0.1407, device='cuda:0') tensor(7.0246e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.082611
Average KL loss: 0.317460
Average total loss: 1.400071
tensor(-15.5050, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-1.3135e-11, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.082442
Average KL loss: 0.317381
Average total loss: 1.399823
tensor(-15.5139, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-2.7665e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.080840
Average KL loss: 0.317199
Average total loss: 1.398039
tensor(-15.5228, device='cuda:0') tensor(0.1426, device='cuda:0') tensor(5.4257e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.077796
Average KL loss: 0.317169
Average total loss: 1.394964
tensor(-15.5316, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-1.3427e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.078471
Average KL loss: 0.316931
Average total loss: 1.395402
tensor(-15.5403, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(-9.1207e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.081108
Average KL loss: 0.316655
Average total loss: 1.397764
tensor(-15.5489, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(-7.5528e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.077406
Average KL loss: 0.316531
Average total loss: 1.393937
tensor(-15.5575, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(-8.8986e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.078521
Average KL loss: 0.316178
Average total loss: 1.394699
tensor(-15.5659, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(-5.2416e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.078559
Average KL loss: 0.316106
Average total loss: 1.394665
tensor(-15.5744, device='cuda:0') tensor(0.1456, device='cuda:0') tensor(-7.3503e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.079064
Average KL loss: 0.316005
Average total loss: 1.395069
tensor(-15.5827, device='cuda:0') tensor(0.1462, device='cuda:0') tensor(-7.3040e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.077973
Average KL loss: 0.316075
Average total loss: 1.394048
tensor(-15.5910, device='cuda:0') tensor(0.1468, device='cuda:0') tensor(-8.5874e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.075855
Average KL loss: 0.315935
Average total loss: 1.391790
tensor(-15.5992, device='cuda:0') tensor(0.1474, device='cuda:0') tensor(-7.7918e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.076047
Average KL loss: 0.315719
Average total loss: 1.391766
tensor(-15.6073, device='cuda:0') tensor(0.1480, device='cuda:0') tensor(-1.0064e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.076561
Average KL loss: 0.315613
Average total loss: 1.392173
tensor(-15.6154, device='cuda:0') tensor(0.1485, device='cuda:0') tensor(-8.2446e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.077092
Average KL loss: 0.315365
Average total loss: 1.392457
tensor(-15.6234, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(-2.3493e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.074542
Average KL loss: 0.315267
Average total loss: 1.389809
tensor(-15.6313, device='cuda:0') tensor(0.1496, device='cuda:0') tensor(-1.1717e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.075709
Average KL loss: 0.315242
Average total loss: 1.390951
tensor(-15.6392, device='cuda:0') tensor(0.1501, device='cuda:0') tensor(-9.7010e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.075608
Average KL loss: 0.315139
Average total loss: 1.390747
tensor(-15.6470, device='cuda:0') tensor(0.1505, device='cuda:0') tensor(-3.2732e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.075255
Average KL loss: 0.315005
Average total loss: 1.390260
tensor(-15.6548, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(-2.7338e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.076103
Average KL loss: 0.314982
Average total loss: 1.391084
tensor(-15.6625, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-7.3525e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.074005
Average KL loss: 0.315068
Average total loss: 1.389073
tensor(-15.6701, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(7.5957e-11, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.073489
Average KL loss: 0.314949
Average total loss: 1.388439
tensor(-15.6777, device='cuda:0') tensor(0.1526, device='cuda:0') tensor(2.3961e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.072986
Average KL loss: 0.314940
Average total loss: 1.387926
tensor(-15.6852, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(2.0771e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.073280
Average KL loss: 0.314953
Average total loss: 1.388233
tensor(-15.6927, device='cuda:0') tensor(0.1535, device='cuda:0') tensor(8.7105e-11, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.073763
Average KL loss: 0.314799
Average total loss: 1.388562
tensor(-15.7001, device='cuda:0') tensor(0.1540, device='cuda:0') tensor(1.8451e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.075869
Average KL loss: 0.314659
Average total loss: 1.390528
tensor(-15.7075, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(4.8389e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.072725
Average KL loss: 0.314470
Average total loss: 1.387195
tensor(-15.7148, device='cuda:0') tensor(0.1549, device='cuda:0') tensor(-1.4587e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.073168
Average KL loss: 0.314485
Average total loss: 1.387653
tensor(-15.7220, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-3.5965e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.073788
Average KL loss: 0.314523
Average total loss: 1.388311
tensor(-15.7292, device='cuda:0') tensor(0.1558, device='cuda:0') tensor(1.5380e-11, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.072031
Average KL loss: 0.314449
Average total loss: 1.386480
tensor(-15.7364, device='cuda:0') tensor(0.1562, device='cuda:0') tensor(-5.5918e-12, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.073264
Average KL loss: 0.314253
Average total loss: 1.387517
tensor(-15.7435, device='cuda:0') tensor(0.1566, device='cuda:0') tensor(-3.8566e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.073498
Average KL loss: 0.313988
Average total loss: 1.387486
tensor(-15.7505, device='cuda:0') tensor(0.1570, device='cuda:0') tensor(2.6059e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.073365
Average KL loss: 0.313914
Average total loss: 1.387280
tensor(-15.7575, device='cuda:0') tensor(0.1575, device='cuda:0') tensor(-1.2835e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.072343
Average KL loss: 0.313785
Average total loss: 1.386128
tensor(-15.7645, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(-7.3356e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.072304
Average KL loss: 0.313690
Average total loss: 1.385993
tensor(-15.7714, device='cuda:0') tensor(0.1583, device='cuda:0') tensor(4.5681e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.072662
Average KL loss: 0.313597
Average total loss: 1.386260
tensor(-15.7782, device='cuda:0') tensor(0.1586, device='cuda:0') tensor(-3.9475e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.071719
Average KL loss: 0.313514
Average total loss: 1.385233
tensor(-15.7850, device='cuda:0') tensor(0.1591, device='cuda:0') tensor(-1.8962e-11, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.070559
Average KL loss: 0.313583
Average total loss: 1.384141
tensor(-15.7918, device='cuda:0') tensor(0.1594, device='cuda:0') tensor(-4.4419e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.072167
Average KL loss: 0.313601
Average total loss: 1.385769
tensor(-15.7985, device='cuda:0') tensor(0.1598, device='cuda:0') tensor(-1.8172e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.071414
Average KL loss: 0.313520
Average total loss: 1.384934
tensor(-15.8052, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(-1.2195e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.070879
Average KL loss: 0.313395
Average total loss: 1.384273
tensor(-15.8118, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(1.7408e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.071194
Average KL loss: 0.313325
Average total loss: 1.384519
tensor(-15.8184, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(-1.3401e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.072534
Average KL loss: 0.313093
Average total loss: 1.385628
tensor(-15.8249, device='cuda:0') tensor(0.1615, device='cuda:0') tensor(-6.2232e-11, device='cuda:0')
Epoch 72
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 73
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 74
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 75
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 76
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 77
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 78
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 79
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 80
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 81
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 82
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 83
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 84
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 85
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 86
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 87
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 88
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 89
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 90
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 91
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 92
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 93
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 94
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 95
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 96
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 97
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 98
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 99
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 100
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 101
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 102
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 103
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 104
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 105
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 106
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 107
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 108
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 109
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 110
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 111
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 112
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 113
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 114
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 115
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 116
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 117
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 118
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 119
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 120
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  266738 / 1179648             ( 22.61%) | total_pruned =  912910 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  435905 / 2359296             ( 18.48%) | total_pruned = 1923391 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   78517 /  131072             ( 59.90%) | total_pruned =   52555 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  343388 / 2359296             ( 14.55%) | total_pruned = 2015908 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     462 /     512             ( 90.23%) | total_pruned =      50 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  262714 / 2359296             ( 11.14%) | total_pruned = 2096582 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
linear.weight        | nonzeros =    5020 /    5120             ( 98.05%) | total_pruned =     100 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 34/100 Loss: 2.302545 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4991 / 2359296             (  0.21%) | total_pruned = 2354305 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   78517 /  131072             ( 59.90%) | total_pruned =   52555 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  343388 / 2359296             ( 14.55%) | total_pruned = 2015908 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     462 /     512             ( 90.23%) | total_pruned =      50 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  262714 / 2359296             ( 11.14%) | total_pruned = 2096582 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
linear.weight        | nonzeros =    5020 /    5120             ( 98.05%) | total_pruned =     100 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 34/100 Loss: 2.302574 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   79604 / 2359296             (  3.37%) | total_pruned = 2279692 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     462 /     512             ( 90.23%) | total_pruned =      50 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  262714 / 2359296             ( 11.14%) | total_pruned = 2096582 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
linear.weight        | nonzeros =    5020 /    5120             ( 98.05%) | total_pruned =     100 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 34/100 Loss: 2.302596 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  168624 / 2359296             (  7.15%) | total_pruned = 2190672 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
linear.weight        | nonzeros =    5020 /    5120             ( 98.05%) | total_pruned =     100 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 34/100 Loss: 2.302652 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   81290 / 2359296             (  3.45%) | total_pruned = 2278006 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
linear.weight        | nonzeros =    5020 /    5120             ( 98.05%) | total_pruned =     100 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 34/100 Loss: 2.302480 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   37623 / 2359296             (  1.59%) | total_pruned = 2321673 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
linear.weight        | nonzeros =    5020 /    5120             ( 98.05%) | total_pruned =     100 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 34/100 Loss: 2.302476 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   15789 / 2359296             (  0.67%) | total_pruned = 2343507 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
linear.weight        | nonzeros =    5020 /    5120             ( 98.05%) | total_pruned =     100 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 34/100 Loss: 2.302579 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    4872 / 2359296             (  0.21%) | total_pruned = 2354424 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
linear.weight        | nonzeros =    5020 /    5120             ( 98.05%) | total_pruned =     100 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 34/100 Loss: 2.302558 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     429 /     512             ( 83.79%) | total_pruned =      83 | shape = torch.Size([512])
linear.weight        | nonzeros =    5020 /    5120             ( 98.05%) | total_pruned =     100 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 34/100 Loss: 2.302586 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
