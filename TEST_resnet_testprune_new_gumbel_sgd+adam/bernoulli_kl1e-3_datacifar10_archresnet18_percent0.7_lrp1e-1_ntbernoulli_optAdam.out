Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1414e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.287595
Average KL loss: 2.354579
Average total loss: 3.642175
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(4.7286e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.860042
Average KL loss: 1.506284
Average total loss: 2.366326
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-4.2080e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.737256
Average KL loss: 1.481204
Average total loss: 2.218459
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.0471e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.669885
Average KL loss: 1.432564
Average total loss: 2.102449
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(9.9544e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.657158
Average KL loss: 1.462230
Average total loss: 2.119388
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-3.7533e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.635901
Average KL loss: 1.443875
Average total loss: 2.079776
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.4137e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.625075
Average KL loss: 1.431127
Average total loss: 2.056202
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.0232e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.620088
Average KL loss: 1.493762
Average total loss: 2.113849
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-7.8015e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.590873
Average KL loss: 1.454911
Average total loss: 2.045784
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.4848e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.590855
Average KL loss: 1.469111
Average total loss: 2.059966
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.8383e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.602011
Average KL loss: 1.459688
Average total loss: 2.061699
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-9.3752e-11, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.587392
Average KL loss: 1.480110
Average total loss: 2.067502
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-1.9317e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.601293
Average KL loss: 1.546752
Average total loss: 2.148045
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(1.5097e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.583971
Average KL loss: 1.476435
Average total loss: 2.060406
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.7518e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.589902
Average KL loss: 1.493985
Average total loss: 2.083887
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(1.6452e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.568900
Average KL loss: 1.468744
Average total loss: 2.037644
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(3.2345e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.565968
Average KL loss: 1.439036
Average total loss: 2.005004
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.0850e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.577830
Average KL loss: 1.523029
Average total loss: 2.100860
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.3936e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.577080
Average KL loss: 1.515445
Average total loss: 2.092525
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(1.6647e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.582210
Average KL loss: 1.586000
Average total loss: 2.168210
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(4.7063e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.578814
Average KL loss: 1.544395
Average total loss: 2.123208
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.5491e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.570826
Average KL loss: 1.519970
Average total loss: 2.090796
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-2.3874e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.575802
Average KL loss: 1.524317
Average total loss: 2.100120
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(1.0432e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.575933
Average KL loss: 1.520660
Average total loss: 2.096593
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.7338e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.570314
Average KL loss: 1.531333
Average total loss: 2.101648
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(1.0048e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.571969
Average KL loss: 1.517481
Average total loss: 2.089450
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-2.5131e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.558129
Average KL loss: 1.529375
Average total loss: 2.087504
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(7.9283e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.572094
Average KL loss: 1.514985
Average total loss: 2.087080
tensor(0.0004, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-1.6580e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.560621
Average KL loss: 0.852974
Average total loss: 1.413595
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.4794e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.550840
Average KL loss: 0.605037
Average total loss: 1.155877
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-5.3210e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.551716
Average KL loss: 0.565107
Average total loss: 1.116823
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(7.3975e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.551852
Average KL loss: 0.554524
Average total loss: 1.106376
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-6.4740e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.537238
Average KL loss: 0.534922
Average total loss: 1.072161
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(6.2584e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.548913
Average KL loss: 0.528566
Average total loss: 1.077479
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.0685e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.563138
Average KL loss: 0.524607
Average total loss: 1.087745
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(7.4170e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.552075
Average KL loss: 0.522866
Average total loss: 1.074942
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-7.2465e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.551858
Average KL loss: 0.516550
Average total loss: 1.068408
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-3.8834e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.554385
Average KL loss: 0.511582
Average total loss: 1.065967
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(3.5903e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.563887
Average KL loss: 0.514455
Average total loss: 1.078342
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.4319e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.553083
Average KL loss: 0.504559
Average total loss: 1.057642
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.8020e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.558697
Average KL loss: 0.505507
Average total loss: 1.064204
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(6.9239e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.549144
Average KL loss: 0.502126
Average total loss: 1.051270
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(9.0343e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.546798
Average KL loss: 0.501960
Average total loss: 1.048759
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.9019e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.571154
Average KL loss: 0.506133
Average total loss: 1.077287
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.5739e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.556599
Average KL loss: 0.505847
Average total loss: 1.062446
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.0071e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.555500
Average KL loss: 0.500645
Average total loss: 1.056145
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.3243e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.567367
Average KL loss: 0.499796
Average total loss: 1.067162
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.8628e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.557992
Average KL loss: 0.500385
Average total loss: 1.058377
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(8.4324e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.556929
Average KL loss: 0.501722
Average total loss: 1.058651
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.6028e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.563377
Average KL loss: 0.502704
Average total loss: 1.066081
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.2382e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.569827
Average KL loss: 0.503806
Average total loss: 1.073633
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-6.7927e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.558150
Average KL loss: 0.501149
Average total loss: 1.059299
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.2669e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.562153
Average KL loss: 0.498248
Average total loss: 1.060401
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.1596e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.568494
Average KL loss: 0.499070
Average total loss: 1.067564
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(6.7834e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.558015
Average KL loss: 0.459375
Average total loss: 1.017389
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(4.8713e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.559488
Average KL loss: 0.420728
Average total loss: 0.980215
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.9138e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.570085
Average KL loss: 0.410489
Average total loss: 0.980574
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(5.6996e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.568295
Average KL loss: 0.405760
Average total loss: 0.974055
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.2072e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.562532
Average KL loss: 0.403121
Average total loss: 0.965653
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(4.5656e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.570799
Average KL loss: 0.401023
Average total loss: 0.971822
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.0080e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.560863
Average KL loss: 0.399373
Average total loss: 0.960236
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-8.6661e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.562892
Average KL loss: 0.397844
Average total loss: 0.960736
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-3.4014e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.563515
Average KL loss: 0.397527
Average total loss: 0.961042
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.2994e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.556369
Average KL loss: 0.395945
Average total loss: 0.952314
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-3.8012e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.563737
Average KL loss: 0.395202
Average total loss: 0.958939
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.8197e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.576674
Average KL loss: 0.394671
Average total loss: 0.971345
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-4.1603e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.551933
Average KL loss: 0.394041
Average total loss: 0.945974
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.4338e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.569330
Average KL loss: 0.393571
Average total loss: 0.962900
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.1406e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.564544
Average KL loss: 0.392707
Average total loss: 0.957251
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.8387e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.562858
Average KL loss: 0.392183
Average total loss: 0.955042
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(5.1411e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.568545
Average KL loss: 0.392198
Average total loss: 0.960743
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(4.1137e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.565368
Average KL loss: 0.391477
Average total loss: 0.956845
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(6.9310e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.564736
Average KL loss: 0.391448
Average total loss: 0.956184
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.0710e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.567743
Average KL loss: 0.391058
Average total loss: 0.958801
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(9.0706e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.559075
Average KL loss: 0.390656
Average total loss: 0.949731
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(3.0993e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.569296
Average KL loss: 0.390380
Average total loss: 0.959676
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.5132e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.556149
Average KL loss: 0.389962
Average total loss: 0.946111
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(4.8199e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.571086
Average KL loss: 0.389281
Average total loss: 0.960368
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.0594e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.565337
Average KL loss: 0.388440
Average total loss: 0.953776
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.0403e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.552055
Average KL loss: 0.386439
Average total loss: 0.938494
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.7504e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.567238
Average KL loss: 0.385144
Average total loss: 0.952382
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(8.2718e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.559121
Average KL loss: 0.384231
Average total loss: 0.943353
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.3198e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.560180
Average KL loss: 0.383543
Average total loss: 0.943723
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-6.5841e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.565918
Average KL loss: 0.382993
Average total loss: 0.948911
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(6.5072e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.563972
Average KL loss: 0.382555
Average total loss: 0.946527
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.9710e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.564962
Average KL loss: 0.382172
Average total loss: 0.947134
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(3.2177e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.573526
Average KL loss: 0.381856
Average total loss: 0.955382
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.5337e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.556730
Average KL loss: 0.381572
Average total loss: 0.938302
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(5.9265e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.560306
Average KL loss: 0.381316
Average total loss: 0.941623
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(5.8766e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.577171
Average KL loss: 0.381157
Average total loss: 0.958328
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-9.0723e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.562224
Average KL loss: 0.380980
Average total loss: 0.943204
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.1558e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.558643
Average KL loss: 0.380772
Average total loss: 0.939415
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(2.6031e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.562616
Average KL loss: 0.380594
Average total loss: 0.943210
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.9359e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.558593
Average KL loss: 0.380447
Average total loss: 0.939041
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(9.4717e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.568301
Average KL loss: 0.380303
Average total loss: 0.948604
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(7.1026e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.551304
Average KL loss: 0.380139
Average total loss: 0.931443
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-4.4539e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.559677
Average KL loss: 0.379996
Average total loss: 0.939673
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.9311e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.563679
Average KL loss: 0.379827
Average total loss: 0.943506
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-6.1402e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.558218
Average KL loss: 0.379710
Average total loss: 0.937927
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.3254e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.573552
Average KL loss: 0.379608
Average total loss: 0.953160
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(3.2537e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.563162
Average KL loss: 0.379516
Average total loss: 0.942678
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(8.6053e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.571272
Average KL loss: 0.379454
Average total loss: 0.950726
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(4.2160e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.561874
Average KL loss: 0.379424
Average total loss: 0.941297
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-7.4908e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.565908
Average KL loss: 0.379366
Average total loss: 0.945274
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.1327e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.566659
Average KL loss: 0.379270
Average total loss: 0.945930
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.3970e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.544674
Average KL loss: 0.379174
Average total loss: 0.923849
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.2302e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.563534
Average KL loss: 0.379081
Average total loss: 0.942615
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.2553e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.566191
Average KL loss: 0.379036
Average total loss: 0.945227
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.9274e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.564116
Average KL loss: 0.378965
Average total loss: 0.943081
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.1878e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.565924
Average KL loss: 0.378908
Average total loss: 0.944831
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(5.1032e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.574347
Average KL loss: 0.378859
Average total loss: 0.953206
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-3.4157e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.567243
Average KL loss: 0.378844
Average total loss: 0.946086
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.3348e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.555378
Average KL loss: 0.378796
Average total loss: 0.934174
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-6.4602e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.562967
Average KL loss: 0.378697
Average total loss: 0.941665
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.6149e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.571723
Average KL loss: 0.378666
Average total loss: 0.950389
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-8.1705e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.568011
Average KL loss: 0.378621
Average total loss: 0.946632
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(4.6944e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.562621
Average KL loss: 0.378543
Average total loss: 0.941164
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.0508e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.570832
Average KL loss: 0.378490
Average total loss: 0.949322
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(8.6436e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.560764
Average KL loss: 0.378444
Average total loss: 0.939208
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-2.0548e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.543885
Average KL loss: 0.378399
Average total loss: 0.922284
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-4.5821e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.558523
Average KL loss: 0.378357
Average total loss: 0.936880
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.1586e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.565669
Average KL loss: 0.378322
Average total loss: 0.943991
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.5883e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.559709
Average KL loss: 0.378289
Average total loss: 0.937998
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.0282e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.560910
Average KL loss: 0.378262
Average total loss: 0.939171
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-6.9934e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.548833
Average KL loss: 0.378230
Average total loss: 0.927063
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.4253e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.563285
Average KL loss: 0.378199
Average total loss: 0.941483
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.0048e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.567618
Average KL loss: 0.378174
Average total loss: 0.945792
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.5207e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.560789
Average KL loss: 0.378151
Average total loss: 0.938940
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(6.3740e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.569948
Average KL loss: 0.378130
Average total loss: 0.948079
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.6157e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.561548
Average KL loss: 0.378109
Average total loss: 0.939657
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(1.2736e-08, device='cuda:0')
 Percentile value: 0.0012643474154174327
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1232 /    1728             ( 71.30%) | total_pruned =     496 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   18481 /   36864             ( 50.13%) | total_pruned =   18383 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   19102 /   36864             ( 51.82%) | total_pruned =   17762 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   18538 /   36864             ( 50.29%) | total_pruned =   18326 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18174 /   36864             ( 49.30%) | total_pruned =   18690 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   36703 /   73728             ( 49.78%) | total_pruned =   37025 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   72138 /  147456             ( 48.92%) | total_pruned =   75318 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4929 /    8192             ( 60.17%) | total_pruned =    3263 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   67561 /  147456             ( 45.82%) | total_pruned =   79895 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   68045 /  147456             ( 46.15%) | total_pruned =   79411 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  140772 /  294912             ( 47.73%) | total_pruned =  154140 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     150 /     256             ( 58.59%) | total_pruned =     106 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  272128 /  589824             ( 46.14%) | total_pruned =  317696 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18194 /   32768             ( 55.52%) | total_pruned =   14574 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     138 /     256             ( 53.91%) | total_pruned =     118 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  224219 /  589824             ( 38.01%) | total_pruned =  365605 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     187 /     256             ( 73.05%) | total_pruned =      69 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  223699 /  589824             ( 37.93%) | total_pruned =  366125 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  498928 / 1179648             ( 42.29%) | total_pruned =  680720 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     311 /     512             ( 60.74%) | total_pruned =     201 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  765344 / 2359296             ( 32.44%) | total_pruned = 1593952 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     454 /     512             ( 88.67%) | total_pruned =      58 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     372 /     512             ( 72.66%) | total_pruned =     140 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   63413 /  131072             ( 48.38%) | total_pruned =   67659 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     445 /     512             ( 86.91%) | total_pruned =      67 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     361 /     512             ( 70.51%) | total_pruned =     151 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  503117 / 2359296             ( 21.32%) | total_pruned = 1856179 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     398 /     512             ( 77.73%) | total_pruned =     114 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     354 /     512             ( 69.14%) | total_pruned =     158 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  307873 / 2359296             ( 13.05%) | total_pruned = 2051423 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     244 /     512             ( 47.66%) | total_pruned =     268 | shape = torch.Size([512])
linear.weight        | nonzeros =    3737 /    5120             ( 72.99%) | total_pruned =    1383 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 76/200 Loss: 0.000064 Accuracy: 86.73 100.00 % Best test Accuracy: 86.85%
tensor(0.0004, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.0485e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.005660
Average KL loss: 2.547343
Average total loss: 3.553003
tensor(0.0002, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-9.7959e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.844520
Average KL loss: 1.731107
Average total loss: 2.575626
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(1.4733e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.813370
Average KL loss: 1.764874
Average total loss: 2.578244
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.8866e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.792525
Average KL loss: 1.824190
Average total loss: 2.616715
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.1515e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.782567
Average KL loss: 1.824729
Average total loss: 2.607296
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.5793e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.754225
Average KL loss: 1.820237
Average total loss: 2.574462
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.0270e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.783673
Average KL loss: 1.854177
Average total loss: 2.637850
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.4857e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.755119
Average KL loss: 1.826148
Average total loss: 2.581267
tensor(0.0006, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.3399e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.773849
Average KL loss: 1.870172
Average total loss: 2.644021
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(7.5776e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.748321
Average KL loss: 1.855104
Average total loss: 2.603426
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(5.3266e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.730634
Average KL loss: 1.786040
Average total loss: 2.516674
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(9.1664e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.735623
Average KL loss: 1.846527
Average total loss: 2.582150
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.5159e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.751207
Average KL loss: 1.883154
Average total loss: 2.634361
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.9573e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.727497
Average KL loss: 1.824853
Average total loss: 2.552349
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(6.8860e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.740389
Average KL loss: 1.811979
Average total loss: 2.552368
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(2.2939e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.751432
Average KL loss: 1.894531
Average total loss: 2.645963
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-9.0062e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.735537
Average KL loss: 1.826436
Average total loss: 2.561973
tensor(0.0006, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.1607e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.736512
Average KL loss: 1.852794
Average total loss: 2.589306
tensor(0.0006, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.7227e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.743756
Average KL loss: 1.885095
Average total loss: 2.628851
tensor(0.0006, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.0529e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.736579
Average KL loss: 1.859522
Average total loss: 2.596101
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.2619e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.729687
Average KL loss: 1.873875
Average total loss: 2.603562
tensor(0.0006, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.2432e-11, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.740546
Average KL loss: 1.905283
Average total loss: 2.645829
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(4.6707e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.721398
Average KL loss: 1.124775
Average total loss: 1.846173
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.8198e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.697307
Average KL loss: 0.781257
Average total loss: 1.478564
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(6.6997e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.692306
Average KL loss: 0.733080
Average total loss: 1.425386
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(5.2532e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.712202
Average KL loss: 0.710479
Average total loss: 1.422681
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.5234e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.699310
Average KL loss: 0.689974
Average total loss: 1.389284
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-7.1485e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.712461
Average KL loss: 0.677288
Average total loss: 1.389749
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.0702e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.706798
Average KL loss: 0.666647
Average total loss: 1.373445
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.9524e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.704952
Average KL loss: 0.659152
Average total loss: 1.364104
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(9.4855e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.706314
Average KL loss: 0.650428
Average total loss: 1.356742
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-4.0183e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.703613
Average KL loss: 0.641698
Average total loss: 1.345311
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.7958e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.700106
Average KL loss: 0.632036
Average total loss: 1.332143
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.3597e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.723391
Average KL loss: 0.631124
Average total loss: 1.354515
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.4058e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.709374
Average KL loss: 0.627664
Average total loss: 1.337037
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.1320e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.729353
Average KL loss: 0.628612
Average total loss: 1.357965
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-4.0211e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.731976
Average KL loss: 0.628343
Average total loss: 1.360319
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.1667e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.736854
Average KL loss: 0.627890
Average total loss: 1.364744
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-6.0005e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.704844
Average KL loss: 0.618928
Average total loss: 1.323772
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(7.8897e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.736549
Average KL loss: 0.618594
Average total loss: 1.355143
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.5902e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.713887
Average KL loss: 0.612252
Average total loss: 1.326140
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.8356e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.733919
Average KL loss: 0.614776
Average total loss: 1.348695
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.1821e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.715217
Average KL loss: 0.607566
Average total loss: 1.322783
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-9.7480e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.721924
Average KL loss: 0.607209
Average total loss: 1.329133
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.5388e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.739526
Average KL loss: 0.607174
Average total loss: 1.346701
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-6.4684e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.717599
Average KL loss: 0.606793
Average total loss: 1.324392
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.4367e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.738378
Average KL loss: 0.604235
Average total loss: 1.342613
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.8931e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.714275
Average KL loss: 0.607171
Average total loss: 1.321445
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.8369e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.714525
Average KL loss: 0.601587
Average total loss: 1.316112
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(6.4116e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.714949
Average KL loss: 0.600284
Average total loss: 1.315233
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.0301e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.730532
Average KL loss: 0.598705
Average total loss: 1.329237
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.5963e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.716181
Average KL loss: 0.599159
Average total loss: 1.315340
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(6.5171e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.731550
Average KL loss: 0.601861
Average total loss: 1.333410
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.6739e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.727540
Average KL loss: 0.599838
Average total loss: 1.327377
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(9.2654e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.745670
Average KL loss: 0.597901
Average total loss: 1.343571
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.2712e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.714606
Average KL loss: 0.594616
Average total loss: 1.309222
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.1360e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.719961
Average KL loss: 0.587637
Average total loss: 1.307599
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(9.7141e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.718140
Average KL loss: 0.587521
Average total loss: 1.305661
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-5.0410e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.722503
Average KL loss: 0.594291
Average total loss: 1.316794
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.4984e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.723762
Average KL loss: 0.595451
Average total loss: 1.319213
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.9550e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.744960
Average KL loss: 0.597430
Average total loss: 1.342390
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(5.8888e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.734155
Average KL loss: 0.599924
Average total loss: 1.334079
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.0352e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.730939
Average KL loss: 0.595674
Average total loss: 1.326613
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-6.6924e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.733391
Average KL loss: 0.590924
Average total loss: 1.324315
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.2000e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.748933
Average KL loss: 0.596536
Average total loss: 1.345469
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.5123e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.728916
Average KL loss: 0.590940
Average total loss: 1.319856
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.0020e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.722319
Average KL loss: 0.593657
Average total loss: 1.315976
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.1549e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.737697
Average KL loss: 0.590556
Average total loss: 1.328254
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.2091e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.732441
Average KL loss: 0.589114
Average total loss: 1.321555
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.7779e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.737751
Average KL loss: 0.561180
Average total loss: 1.298931
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.8862e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.729807
Average KL loss: 0.518089
Average total loss: 1.247896
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.0074e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.725823
Average KL loss: 0.500132
Average total loss: 1.225955
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.9117e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.727735
Average KL loss: 0.490676
Average total loss: 1.218411
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.1235e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.719155
Average KL loss: 0.484747
Average total loss: 1.203902
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-9.2603e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.724215
Average KL loss: 0.480750
Average total loss: 1.204965
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.4842e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.725834
Average KL loss: 0.477909
Average total loss: 1.203743
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.0178e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.725741
Average KL loss: 0.475691
Average total loss: 1.201431
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(5.7642e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.721997
Average KL loss: 0.474140
Average total loss: 1.196137
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.8337e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.740672
Average KL loss: 0.472715
Average total loss: 1.213387
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(6.4437e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.723357
Average KL loss: 0.471738
Average total loss: 1.195095
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.1134e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.743712
Average KL loss: 0.470722
Average total loss: 1.214434
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(6.4424e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.735055
Average KL loss: 0.470329
Average total loss: 1.205383
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.5650e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.746507
Average KL loss: 0.469629
Average total loss: 1.216137
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-8.6876e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.743562
Average KL loss: 0.469322
Average total loss: 1.212884
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.6178e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.729235
Average KL loss: 0.468906
Average total loss: 1.198141
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.7598e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.734077
Average KL loss: 0.467864
Average total loss: 1.201941
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-5.7110e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.746636
Average KL loss: 0.467593
Average total loss: 1.214229
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.2115e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.733146
Average KL loss: 0.467410
Average total loss: 1.200557
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.5923e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.738686
Average KL loss: 0.466700
Average total loss: 1.205386
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.2835e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.735529
Average KL loss: 0.466117
Average total loss: 1.201646
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.5513e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.727714
Average KL loss: 0.465952
Average total loss: 1.193667
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.3469e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.730891
Average KL loss: 0.465156
Average total loss: 1.196047
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.1442e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.710515
Average KL loss: 0.464650
Average total loss: 1.175166
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(8.2863e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.731987
Average KL loss: 0.463749
Average total loss: 1.195736
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.3256e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.733321
Average KL loss: 0.464367
Average total loss: 1.197687
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.9232e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.747043
Average KL loss: 0.464165
Average total loss: 1.211208
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.5661e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.739868
Average KL loss: 0.463753
Average total loss: 1.203621
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-3.5884e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.745853
Average KL loss: 0.463542
Average total loss: 1.209395
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.1351e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.742219
Average KL loss: 0.463372
Average total loss: 1.205591
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(8.0033e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.733843
Average KL loss: 0.462929
Average total loss: 1.196772
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.3400e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.722534
Average KL loss: 0.462623
Average total loss: 1.185157
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-3.5473e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.741947
Average KL loss: 0.462213
Average total loss: 1.204161
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(9.6290e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.718112
Average KL loss: 0.461719
Average total loss: 1.179831
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.9595e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.731528
Average KL loss: 0.460919
Average total loss: 1.192447
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.4298e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.724679
Average KL loss: 0.460284
Average total loss: 1.184962
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(2.9609e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.744421
Average KL loss: 0.459200
Average total loss: 1.203621
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.6478e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.747441
Average KL loss: 0.458310
Average total loss: 1.205751
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(3.5668e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.740273
Average KL loss: 0.457553
Average total loss: 1.197826
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(4.4424e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.725853
Average KL loss: 0.456881
Average total loss: 1.182734
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(7.0140e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.715437
Average KL loss: 0.456279
Average total loss: 1.171716
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(4.7246e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.722030
Average KL loss: 0.455724
Average total loss: 1.177753
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.4761e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.723193
Average KL loss: 0.455251
Average total loss: 1.178444
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(3.1073e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.732294
Average KL loss: 0.454802
Average total loss: 1.187097
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.4925e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.724836
Average KL loss: 0.454406
Average total loss: 1.179242
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(7.7476e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.745346
Average KL loss: 0.454059
Average total loss: 1.199405
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.0033e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.735690
Average KL loss: 0.453777
Average total loss: 1.189467
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.3437e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.734609
Average KL loss: 0.453483
Average total loss: 1.188091
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-3.8116e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.732064
Average KL loss: 0.453223
Average total loss: 1.185287
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.5115e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.721111
Average KL loss: 0.452934
Average total loss: 1.174045
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.8046e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.734898
Average KL loss: 0.452698
Average total loss: 1.187596
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(3.6453e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.730152
Average KL loss: 0.452506
Average total loss: 1.182657
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.0104e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.749201
Average KL loss: 0.452361
Average total loss: 1.201562
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(4.8674e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.711222
Average KL loss: 0.452330
Average total loss: 1.163552
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-3.8932e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.728077
Average KL loss: 0.452294
Average total loss: 1.180371
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-3.3307e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.738590
Average KL loss: 0.452262
Average total loss: 1.190852
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(4.3418e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.734779
Average KL loss: 0.452228
Average total loss: 1.187007
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.6220e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.728968
Average KL loss: 0.452195
Average total loss: 1.181164
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-1.0510e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.733173
Average KL loss: 0.452166
Average total loss: 1.185339
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(3.3727e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.727139
Average KL loss: 0.452135
Average total loss: 1.179274
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-4.7317e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.724366
Average KL loss: 0.452104
Average total loss: 1.176470
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.7472e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.732500
Average KL loss: 0.452074
Average total loss: 1.184574
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-4.7384e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.716429
Average KL loss: 0.452046
Average total loss: 1.168476
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(1.9355e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.721178
Average KL loss: 0.452016
Average total loss: 1.173193
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(3.9017e-09, device='cuda:0')
 Percentile value: 0.006201805919408798
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =     907 /    1728             ( 52.49%) | total_pruned =     821 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    8357 /   36864             ( 22.67%) | total_pruned =   28507 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    9460 /   36864             ( 25.66%) | total_pruned =   27404 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    8738 /   36864             ( 23.70%) | total_pruned =   28126 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    8403 /   36864             ( 22.79%) | total_pruned =   28461 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   17169 /   73728             ( 23.29%) | total_pruned =   56559 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   32588 /  147456             ( 22.10%) | total_pruned =  114868 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2863 /    8192             ( 34.95%) | total_pruned =    5329 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   25101 /  147456             ( 17.02%) | total_pruned =  122355 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   25332 /  147456             ( 17.18%) | total_pruned =  122124 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   60866 /  294912             ( 20.64%) | total_pruned =  234046 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      99 /     256             ( 38.67%) | total_pruned =     157 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  111848 /  589824             ( 18.96%) | total_pruned =  477976 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      84 /     256             ( 32.81%) | total_pruned =     172 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    9313 /   32768             ( 28.42%) | total_pruned =   23455 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      85 /     256             ( 33.20%) | total_pruned =     171 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   57738 /  589824             (  9.79%) | total_pruned =  532086 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      69 /     256             ( 26.95%) | total_pruned =     187 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   56255 /  589824             (  9.54%) | total_pruned =  533569 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  176172 / 1179648             ( 14.93%) | total_pruned = 1003476 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     472 /     512             ( 92.19%) | total_pruned =      40 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     164 /     512             ( 32.03%) | total_pruned =     348 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  201602 / 2359296             (  8.55%) | total_pruned = 2157694 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     405 /     512             ( 79.10%) | total_pruned =     107 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     293 /     512             ( 57.23%) | total_pruned =     219 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   24699 /  131072             ( 18.84%) | total_pruned =  106373 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     355 /     512             ( 69.34%) | total_pruned =     157 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     276 /     512             ( 53.91%) | total_pruned =     236 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  103513 / 2359296             (  4.39%) | total_pruned = 2255783 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     370 /     512             ( 72.27%) | total_pruned =     142 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     177 /     512             ( 34.57%) | total_pruned =     335 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   56999 / 2359296             (  2.42%) | total_pruned = 2302297 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     412 /     512             ( 80.47%) | total_pruned =     100 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     182 /     512             ( 35.55%) | total_pruned =     330 | shape = torch.Size([512])
linear.weight        | nonzeros =    2326 /    5120             ( 45.43%) | total_pruned =    2794 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 38/200 Loss: 0.000083 Accuracy: 86.65 100.00 % Best test Accuracy: 86.77%
tensor(0.0005, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-5.3793e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.393336
Average KL loss: 2.132199
Average total loss: 3.525536
tensor(0.0026, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(4.8588e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.291876
Average KL loss: 1.642650
Average total loss: 2.934526
tensor(0.0008, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(7.1244e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.219779
Average KL loss: 1.742190
Average total loss: 2.961969
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.1587e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.158482
Average KL loss: 1.651377
Average total loss: 2.809859
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.7752e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.114790
Average KL loss: 1.682179
Average total loss: 2.796969
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(7.3603e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.160181
Average KL loss: 1.715989
Average total loss: 2.876170
tensor(0.0006, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.0857e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.120894
Average KL loss: 1.712937
Average total loss: 2.833831
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.7972e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.189776
Average KL loss: 1.770048
Average total loss: 2.959824
tensor(0.0006, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(2.4496e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.136048
Average KL loss: 1.820636
Average total loss: 2.956684
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.1198e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.088836
Average KL loss: 1.752748
Average total loss: 2.841584
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.7195e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.108856
Average KL loss: 1.744797
Average total loss: 2.853654
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.3792e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.100333
Average KL loss: 1.756026
Average total loss: 2.856360
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.5269e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.105034
Average KL loss: 1.779605
Average total loss: 2.884639
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.2793e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.087280
Average KL loss: 1.805040
Average total loss: 2.892320
tensor(0.0006, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.5819e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.065311
Average KL loss: 1.752203
Average total loss: 2.817514
tensor(0.0006, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.5720e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.083038
Average KL loss: 1.816765
Average total loss: 2.899803
tensor(0.0006, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.2738e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.048961
Average KL loss: 1.326973
Average total loss: 2.375934
tensor(0.0006, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(4.2128e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.057655
Average KL loss: 0.938277
Average total loss: 1.995933
tensor(0.0006, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(7.2674e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.033610
Average KL loss: 0.863943
Average total loss: 1.897553
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.3622e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.019402
Average KL loss: 0.832072
Average total loss: 1.851474
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(2.1245e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.043980
Average KL loss: 0.807127
Average total loss: 1.851107
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.0735e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.030784
Average KL loss: 0.792242
Average total loss: 1.823026
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.1710e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.012479
Average KL loss: 0.778087
Average total loss: 1.790566
tensor(0.0006, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(1.8785e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.047019
Average KL loss: 0.763239
Average total loss: 1.810258
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.7004e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.035550
Average KL loss: 0.755591
Average total loss: 1.791141
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-8.3227e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.066520
Average KL loss: 0.751519
Average total loss: 1.818039
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-5.5239e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.063719
Average KL loss: 0.748901
Average total loss: 1.812619
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.0831e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.044378
Average KL loss: 0.736184
Average total loss: 1.780562
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(2.5675e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.064037
Average KL loss: 0.731849
Average total loss: 1.795885
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.0004e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.034121
Average KL loss: 0.725590
Average total loss: 1.759711
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(2.4166e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.043232
Average KL loss: 0.717280
Average total loss: 1.760512
tensor(0.0006, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(1.5367e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.037874
Average KL loss: 0.717036
Average total loss: 1.754910
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(2.8163e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.045883
Average KL loss: 0.709471
Average total loss: 1.755354
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.7797e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.030944
Average KL loss: 0.700870
Average total loss: 1.731813
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(2.0077e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.040215
Average KL loss: 0.695320
Average total loss: 1.735535
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(9.4781e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.046168
Average KL loss: 0.694337
Average total loss: 1.740505
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(3.3908e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.055842
Average KL loss: 0.696052
Average total loss: 1.751893
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.8484e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.075562
Average KL loss: 0.693361
Average total loss: 1.768924
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.1112e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.044142
Average KL loss: 0.690816
Average total loss: 1.734958
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(9.6054e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.050709
Average KL loss: 0.686652
Average total loss: 1.737362
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.9285e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.045235
Average KL loss: 0.685970
Average total loss: 1.731205
tensor(0.0005, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-3.0861e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.044481
Average KL loss: 0.683453
Average total loss: 1.727934
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-3.7450e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.064153
Average KL loss: 0.677480
Average total loss: 1.741634
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.9935e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.048053
Average KL loss: 0.678419
Average total loss: 1.726472
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.4101e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.065491
Average KL loss: 0.675942
Average total loss: 1.741433
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.8834e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.042483
Average KL loss: 0.672327
Average total loss: 1.714811
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.4928e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.043639
Average KL loss: 0.667903
Average total loss: 1.711542
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.9497e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.063446
Average KL loss: 0.663055
Average total loss: 1.726501
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.8010e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.048503
Average KL loss: 0.665443
Average total loss: 1.713946
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.0149e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.035643
Average KL loss: 0.660206
Average total loss: 1.695848
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(6.0231e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.060424
Average KL loss: 0.661400
Average total loss: 1.721824
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.5737e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.060000
Average KL loss: 0.661859
Average total loss: 1.721859
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(5.1602e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.072251
Average KL loss: 0.660033
Average total loss: 1.732284
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.0817e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.071877
Average KL loss: 0.668107
Average total loss: 1.739985
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.1069e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.043324
Average KL loss: 0.661424
Average total loss: 1.704748
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.3569e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.056137
Average KL loss: 0.656046
Average total loss: 1.712183
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.8144e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.057413
Average KL loss: 0.660733
Average total loss: 1.718146
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.6472e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.074653
Average KL loss: 0.658327
Average total loss: 1.732980
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.4850e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.070124
Average KL loss: 0.655923
Average total loss: 1.726047
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(4.1215e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.059587
Average KL loss: 0.655941
Average total loss: 1.715528
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.3778e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.070146
Average KL loss: 0.655346
Average total loss: 1.725492
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.8015e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.075983
Average KL loss: 0.643973
Average total loss: 1.719957
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.3142e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.075443
Average KL loss: 0.618334
Average total loss: 1.693778
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(2.8008e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.054627
Average KL loss: 0.602575
Average total loss: 1.657202
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.5587e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.057512
Average KL loss: 0.592340
Average total loss: 1.649852
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(3.2703e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.049598
Average KL loss: 0.584883
Average total loss: 1.634481
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.1510e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.053134
Average KL loss: 0.579499
Average total loss: 1.632633
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(1.7210e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.046622
Average KL loss: 0.574985
Average total loss: 1.621608
tensor(0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-2.1219e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.092458
Average KL loss: 0.571445
Average total loss: 1.663903
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.0865e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.059892
Average KL loss: 0.569121
Average total loss: 1.629012
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(4.6509e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.098733
Average KL loss: 0.566759
Average total loss: 1.665492
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.0920e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.054694
Average KL loss: 0.565194
Average total loss: 1.619888
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-5.9564e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.067741
Average KL loss: 0.563452
Average total loss: 1.631193
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.1845e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.069824
Average KL loss: 0.561861
Average total loss: 1.631684
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.8981e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.068087
Average KL loss: 0.560550
Average total loss: 1.628636
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-6.3954e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.067313
Average KL loss: 0.559794
Average total loss: 1.627108
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.0624e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.059838
Average KL loss: 0.558759
Average total loss: 1.618597
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.4160e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.058279
Average KL loss: 0.557601
Average total loss: 1.615880
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.6749e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.071603
Average KL loss: 0.556668
Average total loss: 1.628271
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(3.5249e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.059714
Average KL loss: 0.556159
Average total loss: 1.615874
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.7867e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.055639
Average KL loss: 0.555297
Average total loss: 1.610936
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(4.3947e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.031998
Average KL loss: 0.554564
Average total loss: 1.586562
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.8458e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.055615
Average KL loss: 0.553467
Average total loss: 1.609082
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-4.8512e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.047778
Average KL loss: 0.553325
Average total loss: 1.601103
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-5.7258e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.063194
Average KL loss: 0.553015
Average total loss: 1.616209
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.1024e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.060688
Average KL loss: 0.552259
Average total loss: 1.612947
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.8086e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.067941
Average KL loss: 0.551472
Average total loss: 1.619414
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.7624e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.081404
Average KL loss: 0.551091
Average total loss: 1.632495
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.0868e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.047475
Average KL loss: 0.550478
Average total loss: 1.597952
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.3171e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.043012
Average KL loss: 0.549965
Average total loss: 1.592977
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.9017e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.060613
Average KL loss: 0.549522
Average total loss: 1.610135
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.8511e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.054051
Average KL loss: 0.549237
Average total loss: 1.603289
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.4732e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.069134
Average KL loss: 0.549069
Average total loss: 1.618203
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.6336e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.049900
Average KL loss: 0.548985
Average total loss: 1.598886
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-4.8968e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.049924
Average KL loss: 0.548512
Average total loss: 1.598435
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.8838e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.050395
Average KL loss: 0.548093
Average total loss: 1.598488
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.1404e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.094196
Average KL loss: 0.547698
Average total loss: 1.641894
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(7.9699e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.060084
Average KL loss: 0.547350
Average total loss: 1.607434
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.9795e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.053597
Average KL loss: 0.547005
Average total loss: 1.600602
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(4.1440e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.073793
Average KL loss: 0.546680
Average total loss: 1.620473
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.9896e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.061006
Average KL loss: 0.546380
Average total loss: 1.607386
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(9.3978e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.062157
Average KL loss: 0.546095
Average total loss: 1.608252
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.1310e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.058531
Average KL loss: 0.545846
Average total loss: 1.604378
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.6297e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.057692
Average KL loss: 0.545572
Average total loss: 1.603264
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.2308e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.079839
Average KL loss: 0.545414
Average total loss: 1.625253
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.1250e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.078212
Average KL loss: 0.545390
Average total loss: 1.623602
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.4469e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.052385
Average KL loss: 0.545361
Average total loss: 1.597746
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.3541e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.043906
Average KL loss: 0.545329
Average total loss: 1.589235
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.3407e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.054686
Average KL loss: 0.545297
Average total loss: 1.599983
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(9.9960e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.046069
Average KL loss: 0.545267
Average total loss: 1.591337
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(4.5609e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.056059
Average KL loss: 0.545240
Average total loss: 1.601299
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(8.8690e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.065429
Average KL loss: 0.545216
Average total loss: 1.610645
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.6663e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.037757
Average KL loss: 0.545187
Average total loss: 1.582945
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.2340e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.070296
Average KL loss: 0.545156
Average total loss: 1.615452
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(2.5970e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.044485
Average KL loss: 0.545129
Average total loss: 1.589614
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-4.0621e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.054602
Average KL loss: 0.545102
Average total loss: 1.599704
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.4868e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.060697
Average KL loss: 0.545072
Average total loss: 1.605770
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-3.9326e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.051200
Average KL loss: 0.545043
Average total loss: 1.596243
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(4.1382e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.053793
Average KL loss: 0.545012
Average total loss: 1.598805
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.8958e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.045186
Average KL loss: 0.544981
Average total loss: 1.590167
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.0287e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.058277
Average KL loss: 0.544954
Average total loss: 1.603230
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.7382e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.044845
Average KL loss: 0.544925
Average total loss: 1.589770
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-2.4563e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.066426
Average KL loss: 0.544895
Average total loss: 1.611322
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(1.3636e-08, device='cuda:0')
 Percentile value: 0.020480738580226896
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =     684 /    1728             ( 39.58%) | total_pruned =    1044 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
bn1.bias             | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    3582 /   36864             (  9.72%) | total_pruned =   33282 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4495 /   36864             ( 12.19%) | total_pruned =   32369 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4037 /   36864             ( 10.95%) | total_pruned =   32827 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3705 /   36864             ( 10.05%) | total_pruned =   33159 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    7923 /   73728             ( 10.75%) | total_pruned =   65805 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   13702 /  147456             (  9.29%) | total_pruned =  133754 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1598 /    8192             ( 19.51%) | total_pruned =    6594 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    7752 /  147456             (  5.26%) | total_pruned =  139704 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    7579 /  147456             (  5.14%) | total_pruned =  139877 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   24009 /  294912             (  8.14%) | total_pruned =  270903 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   39423 /  589824             (  6.68%) | total_pruned =  550401 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4012 /   32768             ( 12.24%) | total_pruned =   28756 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   14077 /  589824             (  2.39%) | total_pruned =  575747 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     130 /     256             ( 50.78%) | total_pruned =     126 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   13800 /  589824             (  2.34%) | total_pruned =  576024 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     157 /     256             ( 61.33%) | total_pruned =      99 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   52101 / 1179648             (  4.42%) | total_pruned = 1127547 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     433 /     512             ( 84.57%) | total_pruned =      79 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   48012 / 2359296             (  2.04%) | total_pruned = 2311284 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     349 /     512             ( 68.16%) | total_pruned =     163 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     188 /     512             ( 36.72%) | total_pruned =     324 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    7925 /  131072             (  6.05%) | total_pruned =  123147 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     254 /     512             ( 49.61%) | total_pruned =     258 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   24866 / 2359296             (  1.05%) | total_pruned = 2334430 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     334 /     512             ( 65.23%) | total_pruned =     178 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      97 /     512             ( 18.95%) | total_pruned =     415 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   12701 / 2359296             (  0.54%) | total_pruned = 2346595 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     297 /     512             ( 58.01%) | total_pruned =     215 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      91 /     512             ( 17.77%) | total_pruned =     421 | shape = torch.Size([512])
linear.weight        | nonzeros =    1378 /    5120             ( 26.91%) | total_pruned =    3742 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 37/200 Loss: 0.000471 Accuracy: 85.56 100.00 % Best test Accuracy: 85.63%
tensor(0.0005, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-6.4673e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.080161
Average KL loss: 2.006873
Average total loss: 4.087034
tensor(0.0039, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(8.6107e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.908276
Average KL loss: 1.750398
Average total loss: 3.658673
tensor(0.0009, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(7.3932e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.740582
Average KL loss: 1.733609
Average total loss: 3.474191
tensor(0.0006, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(5.3319e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.696035
Average KL loss: 1.709180
Average total loss: 3.405215
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.0691e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.632562
Average KL loss: 1.676470
Average total loss: 3.309032
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.3011e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.642335
Average KL loss: 1.681355
Average total loss: 3.323690
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.2131e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.584742
Average KL loss: 1.668533
Average total loss: 3.253275
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.8609e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.642950
Average KL loss: 1.702258
Average total loss: 3.345208
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.6946e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.555177
Average KL loss: 1.723812
Average total loss: 3.278989
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(3.0089e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.544079
Average KL loss: 1.693945
Average total loss: 3.238024
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(5.8999e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.544089
Average KL loss: 1.681149
Average total loss: 3.225238
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.6418e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.551417
Average KL loss: 1.656242
Average total loss: 3.207659
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(2.4481e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.546182
Average KL loss: 1.657100
Average total loss: 3.203281
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.9134e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.526416
Average KL loss: 1.645664
Average total loss: 3.172081
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-2.0460e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.537707
Average KL loss: 1.671619
Average total loss: 3.209326
tensor(0.0005, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.0579e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.537519
Average KL loss: 1.664807
Average total loss: 3.202326
tensor(0.0005, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2048e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.539638
Average KL loss: 1.716705
Average total loss: 3.256343
tensor(0.0005, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(3.9200e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.504963
Average KL loss: 1.697242
Average total loss: 3.202205
tensor(0.0005, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-6.0978e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.500439
Average KL loss: 1.629340
Average total loss: 3.129779
tensor(0.0005, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.5935e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.510820
Average KL loss: 1.656446
Average total loss: 3.167266
tensor(0.0005, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.7419e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.479390
Average KL loss: 1.657303
Average total loss: 3.136693
tensor(0.0005, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.7223e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.487878
Average KL loss: 1.655428
Average total loss: 3.143306
tensor(0.0005, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.2982e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.491812
Average KL loss: 1.684242
Average total loss: 3.176054
tensor(0.0005, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-8.7710e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.472481
Average KL loss: 1.620634
Average total loss: 3.093115
tensor(0.0005, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.9526e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.498333
Average KL loss: 1.772814
Average total loss: 3.271147
tensor(-0.0074, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.9883e-06, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.499891
Average KL loss: 1.730365
Average total loss: 3.230256
tensor(0.0012, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(1.7767e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.484986
Average KL loss: 1.732828
Average total loss: 3.217815
tensor(0.0005, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.7093e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.467540
Average KL loss: 1.705183
Average total loss: 3.172723
tensor(0.0005, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-5.7752e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.467897
Average KL loss: 1.709811
Average total loss: 3.177707
tensor(0.0005, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.4623e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.445742
Average KL loss: 1.728376
Average total loss: 3.174119
tensor(0.0005, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.2599e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.473838
Average KL loss: 1.707058
Average total loss: 3.180896
tensor(0.0004, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.9858e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.453742
Average KL loss: 1.722548
Average total loss: 3.176290
tensor(0.0005, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(2.8921e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.424153
Average KL loss: 1.662812
Average total loss: 3.086965
tensor(0.0005, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.3800e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.446780
Average KL loss: 1.668918
Average total loss: 3.115698
tensor(-0.0060, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.6320e-06, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.446851
Average KL loss: 1.753598
Average total loss: 3.200449
tensor(0.0017, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(2.5308e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.448851
Average KL loss: 1.683649
Average total loss: 3.132500
tensor(0.0005, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.4064e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.461859
Average KL loss: 1.713643
Average total loss: 3.175502
tensor(0.0005, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(2.0054e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.451158
Average KL loss: 1.731517
Average total loss: 3.182675
tensor(0.0005, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(2.0566e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.472245
Average KL loss: 1.728859
Average total loss: 3.201105
tensor(0.0005, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.6938e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.439991
Average KL loss: 1.759732
Average total loss: 3.199723
tensor(0.0005, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.4224e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.427309
Average KL loss: 1.701176
Average total loss: 3.128485
tensor(0.0007, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(4.2593e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.446672
Average KL loss: 1.805704
Average total loss: 3.252375
tensor(-0.0022, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-6.7811e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.445782
Average KL loss: 1.741422
Average total loss: 3.187204
tensor(0.0005, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.9531e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.458943
Average KL loss: 1.742836
Average total loss: 3.201780
tensor(0.0005, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(8.7134e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.429732
Average KL loss: 1.542223
Average total loss: 2.971955
tensor(0.0005, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-3.2341e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.419249
Average KL loss: 1.220028
Average total loss: 2.639278
tensor(0.0005, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.5455e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.409498
Average KL loss: 1.104164
Average total loss: 2.513662
tensor(0.0005, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(1.4512e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.414773
Average KL loss: 1.047371
Average total loss: 2.462144
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(5.2221e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.396639
Average KL loss: 1.013873
Average total loss: 2.410512
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(5.1972e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.403676
Average KL loss: 0.989369
Average total loss: 2.393045
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(1.4936e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.389403
Average KL loss: 0.969732
Average total loss: 2.359136
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.6811e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.406832
Average KL loss: 0.955421
Average total loss: 2.362254
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.7284e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.417104
Average KL loss: 0.942260
Average total loss: 2.359364
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.5153e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.401985
Average KL loss: 0.935235
Average total loss: 2.337219
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.7411e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.394585
Average KL loss: 0.925346
Average total loss: 2.319931
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.8111e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.429156
Average KL loss: 0.922898
Average total loss: 2.352054
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(2.9371e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.395905
Average KL loss: 0.913005
Average total loss: 2.308910
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.9894e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.415456
Average KL loss: 0.907070
Average total loss: 2.322527
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.7038e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.407455
Average KL loss: 0.901557
Average total loss: 2.309012
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(2.2133e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.392114
Average KL loss: 0.896409
Average total loss: 2.288524
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.9375e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.396963
Average KL loss: 0.891787
Average total loss: 2.288750
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.1961e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.432103
Average KL loss: 0.889680
Average total loss: 2.321783
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.5091e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.395011
Average KL loss: 0.888334
Average total loss: 2.283345
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.1750e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.432365
Average KL loss: 0.882228
Average total loss: 2.314593
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(1.3418e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.401958
Average KL loss: 0.882303
Average total loss: 2.284261
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.2193e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.417654
Average KL loss: 0.876883
Average total loss: 2.294537
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.4014e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.419604
Average KL loss: 0.873174
Average total loss: 2.292778
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.7776e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.449898
Average KL loss: 0.875405
Average total loss: 2.325303
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(5.8374e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.442652
Average KL loss: 0.877364
Average total loss: 2.320016
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.5031e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.403593
Average KL loss: 0.873258
Average total loss: 2.276852
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.8236e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.413243
Average KL loss: 0.868065
Average total loss: 2.281308
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(6.9937e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.410837
Average KL loss: 0.865431
Average total loss: 2.276268
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.5887e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.409746
Average KL loss: 0.863886
Average total loss: 2.273632
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.2090e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.429802
Average KL loss: 0.860817
Average total loss: 2.290620
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.1013e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.423056
Average KL loss: 0.861118
Average total loss: 2.284175
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.3065e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.431041
Average KL loss: 0.859308
Average total loss: 2.290349
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.4159e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.424570
Average KL loss: 0.856008
Average total loss: 2.280578
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.1602e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.435275
Average KL loss: 0.854683
Average total loss: 2.289958
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.6236e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.394663
Average KL loss: 0.853814
Average total loss: 2.248477
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.9650e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.434366
Average KL loss: 0.849265
Average total loss: 2.283631
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(9.6955e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.442214
Average KL loss: 0.851881
Average total loss: 2.294095
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.2297e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.424906
Average KL loss: 0.852583
Average total loss: 2.277489
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.0347e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.422489
Average KL loss: 0.848757
Average total loss: 2.271246
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.0899e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.413151
Average KL loss: 0.845753
Average total loss: 2.258905
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.8729e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.403339
Average KL loss: 0.841732
Average total loss: 2.245071
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.1076e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.412538
Average KL loss: 0.839551
Average total loss: 2.252089
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.2832e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.417029
Average KL loss: 0.839212
Average total loss: 2.256241
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(2.6570e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.421851
Average KL loss: 0.838006
Average total loss: 2.259857
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.7694e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.414515
Average KL loss: 0.838620
Average total loss: 2.253135
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(2.6790e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.417080
Average KL loss: 0.836430
Average total loss: 2.253510
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(1.5361e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.417974
Average KL loss: 0.833959
Average total loss: 2.251934
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.5012e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.426697
Average KL loss: 0.835147
Average total loss: 2.261845
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(3.7706e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.432031
Average KL loss: 0.832007
Average total loss: 2.264038
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(3.1420e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.403113
Average KL loss: 0.828829
Average total loss: 2.231942
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.1442e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.437254
Average KL loss: 0.827053
Average total loss: 2.264308
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.2949e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.410972
Average KL loss: 0.825055
Average total loss: 2.236027
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-7.7003e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.445708
Average KL loss: 0.825703
Average total loss: 2.271411
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(8.6376e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.421978
Average KL loss: 0.827258
Average total loss: 2.249237
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.6699e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.443023
Average KL loss: 0.824834
Average total loss: 2.267857
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.5534e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.439651
Average KL loss: 0.825326
Average total loss: 2.264977
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.5763e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.424283
Average KL loss: 0.822349
Average total loss: 2.246632
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.0098e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.432675
Average KL loss: 0.818813
Average total loss: 2.251488
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.1849e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.420497
Average KL loss: 0.817255
Average total loss: 2.237751
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.9097e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.428267
Average KL loss: 0.816883
Average total loss: 2.245150
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.9121e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.438384
Average KL loss: 0.814102
Average total loss: 2.252486
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(2.7854e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.427066
Average KL loss: 0.811164
Average total loss: 2.238230
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(2.2165e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.418861
Average KL loss: 0.801427
Average total loss: 2.220288
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(9.7519e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.414204
Average KL loss: 0.793548
Average total loss: 2.207753
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.0053e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.438432
Average KL loss: 0.787379
Average total loss: 2.225812
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.1319e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.430800
Average KL loss: 0.782390
Average total loss: 2.213190
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(2.6615e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.417923
Average KL loss: 0.778135
Average total loss: 2.196058
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.1769e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.396972
Average KL loss: 0.774556
Average total loss: 2.171528
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.1477e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.441432
Average KL loss: 0.771534
Average total loss: 2.212965
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.2233e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.416116
Average KL loss: 0.769111
Average total loss: 2.185227
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.5397e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.439473
Average KL loss: 0.766506
Average total loss: 2.205978
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(5.5077e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.433175
Average KL loss: 0.764510
Average total loss: 2.197685
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-9.6341e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.426929
Average KL loss: 0.762948
Average total loss: 2.189876
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.8204e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.428032
Average KL loss: 0.761517
Average total loss: 2.189549
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.5507e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.420709
Average KL loss: 0.759804
Average total loss: 2.180513
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.7491e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.437490
Average KL loss: 0.757955
Average total loss: 2.195445
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.2982e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.437004
Average KL loss: 0.756817
Average total loss: 2.193821
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.6863e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.445797
Average KL loss: 0.755710
Average total loss: 2.201508
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.2157e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.419269
Average KL loss: 0.754590
Average total loss: 2.173859
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(2.5807e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.424108
Average KL loss: 0.753822
Average total loss: 2.177930
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.7114e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.423126
Average KL loss: 0.753547
Average total loss: 2.176673
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.3723e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.423571
Average KL loss: 0.753316
Average total loss: 2.176887
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(2.3933e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.424576
Average KL loss: 0.753079
Average total loss: 2.177656
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.5178e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.443470
Average KL loss: 0.752877
Average total loss: 2.196347
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.4212e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.432507
Average KL loss: 0.752673
Average total loss: 2.185179
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.1224e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.417627
Average KL loss: 0.752436
Average total loss: 2.170063
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.6318e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.450428
Average KL loss: 0.752220
Average total loss: 2.202648
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.8821e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.414653
Average KL loss: 0.752040
Average total loss: 2.166692
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(4.4400e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.438301
Average KL loss: 0.751845
Average total loss: 2.190146
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.5992e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.444851
Average KL loss: 0.751667
Average total loss: 2.196519
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(8.7491e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.417992
Average KL loss: 0.751487
Average total loss: 2.169479
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(3.1484e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.422375
Average KL loss: 0.751278
Average total loss: 2.173652
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.4475e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.428085
Average KL loss: 0.751069
Average total loss: 2.179155
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(3.0855e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.449502
Average KL loss: 0.750906
Average total loss: 2.200408
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.3565e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.420360
Average KL loss: 0.750745
Average total loss: 2.171104
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.0849e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.452828
Average KL loss: 0.750549
Average total loss: 2.203377
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(2.2159e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.433219
Average KL loss: 0.750403
Average total loss: 2.183622
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.4159e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.426912
Average KL loss: 0.750255
Average total loss: 2.177167
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.2497e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.446688
Average KL loss: 0.750067
Average total loss: 2.196755
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.1763e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.429050
Average KL loss: 0.749978
Average total loss: 2.179028
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.8454e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.450822
Average KL loss: 0.749959
Average total loss: 2.200782
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.1143e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.447771
Average KL loss: 0.749940
Average total loss: 2.197711
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.9545e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.452407
Average KL loss: 0.749920
Average total loss: 2.202326
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(3.1174e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.429876
Average KL loss: 0.749901
Average total loss: 2.179777
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.4076e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.421508
Average KL loss: 0.749877
Average total loss: 2.171386
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.0759e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.445958
Average KL loss: 0.749856
Average total loss: 2.195814
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.0301e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.444937
Average KL loss: 0.749837
Average total loss: 2.194774
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-9.7174e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.434316
Average KL loss: 0.749819
Average total loss: 2.184135
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(1.6772e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.445870
Average KL loss: 0.749800
Average total loss: 2.195670
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(5.6350e-09, device='cuda:0')
 Percentile value: 0.061192033439874643
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     442 /    1728             ( 25.58%) | total_pruned =    1286 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
bn1.bias             | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1444 /   36864             (  3.92%) | total_pruned =   35420 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2054 /   36864             (  5.57%) | total_pruned =   34810 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1819 /   36864             (  4.93%) | total_pruned =   35045 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1700 /   36864             (  4.61%) | total_pruned =   35164 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3624 /   73728             (  4.92%) | total_pruned =   70104 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5495 /  147456             (  3.73%) | total_pruned =  141961 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     786 /    8192             (  9.59%) | total_pruned =    7406 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2278 /  147456             (  1.54%) | total_pruned =  145178 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2038 /  147456             (  1.38%) | total_pruned =  145418 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8715 /  294912             (  2.96%) | total_pruned =  286197 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   13029 /  589824             (  2.21%) | total_pruned =  576795 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1540 /   32768             (  4.70%) | total_pruned =   31228 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     144 /     256             ( 56.25%) | total_pruned =     112 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2831 /  589824             (  0.48%) | total_pruned =  586993 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2455 /  589824             (  0.42%) | total_pruned =  587369 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      78 /     256             ( 30.47%) | total_pruned =     178 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   14702 / 1179648             (  1.25%) | total_pruned = 1164946 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   11663 / 2359296             (  0.49%) | total_pruned = 2347633 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     244 /     512             ( 47.66%) | total_pruned =     268 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2255 /  131072             (  1.72%) | total_pruned =  128817 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     189 /     512             ( 36.91%) | total_pruned =     323 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    5807 / 2359296             (  0.25%) | total_pruned = 2353489 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     237 /     512             ( 46.29%) | total_pruned =     275 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2180 / 2359296             (  0.09%) | total_pruned = 2357116 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
linear.weight        | nonzeros =     581 /    5120             ( 11.35%) | total_pruned =    4539 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 48/200 Loss: 0.004510 Accuracy: 81.61 100.00 % Best test Accuracy: 82.78%
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.5124e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 3.884411
Average KL loss: 2.166920
Average total loss: 6.051331
tensor(0.0010, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(9.0651e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 3.241158
Average KL loss: 2.195109
Average total loss: 5.436268
tensor(0.0009, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(2.4473e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.920022
Average KL loss: 2.265166
Average total loss: 5.185188
tensor(0.0005, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(5.0583e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.787662
Average KL loss: 2.197033
Average total loss: 4.984695
tensor(0.0005, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(6.6238e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.545177
Average KL loss: 2.114595
Average total loss: 4.659772
tensor(0.0005, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(7.6579e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.452373
Average KL loss: 2.038425
Average total loss: 4.490798
tensor(0.0005, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.1650e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.281735
Average KL loss: 1.990397
Average total loss: 4.272132
tensor(0.0005, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(1.3402e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.233819
Average KL loss: 1.941691
Average total loss: 4.175510
tensor(0.0005, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.5102e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.183392
Average KL loss: 1.927171
Average total loss: 4.110562
tensor(0.0005, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(1.2369e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.087555
Average KL loss: 1.908828
Average total loss: 3.996383
tensor(0.0005, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(3.3983e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.107726
Average KL loss: 1.886192
Average total loss: 3.993918
tensor(0.0005, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.2134e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.072961
Average KL loss: 1.891570
Average total loss: 3.964531
tensor(0.0005, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(5.5160e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.959793
Average KL loss: 1.870509
Average total loss: 3.830302
tensor(0.0005, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.2247e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.032209
Average KL loss: 1.886460
Average total loss: 3.918669
tensor(0.0005, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.3645e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.929452
Average KL loss: 1.854026
Average total loss: 3.783478
tensor(0.0005, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(1.8609e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.872594
Average KL loss: 1.836309
Average total loss: 3.708903
tensor(0.0005, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.4755e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.892118
Average KL loss: 1.789246
Average total loss: 3.681364
tensor(0.0005, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(7.7789e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.889809
Average KL loss: 1.828017
Average total loss: 3.717827
tensor(0.0005, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.3830e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.880504
Average KL loss: 1.805265
Average total loss: 3.685769
tensor(0.0005, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(4.1505e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.854770
Average KL loss: 1.802248
Average total loss: 3.657018
tensor(0.0005, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(3.1553e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.838141
Average KL loss: 1.794228
Average total loss: 3.632369
tensor(0.0005, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.6044e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.802819
Average KL loss: 1.784783
Average total loss: 3.587602
tensor(0.0005, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.8045e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.811833
Average KL loss: 1.800254
Average total loss: 3.612087
tensor(0.0005, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.7328e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.780127
Average KL loss: 1.765355
Average total loss: 3.545482
tensor(0.0005, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-4.5772e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.772952
Average KL loss: 1.756399
Average total loss: 3.529352
tensor(7.9087e-05, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-9.6403e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.801586
Average KL loss: 1.766219
Average total loss: 3.567805
tensor(0.0005, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(3.3260e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.787828
Average KL loss: 1.775529
Average total loss: 3.563357
tensor(0.0005, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(1.3278e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.787016
Average KL loss: 1.771289
Average total loss: 3.558306
tensor(0.0004, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(1.5270e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.767756
Average KL loss: 1.754963
Average total loss: 3.522719
tensor(0.0005, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-3.1557e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.773620
Average KL loss: 1.747870
Average total loss: 3.521490
tensor(0.0005, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-5.4486e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.784742
Average KL loss: 1.817937
Average total loss: 3.602679
tensor(-0.0036, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.0356e-06, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.738935
Average KL loss: 1.777759
Average total loss: 3.516694
tensor(0.0002, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-6.8723e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.758717
Average KL loss: 1.749727
Average total loss: 3.508444
tensor(0.0005, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(5.2164e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.724866
Average KL loss: 1.749058
Average total loss: 3.473924
tensor(0.0001, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-6.8671e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.751669
Average KL loss: 1.738637
Average total loss: 3.490306
tensor(0.0005, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(4.7596e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.721641
Average KL loss: 1.778380
Average total loss: 3.500020
tensor(-0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.4050e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.706415
Average KL loss: 1.726994
Average total loss: 3.433409
tensor(0.0002, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-4.8648e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.724769
Average KL loss: 1.724767
Average total loss: 3.449536
tensor(0.0004, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.3068e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.735852
Average KL loss: 1.729866
Average total loss: 3.465718
tensor(0.0005, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.6837e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.713359
Average KL loss: 1.745346
Average total loss: 3.458705
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.7397e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.713890
Average KL loss: 1.778066
Average total loss: 3.491956
tensor(0.0034, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(7.8658e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.728353
Average KL loss: 1.736851
Average total loss: 3.465204
tensor(3.4682e-05, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.2444e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.736603
Average KL loss: 1.746781
Average total loss: 3.483384
tensor(0.0005, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.2069e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.737991
Average KL loss: 1.750652
Average total loss: 3.488643
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.6895e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.708691
Average KL loss: 1.745794
Average total loss: 3.454485
tensor(-0.0111, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.8551e-06, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.695734
Average KL loss: 1.730852
Average total loss: 3.426586
tensor(0.0013, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(2.0899e-07, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.721825
Average KL loss: 1.709840
Average total loss: 3.431666
tensor(0.0005, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(9.3358e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.730407
Average KL loss: 1.746359
Average total loss: 3.476766
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(5.2816e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.695119
Average KL loss: 1.755846
Average total loss: 3.450966
tensor(6.6993e-05, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-7.7725e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.704231
Average KL loss: 1.793341
Average total loss: 3.497572
tensor(0.0003, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.8647e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.705724
Average KL loss: 1.739645
Average total loss: 3.445369
tensor(0.0002, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.0337e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.692895
Average KL loss: 1.727400
Average total loss: 3.420295
tensor(0.0004, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.2817e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.693889
Average KL loss: 1.729515
Average total loss: 3.423404
tensor(0.0005, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(1.2882e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.725872
Average KL loss: 1.759397
Average total loss: 3.485269
tensor(0.0004, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(2.1385e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.686872
Average KL loss: 1.748678
Average total loss: 3.435550
tensor(1.4545e-06, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1551e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.684358
Average KL loss: 1.836165
Average total loss: 3.520523
tensor(0.0035, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(7.4639e-07, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.670451
Average KL loss: 1.733423
Average total loss: 3.403873
tensor(0.0003, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.8108e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.697613
Average KL loss: 1.737429
Average total loss: 3.435042
tensor(0.0004, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(9.7333e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.672196
Average KL loss: 1.731143
Average total loss: 3.403339
tensor(0.0004, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(8.9493e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.699533
Average KL loss: 1.733831
Average total loss: 3.433364
tensor(0.0004, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.0303e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.735987
Average KL loss: 1.761034
Average total loss: 3.497020
tensor(0.0004, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-3.7173e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.676229
Average KL loss: 1.752649
Average total loss: 3.428878
tensor(0.0004, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-5.5713e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.702418
Average KL loss: 1.757466
Average total loss: 3.459884
tensor(0.0004, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-4.5850e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.677836
Average KL loss: 1.791968
Average total loss: 3.469804
tensor(0.0019, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(3.9203e-07, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.688171
Average KL loss: 1.758776
Average total loss: 3.446947
tensor(0.0001, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-8.6756e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.694025
Average KL loss: 1.741039
Average total loss: 3.435065
tensor(0.0004, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.1686e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.684178
Average KL loss: 1.741016
Average total loss: 3.425194
tensor(0.0004, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(7.4800e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.685998
Average KL loss: 1.747832
Average total loss: 3.433830
tensor(0.0003, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.9043e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.687271
Average KL loss: 1.809475
Average total loss: 3.496746
tensor(0.0033, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(7.1972e-07, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.662860
Average KL loss: 1.747478
Average total loss: 3.410339
tensor(0.0005, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(2.8429e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.665046
Average KL loss: 1.645962
Average total loss: 3.311009
tensor(0.0004, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(9.8826e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.650114
Average KL loss: 1.510730
Average total loss: 3.160844
tensor(0.0004, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.1711e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.654038
Average KL loss: 1.425366
Average total loss: 3.079405
tensor(0.0004, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(5.5192e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.679723
Average KL loss: 1.365557
Average total loss: 3.045279
tensor(0.0004, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(1.2691e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.654552
Average KL loss: 1.323174
Average total loss: 2.977726
tensor(0.0004, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.8349e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.651403
Average KL loss: 1.289057
Average total loss: 2.940460
tensor(0.0004, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(2.6809e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.659044
Average KL loss: 1.261743
Average total loss: 2.920788
tensor(0.0004, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(1.0432e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.653919
Average KL loss: 1.239545
Average total loss: 2.893464
tensor(0.0004, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(2.2651e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.649494
Average KL loss: 1.221407
Average total loss: 2.870901
tensor(0.0004, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(3.7327e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.660288
Average KL loss: 1.205893
Average total loss: 2.866182
tensor(0.0004, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(3.1826e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.652781
Average KL loss: 1.193493
Average total loss: 2.846274
tensor(0.0004, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(7.8536e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.642141
Average KL loss: 1.180320
Average total loss: 2.822461
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.1757e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.653184
Average KL loss: 1.171277
Average total loss: 2.824461
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.6043e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.675377
Average KL loss: 1.162844
Average total loss: 2.838221
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.1357e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.641115
Average KL loss: 1.155285
Average total loss: 2.796400
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.7586e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.670204
Average KL loss: 1.145695
Average total loss: 2.815900
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.5286e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.675884
Average KL loss: 1.140115
Average total loss: 2.815999
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(7.6229e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.663256
Average KL loss: 1.135691
Average total loss: 2.798947
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.3428e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.654288
Average KL loss: 1.130372
Average total loss: 2.784660
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0152e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.654156
Average KL loss: 1.126300
Average total loss: 2.780456
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0352e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.654507
Average KL loss: 1.122493
Average total loss: 2.777000
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(7.4171e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.649961
Average KL loss: 1.119664
Average total loss: 2.769625
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.4421e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.685323
Average KL loss: 1.114929
Average total loss: 2.800252
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.3807e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.642037
Average KL loss: 1.108477
Average total loss: 2.750514
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.0959e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.641150
Average KL loss: 1.103790
Average total loss: 2.744940
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(5.1748e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.657357
Average KL loss: 1.100981
Average total loss: 2.758338
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.8167e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.694527
Average KL loss: 1.097606
Average total loss: 2.792133
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.9381e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.674571
Average KL loss: 1.097490
Average total loss: 2.772061
tensor(0.0004, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-7.6136e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.666765
Average KL loss: 1.094607
Average total loss: 2.761372
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-4.8979e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.677530
Average KL loss: 1.091529
Average total loss: 2.769058
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(7.7171e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.676890
Average KL loss: 1.088731
Average total loss: 2.765621
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(7.1540e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.659811
Average KL loss: 1.088709
Average total loss: 2.748520
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.5426e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.662428
Average KL loss: 1.084173
Average total loss: 2.746601
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.9083e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.652166
Average KL loss: 1.081999
Average total loss: 2.734166
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.3857e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.696740
Average KL loss: 1.079293
Average total loss: 2.776032
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(2.4086e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.682656
Average KL loss: 1.077287
Average total loss: 2.759943
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(2.0923e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.673858
Average KL loss: 1.076422
Average total loss: 2.750280
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(2.0337e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.687254
Average KL loss: 1.075272
Average total loss: 2.762525
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(2.6252e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.672870
Average KL loss: 1.073807
Average total loss: 2.746677
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.1861e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.665378
Average KL loss: 1.071442
Average total loss: 2.736821
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.9830e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.668834
Average KL loss: 1.068497
Average total loss: 2.737331
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.1113e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.670626
Average KL loss: 1.067621
Average total loss: 2.738247
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.9525e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.675626
Average KL loss: 1.065230
Average total loss: 2.740856
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.9225e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.674763
Average KL loss: 1.063013
Average total loss: 2.737776
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.7232e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.670382
Average KL loss: 1.062974
Average total loss: 2.733356
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.7677e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.672892
Average KL loss: 1.060593
Average total loss: 2.733485
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(3.3259e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.690734
Average KL loss: 1.060031
Average total loss: 2.750766
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(7.5665e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.663471
Average KL loss: 1.055934
Average total loss: 2.719405
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(5.0793e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.665424
Average KL loss: 1.053873
Average total loss: 2.719298
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.8730e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.706936
Average KL loss: 1.053234
Average total loss: 2.760170
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(4.3182e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.693407
Average KL loss: 1.053443
Average total loss: 2.746850
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.9587e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.682007
Average KL loss: 1.054812
Average total loss: 2.736819
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.8884e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.700963
Average KL loss: 1.054776
Average total loss: 2.755740
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(3.8569e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.672916
Average KL loss: 1.052757
Average total loss: 2.725672
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.4623e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.670771
Average KL loss: 1.051457
Average total loss: 2.722228
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-9.4280e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.678692
Average KL loss: 1.050582
Average total loss: 2.729274
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1859e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.669329
Average KL loss: 1.048875
Average total loss: 2.718204
tensor(0.0004, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5226e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.697397
Average KL loss: 1.047608
Average total loss: 2.745006
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.8147e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.689730
Average KL loss: 1.048659
Average total loss: 2.738389
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.3368e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.681651
Average KL loss: 1.048200
Average total loss: 2.729851
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4511e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.672709
Average KL loss: 1.045448
Average total loss: 2.718157
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.2050e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.701945
Average KL loss: 1.044659
Average total loss: 2.746604
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3965e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.662091
Average KL loss: 1.043839
Average total loss: 2.705930
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.1308e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.705148
Average KL loss: 1.042856
Average total loss: 2.748004
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.1377e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.691447
Average KL loss: 1.041958
Average total loss: 2.733405
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(6.5668e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.683698
Average KL loss: 1.041517
Average total loss: 2.725215
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.2549e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.681860
Average KL loss: 1.038647
Average total loss: 2.720507
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.4308e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.694419
Average KL loss: 1.037226
Average total loss: 2.731645
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.8734e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.698638
Average KL loss: 1.037359
Average total loss: 2.735997
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.5987e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.718821
Average KL loss: 1.036098
Average total loss: 2.754919
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.0635e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.698494
Average KL loss: 1.038793
Average total loss: 2.737287
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.3753e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.687051
Average KL loss: 1.037252
Average total loss: 2.724303
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.2286e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.690017
Average KL loss: 1.033840
Average total loss: 2.723857
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9682e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.689569
Average KL loss: 1.032419
Average total loss: 2.721988
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(7.5370e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.695027
Average KL loss: 1.030384
Average total loss: 2.725411
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.4013e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.702891
Average KL loss: 1.027426
Average total loss: 2.730316
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.5064e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.703993
Average KL loss: 1.024665
Average total loss: 2.728658
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(8.0759e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.688974
Average KL loss: 1.022054
Average total loss: 2.711028
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.3218e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.684940
Average KL loss: 1.019597
Average total loss: 2.704538
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.1649e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.690928
Average KL loss: 1.017460
Average total loss: 2.708389
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.7438e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.689673
Average KL loss: 1.015595
Average total loss: 2.705267
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.0194e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.701287
Average KL loss: 1.013574
Average total loss: 2.714861
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.5161e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.683837
Average KL loss: 1.011897
Average total loss: 2.695734
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.2516e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.687019
Average KL loss: 1.010203
Average total loss: 2.697223
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.5843e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.705807
Average KL loss: 1.008667
Average total loss: 2.714474
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.0903e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.729443
Average KL loss: 1.007273
Average total loss: 2.736716
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(8.3581e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.701762
Average KL loss: 1.006050
Average total loss: 2.707812
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.1397e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.712904
Average KL loss: 1.004700
Average total loss: 2.717604
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.3369e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.668941
Average KL loss: 1.003318
Average total loss: 2.672259
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.6943e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.670708
Average KL loss: 1.002023
Average total loss: 2.672731
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.8027e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.704565
Average KL loss: 1.000862
Average total loss: 2.705427
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.3533e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.712075
Average KL loss: 0.999975
Average total loss: 2.712049
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.2441e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.706244
Average KL loss: 0.998800
Average total loss: 2.705044
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.1366e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.690321
Average KL loss: 0.997793
Average total loss: 2.688114
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.2601e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.680150
Average KL loss: 0.996753
Average total loss: 2.676903
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.8154e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.686201
Average KL loss: 0.995669
Average total loss: 2.681870
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0847e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.698072
Average KL loss: 0.994668
Average total loss: 2.692740
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.7110e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.685763
Average KL loss: 0.993841
Average total loss: 2.679605
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.2612e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.687864
Average KL loss: 0.992851
Average total loss: 2.680715
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.6926e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.683390
Average KL loss: 0.992039
Average total loss: 2.675429
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(5.7972e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.697166
Average KL loss: 0.991598
Average total loss: 2.688764
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0761e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 1.694613
Average KL loss: 0.991512
Average total loss: 2.686126
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.3503e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.678050
Average KL loss: 0.991394
Average total loss: 2.669444
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4796e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.691743
Average KL loss: 0.991272
Average total loss: 2.683015
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(8.7334e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 1.697768
Average KL loss: 0.991167
Average total loss: 2.688935
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4357e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 1.689393
Average KL loss: 0.991064
Average total loss: 2.680458
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.2630e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 1.697571
Average KL loss: 0.990972
Average total loss: 2.688543
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.1952e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 1.710717
Average KL loss: 0.990866
Average total loss: 2.701582
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.5286e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 1.682442
Average KL loss: 0.990765
Average total loss: 2.673207
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.3839e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 1.685205
Average KL loss: 0.990649
Average total loss: 2.675854
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.8650e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 1.706626
Average KL loss: 0.990536
Average total loss: 2.697162
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.4158e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 1.675663
Average KL loss: 0.990427
Average total loss: 2.666090
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.6365e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 1.691211
Average KL loss: 0.990287
Average total loss: 2.681498
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.6579e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 1.691607
Average KL loss: 0.990170
Average total loss: 2.681777
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.2150e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 1.704975
Average KL loss: 0.990054
Average total loss: 2.695030
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.2696e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 1.681019
Average KL loss: 0.989945
Average total loss: 2.670965
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.7690e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 1.700050
Average KL loss: 0.989858
Average total loss: 2.689908
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.3724e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 1.679666
Average KL loss: 0.989755
Average total loss: 2.669422
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.7284e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 1.682042
Average KL loss: 0.989640
Average total loss: 2.671681
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9979e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 1.703266
Average KL loss: 0.989532
Average total loss: 2.692799
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.1389e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 1.689790
Average KL loss: 0.989426
Average total loss: 2.679217
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.0459e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 1.709963
Average KL loss: 0.989328
Average total loss: 2.699291
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.1441e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 1.686421
Average KL loss: 0.989222
Average total loss: 2.675643
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.3423e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 1.691501
Average KL loss: 0.989159
Average total loss: 2.680660
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.7582e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 1.673323
Average KL loss: 0.989148
Average total loss: 2.662471
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.3037e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 1.681046
Average KL loss: 0.989135
Average total loss: 2.670181
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(6.1172e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 1.679717
Average KL loss: 0.989126
Average total loss: 2.668842
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9193e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 1.696314
Average KL loss: 0.989116
Average total loss: 2.685430
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.1824e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 1.686711
Average KL loss: 0.989107
Average total loss: 2.675818
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(7.4538e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 1.699561
Average KL loss: 0.989096
Average total loss: 2.688657
 Percentile value: 0.1562027961015701
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     260 /    1728             ( 15.05%) | total_pruned =    1468 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
bn1.bias             | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     617 /   36864             (  1.67%) | total_pruned =   36247 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     921 /   36864             (  2.50%) | total_pruned =   35943 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     883 /   36864             (  2.40%) | total_pruned =   35981 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     848 /   36864             (  2.30%) | total_pruned =   36016 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1655 /   73728             (  2.24%) | total_pruned =   72073 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2215 /  147456             (  1.50%) | total_pruned =  145241 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     405 /    8192             (  4.94%) | total_pruned =    7787 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     741 /  147456             (  0.50%) | total_pruned =  146715 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     532 /  147456             (  0.36%) | total_pruned =  146924 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3317 /  294912             (  1.12%) | total_pruned =  291595 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4108 /  589824             (  0.70%) | total_pruned =  585716 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     587 /   32768             (  1.79%) | total_pruned =   32181 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      98 /     256             ( 38.28%) | total_pruned =     158 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     496 /  589824             (  0.08%) | total_pruned =  589328 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      57 /     256             ( 22.27%) | total_pruned =     199 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     356 /  589824             (  0.06%) | total_pruned =  589468 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    3726 / 1179648             (  0.32%) | total_pruned = 1175922 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2078 / 2359296             (  0.09%) | total_pruned = 2357218 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      96 /     512             ( 18.75%) | total_pruned =     416 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     639 /  131072             (  0.49%) | total_pruned =  130433 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      89 /     512             ( 17.38%) | total_pruned =     423 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     625 / 2359296             (  0.03%) | total_pruned = 2358671 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      58 /     512             ( 11.33%) | total_pruned =     454 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     152 / 2359296             (  0.01%) | total_pruned = 2359144 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      31 /     512             (  6.05%) | total_pruned =     481 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
linear.weight        | nonzeros =     190 /    5120             (  3.71%) | total_pruned =    4930 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 199/200 Loss: 0.216937 Accuracy: 73.00 98.10 % Best test Accuracy: 76.25%
tensor(0.0004, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.9691e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 5.640957
Average KL loss: 1.535781
Average total loss: 7.176738
tensor(0.0043, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(8.6487e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 4.856430
Average KL loss: 1.482024
Average total loss: 6.338454
tensor(0.0008, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.4013e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 4.582851
Average KL loss: 1.703678
Average total loss: 6.286529
tensor(0.0005, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-8.8081e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 4.067877
Average KL loss: 1.840750
Average total loss: 5.908627
tensor(0.0005, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.0468e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 3.593444
Average KL loss: 1.922292
Average total loss: 5.515737
tensor(0.0005, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.3032e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 3.340364
Average KL loss: 1.959311
Average total loss: 5.299676
tensor(0.0006, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.0764e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 3.355156
Average KL loss: 1.996831
Average total loss: 5.351987
tensor(0.0006, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.4435e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 3.025361
Average KL loss: 2.016768
Average total loss: 5.042129
tensor(0.0006, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(6.8729e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 3.250590
Average KL loss: 2.034042
Average total loss: 5.284632
tensor(0.0006, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-4.9587e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.763793
Average KL loss: 2.058674
Average total loss: 4.822468
tensor(0.0006, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.0272e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.699674
Average KL loss: 2.042050
Average total loss: 4.741724
tensor(0.0006, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.4304e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.761248
Average KL loss: 2.053434
Average total loss: 4.814682
tensor(0.0006, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.1664e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.442107
Average KL loss: 2.034534
Average total loss: 4.476641
tensor(0.0006, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.8569e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.452526
Average KL loss: 2.006434
Average total loss: 4.458960
tensor(0.0006, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0525e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.468032
Average KL loss: 1.999327
Average total loss: 4.467359
tensor(0.0006, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(2.0462e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.325600
Average KL loss: 1.991539
Average total loss: 4.317139
tensor(0.0006, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(2.9459e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.327616
Average KL loss: 1.997693
Average total loss: 4.325309
tensor(0.0006, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.3427e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.345123
Average KL loss: 1.998644
Average total loss: 4.343768
tensor(0.0006, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2573e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.350963
Average KL loss: 2.010273
Average total loss: 4.361237
tensor(0.0006, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.4797e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.211360
Average KL loss: 2.011425
Average total loss: 4.222786
tensor(0.0006, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(1.3583e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.406329
Average KL loss: 2.018214
Average total loss: 4.424543
tensor(0.0006, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(3.5699e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.216014
Average KL loss: 2.031901
Average total loss: 4.247916
tensor(0.0006, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.0432e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.106023
Average KL loss: 2.015086
Average total loss: 4.121110
tensor(0.0006, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(1.5482e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.158784
Average KL loss: 2.010701
Average total loss: 4.169486
tensor(0.0006, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1002e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.057757
Average KL loss: 2.085996
Average total loss: 4.143753
tensor(-0.0082, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.2088e-06, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.111333
Average KL loss: 2.015816
Average total loss: 4.127149
tensor(0.0014, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.5760e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.075916
Average KL loss: 2.014498
Average total loss: 4.090414
tensor(0.0006, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(7.1285e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.033792
Average KL loss: 2.013887
Average total loss: 4.047678
tensor(0.0007, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(2.7889e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.038966
Average KL loss: 2.001368
Average total loss: 4.040334
tensor(0.0007, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(9.6333e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.076820
Average KL loss: 1.998872
Average total loss: 4.075692
tensor(0.0006, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(4.3401e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.035887
Average KL loss: 1.998060
Average total loss: 4.033947
tensor(0.0006, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-4.7235e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.010841
Average KL loss: 1.989703
Average total loss: 4.000545
tensor(0.0007, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(3.8080e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.995096
Average KL loss: 1.980677
Average total loss: 3.975774
tensor(0.0007, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(3.2647e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 2.005204
Average KL loss: 1.982528
Average total loss: 3.987732
tensor(-0.0066, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.8368e-06, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.947779
Average KL loss: 2.066987
Average total loss: 4.014766
tensor(0.0020, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(3.4499e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.961624
Average KL loss: 1.980505
Average total loss: 3.942129
tensor(0.0007, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(1.3325e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.967385
Average KL loss: 1.985476
Average total loss: 3.952861
tensor(0.0006, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(6.9975e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.964763
Average KL loss: 1.970054
Average total loss: 3.934817
tensor(0.0007, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(2.2399e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.973394
Average KL loss: 1.966295
Average total loss: 3.939690
tensor(0.0007, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.3073e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.929634
Average KL loss: 1.974336
Average total loss: 3.903970
tensor(0.0007, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6637e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.910804
Average KL loss: 1.967514
Average total loss: 3.878318
tensor(0.0007, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-3.2402e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.910627
Average KL loss: 2.035424
Average total loss: 3.946052
tensor(-0.0024, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-7.8050e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 2.028916
Average KL loss: 1.966810
Average total loss: 3.995726
tensor(0.0006, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.2030e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.871933
Average KL loss: 1.955434
Average total loss: 3.827368
tensor(0.0006, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.8856e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.906427
Average KL loss: 1.962792
Average total loss: 3.869219
tensor(0.0006, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.0886e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.947389
Average KL loss: 1.975834
Average total loss: 3.923222
tensor(0.0007, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.4333e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.843926
Average KL loss: 1.973283
Average total loss: 3.817209
tensor(0.0007, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.1394e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.841702
Average KL loss: 1.959695
Average total loss: 3.801397
tensor(0.0007, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(1.8444e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.846150
Average KL loss: 1.967987
Average total loss: 3.814137
tensor(-0.0098, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.6054e-06, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.821922
Average KL loss: 2.004924
Average total loss: 3.826847
tensor(0.0014, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(1.8259e-07, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.811430
Average KL loss: 1.950260
Average total loss: 3.761690
tensor(0.0007, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(1.7545e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.804715
Average KL loss: 1.958786
Average total loss: 3.763502
tensor(0.0007, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-9.4321e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.813598
Average KL loss: 1.951897
Average total loss: 3.765495
tensor(0.0007, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(1.4373e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.825902
Average KL loss: 1.967227
Average total loss: 3.793130
tensor(0.0007, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(5.3745e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.798404
Average KL loss: 2.024333
Average total loss: 3.822737
tensor(-0.0053, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.4830e-06, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.786117
Average KL loss: 1.973175
Average total loss: 3.759292
tensor(0.0010, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(5.1490e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.812079
Average KL loss: 1.945586
Average total loss: 3.757665
tensor(0.0007, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(2.4511e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.851924
Average KL loss: 1.951752
Average total loss: 3.803677
tensor(0.0007, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.6049e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.812164
Average KL loss: 1.970971
Average total loss: 3.783134
tensor(0.0007, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(5.2481e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.784786
Average KL loss: 1.963883
Average total loss: 3.748669
tensor(0.0007, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(1.3242e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.775276
Average KL loss: 1.952388
Average total loss: 3.727665
tensor(0.0007, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(4.5357e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.794363
Average KL loss: 1.943701
Average total loss: 3.738064
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.0593e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.770174
Average KL loss: 1.971617
Average total loss: 3.741791
tensor(0.0008, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(5.4548e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.754225
Average KL loss: 2.045181
Average total loss: 3.799407
tensor(0.0033, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(6.1358e-07, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.777785
Average KL loss: 1.967316
Average total loss: 3.745101
tensor(0.0004, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.7493e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.775623
Average KL loss: 1.968780
Average total loss: 3.744403
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.3927e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.770653
Average KL loss: 1.965102
Average total loss: 3.735755
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.1016e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.749140
Average KL loss: 1.961343
Average total loss: 3.710483
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.5119e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.759748
Average KL loss: 1.965653
Average total loss: 3.725400
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.5179e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.805133
Average KL loss: 1.970386
Average total loss: 3.775519
tensor(0.0007, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(2.2681e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.834242
Average KL loss: 1.981001
Average total loss: 3.815243
tensor(0.0007, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.5550e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.739894
Average KL loss: 2.054288
Average total loss: 3.794182
tensor(-0.0011, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.2832e-07, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.761115
Average KL loss: 1.998736
Average total loss: 3.759851
tensor(0.0009, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(4.2952e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.761273
Average KL loss: 1.991121
Average total loss: 3.752394
tensor(0.0007, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.5779e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.754354
Average KL loss: 1.987323
Average total loss: 3.741678
tensor(0.0007, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.3181e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.764802
Average KL loss: 1.974002
Average total loss: 3.738805
tensor(0.0007, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(7.9959e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.759073
Average KL loss: 1.972042
Average total loss: 3.731115
tensor(0.0010, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(9.3337e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.753897
Average KL loss: 2.043056
Average total loss: 3.796952
tensor(0.0025, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.3623e-07, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.763804
Average KL loss: 1.967617
Average total loss: 3.731421
tensor(0.0009, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(4.7578e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.755765
Average KL loss: 1.947249
Average total loss: 3.703014
tensor(0.0007, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.2589e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.752617
Average KL loss: 1.907636
Average total loss: 3.660253
tensor(0.0007, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(7.9704e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.731081
Average KL loss: 1.874492
Average total loss: 3.605573
tensor(0.0007, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.4614e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.738031
Average KL loss: 1.847111
Average total loss: 3.585143
tensor(0.0007, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.8182e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.747368
Average KL loss: 1.823576
Average total loss: 3.570944
tensor(0.0007, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-7.5054e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.731353
Average KL loss: 1.803976
Average total loss: 3.535330
tensor(0.0007, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(3.7810e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.723849
Average KL loss: 1.786301
Average total loss: 3.510150
tensor(0.0007, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3841e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.739893
Average KL loss: 1.769830
Average total loss: 3.509723
tensor(0.0007, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.3327e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.725243
Average KL loss: 1.753546
Average total loss: 3.478790
tensor(0.0007, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.2029e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.764342
Average KL loss: 1.738767
Average total loss: 3.503109
tensor(0.0007, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-6.9212e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.735805
Average KL loss: 1.726979
Average total loss: 3.462784
tensor(0.0007, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(1.7648e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.711428
Average KL loss: 1.714874
Average total loss: 3.426302
tensor(0.0007, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-8.7875e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.718667
Average KL loss: 1.704340
Average total loss: 3.423006
tensor(0.0007, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(2.2351e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.746001
Average KL loss: 1.693305
Average total loss: 3.439307
tensor(0.0007, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(2.0136e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.726117
Average KL loss: 1.684931
Average total loss: 3.411048
tensor(0.0007, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(1.5642e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.711455
Average KL loss: 1.675850
Average total loss: 3.387305
tensor(0.0007, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(2.9117e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.731327
Average KL loss: 1.667479
Average total loss: 3.398806
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2497e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.750552
Average KL loss: 1.661202
Average total loss: 3.411754
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(1.8698e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.725443
Average KL loss: 1.654062
Average total loss: 3.379505
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-7.1963e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.721166
Average KL loss: 1.646736
Average total loss: 3.367902
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2546e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.724770
Average KL loss: 1.639065
Average total loss: 3.363835
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.2691e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.733639
Average KL loss: 1.633218
Average total loss: 3.366856
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.5451e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.741745
Average KL loss: 1.627824
Average total loss: 3.369570
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.9686e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.737846
Average KL loss: 1.622279
Average total loss: 3.360124
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(1.4536e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.709972
Average KL loss: 1.615167
Average total loss: 3.325139
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.1746e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.749224
Average KL loss: 1.608835
Average total loss: 3.358059
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(6.5182e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.710383
Average KL loss: 1.605117
Average total loss: 3.315501
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(3.0401e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.738975
Average KL loss: 1.601523
Average total loss: 3.340498
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-3.7417e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.759096
Average KL loss: 1.597289
Average total loss: 3.356386
tensor(0.0007, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-6.7788e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.808455
Average KL loss: 1.595495
Average total loss: 3.403950
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.3307e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.748077
Average KL loss: 1.593748
Average total loss: 3.341825
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(1.0499e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.734867
Average KL loss: 1.589364
Average total loss: 3.324231
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.0746e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.724726
Average KL loss: 1.584352
Average total loss: 3.309077
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.0746e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.742875
Average KL loss: 1.580586
Average total loss: 3.323461
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(3.3799e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.760586
Average KL loss: 1.578125
Average total loss: 3.338711
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(6.8945e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.727916
Average KL loss: 1.573522
Average total loss: 3.301438
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(3.7644e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.752207
Average KL loss: 1.568057
Average total loss: 3.320264
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.2905e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.758731
Average KL loss: 1.565381
Average total loss: 3.324112
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(4.3139e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.738698
Average KL loss: 1.561657
Average total loss: 3.300355
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(1.3385e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.780671
Average KL loss: 1.557912
Average total loss: 3.338583
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.2160e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.746124
Average KL loss: 1.553628
Average total loss: 3.299752
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(3.1366e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.781039
Average KL loss: 1.549541
Average total loss: 3.330580
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.4346e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.756782
Average KL loss: 1.546302
Average total loss: 3.303084
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(1.3260e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.745248
Average KL loss: 1.544641
Average total loss: 3.289889
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.5521e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.769666
Average KL loss: 1.542926
Average total loss: 3.312592
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.5713e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.760550
Average KL loss: 1.541275
Average total loss: 3.301825
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(7.4942e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.735291
Average KL loss: 1.541024
Average total loss: 3.276315
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(3.2302e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.758083
Average KL loss: 1.540242
Average total loss: 3.298326
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.9638e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.753135
Average KL loss: 1.540094
Average total loss: 3.293229
tensor(0.0007, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.1928e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.776493
Average KL loss: 1.538852
Average total loss: 3.315345
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.7460e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.752855
Average KL loss: 1.535249
Average total loss: 3.288104
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.7915e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.748460
Average KL loss: 1.532680
Average total loss: 3.281139
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.9350e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.721311
Average KL loss: 1.530834
Average total loss: 3.252146
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.4728e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.777495
Average KL loss: 1.528950
Average total loss: 3.306445
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.3845e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.753539
Average KL loss: 1.528564
Average total loss: 3.282103
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(4.5387e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.745682
Average KL loss: 1.526292
Average total loss: 3.271973
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-8.3150e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.795490
Average KL loss: 1.525387
Average total loss: 3.320877
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.4478e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.746230
Average KL loss: 1.525869
Average total loss: 3.272099
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.1850e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.750963
Average KL loss: 1.524305
Average total loss: 3.275268
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(8.5700e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.752029
Average KL loss: 1.523459
Average total loss: 3.275488
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-6.5248e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.744263
Average KL loss: 1.521648
Average total loss: 3.265911
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(2.6494e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.732636
Average KL loss: 1.518736
Average total loss: 3.251372
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.0622e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.750768
Average KL loss: 1.515751
Average total loss: 3.266520
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(2.9887e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.739762
Average KL loss: 1.514028
Average total loss: 3.253789
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.7225e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.754366
Average KL loss: 1.513066
Average total loss: 3.267432
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.6050e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.746895
Average KL loss: 1.511098
Average total loss: 3.257994
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.1682e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.775794
Average KL loss: 1.508771
Average total loss: 3.284565
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(9.7928e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.743544
Average KL loss: 1.508575
Average total loss: 3.252118
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(9.6084e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.767834
Average KL loss: 1.509307
Average total loss: 3.277141
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.9264e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.755846
Average KL loss: 1.508548
Average total loss: 3.264393
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.5947e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.746070
Average KL loss: 1.507403
Average total loss: 3.253473
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(2.8477e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.763849
Average KL loss: 1.505992
Average total loss: 3.269841
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.7986e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.763913
Average KL loss: 1.505065
Average total loss: 3.268978
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.5679e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.747274
Average KL loss: 1.504626
Average total loss: 3.251900
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(3.8365e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.741937
Average KL loss: 1.503759
Average total loss: 3.245696
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.5761e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.759843
Average KL loss: 1.502871
Average total loss: 3.262715
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(2.8281e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.762253
Average KL loss: 1.502102
Average total loss: 3.264355
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.1903e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.740191
Average KL loss: 1.501511
Average total loss: 3.241702
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(3.1215e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.780570
Average KL loss: 1.500708
Average total loss: 3.281278
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(3.0706e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.798575
Average KL loss: 1.500100
Average total loss: 3.298675
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.1210e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.736378
Average KL loss: 1.499327
Average total loss: 3.235705
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.3998e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.740118
Average KL loss: 1.498545
Average total loss: 3.238662
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(9.0365e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.733445
Average KL loss: 1.497730
Average total loss: 3.231174
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.0555e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.772838
Average KL loss: 1.496949
Average total loss: 3.269787
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(2.1315e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.746115
Average KL loss: 1.496317
Average total loss: 3.242433
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(2.1894e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.733930
Average KL loss: 1.495685
Average total loss: 3.229615
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(2.8346e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.753267
Average KL loss: 1.495115
Average total loss: 3.248382
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.1940e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.742879
Average KL loss: 1.494543
Average total loss: 3.237422
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(8.0873e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.756619
Average KL loss: 1.493902
Average total loss: 3.250521
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(8.1762e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.763689
Average KL loss: 1.493197
Average total loss: 3.256886
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(8.2047e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.746059
Average KL loss: 1.492531
Average total loss: 3.238590
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.8846e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.733332
Average KL loss: 1.491911
Average total loss: 3.225243
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(4.0958e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 1.779837
Average KL loss: 1.491378
Average total loss: 3.271215
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(2.7201e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.777183
Average KL loss: 1.490909
Average total loss: 3.268092
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.6701e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.793934
Average KL loss: 1.490612
Average total loss: 3.284546
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.1511e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 1.740169
Average KL loss: 1.490140
Average total loss: 3.230308
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.1465e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 1.744607
Average KL loss: 1.489512
Average total loss: 3.234119
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(2.1652e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 1.752266
Average KL loss: 1.489127
Average total loss: 3.241394
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.6507e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 1.732342
Average KL loss: 1.488843
Average total loss: 3.221185
tensor(0.0007, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.7834e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 1.747492
Average KL loss: 1.488293
Average total loss: 3.235785
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(2.6260e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 1.749846
Average KL loss: 1.487749
Average total loss: 3.237595
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-6.8108e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 1.759500
Average KL loss: 1.487292
Average total loss: 3.246793
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.1753e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 1.740250
Average KL loss: 1.486943
Average total loss: 3.227194
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(3.4378e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 1.751609
Average KL loss: 1.486587
Average total loss: 3.238196
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.2123e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 1.779665
Average KL loss: 1.486155
Average total loss: 3.265820
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.4012e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 1.769569
Average KL loss: 1.485777
Average total loss: 3.255346
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.4045e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 1.726478
Average KL loss: 1.485293
Average total loss: 3.211770
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(3.4957e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 1.759718
Average KL loss: 1.484783
Average total loss: 3.244500
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.0574e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 1.745230
Average KL loss: 1.484559
Average total loss: 3.229789
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.6919e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 1.750951
Average KL loss: 1.484033
Average total loss: 3.234984
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.2880e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 1.775134
Average KL loss: 1.483593
Average total loss: 3.258727
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.8298e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 1.760764
Average KL loss: 1.483246
Average total loss: 3.244010
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.0596e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 1.749180
Average KL loss: 1.482868
Average total loss: 3.232048
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(2.3636e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 1.752923
Average KL loss: 1.482517
Average total loss: 3.235439
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.2226e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 1.765266
Average KL loss: 1.482251
Average total loss: 3.247517
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.5174e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 1.742838
Average KL loss: 1.481881
Average total loss: 3.224719
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.1451e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 1.762020
Average KL loss: 1.481588
Average total loss: 3.243609
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.8448e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 1.752124
Average KL loss: 1.481178
Average total loss: 3.233302
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.7371e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 1.736715
Average KL loss: 1.480909
Average total loss: 3.217624
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(6.0040e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 1.771807
Average KL loss: 1.480871
Average total loss: 3.252678
tensor(0.0007, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.5901e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 1.726760
Average KL loss: 1.480829
Average total loss: 3.207590
 Percentile value: 0.7664050042629238
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =     176 /    1728             ( 10.19%) | total_pruned =    1552 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
bn1.bias             | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     248 /   36864             (  0.67%) | total_pruned =   36616 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     375 /   36864             (  1.02%) | total_pruned =   36489 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     440 /   36864             (  1.19%) | total_pruned =   36424 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     458 /   36864             (  1.24%) | total_pruned =   36406 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     719 /   73728             (  0.98%) | total_pruned =   73009 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     821 /  147456             (  0.56%) | total_pruned =  146635 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     196 /    8192             (  2.39%) | total_pruned =    7996 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     246 /  147456             (  0.17%) | total_pruned =  147210 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     161 /  147456             (  0.11%) | total_pruned =  147295 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1072 /  294912             (  0.36%) | total_pruned =  293840 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     105 /     256             ( 41.02%) | total_pruned =     151 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     928 /  589824             (  0.16%) | total_pruned =  588896 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      74 /     256             ( 28.91%) | total_pruned =     182 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     148 /   32768             (  0.45%) | total_pruned =   32620 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =      46 /  589824             (  0.01%) | total_pruned =  589778 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =      19 /  589824             (  0.00%) | total_pruned =  589805 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     587 / 1179648             (  0.05%) | total_pruned = 1179061 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     246 / 2359296             (  0.01%) | total_pruned = 2359050 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      50 /     512             (  9.77%) | total_pruned =     462 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      93 /  131072             (  0.07%) | total_pruned =  130979 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      88 / 2359296             (  0.00%) | total_pruned = 2359208 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      45 / 2359296             (  0.00%) | total_pruned = 2359251 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
linear.weight        | nonzeros =     100 /    5120             (  1.95%) | total_pruned =    5020 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 191/200 Loss: 0.505556 Accuracy: 70.05 78.26 % Best test Accuracy: 70.62%
