Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.161475
Average KL loss: 1.343186
Average total loss: 2.504662
tensor(0.0010, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.7304e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.668209
Average KL loss: 1.116153
Average total loss: 1.784362
tensor(0.0013, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.4812e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.475008
Average KL loss: 0.997365
Average total loss: 1.472372
tensor(0.0014, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.0815e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.382885
Average KL loss: 0.925027
Average total loss: 1.307912
tensor(0.0015, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.6271e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.327131
Average KL loss: 0.885857
Average total loss: 1.212988
tensor(0.0016, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.8818e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.285248
Average KL loss: 0.858401
Average total loss: 1.143649
tensor(0.0016, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-8.5382e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.253701
Average KL loss: 0.812537
Average total loss: 1.066238
tensor(0.0017, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.0896e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.233378
Average KL loss: 0.837447
Average total loss: 1.070825
tensor(0.0017, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.2992e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.208500
Average KL loss: 0.777962
Average total loss: 0.986461
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.1719e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.200276
Average KL loss: 0.788495
Average total loss: 0.988771
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.5320e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.195487
Average KL loss: 0.786292
Average total loss: 0.981779
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.6537e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.188441
Average KL loss: 0.782555
Average total loss: 0.970995
tensor(0.0018, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.2175e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.187097
Average KL loss: 0.834259
Average total loss: 1.021356
tensor(0.0018, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.3159e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.174378
Average KL loss: 0.778300
Average total loss: 0.952678
tensor(0.0017, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.6347e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.177259
Average KL loss: 0.776042
Average total loss: 0.953302
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.1951e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.161704
Average KL loss: 0.774196
Average total loss: 0.935900
tensor(0.0018, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(5.9015e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.156279
Average KL loss: 0.734940
Average total loss: 0.891219
tensor(0.0018, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.2446e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.160850
Average KL loss: 0.763978
Average total loss: 0.924829
tensor(0.0017, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.5163e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.158100
Average KL loss: 0.757845
Average total loss: 0.915945
tensor(0.0017, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.2978e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.161333
Average KL loss: 0.805098
Average total loss: 0.966431
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.0440e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.152235
Average KL loss: 0.768266
Average total loss: 0.920501
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.1471e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.151658
Average KL loss: 0.770610
Average total loss: 0.922267
tensor(0.0017, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.4795e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.154083
Average KL loss: 0.757098
Average total loss: 0.911181
tensor(0.0018, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.1330e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.147608
Average KL loss: 0.772210
Average total loss: 0.919818
tensor(0.0018, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(2.3690e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.147321
Average KL loss: 0.771824
Average total loss: 0.919145
tensor(0.0018, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.4103e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.142706
Average KL loss: 0.757864
Average total loss: 0.900570
tensor(0.0018, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.4349e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.144946
Average KL loss: 0.772362
Average total loss: 0.917308
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.1101e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.152145
Average KL loss: 0.801180
Average total loss: 0.953325
tensor(0.0018, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.9181e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.139399
Average KL loss: 0.529684
Average total loss: 0.669083
tensor(0.0018, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(2.0968e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.128537
Average KL loss: 0.334397
Average total loss: 0.462934
tensor(0.0018, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(3.5979e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.130613
Average KL loss: 0.299239
Average total loss: 0.429852
tensor(0.0017, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(3.3681e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.128607
Average KL loss: 0.285492
Average total loss: 0.414099
tensor(0.0018, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2146e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.125597
Average KL loss: 0.275798
Average total loss: 0.401394
tensor(0.0017, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(2.6018e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.125436
Average KL loss: 0.270401
Average total loss: 0.395836
tensor(0.0017, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(2.3788e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.130256
Average KL loss: 0.266311
Average total loss: 0.396567
tensor(0.0017, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(3.3518e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.128269
Average KL loss: 0.266258
Average total loss: 0.394527
tensor(0.0017, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(9.5574e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.127814
Average KL loss: 0.263897
Average total loss: 0.391712
tensor(0.0017, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.1028e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.130269
Average KL loss: 0.263558
Average total loss: 0.393827
tensor(0.0017, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(2.1037e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.128529
Average KL loss: 0.261608
Average total loss: 0.390137
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.4644e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.124882
Average KL loss: 0.258656
Average total loss: 0.383538
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.7123e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.127840
Average KL loss: 0.256795
Average total loss: 0.384635
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.2451e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.127581
Average KL loss: 0.257720
Average total loss: 0.385301
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.6705e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.120682
Average KL loss: 0.254030
Average total loss: 0.374712
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.6728e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.132637
Average KL loss: 0.255326
Average total loss: 0.387964
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(3.6405e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.125866
Average KL loss: 0.256242
Average total loss: 0.382108
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.9122e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.121899
Average KL loss: 0.252208
Average total loss: 0.374107
tensor(0.0017, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.6840e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.127549
Average KL loss: 0.251225
Average total loss: 0.378774
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(2.2101e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.129165
Average KL loss: 0.253698
Average total loss: 0.382862
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(9.5803e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.127836
Average KL loss: 0.253833
Average total loss: 0.381669
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.2740e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.132484
Average KL loss: 0.255412
Average total loss: 0.387895
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(2.0498e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.127292
Average KL loss: 0.253704
Average total loss: 0.380995
tensor(0.0017, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.0797e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.123955
Average KL loss: 0.252423
Average total loss: 0.376378
tensor(0.0017, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(2.5776e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.127046
Average KL loss: 0.252005
Average total loss: 0.379050
tensor(0.0017, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(2.2470e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.127138
Average KL loss: 0.249436
Average total loss: 0.376574
tensor(0.0017, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(9.4429e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.128562
Average KL loss: 0.251380
Average total loss: 0.379942
tensor(0.0017, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(2.0586e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.126520
Average KL loss: 0.250131
Average total loss: 0.376651
tensor(0.0017, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-6.6658e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.130125
Average KL loss: 0.249766
Average total loss: 0.379890
tensor(0.0017, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.5369e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.128220
Average KL loss: 0.243580
Average total loss: 0.371800
tensor(0.0017, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.0007e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.123641
Average KL loss: 0.229230
Average total loss: 0.352871
tensor(0.0017, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(5.4139e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.121956
Average KL loss: 0.221715
Average total loss: 0.343672
tensor(0.0017, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.0179e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.120987
Average KL loss: 0.216978
Average total loss: 0.337966
tensor(0.0017, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.0371e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.125620
Average KL loss: 0.213561
Average total loss: 0.339181
tensor(0.0017, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.5549e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.125757
Average KL loss: 0.211258
Average total loss: 0.337015
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(1.0050e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.125737
Average KL loss: 0.209434
Average total loss: 0.335171
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(2.9005e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.123126
Average KL loss: 0.207849
Average total loss: 0.330974
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.5279e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.126092
Average KL loss: 0.206571
Average total loss: 0.332662
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.1800e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.124966
Average KL loss: 0.205574
Average total loss: 0.330540
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.6719e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.127483
Average KL loss: 0.204805
Average total loss: 0.332288
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(2.2245e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.126151
Average KL loss: 0.204061
Average total loss: 0.330211
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.9935e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.127047
Average KL loss: 0.203395
Average total loss: 0.330442
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(5.7145e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.129324
Average KL loss: 0.202994
Average total loss: 0.332318
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.9773e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.127961
Average KL loss: 0.202511
Average total loss: 0.330472
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-4.0648e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.121201
Average KL loss: 0.202061
Average total loss: 0.323262
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(1.1129e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.128148
Average KL loss: 0.201740
Average total loss: 0.329888
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(3.0584e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.123002
Average KL loss: 0.201339
Average total loss: 0.324341
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.3737e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.125418
Average KL loss: 0.201000
Average total loss: 0.326419
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-8.2564e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.127088
Average KL loss: 0.200760
Average total loss: 0.327848
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(1.6678e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.125485
Average KL loss: 0.200469
Average total loss: 0.325954
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.7354e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.125853
Average KL loss: 0.200262
Average total loss: 0.326114
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(1.4112e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.122704
Average KL loss: 0.199997
Average total loss: 0.322701
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(3.5136e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.125227
Average KL loss: 0.199730
Average total loss: 0.324957
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(2.9255e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.122322
Average KL loss: 0.199468
Average total loss: 0.321790
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(4.2346e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.123833
Average KL loss: 0.199148
Average total loss: 0.322982
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.9890e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.126874
Average KL loss: 0.199067
Average total loss: 0.325941
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-4.1911e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.124356
Average KL loss: 0.198958
Average total loss: 0.323314
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(1.0159e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.130040
Average KL loss: 0.198821
Average total loss: 0.328861
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.1455e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.125690
Average KL loss: 0.198738
Average total loss: 0.324428
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(1.0535e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.122871
Average KL loss: 0.198524
Average total loss: 0.321395
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.8392e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.124303
Average KL loss: 0.198319
Average total loss: 0.322622
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.1820e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.127935
Average KL loss: 0.198284
Average total loss: 0.326219
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.7049e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.126916
Average KL loss: 0.198172
Average total loss: 0.325089
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(4.9002e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.126259
Average KL loss: 0.198140
Average total loss: 0.324399
tensor(0.0017, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(5.4459e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.127809
Average KL loss: 0.198089
Average total loss: 0.325898
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(7.6666e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.122711
Average KL loss: 0.197929
Average total loss: 0.320641
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.5452e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.125449
Average KL loss: 0.197766
Average total loss: 0.323215
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.8246e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.122454
Average KL loss: 0.197640
Average total loss: 0.320094
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.8661e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.125984
Average KL loss: 0.197479
Average total loss: 0.323463
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-4.6070e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.125564
Average KL loss: 0.197468
Average total loss: 0.323032
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(5.6718e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.121672
Average KL loss: 0.197267
Average total loss: 0.318938
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.0167e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.130158
Average KL loss: 0.197149
Average total loss: 0.327307
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-4.9772e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.122974
Average KL loss: 0.197242
Average total loss: 0.320216
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.7043e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.125685
Average KL loss: 0.196958
Average total loss: 0.322643
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.8004e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.126034
Average KL loss: 0.197107
Average total loss: 0.323141
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.7494e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.124387
Average KL loss: 0.196987
Average total loss: 0.321374
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.1445e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.120764
Average KL loss: 0.196676
Average total loss: 0.317440
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.0275e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.123834
Average KL loss: 0.196530
Average total loss: 0.320365
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(7.0721e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.126759
Average KL loss: 0.196558
Average total loss: 0.323317
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.1197e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.122942
Average KL loss: 0.196556
Average total loss: 0.319498
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(4.3740e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.123926
Average KL loss: 0.196276
Average total loss: 0.320202
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.9734e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.127019
Average KL loss: 0.196213
Average total loss: 0.323232
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-8.0876e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.131603
Average KL loss: 0.196336
Average total loss: 0.327939
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.9042e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.122456
Average KL loss: 0.196210
Average total loss: 0.318666
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.7438e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.125815
Average KL loss: 0.196118
Average total loss: 0.321933
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(4.6737e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.123602
Average KL loss: 0.196056
Average total loss: 0.319657
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.5523e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.123268
Average KL loss: 0.195878
Average total loss: 0.319146
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(7.4317e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.125520
Average KL loss: 0.195718
Average total loss: 0.321238
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-4.1511e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.126726
Average KL loss: 0.195584
Average total loss: 0.322310
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-4.2479e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.124558
Average KL loss: 0.195213
Average total loss: 0.319771
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4866e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.121570
Average KL loss: 0.194907
Average total loss: 0.316476
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.0038e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.123141
Average KL loss: 0.194647
Average total loss: 0.317788
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(9.4441e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.121068
Average KL loss: 0.194423
Average total loss: 0.315491
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(7.3022e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.124214
Average KL loss: 0.194229
Average total loss: 0.318442
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.6761e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.125795
Average KL loss: 0.194054
Average total loss: 0.319849
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.2255e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.125355
Average KL loss: 0.193900
Average total loss: 0.319255
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.6424e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.120916
Average KL loss: 0.193749
Average total loss: 0.314665
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.0017e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.127616
Average KL loss: 0.193613
Average total loss: 0.321230
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(4.5219e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.124532
Average KL loss: 0.193491
Average total loss: 0.318022
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.9363e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.127888
Average KL loss: 0.193378
Average total loss: 0.321266
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.1878e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.124597
Average KL loss: 0.193275
Average total loss: 0.317871
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.7697e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.125015
Average KL loss: 0.193174
Average total loss: 0.318189
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.0598e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.126711
Average KL loss: 0.193082
Average total loss: 0.319793
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.1407e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.127929
Average KL loss: 0.192991
Average total loss: 0.320920
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.1556e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.124774
Average KL loss: 0.192904
Average total loss: 0.317678
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.3346e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.125360
Average KL loss: 0.192819
Average total loss: 0.318178
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0855e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.124576
Average KL loss: 0.192740
Average total loss: 0.317316
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.6607e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.127521
Average KL loss: 0.192671
Average total loss: 0.320192
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.6377e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.119144
Average KL loss: 0.192631
Average total loss: 0.311776
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.4612e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.126715
Average KL loss: 0.192619
Average total loss: 0.319334
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(6.1465e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.126135
Average KL loss: 0.192607
Average total loss: 0.318742
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(7.2062e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.123620
Average KL loss: 0.192596
Average total loss: 0.316216
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(4.0120e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.128616
Average KL loss: 0.192585
Average total loss: 0.321201
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(6.8991e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.130816
Average KL loss: 0.192575
Average total loss: 0.323390
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.9911e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.122265
Average KL loss: 0.192565
Average total loss: 0.314829
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.3147e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.123236
Average KL loss: 0.192554
Average total loss: 0.315790
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.1361e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.128792
Average KL loss: 0.192544
Average total loss: 0.321336
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4609e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.126132
Average KL loss: 0.192534
Average total loss: 0.318666
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-4.6939e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.126318
Average KL loss: 0.192524
Average total loss: 0.318842
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.7385e-09, device='cuda:0')
 Percentile value: 0.00494025181978941
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1234 /    1728             ( 71.41%) | total_pruned =     494 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   18658 /   36864             ( 50.61%) | total_pruned =   18206 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   19542 /   36864             ( 53.01%) | total_pruned =   17322 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   18956 /   36864             ( 51.42%) | total_pruned =   17908 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18787 /   36864             ( 50.96%) | total_pruned =   18077 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   37389 /   73728             ( 50.71%) | total_pruned =   36339 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   72864 /  147456             ( 49.41%) | total_pruned =   74592 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5294 /    8192             ( 64.62%) | total_pruned =    2898 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   67203 /  147456             ( 45.57%) | total_pruned =   80253 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   67415 /  147456             ( 45.72%) | total_pruned =   80041 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  142931 /  294912             ( 48.47%) | total_pruned =  151981 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  276336 /  589824             ( 46.85%) | total_pruned =  313488 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19190 /   32768             ( 58.56%) | total_pruned =   13578 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  225900 /  589824             ( 38.30%) | total_pruned =  363924 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  223509 /  589824             ( 37.89%) | total_pruned =  366315 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  508814 / 1179648             ( 43.13%) | total_pruned =  670834 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     468 /     512             ( 91.41%) | total_pruned =      44 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  764852 / 2359296             ( 32.42%) | total_pruned = 1594444 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     400 /     512             ( 78.12%) | total_pruned =     112 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   63785 /  131072             ( 48.66%) | total_pruned =   67287 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     492 /     512             ( 96.09%) | total_pruned =      20 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     407 /     512             ( 79.49%) | total_pruned =     105 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  490979 / 2359296             ( 20.81%) | total_pruned = 1868317 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     406 /     512             ( 79.30%) | total_pruned =     106 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  297362 / 2359296             ( 12.60%) | total_pruned = 2061934 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([512])
linear.weight        | nonzeros =    4377 /    5120             ( 85.49%) | total_pruned =     743 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 37/200 Loss: 0.000101 Accuracy: 87.00 100.00 % Best test Accuracy: 87.06%
tensor(0.0017, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-4.4975e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.373397
Average KL loss: 1.003327
Average total loss: 1.376724
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.0952e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.324902
Average KL loss: 0.990779
Average total loss: 1.315681
tensor(0.0021, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.4067e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.293986
Average KL loss: 0.936651
Average total loss: 1.230637
tensor(0.0022, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.5722e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.273415
Average KL loss: 0.949045
Average total loss: 1.222460
tensor(0.0023, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.1260e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.265308
Average KL loss: 0.953316
Average total loss: 1.218625
tensor(0.0023, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.8635e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.257105
Average KL loss: 0.939881
Average total loss: 1.196986
tensor(0.0024, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.5429e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.247260
Average KL loss: 0.947771
Average total loss: 1.195031
tensor(0.0023, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(4.1311e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.236091
Average KL loss: 0.923596
Average total loss: 1.159687
tensor(0.0024, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-5.4300e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.223972
Average KL loss: 0.927395
Average total loss: 1.151368
tensor(0.0023, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.0940e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.214234
Average KL loss: 0.870106
Average total loss: 1.084340
tensor(0.0024, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(4.2520e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.213720
Average KL loss: 0.897824
Average total loss: 1.111544
tensor(0.0024, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-4.4440e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.217305
Average KL loss: 0.934216
Average total loss: 1.151521
tensor(0.0024, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(8.3066e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.211043
Average KL loss: 0.902934
Average total loss: 1.113977
tensor(0.0024, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(6.5978e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.216513
Average KL loss: 0.920177
Average total loss: 1.136690
tensor(0.0025, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(2.0518e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.218301
Average KL loss: 0.934648
Average total loss: 1.152948
tensor(0.0025, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-3.8871e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.205818
Average KL loss: 0.920710
Average total loss: 1.126528
tensor(0.0025, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.2370e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.201948
Average KL loss: 0.901436
Average total loss: 1.103385
tensor(0.0024, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-9.3653e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.203987
Average KL loss: 0.909629
Average total loss: 1.113616
tensor(0.0025, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(3.9185e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.204298
Average KL loss: 0.935745
Average total loss: 1.140043
tensor(0.0025, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(6.8701e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.203001
Average KL loss: 0.939150
Average total loss: 1.142152
tensor(0.0024, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-5.0491e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.212489
Average KL loss: 0.974276
Average total loss: 1.186765
tensor(0.0025, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(1.9017e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.182620
Average KL loss: 0.704685
Average total loss: 0.887304
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.3309e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.179815
Average KL loss: 0.475737
Average total loss: 0.655551
tensor(0.0025, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.0715e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.178698
Average KL loss: 0.408124
Average total loss: 0.586822
tensor(0.0024, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.2460e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.181033
Average KL loss: 0.377571
Average total loss: 0.558603
tensor(0.0024, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(4.0594e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.174222
Average KL loss: 0.361629
Average total loss: 0.535850
tensor(0.0024, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(4.0922e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.169089
Average KL loss: 0.347915
Average total loss: 0.517004
tensor(0.0024, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.0659e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.174790
Average KL loss: 0.340674
Average total loss: 0.515463
tensor(0.0024, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.1979e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.175098
Average KL loss: 0.336793
Average total loss: 0.511892
tensor(0.0024, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.3227e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.174152
Average KL loss: 0.332613
Average total loss: 0.506765
tensor(0.0024, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.4086e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.174237
Average KL loss: 0.330202
Average total loss: 0.504439
tensor(0.0024, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.0558e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.167710
Average KL loss: 0.325225
Average total loss: 0.492935
tensor(0.0024, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(7.5639e-11, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.177598
Average KL loss: 0.324378
Average total loss: 0.501976
tensor(0.0024, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.1704e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.178991
Average KL loss: 0.325331
Average total loss: 0.504322
tensor(0.0024, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.4922e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.177379
Average KL loss: 0.323828
Average total loss: 0.501208
tensor(0.0024, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(4.9190e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.172602
Average KL loss: 0.319956
Average total loss: 0.492558
tensor(0.0024, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-5.7273e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.176916
Average KL loss: 0.319298
Average total loss: 0.496214
tensor(0.0024, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.3648e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.177126
Average KL loss: 0.319852
Average total loss: 0.496978
tensor(0.0024, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(3.1509e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.176263
Average KL loss: 0.317018
Average total loss: 0.493281
tensor(0.0024, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(3.1305e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.175339
Average KL loss: 0.316976
Average total loss: 0.492316
tensor(0.0024, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(5.7652e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.174168
Average KL loss: 0.315227
Average total loss: 0.489395
tensor(0.0024, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.5003e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.173532
Average KL loss: 0.313608
Average total loss: 0.487140
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.3983e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.172649
Average KL loss: 0.313017
Average total loss: 0.485665
tensor(0.0024, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(2.4347e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.173421
Average KL loss: 0.312257
Average total loss: 0.485678
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.3490e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.172001
Average KL loss: 0.311294
Average total loss: 0.483295
tensor(0.0024, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.7257e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.173574
Average KL loss: 0.311132
Average total loss: 0.484706
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(4.1787e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.169844
Average KL loss: 0.309254
Average total loss: 0.479099
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.4318e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.172218
Average KL loss: 0.309355
Average total loss: 0.481572
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(7.4384e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.174870
Average KL loss: 0.308344
Average total loss: 0.483214
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-3.1859e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.170705
Average KL loss: 0.309426
Average total loss: 0.480132
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.5129e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.172760
Average KL loss: 0.307917
Average total loss: 0.480676
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(1.1980e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.178079
Average KL loss: 0.307866
Average total loss: 0.485945
tensor(0.0023, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(1.7583e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.168791
Average KL loss: 0.307383
Average total loss: 0.476175
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.4804e-11, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.176276
Average KL loss: 0.305857
Average total loss: 0.482133
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-6.7146e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.178153
Average KL loss: 0.308022
Average total loss: 0.486176
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.0379e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.182197
Average KL loss: 0.308143
Average total loss: 0.490340
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-6.5087e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.176279
Average KL loss: 0.308490
Average total loss: 0.484769
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.4865e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.174074
Average KL loss: 0.307071
Average total loss: 0.481144
tensor(0.0024, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.7981e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.175010
Average KL loss: 0.305916
Average total loss: 0.480926
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-5.7109e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.167817
Average KL loss: 0.303424
Average total loss: 0.471241
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(1.2377e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.174214
Average KL loss: 0.305220
Average total loss: 0.479434
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(3.5077e-11, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.173388
Average KL loss: 0.303042
Average total loss: 0.476429
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.5449e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.174647
Average KL loss: 0.303872
Average total loss: 0.478519
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(1.3923e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.169800
Average KL loss: 0.301703
Average total loss: 0.471503
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(3.2199e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.177535
Average KL loss: 0.303028
Average total loss: 0.480563
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(3.7662e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.177727
Average KL loss: 0.303362
Average total loss: 0.481088
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.9081e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.178828
Average KL loss: 0.305052
Average total loss: 0.483880
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.1609e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.177248
Average KL loss: 0.303723
Average total loss: 0.480971
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(4.0473e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.172761
Average KL loss: 0.303580
Average total loss: 0.476340
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(1.3405e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.173541
Average KL loss: 0.301510
Average total loss: 0.475050
tensor(0.0023, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(8.6782e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.172377
Average KL loss: 0.302108
Average total loss: 0.474485
tensor(0.0023, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(3.7356e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.171941
Average KL loss: 0.295242
Average total loss: 0.467183
tensor(0.0023, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.6285e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.175754
Average KL loss: 0.286056
Average total loss: 0.461810
tensor(0.0023, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(9.7317e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.177362
Average KL loss: 0.279489
Average total loss: 0.456851
tensor(0.0023, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.9797e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.174707
Average KL loss: 0.274551
Average total loss: 0.449259
tensor(0.0023, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-5.3587e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.165908
Average KL loss: 0.270665
Average total loss: 0.436573
tensor(0.0023, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(4.3376e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.166924
Average KL loss: 0.267376
Average total loss: 0.434300
tensor(0.0023, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(5.3362e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.171943
Average KL loss: 0.264624
Average total loss: 0.436567
tensor(0.0023, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(1.2289e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.172527
Average KL loss: 0.262454
Average total loss: 0.434981
tensor(0.0023, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.3956e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.173481
Average KL loss: 0.260619
Average total loss: 0.434100
tensor(0.0023, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(3.1309e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.168431
Average KL loss: 0.259020
Average total loss: 0.427451
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.0650e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.166299
Average KL loss: 0.257514
Average total loss: 0.423812
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.6953e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.169636
Average KL loss: 0.256183
Average total loss: 0.425819
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.0510e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.175454
Average KL loss: 0.255091
Average total loss: 0.430544
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(3.4486e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.175446
Average KL loss: 0.254115
Average total loss: 0.429561
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(2.7941e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.174606
Average KL loss: 0.253292
Average total loss: 0.427898
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(4.3655e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.170549
Average KL loss: 0.252487
Average total loss: 0.423036
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.4627e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.173759
Average KL loss: 0.251718
Average total loss: 0.425477
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(2.2552e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.167056
Average KL loss: 0.251018
Average total loss: 0.418074
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(4.3191e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.171494
Average KL loss: 0.250383
Average total loss: 0.421876
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.4661e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.168289
Average KL loss: 0.249758
Average total loss: 0.418046
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-7.8226e-11, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.174117
Average KL loss: 0.249251
Average total loss: 0.423368
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-6.5645e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.170679
Average KL loss: 0.248847
Average total loss: 0.419526
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.8893e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.170943
Average KL loss: 0.248351
Average total loss: 0.419294
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-3.6932e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.169695
Average KL loss: 0.247876
Average total loss: 0.417571
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.9186e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.171578
Average KL loss: 0.247512
Average total loss: 0.419090
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-6.8052e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.171274
Average KL loss: 0.247162
Average total loss: 0.418436
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.0475e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.164922
Average KL loss: 0.246799
Average total loss: 0.411721
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.9529e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.170996
Average KL loss: 0.246415
Average total loss: 0.417411
tensor(0.0023, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(2.8536e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.170794
Average KL loss: 0.246138
Average total loss: 0.416932
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.4550e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.168295
Average KL loss: 0.245887
Average total loss: 0.414182
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-4.3472e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.170811
Average KL loss: 0.245654
Average total loss: 0.416465
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.1191e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.171970
Average KL loss: 0.245401
Average total loss: 0.417370
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(4.2422e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.167865
Average KL loss: 0.245174
Average total loss: 0.413039
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(3.2481e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.168243
Average KL loss: 0.244888
Average total loss: 0.413132
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.8506e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.167935
Average KL loss: 0.244718
Average total loss: 0.412653
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(5.3581e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.167772
Average KL loss: 0.244466
Average total loss: 0.412238
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.7985e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.174694
Average KL loss: 0.244211
Average total loss: 0.418905
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.8691e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.172855
Average KL loss: 0.244105
Average total loss: 0.416961
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-4.8352e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.176012
Average KL loss: 0.243981
Average total loss: 0.419993
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(3.1503e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.170510
Average KL loss: 0.243820
Average total loss: 0.414330
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(4.2250e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.176857
Average KL loss: 0.243665
Average total loss: 0.420521
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(5.6640e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.173499
Average KL loss: 0.243526
Average total loss: 0.417025
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(3.7980e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.168764
Average KL loss: 0.243387
Average total loss: 0.412151
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.0822e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.167785
Average KL loss: 0.243250
Average total loss: 0.411035
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(3.1752e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.174403
Average KL loss: 0.243124
Average total loss: 0.417526
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.0025e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.168945
Average KL loss: 0.243006
Average total loss: 0.411951
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(3.0397e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.169996
Average KL loss: 0.242885
Average total loss: 0.412881
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.5168e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.167340
Average KL loss: 0.242765
Average total loss: 0.410105
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-8.9784e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.170423
Average KL loss: 0.242657
Average total loss: 0.413079
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.1333e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.169782
Average KL loss: 0.242553
Average total loss: 0.412334
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.1139e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.168655
Average KL loss: 0.242450
Average total loss: 0.411105
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.1059e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.175583
Average KL loss: 0.242354
Average total loss: 0.417938
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(7.5679e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.166643
Average KL loss: 0.242263
Average total loss: 0.408906
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.7642e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.174719
Average KL loss: 0.242168
Average total loss: 0.416888
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(5.5229e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.172029
Average KL loss: 0.242078
Average total loss: 0.414107
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.7378e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.165949
Average KL loss: 0.241995
Average total loss: 0.407944
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.0370e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.174828
Average KL loss: 0.241908
Average total loss: 0.416735
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(4.5309e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.169996
Average KL loss: 0.241828
Average total loss: 0.411824
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.6331e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.169926
Average KL loss: 0.241745
Average total loss: 0.411672
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(3.6579e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.169238
Average KL loss: 0.241664
Average total loss: 0.410903
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.8233e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.171935
Average KL loss: 0.241591
Average total loss: 0.413525
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-4.8670e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.172361
Average KL loss: 0.241522
Average total loss: 0.413883
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(3.6713e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.165209
Average KL loss: 0.241448
Average total loss: 0.406657
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-7.3052e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.174300
Average KL loss: 0.241375
Average total loss: 0.415675
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.8077e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.169703
Average KL loss: 0.241308
Average total loss: 0.411011
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.2867e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.173988
Average KL loss: 0.241237
Average total loss: 0.415225
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.6224e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.167992
Average KL loss: 0.241169
Average total loss: 0.409161
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.5368e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.174064
Average KL loss: 0.241103
Average total loss: 0.415168
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.9650e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.167797
Average KL loss: 0.241039
Average total loss: 0.408836
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(3.4776e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.167849
Average KL loss: 0.240972
Average total loss: 0.408821
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.0650e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.172620
Average KL loss: 0.240912
Average total loss: 0.413532
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.5709e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.169246
Average KL loss: 0.240861
Average total loss: 0.410107
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.1238e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.177279
Average KL loss: 0.240804
Average total loss: 0.418083
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(6.7650e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.172298
Average KL loss: 0.240747
Average total loss: 0.413045
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(3.6301e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.171546
Average KL loss: 0.240717
Average total loss: 0.412262
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.8918e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.170852
Average KL loss: 0.240710
Average total loss: 0.411562
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.0193e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.170069
Average KL loss: 0.240702
Average total loss: 0.410770
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.1085e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.163917
Average KL loss: 0.240694
Average total loss: 0.404612
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.5289e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.167787
Average KL loss: 0.240687
Average total loss: 0.408474
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(9.7332e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.172959
Average KL loss: 0.240680
Average total loss: 0.413639
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.7882e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.173447
Average KL loss: 0.240673
Average total loss: 0.414119
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-8.0470e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.174135
Average KL loss: 0.240666
Average total loss: 0.414801
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.9465e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.173709
Average KL loss: 0.240659
Average total loss: 0.414368
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.9032e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.175898
Average KL loss: 0.240653
Average total loss: 0.416551
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(5.7500e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.166755
Average KL loss: 0.240646
Average total loss: 0.407400
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(6.9691e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.166879
Average KL loss: 0.240638
Average total loss: 0.407517
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(4.6760e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.167779
Average KL loss: 0.240631
Average total loss: 0.408410
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(3.3930e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.167190
Average KL loss: 0.240624
Average total loss: 0.407814
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.4425e-09, device='cuda:0')
 Percentile value: 0.020482031628489494
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =     958 /    1728             ( 55.44%) | total_pruned =     770 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    8981 /   36864             ( 24.36%) | total_pruned =   27883 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   10175 /   36864             ( 27.60%) | total_pruned =   26689 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    9371 /   36864             ( 25.42%) | total_pruned =   27493 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9380 /   36864             ( 25.44%) | total_pruned =   27484 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   17980 /   73728             ( 24.39%) | total_pruned =   55748 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   33187 /  147456             ( 22.51%) | total_pruned =  114269 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3621 /    8192             ( 44.20%) | total_pruned =    4571 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   25788 /  147456             ( 17.49%) | total_pruned =  121668 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   26572 /  147456             ( 18.02%) | total_pruned =  120884 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   63800 /  294912             ( 21.63%) | total_pruned =  231112 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  114227 /  589824             ( 19.37%) | total_pruned =  475597 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   11243 /   32768             ( 34.31%) | total_pruned =   21525 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   65524 /  589824             ( 11.11%) | total_pruned =  524300 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   64884 /  589824             ( 11.00%) | total_pruned =  524940 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  185336 / 1179648             ( 15.71%) | total_pruned =  994312 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     393 /     512             ( 76.76%) | total_pruned =     119 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  191946 / 2359296             (  8.14%) | total_pruned = 2167350 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     354 /     512             ( 69.14%) | total_pruned =     158 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   26482 /  131072             ( 20.20%) | total_pruned =  104590 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     452 /     512             ( 88.28%) | total_pruned =      60 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     351 /     512             ( 68.55%) | total_pruned =     161 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   82468 / 2359296             (  3.50%) | total_pruned = 2276828 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     381 /     512             ( 74.41%) | total_pruned =     131 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     220 /     512             ( 42.97%) | total_pruned =     292 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   43373 / 2359296             (  1.84%) | total_pruned = 2315923 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
linear.weight        | nonzeros =    3396 /    5120             ( 66.33%) | total_pruned =    1724 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 31/200 Loss: 0.000016 Accuracy: 86.71 100.00 % Best test Accuracy: 86.93%
tensor(0.0023, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.3012e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.495895
Average KL loss: 0.856858
Average total loss: 1.352753
tensor(0.0007, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.0153e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.468378
Average KL loss: 0.966399
Average total loss: 1.434777
tensor(0.0025, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.2992e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.424279
Average KL loss: 0.929307
Average total loss: 1.353585
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-5.5632e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.402713
Average KL loss: 0.893143
Average total loss: 1.295856
tensor(0.0028, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.8269e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.394357
Average KL loss: 0.918711
Average total loss: 1.313067
tensor(0.0028, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.0063e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.383168
Average KL loss: 0.933879
Average total loss: 1.317048
tensor(0.0029, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(3.6007e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.365501
Average KL loss: 0.932811
Average total loss: 1.298312
tensor(0.0029, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.1131e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.353528
Average KL loss: 0.903878
Average total loss: 1.257406
tensor(0.0029, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-6.3098e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.356555
Average KL loss: 0.946930
Average total loss: 1.303485
tensor(0.0029, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-3.1145e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.352079
Average KL loss: 0.914850
Average total loss: 1.266929
tensor(0.0030, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(3.3483e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.335826
Average KL loss: 0.928948
Average total loss: 1.264775
tensor(0.0030, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.1045e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.333452
Average KL loss: 0.900492
Average total loss: 1.233944
tensor(0.0030, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-2.7432e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.330588
Average KL loss: 0.911349
Average total loss: 1.241937
tensor(0.0030, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-4.2766e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.322359
Average KL loss: 0.906784
Average total loss: 1.229143
tensor(0.0031, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(5.9070e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.327208
Average KL loss: 0.928297
Average total loss: 1.255505
tensor(0.0031, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(6.2161e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.325401
Average KL loss: 0.931892
Average total loss: 1.257292
tensor(-0.0025, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.4848e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.323384
Average KL loss: 0.933905
Average total loss: 1.257289
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(7.4477e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.319703
Average KL loss: 0.925189
Average total loss: 1.244892
tensor(0.0031, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-5.4731e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.316546
Average KL loss: 0.926499
Average total loss: 1.243045
tensor(0.0031, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.0596e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.318064
Average KL loss: 0.925188
Average total loss: 1.243253
tensor(0.0043, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.4307e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.320948
Average KL loss: 0.946869
Average total loss: 1.267817
tensor(0.0038, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.0054e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.312402
Average KL loss: 0.942280
Average total loss: 1.254683
tensor(0.0032, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.2153e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.307375
Average KL loss: 0.936111
Average total loss: 1.243486
tensor(0.0032, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.9728e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.308883
Average KL loss: 0.933137
Average total loss: 1.242021
tensor(0.0025, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-2.0845e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.307294
Average KL loss: 0.956052
Average total loss: 1.263346
tensor(0.0005, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-7.5060e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.293231
Average KL loss: 0.831830
Average total loss: 1.125061
tensor(0.0031, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-9.1635e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.281944
Average KL loss: 0.649004
Average total loss: 0.930948
tensor(0.0032, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(9.6741e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.275696
Average KL loss: 0.557958
Average total loss: 0.833654
tensor(0.0031, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.1976e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.268266
Average KL loss: 0.505378
Average total loss: 0.773644
tensor(0.0031, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(6.8444e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.277401
Average KL loss: 0.471932
Average total loss: 0.749333
tensor(0.0031, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(3.7663e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.275159
Average KL loss: 0.451466
Average total loss: 0.726625
tensor(0.0031, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(6.7084e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.273687
Average KL loss: 0.436348
Average total loss: 0.710035
tensor(0.0031, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.1241e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.275120
Average KL loss: 0.424921
Average total loss: 0.700041
tensor(0.0031, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.1516e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.273958
Average KL loss: 0.416185
Average total loss: 0.690144
tensor(0.0031, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(4.0775e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.285213
Average KL loss: 0.410362
Average total loss: 0.695575
tensor(0.0031, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.5473e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.283226
Average KL loss: 0.406204
Average total loss: 0.689430
tensor(0.0031, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-3.4351e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.273251
Average KL loss: 0.402246
Average total loss: 0.675496
tensor(0.0031, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.1042e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.268962
Average KL loss: 0.396791
Average total loss: 0.665753
tensor(0.0031, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.5029e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.279473
Average KL loss: 0.392770
Average total loss: 0.672243
tensor(0.0031, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.1494e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.272255
Average KL loss: 0.390646
Average total loss: 0.662901
tensor(0.0030, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.9929e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.274310
Average KL loss: 0.388193
Average total loss: 0.662502
tensor(0.0030, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(4.1347e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.277754
Average KL loss: 0.386239
Average total loss: 0.663992
tensor(0.0030, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.0781e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.277243
Average KL loss: 0.384950
Average total loss: 0.662193
tensor(0.0030, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.2480e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.269186
Average KL loss: 0.382633
Average total loss: 0.651819
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(9.7638e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.272093
Average KL loss: 0.380000
Average total loss: 0.652092
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.6475e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.283190
Average KL loss: 0.380023
Average total loss: 0.663213
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(7.1829e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.275000
Average KL loss: 0.380234
Average total loss: 0.655233
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.3914e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.265044
Average KL loss: 0.377753
Average total loss: 0.642796
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.9517e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.275546
Average KL loss: 0.375868
Average total loss: 0.651414
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.5362e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.283094
Average KL loss: 0.376902
Average total loss: 0.659996
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.8451e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.274260
Average KL loss: 0.377393
Average total loss: 0.651653
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.3167e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.268034
Average KL loss: 0.375095
Average total loss: 0.643129
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.1064e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.268754
Average KL loss: 0.373195
Average total loss: 0.641949
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.4084e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.277751
Average KL loss: 0.371819
Average total loss: 0.649570
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.4832e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.277271
Average KL loss: 0.372250
Average total loss: 0.649521
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.4155e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.271458
Average KL loss: 0.371466
Average total loss: 0.642924
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.3156e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.283371
Average KL loss: 0.370435
Average total loss: 0.653806
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.7763e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.277530
Average KL loss: 0.371220
Average total loss: 0.648750
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.3168e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.272674
Average KL loss: 0.370808
Average total loss: 0.643482
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.1029e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.270158
Average KL loss: 0.369128
Average total loss: 0.639286
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.9942e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.274803
Average KL loss: 0.367874
Average total loss: 0.642677
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.4024e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.274857
Average KL loss: 0.366259
Average total loss: 0.641116
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.9773e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.275548
Average KL loss: 0.366530
Average total loss: 0.642078
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.1573e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.272116
Average KL loss: 0.366497
Average total loss: 0.638613
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.2403e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.268325
Average KL loss: 0.364991
Average total loss: 0.633316
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.2757e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.281144
Average KL loss: 0.365106
Average total loss: 0.646251
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(7.2743e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.275941
Average KL loss: 0.365080
Average total loss: 0.641022
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(7.3509e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.277307
Average KL loss: 0.364587
Average total loss: 0.641894
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.6886e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.282180
Average KL loss: 0.365426
Average total loss: 0.647606
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(9.9272e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.276054
Average KL loss: 0.365531
Average total loss: 0.641585
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.1005e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.283537
Average KL loss: 0.364603
Average total loss: 0.648140
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.6042e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.278207
Average KL loss: 0.365469
Average total loss: 0.643676
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.9342e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.276802
Average KL loss: 0.364898
Average total loss: 0.641699
tensor(0.0030, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.4456e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.278432
Average KL loss: 0.363963
Average total loss: 0.642395
tensor(0.0030, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.5524e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.277556
Average KL loss: 0.363169
Average total loss: 0.640724
tensor(0.0030, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.8025e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.278220
Average KL loss: 0.362858
Average total loss: 0.641077
tensor(0.0030, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.6143e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.270502
Average KL loss: 0.360550
Average total loss: 0.631052
tensor(0.0030, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.2116e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.278109
Average KL loss: 0.356403
Average total loss: 0.634513
tensor(0.0030, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(9.1255e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.273321
Average KL loss: 0.352775
Average total loss: 0.626095
tensor(0.0030, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.9302e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.269390
Average KL loss: 0.349604
Average total loss: 0.618994
tensor(0.0030, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(5.5075e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.273121
Average KL loss: 0.346800
Average total loss: 0.619921
tensor(0.0030, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.3717e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.271057
Average KL loss: 0.344343
Average total loss: 0.615400
tensor(0.0030, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.6734e-11, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.271783
Average KL loss: 0.342075
Average total loss: 0.613858
tensor(0.0030, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(5.6093e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.274489
Average KL loss: 0.339982
Average total loss: 0.614471
tensor(0.0030, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2296e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.275877
Average KL loss: 0.338090
Average total loss: 0.613966
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.8393e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.272353
Average KL loss: 0.336461
Average total loss: 0.608814
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.6570e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.268560
Average KL loss: 0.334805
Average total loss: 0.603365
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(7.1924e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.266806
Average KL loss: 0.333267
Average total loss: 0.600073
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(7.5841e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.271617
Average KL loss: 0.331891
Average total loss: 0.603508
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.2985e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.269222
Average KL loss: 0.330628
Average total loss: 0.599850
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.0047e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.275678
Average KL loss: 0.329404
Average total loss: 0.605082
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.2833e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.271583
Average KL loss: 0.328319
Average total loss: 0.599902
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(7.5860e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.266955
Average KL loss: 0.327254
Average total loss: 0.594209
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.4710e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.265922
Average KL loss: 0.326278
Average total loss: 0.592200
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.6905e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.273504
Average KL loss: 0.325312
Average total loss: 0.598816
tensor(0.0030, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(9.4674e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.272123
Average KL loss: 0.324417
Average total loss: 0.596540
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.6692e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.271013
Average KL loss: 0.323630
Average total loss: 0.594642
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.6883e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.275692
Average KL loss: 0.322853
Average total loss: 0.598545
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(6.6519e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.272596
Average KL loss: 0.322116
Average total loss: 0.594713
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.4002e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.267287
Average KL loss: 0.321384
Average total loss: 0.588670
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.4900e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.270727
Average KL loss: 0.320692
Average total loss: 0.591419
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.6255e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.276053
Average KL loss: 0.320120
Average total loss: 0.596173
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.1134e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.270282
Average KL loss: 0.319607
Average total loss: 0.589888
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.5659e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.273166
Average KL loss: 0.318983
Average total loss: 0.592149
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.4438e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.265761
Average KL loss: 0.318426
Average total loss: 0.584188
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.3609e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.273454
Average KL loss: 0.317883
Average total loss: 0.591336
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.4012e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.270166
Average KL loss: 0.317394
Average total loss: 0.587560
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.3746e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.272962
Average KL loss: 0.316933
Average total loss: 0.589895
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.5930e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.270819
Average KL loss: 0.316510
Average total loss: 0.587329
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.7825e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.274361
Average KL loss: 0.316068
Average total loss: 0.590429
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(5.7057e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.265401
Average KL loss: 0.315653
Average total loss: 0.581054
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(9.5531e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.270971
Average KL loss: 0.315259
Average total loss: 0.586230
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.8902e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.276049
Average KL loss: 0.314927
Average total loss: 0.590976
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.6577e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.272462
Average KL loss: 0.314579
Average total loss: 0.587041
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.2404e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.269346
Average KL loss: 0.314178
Average total loss: 0.583524
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.2543e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.273923
Average KL loss: 0.313889
Average total loss: 0.587812
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.2134e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.277020
Average KL loss: 0.313621
Average total loss: 0.590641
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.5638e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.272036
Average KL loss: 0.313357
Average total loss: 0.585393
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.1359e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.272005
Average KL loss: 0.313119
Average total loss: 0.585124
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(3.7871e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.272586
Average KL loss: 0.312844
Average total loss: 0.585430
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.8116e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.275605
Average KL loss: 0.312599
Average total loss: 0.588205
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.6321e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.280301
Average KL loss: 0.312367
Average total loss: 0.592668
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.3406e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.275727
Average KL loss: 0.312207
Average total loss: 0.587935
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.0456e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.270779
Average KL loss: 0.312135
Average total loss: 0.582914
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.1366e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.272116
Average KL loss: 0.312061
Average total loss: 0.584177
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0133e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.276440
Average KL loss: 0.311991
Average total loss: 0.588431
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(6.3079e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.278808
Average KL loss: 0.311927
Average total loss: 0.590735
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.0592e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.276430
Average KL loss: 0.311862
Average total loss: 0.588291
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.9454e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.267384
Average KL loss: 0.311788
Average total loss: 0.579172
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.2146e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.280592
Average KL loss: 0.311714
Average total loss: 0.592306
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.2077e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.272620
Average KL loss: 0.311651
Average total loss: 0.584271
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.3591e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.273579
Average KL loss: 0.311589
Average total loss: 0.585168
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7545e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.268068
Average KL loss: 0.311524
Average total loss: 0.579592
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.8263e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.276162
Average KL loss: 0.311457
Average total loss: 0.587619
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.7230e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.263655
Average KL loss: 0.311390
Average total loss: 0.575044
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.4645e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.270350
Average KL loss: 0.311318
Average total loss: 0.581668
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.0264e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.269601
Average KL loss: 0.311253
Average total loss: 0.580854
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(9.6792e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.269948
Average KL loss: 0.311193
Average total loss: 0.581141
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.9712e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.275385
Average KL loss: 0.311132
Average total loss: 0.586517
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.9634e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.274050
Average KL loss: 0.311077
Average total loss: 0.585127
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.2231e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.274231
Average KL loss: 0.311020
Average total loss: 0.585251
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.3774e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.268688
Average KL loss: 0.310959
Average total loss: 0.579647
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.9134e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.268876
Average KL loss: 0.310895
Average total loss: 0.579772
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.4661e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.268794
Average KL loss: 0.310835
Average total loss: 0.579629
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.4803e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.269088
Average KL loss: 0.310774
Average total loss: 0.579862
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.1511e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.276042
Average KL loss: 0.310717
Average total loss: 0.586759
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.7975e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.264679
Average KL loss: 0.310687
Average total loss: 0.575366
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.5697e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.277297
Average KL loss: 0.310680
Average total loss: 0.587977
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.8198e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.277788
Average KL loss: 0.310674
Average total loss: 0.588462
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.6943e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.273624
Average KL loss: 0.310668
Average total loss: 0.584292
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.7241e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.281112
Average KL loss: 0.310662
Average total loss: 0.591774
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.4602e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.273550
Average KL loss: 0.310656
Average total loss: 0.584206
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.4223e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.268749
Average KL loss: 0.310650
Average total loss: 0.579399
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.2596e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.275186
Average KL loss: 0.310644
Average total loss: 0.585830
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.8333e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.272231
Average KL loss: 0.310638
Average total loss: 0.582869
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.5845e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.266940
Average KL loss: 0.310632
Average total loss: 0.577573
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.5604e-10, device='cuda:0')
 Percentile value: 0.08171366453170775
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =     795 /    1728             ( 46.01%) | total_pruned =     933 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    3938 /   36864             ( 10.68%) | total_pruned =   32926 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4922 /   36864             ( 13.35%) | total_pruned =   31942 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4428 /   36864             ( 12.01%) | total_pruned =   32436 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4446 /   36864             ( 12.06%) | total_pruned =   32418 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8163 /   73728             ( 11.07%) | total_pruned =   65565 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   13846 /  147456             (  9.39%) | total_pruned =  133610 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2460 /    8192             ( 30.03%) | total_pruned =    5732 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8611 /  147456             (  5.84%) | total_pruned =  138845 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    9082 /  147456             (  6.16%) | total_pruned =  138374 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   24807 /  294912             (  8.41%) | total_pruned =  270105 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     174 /     256             ( 67.97%) | total_pruned =      82 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   38820 /  589824             (  6.58%) | total_pruned =  551004 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6335 /   32768             ( 19.33%) | total_pruned =   26433 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   17141 /  589824             (  2.91%) | total_pruned =  572683 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   17175 /  589824             (  2.91%) | total_pruned =  572649 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   53283 / 1179648             (  4.52%) | total_pruned = 1126365 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     307 /     512             ( 59.96%) | total_pruned =     205 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   40882 / 2359296             (  1.73%) | total_pruned = 2318414 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     465 /     512             ( 90.82%) | total_pruned =      47 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     302 /     512             ( 58.98%) | total_pruned =     210 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    8743 /  131072             (  6.67%) | total_pruned =  122329 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     298 /     512             ( 58.20%) | total_pruned =     214 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   17103 / 2359296             (  0.72%) | total_pruned = 2342193 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     345 /     512             ( 67.38%) | total_pruned =     167 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     116 /     512             ( 22.66%) | total_pruned =     396 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    8083 / 2359296             (  0.34%) | total_pruned = 2351213 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     445 /     512             ( 86.91%) | total_pruned =      67 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
linear.weight        | nonzeros =    2248 /    5120             ( 43.91%) | total_pruned =    2872 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 30/200 Loss: 0.004005 Accuracy: 86.23 100.00 % Best test Accuracy: 86.52%
tensor(0.0030, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.5042e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.815520
Average KL loss: 0.715029
Average total loss: 1.530549
tensor(0.0004, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-9.0577e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.740060
Average KL loss: 0.913346
Average total loss: 1.653406
tensor(0.0031, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.2785e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.640855
Average KL loss: 0.936075
Average total loss: 1.576930
tensor(0.0033, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.4428e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.629726
Average KL loss: 0.923327
Average total loss: 1.553053
tensor(0.0033, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-5.9731e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.582659
Average KL loss: 0.911690
Average total loss: 1.494349
tensor(0.0034, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.6905e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.580119
Average KL loss: 0.894778
Average total loss: 1.474897
tensor(0.0034, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(8.9124e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.558827
Average KL loss: 0.893598
Average total loss: 1.452425
tensor(0.0034, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.5416e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.557816
Average KL loss: 0.893348
Average total loss: 1.451164
tensor(0.0034, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.5781e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.534996
Average KL loss: 0.889351
Average total loss: 1.424346
tensor(0.0035, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.1118e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.551494
Average KL loss: 0.899246
Average total loss: 1.450740
tensor(0.0035, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-5.6423e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.538277
Average KL loss: 0.915818
Average total loss: 1.454095
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(6.5500e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.525163
Average KL loss: 0.894907
Average total loss: 1.420070
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-7.3836e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.534132
Average KL loss: 0.901730
Average total loss: 1.435862
tensor(0.0035, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.2640e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.507795
Average KL loss: 0.897993
Average total loss: 1.405788
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.1238e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.514494
Average KL loss: 0.878591
Average total loss: 1.393085
tensor(0.0035, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.1342e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.511862
Average KL loss: 0.906818
Average total loss: 1.418680
tensor(-0.0042, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.8870e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.507374
Average KL loss: 0.911755
Average total loss: 1.419128
tensor(0.0042, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.0039e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.508071
Average KL loss: 0.923542
Average total loss: 1.431613
tensor(0.0035, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-8.7168e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.495385
Average KL loss: 0.916532
Average total loss: 1.411916
tensor(0.0036, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.4388e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.492850
Average KL loss: 0.901745
Average total loss: 1.394594
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.0971e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.502912
Average KL loss: 0.902389
Average total loss: 1.405302
tensor(0.0049, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.6599e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.487188
Average KL loss: 0.913457
Average total loss: 1.400645
tensor(0.0037, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.1143e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.485886
Average KL loss: 0.901718
Average total loss: 1.387604
tensor(0.0036, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.5801e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.490713
Average KL loss: 0.904660
Average total loss: 1.395372
tensor(0.0034, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.2195e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.495908
Average KL loss: 0.923764
Average total loss: 1.419672
tensor(-0.0007, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.2444e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.490068
Average KL loss: 0.948340
Average total loss: 1.438407
tensor(0.0041, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(1.0843e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.485314
Average KL loss: 0.927266
Average total loss: 1.412580
tensor(0.0037, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(6.2972e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.476793
Average KL loss: 0.931974
Average total loss: 1.408767
tensor(0.0041, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.3054e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.477098
Average KL loss: 0.920025
Average total loss: 1.397124
tensor(0.0025, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-2.9891e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.467267
Average KL loss: 0.912990
Average total loss: 1.380258
tensor(0.0039, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(9.4127e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.473821
Average KL loss: 0.910583
Average total loss: 1.384404
tensor(0.0038, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-3.5605e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.475341
Average KL loss: 0.910577
Average total loss: 1.385918
tensor(0.0038, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.3181e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.483080
Average KL loss: 0.923011
Average total loss: 1.406090
tensor(0.0039, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(5.6811e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.467364
Average KL loss: 0.920759
Average total loss: 1.388123
tensor(0.0037, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-7.5539e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.474952
Average KL loss: 0.916721
Average total loss: 1.391672
tensor(0.0004, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-9.0629e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.477316
Average KL loss: 0.921344
Average total loss: 1.398659
tensor(0.0042, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(1.3744e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.468550
Average KL loss: 0.921028
Average total loss: 1.389577
tensor(0.0040, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(9.8315e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.473053
Average KL loss: 0.925974
Average total loss: 1.399028
tensor(0.0038, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(2.2056e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.468749
Average KL loss: 0.934679
Average total loss: 1.403427
tensor(0.0034, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-6.6596e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.457925
Average KL loss: 0.922477
Average total loss: 1.380402
tensor(0.0033, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-9.7972e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.469078
Average KL loss: 0.909060
Average total loss: 1.378138
tensor(0.0042, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-1.3523e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.470295
Average KL loss: 0.931708
Average total loss: 1.402003
tensor(0.0039, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-3.4352e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.473172
Average KL loss: 0.928128
Average total loss: 1.401299
tensor(0.0039, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(6.7983e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.463483
Average KL loss: 0.929667
Average total loss: 1.393150
tensor(0.0121, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(2.1013e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.454794
Average KL loss: 0.920786
Average total loss: 1.375581
tensor(0.0047, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.5265e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.459299
Average KL loss: 0.917598
Average total loss: 1.376898
tensor(0.0031, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.6794e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.463529
Average KL loss: 0.923476
Average total loss: 1.387005
tensor(0.0040, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-8.3551e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.460264
Average KL loss: 0.916540
Average total loss: 1.376803
tensor(0.0044, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(8.7130e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.466546
Average KL loss: 0.928922
Average total loss: 1.395467
tensor(0.0042, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.0596e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.463671
Average KL loss: 0.931474
Average total loss: 1.395145
tensor(0.0038, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-5.7413e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.456463
Average KL loss: 0.920338
Average total loss: 1.376801
tensor(0.0038, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(5.5623e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.459631
Average KL loss: 0.918575
Average total loss: 1.378206
tensor(0.0038, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-4.5210e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.466758
Average KL loss: 0.940892
Average total loss: 1.407650
tensor(0.0061, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(4.8610e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.460661
Average KL loss: 0.935744
Average total loss: 1.396405
tensor(0.0040, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(7.0067e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.460398
Average KL loss: 0.929360
Average total loss: 1.389758
tensor(0.0039, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(8.5312e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.454302
Average KL loss: 0.925970
Average total loss: 1.380272
tensor(0.0039, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(4.7732e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.434691
Average KL loss: 0.890513
Average total loss: 1.325204
tensor(0.0039, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(8.4268e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.431579
Average KL loss: 0.807615
Average total loss: 1.239194
tensor(0.0039, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(1.6572e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.419246
Average KL loss: 0.746706
Average total loss: 1.165951
tensor(0.0039, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(6.2011e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.427076
Average KL loss: 0.700534
Average total loss: 1.127610
tensor(0.0039, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(6.4083e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.427252
Average KL loss: 0.664625
Average total loss: 1.091876
tensor(0.0039, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(2.6954e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.424527
Average KL loss: 0.635714
Average total loss: 1.060241
tensor(0.0038, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(1.7112e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.427148
Average KL loss: 0.612624
Average total loss: 1.039771
tensor(0.0038, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(6.1563e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.432948
Average KL loss: 0.594039
Average total loss: 1.026988
tensor(0.0038, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(1.3375e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.436415
Average KL loss: 0.579159
Average total loss: 1.015574
tensor(0.0038, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(4.1236e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.428740
Average KL loss: 0.565647
Average total loss: 0.994387
tensor(0.0038, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-4.5078e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.425552
Average KL loss: 0.554470
Average total loss: 0.980022
tensor(0.0038, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(6.1225e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.432467
Average KL loss: 0.544098
Average total loss: 0.976566
tensor(0.0038, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-8.5858e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.434481
Average KL loss: 0.536104
Average total loss: 0.970585
tensor(0.0038, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(3.4114e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.423048
Average KL loss: 0.528442
Average total loss: 0.951490
tensor(0.0038, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.2006e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.429348
Average KL loss: 0.521732
Average total loss: 0.951080
tensor(0.0038, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.7292e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.424103
Average KL loss: 0.516053
Average total loss: 0.940155
tensor(0.0038, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-7.2745e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.432818
Average KL loss: 0.511113
Average total loss: 0.943931
tensor(0.0038, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.8580e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.440887
Average KL loss: 0.507204
Average total loss: 0.948091
tensor(0.0038, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(4.2790e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.432697
Average KL loss: 0.503498
Average total loss: 0.936195
tensor(0.0038, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(1.1278e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.432286
Average KL loss: 0.499523
Average total loss: 0.931809
tensor(0.0038, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.0440e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.436422
Average KL loss: 0.495814
Average total loss: 0.932235
tensor(0.0037, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(2.8467e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.437743
Average KL loss: 0.492843
Average total loss: 0.930585
tensor(0.0037, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(6.0604e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.437700
Average KL loss: 0.490109
Average total loss: 0.927809
tensor(0.0037, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.1589e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.426504
Average KL loss: 0.488115
Average total loss: 0.914619
tensor(0.0037, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(4.5024e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.430983
Average KL loss: 0.485324
Average total loss: 0.916308
tensor(0.0037, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.6691e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.435391
Average KL loss: 0.483279
Average total loss: 0.918670
tensor(0.0037, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.5873e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.441382
Average KL loss: 0.481221
Average total loss: 0.922603
tensor(0.0037, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.5376e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.429327
Average KL loss: 0.479778
Average total loss: 0.909105
tensor(0.0037, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.0828e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.440360
Average KL loss: 0.478283
Average total loss: 0.918642
tensor(0.0037, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(2.0245e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.433283
Average KL loss: 0.476602
Average total loss: 0.909884
tensor(0.0037, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-6.6005e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.436171
Average KL loss: 0.474846
Average total loss: 0.911018
tensor(0.0037, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.9431e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.434947
Average KL loss: 0.472917
Average total loss: 0.907864
tensor(0.0037, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.4947e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.435521
Average KL loss: 0.471715
Average total loss: 0.907236
tensor(0.0037, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(4.7876e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.442396
Average KL loss: 0.470655
Average total loss: 0.913050
tensor(0.0037, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(6.5016e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.442806
Average KL loss: 0.469707
Average total loss: 0.912513
tensor(0.0037, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-3.4526e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.436595
Average KL loss: 0.469088
Average total loss: 0.905683
tensor(0.0037, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.0881e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.439096
Average KL loss: 0.468228
Average total loss: 0.907324
tensor(0.0037, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(4.2602e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.429742
Average KL loss: 0.466734
Average total loss: 0.896475
tensor(0.0037, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(3.4165e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.432525
Average KL loss: 0.465132
Average total loss: 0.897657
tensor(0.0037, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(5.8839e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.432170
Average KL loss: 0.463794
Average total loss: 0.895964
tensor(0.0037, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.6032e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.437338
Average KL loss: 0.463138
Average total loss: 0.900477
tensor(0.0037, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.9191e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.447894
Average KL loss: 0.463154
Average total loss: 0.911049
tensor(0.0037, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.2120e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.434479
Average KL loss: 0.462735
Average total loss: 0.897213
tensor(0.0037, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-4.8964e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.441611
Average KL loss: 0.461325
Average total loss: 0.902935
tensor(0.0037, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.1250e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.439210
Average KL loss: 0.461286
Average total loss: 0.900496
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.0106e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.443460
Average KL loss: 0.461338
Average total loss: 0.904797
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.6658e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.437326
Average KL loss: 0.460742
Average total loss: 0.898068
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(5.0189e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.444167
Average KL loss: 0.460294
Average total loss: 0.904461
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.1868e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.442343
Average KL loss: 0.459535
Average total loss: 0.901878
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.7744e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.432652
Average KL loss: 0.458832
Average total loss: 0.891484
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.7378e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.434292
Average KL loss: 0.457669
Average total loss: 0.891961
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.9254e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.435505
Average KL loss: 0.456626
Average total loss: 0.892132
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.3316e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.442545
Average KL loss: 0.456461
Average total loss: 0.899007
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-4.1429e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.441323
Average KL loss: 0.456689
Average total loss: 0.898012
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(4.2996e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.439851
Average KL loss: 0.455861
Average total loss: 0.895712
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.2643e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.437196
Average KL loss: 0.455729
Average total loss: 0.892925
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(8.5967e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.438828
Average KL loss: 0.455032
Average total loss: 0.893860
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.6339e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.435878
Average KL loss: 0.454789
Average total loss: 0.890668
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(2.6952e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.433829
Average KL loss: 0.453649
Average total loss: 0.887478
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(2.5165e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.446741
Average KL loss: 0.453801
Average total loss: 0.900541
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(4.6450e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.443382
Average KL loss: 0.453761
Average total loss: 0.897143
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-4.7215e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.440243
Average KL loss: 0.453570
Average total loss: 0.893813
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.9752e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.438583
Average KL loss: 0.453079
Average total loss: 0.891662
tensor(0.0037, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(8.2908e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.444302
Average KL loss: 0.452022
Average total loss: 0.896324
tensor(0.0037, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(4.5453e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.444111
Average KL loss: 0.451474
Average total loss: 0.895584
tensor(0.0037, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(2.9527e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.435083
Average KL loss: 0.451119
Average total loss: 0.886202
tensor(0.0037, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(6.0120e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.427103
Average KL loss: 0.450130
Average total loss: 0.877233
tensor(0.0037, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(1.8206e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.454527
Average KL loss: 0.449431
Average total loss: 0.903958
tensor(0.0037, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(2.0061e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.436063
Average KL loss: 0.449938
Average total loss: 0.886002
tensor(0.0037, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(3.7255e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.445849
Average KL loss: 0.449660
Average total loss: 0.895509
tensor(0.0037, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.3339e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.436062
Average KL loss: 0.449541
Average total loss: 0.885603
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.4194e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.437949
Average KL loss: 0.448231
Average total loss: 0.886180
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-5.8611e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.446648
Average KL loss: 0.447924
Average total loss: 0.894572
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.6436e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.443361
Average KL loss: 0.447849
Average total loss: 0.891210
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.2315e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.441602
Average KL loss: 0.447875
Average total loss: 0.889477
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-5.1037e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.443565
Average KL loss: 0.447430
Average total loss: 0.890994
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(7.7103e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.440508
Average KL loss: 0.446932
Average total loss: 0.887440
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(7.5504e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.445356
Average KL loss: 0.446601
Average total loss: 0.891958
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.6536e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.442596
Average KL loss: 0.445888
Average total loss: 0.888484
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.3113e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.439105
Average KL loss: 0.444530
Average total loss: 0.883635
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(4.5680e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.435653
Average KL loss: 0.443171
Average total loss: 0.878824
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(5.7293e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.430938
Average KL loss: 0.441927
Average total loss: 0.872865
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(5.4457e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.445545
Average KL loss: 0.440716
Average total loss: 0.886261
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(6.2849e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.432816
Average KL loss: 0.439563
Average total loss: 0.872378
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-6.7679e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.442302
Average KL loss: 0.438481
Average total loss: 0.880782
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(7.2612e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.443164
Average KL loss: 0.437450
Average total loss: 0.880614
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-5.5480e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.430417
Average KL loss: 0.436478
Average total loss: 0.866895
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-4.8653e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.447800
Average KL loss: 0.435517
Average total loss: 0.883317
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(3.6061e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.436445
Average KL loss: 0.434593
Average total loss: 0.871038
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(8.7111e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.432428
Average KL loss: 0.433696
Average total loss: 0.866124
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(5.3324e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.440274
Average KL loss: 0.432864
Average total loss: 0.873138
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-3.3824e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.432456
Average KL loss: 0.432112
Average total loss: 0.864567
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.2570e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.438893
Average KL loss: 0.431298
Average total loss: 0.870191
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-3.4229e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.437551
Average KL loss: 0.430521
Average total loss: 0.868072
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.8641e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.432555
Average KL loss: 0.429708
Average total loss: 0.862262
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-3.8998e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.436948
Average KL loss: 0.428935
Average total loss: 0.865883
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-8.6304e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.430818
Average KL loss: 0.428263
Average total loss: 0.859081
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(4.1390e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.442299
Average KL loss: 0.427560
Average total loss: 0.869859
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(2.0867e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.431565
Average KL loss: 0.426941
Average total loss: 0.858506
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.7633e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.439265
Average KL loss: 0.426297
Average total loss: 0.865563
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(9.6816e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.433440
Average KL loss: 0.425721
Average total loss: 0.859161
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-9.6595e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.435478
Average KL loss: 0.425105
Average total loss: 0.860584
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(3.0630e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.439434
Average KL loss: 0.424591
Average total loss: 0.864025
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(3.7124e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.438433
Average KL loss: 0.424092
Average total loss: 0.862526
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.7166e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.436639
Average KL loss: 0.423633
Average total loss: 0.860273
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(5.1464e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.425731
Average KL loss: 0.423101
Average total loss: 0.848832
tensor(0.0037, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(2.1997e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.436263
Average KL loss: 0.422557
Average total loss: 0.858819
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(5.0624e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.438493
Average KL loss: 0.422073
Average total loss: 0.860566
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.6881e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.437004
Average KL loss: 0.421607
Average total loss: 0.858611
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(7.3775e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.438313
Average KL loss: 0.421119
Average total loss: 0.859432
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(9.2683e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.433043
Average KL loss: 0.420582
Average total loss: 0.853626
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.0403e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.427581
Average KL loss: 0.420074
Average total loss: 0.847655
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(6.7819e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.433798
Average KL loss: 0.419588
Average total loss: 0.853386
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.5805e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.440222
Average KL loss: 0.419214
Average total loss: 0.859435
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(5.1967e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.438547
Average KL loss: 0.418886
Average total loss: 0.857432
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(7.7373e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.428609
Average KL loss: 0.418437
Average total loss: 0.847046
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(6.7940e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.437019
Average KL loss: 0.417965
Average total loss: 0.854985
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(3.5274e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.440956
Average KL loss: 0.417606
Average total loss: 0.858562
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(5.7232e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.445336
Average KL loss: 0.417289
Average total loss: 0.862625
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.0812e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.435988
Average KL loss: 0.416984
Average total loss: 0.852971
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(6.1570e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.437974
Average KL loss: 0.416638
Average total loss: 0.854612
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(5.0337e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.435271
Average KL loss: 0.416252
Average total loss: 0.851522
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(3.2432e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.431736
Average KL loss: 0.415849
Average total loss: 0.847585
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.3583e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.443441
Average KL loss: 0.415509
Average total loss: 0.858950
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.8656e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.437303
Average KL loss: 0.415227
Average total loss: 0.852529
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.7843e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.447181
Average KL loss: 0.414923
Average total loss: 0.862105
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.8406e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.434507
Average KL loss: 0.414650
Average total loss: 0.849156
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.2038e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.435958
Average KL loss: 0.414469
Average total loss: 0.850426
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.7975e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.432303
Average KL loss: 0.414421
Average total loss: 0.846724
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(3.3280e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.437617
Average KL loss: 0.414374
Average total loss: 0.851990
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.5329e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.439984
Average KL loss: 0.414331
Average total loss: 0.854315
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.0678e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.437861
Average KL loss: 0.414291
Average total loss: 0.852152
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-8.3283e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.445526
Average KL loss: 0.414249
Average total loss: 0.859775
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.0306e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.439369
Average KL loss: 0.414214
Average total loss: 0.853583
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(4.1130e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.442053
Average KL loss: 0.414175
Average total loss: 0.856228
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.8122e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.442886
Average KL loss: 0.414131
Average total loss: 0.857017
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(4.4921e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.442987
Average KL loss: 0.414085
Average total loss: 0.857072
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-7.5812e-11, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.444363
Average KL loss: 0.414044
Average total loss: 0.858406
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.3345e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.446402
Average KL loss: 0.414008
Average total loss: 0.860409
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-5.4158e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.439753
Average KL loss: 0.413970
Average total loss: 0.853723
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(7.9977e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.436126
Average KL loss: 0.413948
Average total loss: 0.850074
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-7.2329e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.442820
Average KL loss: 0.413943
Average total loss: 0.856763
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.0994e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.439172
Average KL loss: 0.413939
Average total loss: 0.853111
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.0142e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.439310
Average KL loss: 0.413935
Average total loss: 0.853245
 Percentile value: 0.2935490727424621
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     642 /    1728             ( 37.15%) | total_pruned =    1086 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
bn1.bias             | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1735 /   36864             (  4.71%) | total_pruned =   35129 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2237 /   36864             (  6.07%) | total_pruned =   34627 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1926 /   36864             (  5.22%) | total_pruned =   34938 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1993 /   36864             (  5.41%) | total_pruned =   34871 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3407 /   73728             (  4.62%) | total_pruned =   70321 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5140 /  147456             (  3.49%) | total_pruned =  142316 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1501 /    8192             ( 18.32%) | total_pruned =    6691 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2784 /  147456             (  1.89%) | total_pruned =  144672 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2878 /  147456             (  1.95%) | total_pruned =  144578 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8679 /  294912             (  2.94%) | total_pruned =  286233 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   11262 /  589824             (  1.91%) | total_pruned =  578562 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2962 /   32768             (  9.04%) | total_pruned =   29806 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     115 /     256             ( 44.92%) | total_pruned =     141 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3979 /  589824             (  0.67%) | total_pruned =  585845 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4059 /  589824             (  0.69%) | total_pruned =  585765 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12640 / 1179648             (  1.07%) | total_pruned = 1167008 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     180 /     512             ( 35.16%) | total_pruned =     332 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    8817 / 2359296             (  0.37%) | total_pruned = 2350479 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     404 /     512             ( 78.91%) | total_pruned =     108 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2304 /  131072             (  1.76%) | total_pruned =  128768 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     281 /     512             ( 54.88%) | total_pruned =     231 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     183 /     512             ( 35.74%) | total_pruned =     329 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3843 / 2359296             (  0.16%) | total_pruned = 2355453 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     252 /     512             ( 49.22%) | total_pruned =     260 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1555 / 2359296             (  0.07%) | total_pruned = 2357741 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     228 /     512             ( 44.53%) | total_pruned =     284 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
linear.weight        | nonzeros =    1116 /    5120             ( 21.80%) | total_pruned =    4004 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 30/200 Loss: 0.001087 Accuracy: 85.11 100.00 % Best test Accuracy: 85.68%
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.6405e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.533819
Average KL loss: 0.558719
Average total loss: 2.092538
tensor(0.0004, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.2176e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.314114
Average KL loss: 0.755690
Average total loss: 2.069804
tensor(0.0032, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-4.8745e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.146911
Average KL loss: 0.854027
Average total loss: 2.000939
tensor(0.0036, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.2650e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.024194
Average KL loss: 0.898256
Average total loss: 1.922451
tensor(0.0037, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.7308e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.969646
Average KL loss: 0.919685
Average total loss: 1.889331
tensor(0.0038, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(3.6339e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.914921
Average KL loss: 0.932239
Average total loss: 1.847161
tensor(0.0038, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.5201e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.878166
Average KL loss: 0.936945
Average total loss: 1.815110
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.7227e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.833384
Average KL loss: 0.937635
Average total loss: 1.771019
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.4988e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.804155
Average KL loss: 0.931886
Average total loss: 1.736040
tensor(0.0039, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.8834e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.812702
Average KL loss: 0.935304
Average total loss: 1.748007
tensor(0.0039, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.9676e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.787387
Average KL loss: 0.938346
Average total loss: 1.725734
tensor(0.0040, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-3.9223e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.766607
Average KL loss: 0.935371
Average total loss: 1.701978
tensor(0.0040, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.9400e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.759022
Average KL loss: 0.938836
Average total loss: 1.697859
tensor(0.0040, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(1.1651e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.730599
Average KL loss: 0.940370
Average total loss: 1.670968
tensor(0.0040, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(4.5620e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.721736
Average KL loss: 0.936275
Average total loss: 1.658011
tensor(0.0040, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-1.5101e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.721381
Average KL loss: 0.941754
Average total loss: 1.663135
tensor(-0.0042, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-2.1824e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.697682
Average KL loss: 0.939296
Average total loss: 1.636978
tensor(0.0047, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(7.9417e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.701695
Average KL loss: 0.934560
Average total loss: 1.636254
tensor(0.0040, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-7.4490e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.691226
Average KL loss: 0.935564
Average total loss: 1.626790
tensor(0.0041, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-4.3678e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.675980
Average KL loss: 0.940480
Average total loss: 1.616460
tensor(0.0046, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(2.1950e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.684411
Average KL loss: 0.942785
Average total loss: 1.627196
tensor(0.0054, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(4.0426e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.664682
Average KL loss: 0.939344
Average total loss: 1.604026
tensor(0.0041, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-6.1801e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.663294
Average KL loss: 0.943606
Average total loss: 1.606900
tensor(0.0041, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(6.4927e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.667678
Average KL loss: 0.941637
Average total loss: 1.609314
tensor(0.0038, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-4.8415e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.654107
Average KL loss: 0.946676
Average total loss: 1.600783
tensor(-0.0005, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-1.0823e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.643400
Average KL loss: 0.937979
Average total loss: 1.581380
tensor(0.0045, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-7.5047e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.664954
Average KL loss: 0.938511
Average total loss: 1.603465
tensor(0.0042, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.2125e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.644980
Average KL loss: 0.938879
Average total loss: 1.583859
tensor(0.0046, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(1.8921e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.645498
Average KL loss: 0.941109
Average total loss: 1.586608
tensor(0.0029, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-3.9108e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.638334
Average KL loss: 0.942977
Average total loss: 1.581311
tensor(0.0043, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.5284e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.645791
Average KL loss: 0.942127
Average total loss: 1.587919
tensor(0.0042, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.3546e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.640200
Average KL loss: 0.946717
Average total loss: 1.586917
tensor(0.0042, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(1.1548e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.640523
Average KL loss: 0.945691
Average total loss: 1.586214
tensor(0.0043, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.1127e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.624245
Average KL loss: 0.946677
Average total loss: 1.570922
tensor(0.0042, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(8.1193e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.627941
Average KL loss: 0.951358
Average total loss: 1.579298
tensor(0.0007, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.0237e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.631342
Average KL loss: 0.949971
Average total loss: 1.581313
tensor(0.0046, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(2.1384e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.628099
Average KL loss: 0.953436
Average total loss: 1.581535
tensor(0.0045, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(4.5817e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.632074
Average KL loss: 0.957596
Average total loss: 1.589670
tensor(0.0043, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-9.0793e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.621829
Average KL loss: 0.960648
Average total loss: 1.582477
tensor(0.0038, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-1.6740e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.622086
Average KL loss: 0.963607
Average total loss: 1.585693
tensor(0.0038, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-1.8264e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.620577
Average KL loss: 0.958905
Average total loss: 1.579482
tensor(0.0048, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(1.7006e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.616541
Average KL loss: 0.958372
Average total loss: 1.574914
tensor(0.0044, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(3.8325e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.604960
Average KL loss: 0.958476
Average total loss: 1.563436
tensor(0.0043, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(5.1037e-11, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.621088
Average KL loss: 0.958586
Average total loss: 1.579674
tensor(0.0129, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(2.1140e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.611977
Average KL loss: 0.964235
Average total loss: 1.576212
tensor(0.0051, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(2.4570e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.624363
Average KL loss: 0.960473
Average total loss: 1.584836
tensor(0.0033, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.7963e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.609785
Average KL loss: 0.964915
Average total loss: 1.574701
tensor(0.0044, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-5.7147e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.600816
Average KL loss: 0.964916
Average total loss: 1.565732
tensor(0.0049, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(8.1806e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.609475
Average KL loss: 0.966438
Average total loss: 1.575912
tensor(0.0046, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(1.6997e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.599672
Average KL loss: 0.966556
Average total loss: 1.566227
tensor(0.0042, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-7.7656e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.594234
Average KL loss: 0.961131
Average total loss: 1.555365
tensor(0.0042, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-1.5388e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.603932
Average KL loss: 0.962450
Average total loss: 1.566382
tensor(0.0042, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.3031e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.604802
Average KL loss: 0.970887
Average total loss: 1.575689
tensor(0.0067, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(6.5855e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.603431
Average KL loss: 0.966518
Average total loss: 1.569948
tensor(0.0045, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(2.7319e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.594776
Average KL loss: 0.967909
Average total loss: 1.562685
tensor(0.0043, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-4.0456e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.592260
Average KL loss: 0.967846
Average total loss: 1.560107
tensor(0.0044, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.5461e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.586377
Average KL loss: 0.964725
Average total loss: 1.551103
tensor(0.0101, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(1.4401e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.599656
Average KL loss: 0.967116
Average total loss: 1.566772
tensor(0.0036, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-3.0107e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.598147
Average KL loss: 0.970743
Average total loss: 1.568889
tensor(0.0045, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.2987e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.595751
Average KL loss: 0.973665
Average total loss: 1.569416
tensor(0.0044, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.9390e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.585919
Average KL loss: 0.973789
Average total loss: 1.559708
tensor(0.0052, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(9.1972e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.590799
Average KL loss: 0.971312
Average total loss: 1.562111
tensor(0.0052, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(1.1417e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.600829
Average KL loss: 0.973150
Average total loss: 1.573979
tensor(0.0045, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-7.5674e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.589446
Average KL loss: 0.978616
Average total loss: 1.568063
tensor(0.0044, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-8.4170e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.601407
Average KL loss: 0.979081
Average total loss: 1.580488
tensor(0.0045, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(2.4240e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.586802
Average KL loss: 0.981553
Average total loss: 1.568355
tensor(-0.0012, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-1.3889e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.598041
Average KL loss: 0.979279
Average total loss: 1.577320
tensor(0.0042, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-2.7842e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.588291
Average KL loss: 0.973830
Average total loss: 1.562122
tensor(0.0045, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-6.7510e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.583298
Average KL loss: 0.961057
Average total loss: 1.544355
tensor(0.0045, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(3.9889e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.570150
Average KL loss: 0.939819
Average total loss: 1.509969
tensor(0.0045, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(6.6820e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.572824
Average KL loss: 0.920407
Average total loss: 1.493231
tensor(0.0044, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(8.4137e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.566817
Average KL loss: 0.903244
Average total loss: 1.470061
tensor(0.0044, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-5.1652e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.561128
Average KL loss: 0.887520
Average total loss: 1.448648
tensor(0.0044, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-6.5943e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.566517
Average KL loss: 0.872694
Average total loss: 1.439211
tensor(0.0044, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-3.1639e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.555876
Average KL loss: 0.859400
Average total loss: 1.415276
tensor(0.0044, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(4.0571e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.572217
Average KL loss: 0.847295
Average total loss: 1.419512
tensor(0.0044, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-2.5125e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.566643
Average KL loss: 0.836410
Average total loss: 1.403053
tensor(0.0044, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(1.3262e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.562154
Average KL loss: 0.825908
Average total loss: 1.388062
tensor(0.0044, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(5.2356e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.563431
Average KL loss: 0.816168
Average total loss: 1.379599
tensor(0.0044, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(1.5146e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.567250
Average KL loss: 0.807168
Average total loss: 1.374418
tensor(0.0044, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-3.1043e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.576791
Average KL loss: 0.798921
Average total loss: 1.375712
tensor(0.0044, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(5.5424e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.558957
Average KL loss: 0.791089
Average total loss: 1.350046
tensor(0.0044, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-3.3497e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.556733
Average KL loss: 0.783434
Average total loss: 1.340167
tensor(0.0043, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(8.0271e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.564115
Average KL loss: 0.776361
Average total loss: 1.340476
tensor(0.0043, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.0679e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.568378
Average KL loss: 0.769503
Average total loss: 1.337880
tensor(0.0043, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-9.2122e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.570359
Average KL loss: 0.763854
Average total loss: 1.334212
tensor(0.0043, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(2.6028e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.565641
Average KL loss: 0.758236
Average total loss: 1.323877
tensor(0.0043, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(3.4535e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.564747
Average KL loss: 0.752773
Average total loss: 1.317520
tensor(0.0043, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(1.7413e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.567669
Average KL loss: 0.747412
Average total loss: 1.315081
tensor(0.0043, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-6.3041e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.570938
Average KL loss: 0.742542
Average total loss: 1.313481
tensor(0.0043, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(1.3468e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.570240
Average KL loss: 0.737618
Average total loss: 1.307858
tensor(0.0043, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-4.8094e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.575042
Average KL loss: 0.733130
Average total loss: 1.308172
tensor(0.0043, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-6.4666e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.575329
Average KL loss: 0.729245
Average total loss: 1.304574
tensor(0.0043, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-5.9998e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.562233
Average KL loss: 0.725557
Average total loss: 1.287790
tensor(0.0043, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(8.2427e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.570733
Average KL loss: 0.721602
Average total loss: 1.292335
tensor(0.0043, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(3.2248e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.570883
Average KL loss: 0.717664
Average total loss: 1.288547
tensor(0.0043, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(6.4612e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.563822
Average KL loss: 0.713785
Average total loss: 1.277607
tensor(0.0043, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(2.4470e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.573725
Average KL loss: 0.710147
Average total loss: 1.283871
tensor(0.0042, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-3.5499e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.581826
Average KL loss: 0.707097
Average total loss: 1.288923
tensor(0.0042, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-7.9006e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.575123
Average KL loss: 0.704266
Average total loss: 1.279389
tensor(0.0042, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-8.2010e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.565275
Average KL loss: 0.701349
Average total loss: 1.266623
tensor(0.0042, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-8.1489e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.581777
Average KL loss: 0.698506
Average total loss: 1.280283
tensor(0.0042, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-3.7848e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.580408
Average KL loss: 0.695397
Average total loss: 1.275804
tensor(0.0042, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(6.0385e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.577012
Average KL loss: 0.692400
Average total loss: 1.269412
tensor(0.0042, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(6.1698e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.579230
Average KL loss: 0.689998
Average total loss: 1.269228
tensor(0.0042, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-1.1414e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.577247
Average KL loss: 0.687597
Average total loss: 1.264844
tensor(0.0042, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(9.9535e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.573474
Average KL loss: 0.685237
Average total loss: 1.258711
tensor(0.0042, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(4.5097e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.580547
Average KL loss: 0.682422
Average total loss: 1.262969
tensor(0.0042, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(7.9088e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.578630
Average KL loss: 0.679971
Average total loss: 1.258601
tensor(0.0042, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(8.2586e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.581435
Average KL loss: 0.677917
Average total loss: 1.259352
tensor(0.0042, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(6.8899e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.574561
Average KL loss: 0.676362
Average total loss: 1.250923
tensor(0.0042, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.6972e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.573314
Average KL loss: 0.674368
Average total loss: 1.247682
tensor(0.0042, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.0950e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.577950
Average KL loss: 0.672604
Average total loss: 1.250554
tensor(0.0042, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(4.7655e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.578883
Average KL loss: 0.670743
Average total loss: 1.249626
tensor(0.0042, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(5.6515e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.580750
Average KL loss: 0.668974
Average total loss: 1.249724
tensor(0.0042, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-4.2037e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.577596
Average KL loss: 0.667010
Average total loss: 1.244605
tensor(0.0042, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(7.8882e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.588553
Average KL loss: 0.665248
Average total loss: 1.253802
tensor(0.0042, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(7.1386e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.580326
Average KL loss: 0.663531
Average total loss: 1.243858
tensor(0.0042, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-7.7273e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.592504
Average KL loss: 0.661907
Average total loss: 1.254411
tensor(0.0042, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-6.5468e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.584760
Average KL loss: 0.660461
Average total loss: 1.245220
tensor(0.0042, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-2.1790e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.589071
Average KL loss: 0.659242
Average total loss: 1.248313
tensor(0.0042, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-7.4892e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.583632
Average KL loss: 0.658193
Average total loss: 1.241825
tensor(0.0042, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(4.0302e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.579617
Average KL loss: 0.656693
Average total loss: 1.236309
tensor(0.0042, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-1.0763e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.579651
Average KL loss: 0.654926
Average total loss: 1.234577
tensor(0.0042, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-9.3076e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.580398
Average KL loss: 0.653628
Average total loss: 1.234026
tensor(0.0042, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(6.8419e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.576750
Average KL loss: 0.652102
Average total loss: 1.228852
tensor(0.0041, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(8.6236e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.586861
Average KL loss: 0.650929
Average total loss: 1.237790
tensor(0.0041, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-1.5503e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.586620
Average KL loss: 0.650133
Average total loss: 1.236753
tensor(0.0041, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-1.3708e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.589495
Average KL loss: 0.649240
Average total loss: 1.238735
tensor(0.0041, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(7.7605e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.583675
Average KL loss: 0.647836
Average total loss: 1.231511
tensor(0.0041, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(1.0119e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.590320
Average KL loss: 0.646765
Average total loss: 1.237085
tensor(0.0041, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(4.0925e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.589472
Average KL loss: 0.645914
Average total loss: 1.235387
tensor(0.0041, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(8.0193e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.590523
Average KL loss: 0.645031
Average total loss: 1.235554
tensor(0.0041, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(9.6187e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.587081
Average KL loss: 0.643949
Average total loss: 1.231030
tensor(0.0041, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-1.6355e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.591032
Average KL loss: 0.643056
Average total loss: 1.234088
tensor(0.0041, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(4.3347e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.591483
Average KL loss: 0.641992
Average total loss: 1.233475
tensor(0.0041, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(2.3188e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.587187
Average KL loss: 0.640923
Average total loss: 1.228109
tensor(0.0041, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(8.6455e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.586881
Average KL loss: 0.639985
Average total loss: 1.226866
tensor(0.0041, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-2.6212e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.587922
Average KL loss: 0.638956
Average total loss: 1.226878
tensor(0.0041, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.7733e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.586681
Average KL loss: 0.637748
Average total loss: 1.224429
tensor(0.0041, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(6.6971e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.586487
Average KL loss: 0.637144
Average total loss: 1.223631
tensor(0.0041, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-3.7197e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.583421
Average KL loss: 0.635902
Average total loss: 1.219323
tensor(0.0041, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(4.9517e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.587945
Average KL loss: 0.634996
Average total loss: 1.222940
tensor(0.0041, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-1.0306e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.587590
Average KL loss: 0.634047
Average total loss: 1.221638
tensor(0.0041, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(4.1676e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.589205
Average KL loss: 0.633449
Average total loss: 1.222653
tensor(0.0041, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-1.4028e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.579602
Average KL loss: 0.632606
Average total loss: 1.212208
tensor(0.0041, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-5.9455e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.582633
Average KL loss: 0.631873
Average total loss: 1.214506
tensor(0.0041, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(6.2323e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.590027
Average KL loss: 0.630730
Average total loss: 1.220756
tensor(0.0041, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(3.2763e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.600870
Average KL loss: 0.630151
Average total loss: 1.231021
tensor(0.0041, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(8.1742e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.583173
Average KL loss: 0.629727
Average total loss: 1.212900
tensor(0.0041, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.3715e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.592281
Average KL loss: 0.628518
Average total loss: 1.220799
tensor(0.0041, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.1675e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.591390
Average KL loss: 0.627996
Average total loss: 1.219386
tensor(0.0041, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(7.8381e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.596174
Average KL loss: 0.627406
Average total loss: 1.223580
tensor(0.0041, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(1.6694e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.595197
Average KL loss: 0.626685
Average total loss: 1.221881
tensor(0.0041, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(1.0045e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.593885
Average KL loss: 0.626341
Average total loss: 1.220226
tensor(0.0041, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.2118e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.591905
Average KL loss: 0.625389
Average total loss: 1.217294
tensor(0.0041, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.2508e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.600417
Average KL loss: 0.624903
Average total loss: 1.225320
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(4.2982e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.594533
Average KL loss: 0.624791
Average total loss: 1.219324
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.2257e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.599399
Average KL loss: 0.624407
Average total loss: 1.223806
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(6.9585e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.590926
Average KL loss: 0.623981
Average total loss: 1.214907
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.3828e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.586348
Average KL loss: 0.623568
Average total loss: 1.209916
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-5.9144e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.594120
Average KL loss: 0.623204
Average total loss: 1.217325
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.1145e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.594205
Average KL loss: 0.622847
Average total loss: 1.217052
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.4420e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.592659
Average KL loss: 0.622511
Average total loss: 1.215170
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(6.7546e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.596949
Average KL loss: 0.622166
Average total loss: 1.219115
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-9.1510e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.597148
Average KL loss: 0.621798
Average total loss: 1.218947
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-3.3246e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.582903
Average KL loss: 0.621439
Average total loss: 1.204342
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(5.2366e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.591149
Average KL loss: 0.621082
Average total loss: 1.212231
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(3.2935e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.592603
Average KL loss: 0.620733
Average total loss: 1.213335
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.2611e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.598834
Average KL loss: 0.620403
Average total loss: 1.219237
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(6.9023e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.590659
Average KL loss: 0.620035
Average total loss: 1.210694
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.9098e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.590559
Average KL loss: 0.619652
Average total loss: 1.210211
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-7.5838e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.586599
Average KL loss: 0.619369
Average total loss: 1.205967
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(4.9416e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.582238
Average KL loss: 0.619013
Average total loss: 1.201250
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-3.1504e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.599184
Average KL loss: 0.618729
Average total loss: 1.217913
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-8.4339e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.587165
Average KL loss: 0.618448
Average total loss: 1.205613
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(6.0355e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.591126
Average KL loss: 0.618134
Average total loss: 1.209260
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.7280e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.596209
Average KL loss: 0.617820
Average total loss: 1.214029
tensor(0.0041, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(6.0975e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.591351
Average KL loss: 0.617524
Average total loss: 1.208875
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-4.2396e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.588863
Average KL loss: 0.617209
Average total loss: 1.206072
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.1833e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.596452
Average KL loss: 0.616912
Average total loss: 1.213365
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(1.5885e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.590880
Average KL loss: 0.616634
Average total loss: 1.207514
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.4739e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.598227
Average KL loss: 0.616338
Average total loss: 1.214564
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(4.9137e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.595332
Average KL loss: 0.616044
Average total loss: 1.211376
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-3.8621e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.586754
Average KL loss: 0.615771
Average total loss: 1.202525
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(3.1988e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.585103
Average KL loss: 0.615594
Average total loss: 1.200697
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(3.1230e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.588662
Average KL loss: 0.615561
Average total loss: 1.204222
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.1706e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.594868
Average KL loss: 0.615526
Average total loss: 1.210394
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.8245e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.589174
Average KL loss: 0.615496
Average total loss: 1.204669
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.3041e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.593721
Average KL loss: 0.615464
Average total loss: 1.209185
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(1.1620e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.592361
Average KL loss: 0.615432
Average total loss: 1.207793
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(8.3806e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.582892
Average KL loss: 0.615396
Average total loss: 1.198289
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(4.6190e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.589187
Average KL loss: 0.615361
Average total loss: 1.204548
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-7.3689e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.590436
Average KL loss: 0.615325
Average total loss: 1.205761
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-4.6697e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.590021
Average KL loss: 0.615292
Average total loss: 1.205312
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-6.7926e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.599900
Average KL loss: 0.615261
Average total loss: 1.215161
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.6659e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.592810
Average KL loss: 0.615233
Average total loss: 1.208043
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-4.5813e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.595882
Average KL loss: 0.615205
Average total loss: 1.211087
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-3.2250e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.590433
Average KL loss: 0.615174
Average total loss: 1.205607
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(6.1734e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.602822
Average KL loss: 0.615145
Average total loss: 1.217966
 Percentile value: 1.316011071205139
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     527 /    1728             ( 30.50%) | total_pruned =    1201 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
bn1.bias             | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     718 /   36864             (  1.95%) | total_pruned =   36146 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     941 /   36864             (  2.55%) | total_pruned =   35923 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     776 /   36864             (  2.11%) | total_pruned =   36088 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     806 /   36864             (  2.19%) | total_pruned =   36058 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1280 /   73728             (  1.74%) | total_pruned =   72448 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1676 /  147456             (  1.14%) | total_pruned =  145780 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     733 /    8192             (  8.95%) | total_pruned =    7459 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     873 /  147456             (  0.59%) | total_pruned =  146583 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     808 /  147456             (  0.55%) | total_pruned =  146648 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2455 /  294912             (  0.83%) | total_pruned =  292457 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      56 /     256             ( 21.88%) | total_pruned =     200 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2794 /  589824             (  0.47%) | total_pruned =  587030 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     965 /   32768             (  2.94%) | total_pruned =   31803 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     899 /  589824             (  0.15%) | total_pruned =  588925 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     862 /  589824             (  0.15%) | total_pruned =  588962 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2612 / 1179648             (  0.22%) | total_pruned = 1177036 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1851 / 2359296             (  0.08%) | total_pruned = 2357445 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     272 /     512             ( 53.12%) | total_pruned =     240 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     545 /  131072             (  0.42%) | total_pruned =  130527 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     165 /     512             ( 32.23%) | total_pruned =     347 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     761 / 2359296             (  0.03%) | total_pruned = 2358535 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     268 / 2359296             (  0.01%) | total_pruned = 2359028 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     554 /    5120             ( 10.82%) | total_pruned =    4566 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 88/200 Loss: 0.038110 Accuracy: 80.67 100.00 % Best test Accuracy: 82.89%
tensor(0.0041, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.1535e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.497015
Average KL loss: 0.545079
Average total loss: 3.042094
tensor(0.0007, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.4536e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.354950
Average KL loss: 0.572866
Average total loss: 2.927816
tensor(0.0033, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-9.1944e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.113595
Average KL loss: 0.636290
Average total loss: 2.749884
tensor(0.0035, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-6.9797e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.839469
Average KL loss: 0.681920
Average total loss: 2.521389
tensor(0.0036, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.4068e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.634134
Average KL loss: 0.715114
Average total loss: 2.349248
tensor(0.0038, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.4156e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.521006
Average KL loss: 0.741061
Average total loss: 2.262066
tensor(0.0039, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.5234e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.478013
Average KL loss: 0.761717
Average total loss: 2.239730
tensor(0.0040, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-3.5223e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.401488
Average KL loss: 0.782208
Average total loss: 2.183696
tensor(0.0040, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.9627e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.295386
Average KL loss: 0.798021
Average total loss: 2.093407
tensor(0.0041, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-4.2420e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.241454
Average KL loss: 0.811603
Average total loss: 2.053057
tensor(0.0042, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.4556e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.186163
Average KL loss: 0.822164
Average total loss: 2.008328
tensor(0.0042, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-2.6428e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.142704
Average KL loss: 0.834273
Average total loss: 1.976977
tensor(0.0043, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-4.1501e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.101095
Average KL loss: 0.843083
Average total loss: 1.944178
tensor(0.0044, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.8375e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.078303
Average KL loss: 0.852134
Average total loss: 1.930437
tensor(0.0044, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.1316e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.045266
Average KL loss: 0.858914
Average total loss: 1.904180
tensor(0.0045, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-1.6239e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.014227
Average KL loss: 0.866493
Average total loss: 1.880720
tensor(0.0036, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-2.4826e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.990504
Average KL loss: 0.875050
Average total loss: 1.865555
tensor(0.0059, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.7585e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.957512
Average KL loss: 0.879898
Average total loss: 1.837410
tensor(0.0045, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-8.8204e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.938764
Average KL loss: 0.885262
Average total loss: 1.824026
tensor(0.0046, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-1.9108e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.937885
Average KL loss: 0.888492
Average total loss: 1.826377
tensor(0.0038, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-6.0647e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.912761
Average KL loss: 0.894797
Average total loss: 1.807558
tensor(0.0056, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(1.3781e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.879872
Average KL loss: 0.897329
Average total loss: 1.777201
tensor(0.0048, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-7.9742e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.873506
Average KL loss: 0.900830
Average total loss: 1.774335
tensor(0.0048, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.6251e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.886583
Average KL loss: 0.903366
Average total loss: 1.789950
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(2.8093e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.836675
Average KL loss: 0.909858
Average total loss: 1.746533
tensor(0.0054, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-3.1093e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.830921
Average KL loss: 0.908820
Average total loss: 1.739741
tensor(0.0050, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-1.1384e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.826847
Average KL loss: 0.911316
Average total loss: 1.738163
tensor(0.0049, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-9.7518e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.807028
Average KL loss: 0.913326
Average total loss: 1.720354
tensor(0.0045, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-1.7320e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.802299
Average KL loss: 0.918466
Average total loss: 1.720766
tensor(0.0039, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-4.7397e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.811935
Average KL loss: 0.919121
Average total loss: 1.731057
tensor(0.0051, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(5.5069e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.783765
Average KL loss: 0.922041
Average total loss: 1.705807
tensor(0.0051, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(5.9565e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.775422
Average KL loss: 0.923667
Average total loss: 1.699089
tensor(0.0051, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-3.7994e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.778254
Average KL loss: 0.929733
Average total loss: 1.707987
tensor(0.0088, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(7.3152e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.761944
Average KL loss: 0.930941
Average total loss: 1.692885
tensor(0.0050, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-1.6713e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.748872
Average KL loss: 0.932678
Average total loss: 1.681550
tensor(0.0052, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-2.7806e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.748077
Average KL loss: 0.935153
Average total loss: 1.683230
tensor(0.0052, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-5.3880e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.747859
Average KL loss: 0.938162
Average total loss: 1.686020
tensor(0.0154, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(2.4282e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.744517
Average KL loss: 0.941481
Average total loss: 1.685998
tensor(0.0047, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-2.0583e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.721122
Average KL loss: 0.943238
Average total loss: 1.664360
tensor(0.0053, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.2375e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.709245
Average KL loss: 0.945172
Average total loss: 1.654417
tensor(0.0053, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-2.5485e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.699052
Average KL loss: 0.946103
Average total loss: 1.645155
tensor(0.0059, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(1.0313e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.703774
Average KL loss: 0.951735
Average total loss: 1.655510
tensor(0.0052, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-1.0002e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.702266
Average KL loss: 0.952635
Average total loss: 1.654901
tensor(0.0053, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-1.2154e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.698571
Average KL loss: 0.953591
Average total loss: 1.652162
tensor(0.0054, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-1.1874e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.677411
Average KL loss: 0.955959
Average total loss: 1.633371
tensor(0.0059, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(5.1219e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.683459
Average KL loss: 0.960543
Average total loss: 1.644003
tensor(0.0066, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(2.6523e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.673607
Average KL loss: 0.958808
Average total loss: 1.632414
tensor(0.0052, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-5.4555e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.677982
Average KL loss: 0.959534
Average total loss: 1.637516
tensor(0.0055, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-1.1361e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.680852
Average KL loss: 0.961472
Average total loss: 1.642325
tensor(0.0056, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-4.7141e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.664436
Average KL loss: 0.966807
Average total loss: 1.631242
tensor(0.0051, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.3602e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.677792
Average KL loss: 0.965264
Average total loss: 1.643055
tensor(0.0055, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(1.1711e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.666656
Average KL loss: 0.967734
Average total loss: 1.634390
tensor(0.0055, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(4.7990e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.657260
Average KL loss: 0.969096
Average total loss: 1.626357
tensor(0.0056, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-2.2655e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.653758
Average KL loss: 0.969985
Average total loss: 1.623743
tensor(0.0054, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-8.8169e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.655343
Average KL loss: 0.975226
Average total loss: 1.630568
tensor(0.0050, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-2.1325e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.646461
Average KL loss: 0.974686
Average total loss: 1.621147
tensor(0.0063, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(2.8387e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.640877
Average KL loss: 0.976012
Average total loss: 1.616890
tensor(0.0058, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(3.9840e-11, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.648259
Average KL loss: 0.975855
Average total loss: 1.624114
tensor(0.0058, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-1.4491e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.640426
Average KL loss: 0.977953
Average total loss: 1.618379
tensor(0.0050, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-3.0136e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.638235
Average KL loss: 0.981811
Average total loss: 1.620046
tensor(0.0044, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-3.3200e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.628327
Average KL loss: 0.981282
Average total loss: 1.609609
tensor(0.0064, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(7.8229e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.621469
Average KL loss: 0.983363
Average total loss: 1.604832
tensor(0.0059, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-1.3668e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.631894
Average KL loss: 0.985706
Average total loss: 1.617600
tensor(0.0059, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-5.1012e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.617050
Average KL loss: 0.991730
Average total loss: 1.608780
tensor(0.0091, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(8.4568e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.622840
Average KL loss: 0.991265
Average total loss: 1.614105
tensor(0.0061, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(4.0377e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.614639
Average KL loss: 0.993133
Average total loss: 1.607772
tensor(0.0061, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-5.6800e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.605582
Average KL loss: 0.994285
Average total loss: 1.599867
tensor(0.0059, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(4.8064e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.614099
Average KL loss: 0.995975
Average total loss: 1.610074
tensor(0.0049, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-3.2055e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.600597
Average KL loss: 1.002016
Average total loss: 1.602613
tensor(0.0075, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(3.8631e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.605618
Average KL loss: 0.999302
Average total loss: 1.604920
tensor(0.0057, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.3860e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.608991
Average KL loss: 1.001355
Average total loss: 1.610346
tensor(0.0061, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-3.7734e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.596674
Average KL loss: 1.004044
Average total loss: 1.600718
tensor(0.0061, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(7.7835e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.595910
Average KL loss: 1.006110
Average total loss: 1.602021
tensor(0.0061, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-2.2377e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.598846
Average KL loss: 1.011268
Average total loss: 1.610114
tensor(0.0093, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(7.2816e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.598873
Average KL loss: 1.007977
Average total loss: 1.606851
tensor(0.0059, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-1.4237e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.592641
Average KL loss: 1.008377
Average total loss: 1.601018
tensor(0.0062, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-3.7072e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.606894
Average KL loss: 1.010263
Average total loss: 1.617158
tensor(0.0062, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-3.9939e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.589429
Average KL loss: 1.011408
Average total loss: 1.600836
tensor(0.0063, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(1.5283e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.587491
Average KL loss: 1.010547
Average total loss: 1.598038
tensor(0.0062, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(5.7396e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.578769
Average KL loss: 1.008039
Average total loss: 1.586808
tensor(0.0062, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-6.2769e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.573883
Average KL loss: 1.005640
Average total loss: 1.579523
tensor(0.0062, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(5.0737e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.565651
Average KL loss: 1.003425
Average total loss: 1.569076
tensor(0.0062, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(1.7923e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.578443
Average KL loss: 1.001340
Average total loss: 1.579782
tensor(0.0062, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-5.9094e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.576328
Average KL loss: 0.999372
Average total loss: 1.575700
tensor(0.0062, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-6.1495e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.571960
Average KL loss: 0.997393
Average total loss: 1.569354
tensor(0.0062, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(3.0004e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.570616
Average KL loss: 0.995451
Average total loss: 1.566067
tensor(0.0062, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.0739e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.576485
Average KL loss: 0.993579
Average total loss: 1.570065
tensor(0.0062, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(7.7295e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.563592
Average KL loss: 0.991695
Average total loss: 1.555288
tensor(0.0062, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-3.7979e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.561546
Average KL loss: 0.989909
Average total loss: 1.551455
tensor(0.0062, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(2.3268e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.562494
Average KL loss: 0.988215
Average total loss: 1.550709
tensor(0.0062, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-7.8384e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.574206
Average KL loss: 0.986615
Average total loss: 1.560821
tensor(0.0062, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(1.3299e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.570577
Average KL loss: 0.985176
Average total loss: 1.555753
tensor(0.0062, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(5.9793e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.567617
Average KL loss: 0.983534
Average total loss: 1.551151
tensor(0.0062, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-1.8994e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.565061
Average KL loss: 0.981982
Average total loss: 1.547043
tensor(0.0062, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.1154e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.562443
Average KL loss: 0.980545
Average total loss: 1.542987
tensor(0.0062, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.0387e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.562908
Average KL loss: 0.978942
Average total loss: 1.541850
tensor(0.0062, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-5.2894e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.562384
Average KL loss: 0.977596
Average total loss: 1.539980
tensor(0.0062, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(3.4597e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.563783
Average KL loss: 0.976127
Average total loss: 1.539910
tensor(0.0062, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(4.2112e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.554806
Average KL loss: 0.974666
Average total loss: 1.529472
tensor(0.0062, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-9.9454e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.558368
Average KL loss: 0.973191
Average total loss: 1.531558
tensor(0.0062, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-8.1961e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.551789
Average KL loss: 0.971882
Average total loss: 1.523671
tensor(0.0062, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(1.9592e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.558967
Average KL loss: 0.970727
Average total loss: 1.529694
tensor(0.0062, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(3.2549e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.564757
Average KL loss: 0.969530
Average total loss: 1.534288
tensor(0.0062, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-5.9219e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.567930
Average KL loss: 0.968196
Average total loss: 1.536126
tensor(0.0062, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-6.9322e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.556210
Average KL loss: 0.966919
Average total loss: 1.523129
tensor(0.0062, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(1.6633e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.550746
Average KL loss: 0.965667
Average total loss: 1.516414
tensor(0.0062, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-1.7406e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.549388
Average KL loss: 0.964437
Average total loss: 1.513825
tensor(0.0062, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-2.6980e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.555929
Average KL loss: 0.963129
Average total loss: 1.519058
tensor(0.0062, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(7.0953e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.553332
Average KL loss: 0.961957
Average total loss: 1.515289
tensor(0.0062, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(4.8879e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.561192
Average KL loss: 0.960707
Average total loss: 1.521899
tensor(0.0062, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-1.0960e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.557280
Average KL loss: 0.959565
Average total loss: 1.516845
tensor(0.0062, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(4.5716e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.559391
Average KL loss: 0.958527
Average total loss: 1.517919
tensor(0.0062, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-1.9589e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.552576
Average KL loss: 0.957564
Average total loss: 1.510140
tensor(0.0062, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-8.3130e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.544606
Average KL loss: 0.956494
Average total loss: 1.501100
tensor(0.0062, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(1.3449e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.559406
Average KL loss: 0.955430
Average total loss: 1.514836
tensor(0.0062, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(5.7994e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.555911
Average KL loss: 0.954479
Average total loss: 1.510389
tensor(0.0062, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(2.5872e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.552703
Average KL loss: 0.953351
Average total loss: 1.506054
tensor(0.0062, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(3.1557e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.545462
Average KL loss: 0.952286
Average total loss: 1.497748
tensor(0.0061, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(2.3575e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.556036
Average KL loss: 0.951197
Average total loss: 1.507234
tensor(0.0061, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-1.1289e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.554366
Average KL loss: 0.950348
Average total loss: 1.504714
tensor(0.0061, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(3.7149e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.555777
Average KL loss: 0.949434
Average total loss: 1.505212
tensor(0.0061, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(1.6586e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.551762
Average KL loss: 0.948467
Average total loss: 1.500228
tensor(0.0061, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-2.0179e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.558073
Average KL loss: 0.947473
Average total loss: 1.505547
tensor(0.0061, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-9.6180e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.547848
Average KL loss: 0.946652
Average total loss: 1.494500
tensor(0.0061, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(3.5936e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.555841
Average KL loss: 0.945658
Average total loss: 1.501499
tensor(0.0061, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-6.4327e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.558394
Average KL loss: 0.944851
Average total loss: 1.503246
tensor(0.0061, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-1.2560e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.553595
Average KL loss: 0.944101
Average total loss: 1.497696
tensor(0.0061, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(2.4874e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.549286
Average KL loss: 0.943235
Average total loss: 1.492522
tensor(0.0061, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-5.7656e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.554771
Average KL loss: 0.942543
Average total loss: 1.497314
tensor(0.0061, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-3.2351e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.548389
Average KL loss: 0.941640
Average total loss: 1.490029
tensor(0.0061, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-8.1279e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.553443
Average KL loss: 0.940712
Average total loss: 1.494155
tensor(0.0061, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-1.1220e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.558119
Average KL loss: 0.939711
Average total loss: 1.497830
tensor(0.0061, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-2.4601e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.553364
Average KL loss: 0.938893
Average total loss: 1.492257
tensor(0.0061, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(2.8935e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.559232
Average KL loss: 0.938022
Average total loss: 1.497253
tensor(0.0061, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-1.9228e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.559161
Average KL loss: 0.937157
Average total loss: 1.496317
tensor(0.0061, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-3.3874e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.546645
Average KL loss: 0.936457
Average total loss: 1.483102
tensor(0.0061, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-5.8979e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.540379
Average KL loss: 0.935649
Average total loss: 1.476029
tensor(0.0061, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-7.2840e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.553580
Average KL loss: 0.934725
Average total loss: 1.488305
tensor(0.0061, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-7.5554e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.558813
Average KL loss: 0.933993
Average total loss: 1.492806
tensor(0.0061, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-8.3847e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.555301
Average KL loss: 0.933159
Average total loss: 1.488461
tensor(0.0061, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-3.6160e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.562424
Average KL loss: 0.932409
Average total loss: 1.494832
tensor(0.0061, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(4.7874e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.551384
Average KL loss: 0.931762
Average total loss: 1.483147
tensor(0.0061, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-1.1247e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.547769
Average KL loss: 0.931054
Average total loss: 1.478823
tensor(0.0061, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-1.5567e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.557273
Average KL loss: 0.930277
Average total loss: 1.487550
tensor(0.0061, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-3.9481e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.555999
Average KL loss: 0.929685
Average total loss: 1.485683
tensor(0.0061, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(5.4828e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.557824
Average KL loss: 0.929003
Average total loss: 1.486827
tensor(0.0061, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-1.0922e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.550602
Average KL loss: 0.928312
Average total loss: 1.478914
tensor(0.0061, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-6.9473e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.550157
Average KL loss: 0.927551
Average total loss: 1.477708
tensor(0.0061, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(7.4434e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.551755
Average KL loss: 0.927100
Average total loss: 1.478855
tensor(0.0061, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-2.4313e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.554692
Average KL loss: 0.926977
Average total loss: 1.481669
tensor(0.0061, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-3.4205e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.549791
Average KL loss: 0.926868
Average total loss: 1.476659
tensor(0.0061, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(5.8017e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.549940
Average KL loss: 0.926756
Average total loss: 1.476696
tensor(0.0061, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-8.3302e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.550150
Average KL loss: 0.926645
Average total loss: 1.476796
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(1.4616e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.555528
Average KL loss: 0.926556
Average total loss: 1.482084
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(3.5230e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.553017
Average KL loss: 0.926459
Average total loss: 1.479476
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-9.8493e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.549696
Average KL loss: 0.926360
Average total loss: 1.476056
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-6.7127e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.561927
Average KL loss: 0.926259
Average total loss: 1.488186
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(3.2228e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.556509
Average KL loss: 0.926155
Average total loss: 1.482664
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(2.5818e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.555998
Average KL loss: 0.926050
Average total loss: 1.482048
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-6.0467e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.553475
Average KL loss: 0.925987
Average total loss: 1.479462
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(4.5190e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.547024
Average KL loss: 0.925976
Average total loss: 1.472999
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(1.0011e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.552276
Average KL loss: 0.925965
Average total loss: 1.478241
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-4.9560e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.559782
Average KL loss: 0.925955
Average total loss: 1.485737
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-3.9884e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.551744
Average KL loss: 0.925946
Average total loss: 1.477690
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-4.4488e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.557078
Average KL loss: 0.925937
Average total loss: 1.483015
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(2.9090e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.555688
Average KL loss: 0.925927
Average total loss: 1.481614
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(1.8592e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.549651
Average KL loss: 0.925917
Average total loss: 1.475567
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-4.7113e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.552995
Average KL loss: 0.925907
Average total loss: 1.478902
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-5.1094e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.552996
Average KL loss: 0.925894
Average total loss: 1.478891
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-1.3562e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.537909
Average KL loss: 0.925882
Average total loss: 1.463791
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(3.1193e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.550218
Average KL loss: 0.925870
Average total loss: 1.476088
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-6.6629e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.565813
Average KL loss: 0.925859
Average total loss: 1.491672
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(1.0523e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.564413
Average KL loss: 0.925847
Average total loss: 1.490260
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-2.5512e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.554817
Average KL loss: 0.925837
Average total loss: 1.480654
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-1.9285e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.559892
Average KL loss: 0.925827
Average total loss: 1.485719
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-1.0351e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.556633
Average KL loss: 0.925817
Average total loss: 1.482450
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-6.9426e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.557535
Average KL loss: 0.925807
Average total loss: 1.483343
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(3.4007e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.554734
Average KL loss: 0.925798
Average total loss: 1.480532
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-6.2095e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.550032
Average KL loss: 0.925788
Average total loss: 1.475819
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-2.4570e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.557220
Average KL loss: 0.925777
Average total loss: 1.482996
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(6.8683e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.561103
Average KL loss: 0.925767
Average total loss: 1.486869
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(2.6682e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.551515
Average KL loss: 0.925761
Average total loss: 1.477277
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-2.0778e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.556138
Average KL loss: 0.925760
Average total loss: 1.481898
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-1.0238e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.549940
Average KL loss: 0.925759
Average total loss: 1.475699
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(2.4268e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.548174
Average KL loss: 0.925758
Average total loss: 1.473932
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-2.7215e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.550824
Average KL loss: 0.925757
Average total loss: 1.476581
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-4.9425e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.554610
Average KL loss: 0.925756
Average total loss: 1.480366
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-1.4377e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.549201
Average KL loss: 0.925755
Average total loss: 1.474956
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(3.1515e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.557148
Average KL loss: 0.925754
Average total loss: 1.482902
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-9.7315e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.553082
Average KL loss: 0.925753
Average total loss: 1.478835
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-9.9682e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.547747
Average KL loss: 0.925752
Average total loss: 1.473498
tensor(0.0061, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(7.6367e-09, device='cuda:0')
 Percentile value: 7.204313993453979
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =     432 /    1728             ( 25.00%) | total_pruned =    1296 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
bn1.bias             | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     285 /   36864             (  0.77%) | total_pruned =   36579 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     277 /   36864             (  0.75%) | total_pruned =   36587 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     248 /   36864             (  0.67%) | total_pruned =   36616 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     237 /   36864             (  0.64%) | total_pruned =   36627 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     316 /   73728             (  0.43%) | total_pruned =   73412 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     355 /  147456             (  0.24%) | total_pruned =  147101 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     234 /    8192             (  2.86%) | total_pruned =    7958 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     208 /  147456             (  0.14%) | total_pruned =  147248 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     181 /  147456             (  0.12%) | total_pruned =  147275 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     405 /  294912             (  0.14%) | total_pruned =  294507 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     440 /  589824             (  0.07%) | total_pruned =  589384 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     181 /   32768             (  0.55%) | total_pruned =   32587 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     131 /     256             ( 51.17%) | total_pruned =     125 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     180 /  589824             (  0.03%) | total_pruned =  589644 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      92 /     256             ( 35.94%) | total_pruned =     164 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     177 /  589824             (  0.03%) | total_pruned =  589647 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     438 / 1179648             (  0.04%) | total_pruned = 1179210 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     233 /     512             ( 45.51%) | total_pruned =     279 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     400 / 2359296             (  0.02%) | total_pruned = 2358896 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     185 /     512             ( 36.13%) | total_pruned =     327 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     133 /  131072             (  0.10%) | total_pruned =  130939 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      92 /     512             ( 17.97%) | total_pruned =     420 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     208 / 2359296             (  0.01%) | total_pruned = 2359088 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     126 / 2359296             (  0.01%) | total_pruned = 2359170 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     384 /    5120             (  7.50%) | total_pruned =    4736 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 199/200 Loss: 0.813964 Accuracy: 69.07 76.40 % Best test Accuracy: 69.25%
