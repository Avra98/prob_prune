Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.4786e-05, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.940430
Average KL loss: 497.196815
Average total loss: 499.137234
tensor(-0.4495, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(2.3638e-05, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.740915
Average KL loss: 382.591252
Average total loss: 384.332157
tensor(-0.8686, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(2.0581e-05, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.593838
Average KL loss: 290.750908
Average total loss: 292.344737
tensor(-1.2452, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(1.7086e-05, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.529572
Average KL loss: 223.251627
Average total loss: 224.781195
tensor(-1.5745, device='cuda:0') tensor(0.0826, device='cuda:0') tensor(1.4049e-05, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.520300
Average KL loss: 175.320470
Average total loss: 176.840766
tensor(-1.8600, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(1.1595e-05, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.510421
Average KL loss: 141.173891
Average total loss: 142.684308
tensor(-2.1087, device='cuda:0') tensor(0.1326, device='cuda:0') tensor(9.6770e-06, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.516606
Average KL loss: 116.361584
Average total loss: 117.878188
tensor(-2.3271, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(8.2109e-06, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.524042
Average KL loss: 97.875790
Average total loss: 99.399829
tensor(-2.5210, device='cuda:0') tensor(0.1707, device='cuda:0') tensor(7.0128e-06, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.522243
Average KL loss: 83.768948
Average total loss: 85.291190
tensor(-2.6946, device='cuda:0') tensor(0.1863, device='cuda:0') tensor(6.0908e-06, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.542791
Average KL loss: 72.745819
Average total loss: 74.288609
tensor(-2.8516, device='cuda:0') tensor(0.2001, device='cuda:0') tensor(5.3918e-06, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.545880
Average KL loss: 63.955064
Average total loss: 65.500943
tensor(-2.9949, device='cuda:0') tensor(0.2124, device='cuda:0') tensor(4.7591e-06, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.572343
Average KL loss: 56.823226
Average total loss: 58.395567
tensor(-3.1262, device='cuda:0') tensor(0.2238, device='cuda:0') tensor(4.2582e-06, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.560700
Average KL loss: 50.951890
Average total loss: 52.512587
tensor(-3.2476, device='cuda:0') tensor(0.2342, device='cuda:0') tensor(3.8515e-06, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.552316
Average KL loss: 46.043240
Average total loss: 47.595555
tensor(-3.3604, device='cuda:0') tensor(0.2437, device='cuda:0') tensor(3.5095e-06, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.567541
Average KL loss: 41.887307
Average total loss: 43.454846
tensor(-3.4659, device='cuda:0') tensor(0.2526, device='cuda:0') tensor(3.1946e-06, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.571494
Average KL loss: 38.335873
Average total loss: 39.907366
tensor(-3.5647, device='cuda:0') tensor(0.2611, device='cuda:0') tensor(2.9242e-06, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.556045
Average KL loss: 35.271340
Average total loss: 36.827383
tensor(-3.6579, device='cuda:0') tensor(0.2691, device='cuda:0') tensor(2.7025e-06, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.587805
Average KL loss: 32.604979
Average total loss: 34.192782
tensor(-3.7460, device='cuda:0') tensor(0.2768, device='cuda:0') tensor(2.5103e-06, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.591291
Average KL loss: 30.269555
Average total loss: 31.860845
tensor(-3.8295, device='cuda:0') tensor(0.2842, device='cuda:0') tensor(2.3322e-06, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.580419
Average KL loss: 28.209792
Average total loss: 29.790210
tensor(-3.9088, device='cuda:0') tensor(0.2915, device='cuda:0') tensor(2.1660e-06, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.584884
Average KL loss: 26.382687
Average total loss: 27.967570
tensor(-3.9845, device='cuda:0') tensor(0.2986, device='cuda:0') tensor(2.0561e-06, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.580085
Average KL loss: 24.749367
Average total loss: 26.329452
tensor(-4.0569, device='cuda:0') tensor(0.3054, device='cuda:0') tensor(1.8867e-06, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.579630
Average KL loss: 23.284456
Average total loss: 24.864085
tensor(-4.1262, device='cuda:0') tensor(0.3121, device='cuda:0') tensor(1.8325e-06, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.587773
Average KL loss: 21.963372
Average total loss: 23.551145
tensor(-4.1928, device='cuda:0') tensor(0.3187, device='cuda:0') tensor(1.6858e-06, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.579465
Average KL loss: 20.766926
Average total loss: 22.346391
tensor(-4.2568, device='cuda:0') tensor(0.3252, device='cuda:0') tensor(1.6087e-06, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.570536
Average KL loss: 19.680012
Average total loss: 21.250548
tensor(-4.3185, device='cuda:0') tensor(0.3317, device='cuda:0') tensor(1.5143e-06, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.578422
Average KL loss: 18.689397
Average total loss: 20.267819
tensor(-4.3780, device='cuda:0') tensor(0.3380, device='cuda:0') tensor(1.4552e-06, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.568958
Average KL loss: 17.779877
Average total loss: 19.348834
tensor(-4.4356, device='cuda:0') tensor(0.3443, device='cuda:0') tensor(1.3709e-06, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.574608
Average KL loss: 16.946285
Average total loss: 18.520893
tensor(-4.4913, device='cuda:0') tensor(0.3505, device='cuda:0') tensor(1.3016e-06, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.585844
Average KL loss: 16.179137
Average total loss: 17.764980
tensor(-4.5452, device='cuda:0') tensor(0.3568, device='cuda:0') tensor(1.2468e-06, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.579765
Average KL loss: 15.470410
Average total loss: 17.050174
tensor(-4.5976, device='cuda:0') tensor(0.3629, device='cuda:0') tensor(1.1891e-06, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.565208
Average KL loss: 14.813815
Average total loss: 16.379023
tensor(-4.6485, device='cuda:0') tensor(0.3690, device='cuda:0') tensor(1.1289e-06, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.575472
Average KL loss: 14.204426
Average total loss: 15.779897
tensor(-4.6979, device='cuda:0') tensor(0.3751, device='cuda:0') tensor(1.0992e-06, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.556956
Average KL loss: 13.637322
Average total loss: 15.194278
tensor(-4.7461, device='cuda:0') tensor(0.3811, device='cuda:0') tensor(1.0640e-06, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.582010
Average KL loss: 13.107720
Average total loss: 14.689729
tensor(-4.7931, device='cuda:0') tensor(0.3871, device='cuda:0') tensor(1.0024e-06, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.577257
Average KL loss: 12.613755
Average total loss: 14.191011
tensor(-4.8390, device='cuda:0') tensor(0.3931, device='cuda:0') tensor(9.5104e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.577551
Average KL loss: 12.150977
Average total loss: 13.728528
tensor(-4.8837, device='cuda:0') tensor(0.3992, device='cuda:0') tensor(9.0284e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.563848
Average KL loss: 11.718181
Average total loss: 13.282029
tensor(-4.9274, device='cuda:0') tensor(0.4052, device='cuda:0') tensor(9.1835e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.561221
Average KL loss: 11.311717
Average total loss: 12.872938
tensor(-4.9702, device='cuda:0') tensor(0.4112, device='cuda:0') tensor(8.6293e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.546134
Average KL loss: 10.928841
Average total loss: 12.474975
tensor(-5.0120, device='cuda:0') tensor(0.4172, device='cuda:0') tensor(8.2099e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.536811
Average KL loss: 10.567259
Average total loss: 12.104069
tensor(-5.0530, device='cuda:0') tensor(0.4231, device='cuda:0') tensor(8.0922e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.541069
Average KL loss: 10.225803
Average total loss: 11.766871
tensor(-5.0932, device='cuda:0') tensor(0.4290, device='cuda:0') tensor(7.7869e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.544426
Average KL loss: 9.903213
Average total loss: 11.447639
tensor(-5.1326, device='cuda:0') tensor(0.4350, device='cuda:0') tensor(7.5688e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.550940
Average KL loss: 9.597365
Average total loss: 11.148305
tensor(-5.1713, device='cuda:0') tensor(0.4409, device='cuda:0') tensor(7.1251e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.526121
Average KL loss: 9.307832
Average total loss: 10.833953
tensor(-5.2093, device='cuda:0') tensor(0.4469, device='cuda:0') tensor(6.9853e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.528410
Average KL loss: 9.032831
Average total loss: 10.561241
tensor(-5.2467, device='cuda:0') tensor(0.4527, device='cuda:0') tensor(6.8619e-07, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.549271
Average KL loss: 8.771377
Average total loss: 10.320648
tensor(-5.2834, device='cuda:0') tensor(0.4587, device='cuda:0') tensor(6.5885e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.523916
Average KL loss: 8.522767
Average total loss: 10.046683
tensor(-5.3195, device='cuda:0') tensor(0.4646, device='cuda:0') tensor(6.6967e-07, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.511209
Average KL loss: 8.285485
Average total loss: 9.796694
tensor(-5.3551, device='cuda:0') tensor(0.4705, device='cuda:0') tensor(6.2660e-07, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.529004
Average KL loss: 8.059499
Average total loss: 9.588503
tensor(-5.3901, device='cuda:0') tensor(0.4765, device='cuda:0') tensor(5.9948e-07, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.514446
Average KL loss: 7.844027
Average total loss: 9.358473
tensor(-5.4247, device='cuda:0') tensor(0.4824, device='cuda:0') tensor(5.6387e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.499398
Average KL loss: 7.637510
Average total loss: 9.136908
tensor(-5.4587, device='cuda:0') tensor(0.4882, device='cuda:0') tensor(5.6308e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.519606
Average KL loss: 7.439900
Average total loss: 8.959506
tensor(-5.4923, device='cuda:0') tensor(0.4941, device='cuda:0') tensor(5.4653e-07, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.497700
Average KL loss: 7.250867
Average total loss: 8.748567
tensor(-5.5254, device='cuda:0') tensor(0.5000, device='cuda:0') tensor(5.3785e-07, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.490128
Average KL loss: 7.070078
Average total loss: 8.560206
tensor(-5.5581, device='cuda:0') tensor(0.5059, device='cuda:0') tensor(5.2794e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.510130
Average KL loss: 6.896487
Average total loss: 8.406617
tensor(-5.5904, device='cuda:0') tensor(0.5118, device='cuda:0') tensor(5.0188e-07, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.494731
Average KL loss: 6.729733
Average total loss: 8.224463
tensor(-5.6223, device='cuda:0') tensor(0.5177, device='cuda:0') tensor(5.1912e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.489769
Average KL loss: 6.570016
Average total loss: 8.059786
tensor(-5.6538, device='cuda:0') tensor(0.5237, device='cuda:0') tensor(5.0867e-07, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.487566
Average KL loss: 6.416513
Average total loss: 7.904079
tensor(-5.6850, device='cuda:0') tensor(0.5296, device='cuda:0') tensor(4.7016e-07, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.487336
Average KL loss: 6.268661
Average total loss: 7.755997
tensor(-5.7158, device='cuda:0') tensor(0.5355, device='cuda:0') tensor(4.6325e-07, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.490617
Average KL loss: 6.126600
Average total loss: 7.617217
tensor(-5.7463, device='cuda:0') tensor(0.5415, device='cuda:0') tensor(4.4262e-07, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.475734
Average KL loss: 5.989728
Average total loss: 7.465462
tensor(-5.7764, device='cuda:0') tensor(0.5474, device='cuda:0') tensor(4.1620e-07, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.493400
Average KL loss: 5.857685
Average total loss: 7.351085
tensor(-5.8063, device='cuda:0') tensor(0.5534, device='cuda:0') tensor(4.4399e-07, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.469716
Average KL loss: 5.730242
Average total loss: 7.199958
tensor(-5.8358, device='cuda:0') tensor(0.5593, device='cuda:0') tensor(4.2083e-07, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.462749
Average KL loss: 5.607360
Average total loss: 7.070109
tensor(-5.8651, device='cuda:0') tensor(0.5653, device='cuda:0') tensor(4.1261e-07, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.461835
Average KL loss: 5.488711
Average total loss: 6.950546
tensor(-5.8941, device='cuda:0') tensor(0.5713, device='cuda:0') tensor(3.9879e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.460109
Average KL loss: 5.373491
Average total loss: 6.833600
tensor(-5.9229, device='cuda:0') tensor(0.5772, device='cuda:0') tensor(3.8723e-07, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.457188
Average KL loss: 5.262430
Average total loss: 6.719618
tensor(-5.9514, device='cuda:0') tensor(0.5832, device='cuda:0') tensor(3.6154e-07, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.463229
Average KL loss: 5.155459
Average total loss: 6.618688
tensor(-5.9797, device='cuda:0') tensor(0.5893, device='cuda:0') tensor(3.7609e-07, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.459733
Average KL loss: 5.052136
Average total loss: 6.511869
tensor(-6.0077, device='cuda:0') tensor(0.5953, device='cuda:0') tensor(3.3512e-07, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.452112
Average KL loss: 4.952350
Average total loss: 6.404462
tensor(-6.0355, device='cuda:0') tensor(0.6014, device='cuda:0') tensor(3.5562e-07, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.439267
Average KL loss: 4.855267
Average total loss: 6.294534
tensor(-6.0630, device='cuda:0') tensor(0.6075, device='cuda:0') tensor(3.7348e-07, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.450869
Average KL loss: 4.760955
Average total loss: 6.211824
tensor(-6.0904, device='cuda:0') tensor(0.6136, device='cuda:0') tensor(3.3594e-07, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.435716
Average KL loss: 4.669782
Average total loss: 6.105498
tensor(-6.1176, device='cuda:0') tensor(0.6197, device='cuda:0') tensor(3.3689e-07, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.448750
Average KL loss: 4.581601
Average total loss: 6.030351
tensor(-6.1446, device='cuda:0') tensor(0.6258, device='cuda:0') tensor(3.4426e-07, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.441551
Average KL loss: 4.495575
Average total loss: 5.937126
tensor(-6.1714, device='cuda:0') tensor(0.6319, device='cuda:0') tensor(3.2885e-07, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.417984
Average KL loss: 4.412183
Average total loss: 5.830166
tensor(-6.1980, device='cuda:0') tensor(0.6380, device='cuda:0') tensor(3.0801e-07, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.427829
Average KL loss: 4.331180
Average total loss: 5.759009
tensor(-6.2245, device='cuda:0') tensor(0.6441, device='cuda:0') tensor(3.3006e-07, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.428890
Average KL loss: 4.252719
Average total loss: 5.681608
tensor(-6.2508, device='cuda:0') tensor(0.6503, device='cuda:0') tensor(2.8939e-07, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.416177
Average KL loss: 4.176339
Average total loss: 5.592516
tensor(-6.2769, device='cuda:0') tensor(0.6565, device='cuda:0') tensor(2.9492e-07, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.415113
Average KL loss: 4.102161
Average total loss: 5.517274
tensor(-6.3029, device='cuda:0') tensor(0.6627, device='cuda:0') tensor(2.8774e-07, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.412947
Average KL loss: 4.029691
Average total loss: 5.442639
tensor(-6.3287, device='cuda:0') tensor(0.6688, device='cuda:0') tensor(2.8346e-07, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.414844
Average KL loss: 3.959614
Average total loss: 5.374458
tensor(-6.3544, device='cuda:0') tensor(0.6751, device='cuda:0') tensor(2.9148e-07, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.409013
Average KL loss: 3.891403
Average total loss: 5.300416
tensor(-6.3799, device='cuda:0') tensor(0.6813, device='cuda:0') tensor(2.6312e-07, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.398938
Average KL loss: 3.824878
Average total loss: 5.223817
tensor(-6.4054, device='cuda:0') tensor(0.6875, device='cuda:0') tensor(2.5958e-07, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.394064
Average KL loss: 3.759690
Average total loss: 5.153755
tensor(-6.4307, device='cuda:0') tensor(0.6938, device='cuda:0') tensor(2.6650e-07, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.411548
Average KL loss: 3.696754
Average total loss: 5.108302
tensor(-6.4558, device='cuda:0') tensor(0.7001, device='cuda:0') tensor(2.5542e-07, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.390093
Average KL loss: 3.635545
Average total loss: 5.025638
tensor(-6.4809, device='cuda:0') tensor(0.7063, device='cuda:0') tensor(2.6010e-07, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.400198
Average KL loss: 3.575193
Average total loss: 4.975391
tensor(-6.5058, device='cuda:0') tensor(0.7126, device='cuda:0') tensor(2.3601e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.381594
Average KL loss: 3.516799
Average total loss: 4.898393
tensor(-6.5306, device='cuda:0') tensor(0.7190, device='cuda:0') tensor(2.3741e-07, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.384941
Average KL loss: 3.459704
Average total loss: 4.844645
tensor(-6.5553, device='cuda:0') tensor(0.7253, device='cuda:0') tensor(2.3907e-07, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.385717
Average KL loss: 3.403772
Average total loss: 4.789489
tensor(-6.5800, device='cuda:0') tensor(0.7316, device='cuda:0') tensor(2.3433e-07, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.386409
Average KL loss: 3.349192
Average total loss: 4.735601
tensor(-6.6045, device='cuda:0') tensor(0.7379, device='cuda:0') tensor(2.4686e-07, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.376168
Average KL loss: 3.296326
Average total loss: 4.672494
tensor(-6.6289, device='cuda:0') tensor(0.7443, device='cuda:0') tensor(2.3489e-07, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.377475
Average KL loss: 3.244446
Average total loss: 4.621921
tensor(-6.6532, device='cuda:0') tensor(0.7507, device='cuda:0') tensor(1.9913e-07, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.388670
Average KL loss: 3.193969
Average total loss: 4.582639
tensor(-6.6774, device='cuda:0') tensor(0.7571, device='cuda:0') tensor(2.0614e-07, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.379600
Average KL loss: 3.145048
Average total loss: 4.524649
tensor(-6.7016, device='cuda:0') tensor(0.7636, device='cuda:0') tensor(2.1460e-07, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.382124
Average KL loss: 3.097313
Average total loss: 4.479436
tensor(-6.7257, device='cuda:0') tensor(0.7701, device='cuda:0') tensor(1.9312e-07, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.373813
Average KL loss: 3.050732
Average total loss: 4.424545
tensor(-6.7496, device='cuda:0') tensor(0.7766, device='cuda:0') tensor(2.0175e-07, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.364700
Average KL loss: 3.004871
Average total loss: 4.369571
tensor(-6.7736, device='cuda:0') tensor(0.7831, device='cuda:0') tensor(2.0606e-07, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.359124
Average KL loss: 2.960021
Average total loss: 4.319145
tensor(-6.7974, device='cuda:0') tensor(0.7896, device='cuda:0') tensor(1.9031e-07, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.352006
Average KL loss: 2.916201
Average total loss: 4.268206
tensor(-6.8212, device='cuda:0') tensor(0.7961, device='cuda:0') tensor(1.7961e-07, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.361599
Average KL loss: 2.873423
Average total loss: 4.235022
tensor(-6.8448, device='cuda:0') tensor(0.8027, device='cuda:0') tensor(2.0171e-07, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.350057
Average KL loss: 2.831493
Average total loss: 4.181550
tensor(-6.8685, device='cuda:0') tensor(0.8092, device='cuda:0') tensor(1.9168e-07, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.352241
Average KL loss: 2.790439
Average total loss: 4.142680
tensor(-6.8920, device='cuda:0') tensor(0.8158, device='cuda:0') tensor(1.8576e-07, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.347856
Average KL loss: 2.750317
Average total loss: 4.098173
tensor(-6.9156, device='cuda:0') tensor(0.8223, device='cuda:0') tensor(1.7166e-07, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.351826
Average KL loss: 2.710990
Average total loss: 4.062816
tensor(-6.9390, device='cuda:0') tensor(0.8289, device='cuda:0') tensor(1.6826e-07, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.344304
Average KL loss: 2.672448
Average total loss: 4.016752
tensor(-6.9624, device='cuda:0') tensor(0.8355, device='cuda:0') tensor(1.8527e-07, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.340020
Average KL loss: 2.634711
Average total loss: 3.974731
tensor(-6.9857, device='cuda:0') tensor(0.8421, device='cuda:0') tensor(1.6175e-07, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.346052
Average KL loss: 2.597991
Average total loss: 3.944042
tensor(-7.0090, device='cuda:0') tensor(0.8488, device='cuda:0') tensor(1.5984e-07, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.333556
Average KL loss: 2.561823
Average total loss: 3.895379
tensor(-7.0322, device='cuda:0') tensor(0.8555, device='cuda:0') tensor(1.6393e-07, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.332045
Average KL loss: 2.526310
Average total loss: 3.858356
tensor(-7.0554, device='cuda:0') tensor(0.8621, device='cuda:0') tensor(1.6827e-07, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.330346
Average KL loss: 2.491791
Average total loss: 3.822137
tensor(-7.0785, device='cuda:0') tensor(0.8688, device='cuda:0') tensor(1.6414e-07, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.321500
Average KL loss: 2.457633
Average total loss: 3.779133
tensor(-7.1016, device='cuda:0') tensor(0.8755, device='cuda:0') tensor(1.6436e-07, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.332411
Average KL loss: 2.424217
Average total loss: 3.756628
tensor(-7.1247, device='cuda:0') tensor(0.8822, device='cuda:0') tensor(1.5697e-07, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.331179
Average KL loss: 2.391587
Average total loss: 3.722766
tensor(-7.1477, device='cuda:0') tensor(0.8890, device='cuda:0') tensor(1.4757e-07, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.317691
Average KL loss: 2.359699
Average total loss: 3.677390
tensor(-7.1706, device='cuda:0') tensor(0.8958, device='cuda:0') tensor(1.4625e-07, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.316484
Average KL loss: 2.328370
Average total loss: 3.644854
tensor(-7.1936, device='cuda:0') tensor(0.9025, device='cuda:0') tensor(1.5060e-07, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.313559
Average KL loss: 2.297787
Average total loss: 3.611346
tensor(-7.2164, device='cuda:0') tensor(0.9093, device='cuda:0') tensor(1.2416e-07, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.311324
Average KL loss: 2.267571
Average total loss: 3.578895
tensor(-7.2393, device='cuda:0') tensor(0.9161, device='cuda:0') tensor(1.4065e-07, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.312370
Average KL loss: 2.238117
Average total loss: 3.550487
tensor(-7.2621, device='cuda:0') tensor(0.9229, device='cuda:0') tensor(1.4876e-07, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.296377
Average KL loss: 2.209391
Average total loss: 3.505768
tensor(-7.2849, device='cuda:0') tensor(0.9297, device='cuda:0') tensor(1.3756e-07, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.302992
Average KL loss: 2.180977
Average total loss: 3.483968
tensor(-7.3076, device='cuda:0') tensor(0.9365, device='cuda:0') tensor(1.4016e-07, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.297431
Average KL loss: 2.153043
Average total loss: 3.450474
tensor(-7.3304, device='cuda:0') tensor(0.9434, device='cuda:0') tensor(1.4301e-07, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.300767
Average KL loss: 2.125673
Average total loss: 3.426440
tensor(-7.3531, device='cuda:0') tensor(0.9502, device='cuda:0') tensor(1.3386e-07, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.297690
Average KL loss: 2.098996
Average total loss: 3.396686
tensor(-7.3757, device='cuda:0') tensor(0.9571, device='cuda:0') tensor(1.2699e-07, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.293029
Average KL loss: 2.072754
Average total loss: 3.365783
tensor(-7.3984, device='cuda:0') tensor(0.9640, device='cuda:0') tensor(1.3035e-07, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.289112
Average KL loss: 2.046815
Average total loss: 3.335927
tensor(-7.4210, device='cuda:0') tensor(0.9708, device='cuda:0') tensor(1.1916e-07, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.291491
Average KL loss: 2.021397
Average total loss: 3.312888
tensor(-7.4436, device='cuda:0') tensor(0.9777, device='cuda:0') tensor(1.2732e-07, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.289855
Average KL loss: 1.996377
Average total loss: 3.286232
tensor(-7.4661, device='cuda:0') tensor(0.9846, device='cuda:0') tensor(1.1959e-07, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.287994
Average KL loss: 1.971733
Average total loss: 3.259728
tensor(-7.4887, device='cuda:0') tensor(0.9915, device='cuda:0') tensor(1.1639e-07, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.279029
Average KL loss: 1.947688
Average total loss: 3.226717
tensor(-7.5112, device='cuda:0') tensor(0.9984, device='cuda:0') tensor(1.2256e-07, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.276267
Average KL loss: 1.923976
Average total loss: 3.200243
tensor(-7.5337, device='cuda:0') tensor(1.0053, device='cuda:0') tensor(1.2381e-07, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.281280
Average KL loss: 1.900865
Average total loss: 3.182145
tensor(-7.5562, device='cuda:0') tensor(1.0123, device='cuda:0') tensor(1.1976e-07, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.274036
Average KL loss: 1.878064
Average total loss: 3.152100
tensor(-7.5786, device='cuda:0') tensor(1.0192, device='cuda:0') tensor(1.1350e-07, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.268178
Average KL loss: 1.855714
Average total loss: 3.123892
tensor(-7.6011, device='cuda:0') tensor(1.0261, device='cuda:0') tensor(1.1474e-07, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.263099
Average KL loss: 1.833744
Average total loss: 3.096844
tensor(-7.6235, device='cuda:0') tensor(1.0331, device='cuda:0') tensor(1.0422e-07, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.267380
Average KL loss: 1.812298
Average total loss: 3.079678
tensor(-7.6459, device='cuda:0') tensor(1.0401, device='cuda:0') tensor(1.1119e-07, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.264497
Average KL loss: 1.790933
Average total loss: 3.055430
tensor(-7.6684, device='cuda:0') tensor(1.0470, device='cuda:0') tensor(1.1153e-07, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.273731
Average KL loss: 1.770080
Average total loss: 3.043810
tensor(-7.6907, device='cuda:0') tensor(1.0540, device='cuda:0') tensor(1.0899e-07, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.258840
Average KL loss: 1.749805
Average total loss: 3.008646
tensor(-7.7131, device='cuda:0') tensor(1.0610, device='cuda:0') tensor(1.0274e-07, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.260984
Average KL loss: 1.729587
Average total loss: 2.990571
tensor(-7.7355, device='cuda:0') tensor(1.0679, device='cuda:0') tensor(9.9608e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.260642
Average KL loss: 1.709765
Average total loss: 2.970407
tensor(-7.7578, device='cuda:0') tensor(1.0749, device='cuda:0') tensor(1.0078e-07, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.260533
Average KL loss: 1.690173
Average total loss: 2.950706
tensor(-7.7802, device='cuda:0') tensor(1.0818, device='cuda:0') tensor(9.7399e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.250902
Average KL loss: 1.670894
Average total loss: 2.921795
tensor(-7.8025, device='cuda:0') tensor(1.0888, device='cuda:0') tensor(9.6639e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.255291
Average KL loss: 1.652152
Average total loss: 2.907443
tensor(-7.8248, device='cuda:0') tensor(1.0958, device='cuda:0') tensor(9.7757e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.245238
Average KL loss: 1.633624
Average total loss: 2.878863
tensor(-7.8471, device='cuda:0') tensor(1.1028, device='cuda:0') tensor(9.5869e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.247796
Average KL loss: 1.615393
Average total loss: 2.863189
tensor(-7.8694, device='cuda:0') tensor(1.1098, device='cuda:0') tensor(8.1961e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.246943
Average KL loss: 1.597598
Average total loss: 2.844541
tensor(-7.8917, device='cuda:0') tensor(1.1168, device='cuda:0') tensor(9.0555e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.235077
Average KL loss: 1.579789
Average total loss: 2.814865
tensor(-7.9140, device='cuda:0') tensor(1.1238, device='cuda:0') tensor(9.7662e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.238692
Average KL loss: 1.562423
Average total loss: 2.801114
tensor(-7.9362, device='cuda:0') tensor(1.1308, device='cuda:0') tensor(8.5140e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.237088
Average KL loss: 1.545341
Average total loss: 2.782429
tensor(-7.9585, device='cuda:0') tensor(1.1377, device='cuda:0') tensor(9.1277e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.247135
Average KL loss: 1.528418
Average total loss: 2.775553
tensor(-7.9807, device='cuda:0') tensor(1.1448, device='cuda:0') tensor(9.1637e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.239452
Average KL loss: 1.512086
Average total loss: 2.751537
tensor(-8.0030, device='cuda:0') tensor(1.1518, device='cuda:0') tensor(8.6652e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.236436
Average KL loss: 1.495930
Average total loss: 2.732366
tensor(-8.0252, device='cuda:0') tensor(1.1587, device='cuda:0') tensor(8.8760e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.225737
Average KL loss: 1.479978
Average total loss: 2.705716
tensor(-8.0475, device='cuda:0') tensor(1.1657, device='cuda:0') tensor(7.7059e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.237241
Average KL loss: 1.464419
Average total loss: 2.701660
tensor(-8.0697, device='cuda:0') tensor(1.1727, device='cuda:0') tensor(8.1404e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.225147
Average KL loss: 1.448962
Average total loss: 2.674108
tensor(-8.0919, device='cuda:0') tensor(1.1797, device='cuda:0') tensor(7.8849e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.222808
Average KL loss: 1.433711
Average total loss: 2.656520
tensor(-8.1142, device='cuda:0') tensor(1.1866, device='cuda:0') tensor(8.3603e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.225244
Average KL loss: 1.418697
Average total loss: 2.643941
tensor(-8.1364, device='cuda:0') tensor(1.1936, device='cuda:0') tensor(7.0832e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.222496
Average KL loss: 1.403936
Average total loss: 2.626432
tensor(-8.1586, device='cuda:0') tensor(1.2005, device='cuda:0') tensor(7.7629e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.214218
Average KL loss: 1.389418
Average total loss: 2.603636
tensor(-8.1808, device='cuda:0') tensor(1.2074, device='cuda:0') tensor(8.6912e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.220190
Average KL loss: 1.374924
Average total loss: 2.595114
tensor(-8.2030, device='cuda:0') tensor(1.2143, device='cuda:0') tensor(7.2441e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.221915
Average KL loss: 1.360653
Average total loss: 2.582569
tensor(-8.2252, device='cuda:0') tensor(1.2212, device='cuda:0') tensor(5.9957e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.211357
Average KL loss: 1.346618
Average total loss: 2.557975
tensor(-8.2474, device='cuda:0') tensor(1.2281, device='cuda:0') tensor(7.3136e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.209435
Average KL loss: 1.333033
Average total loss: 2.542468
tensor(-8.2696, device='cuda:0') tensor(1.2351, device='cuda:0') tensor(6.8708e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.213394
Average KL loss: 1.319709
Average total loss: 2.533103
tensor(-8.2918, device='cuda:0') tensor(1.2419, device='cuda:0') tensor(6.7365e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.205229
Average KL loss: 1.306604
Average total loss: 2.511833
tensor(-8.3140, device='cuda:0') tensor(1.2488, device='cuda:0') tensor(7.2894e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.204724
Average KL loss: 1.293695
Average total loss: 2.498418
tensor(-8.3362, device='cuda:0') tensor(1.2557, device='cuda:0') tensor(7.0408e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.210171
Average KL loss: 1.280964
Average total loss: 2.491135
tensor(-8.3583, device='cuda:0') tensor(1.2626, device='cuda:0') tensor(7.1049e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.204633
Average KL loss: 1.268447
Average total loss: 2.473079
tensor(-8.3805, device='cuda:0') tensor(1.2694, device='cuda:0') tensor(6.8870e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 1.202632
Average KL loss: 1.256002
Average total loss: 2.458634
tensor(-8.4027, device='cuda:0') tensor(1.2763, device='cuda:0') tensor(5.9530e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.200381
Average KL loss: 1.243784
Average total loss: 2.444165
tensor(-8.4249, device='cuda:0') tensor(1.2831, device='cuda:0') tensor(6.7841e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.200722
Average KL loss: 1.231639
Average total loss: 2.432361
tensor(-8.4470, device='cuda:0') tensor(1.2899, device='cuda:0') tensor(6.2389e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 1.200030
Average KL loss: 1.219906
Average total loss: 2.419936
tensor(-8.4692, device='cuda:0') tensor(1.2966, device='cuda:0') tensor(5.8476e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 1.188695
Average KL loss: 1.208393
Average total loss: 2.397088
tensor(-8.4914, device='cuda:0') tensor(1.3034, device='cuda:0') tensor(6.4657e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 1.193055
Average KL loss: 1.196848
Average total loss: 2.389903
tensor(-8.5135, device='cuda:0') tensor(1.3101, device='cuda:0') tensor(7.0998e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 1.190461
Average KL loss: 1.185359
Average total loss: 2.375820
tensor(-8.5357, device='cuda:0') tensor(1.3168, device='cuda:0') tensor(5.3807e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 1.188153
Average KL loss: 1.174288
Average total loss: 2.362442
tensor(-8.5578, device='cuda:0') tensor(1.3235, device='cuda:0') tensor(6.2099e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 1.188094
Average KL loss: 1.163338
Average total loss: 2.351431
tensor(-8.5800, device='cuda:0') tensor(1.3302, device='cuda:0') tensor(5.7722e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 1.184146
Average KL loss: 1.152494
Average total loss: 2.336640
tensor(-8.6021, device='cuda:0') tensor(1.3369, device='cuda:0') tensor(5.4931e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 1.182247
Average KL loss: 1.141857
Average total loss: 2.324103
tensor(-8.6243, device='cuda:0') tensor(1.3435, device='cuda:0') tensor(5.6091e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 1.185638
Average KL loss: 1.131251
Average total loss: 2.316888
tensor(-8.6464, device='cuda:0') tensor(1.3502, device='cuda:0') tensor(5.1199e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 1.183925
Average KL loss: 1.120908
Average total loss: 2.304833
tensor(-8.6686, device='cuda:0') tensor(1.3568, device='cuda:0') tensor(5.4298e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 1.182517
Average KL loss: 1.110602
Average total loss: 2.293120
tensor(-8.6907, device='cuda:0') tensor(1.3633, device='cuda:0') tensor(5.6832e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 1.185745
Average KL loss: 1.100625
Average total loss: 2.286370
tensor(-8.7129, device='cuda:0') tensor(1.3699, device='cuda:0') tensor(5.7266e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 1.173311
Average KL loss: 1.090802
Average total loss: 2.264113
tensor(-8.7350, device='cuda:0') tensor(1.3765, device='cuda:0') tensor(4.5257e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 1.176157
Average KL loss: 1.081178
Average total loss: 2.257335
tensor(-8.7571, device='cuda:0') tensor(1.3830, device='cuda:0') tensor(5.9118e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 1.172194
Average KL loss: 1.071603
Average total loss: 2.243798
tensor(-8.7792, device='cuda:0') tensor(1.3895, device='cuda:0') tensor(4.4333e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 1.172210
Average KL loss: 1.062140
Average total loss: 2.234350
tensor(-8.8014, device='cuda:0') tensor(1.3960, device='cuda:0') tensor(4.6984e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 1.169512
Average KL loss: 1.052858
Average total loss: 2.222370
tensor(-8.8235, device='cuda:0') tensor(1.4024, device='cuda:0') tensor(4.8201e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 1.170815
Average KL loss: 1.043754
Average total loss: 2.214569
tensor(-8.8456, device='cuda:0') tensor(1.4088, device='cuda:0') tensor(4.5250e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 1.169569
Average KL loss: 1.034784
Average total loss: 2.204353
tensor(-8.8677, device='cuda:0') tensor(1.4151, device='cuda:0') tensor(4.5663e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 1.165047
Average KL loss: 1.026023
Average total loss: 2.191069
tensor(-8.8898, device='cuda:0') tensor(1.4215, device='cuda:0') tensor(4.0924e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 1.161872
Average KL loss: 1.017324
Average total loss: 2.179197
tensor(-8.9119, device='cuda:0') tensor(1.4278, device='cuda:0') tensor(4.4087e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 1.167329
Average KL loss: 1.008864
Average total loss: 2.176192
tensor(-8.9340, device='cuda:0') tensor(1.4341, device='cuda:0') tensor(4.0183e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 1.158160
Average KL loss: 1.000552
Average total loss: 2.158712
tensor(-8.9561, device='cuda:0') tensor(1.4403, device='cuda:0') tensor(3.8633e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 1.162211
Average KL loss: 0.992292
Average total loss: 2.154503
tensor(-8.9782, device='cuda:0') tensor(1.4466, device='cuda:0') tensor(4.3614e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 1.157788
Average KL loss: 0.984245
Average total loss: 2.142033
tensor(-9.0003, device='cuda:0') tensor(1.4527, device='cuda:0') tensor(4.8463e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 1.158468
Average KL loss: 0.976185
Average total loss: 2.134653
 Percentile value: -7.194488048553468
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1708 /    1728             ( 98.84%) | total_pruned =      20 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   31235 /   36864             ( 84.73%) | total_pruned =    5629 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   31425 /   36864             ( 85.25%) | total_pruned =    5439 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   29640 /   36864             ( 80.40%) | total_pruned =    7224 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   28780 /   36864             ( 78.07%) | total_pruned =    8084 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   59002 /   73728             ( 80.03%) | total_pruned =   14726 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  104286 /  147456             ( 70.72%) | total_pruned =   43170 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7652 /    8192             ( 93.41%) | total_pruned =     540 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   94817 /  147456             ( 64.30%) | total_pruned =   52639 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   90403 /  147456             ( 61.31%) | total_pruned =   57053 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  176795 /  294912             ( 59.95%) | total_pruned =  118117 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  266063 /  589824             ( 45.11%) | total_pruned =  323761 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   26834 /   32768             ( 81.89%) | total_pruned =    5934 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  166672 /  589824             ( 28.26%) | total_pruned =  423152 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  162273 /  589824             ( 27.51%) | total_pruned =  427551 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  377206 / 1179648             ( 31.98%) | total_pruned =  802442 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  532610 / 2359296             ( 22.57%) | total_pruned = 1826686 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   87814 /  131072             ( 67.00%) | total_pruned =   43258 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  497499 / 2359296             ( 21.09%) | total_pruned = 1861797 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  566308 / 2359296             ( 24.00%) | total_pruned = 1792988 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
linear.weight        | nonzeros =    5031 /    5120             ( 98.26%) | total_pruned =      89 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 39/200 Loss: 0.000004 Accuracy: 86.99 100.00 % Best test Accuracy: 86.99%
tensor(-9.0223, device='cuda:0') tensor(1.4589, device='cuda:0') tensor(5.1235e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.195458
Average KL loss: 0.894364
Average total loss: 2.089822
tensor(-9.2574, device='cuda:0') tensor(1.2716, device='cuda:0') tensor(3.9356e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.177495
Average KL loss: 0.798543
Average total loss: 1.976038
tensor(-9.4553, device='cuda:0') tensor(1.1539, device='cuda:0') tensor(2.2167e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.175242
Average KL loss: 0.745514
Average total loss: 1.920756
tensor(-9.6243, device='cuda:0') tensor(1.0755, device='cuda:0') tensor(2.9016e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.170382
Average KL loss: 0.711392
Average total loss: 1.881773
tensor(-9.7721, device='cuda:0') tensor(1.0202, device='cuda:0') tensor(1.6361e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.162795
Average KL loss: 0.687490
Average total loss: 1.850285
tensor(-9.9035, device='cuda:0') tensor(0.9795, device='cuda:0') tensor(2.5720e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.166202
Average KL loss: 0.669390
Average total loss: 1.835592
tensor(-10.0218, device='cuda:0') tensor(0.9485, device='cuda:0') tensor(1.8092e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.161047
Average KL loss: 0.655148
Average total loss: 1.816196
tensor(-10.1295, device='cuda:0') tensor(0.9245, device='cuda:0') tensor(2.2305e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.152370
Average KL loss: 0.643579
Average total loss: 1.795949
tensor(-10.2282, device='cuda:0') tensor(0.9056, device='cuda:0') tensor(1.3956e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.157891
Average KL loss: 0.633871
Average total loss: 1.791762
tensor(-10.3194, device='cuda:0') tensor(0.8904, device='cuda:0') tensor(1.7727e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.155231
Average KL loss: 0.625716
Average total loss: 1.780947
tensor(-10.4042, device='cuda:0') tensor(0.8780, device='cuda:0') tensor(9.5044e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.154560
Average KL loss: 0.618515
Average total loss: 1.773074
tensor(-10.4834, device='cuda:0') tensor(0.8678, device='cuda:0') tensor(1.2057e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.144647
Average KL loss: 0.612140
Average total loss: 1.756787
tensor(-10.5577, device='cuda:0') tensor(0.8594, device='cuda:0') tensor(1.2763e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.146393
Average KL loss: 0.606533
Average total loss: 1.752926
tensor(-10.6277, device='cuda:0') tensor(0.8524, device='cuda:0') tensor(1.2091e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.147700
Average KL loss: 0.601626
Average total loss: 1.749326
tensor(-10.6938, device='cuda:0') tensor(0.8464, device='cuda:0') tensor(1.3318e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.145586
Average KL loss: 0.597129
Average total loss: 1.742715
tensor(-10.7565, device='cuda:0') tensor(0.8415, device='cuda:0') tensor(1.2665e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.139858
Average KL loss: 0.592953
Average total loss: 1.732811
tensor(-10.8161, device='cuda:0') tensor(0.8372, device='cuda:0') tensor(9.7833e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.134873
Average KL loss: 0.589060
Average total loss: 1.723933
tensor(-10.8729, device='cuda:0') tensor(0.8335, device='cuda:0') tensor(6.3172e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.144207
Average KL loss: 0.585409
Average total loss: 1.729617
tensor(-10.9272, device='cuda:0') tensor(0.8304, device='cuda:0') tensor(9.9706e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.138193
Average KL loss: 0.582001
Average total loss: 1.720194
tensor(-10.9791, device='cuda:0') tensor(0.8278, device='cuda:0') tensor(9.6272e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.138726
Average KL loss: 0.578787
Average total loss: 1.717512
tensor(-11.0289, device='cuda:0') tensor(0.8254, device='cuda:0') tensor(9.7364e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.133019
Average KL loss: 0.575724
Average total loss: 1.708743
tensor(-11.0767, device='cuda:0') tensor(0.8234, device='cuda:0') tensor(1.1222e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.131467
Average KL loss: 0.572866
Average total loss: 1.704333
tensor(-11.1227, device='cuda:0') tensor(0.8216, device='cuda:0') tensor(1.2184e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.127132
Average KL loss: 0.570122
Average total loss: 1.697255
tensor(-11.1671, device='cuda:0') tensor(0.8201, device='cuda:0') tensor(1.1012e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.126177
Average KL loss: 0.567462
Average total loss: 1.693639
tensor(-11.2098, device='cuda:0') tensor(0.8188, device='cuda:0') tensor(6.5125e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.127611
Average KL loss: 0.564887
Average total loss: 1.692498
tensor(-11.2511, device='cuda:0') tensor(0.8176, device='cuda:0') tensor(1.1039e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.128448
Average KL loss: 0.562585
Average total loss: 1.691032
tensor(-11.2911, device='cuda:0') tensor(0.8166, device='cuda:0') tensor(7.3171e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.121675
Average KL loss: 0.560296
Average total loss: 1.681971
tensor(-11.3298, device='cuda:0') tensor(0.8157, device='cuda:0') tensor(1.4605e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.117916
Average KL loss: 0.558054
Average total loss: 1.675970
tensor(-11.3673, device='cuda:0') tensor(0.8149, device='cuda:0') tensor(1.3077e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.117849
Average KL loss: 0.555874
Average total loss: 1.673724
tensor(-11.4036, device='cuda:0') tensor(0.8141, device='cuda:0') tensor(4.1660e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.118805
Average KL loss: 0.553841
Average total loss: 1.672647
tensor(-11.4390, device='cuda:0') tensor(0.8135, device='cuda:0') tensor(1.3509e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.112213
Average KL loss: 0.551742
Average total loss: 1.663954
tensor(-11.4733, device='cuda:0') tensor(0.8129, device='cuda:0') tensor(1.0969e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.121095
Average KL loss: 0.549786
Average total loss: 1.670881
tensor(-11.5067, device='cuda:0') tensor(0.8124, device='cuda:0') tensor(4.3354e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.117114
Average KL loss: 0.547956
Average total loss: 1.665070
tensor(-11.5391, device='cuda:0') tensor(0.8120, device='cuda:0') tensor(8.9450e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.113810
Average KL loss: 0.546240
Average total loss: 1.660050
tensor(-11.5708, device='cuda:0') tensor(0.8115, device='cuda:0') tensor(1.1405e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.112389
Average KL loss: 0.544438
Average total loss: 1.656826
tensor(-11.6017, device='cuda:0') tensor(0.8111, device='cuda:0') tensor(6.3329e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.106452
Average KL loss: 0.542685
Average total loss: 1.649137
tensor(-11.6317, device='cuda:0') tensor(0.8107, device='cuda:0') tensor(1.1246e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.110831
Average KL loss: 0.540966
Average total loss: 1.651797
tensor(-11.6611, device='cuda:0') tensor(0.8104, device='cuda:0') tensor(7.6120e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.099294
Average KL loss: 0.539358
Average total loss: 1.638653
tensor(-11.6898, device='cuda:0') tensor(0.8101, device='cuda:0') tensor(8.2695e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.107059
Average KL loss: 0.537699
Average total loss: 1.644758
tensor(-11.7178, device='cuda:0') tensor(0.8098, device='cuda:0') tensor(9.4349e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.103653
Average KL loss: 0.536042
Average total loss: 1.639694
tensor(-11.7452, device='cuda:0') tensor(0.8095, device='cuda:0') tensor(1.1746e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.099349
Average KL loss: 0.534236
Average total loss: 1.633586
tensor(-11.7720, device='cuda:0') tensor(0.8092, device='cuda:0') tensor(9.5655e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.103548
Average KL loss: 0.532624
Average total loss: 1.636172
tensor(-11.7982, device='cuda:0') tensor(0.8089, device='cuda:0') tensor(1.3041e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.103589
Average KL loss: 0.531068
Average total loss: 1.634658
tensor(-11.8239, device='cuda:0') tensor(0.8086, device='cuda:0') tensor(4.2419e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.102642
Average KL loss: 0.529603
Average total loss: 1.632245
tensor(-11.8490, device='cuda:0') tensor(0.8083, device='cuda:0') tensor(7.0794e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.094784
Average KL loss: 0.528072
Average total loss: 1.622856
tensor(-11.8737, device='cuda:0') tensor(0.8080, device='cuda:0') tensor(4.6768e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.099437
Average KL loss: 0.526651
Average total loss: 1.626087
tensor(-11.8978, device='cuda:0') tensor(0.8078, device='cuda:0') tensor(5.4504e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.095037
Average KL loss: 0.525217
Average total loss: 1.620254
tensor(-11.9215, device='cuda:0') tensor(0.8075, device='cuda:0') tensor(3.4766e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.093399
Average KL loss: 0.523918
Average total loss: 1.617317
tensor(-11.9447, device='cuda:0') tensor(0.8072, device='cuda:0') tensor(1.8309e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.087943
Average KL loss: 0.522597
Average total loss: 1.610539
tensor(-11.9675, device='cuda:0') tensor(0.8069, device='cuda:0') tensor(1.2615e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.091407
Average KL loss: 0.521308
Average total loss: 1.612714
tensor(-11.9899, device='cuda:0') tensor(0.8066, device='cuda:0') tensor(8.6149e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.094044
Average KL loss: 0.520035
Average total loss: 1.614078
tensor(-12.0119, device='cuda:0') tensor(0.8063, device='cuda:0') tensor(1.2428e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.086383
Average KL loss: 0.518711
Average total loss: 1.605093
tensor(-12.0335, device='cuda:0') tensor(0.8060, device='cuda:0') tensor(8.3173e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.077145
Average KL loss: 0.517526
Average total loss: 1.594671
tensor(-12.0547, device='cuda:0') tensor(0.8057, device='cuda:0') tensor(1.0534e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.086098
Average KL loss: 0.516281
Average total loss: 1.602379
tensor(-12.0756, device='cuda:0') tensor(0.8054, device='cuda:0') tensor(6.6599e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.080639
Average KL loss: 0.515100
Average total loss: 1.595739
tensor(-12.0961, device='cuda:0') tensor(0.8051, device='cuda:0') tensor(1.5343e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.082053
Average KL loss: 0.513946
Average total loss: 1.595999
tensor(-12.1163, device='cuda:0') tensor(0.8048, device='cuda:0') tensor(6.0487e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.082006
Average KL loss: 0.512741
Average total loss: 1.594746
tensor(-12.1361, device='cuda:0') tensor(0.8044, device='cuda:0') tensor(6.9137e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.079956
Average KL loss: 0.511422
Average total loss: 1.591378
tensor(-12.1556, device='cuda:0') tensor(0.8040, device='cuda:0') tensor(5.6987e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.079774
Average KL loss: 0.510189
Average total loss: 1.589963
tensor(-12.1749, device='cuda:0') tensor(0.8037, device='cuda:0') tensor(7.3039e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.076840
Average KL loss: 0.509095
Average total loss: 1.585935
tensor(-12.1938, device='cuda:0') tensor(0.8033, device='cuda:0') tensor(7.7229e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.079853
Average KL loss: 0.507959
Average total loss: 1.587812
tensor(-12.2124, device='cuda:0') tensor(0.8030, device='cuda:0') tensor(6.1997e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.072407
Average KL loss: 0.506831
Average total loss: 1.579239
tensor(-12.2308, device='cuda:0') tensor(0.8026, device='cuda:0') tensor(2.9624e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.076686
Average KL loss: 0.505697
Average total loss: 1.582383
tensor(-12.2488, device='cuda:0') tensor(0.8022, device='cuda:0') tensor(9.5602e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.075250
Average KL loss: 0.504648
Average total loss: 1.579899
tensor(-12.2667, device='cuda:0') tensor(0.8018, device='cuda:0') tensor(6.3116e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.073714
Average KL loss: 0.503664
Average total loss: 1.577378
tensor(-12.2842, device='cuda:0') tensor(0.8014, device='cuda:0') tensor(2.7476e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.070170
Average KL loss: 0.502616
Average total loss: 1.572786
tensor(-12.3015, device='cuda:0') tensor(0.8009, device='cuda:0') tensor(8.7046e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.068757
Average KL loss: 0.501577
Average total loss: 1.570334
tensor(-12.3186, device='cuda:0') tensor(0.8005, device='cuda:0') tensor(4.3124e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.068651
Average KL loss: 0.500580
Average total loss: 1.569232
tensor(-12.3354, device='cuda:0') tensor(0.8001, device='cuda:0') tensor(3.6052e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.062358
Average KL loss: 0.499473
Average total loss: 1.561831
tensor(-12.3520, device='cuda:0') tensor(0.7996, device='cuda:0') tensor(7.7493e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.064123
Average KL loss: 0.498447
Average total loss: 1.562570
tensor(-12.3684, device='cuda:0') tensor(0.7991, device='cuda:0') tensor(4.1435e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.064578
Average KL loss: 0.497469
Average total loss: 1.562047
tensor(-12.3845, device='cuda:0') tensor(0.7986, device='cuda:0') tensor(1.2730e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.061044
Average KL loss: 0.496403
Average total loss: 1.557447
tensor(-12.4005, device='cuda:0') tensor(0.7981, device='cuda:0') tensor(4.8648e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.061157
Average KL loss: 0.495357
Average total loss: 1.556515
tensor(-12.4162, device='cuda:0') tensor(0.7976, device='cuda:0') tensor(1.2143e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.062080
Average KL loss: 0.494313
Average total loss: 1.556393
tensor(-12.4318, device='cuda:0') tensor(0.7970, device='cuda:0') tensor(1.1302e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.057628
Average KL loss: 0.493297
Average total loss: 1.550925
tensor(-12.4471, device='cuda:0') tensor(0.7965, device='cuda:0') tensor(4.3976e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.056531
Average KL loss: 0.492396
Average total loss: 1.548927
tensor(-12.4622, device='cuda:0') tensor(0.7960, device='cuda:0') tensor(9.2169e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.057426
Average KL loss: 0.491396
Average total loss: 1.548822
tensor(-12.4772, device='cuda:0') tensor(0.7954, device='cuda:0') tensor(4.1333e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.055904
Average KL loss: 0.490327
Average total loss: 1.546232
tensor(-12.4920, device='cuda:0') tensor(0.7948, device='cuda:0') tensor(4.4405e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.050913
Average KL loss: 0.489349
Average total loss: 1.540261
tensor(-12.5066, device='cuda:0') tensor(0.7942, device='cuda:0') tensor(5.2790e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.053237
Average KL loss: 0.488428
Average total loss: 1.541665
tensor(-12.5210, device='cuda:0') tensor(0.7936, device='cuda:0') tensor(5.8520e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.057558
Average KL loss: 0.487446
Average total loss: 1.545004
tensor(-12.5353, device='cuda:0') tensor(0.7929, device='cuda:0') tensor(6.1162e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.051883
Average KL loss: 0.486566
Average total loss: 1.538449
tensor(-12.5493, device='cuda:0') tensor(0.7924, device='cuda:0') tensor(7.9586e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.054547
Average KL loss: 0.485763
Average total loss: 1.540310
tensor(-12.5633, device='cuda:0') tensor(0.7917, device='cuda:0') tensor(1.2656e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.047554
Average KL loss: 0.484907
Average total loss: 1.532461
tensor(-12.5770, device='cuda:0') tensor(0.7911, device='cuda:0') tensor(8.9553e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.049077
Average KL loss: 0.484048
Average total loss: 1.533125
tensor(-12.5906, device='cuda:0') tensor(0.7904, device='cuda:0') tensor(5.7440e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.044191
Average KL loss: 0.483263
Average total loss: 1.527454
tensor(-12.6041, device='cuda:0') tensor(0.7897, device='cuda:0') tensor(8.5862e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.043394
Average KL loss: 0.482411
Average total loss: 1.525805
tensor(-12.6174, device='cuda:0') tensor(0.7891, device='cuda:0') tensor(3.3601e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.041957
Average KL loss: 0.481515
Average total loss: 1.523473
tensor(-12.6306, device='cuda:0') tensor(0.7884, device='cuda:0') tensor(5.3356e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.043727
Average KL loss: 0.480578
Average total loss: 1.524305
tensor(-12.6436, device='cuda:0') tensor(0.7877, device='cuda:0') tensor(7.3668e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.043594
Average KL loss: 0.479762
Average total loss: 1.523356
tensor(-12.6564, device='cuda:0') tensor(0.7870, device='cuda:0') tensor(3.5649e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.045565
Average KL loss: 0.478970
Average total loss: 1.524535
tensor(-12.6692, device='cuda:0') tensor(0.7863, device='cuda:0') tensor(5.5855e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.042717
Average KL loss: 0.478167
Average total loss: 1.520884
tensor(-12.6818, device='cuda:0') tensor(0.7856, device='cuda:0') tensor(1.1287e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.040983
Average KL loss: 0.477421
Average total loss: 1.518404
tensor(-12.6943, device='cuda:0') tensor(0.7848, device='cuda:0') tensor(4.8010e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.040229
Average KL loss: 0.476551
Average total loss: 1.516780
tensor(-12.7066, device='cuda:0') tensor(0.7841, device='cuda:0') tensor(4.0491e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.036622
Average KL loss: 0.475789
Average total loss: 1.512410
tensor(-12.7188, device='cuda:0') tensor(0.7833, device='cuda:0') tensor(6.8150e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.030673
Average KL loss: 0.474957
Average total loss: 1.505630
tensor(-12.7309, device='cuda:0') tensor(0.7825, device='cuda:0') tensor(7.8758e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.037432
Average KL loss: 0.474089
Average total loss: 1.511521
tensor(-12.7429, device='cuda:0') tensor(0.7818, device='cuda:0') tensor(1.7152e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.037078
Average KL loss: 0.473347
Average total loss: 1.510425
tensor(-12.7547, device='cuda:0') tensor(0.7810, device='cuda:0') tensor(5.2008e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.032673
Average KL loss: 0.472503
Average total loss: 1.505176
tensor(-12.7665, device='cuda:0') tensor(0.7802, device='cuda:0') tensor(5.4473e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.031582
Average KL loss: 0.471660
Average total loss: 1.503242
tensor(-12.7781, device='cuda:0') tensor(0.7794, device='cuda:0') tensor(3.4923e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.034637
Average KL loss: 0.470898
Average total loss: 1.505535
tensor(-12.7896, device='cuda:0') tensor(0.7785, device='cuda:0') tensor(5.5360e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.029911
Average KL loss: 0.470216
Average total loss: 1.500126
tensor(-12.8010, device='cuda:0') tensor(0.7777, device='cuda:0') tensor(3.5552e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.033248
Average KL loss: 0.469436
Average total loss: 1.502683
tensor(-12.8123, device='cuda:0') tensor(0.7768, device='cuda:0') tensor(4.4210e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.030889
Average KL loss: 0.468561
Average total loss: 1.499450
tensor(-12.8234, device='cuda:0') tensor(0.7760, device='cuda:0') tensor(4.9624e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.025667
Average KL loss: 0.467766
Average total loss: 1.493433
tensor(-12.8345, device='cuda:0') tensor(0.7751, device='cuda:0') tensor(8.6710e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.028173
Average KL loss: 0.467060
Average total loss: 1.495232
tensor(-12.8455, device='cuda:0') tensor(0.7743, device='cuda:0') tensor(-1.9637e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.029632
Average KL loss: 0.466352
Average total loss: 1.495985
tensor(-12.8563, device='cuda:0') tensor(0.7734, device='cuda:0') tensor(2.1269e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.027784
Average KL loss: 0.465736
Average total loss: 1.493520
tensor(-12.8671, device='cuda:0') tensor(0.7725, device='cuda:0') tensor(2.9614e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.029089
Average KL loss: 0.465011
Average total loss: 1.494101
tensor(-12.8778, device='cuda:0') tensor(0.7717, device='cuda:0') tensor(4.5728e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.025269
Average KL loss: 0.464245
Average total loss: 1.489514
tensor(-12.8883, device='cuda:0') tensor(0.7708, device='cuda:0') tensor(3.0759e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.024070
Average KL loss: 0.463577
Average total loss: 1.487646
tensor(-12.8988, device='cuda:0') tensor(0.7699, device='cuda:0') tensor(4.0975e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.019554
Average KL loss: 0.462817
Average total loss: 1.482371
tensor(-12.9092, device='cuda:0') tensor(0.7689, device='cuda:0') tensor(7.9279e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.026260
Average KL loss: 0.462136
Average total loss: 1.488397
tensor(-12.9195, device='cuda:0') tensor(0.7680, device='cuda:0') tensor(2.9629e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.020379
Average KL loss: 0.461488
Average total loss: 1.481867
tensor(-12.9297, device='cuda:0') tensor(0.7671, device='cuda:0') tensor(4.0382e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.019417
Average KL loss: 0.460759
Average total loss: 1.480176
tensor(-12.9398, device='cuda:0') tensor(0.7662, device='cuda:0') tensor(9.3430e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.019205
Average KL loss: 0.460103
Average total loss: 1.479308
tensor(-12.9498, device='cuda:0') tensor(0.7653, device='cuda:0') tensor(7.2711e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.016943
Average KL loss: 0.459453
Average total loss: 1.476396
tensor(-12.9598, device='cuda:0') tensor(0.7643, device='cuda:0') tensor(1.6111e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.026091
Average KL loss: 0.458776
Average total loss: 1.484867
tensor(-12.9696, device='cuda:0') tensor(0.7634, device='cuda:0') tensor(4.1482e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.017273
Average KL loss: 0.458132
Average total loss: 1.475406
tensor(-12.9794, device='cuda:0') tensor(0.7624, device='cuda:0') tensor(7.0024e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.011597
Average KL loss: 0.457472
Average total loss: 1.469069
tensor(-12.9891, device='cuda:0') tensor(0.7614, device='cuda:0') tensor(3.9038e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.015396
Average KL loss: 0.456841
Average total loss: 1.472237
tensor(-12.9987, device='cuda:0') tensor(0.7604, device='cuda:0') tensor(6.1741e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.009553
Average KL loss: 0.456214
Average total loss: 1.465767
tensor(-13.0082, device='cuda:0') tensor(0.7595, device='cuda:0') tensor(6.4342e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.013658
Average KL loss: 0.455557
Average total loss: 1.469215
tensor(-13.0177, device='cuda:0') tensor(0.7585, device='cuda:0') tensor(1.6173e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.012457
Average KL loss: 0.454882
Average total loss: 1.467339
tensor(-13.0271, device='cuda:0') tensor(0.7575, device='cuda:0') tensor(3.8430e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.011724
Average KL loss: 0.454163
Average total loss: 1.465887
tensor(-13.0364, device='cuda:0') tensor(0.7564, device='cuda:0') tensor(-1.7485e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.013491
Average KL loss: 0.453457
Average total loss: 1.466948
tensor(-13.0456, device='cuda:0') tensor(0.7554, device='cuda:0') tensor(2.1355e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.009798
Average KL loss: 0.452802
Average total loss: 1.462600
tensor(-13.0547, device='cuda:0') tensor(0.7544, device='cuda:0') tensor(6.2085e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.007831
Average KL loss: 0.452199
Average total loss: 1.460030
tensor(-13.0638, device='cuda:0') tensor(0.7533, device='cuda:0') tensor(3.2745e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.008976
Average KL loss: 0.451617
Average total loss: 1.460593
tensor(-13.0728, device='cuda:0') tensor(0.7523, device='cuda:0') tensor(4.4863e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.007859
Average KL loss: 0.450997
Average total loss: 1.458856
tensor(-13.0818, device='cuda:0') tensor(0.7512, device='cuda:0') tensor(6.9090e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.010432
Average KL loss: 0.450391
Average total loss: 1.460823
tensor(-13.0906, device='cuda:0') tensor(0.7502, device='cuda:0') tensor(4.1711e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.005924
Average KL loss: 0.449806
Average total loss: 1.455731
tensor(-13.0994, device='cuda:0') tensor(0.7491, device='cuda:0') tensor(4.6633e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.004507
Average KL loss: 0.449246
Average total loss: 1.453753
tensor(-13.1082, device='cuda:0') tensor(0.7480, device='cuda:0') tensor(1.8901e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.007103
Average KL loss: 0.448642
Average total loss: 1.455745
tensor(-13.1169, device='cuda:0') tensor(0.7470, device='cuda:0') tensor(6.0754e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.003382
Average KL loss: 0.448069
Average total loss: 1.451452
tensor(-13.1255, device='cuda:0') tensor(0.7458, device='cuda:0') tensor(5.0971e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.004201
Average KL loss: 0.447508
Average total loss: 1.451708
tensor(-13.1340, device='cuda:0') tensor(0.7448, device='cuda:0') tensor(2.8311e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.003047
Average KL loss: 0.446969
Average total loss: 1.450016
tensor(-13.1425, device='cuda:0') tensor(0.7437, device='cuda:0') tensor(1.7470e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.004044
Average KL loss: 0.446431
Average total loss: 1.450475
tensor(-13.1509, device='cuda:0') tensor(0.7426, device='cuda:0') tensor(3.5736e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.999704
Average KL loss: 0.445906
Average total loss: 1.445610
tensor(-13.1592, device='cuda:0') tensor(0.7415, device='cuda:0') tensor(6.1901e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.999156
Average KL loss: 0.445322
Average total loss: 1.444479
tensor(-13.1675, device='cuda:0') tensor(0.7404, device='cuda:0') tensor(3.7239e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.995300
Average KL loss: 0.444787
Average total loss: 1.440087
tensor(-13.1758, device='cuda:0') tensor(0.7393, device='cuda:0') tensor(3.3921e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.996065
Average KL loss: 0.444254
Average total loss: 1.440320
tensor(-13.1839, device='cuda:0') tensor(0.7381, device='cuda:0') tensor(8.4511e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.998045
Average KL loss: 0.443702
Average total loss: 1.441746
tensor(-13.1920, device='cuda:0') tensor(0.7370, device='cuda:0') tensor(8.6888e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.994055
Average KL loss: 0.443104
Average total loss: 1.437159
tensor(-13.2001, device='cuda:0') tensor(0.7358, device='cuda:0') tensor(3.6209e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.998815
Average KL loss: 0.442625
Average total loss: 1.441440
tensor(-13.2081, device='cuda:0') tensor(0.7347, device='cuda:0') tensor(1.5458e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.997117
Average KL loss: 0.442103
Average total loss: 1.439219
tensor(-13.2161, device='cuda:0') tensor(0.7335, device='cuda:0') tensor(5.8289e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.996922
Average KL loss: 0.441593
Average total loss: 1.438515
tensor(-13.2239, device='cuda:0') tensor(0.7324, device='cuda:0') tensor(3.9276e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.992486
Average KL loss: 0.441194
Average total loss: 1.433680
tensor(-13.2318, device='cuda:0') tensor(0.7312, device='cuda:0') tensor(1.3422e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.991038
Average KL loss: 0.440656
Average total loss: 1.431693
tensor(-13.2396, device='cuda:0') tensor(0.7301, device='cuda:0') tensor(2.5490e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.991389
Average KL loss: 0.440095
Average total loss: 1.431484
tensor(-13.2473, device='cuda:0') tensor(0.7289, device='cuda:0') tensor(3.1589e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.989843
Average KL loss: 0.439556
Average total loss: 1.429399
tensor(-13.2550, device='cuda:0') tensor(0.7277, device='cuda:0') tensor(6.0742e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.992080
Average KL loss: 0.439112
Average total loss: 1.431193
tensor(-13.2626, device='cuda:0') tensor(0.7266, device='cuda:0') tensor(4.7426e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.989141
Average KL loss: 0.438671
Average total loss: 1.427812
tensor(-13.2701, device='cuda:0') tensor(0.7254, device='cuda:0') tensor(5.0886e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.991323
Average KL loss: 0.438208
Average total loss: 1.429531
tensor(-13.2777, device='cuda:0') tensor(0.7242, device='cuda:0') tensor(1.1400e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.988299
Average KL loss: 0.437722
Average total loss: 1.426021
tensor(-13.2851, device='cuda:0') tensor(0.7230, device='cuda:0') tensor(3.3984e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.985838
Average KL loss: 0.437227
Average total loss: 1.423065
tensor(-13.2926, device='cuda:0') tensor(0.7218, device='cuda:0') tensor(3.8044e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.987417
Average KL loss: 0.436741
Average total loss: 1.424157
tensor(-13.2999, device='cuda:0') tensor(0.7206, device='cuda:0') tensor(6.1884e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.988157
Average KL loss: 0.436200
Average total loss: 1.424357
tensor(-13.3073, device='cuda:0') tensor(0.7194, device='cuda:0') tensor(2.3313e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.983116
Average KL loss: 0.435781
Average total loss: 1.418897
tensor(-13.3145, device='cuda:0') tensor(0.7182, device='cuda:0') tensor(1.8202e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.979900
Average KL loss: 0.435311
Average total loss: 1.415210
tensor(-13.3218, device='cuda:0') tensor(0.7170, device='cuda:0') tensor(1.6656e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.983390
Average KL loss: 0.434895
Average total loss: 1.418286
tensor(-13.3290, device='cuda:0') tensor(0.7157, device='cuda:0') tensor(3.8043e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.983035
Average KL loss: 0.434497
Average total loss: 1.417532
tensor(-13.3361, device='cuda:0') tensor(0.7145, device='cuda:0') tensor(6.9200e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.985568
Average KL loss: 0.434080
Average total loss: 1.419648
tensor(-13.3432, device='cuda:0') tensor(0.7133, device='cuda:0') tensor(3.1315e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.982336
Average KL loss: 0.433664
Average total loss: 1.416000
tensor(-13.3502, device='cuda:0') tensor(0.7121, device='cuda:0') tensor(3.6638e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.979913
Average KL loss: 0.433236
Average total loss: 1.413150
tensor(-13.3572, device='cuda:0') tensor(0.7108, device='cuda:0') tensor(1.2202e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.980491
Average KL loss: 0.432801
Average total loss: 1.413291
tensor(-13.3642, device='cuda:0') tensor(0.7096, device='cuda:0') tensor(3.2761e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.982026
Average KL loss: 0.432341
Average total loss: 1.414368
tensor(-13.3711, device='cuda:0') tensor(0.7084, device='cuda:0') tensor(4.7438e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.981155
Average KL loss: 0.431929
Average total loss: 1.413084
tensor(-13.3780, device='cuda:0') tensor(0.7072, device='cuda:0') tensor(2.3433e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.979800
Average KL loss: 0.431559
Average total loss: 1.411359
tensor(-13.3848, device='cuda:0') tensor(0.7059, device='cuda:0') tensor(4.8079e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.979318
Average KL loss: 0.431215
Average total loss: 1.410533
tensor(-13.3916, device='cuda:0') tensor(0.7047, device='cuda:0') tensor(4.7612e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.977415
Average KL loss: 0.430843
Average total loss: 1.408258
tensor(-13.3984, device='cuda:0') tensor(0.7034, device='cuda:0') tensor(2.9935e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.973868
Average KL loss: 0.430489
Average total loss: 1.404357
tensor(-13.4051, device='cuda:0') tensor(0.7022, device='cuda:0') tensor(3.1729e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.973245
Average KL loss: 0.430124
Average total loss: 1.403369
tensor(-13.4118, device='cuda:0') tensor(0.7009, device='cuda:0') tensor(2.9558e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.974571
Average KL loss: 0.429791
Average total loss: 1.404362
tensor(-13.4184, device='cuda:0') tensor(0.6996, device='cuda:0') tensor(3.9983e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.974844
Average KL loss: 0.429400
Average total loss: 1.404245
tensor(-13.4250, device='cuda:0') tensor(0.6984, device='cuda:0') tensor(3.5898e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.972966
Average KL loss: 0.428983
Average total loss: 1.401949
tensor(-13.4315, device='cuda:0') tensor(0.6971, device='cuda:0') tensor(2.1518e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.975289
Average KL loss: 0.428583
Average total loss: 1.403872
tensor(-13.4381, device='cuda:0') tensor(0.6958, device='cuda:0') tensor(5.3726e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.971080
Average KL loss: 0.428126
Average total loss: 1.399207
tensor(-13.4445, device='cuda:0') tensor(0.6945, device='cuda:0') tensor(3.6029e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.974564
Average KL loss: 0.427774
Average total loss: 1.402338
tensor(-13.4510, device='cuda:0') tensor(0.6932, device='cuda:0') tensor(2.0888e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.969751
Average KL loss: 0.427449
Average total loss: 1.397200
tensor(-13.4574, device='cuda:0') tensor(0.6919, device='cuda:0') tensor(5.9710e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.970341
Average KL loss: 0.427091
Average total loss: 1.397432
tensor(-13.4638, device='cuda:0') tensor(0.6906, device='cuda:0') tensor(1.3920e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.969335
Average KL loss: 0.426747
Average total loss: 1.396083
tensor(-13.4701, device='cuda:0') tensor(0.6893, device='cuda:0') tensor(4.7729e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.968648
Average KL loss: 0.426331
Average total loss: 1.394979
tensor(-13.4764, device='cuda:0') tensor(0.6880, device='cuda:0') tensor(4.8897e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.969108
Average KL loss: 0.425970
Average total loss: 1.395077
tensor(-13.4827, device='cuda:0') tensor(0.6867, device='cuda:0') tensor(2.8041e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.968460
Average KL loss: 0.425615
Average total loss: 1.394075
tensor(-13.4889, device='cuda:0') tensor(0.6854, device='cuda:0') tensor(8.7851e-11, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.968086
Average KL loss: 0.425239
Average total loss: 1.393325
tensor(-13.4951, device='cuda:0') tensor(0.6841, device='cuda:0') tensor(2.0219e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.967248
Average KL loss: 0.424886
Average total loss: 1.392134
tensor(-13.5012, device='cuda:0') tensor(0.6828, device='cuda:0') tensor(2.8432e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.967433
Average KL loss: 0.424519
Average total loss: 1.391952
tensor(-13.5073, device='cuda:0') tensor(0.6815, device='cuda:0') tensor(1.4644e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.965312
Average KL loss: 0.424177
Average total loss: 1.389489
tensor(-13.5134, device='cuda:0') tensor(0.6802, device='cuda:0') tensor(-3.0788e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.964286
Average KL loss: 0.423871
Average total loss: 1.388157
tensor(-13.5195, device='cuda:0') tensor(0.6789, device='cuda:0') tensor(7.0446e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.964713
Average KL loss: 0.423515
Average total loss: 1.388228
tensor(-13.5255, device='cuda:0') tensor(0.6776, device='cuda:0') tensor(2.8764e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.961073
Average KL loss: 0.423137
Average total loss: 1.384209
tensor(-13.5315, device='cuda:0') tensor(0.6762, device='cuda:0') tensor(2.4394e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.963313
Average KL loss: 0.422794
Average total loss: 1.386107
tensor(-13.5375, device='cuda:0') tensor(0.6749, device='cuda:0') tensor(3.3623e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.963168
Average KL loss: 0.422465
Average total loss: 1.385633
tensor(-13.5434, device='cuda:0') tensor(0.6736, device='cuda:0') tensor(2.4767e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.958214
Average KL loss: 0.422136
Average total loss: 1.380349
tensor(-13.5493, device='cuda:0') tensor(0.6723, device='cuda:0') tensor(2.5358e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.959110
Average KL loss: 0.421833
Average total loss: 1.380942
tensor(-13.5552, device='cuda:0') tensor(0.6709, device='cuda:0') tensor(2.1849e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.959618
Average KL loss: 0.421436
Average total loss: 1.381054
tensor(-13.5610, device='cuda:0') tensor(0.6695, device='cuda:0') tensor(1.5464e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.961779
Average KL loss: 0.421102
Average total loss: 1.382881
tensor(-13.5668, device='cuda:0') tensor(0.6682, device='cuda:0') tensor(2.6235e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.961386
Average KL loss: 0.420804
Average total loss: 1.382189
tensor(-13.5726, device='cuda:0') tensor(0.6669, device='cuda:0') tensor(5.6177e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.959360
Average KL loss: 0.420475
Average total loss: 1.379835
 Percentile value: -12.95986270904541
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =    1676 /    1728             ( 96.99%) | total_pruned =      52 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   24176 /   36864             ( 65.58%) | total_pruned =   12688 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   24061 /   36864             ( 65.27%) | total_pruned =   12803 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   20440 /   36864             ( 55.45%) | total_pruned =   16424 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18787 /   36864             ( 50.96%) | total_pruned =   18077 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   41385 /   73728             ( 56.13%) | total_pruned =   32343 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   58595 /  147456             ( 39.74%) | total_pruned =   88861 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    6751 /    8192             ( 82.41%) | total_pruned =    1441 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   45881 /  147456             ( 31.12%) | total_pruned =  101575 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   40292 /  147456             ( 27.32%) | total_pruned =  107164 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   71892 /  294912             ( 24.38%) | total_pruned =  223020 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   74709 /  589824             ( 12.67%) | total_pruned =  515115 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   17382 /   32768             ( 53.05%) | total_pruned =   15386 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   31009 /  589824             (  5.26%) | total_pruned =  558815 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   30070 /  589824             (  5.10%) | total_pruned =  559754 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   74185 / 1179648             (  6.29%) | total_pruned = 1105463 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  110080 / 2359296             (  4.67%) | total_pruned = 2249216 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   44390 /  131072             ( 33.87%) | total_pruned =   86682 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  103555 / 2359296             (  4.39%) | total_pruned = 2255741 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     161 /     512             ( 31.45%) | total_pruned =     351 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  152749 / 2359296             (  6.47%) | total_pruned = 2206547 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
linear.weight        | nonzeros =    4847 /    5120             ( 94.67%) | total_pruned =     273 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 30/200 Loss: 0.000112 Accuracy: 85.73 100.00 % Best test Accuracy: 85.80%
tensor(-13.5783, device='cuda:0') tensor(0.6655, device='cuda:0') tensor(-8.5190e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.005955
Average KL loss: 0.415143
Average total loss: 1.421098
tensor(-13.5883, device='cuda:0') tensor(0.6133, device='cuda:0') tensor(2.3162e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.002463
Average KL loss: 0.410037
Average total loss: 1.412500
tensor(-13.5973, device='cuda:0') tensor(0.5769, device='cuda:0') tensor(-1.2029e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.995147
Average KL loss: 0.407524
Average total loss: 1.402671
tensor(-13.6056, device='cuda:0') tensor(0.5496, device='cuda:0') tensor(5.6874e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.998884
Average KL loss: 0.405934
Average total loss: 1.404818
tensor(-13.6134, device='cuda:0') tensor(0.5279, device='cuda:0') tensor(9.4507e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.991545
Average KL loss: 0.404866
Average total loss: 1.396411
tensor(-13.6209, device='cuda:0') tensor(0.5101, device='cuda:0') tensor(9.3100e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.991883
Average KL loss: 0.404143
Average total loss: 1.396026
tensor(-13.6281, device='cuda:0') tensor(0.4950, device='cuda:0') tensor(1.0566e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.985679
Average KL loss: 0.403556
Average total loss: 1.389235
tensor(-13.6351, device='cuda:0') tensor(0.4820, device='cuda:0') tensor(2.9700e-11, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.990368
Average KL loss: 0.403067
Average total loss: 1.393434
tensor(-13.6420, device='cuda:0') tensor(0.4705, device='cuda:0') tensor(5.4063e-11, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.981283
Average KL loss: 0.402629
Average total loss: 1.383912
tensor(-13.6487, device='cuda:0') tensor(0.4604, device='cuda:0') tensor(2.8357e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.982967
Average KL loss: 0.402242
Average total loss: 1.385209
tensor(-13.6552, device='cuda:0') tensor(0.4512, device='cuda:0') tensor(-1.0659e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.984366
Average KL loss: 0.401895
Average total loss: 1.386261
tensor(-13.6617, device='cuda:0') tensor(0.4430, device='cuda:0') tensor(2.2973e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.977264
Average KL loss: 0.401543
Average total loss: 1.378807
tensor(-13.6680, device='cuda:0') tensor(0.4355, device='cuda:0') tensor(-1.6060e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.979908
Average KL loss: 0.401259
Average total loss: 1.381167
tensor(-13.6742, device='cuda:0') tensor(0.4287, device='cuda:0') tensor(-2.6786e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.974416
Average KL loss: 0.401037
Average total loss: 1.375454
tensor(-13.6804, device='cuda:0') tensor(0.4224, device='cuda:0') tensor(-1.7318e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.972245
Average KL loss: 0.400807
Average total loss: 1.373052
tensor(-13.6865, device='cuda:0') tensor(0.4165, device='cuda:0') tensor(-2.6625e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.972909
Average KL loss: 0.400517
Average total loss: 1.373426
tensor(-13.6925, device='cuda:0') tensor(0.4112, device='cuda:0') tensor(-1.6672e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.973222
Average KL loss: 0.400244
Average total loss: 1.373467
tensor(-13.6984, device='cuda:0') tensor(0.4061, device='cuda:0') tensor(2.0613e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.968790
Average KL loss: 0.400034
Average total loss: 1.368824
tensor(-13.7042, device='cuda:0') tensor(0.4014, device='cuda:0') tensor(1.4395e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.970664
Average KL loss: 0.399787
Average total loss: 1.370452
tensor(-13.7101, device='cuda:0') tensor(0.3970, device='cuda:0') tensor(1.6170e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.969960
Average KL loss: 0.399603
Average total loss: 1.369564
tensor(-13.7158, device='cuda:0') tensor(0.3929, device='cuda:0') tensor(-6.6153e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.969892
Average KL loss: 0.399445
Average total loss: 1.369337
tensor(-13.7215, device='cuda:0') tensor(0.3890, device='cuda:0') tensor(8.9480e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.967468
Average KL loss: 0.399259
Average total loss: 1.366727
tensor(-13.7271, device='cuda:0') tensor(0.3853, device='cuda:0') tensor(2.3788e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.962610
Average KL loss: 0.399062
Average total loss: 1.361672
tensor(-13.7327, device='cuda:0') tensor(0.3818, device='cuda:0') tensor(-9.2509e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.965343
Average KL loss: 0.398854
Average total loss: 1.364197
tensor(-13.7382, device='cuda:0') tensor(0.3785, device='cuda:0') tensor(-3.1019e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.966617
Average KL loss: 0.398649
Average total loss: 1.365266
tensor(-13.7437, device='cuda:0') tensor(0.3754, device='cuda:0') tensor(-2.8426e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.967130
Average KL loss: 0.398487
Average total loss: 1.365617
tensor(-13.7492, device='cuda:0') tensor(0.3725, device='cuda:0') tensor(1.8435e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.964766
Average KL loss: 0.398274
Average total loss: 1.363040
tensor(-13.7546, device='cuda:0') tensor(0.3696, device='cuda:0') tensor(3.2648e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.961059
Average KL loss: 0.398086
Average total loss: 1.359145
tensor(-13.7599, device='cuda:0') tensor(0.3669, device='cuda:0') tensor(4.1155e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.958174
Average KL loss: 0.397944
Average total loss: 1.356118
tensor(-13.7653, device='cuda:0') tensor(0.3644, device='cuda:0') tensor(-2.0279e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.963556
Average KL loss: 0.397835
Average total loss: 1.361391
tensor(-13.7705, device='cuda:0') tensor(0.3619, device='cuda:0') tensor(-1.5727e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.959187
Average KL loss: 0.397686
Average total loss: 1.356873
tensor(-13.7758, device='cuda:0') tensor(0.3596, device='cuda:0') tensor(-7.3346e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.956870
Average KL loss: 0.397508
Average total loss: 1.354378
tensor(-13.7810, device='cuda:0') tensor(0.3573, device='cuda:0') tensor(1.0894e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.958936
Average KL loss: 0.397302
Average total loss: 1.356238
tensor(-13.7862, device='cuda:0') tensor(0.3551, device='cuda:0') tensor(5.6729e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.958884
Average KL loss: 0.397132
Average total loss: 1.356016
tensor(-13.7913, device='cuda:0') tensor(0.3531, device='cuda:0') tensor(-9.4851e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.954787
Average KL loss: 0.397007
Average total loss: 1.351793
tensor(-13.7964, device='cuda:0') tensor(0.3511, device='cuda:0') tensor(1.5663e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.954625
Average KL loss: 0.396851
Average total loss: 1.351477
tensor(-13.8015, device='cuda:0') tensor(0.3492, device='cuda:0') tensor(-7.7691e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.957648
Average KL loss: 0.396724
Average total loss: 1.354372
tensor(-13.8065, device='cuda:0') tensor(0.3474, device='cuda:0') tensor(-5.1134e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.953102
Average KL loss: 0.396635
Average total loss: 1.349737
tensor(-13.8115, device='cuda:0') tensor(0.3456, device='cuda:0') tensor(2.4167e-11, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.952461
Average KL loss: 0.396447
Average total loss: 1.348908
tensor(-13.8165, device='cuda:0') tensor(0.3438, device='cuda:0') tensor(1.0002e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.955017
Average KL loss: 0.396282
Average total loss: 1.351299
tensor(-13.8214, device='cuda:0') tensor(0.3422, device='cuda:0') tensor(7.6635e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.952324
Average KL loss: 0.396109
Average total loss: 1.348432
tensor(-13.8263, device='cuda:0') tensor(0.3406, device='cuda:0') tensor(-6.4578e-11, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.949884
Average KL loss: 0.395919
Average total loss: 1.345803
tensor(-13.8312, device='cuda:0') tensor(0.3390, device='cuda:0') tensor(-2.6382e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.950363
Average KL loss: 0.395788
Average total loss: 1.346151
tensor(-13.8361, device='cuda:0') tensor(0.3375, device='cuda:0') tensor(-1.0571e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.949718
Average KL loss: 0.395630
Average total loss: 1.345348
tensor(-13.8409, device='cuda:0') tensor(0.3361, device='cuda:0') tensor(-3.4958e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.946600
Average KL loss: 0.395504
Average total loss: 1.342104
tensor(-13.8457, device='cuda:0') tensor(0.3347, device='cuda:0') tensor(3.4314e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.949339
Average KL loss: 0.395391
Average total loss: 1.344730
tensor(-13.8505, device='cuda:0') tensor(0.3333, device='cuda:0') tensor(-1.0334e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.950578
Average KL loss: 0.395256
Average total loss: 1.345834
tensor(-13.8552, device='cuda:0') tensor(0.3320, device='cuda:0') tensor(-2.4371e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.948958
Average KL loss: 0.395177
Average total loss: 1.344135
tensor(-13.8599, device='cuda:0') tensor(0.3307, device='cuda:0') tensor(1.8519e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.946150
Average KL loss: 0.395080
Average total loss: 1.341230
tensor(-13.8646, device='cuda:0') tensor(0.3295, device='cuda:0') tensor(-2.3818e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.946016
Average KL loss: 0.394918
Average total loss: 1.340934
tensor(-13.8693, device='cuda:0') tensor(0.3283, device='cuda:0') tensor(-5.3304e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.945357
Average KL loss: 0.394769
Average total loss: 1.340125
tensor(-13.8740, device='cuda:0') tensor(0.3271, device='cuda:0') tensor(6.5128e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.945390
Average KL loss: 0.394654
Average total loss: 1.340044
tensor(-13.8786, device='cuda:0') tensor(0.3260, device='cuda:0') tensor(-3.4397e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.943129
Average KL loss: 0.394482
Average total loss: 1.337611
tensor(-13.8832, device='cuda:0') tensor(0.3249, device='cuda:0') tensor(9.8545e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.944108
Average KL loss: 0.394329
Average total loss: 1.338437
tensor(-13.8877, device='cuda:0') tensor(0.3239, device='cuda:0') tensor(6.7958e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.942849
Average KL loss: 0.394211
Average total loss: 1.337061
tensor(-13.8923, device='cuda:0') tensor(0.3229, device='cuda:0') tensor(1.2742e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.940752
Average KL loss: 0.394081
Average total loss: 1.334833
tensor(-13.8968, device='cuda:0') tensor(0.3219, device='cuda:0') tensor(2.4775e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.943038
Average KL loss: 0.393918
Average total loss: 1.336956
tensor(-13.9013, device='cuda:0') tensor(0.3209, device='cuda:0') tensor(-1.0854e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.941610
Average KL loss: 0.393815
Average total loss: 1.335425
tensor(-13.9058, device='cuda:0') tensor(0.3199, device='cuda:0') tensor(-5.7067e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.943564
Average KL loss: 0.393740
Average total loss: 1.337303
tensor(-13.9102, device='cuda:0') tensor(0.3190, device='cuda:0') tensor(-2.7490e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.941491
Average KL loss: 0.393640
Average total loss: 1.335131
tensor(-13.9147, device='cuda:0') tensor(0.3181, device='cuda:0') tensor(8.5360e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.939341
Average KL loss: 0.393546
Average total loss: 1.332887
tensor(-13.9191, device='cuda:0') tensor(0.3172, device='cuda:0') tensor(1.3572e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.938615
Average KL loss: 0.393403
Average total loss: 1.332019
tensor(-13.9235, device='cuda:0') tensor(0.3164, device='cuda:0') tensor(1.2648e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.938224
Average KL loss: 0.393343
Average total loss: 1.331567
tensor(-13.9278, device='cuda:0') tensor(0.3155, device='cuda:0') tensor(1.6435e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.941148
Average KL loss: 0.393268
Average total loss: 1.334416
tensor(-13.9322, device='cuda:0') tensor(0.3147, device='cuda:0') tensor(-7.5885e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.936383
Average KL loss: 0.393194
Average total loss: 1.329577
tensor(-13.9365, device='cuda:0') tensor(0.3139, device='cuda:0') tensor(3.7323e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.937979
Average KL loss: 0.393098
Average total loss: 1.331077
tensor(-13.9408, device='cuda:0') tensor(0.3131, device='cuda:0') tensor(5.5586e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.937740
Average KL loss: 0.392998
Average total loss: 1.330738
tensor(-13.9451, device='cuda:0') tensor(0.3123, device='cuda:0') tensor(-1.1033e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.937804
Average KL loss: 0.392905
Average total loss: 1.330709
tensor(-13.9494, device='cuda:0') tensor(0.3116, device='cuda:0') tensor(-8.6469e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.935403
Average KL loss: 0.392816
Average total loss: 1.328219
tensor(-13.9536, device='cuda:0') tensor(0.3109, device='cuda:0') tensor(4.8614e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.934282
Average KL loss: 0.392755
Average total loss: 1.327037
tensor(-13.9579, device='cuda:0') tensor(0.3102, device='cuda:0') tensor(-1.3652e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.935161
Average KL loss: 0.392709
Average total loss: 1.327870
tensor(-13.9621, device='cuda:0') tensor(0.3095, device='cuda:0') tensor(-6.3489e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.937722
Average KL loss: 0.392705
Average total loss: 1.330427
tensor(-13.9663, device='cuda:0') tensor(0.3088, device='cuda:0') tensor(9.6786e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.935027
Average KL loss: 0.392667
Average total loss: 1.327695
tensor(-13.9704, device='cuda:0') tensor(0.3081, device='cuda:0') tensor(-5.3171e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.934545
Average KL loss: 0.392526
Average total loss: 1.327070
tensor(-13.9746, device='cuda:0') tensor(0.3075, device='cuda:0') tensor(2.8556e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.932498
Average KL loss: 0.392438
Average total loss: 1.324936
tensor(-13.9787, device='cuda:0') tensor(0.3068, device='cuda:0') tensor(-6.6621e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.935547
Average KL loss: 0.392317
Average total loss: 1.327865
tensor(-13.9828, device='cuda:0') tensor(0.3062, device='cuda:0') tensor(2.6886e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.930607
Average KL loss: 0.392193
Average total loss: 1.322800
tensor(-13.9869, device='cuda:0') tensor(0.3056, device='cuda:0') tensor(1.4377e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.931944
Average KL loss: 0.392097
Average total loss: 1.324041
tensor(-13.9910, device='cuda:0') tensor(0.3050, device='cuda:0') tensor(3.4309e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.934183
Average KL loss: 0.391942
Average total loss: 1.326125
tensor(-13.9951, device='cuda:0') tensor(0.3044, device='cuda:0') tensor(5.9621e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.928858
Average KL loss: 0.391835
Average total loss: 1.320693
tensor(-13.9991, device='cuda:0') tensor(0.3038, device='cuda:0') tensor(2.6280e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.931807
Average KL loss: 0.391724
Average total loss: 1.323531
tensor(-14.0032, device='cuda:0') tensor(0.3033, device='cuda:0') tensor(-7.8872e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.929303
Average KL loss: 0.391649
Average total loss: 1.320952
tensor(-14.0072, device='cuda:0') tensor(0.3027, device='cuda:0') tensor(1.1825e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.934626
Average KL loss: 0.391601
Average total loss: 1.326227
tensor(-14.0112, device='cuda:0') tensor(0.3022, device='cuda:0') tensor(-1.1583e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.931266
Average KL loss: 0.391551
Average total loss: 1.322817
tensor(-14.0151, device='cuda:0') tensor(0.3017, device='cuda:0') tensor(-1.0024e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.931645
Average KL loss: 0.391482
Average total loss: 1.323127
tensor(-14.0191, device='cuda:0') tensor(0.3011, device='cuda:0') tensor(-5.0248e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.930404
Average KL loss: 0.391434
Average total loss: 1.321838
tensor(-14.0231, device='cuda:0') tensor(0.3006, device='cuda:0') tensor(-4.3271e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.927134
Average KL loss: 0.391380
Average total loss: 1.318514
tensor(-14.0270, device='cuda:0') tensor(0.3001, device='cuda:0') tensor(2.1619e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.929769
Average KL loss: 0.391240
Average total loss: 1.321009
tensor(-14.0309, device='cuda:0') tensor(0.2996, device='cuda:0') tensor(1.4286e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.927518
Average KL loss: 0.391137
Average total loss: 1.318654
tensor(-14.0348, device='cuda:0') tensor(0.2992, device='cuda:0') tensor(1.1148e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.928200
Average KL loss: 0.391044
Average total loss: 1.319244
tensor(-14.0387, device='cuda:0') tensor(0.2987, device='cuda:0') tensor(1.8087e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.927055
Average KL loss: 0.390917
Average total loss: 1.317972
tensor(-14.0425, device='cuda:0') tensor(0.2982, device='cuda:0') tensor(1.3359e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.924610
Average KL loss: 0.390805
Average total loss: 1.315415
tensor(-14.0464, device='cuda:0') tensor(0.2978, device='cuda:0') tensor(-1.9571e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.926975
Average KL loss: 0.390738
Average total loss: 1.317713
tensor(-14.0502, device='cuda:0') tensor(0.2973, device='cuda:0') tensor(2.7167e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.928462
Average KL loss: 0.390664
Average total loss: 1.319126
tensor(-14.0540, device='cuda:0') tensor(0.2968, device='cuda:0') tensor(-8.9547e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.925796
Average KL loss: 0.390560
Average total loss: 1.316355
tensor(-14.0578, device='cuda:0') tensor(0.2964, device='cuda:0') tensor(2.0812e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.924419
Average KL loss: 0.390455
Average total loss: 1.314874
tensor(-14.0616, device='cuda:0') tensor(0.2959, device='cuda:0') tensor(-6.4662e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.925488
Average KL loss: 0.390385
Average total loss: 1.315873
tensor(-14.0654, device='cuda:0') tensor(0.2955, device='cuda:0') tensor(6.5969e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.923920
Average KL loss: 0.390314
Average total loss: 1.314233
tensor(-14.0692, device='cuda:0') tensor(0.2951, device='cuda:0') tensor(-4.9167e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.926121
Average KL loss: 0.390218
Average total loss: 1.316340
tensor(-14.0729, device='cuda:0') tensor(0.2946, device='cuda:0') tensor(4.9952e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.921860
Average KL loss: 0.390127
Average total loss: 1.311987
tensor(-14.0766, device='cuda:0') tensor(0.2942, device='cuda:0') tensor(1.2225e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.922639
Average KL loss: 0.389989
Average total loss: 1.312628
tensor(-14.0803, device='cuda:0') tensor(0.2938, device='cuda:0') tensor(-1.0366e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.925627
Average KL loss: 0.389894
Average total loss: 1.315521
tensor(-14.0840, device='cuda:0') tensor(0.2934, device='cuda:0') tensor(-1.6828e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.922238
Average KL loss: 0.389816
Average total loss: 1.312054
tensor(-14.0877, device='cuda:0') tensor(0.2930, device='cuda:0') tensor(1.1361e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.921728
Average KL loss: 0.389714
Average total loss: 1.311443
tensor(-14.0914, device='cuda:0') tensor(0.2926, device='cuda:0') tensor(-7.1788e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.922998
Average KL loss: 0.389636
Average total loss: 1.312635
tensor(-14.0951, device='cuda:0') tensor(0.2923, device='cuda:0') tensor(6.3102e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.920881
Average KL loss: 0.389571
Average total loss: 1.310452
tensor(-14.0987, device='cuda:0') tensor(0.2919, device='cuda:0') tensor(1.0593e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.920783
Average KL loss: 0.389477
Average total loss: 1.310260
tensor(-14.1023, device='cuda:0') tensor(0.2916, device='cuda:0') tensor(1.9598e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.919937
Average KL loss: 0.389388
Average total loss: 1.309324
tensor(-14.1060, device='cuda:0') tensor(0.2912, device='cuda:0') tensor(-3.4939e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.919869
Average KL loss: 0.389340
Average total loss: 1.309209
tensor(-14.1096, device='cuda:0') tensor(0.2909, device='cuda:0') tensor(1.3391e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.918862
Average KL loss: 0.389244
Average total loss: 1.308106
tensor(-14.1132, device='cuda:0') tensor(0.2905, device='cuda:0') tensor(1.0192e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.922304
Average KL loss: 0.389181
Average total loss: 1.311486
tensor(-14.1167, device='cuda:0') tensor(0.2902, device='cuda:0') tensor(-1.1384e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.920723
Average KL loss: 0.389114
Average total loss: 1.309837
tensor(-14.1203, device='cuda:0') tensor(0.2898, device='cuda:0') tensor(9.2490e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.920189
Average KL loss: 0.389021
Average total loss: 1.309209
tensor(-14.1238, device='cuda:0') tensor(0.2895, device='cuda:0') tensor(9.1069e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.917596
Average KL loss: 0.388931
Average total loss: 1.306527
tensor(-14.1274, device='cuda:0') tensor(0.2892, device='cuda:0') tensor(1.2267e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.919875
Average KL loss: 0.388860
Average total loss: 1.308736
tensor(-14.1309, device='cuda:0') tensor(0.2889, device='cuda:0') tensor(1.7497e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.915728
Average KL loss: 0.388807
Average total loss: 1.304534
tensor(-14.1344, device='cuda:0') tensor(0.2886, device='cuda:0') tensor(-4.6580e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.916716
Average KL loss: 0.388717
Average total loss: 1.305433
tensor(-14.1379, device='cuda:0') tensor(0.2882, device='cuda:0') tensor(2.9175e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.917700
Average KL loss: 0.388662
Average total loss: 1.306363
tensor(-14.1414, device='cuda:0') tensor(0.2879, device='cuda:0') tensor(-6.4277e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.917557
Average KL loss: 0.388577
Average total loss: 1.306134
tensor(-14.1449, device='cuda:0') tensor(0.2876, device='cuda:0') tensor(6.0855e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.916867
Average KL loss: 0.388524
Average total loss: 1.305390
tensor(-14.1484, device='cuda:0') tensor(0.2873, device='cuda:0') tensor(1.6560e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.916992
Average KL loss: 0.388370
Average total loss: 1.305362
tensor(-14.1518, device='cuda:0') tensor(0.2870, device='cuda:0') tensor(-9.0152e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.918591
Average KL loss: 0.388248
Average total loss: 1.306838
tensor(-14.1552, device='cuda:0') tensor(0.2866, device='cuda:0') tensor(-2.1428e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.920332
Average KL loss: 0.388166
Average total loss: 1.308498
tensor(-14.1587, device='cuda:0') tensor(0.2864, device='cuda:0') tensor(1.8658e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.915672
Average KL loss: 0.388088
Average total loss: 1.303760
tensor(-14.1621, device='cuda:0') tensor(0.2861, device='cuda:0') tensor(-1.1381e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.915837
Average KL loss: 0.388024
Average total loss: 1.303861
tensor(-14.1655, device='cuda:0') tensor(0.2858, device='cuda:0') tensor(2.3553e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.913603
Average KL loss: 0.387920
Average total loss: 1.301524
tensor(-14.1689, device='cuda:0') tensor(0.2855, device='cuda:0') tensor(7.8928e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.915485
Average KL loss: 0.387846
Average total loss: 1.303331
tensor(-14.1723, device='cuda:0') tensor(0.2853, device='cuda:0') tensor(-9.2456e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.915261
Average KL loss: 0.387769
Average total loss: 1.303029
tensor(-14.1756, device='cuda:0') tensor(0.2850, device='cuda:0') tensor(6.5866e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.915380
Average KL loss: 0.387670
Average total loss: 1.303050
tensor(-14.1790, device='cuda:0') tensor(0.2847, device='cuda:0') tensor(5.9605e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.913898
Average KL loss: 0.387571
Average total loss: 1.301469
tensor(-14.1823, device='cuda:0') tensor(0.2844, device='cuda:0') tensor(-5.1275e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.913027
Average KL loss: 0.387468
Average total loss: 1.300495
tensor(-14.1857, device='cuda:0') tensor(0.2841, device='cuda:0') tensor(1.6145e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.915404
Average KL loss: 0.387327
Average total loss: 1.302731
tensor(-14.1890, device='cuda:0') tensor(0.2839, device='cuda:0') tensor(-7.0670e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.915450
Average KL loss: 0.387230
Average total loss: 1.302680
tensor(-14.1923, device='cuda:0') tensor(0.2836, device='cuda:0') tensor(9.6577e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.915113
Average KL loss: 0.387118
Average total loss: 1.302231
tensor(-14.1956, device='cuda:0') tensor(0.2833, device='cuda:0') tensor(9.8971e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.911704
Average KL loss: 0.387017
Average total loss: 1.298721
tensor(-14.1989, device='cuda:0') tensor(0.2831, device='cuda:0') tensor(-2.8370e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.911974
Average KL loss: 0.386915
Average total loss: 1.298888
tensor(-14.2022, device='cuda:0') tensor(0.2828, device='cuda:0') tensor(7.8955e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.910946
Average KL loss: 0.386796
Average total loss: 1.297742
tensor(-14.2054, device='cuda:0') tensor(0.2826, device='cuda:0') tensor(5.8132e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.912476
Average KL loss: 0.386706
Average total loss: 1.299182
tensor(-14.2087, device='cuda:0') tensor(0.2823, device='cuda:0') tensor(1.3618e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.912943
Average KL loss: 0.386661
Average total loss: 1.299604
tensor(-14.2119, device='cuda:0') tensor(0.2821, device='cuda:0') tensor(-7.0047e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.911786
Average KL loss: 0.386563
Average total loss: 1.298349
tensor(-14.2152, device='cuda:0') tensor(0.2818, device='cuda:0') tensor(-1.6421e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.911547
Average KL loss: 0.386425
Average total loss: 1.297972
tensor(-14.2184, device='cuda:0') tensor(0.2816, device='cuda:0') tensor(6.9454e-11, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.911269
Average KL loss: 0.386300
Average total loss: 1.297568
tensor(-14.2216, device='cuda:0') tensor(0.2813, device='cuda:0') tensor(-1.0874e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.910248
Average KL loss: 0.386229
Average total loss: 1.296478
tensor(-14.2248, device='cuda:0') tensor(0.2811, device='cuda:0') tensor(-9.7501e-11, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.910976
Average KL loss: 0.386186
Average total loss: 1.297162
tensor(-14.2280, device='cuda:0') tensor(0.2809, device='cuda:0') tensor(7.8806e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.911093
Average KL loss: 0.386162
Average total loss: 1.297254
tensor(-14.2312, device='cuda:0') tensor(0.2806, device='cuda:0') tensor(-6.6507e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.907894
Average KL loss: 0.386108
Average total loss: 1.294002
tensor(-14.2344, device='cuda:0') tensor(0.2804, device='cuda:0') tensor(-8.5526e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.912898
Average KL loss: 0.386003
Average total loss: 1.298902
tensor(-14.2375, device='cuda:0') tensor(0.2802, device='cuda:0') tensor(-2.3182e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.907772
Average KL loss: 0.385960
Average total loss: 1.293732
tensor(-14.2407, device='cuda:0') tensor(0.2799, device='cuda:0') tensor(1.0891e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.908819
Average KL loss: 0.385878
Average total loss: 1.294697
tensor(-14.2438, device='cuda:0') tensor(0.2797, device='cuda:0') tensor(7.9800e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.909465
Average KL loss: 0.385796
Average total loss: 1.295261
tensor(-14.2470, device='cuda:0') tensor(0.2795, device='cuda:0') tensor(6.2684e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.909863
Average KL loss: 0.385691
Average total loss: 1.295554
tensor(-14.2501, device='cuda:0') tensor(0.2792, device='cuda:0') tensor(6.2479e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.908869
Average KL loss: 0.385587
Average total loss: 1.294456
tensor(-14.2532, device='cuda:0') tensor(0.2790, device='cuda:0') tensor(5.0645e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.908286
Average KL loss: 0.385528
Average total loss: 1.293814
tensor(-14.2563, device='cuda:0') tensor(0.2788, device='cuda:0') tensor(7.8664e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.905678
Average KL loss: 0.385461
Average total loss: 1.291138
tensor(-14.2594, device='cuda:0') tensor(0.2786, device='cuda:0') tensor(2.5466e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.910581
Average KL loss: 0.385328
Average total loss: 1.295909
tensor(-14.2625, device='cuda:0') tensor(0.2784, device='cuda:0') tensor(2.5883e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.907065
Average KL loss: 0.385219
Average total loss: 1.292283
tensor(-14.2655, device='cuda:0') tensor(0.2782, device='cuda:0') tensor(8.8570e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.908069
Average KL loss: 0.385148
Average total loss: 1.293216
tensor(-14.2686, device='cuda:0') tensor(0.2779, device='cuda:0') tensor(-1.7368e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.909072
Average KL loss: 0.385054
Average total loss: 1.294126
tensor(-14.2717, device='cuda:0') tensor(0.2777, device='cuda:0') tensor(5.2963e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.909128
Average KL loss: 0.384959
Average total loss: 1.294087
tensor(-14.2747, device='cuda:0') tensor(0.2775, device='cuda:0') tensor(-1.1647e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.906661
Average KL loss: 0.384880
Average total loss: 1.291541
tensor(-14.2778, device='cuda:0') tensor(0.2773, device='cuda:0') tensor(-6.4399e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.905820
Average KL loss: 0.384853
Average total loss: 1.290673
tensor(-14.2808, device='cuda:0') tensor(0.2771, device='cuda:0') tensor(-5.7249e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.907090
Average KL loss: 0.384797
Average total loss: 1.291887
tensor(-14.2838, device='cuda:0') tensor(0.2769, device='cuda:0') tensor(4.9748e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.907765
Average KL loss: 0.384746
Average total loss: 1.292510
tensor(-14.2868, device='cuda:0') tensor(0.2767, device='cuda:0') tensor(1.0365e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.905618
Average KL loss: 0.384713
Average total loss: 1.290331
tensor(-14.2898, device='cuda:0') tensor(0.2765, device='cuda:0') tensor(2.1493e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.905342
Average KL loss: 0.384625
Average total loss: 1.289967
tensor(-14.2928, device='cuda:0') tensor(0.2763, device='cuda:0') tensor(-8.9917e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.904255
Average KL loss: 0.384562
Average total loss: 1.288817
tensor(-14.2958, device='cuda:0') tensor(0.2761, device='cuda:0') tensor(2.0858e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.904255
Average KL loss: 0.384560
Average total loss: 1.288814
tensor(-14.2988, device='cuda:0') tensor(0.2759, device='cuda:0') tensor(-2.1877e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.904422
Average KL loss: 0.384531
Average total loss: 1.288953
tensor(-14.3017, device='cuda:0') tensor(0.2757, device='cuda:0') tensor(-6.5128e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.905758
Average KL loss: 0.384527
Average total loss: 1.290285
tensor(-14.3047, device='cuda:0') tensor(0.2755, device='cuda:0') tensor(8.4555e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.903821
Average KL loss: 0.384503
Average total loss: 1.288323
tensor(-14.3076, device='cuda:0') tensor(0.2753, device='cuda:0') tensor(1.3414e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.906153
Average KL loss: 0.384422
Average total loss: 1.290575
tensor(-14.3106, device='cuda:0') tensor(0.2752, device='cuda:0') tensor(-5.6285e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.905373
Average KL loss: 0.384355
Average total loss: 1.289728
tensor(-14.3135, device='cuda:0') tensor(0.2750, device='cuda:0') tensor(-1.1236e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.905239
Average KL loss: 0.384316
Average total loss: 1.289555
tensor(-14.3164, device='cuda:0') tensor(0.2748, device='cuda:0') tensor(-8.1367e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.905024
Average KL loss: 0.384246
Average total loss: 1.289271
tensor(-14.3193, device='cuda:0') tensor(0.2746, device='cuda:0') tensor(-3.9288e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.902684
Average KL loss: 0.384187
Average total loss: 1.286871
tensor(-14.3222, device='cuda:0') tensor(0.2744, device='cuda:0') tensor(-3.0554e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.905159
Average KL loss: 0.384160
Average total loss: 1.289319
tensor(-14.3251, device='cuda:0') tensor(0.2742, device='cuda:0') tensor(7.7750e-11, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.904858
Average KL loss: 0.384124
Average total loss: 1.288982
tensor(-14.3280, device='cuda:0') tensor(0.2741, device='cuda:0') tensor(9.6966e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.903998
Average KL loss: 0.384073
Average total loss: 1.288071
tensor(-14.3309, device='cuda:0') tensor(0.2739, device='cuda:0') tensor(-8.3559e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.902925
Average KL loss: 0.384007
Average total loss: 1.286932
tensor(-14.3338, device='cuda:0') tensor(0.2737, device='cuda:0') tensor(-1.3585e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.901906
Average KL loss: 0.383930
Average total loss: 1.285836
tensor(-14.3366, device='cuda:0') tensor(0.2735, device='cuda:0') tensor(1.2485e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.903857
Average KL loss: 0.383920
Average total loss: 1.287776
tensor(-14.3395, device='cuda:0') tensor(0.2734, device='cuda:0') tensor(-6.5250e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.899420
Average KL loss: 0.383865
Average total loss: 1.283285
tensor(-14.3423, device='cuda:0') tensor(0.2732, device='cuda:0') tensor(2.0069e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.904143
Average KL loss: 0.383811
Average total loss: 1.287954
tensor(-14.3452, device='cuda:0') tensor(0.2730, device='cuda:0') tensor(4.5564e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.901809
Average KL loss: 0.383785
Average total loss: 1.285595
tensor(-14.3480, device='cuda:0') tensor(0.2728, device='cuda:0') tensor(9.0694e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.902677
Average KL loss: 0.383709
Average total loss: 1.286386
tensor(-14.3508, device='cuda:0') tensor(0.2726, device='cuda:0') tensor(-8.2632e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.902471
Average KL loss: 0.383615
Average total loss: 1.286086
tensor(-14.3536, device='cuda:0') tensor(0.2725, device='cuda:0') tensor(-5.9965e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.902459
Average KL loss: 0.383594
Average total loss: 1.286053
tensor(-14.3564, device='cuda:0') tensor(0.2723, device='cuda:0') tensor(-8.4190e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.902445
Average KL loss: 0.383566
Average total loss: 1.286012
tensor(-14.3592, device='cuda:0') tensor(0.2721, device='cuda:0') tensor(1.4531e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.901788
Average KL loss: 0.383500
Average total loss: 1.285288
tensor(-14.3620, device='cuda:0') tensor(0.2720, device='cuda:0') tensor(1.1912e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.900722
Average KL loss: 0.383437
Average total loss: 1.284159
tensor(-14.3648, device='cuda:0') tensor(0.2718, device='cuda:0') tensor(1.0914e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.900685
Average KL loss: 0.383424
Average total loss: 1.284109
tensor(-14.3676, device='cuda:0') tensor(0.2716, device='cuda:0') tensor(-1.8518e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.899280
Average KL loss: 0.383377
Average total loss: 1.282657
tensor(-14.3704, device='cuda:0') tensor(0.2714, device='cuda:0') tensor(9.8192e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.899853
Average KL loss: 0.383343
Average total loss: 1.283196
tensor(-14.3731, device='cuda:0') tensor(0.2713, device='cuda:0') tensor(7.6080e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.901394
Average KL loss: 0.383303
Average total loss: 1.284697
tensor(-14.3759, device='cuda:0') tensor(0.2711, device='cuda:0') tensor(-5.4222e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.899006
Average KL loss: 0.383289
Average total loss: 1.282295
tensor(-14.3786, device='cuda:0') tensor(0.2710, device='cuda:0') tensor(2.1663e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.901429
Average KL loss: 0.383287
Average total loss: 1.284716
tensor(-14.3813, device='cuda:0') tensor(0.2708, device='cuda:0') tensor(8.6008e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.900313
Average KL loss: 0.383215
Average total loss: 1.283528
tensor(-14.3841, device='cuda:0') tensor(0.2707, device='cuda:0') tensor(-1.1101e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.897207
Average KL loss: 0.383177
Average total loss: 1.280385
tensor(-14.3868, device='cuda:0') tensor(0.2705, device='cuda:0') tensor(1.5657e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.899586
Average KL loss: 0.383097
Average total loss: 1.282683
tensor(-14.3895, device='cuda:0') tensor(0.2703, device='cuda:0') tensor(1.8031e-11, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.901923
Average KL loss: 0.383008
Average total loss: 1.284931
 Percentile value: -13.608381080627442
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =    1605 /    1728             ( 92.88%) | total_pruned =     123 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   14368 /   36864             ( 38.98%) | total_pruned =   22496 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   13918 /   36864             ( 37.75%) | total_pruned =   22946 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   10261 /   36864             ( 27.83%) | total_pruned =   26603 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    8689 /   36864             ( 23.57%) | total_pruned =   28175 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   21951 /   73728             ( 29.77%) | total_pruned =   51777 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   23851 /  147456             ( 16.17%) | total_pruned =  123605 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4521 /    8192             ( 55.19%) | total_pruned =    3671 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   14644 /  147456             (  9.93%) | total_pruned =  132812 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   10407 /  147456             (  7.06%) | total_pruned =  137049 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   22458 /  294912             (  7.62%) | total_pruned =  272454 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   17131 /  589824             (  2.90%) | total_pruned =  572693 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      69 /     256             ( 26.95%) | total_pruned =     187 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4735 /   32768             ( 14.45%) | total_pruned =   28033 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      62 /     256             ( 24.22%) | total_pruned =     194 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    5146 /  589824             (  0.87%) | total_pruned =  584678 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3323 /  589824             (  0.56%) | total_pruned =  586501 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   13012 / 1179648             (  1.10%) | total_pruned = 1166636 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      56 /     512             ( 10.94%) | total_pruned =     456 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   22366 / 2359296             (  0.95%) | total_pruned = 2336930 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     410 /     512             ( 80.08%) | total_pruned =     102 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9936 /  131072             (  7.58%) | total_pruned =  121136 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     402 /     512             ( 78.52%) | total_pruned =     110 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   27471 / 2359296             (  1.16%) | total_pruned = 2331825 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     458 /     512             ( 89.45%) | total_pruned =      54 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   40953 / 2359296             (  1.74%) | total_pruned = 2318343 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     243 /     512             ( 47.46%) | total_pruned =     269 | shape = torch.Size([512])
linear.weight        | nonzeros =    4316 /    5120             ( 84.30%) | total_pruned =     804 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       8 /      10             ( 80.00%) | total_pruned =       2 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 50/200 Loss: 0.001983 Accuracy: 83.70 100.00 % Best test Accuracy: 83.86%
tensor(-14.3922, device='cuda:0') tensor(0.2701, device='cuda:0') tensor(1.6787e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.086195
Average KL loss: 0.381757
Average total loss: 1.467952
tensor(-14.3957, device='cuda:0') tensor(0.2563, device='cuda:0') tensor(-1.9178e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.082588
Average KL loss: 0.380539
Average total loss: 1.463127
tensor(-14.3990, device='cuda:0') tensor(0.2469, device='cuda:0') tensor(-1.1194e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.073485
Average KL loss: 0.379852
Average total loss: 1.453337
tensor(-14.4022, device='cuda:0') tensor(0.2402, device='cuda:0') tensor(-5.2753e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.064230
Average KL loss: 0.379364
Average total loss: 1.443594
tensor(-14.4052, device='cuda:0') tensor(0.2353, device='cuda:0') tensor(1.6709e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.064338
Average KL loss: 0.378951
Average total loss: 1.443289
tensor(-14.4082, device='cuda:0') tensor(0.2316, device='cuda:0') tensor(2.8495e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.057609
Average KL loss: 0.378615
Average total loss: 1.436224
tensor(-14.4112, device='cuda:0') tensor(0.2286, device='cuda:0') tensor(-1.0167e-11, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.052515
Average KL loss: 0.378353
Average total loss: 1.430868
tensor(-14.4141, device='cuda:0') tensor(0.2261, device='cuda:0') tensor(-1.4131e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.043518
Average KL loss: 0.378109
Average total loss: 1.421627
tensor(-14.4169, device='cuda:0') tensor(0.2240, device='cuda:0') tensor(-1.8028e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.032243
Average KL loss: 0.377914
Average total loss: 1.410158
tensor(-14.4198, device='cuda:0') tensor(0.2221, device='cuda:0') tensor(-4.5894e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.036495
Average KL loss: 0.377754
Average total loss: 1.414249
tensor(-14.4226, device='cuda:0') tensor(0.2204, device='cuda:0') tensor(-2.5313e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.031107
Average KL loss: 0.377603
Average total loss: 1.408710
tensor(-14.4253, device='cuda:0') tensor(0.2189, device='cuda:0') tensor(-1.3239e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.030454
Average KL loss: 0.377474
Average total loss: 1.407928
tensor(-14.4281, device='cuda:0') tensor(0.2175, device='cuda:0') tensor(-2.4373e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.023323
Average KL loss: 0.377328
Average total loss: 1.400651
tensor(-14.4309, device='cuda:0') tensor(0.2163, device='cuda:0') tensor(-3.0947e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.017773
Average KL loss: 0.377186
Average total loss: 1.394959
tensor(-14.4336, device='cuda:0') tensor(0.2151, device='cuda:0') tensor(-1.5521e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.013810
Average KL loss: 0.377071
Average total loss: 1.390882
tensor(-14.4363, device='cuda:0') tensor(0.2141, device='cuda:0') tensor(-1.8444e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.015761
Average KL loss: 0.376917
Average total loss: 1.392678
tensor(-14.4390, device='cuda:0') tensor(0.2131, device='cuda:0') tensor(-3.3266e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.007204
Average KL loss: 0.376765
Average total loss: 1.383969
tensor(-14.4417, device='cuda:0') tensor(0.2121, device='cuda:0') tensor(-9.4683e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.003822
Average KL loss: 0.376596
Average total loss: 1.380418
tensor(-14.4444, device='cuda:0') tensor(0.2113, device='cuda:0') tensor(-3.0688e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.999480
Average KL loss: 0.376448
Average total loss: 1.375928
tensor(-14.4471, device='cuda:0') tensor(0.2104, device='cuda:0') tensor(2.7020e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.999760
Average KL loss: 0.376276
Average total loss: 1.376036
tensor(-14.4497, device='cuda:0') tensor(0.2097, device='cuda:0') tensor(-2.6032e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.999570
Average KL loss: 0.376137
Average total loss: 1.375708
tensor(-14.4524, device='cuda:0') tensor(0.2089, device='cuda:0') tensor(-1.1065e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.995256
Average KL loss: 0.376060
Average total loss: 1.371316
tensor(-14.4550, device='cuda:0') tensor(0.2083, device='cuda:0') tensor(1.8894e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.991147
Average KL loss: 0.375969
Average total loss: 1.367116
tensor(-14.4577, device='cuda:0') tensor(0.2077, device='cuda:0') tensor(-1.6737e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.988123
Average KL loss: 0.375855
Average total loss: 1.363977
tensor(-14.4603, device='cuda:0') tensor(0.2070, device='cuda:0') tensor(-4.2476e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.984545
Average KL loss: 0.375754
Average total loss: 1.360299
tensor(-14.4629, device='cuda:0') tensor(0.2064, device='cuda:0') tensor(-2.2881e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.984531
Average KL loss: 0.375652
Average total loss: 1.360183
tensor(-14.4655, device='cuda:0') tensor(0.2059, device='cuda:0') tensor(4.6680e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.979941
Average KL loss: 0.375540
Average total loss: 1.355481
tensor(-14.4681, device='cuda:0') tensor(0.2054, device='cuda:0') tensor(6.7250e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.979628
Average KL loss: 0.375431
Average total loss: 1.355059
tensor(-14.4706, device='cuda:0') tensor(0.2049, device='cuda:0') tensor(-4.2165e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.980796
Average KL loss: 0.375341
Average total loss: 1.356136
tensor(-14.4732, device='cuda:0') tensor(0.2044, device='cuda:0') tensor(-2.1631e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.978305
Average KL loss: 0.375239
Average total loss: 1.353544
tensor(-14.4758, device='cuda:0') tensor(0.2039, device='cuda:0') tensor(-2.0714e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.974188
Average KL loss: 0.375117
Average total loss: 1.349306
tensor(-14.4783, device='cuda:0') tensor(0.2035, device='cuda:0') tensor(-1.6204e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.974822
Average KL loss: 0.375049
Average total loss: 1.349871
tensor(-14.4809, device='cuda:0') tensor(0.2031, device='cuda:0') tensor(-1.0056e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.972515
Average KL loss: 0.375004
Average total loss: 1.347519
tensor(-14.4834, device='cuda:0') tensor(0.2027, device='cuda:0') tensor(-4.3672e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.972837
Average KL loss: 0.374911
Average total loss: 1.347748
tensor(-14.4859, device='cuda:0') tensor(0.2023, device='cuda:0') tensor(3.2424e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.967264
Average KL loss: 0.374769
Average total loss: 1.342033
tensor(-14.4885, device='cuda:0') tensor(0.2020, device='cuda:0') tensor(-4.8969e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.967307
Average KL loss: 0.374675
Average total loss: 1.341982
tensor(-14.4910, device='cuda:0') tensor(0.2016, device='cuda:0') tensor(1.5544e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.969156
Average KL loss: 0.374601
Average total loss: 1.343757
tensor(-14.4935, device='cuda:0') tensor(0.2013, device='cuda:0') tensor(5.7223e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.966104
Average KL loss: 0.374443
Average total loss: 1.340547
tensor(-14.4960, device='cuda:0') tensor(0.2009, device='cuda:0') tensor(1.5625e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.966075
Average KL loss: 0.374306
Average total loss: 1.340381
tensor(-14.4985, device='cuda:0') tensor(0.2006, device='cuda:0') tensor(-6.8915e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.962943
Average KL loss: 0.374171
Average total loss: 1.337114
tensor(-14.5010, device='cuda:0') tensor(0.2003, device='cuda:0') tensor(-8.4289e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.968122
Average KL loss: 0.374063
Average total loss: 1.342185
tensor(-14.5034, device='cuda:0') tensor(0.2000, device='cuda:0') tensor(-1.7484e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.962436
Average KL loss: 0.373991
Average total loss: 1.336426
tensor(-14.5059, device='cuda:0') tensor(0.1997, device='cuda:0') tensor(-1.4750e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.959113
Average KL loss: 0.373942
Average total loss: 1.333055
tensor(-14.5084, device='cuda:0') tensor(0.1995, device='cuda:0') tensor(-1.9274e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.957591
Average KL loss: 0.373844
Average total loss: 1.331435
tensor(-14.5108, device='cuda:0') tensor(0.1992, device='cuda:0') tensor(3.3158e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.962725
Average KL loss: 0.373750
Average total loss: 1.336475
tensor(-14.5133, device='cuda:0') tensor(0.1989, device='cuda:0') tensor(1.4740e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.958513
Average KL loss: 0.373681
Average total loss: 1.332194
tensor(-14.5157, device='cuda:0') tensor(0.1987, device='cuda:0') tensor(-5.8826e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.958192
Average KL loss: 0.373641
Average total loss: 1.331833
tensor(-14.5181, device='cuda:0') tensor(0.1984, device='cuda:0') tensor(1.6853e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.957060
Average KL loss: 0.373594
Average total loss: 1.330654
tensor(-14.5206, device='cuda:0') tensor(0.1982, device='cuda:0') tensor(-5.2915e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.954929
Average KL loss: 0.373520
Average total loss: 1.328449
tensor(-14.5230, device='cuda:0') tensor(0.1980, device='cuda:0') tensor(6.9371e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.953380
Average KL loss: 0.373395
Average total loss: 1.326775
tensor(-14.5254, device='cuda:0') tensor(0.1977, device='cuda:0') tensor(-1.8983e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.955484
Average KL loss: 0.373279
Average total loss: 1.328763
tensor(-14.5278, device='cuda:0') tensor(0.1975, device='cuda:0') tensor(-1.2683e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.952631
Average KL loss: 0.373197
Average total loss: 1.325828
tensor(-14.5302, device='cuda:0') tensor(0.1973, device='cuda:0') tensor(-3.7898e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.954024
Average KL loss: 0.373133
Average total loss: 1.327157
tensor(-14.5326, device='cuda:0') tensor(0.1971, device='cuda:0') tensor(3.6657e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.950990
Average KL loss: 0.373066
Average total loss: 1.324056
tensor(-14.5350, device='cuda:0') tensor(0.1969, device='cuda:0') tensor(-1.5512e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.947369
Average KL loss: 0.373020
Average total loss: 1.320388
tensor(-14.5374, device='cuda:0') tensor(0.1967, device='cuda:0') tensor(1.9273e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.949561
Average KL loss: 0.372975
Average total loss: 1.322537
tensor(-14.5397, device='cuda:0') tensor(0.1965, device='cuda:0') tensor(1.9054e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.952087
Average KL loss: 0.372915
Average total loss: 1.325003
tensor(-14.5421, device='cuda:0') tensor(0.1963, device='cuda:0') tensor(4.6088e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.946519
Average KL loss: 0.372851
Average total loss: 1.319370
tensor(-14.5445, device='cuda:0') tensor(0.1962, device='cuda:0') tensor(6.1966e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.945489
Average KL loss: 0.372835
Average total loss: 1.318324
tensor(-14.5468, device='cuda:0') tensor(0.1960, device='cuda:0') tensor(-1.6199e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.948067
Average KL loss: 0.372794
Average total loss: 1.320861
tensor(-14.5492, device='cuda:0') tensor(0.1959, device='cuda:0') tensor(-1.9589e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.944463
Average KL loss: 0.372707
Average total loss: 1.317170
tensor(-14.5515, device='cuda:0') tensor(0.1957, device='cuda:0') tensor(1.2051e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.944174
Average KL loss: 0.372577
Average total loss: 1.316751
tensor(-14.5539, device='cuda:0') tensor(0.1955, device='cuda:0') tensor(-2.6107e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.945082
Average KL loss: 0.372454
Average total loss: 1.317536
tensor(-14.5562, device='cuda:0') tensor(0.1954, device='cuda:0') tensor(-1.8156e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.944492
Average KL loss: 0.372372
Average total loss: 1.316864
tensor(-14.5585, device='cuda:0') tensor(0.1952, device='cuda:0') tensor(7.7281e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.942938
Average KL loss: 0.372326
Average total loss: 1.315264
tensor(-14.5609, device='cuda:0') tensor(0.1951, device='cuda:0') tensor(-2.4110e-11, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.945163
Average KL loss: 0.372189
Average total loss: 1.317352
tensor(-14.5632, device='cuda:0') tensor(0.1949, device='cuda:0') tensor(3.0393e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.941872
Average KL loss: 0.372065
Average total loss: 1.313937
tensor(-14.5655, device='cuda:0') tensor(0.1948, device='cuda:0') tensor(-2.2741e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.941237
Average KL loss: 0.371978
Average total loss: 1.313215
tensor(-14.5678, device='cuda:0') tensor(0.1946, device='cuda:0') tensor(6.6597e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.940258
Average KL loss: 0.371865
Average total loss: 1.312122
tensor(-14.5701, device='cuda:0') tensor(0.1945, device='cuda:0') tensor(-2.2404e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.937038
Average KL loss: 0.371780
Average total loss: 1.308817
tensor(-14.5724, device='cuda:0') tensor(0.1944, device='cuda:0') tensor(-1.1809e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.939422
Average KL loss: 0.371697
Average total loss: 1.311119
tensor(-14.5747, device='cuda:0') tensor(0.1943, device='cuda:0') tensor(-5.4316e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.936627
Average KL loss: 0.371593
Average total loss: 1.308219
tensor(-14.5770, device='cuda:0') tensor(0.1941, device='cuda:0') tensor(-3.4508e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.937120
Average KL loss: 0.371494
Average total loss: 1.308613
tensor(-14.5792, device='cuda:0') tensor(0.1940, device='cuda:0') tensor(7.5448e-12, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.935702
Average KL loss: 0.371421
Average total loss: 1.307123
tensor(-14.5815, device='cuda:0') tensor(0.1939, device='cuda:0') tensor(9.4441e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.938547
Average KL loss: 0.371349
Average total loss: 1.309896
tensor(-14.5838, device='cuda:0') tensor(0.1938, device='cuda:0') tensor(-3.7000e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.938349
Average KL loss: 0.371300
Average total loss: 1.309649
tensor(-14.5860, device='cuda:0') tensor(0.1936, device='cuda:0') tensor(-1.5984e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.934385
Average KL loss: 0.371223
Average total loss: 1.305608
tensor(-14.5883, device='cuda:0') tensor(0.1935, device='cuda:0') tensor(1.4776e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.936765
Average KL loss: 0.371169
Average total loss: 1.307934
tensor(-14.5905, device='cuda:0') tensor(0.1934, device='cuda:0') tensor(-3.4342e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.938300
Average KL loss: 0.371121
Average total loss: 1.309421
tensor(-14.5928, device='cuda:0') tensor(0.1933, device='cuda:0') tensor(-3.2297e-11, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.935035
Average KL loss: 0.371063
Average total loss: 1.306097
tensor(-14.5950, device='cuda:0') tensor(0.1932, device='cuda:0') tensor(-1.9886e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.936444
Average KL loss: 0.371014
Average total loss: 1.307458
tensor(-14.5972, device='cuda:0') tensor(0.1931, device='cuda:0') tensor(-2.5980e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.936429
Average KL loss: 0.370992
Average total loss: 1.307420
tensor(-14.5995, device='cuda:0') tensor(0.1931, device='cuda:0') tensor(-2.1786e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.932981
Average KL loss: 0.370965
Average total loss: 1.303946
tensor(-14.6017, device='cuda:0') tensor(0.1930, device='cuda:0') tensor(1.0523e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.933641
Average KL loss: 0.370910
Average total loss: 1.304552
tensor(-14.6039, device='cuda:0') tensor(0.1929, device='cuda:0') tensor(-3.1388e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.933864
Average KL loss: 0.370872
Average total loss: 1.304735
tensor(-14.6061, device='cuda:0') tensor(0.1928, device='cuda:0') tensor(6.8050e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.933265
Average KL loss: 0.370823
Average total loss: 1.304088
tensor(-14.6083, device='cuda:0') tensor(0.1927, device='cuda:0') tensor(-2.5109e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.932398
Average KL loss: 0.370770
Average total loss: 1.303168
tensor(-14.6105, device='cuda:0') tensor(0.1927, device='cuda:0') tensor(-9.9835e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.932535
Average KL loss: 0.370703
Average total loss: 1.303238
tensor(-14.6127, device='cuda:0') tensor(0.1926, device='cuda:0') tensor(3.9077e-11, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.930322
Average KL loss: 0.370622
Average total loss: 1.300944
tensor(-14.6149, device='cuda:0') tensor(0.1925, device='cuda:0') tensor(-8.6529e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.931069
Average KL loss: 0.370546
Average total loss: 1.301615
tensor(-14.6171, device='cuda:0') tensor(0.1924, device='cuda:0') tensor(1.3797e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.929678
Average KL loss: 0.370471
Average total loss: 1.300149
tensor(-14.6193, device='cuda:0') tensor(0.1923, device='cuda:0') tensor(-1.5696e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.931182
Average KL loss: 0.370404
Average total loss: 1.301585
tensor(-14.6215, device='cuda:0') tensor(0.1923, device='cuda:0') tensor(-1.0793e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.930129
Average KL loss: 0.370305
Average total loss: 1.300434
tensor(-14.6236, device='cuda:0') tensor(0.1922, device='cuda:0') tensor(-1.9935e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.925955
Average KL loss: 0.370210
Average total loss: 1.296166
tensor(-14.6258, device='cuda:0') tensor(0.1921, device='cuda:0') tensor(-1.5622e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.927429
Average KL loss: 0.370163
Average total loss: 1.297593
tensor(-14.6280, device='cuda:0') tensor(0.1920, device='cuda:0') tensor(-4.5152e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.927434
Average KL loss: 0.370079
Average total loss: 1.297512
tensor(-14.6301, device='cuda:0') tensor(0.1920, device='cuda:0') tensor(-1.2407e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.926525
Average KL loss: 0.370051
Average total loss: 1.296576
tensor(-14.6323, device='cuda:0') tensor(0.1919, device='cuda:0') tensor(2.4538e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.928924
Average KL loss: 0.370000
Average total loss: 1.298924
tensor(-14.6344, device='cuda:0') tensor(0.1919, device='cuda:0') tensor(-7.5886e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.925894
Average KL loss: 0.369932
Average total loss: 1.295826
tensor(-14.6366, device='cuda:0') tensor(0.1918, device='cuda:0') tensor(6.8228e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.925196
Average KL loss: 0.369870
Average total loss: 1.295066
tensor(-14.6387, device='cuda:0') tensor(0.1917, device='cuda:0') tensor(-6.5123e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.926545
Average KL loss: 0.369802
Average total loss: 1.296347
tensor(-14.6409, device='cuda:0') tensor(0.1917, device='cuda:0') tensor(-1.6089e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.927165
Average KL loss: 0.369745
Average total loss: 1.296910
tensor(-14.6430, device='cuda:0') tensor(0.1916, device='cuda:0') tensor(1.4941e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.926597
Average KL loss: 0.369682
Average total loss: 1.296280
tensor(-14.6451, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(1.5528e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.925154
Average KL loss: 0.369623
Average total loss: 1.294777
tensor(-14.6472, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(-2.8783e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.924460
Average KL loss: 0.369560
Average total loss: 1.294020
tensor(-14.6493, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(1.9215e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.921651
Average KL loss: 0.369539
Average total loss: 1.291189
tensor(-14.6515, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-2.1004e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.924544
Average KL loss: 0.369487
Average total loss: 1.294032
tensor(-14.6536, device='cuda:0') tensor(0.1913, device='cuda:0') tensor(-7.4416e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.923319
Average KL loss: 0.369380
Average total loss: 1.292699
tensor(-14.6557, device='cuda:0') tensor(0.1912, device='cuda:0') tensor(1.2717e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.924337
Average KL loss: 0.369302
Average total loss: 1.293639
tensor(-14.6578, device='cuda:0') tensor(0.1912, device='cuda:0') tensor(7.2853e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.921595
Average KL loss: 0.369231
Average total loss: 1.290826
tensor(-14.6599, device='cuda:0') tensor(0.1911, device='cuda:0') tensor(-1.1833e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.924079
Average KL loss: 0.369176
Average total loss: 1.293255
tensor(-14.6620, device='cuda:0') tensor(0.1911, device='cuda:0') tensor(-2.9364e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.921850
Average KL loss: 0.369122
Average total loss: 1.290973
tensor(-14.6640, device='cuda:0') tensor(0.1910, device='cuda:0') tensor(1.8924e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.922123
Average KL loss: 0.369060
Average total loss: 1.291183
tensor(-14.6661, device='cuda:0') tensor(0.1910, device='cuda:0') tensor(-8.4274e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.922046
Average KL loss: 0.369024
Average total loss: 1.291069
tensor(-14.6682, device='cuda:0') tensor(0.1909, device='cuda:0') tensor(-5.9007e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.921623
Average KL loss: 0.368969
Average total loss: 1.290592
tensor(-14.6703, device='cuda:0') tensor(0.1909, device='cuda:0') tensor(-3.3055e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.923452
Average KL loss: 0.368892
Average total loss: 1.292344
tensor(-14.6723, device='cuda:0') tensor(0.1909, device='cuda:0') tensor(-3.9643e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.922345
Average KL loss: 0.368796
Average total loss: 1.291141
tensor(-14.6744, device='cuda:0') tensor(0.1908, device='cuda:0') tensor(1.2406e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.919070
Average KL loss: 0.368741
Average total loss: 1.287811
tensor(-14.6764, device='cuda:0') tensor(0.1908, device='cuda:0') tensor(-5.2183e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.920813
Average KL loss: 0.368674
Average total loss: 1.289487
tensor(-14.6785, device='cuda:0') tensor(0.1907, device='cuda:0') tensor(-1.3804e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.917638
Average KL loss: 0.368613
Average total loss: 1.286250
tensor(-14.6805, device='cuda:0') tensor(0.1907, device='cuda:0') tensor(-4.1199e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.924183
Average KL loss: 0.368520
Average total loss: 1.292703
tensor(-14.6826, device='cuda:0') tensor(0.1906, device='cuda:0') tensor(-1.0214e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.920670
Average KL loss: 0.368441
Average total loss: 1.289112
tensor(-14.6846, device='cuda:0') tensor(0.1906, device='cuda:0') tensor(-4.9965e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.920439
Average KL loss: 0.368407
Average total loss: 1.288846
tensor(-14.6867, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-8.6995e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.920464
Average KL loss: 0.368368
Average total loss: 1.288831
tensor(-14.6887, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-1.3419e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.920292
Average KL loss: 0.368338
Average total loss: 1.288630
tensor(-14.6907, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(1.4547e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.918105
Average KL loss: 0.368274
Average total loss: 1.286379
tensor(-14.6928, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-8.2661e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.920340
Average KL loss: 0.368220
Average total loss: 1.288560
tensor(-14.6948, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(7.8171e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.920155
Average KL loss: 0.368189
Average total loss: 1.288344
tensor(-14.6968, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(9.8429e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.918205
Average KL loss: 0.368132
Average total loss: 1.286338
tensor(-14.6988, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(3.9534e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.920540
Average KL loss: 0.368053
Average total loss: 1.288593
tensor(-14.7008, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(2.4770e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.917109
Average KL loss: 0.368020
Average total loss: 1.285130
tensor(-14.7028, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-7.4247e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.916972
Average KL loss: 0.368013
Average total loss: 1.284985
tensor(-14.7048, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-2.0401e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.917196
Average KL loss: 0.367977
Average total loss: 1.285173
tensor(-14.7068, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-1.2116e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.916449
Average KL loss: 0.367965
Average total loss: 1.284414
tensor(-14.7088, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(5.2048e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.917054
Average KL loss: 0.367954
Average total loss: 1.285008
tensor(-14.7108, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-1.8406e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.917962
Average KL loss: 0.367904
Average total loss: 1.285866
tensor(-14.7128, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-1.7513e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.913761
Average KL loss: 0.367855
Average total loss: 1.281616
tensor(-14.7147, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(8.2905e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.917576
Average KL loss: 0.367796
Average total loss: 1.285372
tensor(-14.7167, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(-1.5899e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.916897
Average KL loss: 0.367751
Average total loss: 1.284648
tensor(-14.7187, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(-5.4439e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.916478
Average KL loss: 0.367684
Average total loss: 1.284162
tensor(-14.7206, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(4.5167e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.915326
Average KL loss: 0.367651
Average total loss: 1.282977
tensor(-14.7226, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(-2.2527e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.914035
Average KL loss: 0.367612
Average total loss: 1.281647
tensor(-14.7246, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(9.3935e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.914390
Average KL loss: 0.367543
Average total loss: 1.281933
tensor(-14.7265, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(-8.5647e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.914876
Average KL loss: 0.367490
Average total loss: 1.282365
tensor(-14.7285, device='cuda:0') tensor(0.1899, device='cuda:0') tensor(-6.5338e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.914475
Average KL loss: 0.367432
Average total loss: 1.281907
tensor(-14.7304, device='cuda:0') tensor(0.1899, device='cuda:0') tensor(1.0046e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.914680
Average KL loss: 0.367360
Average total loss: 1.282041
tensor(-14.7324, device='cuda:0') tensor(0.1899, device='cuda:0') tensor(1.5697e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.915815
Average KL loss: 0.367309
Average total loss: 1.283124
tensor(-14.7343, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-1.5018e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.914982
Average KL loss: 0.367222
Average total loss: 1.282204
tensor(-14.7362, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(4.5503e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.914246
Average KL loss: 0.367159
Average total loss: 1.281406
tensor(-14.7364, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-8.0066e-11, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.912893
Average KL loss: 0.367149
Average total loss: 1.280042
tensor(-14.7366, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-1.0028e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.914746
Average KL loss: 0.367141
Average total loss: 1.281887
tensor(-14.7368, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-8.7396e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.915729
Average KL loss: 0.367138
Average total loss: 1.282867
tensor(-14.7370, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(8.6579e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.914354
Average KL loss: 0.367132
Average total loss: 1.281486
tensor(-14.7372, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-7.0359e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.915696
Average KL loss: 0.367125
Average total loss: 1.282821
tensor(-14.7374, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-7.1996e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.912963
Average KL loss: 0.367118
Average total loss: 1.280081
tensor(-14.7376, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-3.7780e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.914200
Average KL loss: 0.367110
Average total loss: 1.281310
tensor(-14.7378, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-1.0788e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.913871
Average KL loss: 0.367106
Average total loss: 1.280977
tensor(-14.7380, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(1.3606e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.916392
Average KL loss: 0.367102
Average total loss: 1.283493
tensor(-14.7382, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(5.7886e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.915067
Average KL loss: 0.367094
Average total loss: 1.282161
tensor(-14.7384, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-2.8265e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.916791
Average KL loss: 0.367086
Average total loss: 1.283877
tensor(-14.7385, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-7.0879e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.914544
Average KL loss: 0.367078
Average total loss: 1.281622
tensor(-14.7387, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-2.6992e-12, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.917181
Average KL loss: 0.367074
Average total loss: 1.284255
tensor(-14.7387, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-1.8317e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.916580
Average KL loss: 0.367073
Average total loss: 1.283653
tensor(-14.7387, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-4.3170e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.915545
Average KL loss: 0.367072
Average total loss: 1.282618
tensor(-14.7387, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-4.3297e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.913607
Average KL loss: 0.367072
Average total loss: 1.280679
tensor(-14.7387, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-6.7309e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.913309
Average KL loss: 0.367071
Average total loss: 1.280380
tensor(-14.7387, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(1.1408e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.912607
Average KL loss: 0.367071
Average total loss: 1.279678
tensor(-14.7387, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-5.0428e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.911393
Average KL loss: 0.367070
Average total loss: 1.278463
tensor(-14.7387, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-7.4149e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.912483
Average KL loss: 0.367069
Average total loss: 1.279552
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(4.1878e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.915836
Average KL loss: 0.367069
Average total loss: 1.282905
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(1.7324e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.914776
Average KL loss: 0.367068
Average total loss: 1.281844
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(6.3541e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.913711
Average KL loss: 0.367068
Average total loss: 1.280778
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-2.9844e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.913419
Average KL loss: 0.367067
Average total loss: 1.280487
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-5.5567e-12, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.914433
Average KL loss: 0.367067
Average total loss: 1.281499
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-8.7562e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.917425
Average KL loss: 0.367066
Average total loss: 1.284491
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-1.2926e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.915089
Average KL loss: 0.367065
Average total loss: 1.282155
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(3.9611e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.913043
Average KL loss: 0.367065
Average total loss: 1.280108
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-2.1284e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.912501
Average KL loss: 0.367064
Average total loss: 1.279566
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(8.0082e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.913509
Average KL loss: 0.367063
Average total loss: 1.280572
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(3.0187e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.913648
Average KL loss: 0.367063
Average total loss: 1.280711
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(4.7139e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.911024
Average KL loss: 0.367063
Average total loss: 1.278087
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-6.2198e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.912921
Average KL loss: 0.367063
Average total loss: 1.279984
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-1.4179e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.914200
Average KL loss: 0.367063
Average total loss: 1.281263
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-4.2223e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.914397
Average KL loss: 0.367063
Average total loss: 1.281460
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(1.6679e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.917145
Average KL loss: 0.367063
Average total loss: 1.284207
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(4.3525e-11, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.913798
Average KL loss: 0.367063
Average total loss: 1.280861
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-8.5283e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.914876
Average KL loss: 0.367063
Average total loss: 1.281939
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-1.5752e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.912520
Average KL loss: 0.367063
Average total loss: 1.279583
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-1.6060e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.915672
Average KL loss: 0.367062
Average total loss: 1.282735
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-6.8744e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.913014
Average KL loss: 0.367062
Average total loss: 1.280076
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(4.6642e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.915620
Average KL loss: 0.367062
Average total loss: 1.282682
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-3.0548e-11, device='cuda:0')
 Percentile value: -13.395746994018555
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =    1304 /    1728             ( 75.46%) | total_pruned =     424 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5733 /   36864             ( 15.55%) | total_pruned =   31131 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5625 /   36864             ( 15.26%) | total_pruned =   31239 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4432 /   36864             ( 12.02%) | total_pruned =   32432 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3378 /   36864             (  9.16%) | total_pruned =   33486 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8567 /   73728             ( 11.62%) | total_pruned =   65161 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    7874 /  147456             (  5.34%) | total_pruned =  139582 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1934 /    8192             ( 23.61%) | total_pruned =    6258 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4365 /  147456             (  2.96%) | total_pruned =  143091 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2668 /  147456             (  1.81%) | total_pruned =  144788 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6895 /  294912             (  2.34%) | total_pruned =  288017 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5075 /  589824             (  0.86%) | total_pruned =  584749 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1489 /   32768             (  4.54%) | total_pruned =   31279 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      67 /     256             ( 26.17%) | total_pruned =     189 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1352 /  589824             (  0.23%) | total_pruned =  588472 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     880 /  589824             (  0.15%) | total_pruned =  588944 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    3127 / 1179648             (  0.27%) | total_pruned = 1176521 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    5142 / 2359296             (  0.22%) | total_pruned = 2354154 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     185 /     512             ( 36.13%) | total_pruned =     327 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     124 /     512             ( 24.22%) | total_pruned =     388 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2747 /  131072             (  2.10%) | total_pruned =  128325 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     197 /     512             ( 38.48%) | total_pruned =     315 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    4992 / 2359296             (  0.21%) | total_pruned = 2354304 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    8766 / 2359296             (  0.37%) | total_pruned = 2350530 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     216 /     512             ( 42.19%) | total_pruned =     296 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      68 /     512             ( 13.28%) | total_pruned =     444 | shape = torch.Size([512])
linear.weight        | nonzeros =    1826 /    5120             ( 35.66%) | total_pruned =    3294 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       5 /      10             ( 50.00%) | total_pruned =       5 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 58/200 Loss: 0.010829 Accuracy: 79.98 100.00 % Best test Accuracy: 80.37%
tensor(-14.7388, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(2.1848e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.796654
Average KL loss: 0.366370
Average total loss: 2.163024
tensor(-14.7410, device='cuda:0') tensor(0.1828, device='cuda:0') tensor(2.8979e-11, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.765249
Average KL loss: 0.365642
Average total loss: 2.130891
tensor(-14.7431, device='cuda:0') tensor(0.1784, device='cuda:0') tensor(5.4908e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.749297
Average KL loss: 0.365140
Average total loss: 2.114437
tensor(-14.7452, device='cuda:0') tensor(0.1754, device='cuda:0') tensor(1.5083e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.696412
Average KL loss: 0.364764
Average total loss: 2.061176
tensor(-14.7472, device='cuda:0') tensor(0.1736, device='cuda:0') tensor(5.4519e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.657999
Average KL loss: 0.364495
Average total loss: 2.022494
tensor(-14.7492, device='cuda:0') tensor(0.1723, device='cuda:0') tensor(6.0429e-11, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.643209
Average KL loss: 0.364256
Average total loss: 2.007465
tensor(-14.7512, device='cuda:0') tensor(0.1713, device='cuda:0') tensor(4.6427e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.617840
Average KL loss: 0.364014
Average total loss: 1.981854
tensor(-14.7532, device='cuda:0') tensor(0.1705, device='cuda:0') tensor(9.4843e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.567587
Average KL loss: 0.363735
Average total loss: 1.931322
tensor(-14.7551, device='cuda:0') tensor(0.1698, device='cuda:0') tensor(-2.3633e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.553101
Average KL loss: 0.363480
Average total loss: 1.916581
tensor(-14.7571, device='cuda:0') tensor(0.1692, device='cuda:0') tensor(1.1293e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.529717
Average KL loss: 0.363223
Average total loss: 1.892940
tensor(-14.7590, device='cuda:0') tensor(0.1687, device='cuda:0') tensor(2.4681e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.482757
Average KL loss: 0.362972
Average total loss: 1.845729
tensor(-14.7610, device='cuda:0') tensor(0.1682, device='cuda:0') tensor(1.1614e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.487197
Average KL loss: 0.362714
Average total loss: 1.849910
tensor(-14.7629, device='cuda:0') tensor(0.1677, device='cuda:0') tensor(5.6229e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.447036
Average KL loss: 0.362490
Average total loss: 1.809526
tensor(-14.7648, device='cuda:0') tensor(0.1673, device='cuda:0') tensor(1.5089e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.426654
Average KL loss: 0.362219
Average total loss: 1.788873
tensor(-14.7667, device='cuda:0') tensor(0.1669, device='cuda:0') tensor(7.7709e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.421279
Average KL loss: 0.361971
Average total loss: 1.783251
tensor(-14.7687, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-6.3415e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.398265
Average KL loss: 0.361735
Average total loss: 1.760000
tensor(-14.7706, device='cuda:0') tensor(0.1662, device='cuda:0') tensor(-5.4504e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.386152
Average KL loss: 0.361500
Average total loss: 1.747653
tensor(-14.7725, device='cuda:0') tensor(0.1659, device='cuda:0') tensor(5.7109e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.367177
Average KL loss: 0.361289
Average total loss: 1.728466
tensor(-14.7744, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(-1.3585e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.347466
Average KL loss: 0.361076
Average total loss: 1.708542
tensor(-14.7762, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(1.0591e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.338280
Average KL loss: 0.360866
Average total loss: 1.699147
tensor(-14.7781, device='cuda:0') tensor(0.1651, device='cuda:0') tensor(1.0561e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.319800
Average KL loss: 0.360625
Average total loss: 1.680425
tensor(-14.7800, device='cuda:0') tensor(0.1648, device='cuda:0') tensor(2.3792e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.302880
Average KL loss: 0.360418
Average total loss: 1.663298
tensor(-14.7819, device='cuda:0') tensor(0.1646, device='cuda:0') tensor(7.4051e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.284018
Average KL loss: 0.360235
Average total loss: 1.644253
tensor(-14.7837, device='cuda:0') tensor(0.1644, device='cuda:0') tensor(4.1666e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.283931
Average KL loss: 0.360056
Average total loss: 1.643987
tensor(-14.7856, device='cuda:0') tensor(0.1641, device='cuda:0') tensor(5.1067e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.275428
Average KL loss: 0.359855
Average total loss: 1.635283
tensor(-14.7875, device='cuda:0') tensor(0.1640, device='cuda:0') tensor(-6.0457e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.252848
Average KL loss: 0.359653
Average total loss: 1.612501
tensor(-14.7893, device='cuda:0') tensor(0.1638, device='cuda:0') tensor(5.2911e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.254019
Average KL loss: 0.359453
Average total loss: 1.613473
tensor(-14.7912, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(2.0839e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.252139
Average KL loss: 0.359240
Average total loss: 1.611380
tensor(-14.7930, device='cuda:0') tensor(0.1634, device='cuda:0') tensor(-7.9742e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.245838
Average KL loss: 0.359048
Average total loss: 1.604886
tensor(-14.7949, device='cuda:0') tensor(0.1633, device='cuda:0') tensor(-4.4844e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.227041
Average KL loss: 0.358839
Average total loss: 1.585880
tensor(-14.7967, device='cuda:0') tensor(0.1632, device='cuda:0') tensor(4.2272e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.221653
Average KL loss: 0.358695
Average total loss: 1.580348
tensor(-14.7986, device='cuda:0') tensor(0.1630, device='cuda:0') tensor(5.5195e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.217181
Average KL loss: 0.358528
Average total loss: 1.575709
tensor(-14.8004, device='cuda:0') tensor(0.1628, device='cuda:0') tensor(2.0067e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.208593
Average KL loss: 0.358332
Average total loss: 1.566925
tensor(-14.8022, device='cuda:0') tensor(0.1627, device='cuda:0') tensor(1.9302e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.208367
Average KL loss: 0.358161
Average total loss: 1.566528
tensor(-14.8041, device='cuda:0') tensor(0.1626, device='cuda:0') tensor(5.3023e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.197853
Average KL loss: 0.357959
Average total loss: 1.555812
tensor(-14.8059, device='cuda:0') tensor(0.1624, device='cuda:0') tensor(-8.0734e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.194258
Average KL loss: 0.357777
Average total loss: 1.552034
tensor(-14.8077, device='cuda:0') tensor(0.1623, device='cuda:0') tensor(3.7940e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.200120
Average KL loss: 0.357578
Average total loss: 1.557698
tensor(-14.8095, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(1.2776e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.188529
Average KL loss: 0.357407
Average total loss: 1.545935
tensor(-14.8113, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(4.4135e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.183117
Average KL loss: 0.357204
Average total loss: 1.540321
tensor(-14.8131, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-4.9463e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.183886
Average KL loss: 0.357063
Average total loss: 1.540949
tensor(-14.8149, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(-1.2198e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.180286
Average KL loss: 0.356916
Average total loss: 1.537202
tensor(-14.8167, device='cuda:0') tensor(0.1619, device='cuda:0') tensor(-9.4136e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.167495
Average KL loss: 0.356770
Average total loss: 1.524265
tensor(-14.8185, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(-7.0751e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.166941
Average KL loss: 0.356635
Average total loss: 1.523576
tensor(-14.8203, device='cuda:0') tensor(0.1617, device='cuda:0') tensor(2.6957e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.153302
Average KL loss: 0.356504
Average total loss: 1.509806
tensor(-14.8221, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-4.8214e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.165674
Average KL loss: 0.356335
Average total loss: 1.522009
tensor(-14.8239, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-5.3179e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.153410
Average KL loss: 0.356233
Average total loss: 1.509644
tensor(-14.8257, device='cuda:0') tensor(0.1615, device='cuda:0') tensor(-1.3576e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.142594
Average KL loss: 0.356110
Average total loss: 1.498704
tensor(-14.8275, device='cuda:0') tensor(0.1614, device='cuda:0') tensor(-5.8387e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.153226
Average KL loss: 0.355988
Average total loss: 1.509214
tensor(-14.8292, device='cuda:0') tensor(0.1614, device='cuda:0') tensor(7.6080e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.141632
Average KL loss: 0.355852
Average total loss: 1.497485
tensor(-14.8310, device='cuda:0') tensor(0.1613, device='cuda:0') tensor(2.7216e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.147247
Average KL loss: 0.355700
Average total loss: 1.502948
tensor(-14.8328, device='cuda:0') tensor(0.1612, device='cuda:0') tensor(2.6332e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.138597
Average KL loss: 0.355544
Average total loss: 1.494142
tensor(-14.8345, device='cuda:0') tensor(0.1612, device='cuda:0') tensor(3.5963e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.135333
Average KL loss: 0.355393
Average total loss: 1.490726
tensor(-14.8363, device='cuda:0') tensor(0.1611, device='cuda:0') tensor(4.0372e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.137999
Average KL loss: 0.355253
Average total loss: 1.493252
tensor(-14.8381, device='cuda:0') tensor(0.1611, device='cuda:0') tensor(3.2316e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.130366
Average KL loss: 0.355110
Average total loss: 1.485475
tensor(-14.8398, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(-3.5668e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.128722
Average KL loss: 0.355016
Average total loss: 1.483739
tensor(-14.8416, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(-9.0700e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.126184
Average KL loss: 0.354903
Average total loss: 1.481086
tensor(-14.8433, device='cuda:0') tensor(0.1609, device='cuda:0') tensor(2.5883e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.121280
Average KL loss: 0.354794
Average total loss: 1.476074
tensor(-14.8451, device='cuda:0') tensor(0.1609, device='cuda:0') tensor(-1.1987e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.117438
Average KL loss: 0.354663
Average total loss: 1.472101
tensor(-14.8468, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-6.8878e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.115398
Average KL loss: 0.354542
Average total loss: 1.469939
tensor(-14.8485, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-9.8596e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.117816
Average KL loss: 0.354397
Average total loss: 1.472213
tensor(-14.8503, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-2.5336e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.114821
Average KL loss: 0.354251
Average total loss: 1.469072
tensor(-14.8520, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(-6.6187e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.117422
Average KL loss: 0.354135
Average total loss: 1.471557
tensor(-14.8538, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(-1.1032e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.108173
Average KL loss: 0.354034
Average total loss: 1.462208
tensor(-14.8555, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(-3.1264e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.105743
Average KL loss: 0.353924
Average total loss: 1.459667
tensor(-14.8572, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(3.1573e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.107207
Average KL loss: 0.353791
Average total loss: 1.460998
tensor(-14.8589, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(8.8478e-11, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.108433
Average KL loss: 0.353680
Average total loss: 1.462113
tensor(-14.8606, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(-2.4401e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.097795
Average KL loss: 0.353534
Average total loss: 1.451329
tensor(-14.8623, device='cuda:0') tensor(0.1605, device='cuda:0') tensor(-3.4879e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.096841
Average KL loss: 0.353410
Average total loss: 1.450251
tensor(-14.8640, device='cuda:0') tensor(0.1605, device='cuda:0') tensor(4.4755e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.095571
Average KL loss: 0.353335
Average total loss: 1.448907
tensor(-14.8657, device='cuda:0') tensor(0.1605, device='cuda:0') tensor(4.4753e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.095863
Average KL loss: 0.353221
Average total loss: 1.449084
tensor(-14.8675, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(-3.8173e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.093073
Average KL loss: 0.353080
Average total loss: 1.446153
tensor(-14.8692, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(-3.7226e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.092709
Average KL loss: 0.352902
Average total loss: 1.445610
tensor(-14.8708, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(2.8889e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.089245
Average KL loss: 0.352757
Average total loss: 1.442002
tensor(-14.8725, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(3.1755e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.085225
Average KL loss: 0.352591
Average total loss: 1.437816
tensor(-14.8742, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(2.4093e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.082216
Average KL loss: 0.352458
Average total loss: 1.434675
tensor(-14.8759, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(3.4995e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.084714
Average KL loss: 0.352279
Average total loss: 1.436992
tensor(-14.8776, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(2.0471e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.080593
Average KL loss: 0.352091
Average total loss: 1.432684
tensor(-14.8793, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(-5.1590e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.076035
Average KL loss: 0.351948
Average total loss: 1.427982
tensor(-14.8810, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(3.1442e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.079045
Average KL loss: 0.351826
Average total loss: 1.430870
tensor(-14.8827, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-1.0014e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.075429
Average KL loss: 0.351717
Average total loss: 1.427146
tensor(-14.8844, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(4.5432e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.073407
Average KL loss: 0.351609
Average total loss: 1.425016
tensor(-14.8860, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(1.4344e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.070839
Average KL loss: 0.351467
Average total loss: 1.422306
tensor(-14.8877, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-1.1357e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.074129
Average KL loss: 0.351344
Average total loss: 1.425473
tensor(-14.8894, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(1.7047e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.070512
Average KL loss: 0.351215
Average total loss: 1.421727
tensor(-14.8910, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-1.0363e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.066655
Average KL loss: 0.351064
Average total loss: 1.417718
tensor(-14.8927, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-7.0541e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.061408
Average KL loss: 0.350952
Average total loss: 1.412360
tensor(-14.8943, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(-9.6223e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.060103
Average KL loss: 0.350846
Average total loss: 1.410950
tensor(-14.8960, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(1.9553e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.068397
Average KL loss: 0.350685
Average total loss: 1.419082
tensor(-14.8976, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(2.2539e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.064379
Average KL loss: 0.350520
Average total loss: 1.414899
tensor(-14.8993, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(4.6561e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.058876
Average KL loss: 0.350366
Average total loss: 1.409242
tensor(-14.9009, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(5.4396e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.056800
Average KL loss: 0.350232
Average total loss: 1.407033
tensor(-14.9026, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(1.9691e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.061530
Average KL loss: 0.350129
Average total loss: 1.411659
tensor(-14.9042, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-8.4248e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.056504
Average KL loss: 0.349994
Average total loss: 1.406498
tensor(-14.9059, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-1.1850e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.055532
Average KL loss: 0.349853
Average total loss: 1.405384
tensor(-14.9075, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(3.2891e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.055083
Average KL loss: 0.349744
Average total loss: 1.404827
tensor(-14.9091, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(1.8630e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.052771
Average KL loss: 0.349608
Average total loss: 1.402379
tensor(-14.9108, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-1.2519e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.048983
Average KL loss: 0.349440
Average total loss: 1.398423
tensor(-14.9124, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-2.7171e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.049157
Average KL loss: 0.349298
Average total loss: 1.398455
tensor(-14.9140, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-2.5385e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.052307
Average KL loss: 0.349160
Average total loss: 1.401467
tensor(-14.9157, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-3.2421e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.050955
Average KL loss: 0.348992
Average total loss: 1.399947
tensor(-14.9173, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-1.2775e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.047746
Average KL loss: 0.348853
Average total loss: 1.396599
tensor(-14.9189, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-3.0359e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.043141
Average KL loss: 0.348715
Average total loss: 1.391856
tensor(-14.9205, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-8.0624e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.045225
Average KL loss: 0.348571
Average total loss: 1.393796
tensor(-14.9221, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-5.2951e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.037199
Average KL loss: 0.348453
Average total loss: 1.385652
tensor(-14.9237, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(9.0838e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.040373
Average KL loss: 0.348330
Average total loss: 1.388703
tensor(-14.9253, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-1.3961e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.042500
Average KL loss: 0.348212
Average total loss: 1.390713
tensor(-14.9269, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-1.1266e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.039735
Average KL loss: 0.348084
Average total loss: 1.387819
tensor(-14.9285, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(7.8739e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.042806
Average KL loss: 0.347946
Average total loss: 1.390752
tensor(-14.9301, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-4.9848e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.038277
Average KL loss: 0.347841
Average total loss: 1.386118
tensor(-14.9317, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-1.0910e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.034519
Average KL loss: 0.347723
Average total loss: 1.382242
tensor(-14.9333, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(2.8473e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.038269
Average KL loss: 0.347607
Average total loss: 1.385876
tensor(-14.9349, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(1.0684e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.032198
Average KL loss: 0.347497
Average total loss: 1.379695
tensor(-14.9365, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(3.3110e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.032168
Average KL loss: 0.347355
Average total loss: 1.379523
tensor(-14.9381, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-4.6283e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.032075
Average KL loss: 0.347228
Average total loss: 1.379303
tensor(-14.9396, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(8.0402e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.030495
Average KL loss: 0.347132
Average total loss: 1.377627
tensor(-14.9412, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-1.8011e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.034173
Average KL loss: 0.347068
Average total loss: 1.381241
tensor(-14.9428, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-4.4168e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.032724
Average KL loss: 0.346963
Average total loss: 1.379688
tensor(-14.9444, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(7.2326e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.032132
Average KL loss: 0.346868
Average total loss: 1.378999
tensor(-14.9460, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(2.1112e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.028114
Average KL loss: 0.346777
Average total loss: 1.374891
tensor(-14.9475, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(3.2839e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.026349
Average KL loss: 0.346704
Average total loss: 1.373053
tensor(-14.9491, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(1.8289e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.026754
Average KL loss: 0.346652
Average total loss: 1.373406
tensor(-14.9507, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-1.5226e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.023673
Average KL loss: 0.346579
Average total loss: 1.370252
tensor(-14.9522, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-2.4576e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.027465
Average KL loss: 0.346542
Average total loss: 1.374007
tensor(-14.9538, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(3.8550e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.023333
Average KL loss: 0.346484
Average total loss: 1.369817
tensor(-14.9553, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-1.6550e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.021509
Average KL loss: 0.346400
Average total loss: 1.367909
tensor(-14.9569, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(3.6588e-12, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.020052
Average KL loss: 0.346326
Average total loss: 1.366378
tensor(-14.9584, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(9.6930e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.021351
Average KL loss: 0.346241
Average total loss: 1.367593
tensor(-14.9600, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-2.3549e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.019802
Average KL loss: 0.346127
Average total loss: 1.365929
tensor(-14.9615, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-4.5674e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.024199
Average KL loss: 0.346056
Average total loss: 1.370255
tensor(-14.9631, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(1.1919e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.019024
Average KL loss: 0.345988
Average total loss: 1.365012
tensor(-14.9646, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-5.7265e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.018666
Average KL loss: 0.345929
Average total loss: 1.364595
tensor(-14.9662, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-4.2990e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.020007
Average KL loss: 0.345846
Average total loss: 1.365853
tensor(-14.9677, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-7.3199e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.019089
Average KL loss: 0.345746
Average total loss: 1.364835
tensor(-14.9692, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(8.9104e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.012962
Average KL loss: 0.345658
Average total loss: 1.358620
tensor(-14.9708, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(-7.2190e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.014494
Average KL loss: 0.345565
Average total loss: 1.360060
tensor(-14.9723, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(-1.7352e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.017813
Average KL loss: 0.345474
Average total loss: 1.363287
tensor(-14.9738, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(2.8681e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.015356
Average KL loss: 0.345347
Average total loss: 1.360703
tensor(-14.9754, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(6.3256e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.014527
Average KL loss: 0.345236
Average total loss: 1.359763
tensor(-14.9769, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(-4.6502e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.015612
Average KL loss: 0.345129
Average total loss: 1.360740
tensor(-14.9784, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(1.1431e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.015095
Average KL loss: 0.345025
Average total loss: 1.360120
tensor(-14.9799, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(7.2427e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.011915
Average KL loss: 0.344927
Average total loss: 1.356843
tensor(-14.9815, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(-1.0928e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.011772
Average KL loss: 0.344834
Average total loss: 1.356606
tensor(-14.9830, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(1.3051e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.012657
Average KL loss: 0.344757
Average total loss: 1.357415
tensor(-14.9845, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-4.9364e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.013257
Average KL loss: 0.344669
Average total loss: 1.357926
tensor(-14.9860, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-2.2470e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.009948
Average KL loss: 0.344570
Average total loss: 1.354517
tensor(-14.9875, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(3.1401e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.010076
Average KL loss: 0.344454
Average total loss: 1.354530
tensor(-14.9890, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-4.0476e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.008789
Average KL loss: 0.344335
Average total loss: 1.353123
tensor(-14.9905, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-1.0310e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.009083
Average KL loss: 0.344209
Average total loss: 1.353292
tensor(-14.9920, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-3.4247e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.004880
Average KL loss: 0.344094
Average total loss: 1.348974
tensor(-14.9935, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-9.5182e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.008163
Average KL loss: 0.344020
Average total loss: 1.352183
tensor(-14.9950, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(2.1437e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.008753
Average KL loss: 0.343985
Average total loss: 1.352738
tensor(-14.9965, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(-2.4194e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.005910
Average KL loss: 0.343892
Average total loss: 1.349801
tensor(-14.9980, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(-1.1259e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.006879
Average KL loss: 0.343778
Average total loss: 1.350657
tensor(-14.9994, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(-6.9141e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.005075
Average KL loss: 0.343682
Average total loss: 1.348757
tensor(-15.0009, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(1.0016e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.007197
Average KL loss: 0.343595
Average total loss: 1.350792
tensor(-15.0024, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(3.0315e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.002190
Average KL loss: 0.343497
Average total loss: 1.345687
tensor(-15.0039, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(1.1253e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.001427
Average KL loss: 0.343414
Average total loss: 1.344841
tensor(-15.0054, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(-3.4286e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.003114
Average KL loss: 0.343331
Average total loss: 1.346445
tensor(-15.0069, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(-1.9392e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.005770
Average KL loss: 0.343255
Average total loss: 1.349025
tensor(-15.0084, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(5.7240e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.999699
Average KL loss: 0.343166
Average total loss: 1.342865
tensor(-15.0098, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(2.2881e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.001796
Average KL loss: 0.343066
Average total loss: 1.344863
tensor(-15.0113, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(1.8045e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.000585
Average KL loss: 0.342971
Average total loss: 1.343556
tensor(-15.0128, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(2.9920e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.001493
Average KL loss: 0.342897
Average total loss: 1.344389
tensor(-15.0143, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(3.2737e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.998684
Average KL loss: 0.342812
Average total loss: 1.341496
tensor(-15.0157, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(9.3124e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.002727
Average KL loss: 0.342723
Average total loss: 1.345450
tensor(-15.0172, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(-1.1939e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.999169
Average KL loss: 0.342617
Average total loss: 1.341786
tensor(-15.0186, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(2.4117e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.997060
Average KL loss: 0.342510
Average total loss: 1.339570
tensor(-15.0201, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(-1.0454e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.000086
Average KL loss: 0.342407
Average total loss: 1.342493
tensor(-15.0215, device='cuda:0') tensor(0.1605, device='cuda:0') tensor(7.8089e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.999811
Average KL loss: 0.342295
Average total loss: 1.342105
tensor(-15.0230, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(2.4091e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.997808
Average KL loss: 0.342201
Average total loss: 1.340008
tensor(-15.0244, device='cuda:0') tensor(0.1605, device='cuda:0') tensor(-1.2911e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.998556
Average KL loss: 0.342118
Average total loss: 1.340674
tensor(-15.0259, device='cuda:0') tensor(0.1605, device='cuda:0') tensor(-2.9221e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.995584
Average KL loss: 0.342045
Average total loss: 1.337628
tensor(-15.0273, device='cuda:0') tensor(0.1605, device='cuda:0') tensor(-1.2469e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.996964
Average KL loss: 0.341967
Average total loss: 1.338931
tensor(-15.0288, device='cuda:0') tensor(0.1605, device='cuda:0') tensor(7.6793e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.002103
Average KL loss: 0.341901
Average total loss: 1.344004
tensor(-15.0302, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(-3.0284e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.996599
Average KL loss: 0.341811
Average total loss: 1.338410
tensor(-15.0316, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(-2.3891e-11, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.992187
Average KL loss: 0.341733
Average total loss: 1.333920
tensor(-15.0331, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(1.3444e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.990589
Average KL loss: 0.341661
Average total loss: 1.332249
tensor(-15.0345, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(-9.1327e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.996403
Average KL loss: 0.341591
Average total loss: 1.337993
tensor(-15.0360, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(-1.0435e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.994414
Average KL loss: 0.341527
Average total loss: 1.335940
tensor(-15.0374, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(-8.8197e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.993940
Average KL loss: 0.341445
Average total loss: 1.335384
tensor(-15.0388, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(4.9781e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.990171
Average KL loss: 0.341370
Average total loss: 1.331542
tensor(-15.0403, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(-1.7765e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.991031
Average KL loss: 0.341263
Average total loss: 1.332295
tensor(-15.0417, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(-9.3507e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.988978
Average KL loss: 0.341154
Average total loss: 1.330132
tensor(-15.0431, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(-9.0813e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.990340
Average KL loss: 0.341076
Average total loss: 1.331417
tensor(-15.0446, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(7.2939e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.991981
Average KL loss: 0.340975
Average total loss: 1.332956
tensor(-15.0460, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(5.3455e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.994901
Average KL loss: 0.340839
Average total loss: 1.335741
tensor(-15.0474, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(1.3152e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.990624
Average KL loss: 0.340752
Average total loss: 1.331377
tensor(-15.0488, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(-1.7496e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.993375
Average KL loss: 0.340688
Average total loss: 1.334064
tensor(-15.0502, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(-5.4010e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.989071
Average KL loss: 0.340589
Average total loss: 1.329661
tensor(-15.0517, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(6.3025e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.993142
Average KL loss: 0.340508
Average total loss: 1.333650
tensor(-15.0531, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(7.2278e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.989304
Average KL loss: 0.340416
Average total loss: 1.329720
tensor(-15.0545, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-1.4356e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.986610
Average KL loss: 0.340327
Average total loss: 1.326938
tensor(-15.0559, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-1.1398e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.989231
Average KL loss: 0.340267
Average total loss: 1.329498
tensor(-15.0573, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(1.6603e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.989026
Average KL loss: 0.340194
Average total loss: 1.329220
tensor(-15.0587, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-5.0277e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.988317
Average KL loss: 0.340120
Average total loss: 1.328436
tensor(-15.0601, device='cuda:0') tensor(0.1609, device='cuda:0') tensor(1.3515e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.990986
Average KL loss: 0.340069
Average total loss: 1.331055
tensor(-15.0615, device='cuda:0') tensor(0.1609, device='cuda:0') tensor(3.9460e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.987987
Average KL loss: 0.340007
Average total loss: 1.327994
tensor(-15.0628, device='cuda:0') tensor(0.1609, device='cuda:0') tensor(6.9776e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.988348
Average KL loss: 0.339940
Average total loss: 1.328288
tensor(-15.0642, device='cuda:0') tensor(0.1609, device='cuda:0') tensor(-8.8990e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.987068
Average KL loss: 0.339875
Average total loss: 1.326942
tensor(-15.0656, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(-1.1123e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.987413
Average KL loss: 0.339797
Average total loss: 1.327210
 Percentile value: -13.170689964294434
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     843 /    1728             ( 48.78%) | total_pruned =     885 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1713 /   36864             (  4.65%) | total_pruned =   35151 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1636 /   36864             (  4.44%) | total_pruned =   35228 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1615 /   36864             (  4.38%) | total_pruned =   35249 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1266 /   36864             (  3.43%) | total_pruned =   35598 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2499 /   73728             (  3.39%) | total_pruned =   71229 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2220 /  147456             (  1.51%) | total_pruned =  145236 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     710 /    8192             (  8.67%) | total_pruned =    7482 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1230 /  147456             (  0.83%) | total_pruned =  146226 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     814 /  147456             (  0.55%) | total_pruned =  146642 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1978 /  294912             (  0.67%) | total_pruned =  292934 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1514 /  589824             (  0.26%) | total_pruned =  588310 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     515 /   32768             (  1.57%) | total_pruned =   32253 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     421 /  589824             (  0.07%) | total_pruned =  589403 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     351 /  589824             (  0.06%) | total_pruned =  589473 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     925 / 1179648             (  0.08%) | total_pruned = 1178723 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1266 / 2359296             (  0.05%) | total_pruned = 2358030 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      93 /     512             ( 18.16%) | total_pruned =     419 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     803 /  131072             (  0.61%) | total_pruned =  130269 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      28 /     512             (  5.47%) | total_pruned =     484 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     974 / 2359296             (  0.04%) | total_pruned = 2358322 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      31 /     512             (  6.05%) | total_pruned =     481 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1737 / 2359296             (  0.07%) | total_pruned = 2357559 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      85 /     512             ( 16.60%) | total_pruned =     427 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
linear.weight        | nonzeros =    1051 /    5120             ( 20.53%) | total_pruned =    4069 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 154/200 Loss: 0.081072 Accuracy: 75.20 99.92 % Best test Accuracy: 77.88%
tensor(-15.0670, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(-4.0681e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 3.652657
Average KL loss: 0.339187
Average total loss: 3.991844
tensor(-15.0686, device='cuda:0') tensor(0.1558, device='cuda:0') tensor(2.7801e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 3.602171
Average KL loss: 0.338552
Average total loss: 3.940723
tensor(-15.0701, device='cuda:0') tensor(0.1527, device='cuda:0') tensor(1.5430e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 3.441151
Average KL loss: 0.338087
Average total loss: 3.779237
tensor(-15.0715, device='cuda:0') tensor(0.1506, device='cuda:0') tensor(9.8426e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 3.435681
Average KL loss: 0.337652
Average total loss: 3.773333
tensor(-15.0730, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(-2.5274e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 3.353532
Average KL loss: 0.337232
Average total loss: 3.690764
tensor(-15.0744, device='cuda:0') tensor(0.1484, device='cuda:0') tensor(-2.9504e-11, device='cuda:0')
Epoch 6
Average batch original loss after noise: 3.325337
Average KL loss: 0.336862
Average total loss: 3.662199
tensor(-15.0758, device='cuda:0') tensor(0.1479, device='cuda:0') tensor(-5.9028e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 3.231646
Average KL loss: 0.336489
Average total loss: 3.568136
tensor(-15.0772, device='cuda:0') tensor(0.1475, device='cuda:0') tensor(-2.2960e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 3.206544
Average KL loss: 0.336111
Average total loss: 3.542655
tensor(-15.0786, device='cuda:0') tensor(0.1472, device='cuda:0') tensor(5.5558e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 3.088108
Average KL loss: 0.335793
Average total loss: 3.423900
tensor(-15.0800, device='cuda:0') tensor(0.1469, device='cuda:0') tensor(-2.1536e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 3.061209
Average KL loss: 0.335537
Average total loss: 3.396746
tensor(-15.0814, device='cuda:0') tensor(0.1466, device='cuda:0') tensor(3.9654e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.974232
Average KL loss: 0.335310
Average total loss: 3.309542
tensor(-15.0828, device='cuda:0') tensor(0.1464, device='cuda:0') tensor(8.0282e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.878017
Average KL loss: 0.335077
Average total loss: 3.213094
tensor(-15.0842, device='cuda:0') tensor(0.1462, device='cuda:0') tensor(6.0111e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.856947
Average KL loss: 0.334846
Average total loss: 3.191793
tensor(-15.0856, device='cuda:0') tensor(0.1460, device='cuda:0') tensor(5.4948e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.831381
Average KL loss: 0.334599
Average total loss: 3.165980
tensor(-15.0870, device='cuda:0') tensor(0.1458, device='cuda:0') tensor(2.0599e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.734299
Average KL loss: 0.334342
Average total loss: 3.068641
tensor(-15.0883, device='cuda:0') tensor(0.1456, device='cuda:0') tensor(5.9191e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.703009
Average KL loss: 0.334097
Average total loss: 3.037106
tensor(-15.0897, device='cuda:0') tensor(0.1455, device='cuda:0') tensor(1.0706e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.632859
Average KL loss: 0.333865
Average total loss: 2.966723
tensor(-15.0911, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(-1.5628e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.583010
Average KL loss: 0.333635
Average total loss: 2.916645
tensor(-15.0924, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(6.5726e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.549600
Average KL loss: 0.333367
Average total loss: 2.882967
tensor(-15.0938, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(1.5895e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.490017
Average KL loss: 0.333125
Average total loss: 2.823142
tensor(-15.0952, device='cuda:0') tensor(0.1449, device='cuda:0') tensor(8.2099e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.386052
Average KL loss: 0.332913
Average total loss: 2.718964
tensor(-15.0965, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(4.6588e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.385037
Average KL loss: 0.332715
Average total loss: 2.717752
tensor(-15.0979, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(1.4503e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.343146
Average KL loss: 0.332457
Average total loss: 2.675603
tensor(-15.0992, device='cuda:0') tensor(0.1445, device='cuda:0') tensor(1.3744e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.291921
Average KL loss: 0.332216
Average total loss: 2.624137
tensor(-15.1006, device='cuda:0') tensor(0.1444, device='cuda:0') tensor(1.1727e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.263115
Average KL loss: 0.331971
Average total loss: 2.595086
tensor(-15.1019, device='cuda:0') tensor(0.1443, device='cuda:0') tensor(1.8447e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.220617
Average KL loss: 0.331737
Average total loss: 2.552354
tensor(-15.1033, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(-1.2250e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.162762
Average KL loss: 0.331473
Average total loss: 2.494235
tensor(-15.1046, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(-1.9233e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.168119
Average KL loss: 0.331212
Average total loss: 2.499332
tensor(-15.1060, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(3.8123e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.124753
Average KL loss: 0.330968
Average total loss: 2.455721
tensor(-15.1073, device='cuda:0') tensor(0.1440, device='cuda:0') tensor(-1.4973e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.107048
Average KL loss: 0.330739
Average total loss: 2.437787
tensor(-15.1087, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(1.7397e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.063227
Average KL loss: 0.330518
Average total loss: 2.393745
tensor(-15.1100, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(-1.8029e-11, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.082168
Average KL loss: 0.330295
Average total loss: 2.412462
tensor(-15.1113, device='cuda:0') tensor(0.1438, device='cuda:0') tensor(-8.4284e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 2.031869
Average KL loss: 0.330060
Average total loss: 2.361929
tensor(-15.1127, device='cuda:0') tensor(0.1438, device='cuda:0') tensor(7.1181e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 2.010165
Average KL loss: 0.329804
Average total loss: 2.339969
tensor(-15.1140, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(2.5034e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 2.013003
Average KL loss: 0.329549
Average total loss: 2.342552
tensor(-15.1154, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(4.9428e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.995419
Average KL loss: 0.329288
Average total loss: 2.324707
tensor(-15.1167, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(-2.0298e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.982782
Average KL loss: 0.329047
Average total loss: 2.311829
tensor(-15.1180, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(-1.2901e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.929492
Average KL loss: 0.328849
Average total loss: 2.258341
tensor(-15.1194, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(-1.7081e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.920620
Average KL loss: 0.328614
Average total loss: 2.249235
tensor(-15.1207, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(-7.3235e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.894946
Average KL loss: 0.328367
Average total loss: 2.223312
tensor(-15.1220, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(4.2864e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.909733
Average KL loss: 0.328160
Average total loss: 2.237893
tensor(-15.1233, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-4.1507e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.885288
Average KL loss: 0.327990
Average total loss: 2.213278
tensor(-15.1247, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(2.0990e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.881121
Average KL loss: 0.327800
Average total loss: 2.208922
tensor(-15.1260, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(1.4655e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.846607
Average KL loss: 0.327630
Average total loss: 2.174237
tensor(-15.1273, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-1.2244e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.840656
Average KL loss: 0.327480
Average total loss: 2.168136
tensor(-15.1286, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(2.0624e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.830193
Average KL loss: 0.327329
Average total loss: 2.157522
tensor(-15.1299, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-1.1974e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.812513
Average KL loss: 0.327131
Average total loss: 2.139644
tensor(-15.1312, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(1.4729e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.816703
Average KL loss: 0.326917
Average total loss: 2.143620
tensor(-15.1325, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(9.0640e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.787998
Average KL loss: 0.326687
Average total loss: 2.114685
tensor(-15.1338, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(5.3851e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.774469
Average KL loss: 0.326505
Average total loss: 2.100974
tensor(-15.1351, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-4.5511e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.772677
Average KL loss: 0.326338
Average total loss: 2.099015
tensor(-15.1364, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(1.1736e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.752629
Average KL loss: 0.326184
Average total loss: 2.078813
tensor(-15.1377, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(3.3987e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.739791
Average KL loss: 0.326044
Average total loss: 2.065836
tensor(-15.1390, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(2.2959e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.735295
Average KL loss: 0.325879
Average total loss: 2.061174
tensor(-15.1403, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-4.5853e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.724014
Average KL loss: 0.325763
Average total loss: 2.049777
tensor(-15.1416, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(9.3637e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.730055
Average KL loss: 0.325660
Average total loss: 2.055715
tensor(-15.1429, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(1.4801e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.709754
Average KL loss: 0.325499
Average total loss: 2.035253
tensor(-15.1442, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(1.1455e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.701553
Average KL loss: 0.325331
Average total loss: 2.026884
tensor(-15.1455, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-2.0182e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.690289
Average KL loss: 0.325177
Average total loss: 2.015466
tensor(-15.1467, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-6.4016e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.669373
Average KL loss: 0.325027
Average total loss: 1.994400
tensor(-15.1480, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(1.5292e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.652703
Average KL loss: 0.324876
Average total loss: 1.977579
tensor(-15.1493, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(3.6456e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.671456
Average KL loss: 0.324772
Average total loss: 1.996228
tensor(-15.1506, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-2.3548e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.647958
Average KL loss: 0.324698
Average total loss: 1.972655
tensor(-15.1519, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-8.4215e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.662942
Average KL loss: 0.324589
Average total loss: 1.987530
tensor(-15.1532, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-9.5769e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.638088
Average KL loss: 0.324477
Average total loss: 1.962564
tensor(-15.1545, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-3.7224e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.618543
Average KL loss: 0.324388
Average total loss: 1.942931
tensor(-15.1558, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-1.2216e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.625904
Average KL loss: 0.324280
Average total loss: 1.950184
tensor(-15.1570, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-5.0660e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.629455
Average KL loss: 0.324153
Average total loss: 1.953609
tensor(-15.1583, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-4.9681e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.604279
Average KL loss: 0.324020
Average total loss: 1.928299
tensor(-15.1596, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-4.4978e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.594236
Average KL loss: 0.323877
Average total loss: 1.918113
tensor(-15.1609, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-8.0189e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.583101
Average KL loss: 0.323733
Average total loss: 1.906833
tensor(-15.1621, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-1.6078e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.576202
Average KL loss: 0.323604
Average total loss: 1.899806
tensor(-15.1634, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-2.7273e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.586869
Average KL loss: 0.323486
Average total loss: 1.910355
tensor(-15.1646, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-4.4619e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.587474
Average KL loss: 0.323342
Average total loss: 1.910816
tensor(-15.1659, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-6.2594e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.570760
Average KL loss: 0.323195
Average total loss: 1.893955
tensor(-15.1672, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-4.5066e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.569674
Average KL loss: 0.323051
Average total loss: 1.892725
tensor(-15.1684, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-1.8763e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.554675
Average KL loss: 0.322910
Average total loss: 1.877585
tensor(-15.1697, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(1.1693e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.551332
Average KL loss: 0.322764
Average total loss: 1.874096
tensor(-15.1709, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-8.3978e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.548798
Average KL loss: 0.322635
Average total loss: 1.871432
tensor(-15.1722, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(7.5600e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.547498
Average KL loss: 0.322490
Average total loss: 1.869989
tensor(-15.1734, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(1.7930e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.529534
Average KL loss: 0.322378
Average total loss: 1.851912
tensor(-15.1747, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-1.2548e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.534596
Average KL loss: 0.322260
Average total loss: 1.856857
tensor(-15.1759, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(6.3439e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.523667
Average KL loss: 0.322142
Average total loss: 1.845810
tensor(-15.1771, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-6.7416e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.501499
Average KL loss: 0.322023
Average total loss: 1.823523
tensor(-15.1784, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-3.1396e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.489069
Average KL loss: 0.321926
Average total loss: 1.810995
tensor(-15.1796, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-8.5091e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.502713
Average KL loss: 0.321849
Average total loss: 1.824562
tensor(-15.1809, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(6.2336e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.528817
Average KL loss: 0.321714
Average total loss: 1.850531
tensor(-15.1821, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-4.6713e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.496713
Average KL loss: 0.321591
Average total loss: 1.818304
tensor(-15.1834, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-3.7624e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.492667
Average KL loss: 0.321457
Average total loss: 1.814124
tensor(-15.1846, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(1.1055e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.482361
Average KL loss: 0.321338
Average total loss: 1.803699
tensor(-15.1858, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-5.1651e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.487524
Average KL loss: 0.321216
Average total loss: 1.808741
tensor(-15.1871, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-2.5033e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.473026
Average KL loss: 0.321082
Average total loss: 1.794108
tensor(-15.1883, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(5.5407e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.499657
Average KL loss: 0.320921
Average total loss: 1.820578
tensor(-15.1896, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-8.7376e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.472282
Average KL loss: 0.320781
Average total loss: 1.793063
tensor(-15.1908, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(1.3376e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.471687
Average KL loss: 0.320645
Average total loss: 1.792332
tensor(-15.1920, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(2.3964e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.465034
Average KL loss: 0.320533
Average total loss: 1.785567
tensor(-15.1933, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(7.1185e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.461719
Average KL loss: 0.320387
Average total loss: 1.782106
tensor(-15.1945, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(4.9318e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.461397
Average KL loss: 0.320256
Average total loss: 1.781653
tensor(-15.1957, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-6.0983e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.480791
Average KL loss: 0.320135
Average total loss: 1.800926
tensor(-15.1970, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-3.6156e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.466410
Average KL loss: 0.320016
Average total loss: 1.786426
tensor(-15.1982, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-1.0902e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.462552
Average KL loss: 0.319907
Average total loss: 1.782459
tensor(-15.1994, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-2.3342e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.462997
Average KL loss: 0.319791
Average total loss: 1.782788
tensor(-15.2006, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-1.7437e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.440516
Average KL loss: 0.319671
Average total loss: 1.760187
tensor(-15.2018, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(8.2017e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.447557
Average KL loss: 0.319542
Average total loss: 1.767099
tensor(-15.2031, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(1.1547e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.435713
Average KL loss: 0.319394
Average total loss: 1.755107
tensor(-15.2043, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-1.2798e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.424253
Average KL loss: 0.319277
Average total loss: 1.743530
tensor(-15.2055, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(1.6402e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.442541
Average KL loss: 0.319149
Average total loss: 1.761690
tensor(-15.2067, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(-9.6377e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.430733
Average KL loss: 0.319036
Average total loss: 1.749769
tensor(-15.2079, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(-3.8982e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.418151
Average KL loss: 0.318913
Average total loss: 1.737064
tensor(-15.2091, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(-8.6995e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.439248
Average KL loss: 0.318765
Average total loss: 1.758013
tensor(-15.2103, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(1.4580e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.413319
Average KL loss: 0.318626
Average total loss: 1.731945
tensor(-15.2115, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(3.6629e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.432351
Average KL loss: 0.318456
Average total loss: 1.750807
tensor(-15.2127, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(3.5777e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.412934
Average KL loss: 0.318317
Average total loss: 1.731251
tensor(-15.2139, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(7.7622e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.411607
Average KL loss: 0.318169
Average total loss: 1.729777
tensor(-15.2151, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(1.2930e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.427603
Average KL loss: 0.318041
Average total loss: 1.745643
tensor(-15.2163, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(9.4171e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.404787
Average KL loss: 0.317931
Average total loss: 1.722718
tensor(-15.2175, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(2.3394e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.413776
Average KL loss: 0.317844
Average total loss: 1.731620
tensor(-15.2187, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(1.7283e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.407220
Average KL loss: 0.317769
Average total loss: 1.724989
tensor(-15.2199, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(2.7316e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.418501
Average KL loss: 0.317644
Average total loss: 1.736145
tensor(-15.2211, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(-1.9264e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.395685
Average KL loss: 0.317544
Average total loss: 1.713229
tensor(-15.2223, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(-3.0699e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.399218
Average KL loss: 0.317453
Average total loss: 1.716671
tensor(-15.2234, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(9.3143e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.411060
Average KL loss: 0.317370
Average total loss: 1.728430
tensor(-15.2246, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(5.7599e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.378315
Average KL loss: 0.317297
Average total loss: 1.695612
tensor(-15.2258, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(7.1304e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.382920
Average KL loss: 0.317251
Average total loss: 1.700171
tensor(-15.2270, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(-6.8299e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.396656
Average KL loss: 0.317183
Average total loss: 1.713839
tensor(-15.2282, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(1.0415e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.400681
Average KL loss: 0.317130
Average total loss: 1.717811
tensor(-15.2294, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(4.5448e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.392651
Average KL loss: 0.317095
Average total loss: 1.709745
tensor(-15.2306, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(-7.4512e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.374315
Average KL loss: 0.317043
Average total loss: 1.691358
tensor(-15.2318, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(2.8079e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.368992
Average KL loss: 0.316956
Average total loss: 1.685948
tensor(-15.2330, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(2.4519e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.372450
Average KL loss: 0.316871
Average total loss: 1.689321
tensor(-15.2341, device='cuda:0') tensor(0.1438, device='cuda:0') tensor(1.2671e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.377385
Average KL loss: 0.316772
Average total loss: 1.694157
tensor(-15.2353, device='cuda:0') tensor(0.1438, device='cuda:0') tensor(4.9329e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.367366
Average KL loss: 0.316684
Average total loss: 1.684051
tensor(-15.2365, device='cuda:0') tensor(0.1438, device='cuda:0') tensor(1.7009e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.385850
Average KL loss: 0.316608
Average total loss: 1.702457
tensor(-15.2377, device='cuda:0') tensor(0.1438, device='cuda:0') tensor(-3.5432e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.369832
Average KL loss: 0.316524
Average total loss: 1.686356
tensor(-15.2389, device='cuda:0') tensor(0.1438, device='cuda:0') tensor(4.1425e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.364408
Average KL loss: 0.316464
Average total loss: 1.680872
tensor(-15.2401, device='cuda:0') tensor(0.1438, device='cuda:0') tensor(1.7185e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.361126
Average KL loss: 0.316378
Average total loss: 1.677505
tensor(-15.2412, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(-7.9471e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.358502
Average KL loss: 0.316299
Average total loss: 1.674801
tensor(-15.2424, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(3.0234e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.366143
Average KL loss: 0.316239
Average total loss: 1.682382
tensor(-15.2435, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(-9.3025e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.359511
Average KL loss: 0.316194
Average total loss: 1.675705
tensor(-15.2447, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(4.2773e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.347311
Average KL loss: 0.316128
Average total loss: 1.663438
tensor(-15.2459, device='cuda:0') tensor(0.1440, device='cuda:0') tensor(3.4077e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.358993
Average KL loss: 0.316039
Average total loss: 1.675032
tensor(-15.2470, device='cuda:0') tensor(0.1440, device='cuda:0') tensor(1.9662e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.348901
Average KL loss: 0.315955
Average total loss: 1.664856
tensor(-15.2482, device='cuda:0') tensor(0.1440, device='cuda:0') tensor(-4.6367e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.346957
Average KL loss: 0.315879
Average total loss: 1.662835
tensor(-15.2493, device='cuda:0') tensor(0.1440, device='cuda:0') tensor(-3.1084e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.335194
Average KL loss: 0.315788
Average total loss: 1.650982
tensor(-15.2505, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(-5.0969e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.337954
Average KL loss: 0.315710
Average total loss: 1.653664
tensor(-15.2516, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(-2.8939e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.333185
Average KL loss: 0.315636
Average total loss: 1.648821
tensor(-15.2528, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(-2.8599e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.324421
Average KL loss: 0.315573
Average total loss: 1.639995
tensor(-15.2539, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(8.8316e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.334667
Average KL loss: 0.315514
Average total loss: 1.650181
tensor(-15.2551, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(-1.9401e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.329548
Average KL loss: 0.315475
Average total loss: 1.645024
tensor(-15.2562, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(-3.4687e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.320772
Average KL loss: 0.315424
Average total loss: 1.636196
tensor(-15.2574, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(1.4051e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.336433
Average KL loss: 0.315370
Average total loss: 1.651804
tensor(-15.2585, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(-6.5285e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.325285
Average KL loss: 0.315300
Average total loss: 1.640585
tensor(-15.2597, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(-4.4923e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.319384
Average KL loss: 0.315220
Average total loss: 1.634605
tensor(-15.2608, device='cuda:0') tensor(0.1443, device='cuda:0') tensor(2.0967e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.307159
Average KL loss: 0.315167
Average total loss: 1.622326
tensor(-15.2620, device='cuda:0') tensor(0.1443, device='cuda:0') tensor(1.8214e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.320239
Average KL loss: 0.315110
Average total loss: 1.635349
tensor(-15.2631, device='cuda:0') tensor(0.1443, device='cuda:0') tensor(3.0663e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.310759
Average KL loss: 0.315081
Average total loss: 1.625840
tensor(-15.2642, device='cuda:0') tensor(0.1443, device='cuda:0') tensor(3.1439e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.313323
Average KL loss: 0.315030
Average total loss: 1.628353
tensor(-15.2654, device='cuda:0') tensor(0.1444, device='cuda:0') tensor(-8.9233e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.308525
Average KL loss: 0.314962
Average total loss: 1.623487
tensor(-15.2665, device='cuda:0') tensor(0.1444, device='cuda:0') tensor(-7.9642e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.309355
Average KL loss: 0.314884
Average total loss: 1.624239
tensor(-15.2677, device='cuda:0') tensor(0.1444, device='cuda:0') tensor(-6.7738e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.308757
Average KL loss: 0.314807
Average total loss: 1.623564
tensor(-15.2688, device='cuda:0') tensor(0.1444, device='cuda:0') tensor(2.2563e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.302147
Average KL loss: 0.314747
Average total loss: 1.616894
tensor(-15.2700, device='cuda:0') tensor(0.1445, device='cuda:0') tensor(-6.9818e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.293603
Average KL loss: 0.314711
Average total loss: 1.608314
tensor(-15.2711, device='cuda:0') tensor(0.1445, device='cuda:0') tensor(3.9529e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.325131
Average KL loss: 0.314676
Average total loss: 1.639807
tensor(-15.2722, device='cuda:0') tensor(0.1445, device='cuda:0') tensor(-2.2611e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.295208
Average KL loss: 0.314600
Average total loss: 1.609808
tensor(-15.2734, device='cuda:0') tensor(0.1445, device='cuda:0') tensor(5.4270e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.307911
Average KL loss: 0.314556
Average total loss: 1.622468
tensor(-15.2745, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(-6.7492e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.293880
Average KL loss: 0.314494
Average total loss: 1.608374
tensor(-15.2757, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(-3.4785e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.292049
Average KL loss: 0.314444
Average total loss: 1.606493
tensor(-15.2768, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(-2.1586e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.291039
Average KL loss: 0.314368
Average total loss: 1.605406
tensor(-15.2779, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(-1.8211e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.291621
Average KL loss: 0.314297
Average total loss: 1.605918
tensor(-15.2791, device='cuda:0') tensor(0.1447, device='cuda:0') tensor(-3.4612e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.295831
Average KL loss: 0.314201
Average total loss: 1.610032
tensor(-15.2802, device='cuda:0') tensor(0.1447, device='cuda:0') tensor(3.4983e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.286172
Average KL loss: 0.314095
Average total loss: 1.600266
tensor(-15.2813, device='cuda:0') tensor(0.1447, device='cuda:0') tensor(5.5007e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 1.287892
Average KL loss: 0.313999
Average total loss: 1.601891
tensor(-15.2824, device='cuda:0') tensor(0.1447, device='cuda:0') tensor(6.3061e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.297608
Average KL loss: 0.313930
Average total loss: 1.611538
tensor(-15.2836, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(-3.2286e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.284600
Average KL loss: 0.313820
Average total loss: 1.598420
tensor(-15.2847, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(-1.1453e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 1.288364
Average KL loss: 0.313717
Average total loss: 1.602081
tensor(-15.2858, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(-5.1208e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 1.280379
Average KL loss: 0.313638
Average total loss: 1.594017
tensor(-15.2869, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(1.4420e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 1.282324
Average KL loss: 0.313569
Average total loss: 1.595893
tensor(-15.2880, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(-6.1669e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 1.275651
Average KL loss: 0.313476
Average total loss: 1.589127
tensor(-15.2891, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(-2.5148e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 1.272050
Average KL loss: 0.313383
Average total loss: 1.585433
tensor(-15.2902, device='cuda:0') tensor(0.1449, device='cuda:0') tensor(-3.1139e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 1.277329
Average KL loss: 0.313294
Average total loss: 1.590623
tensor(-15.2913, device='cuda:0') tensor(0.1449, device='cuda:0') tensor(4.0643e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 1.272966
Average KL loss: 0.313222
Average total loss: 1.586187
tensor(-15.2924, device='cuda:0') tensor(0.1449, device='cuda:0') tensor(-5.1551e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 1.275339
Average KL loss: 0.313142
Average total loss: 1.588481
tensor(-15.2935, device='cuda:0') tensor(0.1449, device='cuda:0') tensor(-5.2223e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 1.270557
Average KL loss: 0.313078
Average total loss: 1.583635
tensor(-15.2947, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-4.9467e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 1.271997
Average KL loss: 0.313036
Average total loss: 1.585033
tensor(-15.2958, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-9.6360e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 1.262197
Average KL loss: 0.312978
Average total loss: 1.575174
tensor(-15.2969, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(3.3399e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 1.269037
Average KL loss: 0.312897
Average total loss: 1.581934
tensor(-15.2980, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-6.1151e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 1.279477
Average KL loss: 0.312817
Average total loss: 1.592294
tensor(-15.2991, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-1.0408e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 1.263283
Average KL loss: 0.312743
Average total loss: 1.576026
tensor(-15.3001, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(5.4806e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 1.259884
Average KL loss: 0.312692
Average total loss: 1.572576
tensor(-15.3012, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(-7.3315e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 1.264057
Average KL loss: 0.312629
Average total loss: 1.576686
tensor(-15.3023, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(4.0256e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 1.257749
Average KL loss: 0.312554
Average total loss: 1.570302
tensor(-15.3034, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(-1.4368e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 1.259260
Average KL loss: 0.312481
Average total loss: 1.571741
tensor(-15.3045, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(-4.9692e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 1.264442
Average KL loss: 0.312422
Average total loss: 1.576864
tensor(-15.3056, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-5.3115e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 1.258831
Average KL loss: 0.312366
Average total loss: 1.571197
tensor(-15.3067, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-1.1707e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 1.256976
Average KL loss: 0.312299
Average total loss: 1.569275
tensor(-15.3078, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(1.9913e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 1.253975
Average KL loss: 0.312234
Average total loss: 1.566208
tensor(-15.3089, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(5.1046e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 1.257586
Average KL loss: 0.312191
Average total loss: 1.569777
tensor(-15.3100, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-4.1683e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 1.260898
Average KL loss: 0.312142
Average total loss: 1.573040
tensor(-15.3111, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(4.3366e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 1.256670
Average KL loss: 0.312061
Average total loss: 1.568731
tensor(-15.3122, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(7.8757e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 1.248492
Average KL loss: 0.312004
Average total loss: 1.560496
 Percentile value: 5.074423408508299
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =     382 /    1728             ( 22.11%) | total_pruned =    1346 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
bn1.bias             | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     456 /   36864             (  1.24%) | total_pruned =   36408 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     429 /   36864             (  1.16%) | total_pruned =   36435 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     416 /   36864             (  1.13%) | total_pruned =   36448 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     372 /   36864             (  1.01%) | total_pruned =   36492 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     560 /   73728             (  0.76%) | total_pruned =   73168 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     561 /  147456             (  0.38%) | total_pruned =  146895 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     225 /    8192             (  2.75%) | total_pruned =    7967 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     286 /  147456             (  0.19%) | total_pruned =  147170 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     211 /  147456             (  0.14%) | total_pruned =  147245 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     470 /  294912             (  0.16%) | total_pruned =  294442 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     421 /  589824             (  0.07%) | total_pruned =  589403 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     169 /   32768             (  0.52%) | total_pruned =   32599 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =      93 /  589824             (  0.02%) | total_pruned =  589731 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =      90 /  589824             (  0.02%) | total_pruned =  589734 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     220 / 1179648             (  0.02%) | total_pruned = 1179428 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     339 / 2359296             (  0.01%) | total_pruned = 2358957 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     254 /  131072             (  0.19%) | total_pruned =  130818 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     104 /     512             ( 20.31%) | total_pruned =     408 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     215 / 2359296             (  0.01%) | total_pruned = 2359081 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     514 / 2359296             (  0.02%) | total_pruned = 2358782 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      79 /     512             ( 15.43%) | total_pruned =     433 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     614 /    5120             ( 11.99%) | total_pruned =    4506 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 199/200 Loss: 0.514865 Accuracy: 73.82 83.96 % Best test Accuracy: 73.92%
