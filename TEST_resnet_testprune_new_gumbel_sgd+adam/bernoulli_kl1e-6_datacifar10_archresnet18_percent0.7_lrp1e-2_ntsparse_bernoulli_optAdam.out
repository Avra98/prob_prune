Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(3.5847e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.801855
Average KL loss: 5.331205
Average total loss: 7.133060
tensor(-0.1594, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(1.3198e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.488218
Average KL loss: 5.007196
Average total loss: 6.495414
tensor(-0.2654, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(8.7149e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.278026
Average KL loss: 4.746463
Average total loss: 6.024489
tensor(-0.3647, device='cuda:0') tensor(0.1459, device='cuda:0') tensor(7.4143e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.139301
Average KL loss: 4.517305
Average total loss: 5.656606
tensor(-0.4591, device='cuda:0') tensor(0.2313, device='cuda:0') tensor(1.1126e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.049235
Average KL loss: 4.315590
Average total loss: 5.364825
tensor(-0.5483, device='cuda:0') tensor(0.3238, device='cuda:0') tensor(1.3554e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.967246
Average KL loss: 4.136796
Average total loss: 5.104042
tensor(-0.6328, device='cuda:0') tensor(0.4192, device='cuda:0') tensor(1.1189e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.900264
Average KL loss: 3.976788
Average total loss: 4.877052
tensor(-0.7130, device='cuda:0') tensor(0.5149, device='cuda:0') tensor(1.0381e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.844056
Average KL loss: 3.832404
Average total loss: 4.676460
tensor(-0.7891, device='cuda:0') tensor(0.6091, device='cuda:0') tensor(1.2141e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.772405
Average KL loss: 3.701095
Average total loss: 4.473500
tensor(-0.8616, device='cuda:0') tensor(0.7008, device='cuda:0') tensor(1.0771e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.743673
Average KL loss: 3.580472
Average total loss: 4.324144
tensor(-0.9310, device='cuda:0') tensor(0.7897, device='cuda:0') tensor(1.2080e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.707589
Average KL loss: 3.469111
Average total loss: 4.176700
tensor(-0.9973, device='cuda:0') tensor(0.8755, device='cuda:0') tensor(1.1397e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.668014
Average KL loss: 3.365759
Average total loss: 4.033773
tensor(-1.0610, device='cuda:0') tensor(0.9582, device='cuda:0') tensor(1.0039e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.623476
Average KL loss: 3.269557
Average total loss: 3.893033
tensor(-1.1221, device='cuda:0') tensor(1.0378, device='cuda:0') tensor(1.0953e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.612098
Average KL loss: 3.179557
Average total loss: 3.791654
tensor(-1.1810, device='cuda:0') tensor(1.1142, device='cuda:0') tensor(1.0255e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.579652
Average KL loss: 3.094996
Average total loss: 3.674647
tensor(-1.2379, device='cuda:0') tensor(1.1877, device='cuda:0') tensor(1.2352e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.545507
Average KL loss: 3.015398
Average total loss: 3.560905
tensor(-1.2927, device='cuda:0') tensor(1.2583, device='cuda:0') tensor(1.1003e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.510228
Average KL loss: 2.940152
Average total loss: 3.450380
tensor(-1.3459, device='cuda:0') tensor(1.3259, device='cuda:0') tensor(1.0309e-07, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.503538
Average KL loss: 2.868796
Average total loss: 3.372335
tensor(-1.3974, device='cuda:0') tensor(1.3912, device='cuda:0') tensor(1.0081e-07, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.481173
Average KL loss: 2.801168
Average total loss: 3.282341
tensor(-1.4473, device='cuda:0') tensor(1.4540, device='cuda:0') tensor(8.9616e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.463904
Average KL loss: 2.736969
Average total loss: 3.200873
tensor(-1.4958, device='cuda:0') tensor(1.5146, device='cuda:0') tensor(1.0675e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.442279
Average KL loss: 2.675835
Average total loss: 3.118114
tensor(-1.5429, device='cuda:0') tensor(1.5730, device='cuda:0') tensor(8.6234e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.421127
Average KL loss: 2.617568
Average total loss: 3.038694
tensor(-1.5887, device='cuda:0') tensor(1.6292, device='cuda:0') tensor(8.0405e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.406040
Average KL loss: 2.561907
Average total loss: 2.967947
tensor(-1.6333, device='cuda:0') tensor(1.6834, device='cuda:0') tensor(1.0322e-07, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.389372
Average KL loss: 2.508615
Average total loss: 2.897987
tensor(-1.6768, device='cuda:0') tensor(1.7360, device='cuda:0') tensor(9.7001e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.374391
Average KL loss: 2.457632
Average total loss: 2.832023
tensor(-1.7191, device='cuda:0') tensor(1.7868, device='cuda:0') tensor(9.8846e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.356812
Average KL loss: 2.408786
Average total loss: 2.765597
tensor(-1.7605, device='cuda:0') tensor(1.8358, device='cuda:0') tensor(8.9099e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.347939
Average KL loss: 2.361909
Average total loss: 2.709848
tensor(-1.8009, device='cuda:0') tensor(1.8834, device='cuda:0') tensor(8.7578e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.331854
Average KL loss: 2.316871
Average total loss: 2.648725
tensor(-1.8403, device='cuda:0') tensor(1.9295, device='cuda:0') tensor(9.2819e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.322916
Average KL loss: 2.273644
Average total loss: 2.596560
tensor(-1.8789, device='cuda:0') tensor(1.9742, device='cuda:0') tensor(9.2370e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.308284
Average KL loss: 2.232022
Average total loss: 2.540306
tensor(-1.9167, device='cuda:0') tensor(2.0176, device='cuda:0') tensor(8.6332e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.306111
Average KL loss: 2.191871
Average total loss: 2.497983
tensor(-1.9536, device='cuda:0') tensor(2.0598, device='cuda:0') tensor(8.4946e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.286344
Average KL loss: 2.153204
Average total loss: 2.439548
tensor(-1.9898, device='cuda:0') tensor(2.1007, device='cuda:0') tensor(8.9036e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.273141
Average KL loss: 2.115869
Average total loss: 2.389010
tensor(-2.0253, device='cuda:0') tensor(2.1405, device='cuda:0') tensor(9.0230e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.268232
Average KL loss: 2.079848
Average total loss: 2.348080
tensor(-2.0600, device='cuda:0') tensor(2.1793, device='cuda:0') tensor(8.3090e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.265004
Average KL loss: 2.044999
Average total loss: 2.310003
tensor(-2.0942, device='cuda:0') tensor(2.2171, device='cuda:0') tensor(9.2338e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.249574
Average KL loss: 2.011377
Average total loss: 2.260951
tensor(-2.1276, device='cuda:0') tensor(2.2540, device='cuda:0') tensor(6.8846e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.247701
Average KL loss: 1.978886
Average total loss: 2.226587
tensor(-2.1605, device='cuda:0') tensor(2.2901, device='cuda:0') tensor(7.6022e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.236606
Average KL loss: 1.947460
Average total loss: 2.184065
tensor(-2.1927, device='cuda:0') tensor(2.3252, device='cuda:0') tensor(7.9241e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.230253
Average KL loss: 1.917051
Average total loss: 2.147304
tensor(-2.2243, device='cuda:0') tensor(2.3596, device='cuda:0') tensor(7.4452e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.216698
Average KL loss: 1.887576
Average total loss: 2.104274
tensor(-2.2555, device='cuda:0') tensor(2.3930, device='cuda:0') tensor(8.9362e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.209955
Average KL loss: 1.858894
Average total loss: 2.068849
tensor(-2.2861, device='cuda:0') tensor(2.4255, device='cuda:0') tensor(8.0654e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.202660
Average KL loss: 1.831056
Average total loss: 2.033717
tensor(-2.3162, device='cuda:0') tensor(2.4574, device='cuda:0') tensor(8.3385e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.195339
Average KL loss: 1.804042
Average total loss: 1.999381
tensor(-2.3459, device='cuda:0') tensor(2.4887, device='cuda:0') tensor(7.8177e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.200279
Average KL loss: 1.777898
Average total loss: 1.978178
tensor(-2.3750, device='cuda:0') tensor(2.5195, device='cuda:0') tensor(8.2026e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.185722
Average KL loss: 1.752516
Average total loss: 1.938239
tensor(-2.4037, device='cuda:0') tensor(2.5495, device='cuda:0') tensor(7.9522e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.179027
Average KL loss: 1.727766
Average total loss: 1.906793
tensor(-2.4320, device='cuda:0') tensor(2.5788, device='cuda:0') tensor(7.2469e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.181164
Average KL loss: 1.703760
Average total loss: 1.884923
tensor(-2.4598, device='cuda:0') tensor(2.6078, device='cuda:0') tensor(7.7314e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.168160
Average KL loss: 1.680415
Average total loss: 1.848575
tensor(-2.4873, device='cuda:0') tensor(2.6361, device='cuda:0') tensor(7.4483e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.154107
Average KL loss: 1.657684
Average total loss: 1.811791
tensor(-2.5143, device='cuda:0') tensor(2.6637, device='cuda:0') tensor(6.8499e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.158486
Average KL loss: 1.635438
Average total loss: 1.793923
tensor(-2.5410, device='cuda:0') tensor(2.6909, device='cuda:0') tensor(6.5613e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.151658
Average KL loss: 1.613827
Average total loss: 1.765485
tensor(-2.5673, device='cuda:0') tensor(2.7176, device='cuda:0') tensor(6.3884e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.145837
Average KL loss: 1.592750
Average total loss: 1.738586
tensor(-2.5933, device='cuda:0') tensor(2.7437, device='cuda:0') tensor(6.8473e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.143111
Average KL loss: 1.572181
Average total loss: 1.715292
tensor(-2.6189, device='cuda:0') tensor(2.7694, device='cuda:0') tensor(6.6062e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.141752
Average KL loss: 1.552108
Average total loss: 1.693860
tensor(-2.6442, device='cuda:0') tensor(2.7947, device='cuda:0') tensor(7.2861e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.134856
Average KL loss: 1.532515
Average total loss: 1.667371
tensor(-2.6692, device='cuda:0') tensor(2.8195, device='cuda:0') tensor(7.0380e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.132485
Average KL loss: 1.513397
Average total loss: 1.645882
tensor(-2.6939, device='cuda:0') tensor(2.8440, device='cuda:0') tensor(6.3627e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.128354
Average KL loss: 1.494769
Average total loss: 1.623122
tensor(-2.7183, device='cuda:0') tensor(2.8681, device='cuda:0') tensor(6.6885e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.127782
Average KL loss: 1.476554
Average total loss: 1.604335
tensor(-2.7424, device='cuda:0') tensor(2.8919, device='cuda:0') tensor(6.0798e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.124271
Average KL loss: 1.458798
Average total loss: 1.583069
tensor(-2.7662, device='cuda:0') tensor(2.9154, device='cuda:0') tensor(5.7323e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.118523
Average KL loss: 1.441480
Average total loss: 1.560004
tensor(-2.7897, device='cuda:0') tensor(2.9385, device='cuda:0') tensor(6.4431e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.110909
Average KL loss: 1.424409
Average total loss: 1.535317
tensor(-2.8130, device='cuda:0') tensor(2.9608, device='cuda:0') tensor(6.8165e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.110937
Average KL loss: 1.407624
Average total loss: 1.518561
tensor(-2.8360, device='cuda:0') tensor(2.9829, device='cuda:0') tensor(6.9122e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.111869
Average KL loss: 1.391282
Average total loss: 1.503151
tensor(-2.8588, device='cuda:0') tensor(3.0048, device='cuda:0') tensor(5.8762e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.106407
Average KL loss: 1.375326
Average total loss: 1.481733
tensor(-2.8813, device='cuda:0') tensor(3.0265, device='cuda:0') tensor(6.5883e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.102734
Average KL loss: 1.359742
Average total loss: 1.462476
tensor(-2.9036, device='cuda:0') tensor(3.0478, device='cuda:0') tensor(5.9579e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.104665
Average KL loss: 1.344377
Average total loss: 1.449042
tensor(-2.9257, device='cuda:0') tensor(3.0687, device='cuda:0') tensor(5.9402e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.098266
Average KL loss: 1.329348
Average total loss: 1.427614
tensor(-2.9475, device='cuda:0') tensor(3.0894, device='cuda:0') tensor(5.7141e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.099213
Average KL loss: 1.314691
Average total loss: 1.413904
tensor(-2.9691, device='cuda:0') tensor(3.1098, device='cuda:0') tensor(6.3483e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.100459
Average KL loss: 1.300348
Average total loss: 1.400807
tensor(-2.9905, device='cuda:0') tensor(3.1303, device='cuda:0') tensor(5.1934e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.093884
Average KL loss: 1.286319
Average total loss: 1.380202
tensor(-3.0116, device='cuda:0') tensor(3.1502, device='cuda:0') tensor(6.2467e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.091236
Average KL loss: 1.272521
Average total loss: 1.363757
tensor(-3.0326, device='cuda:0') tensor(3.1698, device='cuda:0') tensor(5.8470e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.088360
Average KL loss: 1.258932
Average total loss: 1.347291
tensor(-3.0534, device='cuda:0') tensor(3.1891, device='cuda:0') tensor(5.7991e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.085770
Average KL loss: 1.245582
Average total loss: 1.331352
tensor(-3.0739, device='cuda:0') tensor(3.2081, device='cuda:0') tensor(5.8244e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.084841
Average KL loss: 1.232546
Average total loss: 1.317387
tensor(-3.0943, device='cuda:0') tensor(3.2269, device='cuda:0') tensor(5.6915e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.082349
Average KL loss: 1.219721
Average total loss: 1.302070
tensor(-3.1145, device='cuda:0') tensor(3.2455, device='cuda:0') tensor(6.1386e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.084583
Average KL loss: 1.207158
Average total loss: 1.291741
tensor(-3.1345, device='cuda:0') tensor(3.2641, device='cuda:0') tensor(4.4486e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.081430
Average KL loss: 1.194879
Average total loss: 1.276309
tensor(-3.1543, device='cuda:0') tensor(3.2824, device='cuda:0') tensor(5.8729e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.083000
Average KL loss: 1.182769
Average total loss: 1.265769
tensor(-3.1740, device='cuda:0') tensor(3.3005, device='cuda:0') tensor(5.5349e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.075337
Average KL loss: 1.170951
Average total loss: 1.246288
tensor(-3.1934, device='cuda:0') tensor(3.3184, device='cuda:0') tensor(5.6714e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.072755
Average KL loss: 1.159269
Average total loss: 1.232024
tensor(-3.2128, device='cuda:0') tensor(3.3359, device='cuda:0') tensor(5.4968e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.072988
Average KL loss: 1.147788
Average total loss: 1.220776
tensor(-3.2319, device='cuda:0') tensor(3.3532, device='cuda:0') tensor(5.4840e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.073327
Average KL loss: 1.136499
Average total loss: 1.209826
tensor(-3.2509, device='cuda:0') tensor(3.3703, device='cuda:0') tensor(5.5451e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.070706
Average KL loss: 1.125406
Average total loss: 1.196112
tensor(-3.2697, device='cuda:0') tensor(3.3872, device='cuda:0') tensor(5.2594e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.069884
Average KL loss: 1.114547
Average total loss: 1.184432
tensor(-3.2884, device='cuda:0') tensor(3.4041, device='cuda:0') tensor(4.9376e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.069099
Average KL loss: 1.103805
Average total loss: 1.172904
tensor(-3.3069, device='cuda:0') tensor(3.4206, device='cuda:0') tensor(4.9790e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.066988
Average KL loss: 1.093284
Average total loss: 1.160272
tensor(-3.3253, device='cuda:0') tensor(3.4372, device='cuda:0') tensor(5.2501e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.066684
Average KL loss: 1.082973
Average total loss: 1.149658
tensor(-3.3436, device='cuda:0') tensor(3.4535, device='cuda:0') tensor(5.0373e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.066678
Average KL loss: 1.072779
Average total loss: 1.139457
tensor(-3.3616, device='cuda:0') tensor(3.4697, device='cuda:0') tensor(4.7729e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.062432
Average KL loss: 1.062775
Average total loss: 1.125206
tensor(-3.3796, device='cuda:0') tensor(3.4855, device='cuda:0') tensor(4.3630e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.063178
Average KL loss: 1.052902
Average total loss: 1.116080
tensor(-3.3975, device='cuda:0') tensor(3.5012, device='cuda:0') tensor(5.2839e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.062839
Average KL loss: 1.043189
Average total loss: 1.106028
tensor(-3.4151, device='cuda:0') tensor(3.5168, device='cuda:0') tensor(5.1208e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.063043
Average KL loss: 1.033716
Average total loss: 1.096758
tensor(-3.4326, device='cuda:0') tensor(3.5325, device='cuda:0') tensor(4.9161e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.059911
Average KL loss: 1.024374
Average total loss: 1.084284
tensor(-3.4501, device='cuda:0') tensor(3.5478, device='cuda:0') tensor(5.1713e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.059334
Average KL loss: 1.015195
Average total loss: 1.074529
tensor(-3.4673, device='cuda:0') tensor(3.5631, device='cuda:0') tensor(5.0413e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.060357
Average KL loss: 1.006172
Average total loss: 1.066530
tensor(-3.4844, device='cuda:0') tensor(3.5782, device='cuda:0') tensor(4.5999e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.060328
Average KL loss: 0.997331
Average total loss: 1.057660
tensor(-3.5014, device='cuda:0') tensor(3.5934, device='cuda:0') tensor(4.3509e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.056384
Average KL loss: 0.988586
Average total loss: 1.044970
tensor(-3.5182, device='cuda:0') tensor(3.6080, device='cuda:0') tensor(4.7735e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.054750
Average KL loss: 0.979906
Average total loss: 1.034656
tensor(-3.5350, device='cuda:0') tensor(3.6225, device='cuda:0') tensor(4.5826e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.053656
Average KL loss: 0.971353
Average total loss: 1.025009
tensor(-3.5517, device='cuda:0') tensor(3.6368, device='cuda:0') tensor(4.7363e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.056209
Average KL loss: 0.962980
Average total loss: 1.019189
tensor(-3.5682, device='cuda:0') tensor(3.6513, device='cuda:0') tensor(4.9823e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.053081
Average KL loss: 0.954753
Average total loss: 1.007835
tensor(-3.5846, device='cuda:0') tensor(3.6656, device='cuda:0') tensor(4.5160e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.054403
Average KL loss: 0.946633
Average total loss: 1.001036
tensor(-3.6009, device='cuda:0') tensor(3.6796, device='cuda:0') tensor(4.7724e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.051851
Average KL loss: 0.938686
Average total loss: 0.990537
tensor(-3.6170, device='cuda:0') tensor(3.6937, device='cuda:0') tensor(4.6188e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.051945
Average KL loss: 0.930807
Average total loss: 0.982752
tensor(-3.6331, device='cuda:0') tensor(3.7075, device='cuda:0') tensor(4.5217e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.050104
Average KL loss: 0.922995
Average total loss: 0.973099
tensor(-3.6491, device='cuda:0') tensor(3.7211, device='cuda:0') tensor(3.9415e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.050913
Average KL loss: 0.915325
Average total loss: 0.966237
tensor(-3.6649, device='cuda:0') tensor(3.7346, device='cuda:0') tensor(3.8559e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.051841
Average KL loss: 0.907773
Average total loss: 0.959615
tensor(-3.6807, device='cuda:0') tensor(3.7481, device='cuda:0') tensor(4.6669e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.049642
Average KL loss: 0.900374
Average total loss: 0.950016
tensor(-3.6963, device='cuda:0') tensor(3.7615, device='cuda:0') tensor(4.2316e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.049034
Average KL loss: 0.893066
Average total loss: 0.942100
tensor(-3.7118, device='cuda:0') tensor(3.7748, device='cuda:0') tensor(4.4399e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.047287
Average KL loss: 0.885810
Average total loss: 0.933097
tensor(-3.7272, device='cuda:0') tensor(3.7876, device='cuda:0') tensor(4.2939e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.051575
Average KL loss: 0.878719
Average total loss: 0.930294
tensor(-3.7425, device='cuda:0') tensor(3.8010, device='cuda:0') tensor(4.2360e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.047257
Average KL loss: 0.871784
Average total loss: 0.919040
tensor(-3.7577, device='cuda:0') tensor(3.8139, device='cuda:0') tensor(3.7875e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.046624
Average KL loss: 0.864876
Average total loss: 0.911500
tensor(-3.7728, device='cuda:0') tensor(3.8267, device='cuda:0') tensor(4.5376e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.047848
Average KL loss: 0.858093
Average total loss: 0.905941
tensor(-3.7878, device='cuda:0') tensor(3.8396, device='cuda:0') tensor(4.2037e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.048843
Average KL loss: 0.851441
Average total loss: 0.900284
tensor(-3.8027, device='cuda:0') tensor(3.8524, device='cuda:0') tensor(4.3609e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.047040
Average KL loss: 0.844895
Average total loss: 0.891936
tensor(-3.8174, device='cuda:0') tensor(3.8651, device='cuda:0') tensor(4.1967e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.047220
Average KL loss: 0.838477
Average total loss: 0.885697
tensor(-3.8321, device='cuda:0') tensor(3.8779, device='cuda:0') tensor(4.0703e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.047462
Average KL loss: 0.832154
Average total loss: 0.879616
tensor(-3.8466, device='cuda:0') tensor(3.8904, device='cuda:0') tensor(4.1722e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.042893
Average KL loss: 0.825877
Average total loss: 0.868770
tensor(-3.8612, device='cuda:0') tensor(3.9025, device='cuda:0') tensor(3.8717e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.043377
Average KL loss: 0.819613
Average total loss: 0.862989
tensor(-3.8755, device='cuda:0') tensor(3.9146, device='cuda:0') tensor(3.9461e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.042598
Average KL loss: 0.813497
Average total loss: 0.856095
tensor(-3.8898, device='cuda:0') tensor(3.9267, device='cuda:0') tensor(3.8745e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.043523
Average KL loss: 0.807436
Average total loss: 0.850960
tensor(-3.9041, device='cuda:0') tensor(3.9387, device='cuda:0') tensor(2.6944e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.046471
Average KL loss: 0.801550
Average total loss: 0.848022
tensor(-3.9181, device='cuda:0') tensor(3.9509, device='cuda:0') tensor(3.7322e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.042198
Average KL loss: 0.795724
Average total loss: 0.837923
tensor(-3.9322, device='cuda:0') tensor(3.9627, device='cuda:0') tensor(3.9673e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.042054
Average KL loss: 0.789931
Average total loss: 0.831985
tensor(-3.9461, device='cuda:0') tensor(3.9745, device='cuda:0') tensor(4.1327e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.043542
Average KL loss: 0.784268
Average total loss: 0.827810
tensor(-3.9599, device='cuda:0') tensor(3.9864, device='cuda:0') tensor(3.8296e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.042347
Average KL loss: 0.778753
Average total loss: 0.821100
tensor(-3.9736, device='cuda:0') tensor(3.9982, device='cuda:0') tensor(3.4070e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.045305
Average KL loss: 0.773285
Average total loss: 0.818591
tensor(-3.9873, device='cuda:0') tensor(4.0102, device='cuda:0') tensor(3.9280e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.040946
Average KL loss: 0.767892
Average total loss: 0.808838
tensor(-4.0008, device='cuda:0') tensor(4.0217, device='cuda:0') tensor(3.6893e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.042260
Average KL loss: 0.762534
Average total loss: 0.804794
tensor(-4.0143, device='cuda:0') tensor(4.0332, device='cuda:0') tensor(3.5079e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.043326
Average KL loss: 0.757302
Average total loss: 0.800627
tensor(-4.0276, device='cuda:0') tensor(4.0448, device='cuda:0') tensor(3.8045e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.044308
Average KL loss: 0.752178
Average total loss: 0.796486
tensor(-4.0409, device='cuda:0') tensor(4.0566, device='cuda:0') tensor(3.6220e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.039279
Average KL loss: 0.747103
Average total loss: 0.786383
tensor(-4.0541, device='cuda:0') tensor(4.0678, device='cuda:0') tensor(3.5779e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.041544
Average KL loss: 0.742047
Average total loss: 0.783591
tensor(-4.0672, device='cuda:0') tensor(4.0791, device='cuda:0') tensor(3.6665e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.042318
Average KL loss: 0.737090
Average total loss: 0.779409
tensor(-4.0802, device='cuda:0') tensor(4.0903, device='cuda:0') tensor(3.6604e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.043255
Average KL loss: 0.732268
Average total loss: 0.775522
tensor(-4.0930, device='cuda:0') tensor(4.1019, device='cuda:0') tensor(3.5328e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.038184
Average KL loss: 0.727533
Average total loss: 0.765717
tensor(-4.1058, device='cuda:0') tensor(4.1130, device='cuda:0') tensor(3.8040e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.041305
Average KL loss: 0.722770
Average total loss: 0.764075
tensor(-4.1186, device='cuda:0') tensor(4.1241, device='cuda:0') tensor(3.0701e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.039285
Average KL loss: 0.718133
Average total loss: 0.757418
tensor(-4.1312, device='cuda:0') tensor(4.1351, device='cuda:0') tensor(3.3618e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.038097
Average KL loss: 0.713506
Average total loss: 0.751602
tensor(-4.1438, device='cuda:0') tensor(4.1460, device='cuda:0') tensor(3.6748e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.041162
Average KL loss: 0.708936
Average total loss: 0.750098
tensor(-4.1563, device='cuda:0') tensor(4.1568, device='cuda:0') tensor(3.0378e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.039623
Average KL loss: 0.704487
Average total loss: 0.744110
tensor(-4.1687, device='cuda:0') tensor(4.1677, device='cuda:0') tensor(3.4822e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.037121
Average KL loss: 0.700031
Average total loss: 0.737152
tensor(-4.1810, device='cuda:0') tensor(4.1782, device='cuda:0') tensor(3.3658e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.037583
Average KL loss: 0.695647
Average total loss: 0.733230
tensor(-4.1933, device='cuda:0') tensor(4.1888, device='cuda:0') tensor(3.3069e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.040287
Average KL loss: 0.691350
Average total loss: 0.731637
tensor(-4.2054, device='cuda:0') tensor(4.1996, device='cuda:0') tensor(3.4447e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.037083
Average KL loss: 0.687131
Average total loss: 0.724214
tensor(-4.2175, device='cuda:0') tensor(4.2100, device='cuda:0') tensor(3.2880e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.039027
Average KL loss: 0.682950
Average total loss: 0.721977
tensor(-4.2295, device='cuda:0') tensor(4.2206, device='cuda:0') tensor(2.5633e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.038600
Average KL loss: 0.678836
Average total loss: 0.717435
tensor(-4.2415, device='cuda:0') tensor(4.2310, device='cuda:0') tensor(3.2107e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.039297
Average KL loss: 0.674778
Average total loss: 0.714075
tensor(-4.2533, device='cuda:0') tensor(4.2416, device='cuda:0') tensor(2.7679e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.038725
Average KL loss: 0.670820
Average total loss: 0.709545
tensor(-4.2650, device='cuda:0') tensor(4.2521, device='cuda:0') tensor(3.4623e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.037300
Average KL loss: 0.666894
Average total loss: 0.704193
tensor(-4.2767, device='cuda:0') tensor(4.2625, device='cuda:0') tensor(3.2971e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.038111
Average KL loss: 0.663002
Average total loss: 0.701113
tensor(-4.2884, device='cuda:0') tensor(4.2728, device='cuda:0') tensor(3.3588e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.034090
Average KL loss: 0.659106
Average total loss: 0.693196
tensor(-4.2999, device='cuda:0') tensor(4.2826, device='cuda:0') tensor(3.0557e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.036769
Average KL loss: 0.655222
Average total loss: 0.691991
tensor(-4.3115, device='cuda:0') tensor(4.2925, device='cuda:0') tensor(3.0619e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.035444
Average KL loss: 0.651420
Average total loss: 0.686865
tensor(-4.3229, device='cuda:0') tensor(4.3024, device='cuda:0') tensor(3.3518e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.035285
Average KL loss: 0.647684
Average total loss: 0.682969
tensor(-4.3343, device='cuda:0') tensor(4.3123, device='cuda:0') tensor(3.0457e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.036738
Average KL loss: 0.644000
Average total loss: 0.680738
tensor(-4.3456, device='cuda:0') tensor(4.3222, device='cuda:0') tensor(3.1965e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.034393
Average KL loss: 0.640340
Average total loss: 0.674733
tensor(-4.3568, device='cuda:0') tensor(4.3318, device='cuda:0') tensor(3.2829e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.035112
Average KL loss: 0.636740
Average total loss: 0.671852
tensor(-4.3680, device='cuda:0') tensor(4.3414, device='cuda:0') tensor(2.4504e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.034670
Average KL loss: 0.633113
Average total loss: 0.667783
tensor(-4.3792, device='cuda:0') tensor(4.3508, device='cuda:0') tensor(3.1858e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.035313
Average KL loss: 0.629552
Average total loss: 0.664865
tensor(-4.3902, device='cuda:0') tensor(4.3603, device='cuda:0') tensor(2.6424e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.036488
Average KL loss: 0.626088
Average total loss: 0.662575
tensor(-4.4012, device='cuda:0') tensor(4.3699, device='cuda:0') tensor(3.1662e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.035455
Average KL loss: 0.622663
Average total loss: 0.658118
tensor(-4.4121, device='cuda:0') tensor(4.3795, device='cuda:0') tensor(2.6366e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.033029
Average KL loss: 0.619286
Average total loss: 0.652315
tensor(-4.4230, device='cuda:0') tensor(4.3889, device='cuda:0') tensor(3.0660e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.037594
Average KL loss: 0.615934
Average total loss: 0.653528
tensor(-4.4338, device='cuda:0') tensor(4.3985, device='cuda:0') tensor(2.7294e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.035418
Average KL loss: 0.612695
Average total loss: 0.648113
tensor(-4.4445, device='cuda:0') tensor(4.4080, device='cuda:0') tensor(3.3417e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.035182
Average KL loss: 0.609448
Average total loss: 0.644629
tensor(-4.4552, device='cuda:0') tensor(4.4173, device='cuda:0') tensor(3.1252e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.034752
Average KL loss: 0.606261
Average total loss: 0.641013
tensor(-4.4658, device='cuda:0') tensor(4.4268, device='cuda:0') tensor(2.8636e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.036226
Average KL loss: 0.603139
Average total loss: 0.639364
tensor(-4.4763, device='cuda:0') tensor(4.4362, device='cuda:0') tensor(2.9682e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.032824
Average KL loss: 0.600028
Average total loss: 0.632853
tensor(-4.4868, device='cuda:0') tensor(4.4454, device='cuda:0') tensor(2.7284e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.036165
Average KL loss: 0.596946
Average total loss: 0.633112
tensor(-4.4971, device='cuda:0') tensor(4.4548, device='cuda:0') tensor(2.5730e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.032297
Average KL loss: 0.593948
Average total loss: 0.626245
tensor(-4.5075, device='cuda:0') tensor(4.4638, device='cuda:0') tensor(2.3668e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.034023
Average KL loss: 0.590884
Average total loss: 0.624907
tensor(-4.5178, device='cuda:0') tensor(4.4728, device='cuda:0') tensor(2.5892e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.033800
Average KL loss: 0.587894
Average total loss: 0.621694
tensor(-4.5281, device='cuda:0') tensor(4.4818, device='cuda:0') tensor(2.4488e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.033224
Average KL loss: 0.584949
Average total loss: 0.618173
tensor(-4.5382, device='cuda:0') tensor(4.4907, device='cuda:0') tensor(2.9213e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.033500
Average KL loss: 0.582003
Average total loss: 0.615503
tensor(-4.5484, device='cuda:0') tensor(4.4995, device='cuda:0') tensor(2.0652e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.033157
Average KL loss: 0.579109
Average total loss: 0.612266
tensor(-4.5585, device='cuda:0') tensor(4.5084, device='cuda:0') tensor(2.7353e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.033658
Average KL loss: 0.576278
Average total loss: 0.609936
tensor(-4.5685, device='cuda:0') tensor(4.5175, device='cuda:0') tensor(2.6375e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.033706
Average KL loss: 0.573512
Average total loss: 0.607219
tensor(-4.5784, device='cuda:0') tensor(4.5263, device='cuda:0') tensor(2.2736e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.033022
Average KL loss: 0.570719
Average total loss: 0.603741
tensor(-4.5883, device='cuda:0') tensor(4.5349, device='cuda:0') tensor(2.2918e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.034551
Average KL loss: 0.567985
Average total loss: 0.602536
tensor(-4.5982, device='cuda:0') tensor(4.5438, device='cuda:0') tensor(2.4500e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.033000
Average KL loss: 0.565270
Average total loss: 0.598270
tensor(-4.6080, device='cuda:0') tensor(4.5523, device='cuda:0') tensor(2.7445e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.032953
Average KL loss: 0.562572
Average total loss: 0.595525
tensor(-4.6178, device='cuda:0') tensor(4.5610, device='cuda:0') tensor(2.3872e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.034073
Average KL loss: 0.559946
Average total loss: 0.594019
tensor(-4.6275, device='cuda:0') tensor(4.5698, device='cuda:0') tensor(2.4740e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.032899
Average KL loss: 0.557347
Average total loss: 0.590246
tensor(-4.6371, device='cuda:0') tensor(4.5783, device='cuda:0') tensor(2.4383e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.033277
Average KL loss: 0.554775
Average total loss: 0.588051
tensor(-4.6467, device='cuda:0') tensor(4.5869, device='cuda:0') tensor(2.8070e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.031889
Average KL loss: 0.552195
Average total loss: 0.584084
tensor(-4.6563, device='cuda:0') tensor(4.5952, device='cuda:0') tensor(2.2338e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.031544
Average KL loss: 0.549631
Average total loss: 0.581175
tensor(-4.6658, device='cuda:0') tensor(4.6035, device='cuda:0') tensor(2.6651e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.031893
Average KL loss: 0.547081
Average total loss: 0.578974
tensor(-4.6752, device='cuda:0') tensor(4.6117, device='cuda:0') tensor(2.2389e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.032727
Average KL loss: 0.544598
Average total loss: 0.577325
tensor(-4.6847, device='cuda:0') tensor(4.6199, device='cuda:0') tensor(1.7107e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.031301
Average KL loss: 0.542118
Average total loss: 0.573419
tensor(-4.6940, device='cuda:0') tensor(4.6280, device='cuda:0') tensor(2.4854e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.030692
Average KL loss: 0.539624
Average total loss: 0.570316
tensor(-4.7034, device='cuda:0') tensor(4.6360, device='cuda:0') tensor(2.0541e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.033177
Average KL loss: 0.537207
Average total loss: 0.570384
tensor(-4.7127, device='cuda:0') tensor(4.6443, device='cuda:0') tensor(1.9621e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.031917
Average KL loss: 0.534859
Average total loss: 0.566777
tensor(-4.7219, device='cuda:0') tensor(4.6525, device='cuda:0') tensor(2.5454e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.031600
Average KL loss: 0.532496
Average total loss: 0.564096
tensor(-4.7311, device='cuda:0') tensor(4.6606, device='cuda:0') tensor(2.3998e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.032631
Average KL loss: 0.530206
Average total loss: 0.562837
tensor(-4.7402, device='cuda:0') tensor(4.6690, device='cuda:0') tensor(2.4928e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.030537
Average KL loss: 0.527915
Average total loss: 0.558452
tensor(-4.7493, device='cuda:0') tensor(4.6769, device='cuda:0') tensor(2.5765e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.031480
Average KL loss: 0.525617
Average total loss: 0.557097
tensor(-4.7583, device='cuda:0') tensor(4.6849, device='cuda:0') tensor(2.8543e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.030338
Average KL loss: 0.523350
Average total loss: 0.553688
tensor(-4.7673, device='cuda:0') tensor(4.6925, device='cuda:0') tensor(2.4510e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.032513
Average KL loss: 0.521102
Average total loss: 0.553616
 Percentile value: -1.8646984815597538
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1710 /    1728             ( 98.96%) | total_pruned =      18 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   30781 /   36864             ( 83.50%) | total_pruned =    6083 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   31089 /   36864             ( 84.33%) | total_pruned =    5775 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   30060 /   36864             ( 81.54%) | total_pruned =    6804 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   29714 /   36864             ( 80.60%) | total_pruned =    7150 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   57104 /   73728             ( 77.45%) | total_pruned =   16624 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  106819 /  147456             ( 72.44%) | total_pruned =   40637 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7772 /    8192             ( 94.87%) | total_pruned =     420 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   92135 /  147456             ( 62.48%) | total_pruned =   55321 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   93155 /  147456             ( 63.17%) | total_pruned =   54301 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  200644 /  294912             ( 68.04%) | total_pruned =   94268 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  363019 /  589824             ( 61.55%) | total_pruned =  226805 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   29113 /   32768             ( 88.85%) | total_pruned =    3655 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  246783 /  589824             ( 41.84%) | total_pruned =  343041 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  245710 /  589824             ( 41.66%) | total_pruned =  344114 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  604118 / 1179648             ( 51.21%) | total_pruned =  575530 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  649462 / 2359296             ( 27.53%) | total_pruned = 1709834 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   89893 /  131072             ( 68.58%) | total_pruned =   41179 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  287721 / 2359296             ( 12.20%) | total_pruned = 2071575 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     472 /     512             ( 92.19%) | total_pruned =      40 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  142254 / 2359296             (  6.03%) | total_pruned = 2217042 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
linear.weight        | nonzeros =    5032 /    5120             ( 98.28%) | total_pruned =      88 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 38/200 Loss: 0.000035 Accuracy: 86.53 100.00 % Best test Accuracy: 86.53%
tensor(-4.7763, device='cuda:0') tensor(4.7005, device='cuda:0') tensor(1.2443e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.102837
Average KL loss: 0.504894
Average total loss: 0.607730
tensor(-4.8906, device='cuda:0') tensor(4.6401, device='cuda:0') tensor(4.4323e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.092301
Average KL loss: 0.492384
Average total loss: 0.584686
tensor(-4.9779, device='cuda:0') tensor(4.6626, device='cuda:0') tensor(1.5697e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.083728
Average KL loss: 0.484882
Average total loss: 0.568610
tensor(-5.0540, device='cuda:0') tensor(4.7017, device='cuda:0') tensor(8.2976e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.079140
Average KL loss: 0.479352
Average total loss: 0.558493
tensor(-5.1219, device='cuda:0') tensor(4.7501, device='cuda:0') tensor(1.1259e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.073502
Average KL loss: 0.474999
Average total loss: 0.548501
tensor(-5.1833, device='cuda:0') tensor(4.8035, device='cuda:0') tensor(1.8807e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.074007
Average KL loss: 0.471385
Average total loss: 0.545392
tensor(-5.2396, device='cuda:0') tensor(4.8597, device='cuda:0') tensor(9.2129e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.072188
Average KL loss: 0.468349
Average total loss: 0.540536
tensor(-5.2915, device='cuda:0') tensor(4.9174, device='cuda:0') tensor(1.0270e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.067132
Average KL loss: 0.465697
Average total loss: 0.532829
tensor(-5.3398, device='cuda:0') tensor(4.9758, device='cuda:0') tensor(8.0922e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.067237
Average KL loss: 0.463350
Average total loss: 0.530588
tensor(-5.3850, device='cuda:0') tensor(5.0343, device='cuda:0') tensor(1.5361e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.063894
Average KL loss: 0.461238
Average total loss: 0.525132
tensor(-5.4274, device='cuda:0') tensor(5.0923, device='cuda:0') tensor(1.0636e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.060357
Average KL loss: 0.459280
Average total loss: 0.519637
tensor(-5.4675, device='cuda:0') tensor(5.1494, device='cuda:0') tensor(1.2615e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.061988
Average KL loss: 0.457452
Average total loss: 0.519439
tensor(-5.5055, device='cuda:0') tensor(5.2058, device='cuda:0') tensor(1.0386e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.058706
Average KL loss: 0.455746
Average total loss: 0.514452
tensor(-5.5416, device='cuda:0') tensor(5.2612, device='cuda:0') tensor(1.5193e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.056372
Average KL loss: 0.454118
Average total loss: 0.510490
tensor(-5.5761, device='cuda:0') tensor(5.3155, device='cuda:0') tensor(1.5719e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.058243
Average KL loss: 0.452598
Average total loss: 0.510841
tensor(-5.6090, device='cuda:0') tensor(5.3689, device='cuda:0') tensor(1.7769e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.051867
Average KL loss: 0.451132
Average total loss: 0.503000
tensor(-5.6406, device='cuda:0') tensor(5.4210, device='cuda:0') tensor(5.7288e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.055698
Average KL loss: 0.449690
Average total loss: 0.505388
tensor(-5.6709, device='cuda:0') tensor(5.4721, device='cuda:0') tensor(1.2145e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.053736
Average KL loss: 0.448327
Average total loss: 0.502063
tensor(-5.7001, device='cuda:0') tensor(5.5221, device='cuda:0') tensor(1.4781e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.054022
Average KL loss: 0.446987
Average total loss: 0.501009
tensor(-5.7282, device='cuda:0') tensor(5.5708, device='cuda:0') tensor(1.5021e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.050304
Average KL loss: 0.445687
Average total loss: 0.495991
tensor(-5.7554, device='cuda:0') tensor(5.6184, device='cuda:0') tensor(1.1410e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.047174
Average KL loss: 0.444354
Average total loss: 0.491528
tensor(-5.7817, device='cuda:0') tensor(5.6647, device='cuda:0') tensor(1.4076e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.049333
Average KL loss: 0.443048
Average total loss: 0.492381
tensor(-5.8072, device='cuda:0') tensor(5.7101, device='cuda:0') tensor(1.2121e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.045739
Average KL loss: 0.441777
Average total loss: 0.487515
tensor(-5.8319, device='cuda:0') tensor(5.7543, device='cuda:0') tensor(1.5052e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.046773
Average KL loss: 0.440523
Average total loss: 0.487296
tensor(-5.8559, device='cuda:0') tensor(5.7978, device='cuda:0') tensor(1.9853e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.047688
Average KL loss: 0.439306
Average total loss: 0.486993
tensor(-5.8791, device='cuda:0') tensor(5.8403, device='cuda:0') tensor(1.2937e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.042590
Average KL loss: 0.438083
Average total loss: 0.480673
tensor(-5.9018, device='cuda:0') tensor(5.8815, device='cuda:0') tensor(1.3550e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.044144
Average KL loss: 0.436861
Average total loss: 0.481005
tensor(-5.9239, device='cuda:0') tensor(5.9219, device='cuda:0') tensor(1.4847e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.042985
Average KL loss: 0.435641
Average total loss: 0.478626
tensor(-5.9454, device='cuda:0') tensor(5.9613, device='cuda:0') tensor(1.7845e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.045042
Average KL loss: 0.434457
Average total loss: 0.479499
tensor(-5.9664, device='cuda:0') tensor(6.0001, device='cuda:0') tensor(1.7936e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.044589
Average KL loss: 0.433311
Average total loss: 0.477900
tensor(-5.9868, device='cuda:0') tensor(6.0381, device='cuda:0') tensor(1.5490e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.040766
Average KL loss: 0.432168
Average total loss: 0.472934
tensor(-6.0068, device='cuda:0') tensor(6.0752, device='cuda:0') tensor(1.5068e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.040866
Average KL loss: 0.431011
Average total loss: 0.471877
tensor(-6.0264, device='cuda:0') tensor(6.1114, device='cuda:0') tensor(1.5514e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.040726
Average KL loss: 0.429855
Average total loss: 0.470581
tensor(-6.0455, device='cuda:0') tensor(6.1469, device='cuda:0') tensor(1.4769e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.040059
Average KL loss: 0.428718
Average total loss: 0.468777
tensor(-6.0642, device='cuda:0') tensor(6.1817, device='cuda:0') tensor(7.4785e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.043433
Average KL loss: 0.427620
Average total loss: 0.471053
tensor(-6.0825, device='cuda:0') tensor(6.2159, device='cuda:0') tensor(1.3570e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.041964
Average KL loss: 0.426570
Average total loss: 0.468534
tensor(-6.1004, device='cuda:0') tensor(6.2497, device='cuda:0') tensor(1.7597e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.036553
Average KL loss: 0.425480
Average total loss: 0.462033
tensor(-6.1180, device='cuda:0') tensor(6.2820, device='cuda:0') tensor(1.5428e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.035931
Average KL loss: 0.424331
Average total loss: 0.460262
tensor(-6.1353, device='cuda:0') tensor(6.3137, device='cuda:0') tensor(1.7284e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.036249
Average KL loss: 0.423190
Average total loss: 0.459439
tensor(-6.1522, device='cuda:0') tensor(6.3449, device='cuda:0') tensor(1.6569e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.034580
Average KL loss: 0.422055
Average total loss: 0.456635
tensor(-6.1689, device='cuda:0') tensor(6.3753, device='cuda:0') tensor(9.5560e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.036308
Average KL loss: 0.420918
Average total loss: 0.457226
tensor(-6.1852, device='cuda:0') tensor(6.4051, device='cuda:0') tensor(1.3866e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.039680
Average KL loss: 0.419796
Average total loss: 0.459476
tensor(-6.2013, device='cuda:0') tensor(6.4345, device='cuda:0') tensor(1.6929e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.036119
Average KL loss: 0.418720
Average total loss: 0.454840
tensor(-6.2171, device='cuda:0') tensor(6.4634, device='cuda:0') tensor(1.3413e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.037034
Average KL loss: 0.417647
Average total loss: 0.454681
tensor(-6.2326, device='cuda:0') tensor(6.4918, device='cuda:0') tensor(1.3904e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.036850
Average KL loss: 0.416570
Average total loss: 0.453420
tensor(-6.2478, device='cuda:0') tensor(6.5194, device='cuda:0') tensor(1.5019e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.036416
Average KL loss: 0.415506
Average total loss: 0.451922
tensor(-6.2629, device='cuda:0') tensor(6.5466, device='cuda:0') tensor(1.3379e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.036860
Average KL loss: 0.414461
Average total loss: 0.451321
tensor(-6.2776, device='cuda:0') tensor(6.5735, device='cuda:0') tensor(1.6707e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.036078
Average KL loss: 0.413427
Average total loss: 0.449504
tensor(-6.2922, device='cuda:0') tensor(6.5997, device='cuda:0') tensor(1.5377e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.034282
Average KL loss: 0.412355
Average total loss: 0.446637
tensor(-6.3065, device='cuda:0') tensor(6.6254, device='cuda:0') tensor(1.5233e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.033072
Average KL loss: 0.411302
Average total loss: 0.444374
tensor(-6.3206, device='cuda:0') tensor(6.6504, device='cuda:0') tensor(1.5678e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.034464
Average KL loss: 0.410247
Average total loss: 0.444711
tensor(-6.3346, device='cuda:0') tensor(6.6752, device='cuda:0') tensor(1.7406e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.034065
Average KL loss: 0.409218
Average total loss: 0.443283
tensor(-6.3483, device='cuda:0') tensor(6.6994, device='cuda:0') tensor(1.4607e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.033134
Average KL loss: 0.408178
Average total loss: 0.441313
tensor(-6.3618, device='cuda:0') tensor(6.7232, device='cuda:0') tensor(1.8043e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.033987
Average KL loss: 0.407135
Average total loss: 0.441122
tensor(-6.3751, device='cuda:0') tensor(6.7465, device='cuda:0') tensor(1.2329e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.033565
Average KL loss: 0.406127
Average total loss: 0.439692
tensor(-6.3883, device='cuda:0') tensor(6.7695, device='cuda:0') tensor(8.6461e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.032617
Average KL loss: 0.405092
Average total loss: 0.437708
tensor(-6.4013, device='cuda:0') tensor(6.7919, device='cuda:0') tensor(1.4890e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.035025
Average KL loss: 0.404086
Average total loss: 0.439110
tensor(-6.4141, device='cuda:0') tensor(6.8143, device='cuda:0') tensor(1.4970e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.031027
Average KL loss: 0.403083
Average total loss: 0.434110
tensor(-6.4268, device='cuda:0') tensor(6.8359, device='cuda:0') tensor(1.6499e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.032839
Average KL loss: 0.402036
Average total loss: 0.434875
tensor(-6.4393, device='cuda:0') tensor(6.8571, device='cuda:0') tensor(1.7703e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.031798
Average KL loss: 0.401010
Average total loss: 0.432808
tensor(-6.4517, device='cuda:0') tensor(6.8778, device='cuda:0') tensor(1.4748e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.032318
Average KL loss: 0.399984
Average total loss: 0.432302
tensor(-6.4638, device='cuda:0') tensor(6.8984, device='cuda:0') tensor(1.6130e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.030031
Average KL loss: 0.398984
Average total loss: 0.429016
tensor(-6.4759, device='cuda:0') tensor(6.9185, device='cuda:0') tensor(9.9034e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.033804
Average KL loss: 0.397984
Average total loss: 0.431788
tensor(-6.4878, device='cuda:0') tensor(6.9385, device='cuda:0') tensor(1.6483e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.033829
Average KL loss: 0.397011
Average total loss: 0.430840
tensor(-6.4996, device='cuda:0') tensor(6.9580, device='cuda:0') tensor(1.1823e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.031152
Average KL loss: 0.396034
Average total loss: 0.427186
tensor(-6.5112, device='cuda:0') tensor(6.9771, device='cuda:0') tensor(1.6624e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.030844
Average KL loss: 0.395038
Average total loss: 0.425882
tensor(-6.5227, device='cuda:0') tensor(6.9959, device='cuda:0') tensor(1.4740e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.031069
Average KL loss: 0.394061
Average total loss: 0.425130
tensor(-6.5341, device='cuda:0') tensor(7.0144, device='cuda:0') tensor(1.2268e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.029740
Average KL loss: 0.393076
Average total loss: 0.422817
tensor(-6.5453, device='cuda:0') tensor(7.0326, device='cuda:0') tensor(1.0787e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.030761
Average KL loss: 0.392094
Average total loss: 0.422855
tensor(-6.5564, device='cuda:0') tensor(7.0505, device='cuda:0') tensor(1.2931e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.029935
Average KL loss: 0.391132
Average total loss: 0.421067
tensor(-6.5675, device='cuda:0') tensor(7.0679, device='cuda:0') tensor(1.0606e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.031657
Average KL loss: 0.390175
Average total loss: 0.421832
tensor(-6.5783, device='cuda:0') tensor(7.0855, device='cuda:0') tensor(1.0667e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.031919
Average KL loss: 0.389262
Average total loss: 0.421181
tensor(-6.5891, device='cuda:0') tensor(7.1028, device='cuda:0') tensor(1.3899e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.031362
Average KL loss: 0.388341
Average total loss: 0.419702
tensor(-6.5997, device='cuda:0') tensor(7.1196, device='cuda:0') tensor(1.3585e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.030336
Average KL loss: 0.387402
Average total loss: 0.417738
tensor(-6.6103, device='cuda:0') tensor(7.1361, device='cuda:0') tensor(1.4698e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.029786
Average KL loss: 0.386466
Average total loss: 0.416252
tensor(-6.6208, device='cuda:0') tensor(7.1522, device='cuda:0') tensor(1.6231e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.029179
Average KL loss: 0.385520
Average total loss: 0.414699
tensor(-6.6311, device='cuda:0') tensor(7.1681, device='cuda:0') tensor(1.4585e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.031009
Average KL loss: 0.384585
Average total loss: 0.415594
tensor(-6.6413, device='cuda:0') tensor(7.1839, device='cuda:0') tensor(1.5592e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.029266
Average KL loss: 0.383679
Average total loss: 0.412945
tensor(-6.6515, device='cuda:0') tensor(7.1994, device='cuda:0') tensor(1.5777e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.027099
Average KL loss: 0.382743
Average total loss: 0.409842
tensor(-6.6615, device='cuda:0') tensor(7.2143, device='cuda:0') tensor(1.3021e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.028643
Average KL loss: 0.381770
Average total loss: 0.410413
tensor(-6.6715, device='cuda:0') tensor(7.2289, device='cuda:0') tensor(1.4872e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.027103
Average KL loss: 0.380806
Average total loss: 0.407909
tensor(-6.6814, device='cuda:0') tensor(7.2432, device='cuda:0') tensor(1.1640e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.029056
Average KL loss: 0.379842
Average total loss: 0.408898
tensor(-6.6912, device='cuda:0') tensor(7.2574, device='cuda:0') tensor(1.1320e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.027569
Average KL loss: 0.378907
Average total loss: 0.406476
tensor(-6.7009, device='cuda:0') tensor(7.2714, device='cuda:0') tensor(1.4168e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.028491
Average KL loss: 0.377987
Average total loss: 0.406478
tensor(-6.7105, device='cuda:0') tensor(7.2854, device='cuda:0') tensor(1.2725e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.027942
Average KL loss: 0.377085
Average total loss: 0.405028
tensor(-6.7200, device='cuda:0') tensor(7.2990, device='cuda:0') tensor(1.3975e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.029848
Average KL loss: 0.376165
Average total loss: 0.406013
tensor(-6.7294, device='cuda:0') tensor(7.3126, device='cuda:0') tensor(1.3692e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.028550
Average KL loss: 0.375282
Average total loss: 0.403833
tensor(-6.7388, device='cuda:0') tensor(7.3259, device='cuda:0') tensor(1.1205e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.028275
Average KL loss: 0.374419
Average total loss: 0.402694
tensor(-6.7480, device='cuda:0') tensor(7.3392, device='cuda:0') tensor(1.0105e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.027407
Average KL loss: 0.373528
Average total loss: 0.400935
tensor(-6.7572, device='cuda:0') tensor(7.3518, device='cuda:0') tensor(1.4707e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.026678
Average KL loss: 0.372613
Average total loss: 0.399291
tensor(-6.7663, device='cuda:0') tensor(7.3644, device='cuda:0') tensor(1.3717e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.026481
Average KL loss: 0.371693
Average total loss: 0.398175
tensor(-6.7754, device='cuda:0') tensor(7.3766, device='cuda:0') tensor(1.4227e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.030254
Average KL loss: 0.370812
Average total loss: 0.401066
tensor(-6.7843, device='cuda:0') tensor(7.3891, device='cuda:0') tensor(1.3697e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.028391
Average KL loss: 0.370000
Average total loss: 0.398390
tensor(-6.7932, device='cuda:0') tensor(7.4013, device='cuda:0') tensor(1.2517e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.029810
Average KL loss: 0.369145
Average total loss: 0.398955
tensor(-6.8020, device='cuda:0') tensor(7.4134, device='cuda:0') tensor(1.4196e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.026605
Average KL loss: 0.368333
Average total loss: 0.394938
tensor(-6.8107, device='cuda:0') tensor(7.4252, device='cuda:0') tensor(1.4568e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.025303
Average KL loss: 0.367437
Average total loss: 0.392740
tensor(-6.8194, device='cuda:0') tensor(7.4363, device='cuda:0') tensor(1.2892e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.026426
Average KL loss: 0.366521
Average total loss: 0.392947
tensor(-6.8281, device='cuda:0') tensor(7.4474, device='cuda:0') tensor(1.0544e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.026357
Average KL loss: 0.365645
Average total loss: 0.392003
tensor(-6.8366, device='cuda:0') tensor(7.4584, device='cuda:0') tensor(1.3745e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.026241
Average KL loss: 0.364792
Average total loss: 0.391033
tensor(-6.8451, device='cuda:0') tensor(7.4693, device='cuda:0') tensor(9.7212e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.028082
Average KL loss: 0.363920
Average total loss: 0.392003
tensor(-6.8535, device='cuda:0') tensor(7.4801, device='cuda:0') tensor(1.2778e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.027822
Average KL loss: 0.363089
Average total loss: 0.390910
tensor(-6.8618, device='cuda:0') tensor(7.4907, device='cuda:0') tensor(1.1323e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.026631
Average KL loss: 0.362263
Average total loss: 0.388894
tensor(-6.8701, device='cuda:0') tensor(7.5012, device='cuda:0') tensor(1.3518e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.025733
Average KL loss: 0.361407
Average total loss: 0.387140
tensor(-6.8784, device='cuda:0') tensor(7.5113, device='cuda:0') tensor(1.4559e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.025498
Average KL loss: 0.360562
Average total loss: 0.386059
tensor(-6.8865, device='cuda:0') tensor(7.5215, device='cuda:0') tensor(1.2629e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.026735
Average KL loss: 0.359725
Average total loss: 0.386460
tensor(-6.8946, device='cuda:0') tensor(7.5314, device='cuda:0') tensor(1.3348e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.028724
Average KL loss: 0.358915
Average total loss: 0.387640
tensor(-6.9027, device='cuda:0') tensor(7.5417, device='cuda:0') tensor(1.2838e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.025945
Average KL loss: 0.358144
Average total loss: 0.384089
tensor(-6.9106, device='cuda:0') tensor(7.5514, device='cuda:0') tensor(1.4760e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.025795
Average KL loss: 0.357325
Average total loss: 0.383120
tensor(-6.9186, device='cuda:0') tensor(7.5610, device='cuda:0') tensor(9.3991e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.025902
Average KL loss: 0.356522
Average total loss: 0.382424
tensor(-6.9264, device='cuda:0') tensor(7.5705, device='cuda:0') tensor(1.1924e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.026872
Average KL loss: 0.355727
Average total loss: 0.382599
tensor(-6.9342, device='cuda:0') tensor(7.5799, device='cuda:0') tensor(1.0589e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.027184
Average KL loss: 0.354952
Average total loss: 0.382136
tensor(-6.9420, device='cuda:0') tensor(7.5892, device='cuda:0') tensor(1.3567e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.025913
Average KL loss: 0.354157
Average total loss: 0.380070
tensor(-6.9497, device='cuda:0') tensor(7.5984, device='cuda:0') tensor(1.1581e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.026231
Average KL loss: 0.353373
Average total loss: 0.379604
tensor(-6.9573, device='cuda:0') tensor(7.6073, device='cuda:0') tensor(1.3187e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.027085
Average KL loss: 0.352609
Average total loss: 0.379694
tensor(-6.9649, device='cuda:0') tensor(7.6162, device='cuda:0') tensor(1.3701e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.025422
Average KL loss: 0.351829
Average total loss: 0.377251
tensor(-6.9724, device='cuda:0') tensor(7.6248, device='cuda:0') tensor(1.5558e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.027037
Average KL loss: 0.351049
Average total loss: 0.378086
tensor(-6.9800, device='cuda:0') tensor(7.6334, device='cuda:0') tensor(1.0856e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.024432
Average KL loss: 0.350272
Average total loss: 0.374704
tensor(-6.9874, device='cuda:0') tensor(7.6416, device='cuda:0') tensor(1.3893e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.024748
Average KL loss: 0.349489
Average total loss: 0.374238
tensor(-6.9948, device='cuda:0') tensor(7.6499, device='cuda:0') tensor(1.4685e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.024736
Average KL loss: 0.348698
Average total loss: 0.373435
tensor(-7.0022, device='cuda:0') tensor(7.6579, device='cuda:0') tensor(9.4849e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.024903
Average KL loss: 0.347939
Average total loss: 0.372842
tensor(-7.0095, device='cuda:0') tensor(7.6659, device='cuda:0') tensor(1.4727e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.024787
Average KL loss: 0.347147
Average total loss: 0.371934
tensor(-7.0167, device='cuda:0') tensor(7.6735, device='cuda:0') tensor(1.0979e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.023274
Average KL loss: 0.346374
Average total loss: 0.369648
tensor(-7.0240, device='cuda:0') tensor(7.6812, device='cuda:0') tensor(1.1174e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.025168
Average KL loss: 0.345574
Average total loss: 0.370742
tensor(-7.0311, device='cuda:0') tensor(7.6886, device='cuda:0') tensor(1.2320e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.022883
Average KL loss: 0.344822
Average total loss: 0.367705
tensor(-7.0383, device='cuda:0') tensor(7.6961, device='cuda:0') tensor(1.3359e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.025423
Average KL loss: 0.344058
Average total loss: 0.369481
tensor(-7.0453, device='cuda:0') tensor(7.7034, device='cuda:0') tensor(1.1761e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.026323
Average KL loss: 0.343332
Average total loss: 0.369654
tensor(-7.0524, device='cuda:0') tensor(7.7110, device='cuda:0') tensor(8.9418e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.025635
Average KL loss: 0.342624
Average total loss: 0.368259
tensor(-7.0594, device='cuda:0') tensor(7.7182, device='cuda:0') tensor(1.2015e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.024266
Average KL loss: 0.341874
Average total loss: 0.366140
tensor(-7.0663, device='cuda:0') tensor(7.7252, device='cuda:0') tensor(1.2782e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.023691
Average KL loss: 0.341122
Average total loss: 0.364813
tensor(-7.0732, device='cuda:0') tensor(7.7320, device='cuda:0') tensor(9.7525e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.023594
Average KL loss: 0.340360
Average total loss: 0.363954
tensor(-7.0801, device='cuda:0') tensor(7.7386, device='cuda:0') tensor(1.4877e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.025474
Average KL loss: 0.339613
Average total loss: 0.365088
tensor(-7.0870, device='cuda:0') tensor(7.7455, device='cuda:0') tensor(1.1245e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.022782
Average KL loss: 0.338916
Average total loss: 0.361698
tensor(-7.0938, device='cuda:0') tensor(7.7520, device='cuda:0') tensor(1.2785e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.023996
Average KL loss: 0.338149
Average total loss: 0.362145
tensor(-7.1005, device='cuda:0') tensor(7.7581, device='cuda:0') tensor(1.2622e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.024848
Average KL loss: 0.337388
Average total loss: 0.362236
tensor(-7.1073, device='cuda:0') tensor(7.7646, device='cuda:0') tensor(1.3540e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.024265
Average KL loss: 0.336687
Average total loss: 0.360952
tensor(-7.1139, device='cuda:0') tensor(7.7710, device='cuda:0') tensor(1.3211e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.023701
Average KL loss: 0.335970
Average total loss: 0.359671
tensor(-7.1206, device='cuda:0') tensor(7.7771, device='cuda:0') tensor(1.0388e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.022486
Average KL loss: 0.335250
Average total loss: 0.357736
tensor(-7.1272, device='cuda:0') tensor(7.7832, device='cuda:0') tensor(1.5326e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.023109
Average KL loss: 0.334519
Average total loss: 0.357627
tensor(-7.1337, device='cuda:0') tensor(7.7892, device='cuda:0') tensor(1.3018e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.024782
Average KL loss: 0.333831
Average total loss: 0.358613
tensor(-7.1402, device='cuda:0') tensor(7.7953, device='cuda:0') tensor(1.0490e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.024602
Average KL loss: 0.333143
Average total loss: 0.357745
tensor(-7.1467, device='cuda:0') tensor(7.8012, device='cuda:0') tensor(1.4290e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.022899
Average KL loss: 0.332444
Average total loss: 0.355344
tensor(-7.1532, device='cuda:0') tensor(7.8071, device='cuda:0') tensor(1.2732e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.024923
Average KL loss: 0.331760
Average total loss: 0.356683
tensor(-7.1596, device='cuda:0') tensor(7.8129, device='cuda:0') tensor(1.1770e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.023930
Average KL loss: 0.331087
Average total loss: 0.355017
tensor(-7.1660, device='cuda:0') tensor(7.8186, device='cuda:0') tensor(1.1801e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.023777
Average KL loss: 0.330395
Average total loss: 0.354172
tensor(-7.1723, device='cuda:0') tensor(7.8243, device='cuda:0') tensor(9.3701e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.023269
Average KL loss: 0.329710
Average total loss: 0.352979
tensor(-7.1786, device='cuda:0') tensor(7.8297, device='cuda:0') tensor(1.0348e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.025057
Average KL loss: 0.329039
Average total loss: 0.354096
tensor(-7.1849, device='cuda:0') tensor(7.8352, device='cuda:0') tensor(1.1048e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.023648
Average KL loss: 0.328378
Average total loss: 0.352027
tensor(-7.1911, device='cuda:0') tensor(7.8407, device='cuda:0') tensor(5.9452e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.023507
Average KL loss: 0.327758
Average total loss: 0.351266
tensor(-7.1973, device='cuda:0') tensor(7.8462, device='cuda:0') tensor(7.4901e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.024328
Average KL loss: 0.327110
Average total loss: 0.351438
tensor(-7.2034, device='cuda:0') tensor(7.8516, device='cuda:0') tensor(1.0355e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.022804
Average KL loss: 0.326461
Average total loss: 0.349266
tensor(-7.2096, device='cuda:0') tensor(7.8566, device='cuda:0') tensor(1.1829e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.020598
Average KL loss: 0.325783
Average total loss: 0.346381
tensor(-7.2157, device='cuda:0') tensor(7.8614, device='cuda:0') tensor(1.3209e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.023288
Average KL loss: 0.325060
Average total loss: 0.348348
tensor(-7.2218, device='cuda:0') tensor(7.8661, device='cuda:0') tensor(1.3063e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.023723
Average KL loss: 0.324415
Average total loss: 0.348138
tensor(-7.2278, device='cuda:0') tensor(7.8713, device='cuda:0') tensor(1.2949e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.023452
Average KL loss: 0.323788
Average total loss: 0.347241
tensor(-7.2339, device='cuda:0') tensor(7.8762, device='cuda:0') tensor(7.6681e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.024064
Average KL loss: 0.323153
Average total loss: 0.347216
tensor(-7.2398, device='cuda:0') tensor(7.8811, device='cuda:0') tensor(1.3017e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.021614
Average KL loss: 0.322531
Average total loss: 0.344145
tensor(-7.2458, device='cuda:0') tensor(7.8857, device='cuda:0') tensor(9.9456e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.024657
Average KL loss: 0.321873
Average total loss: 0.346531
tensor(-7.2517, device='cuda:0') tensor(7.8905, device='cuda:0') tensor(1.2779e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.022425
Average KL loss: 0.321255
Average total loss: 0.343680
tensor(-7.2576, device='cuda:0') tensor(7.8951, device='cuda:0') tensor(8.2166e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.023227
Average KL loss: 0.320634
Average total loss: 0.343860
tensor(-7.2634, device='cuda:0') tensor(7.8998, device='cuda:0') tensor(1.1195e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.023290
Average KL loss: 0.320023
Average total loss: 0.343313
tensor(-7.2693, device='cuda:0') tensor(7.9042, device='cuda:0') tensor(1.2342e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.021969
Average KL loss: 0.319372
Average total loss: 0.341341
tensor(-7.2751, device='cuda:0') tensor(7.9084, device='cuda:0') tensor(1.0336e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.023247
Average KL loss: 0.318725
Average total loss: 0.341972
tensor(-7.2809, device='cuda:0') tensor(7.9127, device='cuda:0') tensor(1.2683e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.022261
Average KL loss: 0.318096
Average total loss: 0.340356
tensor(-7.2866, device='cuda:0') tensor(7.9169, device='cuda:0') tensor(1.1347e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.023465
Average KL loss: 0.317477
Average total loss: 0.340942
tensor(-7.2923, device='cuda:0') tensor(7.9211, device='cuda:0') tensor(9.5359e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.022657
Average KL loss: 0.316878
Average total loss: 0.339535
tensor(-7.2980, device='cuda:0') tensor(7.9254, device='cuda:0') tensor(1.4016e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.022398
Average KL loss: 0.316264
Average total loss: 0.338663
tensor(-7.3037, device='cuda:0') tensor(7.9295, device='cuda:0') tensor(1.0469e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.021582
Average KL loss: 0.315652
Average total loss: 0.337234
tensor(-7.3093, device='cuda:0') tensor(7.9333, device='cuda:0') tensor(1.1877e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.021596
Average KL loss: 0.315016
Average total loss: 0.336612
tensor(-7.3149, device='cuda:0') tensor(7.9371, device='cuda:0') tensor(1.0194e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.021652
Average KL loss: 0.314398
Average total loss: 0.336050
tensor(-7.3205, device='cuda:0') tensor(7.9409, device='cuda:0') tensor(1.2368e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.021058
Average KL loss: 0.313758
Average total loss: 0.334816
tensor(-7.3261, device='cuda:0') tensor(7.9444, device='cuda:0') tensor(1.1552e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.022112
Average KL loss: 0.313145
Average total loss: 0.335257
tensor(-7.3316, device='cuda:0') tensor(7.9481, device='cuda:0') tensor(8.4224e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.020892
Average KL loss: 0.312565
Average total loss: 0.333457
tensor(-7.3372, device='cuda:0') tensor(7.9519, device='cuda:0') tensor(1.2824e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.023533
Average KL loss: 0.311968
Average total loss: 0.335501
tensor(-7.3426, device='cuda:0') tensor(7.9556, device='cuda:0') tensor(1.0027e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.021871
Average KL loss: 0.311383
Average total loss: 0.333254
tensor(-7.3481, device='cuda:0') tensor(7.9591, device='cuda:0') tensor(1.1477e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.022622
Average KL loss: 0.310792
Average total loss: 0.333414
tensor(-7.3535, device='cuda:0') tensor(7.9628, device='cuda:0') tensor(1.3663e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.022370
Average KL loss: 0.310211
Average total loss: 0.332582
tensor(-7.3589, device='cuda:0') tensor(7.9663, device='cuda:0') tensor(9.6849e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.022306
Average KL loss: 0.309644
Average total loss: 0.331951
tensor(-7.3643, device='cuda:0') tensor(7.9701, device='cuda:0') tensor(1.2027e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.022257
Average KL loss: 0.309078
Average total loss: 0.331335
tensor(-7.3697, device='cuda:0') tensor(7.9735, device='cuda:0') tensor(1.0484e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.022829
Average KL loss: 0.308487
Average total loss: 0.331315
tensor(-7.3750, device='cuda:0') tensor(7.9767, device='cuda:0') tensor(8.8848e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.022360
Average KL loss: 0.307926
Average total loss: 0.330287
tensor(-7.3803, device='cuda:0') tensor(7.9801, device='cuda:0') tensor(8.2699e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.020624
Average KL loss: 0.307338
Average total loss: 0.327962
tensor(-7.3856, device='cuda:0') tensor(7.9829, device='cuda:0') tensor(9.8152e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.022304
Average KL loss: 0.306742
Average total loss: 0.329046
tensor(-7.3909, device='cuda:0') tensor(7.9861, device='cuda:0') tensor(1.1694e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.023190
Average KL loss: 0.306200
Average total loss: 0.329390
tensor(-7.3961, device='cuda:0') tensor(7.9896, device='cuda:0') tensor(1.0393e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.020724
Average KL loss: 0.305658
Average total loss: 0.326382
tensor(-7.4014, device='cuda:0') tensor(7.9926, device='cuda:0') tensor(8.3567e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.021466
Average KL loss: 0.305086
Average total loss: 0.326552
tensor(-7.4065, device='cuda:0') tensor(7.9957, device='cuda:0') tensor(9.2813e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.021356
Average KL loss: 0.304510
Average total loss: 0.325866
tensor(-7.4117, device='cuda:0') tensor(7.9985, device='cuda:0') tensor(9.0485e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.021937
Average KL loss: 0.303956
Average total loss: 0.325892
tensor(-7.4169, device='cuda:0') tensor(8.0017, device='cuda:0') tensor(6.8425e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.021810
Average KL loss: 0.303421
Average total loss: 0.325231
tensor(-7.4220, device='cuda:0') tensor(8.0047, device='cuda:0') tensor(1.1173e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.021157
Average KL loss: 0.302864
Average total loss: 0.324022
tensor(-7.4271, device='cuda:0') tensor(8.0075, device='cuda:0') tensor(1.1717e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.020749
Average KL loss: 0.302297
Average total loss: 0.323046
tensor(-7.4322, device='cuda:0') tensor(8.0101, device='cuda:0') tensor(1.1023e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.020621
Average KL loss: 0.301740
Average total loss: 0.322361
tensor(-7.4373, device='cuda:0') tensor(8.0128, device='cuda:0') tensor(9.2784e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.020717
Average KL loss: 0.301194
Average total loss: 0.321911
tensor(-7.4424, device='cuda:0') tensor(8.0155, device='cuda:0') tensor(1.3211e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.022646
Average KL loss: 0.300627
Average total loss: 0.323273
tensor(-7.4474, device='cuda:0') tensor(8.0181, device='cuda:0') tensor(1.3031e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.021151
Average KL loss: 0.300100
Average total loss: 0.321251
tensor(-7.4524, device='cuda:0') tensor(8.0209, device='cuda:0') tensor(1.2421e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.020446
Average KL loss: 0.299559
Average total loss: 0.320004
tensor(-7.4574, device='cuda:0') tensor(8.0235, device='cuda:0') tensor(1.0917e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.020507
Average KL loss: 0.299037
Average total loss: 0.319543
tensor(-7.4623, device='cuda:0') tensor(8.0261, device='cuda:0') tensor(9.4737e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.020208
Average KL loss: 0.298490
Average total loss: 0.318698
tensor(-7.4673, device='cuda:0') tensor(8.0284, device='cuda:0') tensor(1.0507e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.021562
Average KL loss: 0.297943
Average total loss: 0.319505
tensor(-7.4722, device='cuda:0') tensor(8.0309, device='cuda:0') tensor(1.0797e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.022005
Average KL loss: 0.297413
Average total loss: 0.319417
tensor(-7.4771, device='cuda:0') tensor(8.0334, device='cuda:0') tensor(1.0417e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.020859
Average KL loss: 0.296892
Average total loss: 0.317751
 Percentile value: -1.0879530906677246
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =    1494 /    1728             ( 86.46%) | total_pruned =     234 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   14471 /   36864             ( 39.26%) | total_pruned =   22393 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   15120 /   36864             ( 41.02%) | total_pruned =   21744 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   13903 /   36864             ( 37.71%) | total_pruned =   22961 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   13647 /   36864             ( 37.02%) | total_pruned =   23217 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   25136 /   73728             ( 34.09%) | total_pruned =   48592 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   43104 /  147456             ( 29.23%) | total_pruned =  104352 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5794 /    8192             ( 70.73%) | total_pruned =    2398 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   31942 /  147456             ( 21.66%) | total_pruned =  115514 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   32351 /  147456             ( 21.94%) | total_pruned =  115105 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   78219 /  294912             ( 26.52%) | total_pruned =  216693 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  125784 /  589824             ( 21.33%) | total_pruned =  464040 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18365 /   32768             ( 56.05%) | total_pruned =   14403 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   67170 /  589824             ( 11.39%) | total_pruned =  522654 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   66249 /  589824             ( 11.23%) | total_pruned =  523575 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  179586 / 1179648             ( 15.22%) | total_pruned = 1000062 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  139727 / 2359296             (  5.92%) | total_pruned = 2219569 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     494 /     512             ( 96.48%) | total_pruned =      18 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   35210 /  131072             ( 26.86%) | total_pruned =   95862 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   59438 / 2359296             (  2.52%) | total_pruned = 2299858 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     412 /     512             ( 80.47%) | total_pruned =     100 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     225 /     512             ( 43.95%) | total_pruned =     287 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   26090 / 2359296             (  1.11%) | total_pruned = 2333206 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     318 /     512             ( 62.11%) | total_pruned =     194 | shape = torch.Size([512])
linear.weight        | nonzeros =    4556 /    5120             ( 88.98%) | total_pruned =     564 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 22/200 Loss: 0.000251 Accuracy: 86.57 100.00 % Best test Accuracy: 87.20%
tensor(-7.4820, device='cuda:0') tensor(8.0357, device='cuda:0') tensor(-9.4575e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.084138
Average KL loss: 0.287704
Average total loss: 0.371842
tensor(-7.5427, device='cuda:0') tensor(7.6408, device='cuda:0') tensor(-5.3382e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.069252
Average KL loss: 0.277457
Average total loss: 0.346709
tensor(-7.5924, device='cuda:0') tensor(7.3539, device='cuda:0') tensor(2.9607e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.062622
Average KL loss: 0.271151
Average total loss: 0.333773
tensor(-7.6352, device='cuda:0') tensor(7.1270, device='cuda:0') tensor(3.3240e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.059972
Average KL loss: 0.266886
Average total loss: 0.326858
tensor(-7.6729, device='cuda:0') tensor(6.9422, device='cuda:0') tensor(2.0657e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.057462
Average KL loss: 0.263865
Average total loss: 0.321327
tensor(-7.7065, device='cuda:0') tensor(6.7886, device='cuda:0') tensor(1.5177e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.051734
Average KL loss: 0.261605
Average total loss: 0.313338
tensor(-7.7370, device='cuda:0') tensor(6.6584, device='cuda:0') tensor(9.1031e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.051622
Average KL loss: 0.259871
Average total loss: 0.311493
tensor(-7.7649, device='cuda:0') tensor(6.5467, device='cuda:0') tensor(4.9725e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.049716
Average KL loss: 0.258485
Average total loss: 0.308201
tensor(-7.7907, device='cuda:0') tensor(6.4494, device='cuda:0') tensor(5.4088e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.048332
Average KL loss: 0.257352
Average total loss: 0.305683
tensor(-7.8147, device='cuda:0') tensor(6.3641, device='cuda:0') tensor(-5.6648e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.044506
Average KL loss: 0.256399
Average total loss: 0.300906
tensor(-7.8372, device='cuda:0') tensor(6.2885, device='cuda:0') tensor(-1.9730e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.043731
Average KL loss: 0.255587
Average total loss: 0.299317
tensor(-7.8583, device='cuda:0') tensor(6.2212, device='cuda:0') tensor(-6.1383e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.042784
Average KL loss: 0.254888
Average total loss: 0.297673
tensor(-7.8783, device='cuda:0') tensor(6.1609, device='cuda:0') tensor(4.8946e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.042010
Average KL loss: 0.254259
Average total loss: 0.296269
tensor(-7.8973, device='cuda:0') tensor(6.1063, device='cuda:0') tensor(1.3964e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.041771
Average KL loss: 0.253704
Average total loss: 0.295475
tensor(-7.9154, device='cuda:0') tensor(6.0570, device='cuda:0') tensor(1.2905e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.038000
Average KL loss: 0.253214
Average total loss: 0.291214
tensor(-7.9327, device='cuda:0') tensor(6.0122, device='cuda:0') tensor(1.8255e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.038585
Average KL loss: 0.252760
Average total loss: 0.291344
tensor(-7.9492, device='cuda:0') tensor(5.9712, device='cuda:0') tensor(2.0307e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.039242
Average KL loss: 0.252366
Average total loss: 0.291608
tensor(-7.9651, device='cuda:0') tensor(5.9339, device='cuda:0') tensor(2.3199e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.037344
Average KL loss: 0.251992
Average total loss: 0.289336
tensor(-7.9804, device='cuda:0') tensor(5.8995, device='cuda:0') tensor(-7.0063e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.037621
Average KL loss: 0.251628
Average total loss: 0.289249
tensor(-7.9952, device='cuda:0') tensor(5.8677, device='cuda:0') tensor(3.0954e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.034125
Average KL loss: 0.251287
Average total loss: 0.285412
tensor(-8.0094, device='cuda:0') tensor(5.8383, device='cuda:0') tensor(4.1412e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.035764
Average KL loss: 0.250962
Average total loss: 0.286725
tensor(-8.0232, device='cuda:0') tensor(5.8111, device='cuda:0') tensor(7.9119e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.035557
Average KL loss: 0.250659
Average total loss: 0.286216
tensor(-8.0366, device='cuda:0') tensor(5.7859, device='cuda:0') tensor(5.1710e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.036383
Average KL loss: 0.250378
Average total loss: 0.286761
tensor(-8.0496, device='cuda:0') tensor(5.7626, device='cuda:0') tensor(2.8647e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.033680
Average KL loss: 0.250103
Average total loss: 0.283782
tensor(-8.0622, device='cuda:0') tensor(5.7408, device='cuda:0') tensor(2.5203e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.033240
Average KL loss: 0.249828
Average total loss: 0.283067
tensor(-8.0745, device='cuda:0') tensor(5.7204, device='cuda:0') tensor(-3.3391e-11, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.032238
Average KL loss: 0.249558
Average total loss: 0.281796
tensor(-8.0865, device='cuda:0') tensor(5.7013, device='cuda:0') tensor(5.5304e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.031728
Average KL loss: 0.249278
Average total loss: 0.281007
tensor(-8.0982, device='cuda:0') tensor(5.6834, device='cuda:0') tensor(-1.9059e-11, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.031776
Average KL loss: 0.249021
Average total loss: 0.280797
tensor(-8.1096, device='cuda:0') tensor(5.6669, device='cuda:0') tensor(1.1973e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.030757
Average KL loss: 0.248773
Average total loss: 0.279530
tensor(-8.1207, device='cuda:0') tensor(5.6511, device='cuda:0') tensor(3.2141e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.030915
Average KL loss: 0.248512
Average total loss: 0.279427
tensor(-8.1316, device='cuda:0') tensor(5.6365, device='cuda:0') tensor(5.9605e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.029912
Average KL loss: 0.248253
Average total loss: 0.278166
tensor(-8.1423, device='cuda:0') tensor(5.6224, device='cuda:0') tensor(4.4397e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.030001
Average KL loss: 0.248008
Average total loss: 0.278009
tensor(-8.1528, device='cuda:0') tensor(5.6094, device='cuda:0') tensor(3.8139e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.027771
Average KL loss: 0.247759
Average total loss: 0.275530
tensor(-8.1630, device='cuda:0') tensor(5.5970, device='cuda:0') tensor(4.4063e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.028656
Average KL loss: 0.247501
Average total loss: 0.276157
tensor(-8.1730, device='cuda:0') tensor(5.5853, device='cuda:0') tensor(4.7685e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.029949
Average KL loss: 0.247267
Average total loss: 0.277216
tensor(-8.1829, device='cuda:0') tensor(5.5745, device='cuda:0') tensor(5.4488e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.029417
Average KL loss: 0.247033
Average total loss: 0.276449
tensor(-8.1925, device='cuda:0') tensor(5.5642, device='cuda:0') tensor(4.9491e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.028925
Average KL loss: 0.246804
Average total loss: 0.275729
tensor(-8.2020, device='cuda:0') tensor(5.5545, device='cuda:0') tensor(5.6945e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.028437
Average KL loss: 0.246562
Average total loss: 0.274998
tensor(-8.2114, device='cuda:0') tensor(5.5451, device='cuda:0') tensor(7.5641e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.026732
Average KL loss: 0.246311
Average total loss: 0.273043
tensor(-8.2206, device='cuda:0') tensor(5.5363, device='cuda:0') tensor(5.7487e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.025300
Average KL loss: 0.246054
Average total loss: 0.271354
tensor(-8.2296, device='cuda:0') tensor(5.5278, device='cuda:0') tensor(6.8094e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.027243
Average KL loss: 0.245790
Average total loss: 0.273033
tensor(-8.2385, device='cuda:0') tensor(5.5198, device='cuda:0') tensor(1.8256e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.027511
Average KL loss: 0.245545
Average total loss: 0.273056
tensor(-8.2472, device='cuda:0') tensor(5.5124, device='cuda:0') tensor(2.8896e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.027723
Average KL loss: 0.245318
Average total loss: 0.273041
tensor(-8.2558, device='cuda:0') tensor(5.5055, device='cuda:0') tensor(3.7974e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.026439
Average KL loss: 0.245088
Average total loss: 0.271526
tensor(-8.2643, device='cuda:0') tensor(5.4986, device='cuda:0') tensor(5.5138e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.026497
Average KL loss: 0.244831
Average total loss: 0.271328
tensor(-8.2727, device='cuda:0') tensor(5.4922, device='cuda:0') tensor(7.4327e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.027094
Average KL loss: 0.244593
Average total loss: 0.271687
tensor(-8.2810, device='cuda:0') tensor(5.4862, device='cuda:0') tensor(4.2246e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.027065
Average KL loss: 0.244367
Average total loss: 0.271432
tensor(-8.2891, device='cuda:0') tensor(5.4805, device='cuda:0') tensor(4.9152e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.024479
Average KL loss: 0.244124
Average total loss: 0.268603
tensor(-8.2971, device='cuda:0') tensor(5.4748, device='cuda:0') tensor(4.0461e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.025579
Average KL loss: 0.243881
Average total loss: 0.269461
tensor(-8.3050, device='cuda:0') tensor(5.4696, device='cuda:0') tensor(2.3502e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.023890
Average KL loss: 0.243637
Average total loss: 0.267527
tensor(-8.3129, device='cuda:0') tensor(5.4646, device='cuda:0') tensor(-1.1344e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.026229
Average KL loss: 0.243398
Average total loss: 0.269627
tensor(-8.3206, device='cuda:0') tensor(5.4600, device='cuda:0') tensor(2.5386e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.026617
Average KL loss: 0.243170
Average total loss: 0.269787
tensor(-8.3282, device='cuda:0') tensor(5.4555, device='cuda:0') tensor(5.2938e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.024093
Average KL loss: 0.242930
Average total loss: 0.267023
tensor(-8.3358, device='cuda:0') tensor(5.4511, device='cuda:0') tensor(1.8217e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.022844
Average KL loss: 0.242676
Average total loss: 0.265520
tensor(-8.3432, device='cuda:0') tensor(5.4469, device='cuda:0') tensor(3.9264e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.024095
Average KL loss: 0.242401
Average total loss: 0.266496
tensor(-8.3506, device='cuda:0') tensor(5.4427, device='cuda:0') tensor(2.9959e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.023948
Average KL loss: 0.242137
Average total loss: 0.266085
tensor(-8.3579, device='cuda:0') tensor(5.4390, device='cuda:0') tensor(5.1767e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.022659
Average KL loss: 0.241884
Average total loss: 0.264543
tensor(-8.3651, device='cuda:0') tensor(5.4353, device='cuda:0') tensor(4.0056e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.023256
Average KL loss: 0.241625
Average total loss: 0.264881
tensor(-8.3722, device='cuda:0') tensor(5.4318, device='cuda:0') tensor(4.9353e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.020773
Average KL loss: 0.241357
Average total loss: 0.262130
tensor(-8.3792, device='cuda:0') tensor(5.4282, device='cuda:0') tensor(3.4528e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.024576
Average KL loss: 0.241072
Average total loss: 0.265648
tensor(-8.3862, device='cuda:0') tensor(5.4250, device='cuda:0') tensor(5.6283e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.023013
Average KL loss: 0.240813
Average total loss: 0.263826
tensor(-8.3931, device='cuda:0') tensor(5.4219, device='cuda:0') tensor(8.0066e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.022663
Average KL loss: 0.240536
Average total loss: 0.263199
tensor(-8.3999, device='cuda:0') tensor(5.4189, device='cuda:0') tensor(2.3091e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.022664
Average KL loss: 0.240287
Average total loss: 0.262951
tensor(-8.4067, device='cuda:0') tensor(5.4163, device='cuda:0') tensor(4.0262e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.024610
Average KL loss: 0.240041
Average total loss: 0.264651
tensor(-8.4134, device='cuda:0') tensor(5.4137, device='cuda:0') tensor(6.2143e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.023004
Average KL loss: 0.239788
Average total loss: 0.262792
tensor(-8.4200, device='cuda:0') tensor(5.4111, device='cuda:0') tensor(7.9103e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.022369
Average KL loss: 0.239532
Average total loss: 0.261901
tensor(-8.4266, device='cuda:0') tensor(5.4087, device='cuda:0') tensor(4.9788e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.022254
Average KL loss: 0.239270
Average total loss: 0.261524
tensor(-8.4331, device='cuda:0') tensor(5.4064, device='cuda:0') tensor(5.1244e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.021127
Average KL loss: 0.238997
Average total loss: 0.260125
tensor(-8.4395, device='cuda:0') tensor(5.4040, device='cuda:0') tensor(1.1548e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.022347
Average KL loss: 0.238743
Average total loss: 0.261090
tensor(-8.4459, device='cuda:0') tensor(5.4021, device='cuda:0') tensor(2.9883e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.022483
Average KL loss: 0.238514
Average total loss: 0.260997
tensor(-8.4522, device='cuda:0') tensor(5.4001, device='cuda:0') tensor(3.3070e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.021803
Average KL loss: 0.238253
Average total loss: 0.260056
tensor(-8.4585, device='cuda:0') tensor(5.3982, device='cuda:0') tensor(4.5136e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.021674
Average KL loss: 0.237995
Average total loss: 0.259668
tensor(-8.4647, device='cuda:0') tensor(5.3963, device='cuda:0') tensor(5.6960e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.021309
Average KL loss: 0.237725
Average total loss: 0.259034
tensor(-8.4709, device='cuda:0') tensor(5.3943, device='cuda:0') tensor(4.3836e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.021214
Average KL loss: 0.237449
Average total loss: 0.258662
tensor(-8.4770, device='cuda:0') tensor(5.3926, device='cuda:0') tensor(3.3318e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.020513
Average KL loss: 0.237197
Average total loss: 0.257710
tensor(-8.4830, device='cuda:0') tensor(5.3909, device='cuda:0') tensor(7.1984e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.020365
Average KL loss: 0.236929
Average total loss: 0.257294
tensor(-8.4890, device='cuda:0') tensor(5.3893, device='cuda:0') tensor(5.3716e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.020190
Average KL loss: 0.236656
Average total loss: 0.256846
tensor(-8.4950, device='cuda:0') tensor(5.3876, device='cuda:0') tensor(5.0717e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.020600
Average KL loss: 0.236380
Average total loss: 0.256979
tensor(-8.5009, device='cuda:0') tensor(5.3862, device='cuda:0') tensor(8.1351e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.021161
Average KL loss: 0.236117
Average total loss: 0.257278
tensor(-8.5067, device='cuda:0') tensor(5.3847, device='cuda:0') tensor(3.2056e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.020616
Average KL loss: 0.235852
Average total loss: 0.256468
tensor(-8.5125, device='cuda:0') tensor(5.3833, device='cuda:0') tensor(6.2905e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.021730
Average KL loss: 0.235598
Average total loss: 0.257328
tensor(-8.5183, device='cuda:0') tensor(5.3822, device='cuda:0') tensor(6.9915e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.021182
Average KL loss: 0.235333
Average total loss: 0.256515
tensor(-8.5240, device='cuda:0') tensor(5.3808, device='cuda:0') tensor(1.6022e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.022314
Average KL loss: 0.235077
Average total loss: 0.257392
tensor(-8.5297, device='cuda:0') tensor(5.3797, device='cuda:0') tensor(6.0643e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.021496
Average KL loss: 0.234823
Average total loss: 0.256319
tensor(-8.5353, device='cuda:0') tensor(5.3787, device='cuda:0') tensor(4.4826e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.020139
Average KL loss: 0.234573
Average total loss: 0.254712
tensor(-8.5409, device='cuda:0') tensor(5.3776, device='cuda:0') tensor(5.3226e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.019817
Average KL loss: 0.234300
Average total loss: 0.254117
tensor(-8.5465, device='cuda:0') tensor(5.3765, device='cuda:0') tensor(5.4773e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.021836
Average KL loss: 0.234037
Average total loss: 0.255873
tensor(-8.5520, device='cuda:0') tensor(5.3754, device='cuda:0') tensor(4.5179e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.019206
Average KL loss: 0.233768
Average total loss: 0.252973
tensor(-8.5575, device='cuda:0') tensor(5.3744, device='cuda:0') tensor(6.5604e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.020493
Average KL loss: 0.233492
Average total loss: 0.253985
tensor(-8.5629, device='cuda:0') tensor(5.3734, device='cuda:0') tensor(4.1145e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.021772
Average KL loss: 0.233236
Average total loss: 0.255008
tensor(-8.5683, device='cuda:0') tensor(5.3726, device='cuda:0') tensor(5.0093e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.019956
Average KL loss: 0.232976
Average total loss: 0.252932
tensor(-8.5736, device='cuda:0') tensor(5.3717, device='cuda:0') tensor(3.7437e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.020392
Average KL loss: 0.232727
Average total loss: 0.253119
tensor(-8.5790, device='cuda:0') tensor(5.3710, device='cuda:0') tensor(2.4082e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.019697
Average KL loss: 0.232483
Average total loss: 0.252180
tensor(-8.5842, device='cuda:0') tensor(5.3704, device='cuda:0') tensor(2.9679e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.018063
Average KL loss: 0.232221
Average total loss: 0.250283
tensor(-8.5895, device='cuda:0') tensor(5.3694, device='cuda:0') tensor(2.7184e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.020504
Average KL loss: 0.231938
Average total loss: 0.252443
tensor(-8.5947, device='cuda:0') tensor(5.3686, device='cuda:0') tensor(5.5771e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.018640
Average KL loss: 0.231662
Average total loss: 0.250303
tensor(-8.5999, device='cuda:0') tensor(5.3677, device='cuda:0') tensor(6.5406e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.019735
Average KL loss: 0.231387
Average total loss: 0.251121
tensor(-8.6050, device='cuda:0') tensor(5.3670, device='cuda:0') tensor(1.4879e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.020952
Average KL loss: 0.231136
Average total loss: 0.252088
tensor(-8.6101, device='cuda:0') tensor(5.3665, device='cuda:0') tensor(5.0900e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.019061
Average KL loss: 0.230881
Average total loss: 0.249942
tensor(-8.6152, device='cuda:0') tensor(5.3658, device='cuda:0') tensor(4.5710e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.018381
Average KL loss: 0.230613
Average total loss: 0.248993
tensor(-8.6203, device='cuda:0') tensor(5.3652, device='cuda:0') tensor(4.6566e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.018953
Average KL loss: 0.230326
Average total loss: 0.249280
tensor(-8.6253, device='cuda:0') tensor(5.3645, device='cuda:0') tensor(5.9029e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.019384
Average KL loss: 0.230064
Average total loss: 0.249448
tensor(-8.6302, device='cuda:0') tensor(5.3638, device='cuda:0') tensor(5.7920e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.017635
Average KL loss: 0.229795
Average total loss: 0.247430
tensor(-8.6352, device='cuda:0') tensor(5.3632, device='cuda:0') tensor(-5.4210e-12, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.018267
Average KL loss: 0.229513
Average total loss: 0.247780
tensor(-8.6401, device='cuda:0') tensor(5.3626, device='cuda:0') tensor(5.2747e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.019860
Average KL loss: 0.229244
Average total loss: 0.249104
tensor(-8.6450, device='cuda:0') tensor(5.3621, device='cuda:0') tensor(4.0810e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.018875
Average KL loss: 0.228988
Average total loss: 0.247864
tensor(-8.6499, device='cuda:0') tensor(5.3615, device='cuda:0') tensor(3.4406e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.018181
Average KL loss: 0.228714
Average total loss: 0.246896
tensor(-8.6547, device='cuda:0') tensor(5.3609, device='cuda:0') tensor(8.2141e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.019445
Average KL loss: 0.228449
Average total loss: 0.247894
tensor(-8.6595, device='cuda:0') tensor(5.3604, device='cuda:0') tensor(3.9031e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.019871
Average KL loss: 0.228201
Average total loss: 0.248072
tensor(-8.6643, device='cuda:0') tensor(5.3601, device='cuda:0') tensor(4.2915e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.019187
Average KL loss: 0.227948
Average total loss: 0.247134
tensor(-8.6690, device='cuda:0') tensor(5.3597, device='cuda:0') tensor(-2.7407e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.018423
Average KL loss: 0.227694
Average total loss: 0.246117
tensor(-8.6737, device='cuda:0') tensor(5.3592, device='cuda:0') tensor(3.6689e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.020044
Average KL loss: 0.227434
Average total loss: 0.247478
tensor(-8.6784, device='cuda:0') tensor(5.3589, device='cuda:0') tensor(2.3460e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.018517
Average KL loss: 0.227177
Average total loss: 0.245694
tensor(-8.6831, device='cuda:0') tensor(5.3584, device='cuda:0') tensor(6.1019e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.017762
Average KL loss: 0.226910
Average total loss: 0.244671
tensor(-8.6877, device='cuda:0') tensor(5.3581, device='cuda:0') tensor(6.3784e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.019704
Average KL loss: 0.226667
Average total loss: 0.246370
tensor(-8.6923, device='cuda:0') tensor(5.3577, device='cuda:0') tensor(5.6149e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.019537
Average KL loss: 0.226413
Average total loss: 0.245950
tensor(-8.6969, device='cuda:0') tensor(5.3575, device='cuda:0') tensor(6.4778e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.019279
Average KL loss: 0.226157
Average total loss: 0.245436
tensor(-8.7015, device='cuda:0') tensor(5.3572, device='cuda:0') tensor(4.9703e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.017947
Average KL loss: 0.225899
Average total loss: 0.243846
tensor(-8.7060, device='cuda:0') tensor(5.3568, device='cuda:0') tensor(3.6796e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.018648
Average KL loss: 0.225624
Average total loss: 0.244272
tensor(-8.7105, device='cuda:0') tensor(5.3564, device='cuda:0') tensor(5.1208e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.018962
Average KL loss: 0.225371
Average total loss: 0.244333
tensor(-8.7150, device='cuda:0') tensor(5.3562, device='cuda:0') tensor(-1.0837e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.018154
Average KL loss: 0.225121
Average total loss: 0.243275
tensor(-8.7194, device='cuda:0') tensor(5.3559, device='cuda:0') tensor(5.7642e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.017226
Average KL loss: 0.224863
Average total loss: 0.242089
tensor(-8.7239, device='cuda:0') tensor(5.3555, device='cuda:0') tensor(5.6001e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.017809
Average KL loss: 0.224591
Average total loss: 0.242399
tensor(-8.7283, device='cuda:0') tensor(5.3551, device='cuda:0') tensor(3.9585e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.019642
Average KL loss: 0.224341
Average total loss: 0.243982
tensor(-8.7327, device='cuda:0') tensor(5.3550, device='cuda:0') tensor(5.6578e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.017827
Average KL loss: 0.224103
Average total loss: 0.241930
tensor(-8.7370, device='cuda:0') tensor(5.3549, device='cuda:0') tensor(3.1254e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.018830
Average KL loss: 0.223864
Average total loss: 0.242695
tensor(-8.7414, device='cuda:0') tensor(5.3547, device='cuda:0') tensor(3.8516e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.016478
Average KL loss: 0.223607
Average total loss: 0.240085
tensor(-8.7457, device='cuda:0') tensor(5.3543, device='cuda:0') tensor(4.8837e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.016899
Average KL loss: 0.223347
Average total loss: 0.240246
tensor(-8.7500, device='cuda:0') tensor(5.3540, device='cuda:0') tensor(5.1740e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.017901
Average KL loss: 0.223084
Average total loss: 0.240986
tensor(-8.7543, device='cuda:0') tensor(5.3539, device='cuda:0') tensor(5.2700e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.017480
Average KL loss: 0.222827
Average total loss: 0.240307
tensor(-8.7585, device='cuda:0') tensor(5.3535, device='cuda:0') tensor(3.9418e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.017561
Average KL loss: 0.222569
Average total loss: 0.240131
tensor(-8.7628, device='cuda:0') tensor(5.3532, device='cuda:0') tensor(4.4777e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.016873
Average KL loss: 0.222315
Average total loss: 0.239187
tensor(-8.7670, device='cuda:0') tensor(5.3530, device='cuda:0') tensor(5.8091e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.017818
Average KL loss: 0.222055
Average total loss: 0.239873
tensor(-8.7712, device='cuda:0') tensor(5.3527, device='cuda:0') tensor(5.9518e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.018073
Average KL loss: 0.221804
Average total loss: 0.239877
tensor(-8.7754, device='cuda:0') tensor(5.3525, device='cuda:0') tensor(4.6043e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.015249
Average KL loss: 0.221554
Average total loss: 0.236803
tensor(-8.7795, device='cuda:0') tensor(5.3521, device='cuda:0') tensor(5.4171e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.018167
Average KL loss: 0.221296
Average total loss: 0.239463
tensor(-8.7837, device='cuda:0') tensor(5.3521, device='cuda:0') tensor(6.0638e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.015900
Average KL loss: 0.221056
Average total loss: 0.236956
tensor(-8.7878, device='cuda:0') tensor(5.3518, device='cuda:0') tensor(9.2196e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.017652
Average KL loss: 0.220799
Average total loss: 0.238451
tensor(-8.7919, device='cuda:0') tensor(5.3516, device='cuda:0') tensor(5.8846e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.017904
Average KL loss: 0.220552
Average total loss: 0.238456
tensor(-8.7959, device='cuda:0') tensor(5.3513, device='cuda:0') tensor(4.3735e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.016718
Average KL loss: 0.220295
Average total loss: 0.237013
tensor(-8.8000, device='cuda:0') tensor(5.3510, device='cuda:0') tensor(6.3031e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.016833
Average KL loss: 0.220038
Average total loss: 0.236871
tensor(-8.8040, device='cuda:0') tensor(5.3508, device='cuda:0') tensor(5.6847e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.016915
Average KL loss: 0.219790
Average total loss: 0.236705
tensor(-8.8081, device='cuda:0') tensor(5.3505, device='cuda:0') tensor(4.5812e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.016822
Average KL loss: 0.219524
Average total loss: 0.236345
tensor(-8.8121, device='cuda:0') tensor(5.3502, device='cuda:0') tensor(5.2974e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.016918
Average KL loss: 0.219278
Average total loss: 0.236195
tensor(-8.8161, device='cuda:0') tensor(5.3500, device='cuda:0') tensor(5.1594e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.015153
Average KL loss: 0.219005
Average total loss: 0.234158
tensor(-8.8200, device='cuda:0') tensor(5.3495, device='cuda:0') tensor(4.5624e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.018677
Average KL loss: 0.218745
Average total loss: 0.237422
tensor(-8.8240, device='cuda:0') tensor(5.3494, device='cuda:0') tensor(4.0741e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.018148
Average KL loss: 0.218529
Average total loss: 0.236678
tensor(-8.8279, device='cuda:0') tensor(5.3494, device='cuda:0') tensor(4.4292e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.017079
Average KL loss: 0.218290
Average total loss: 0.235369
tensor(-8.8318, device='cuda:0') tensor(5.3491, device='cuda:0') tensor(6.7089e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.017647
Average KL loss: 0.218047
Average total loss: 0.235694
tensor(-8.8357, device='cuda:0') tensor(5.3490, device='cuda:0') tensor(4.6922e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.016788
Average KL loss: 0.217813
Average total loss: 0.234601
tensor(-8.8396, device='cuda:0') tensor(5.3489, device='cuda:0') tensor(1.5091e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.016492
Average KL loss: 0.217562
Average total loss: 0.234054
tensor(-8.8434, device='cuda:0') tensor(5.3486, device='cuda:0') tensor(2.6461e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.016579
Average KL loss: 0.217314
Average total loss: 0.233893
tensor(-8.8473, device='cuda:0') tensor(5.3485, device='cuda:0') tensor(4.7529e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.017255
Average KL loss: 0.217082
Average total loss: 0.234337
tensor(-8.8511, device='cuda:0') tensor(5.3483, device='cuda:0') tensor(5.8610e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.016099
Average KL loss: 0.216838
Average total loss: 0.232937
tensor(-8.8549, device='cuda:0') tensor(5.3479, device='cuda:0') tensor(4.1899e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.016819
Average KL loss: 0.216591
Average total loss: 0.233410
tensor(-8.8587, device='cuda:0') tensor(5.3478, device='cuda:0') tensor(3.4109e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.015278
Average KL loss: 0.216344
Average total loss: 0.231622
tensor(-8.8625, device='cuda:0') tensor(5.3475, device='cuda:0') tensor(6.1550e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.015838
Average KL loss: 0.216081
Average total loss: 0.231919
tensor(-8.8663, device='cuda:0') tensor(5.3472, device='cuda:0') tensor(4.5433e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.016259
Average KL loss: 0.215818
Average total loss: 0.232077
tensor(-8.8700, device='cuda:0') tensor(5.3470, device='cuda:0') tensor(4.7068e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.017154
Average KL loss: 0.215580
Average total loss: 0.232734
tensor(-8.8737, device='cuda:0') tensor(5.3468, device='cuda:0') tensor(2.7944e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.017529
Average KL loss: 0.215357
Average total loss: 0.232886
tensor(-8.8774, device='cuda:0') tensor(5.3468, device='cuda:0') tensor(5.2849e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.017087
Average KL loss: 0.215124
Average total loss: 0.232211
tensor(-8.8811, device='cuda:0') tensor(5.3466, device='cuda:0') tensor(6.5931e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.014971
Average KL loss: 0.214881
Average total loss: 0.229852
tensor(-8.8848, device='cuda:0') tensor(5.3464, device='cuda:0') tensor(3.9641e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.014211
Average KL loss: 0.214633
Average total loss: 0.228845
tensor(-8.8885, device='cuda:0') tensor(5.3459, device='cuda:0') tensor(3.6604e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.017226
Average KL loss: 0.214375
Average total loss: 0.231601
tensor(-8.8921, device='cuda:0') tensor(5.3457, device='cuda:0') tensor(3.0044e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.015161
Average KL loss: 0.214127
Average total loss: 0.229287
tensor(-8.8958, device='cuda:0') tensor(5.3454, device='cuda:0') tensor(1.5067e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.016851
Average KL loss: 0.213887
Average total loss: 0.230737
tensor(-8.8994, device='cuda:0') tensor(5.3452, device='cuda:0') tensor(2.8149e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.016650
Average KL loss: 0.213651
Average total loss: 0.230301
tensor(-8.9030, device='cuda:0') tensor(5.3450, device='cuda:0') tensor(3.4748e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.015713
Average KL loss: 0.213401
Average total loss: 0.229114
tensor(-8.9066, device='cuda:0') tensor(5.3447, device='cuda:0') tensor(4.3270e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.016921
Average KL loss: 0.213174
Average total loss: 0.230095
tensor(-8.9102, device='cuda:0') tensor(5.3446, device='cuda:0') tensor(7.0398e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.016144
Average KL loss: 0.212940
Average total loss: 0.229084
tensor(-8.9138, device='cuda:0') tensor(5.3444, device='cuda:0') tensor(4.8698e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.014969
Average KL loss: 0.212712
Average total loss: 0.227682
tensor(-8.9173, device='cuda:0') tensor(5.3441, device='cuda:0') tensor(4.5447e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.014503
Average KL loss: 0.212441
Average total loss: 0.226944
tensor(-8.9209, device='cuda:0') tensor(5.3435, device='cuda:0') tensor(3.7322e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.015099
Average KL loss: 0.212180
Average total loss: 0.227279
tensor(-8.9244, device='cuda:0') tensor(5.3431, device='cuda:0') tensor(5.3608e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.017168
Average KL loss: 0.211938
Average total loss: 0.229106
tensor(-8.9279, device='cuda:0') tensor(5.3430, device='cuda:0') tensor(6.2089e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.016691
Average KL loss: 0.211710
Average total loss: 0.228400
tensor(-8.9314, device='cuda:0') tensor(5.3428, device='cuda:0') tensor(5.1948e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.015337
Average KL loss: 0.211487
Average total loss: 0.226824
tensor(-8.9349, device='cuda:0') tensor(5.3426, device='cuda:0') tensor(1.1659e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.015752
Average KL loss: 0.211258
Average total loss: 0.227010
tensor(-8.9384, device='cuda:0') tensor(5.3424, device='cuda:0') tensor(2.4631e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.016495
Average KL loss: 0.211019
Average total loss: 0.227515
tensor(-8.9419, device='cuda:0') tensor(5.3421, device='cuda:0') tensor(3.3663e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.016302
Average KL loss: 0.210789
Average total loss: 0.227091
tensor(-8.9453, device='cuda:0') tensor(5.3419, device='cuda:0') tensor(3.8050e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.016024
Average KL loss: 0.210562
Average total loss: 0.226586
tensor(-8.9487, device='cuda:0') tensor(5.3416, device='cuda:0') tensor(6.2562e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.015380
Average KL loss: 0.210321
Average total loss: 0.225701
tensor(-8.9522, device='cuda:0') tensor(5.3413, device='cuda:0') tensor(4.3703e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.015495
Average KL loss: 0.210092
Average total loss: 0.225587
tensor(-8.9556, device='cuda:0') tensor(5.3410, device='cuda:0') tensor(3.4324e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.015790
Average KL loss: 0.209857
Average total loss: 0.225647
tensor(-8.9590, device='cuda:0') tensor(5.3408, device='cuda:0') tensor(4.4508e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.014829
Average KL loss: 0.209636
Average total loss: 0.224465
tensor(-8.9624, device='cuda:0') tensor(5.3405, device='cuda:0') tensor(3.3917e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.016755
Average KL loss: 0.209395
Average total loss: 0.226150
tensor(-8.9657, device='cuda:0') tensor(5.3401, device='cuda:0') tensor(1.6720e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.016589
Average KL loss: 0.209177
Average total loss: 0.225766
tensor(-8.9691, device='cuda:0') tensor(5.3400, device='cuda:0') tensor(3.7230e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.017085
Average KL loss: 0.208965
Average total loss: 0.226049
tensor(-8.9724, device='cuda:0') tensor(5.3399, device='cuda:0') tensor(6.5348e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.016465
Average KL loss: 0.208758
Average total loss: 0.225223
tensor(-8.9758, device='cuda:0') tensor(5.3398, device='cuda:0') tensor(3.8558e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.015864
Average KL loss: 0.208523
Average total loss: 0.224387
tensor(-8.9791, device='cuda:0') tensor(5.3394, device='cuda:0') tensor(5.9705e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.015674
Average KL loss: 0.208296
Average total loss: 0.223969
tensor(-8.9824, device='cuda:0') tensor(5.3391, device='cuda:0') tensor(4.5128e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.016752
Average KL loss: 0.208076
Average total loss: 0.224827
tensor(-8.9857, device='cuda:0') tensor(5.3390, device='cuda:0') tensor(3.5066e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.016060
Average KL loss: 0.207867
Average total loss: 0.223927
tensor(-8.9890, device='cuda:0') tensor(5.3389, device='cuda:0') tensor(4.5331e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.014919
Average KL loss: 0.207655
Average total loss: 0.222574
tensor(-8.9923, device='cuda:0') tensor(5.3386, device='cuda:0') tensor(5.4384e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.014181
Average KL loss: 0.207426
Average total loss: 0.221607
tensor(-8.9956, device='cuda:0') tensor(5.3381, device='cuda:0') tensor(2.7240e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.014709
Average KL loss: 0.207175
Average total loss: 0.221884
tensor(-8.9988, device='cuda:0') tensor(5.3376, device='cuda:0') tensor(4.9735e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.016132
Average KL loss: 0.206954
Average total loss: 0.223086
tensor(-9.0021, device='cuda:0') tensor(5.3375, device='cuda:0') tensor(4.3001e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.016434
Average KL loss: 0.206743
Average total loss: 0.223177
tensor(-9.0053, device='cuda:0') tensor(5.3373, device='cuda:0') tensor(5.0744e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.015433
Average KL loss: 0.206530
Average total loss: 0.221963
tensor(-9.0085, device='cuda:0') tensor(5.3370, device='cuda:0') tensor(3.0028e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.016180
Average KL loss: 0.206324
Average total loss: 0.222503
tensor(-9.0117, device='cuda:0') tensor(5.3370, device='cuda:0') tensor(5.5554e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.014982
Average KL loss: 0.206101
Average total loss: 0.221083
 Percentile value: 1.1179903030395506
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =    1208 /    1728             ( 69.91%) | total_pruned =     520 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5514 /   36864             ( 14.96%) | total_pruned =   31350 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    6092 /   36864             ( 16.53%) | total_pruned =   30772 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    5375 /   36864             ( 14.58%) | total_pruned =   31489 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    5374 /   36864             ( 14.58%) | total_pruned =   31490 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    9420 /   73728             ( 12.78%) | total_pruned =   64308 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   15252 /  147456             ( 10.34%) | total_pruned =  132204 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3826 /    8192             ( 46.70%) | total_pruned =    4366 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    9672 /  147456             (  6.56%) | total_pruned =  137784 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    9560 /  147456             (  6.48%) | total_pruned =  137896 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   27398 /  294912             (  9.29%) | total_pruned =  267514 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   39856 /  589824             (  6.76%) | total_pruned =  549968 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   10229 /   32768             ( 31.22%) | total_pruned =   22539 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   16811 /  589824             (  2.85%) | total_pruned =  573013 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   16377 /  589824             (  2.78%) | total_pruned =  573447 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     199 /     256             ( 77.73%) | total_pruned =      57 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   49049 / 1179648             (  4.16%) | total_pruned = 1130599 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     477 /     512             ( 93.16%) | total_pruned =      35 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   29790 / 2359296             (  1.26%) | total_pruned = 2329506 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   11609 /  131072             (  8.86%) | total_pruned =  119463 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     368 /     512             ( 71.88%) | total_pruned =     144 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   12709 / 2359296             (  0.54%) | total_pruned = 2346587 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     338 /     512             ( 66.02%) | total_pruned =     174 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     129 /     512             ( 25.20%) | total_pruned =     383 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    5274 / 2359296             (  0.22%) | total_pruned = 2354022 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
linear.weight        | nonzeros =    3781 /    5120             ( 73.85%) | total_pruned =    1339 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 21/200 Loss: 0.000000 Accuracy: 86.66 100.00 % Best test Accuracy: 86.97%
tensor(-9.0149, device='cuda:0') tensor(5.3367, device='cuda:0') tensor(-1.0305e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.076647
Average KL loss: 0.198527
Average total loss: 0.275173
tensor(-9.0409, device='cuda:0') tensor(5.0598, device='cuda:0') tensor(-2.9300e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.060975
Average KL loss: 0.188258
Average total loss: 0.249234
tensor(-9.0628, device='cuda:0') tensor(4.8495, device='cuda:0') tensor(-6.1563e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.055646
Average KL loss: 0.182018
Average total loss: 0.237664
tensor(-9.0815, device='cuda:0') tensor(4.6828, device='cuda:0') tensor(-4.1291e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.048906
Average KL loss: 0.178002
Average total loss: 0.226908
tensor(-9.0979, device='cuda:0') tensor(4.5467, device='cuda:0') tensor(-4.6232e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.050854
Average KL loss: 0.175274
Average total loss: 0.226128
tensor(-9.1126, device='cuda:0') tensor(4.4333, device='cuda:0') tensor(-6.7243e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.047444
Average KL loss: 0.173334
Average total loss: 0.220779
tensor(-9.1259, device='cuda:0') tensor(4.3367, device='cuda:0') tensor(-8.6592e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.041710
Average KL loss: 0.171910
Average total loss: 0.213619
tensor(-9.1381, device='cuda:0') tensor(4.2532, device='cuda:0') tensor(-2.5946e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.039230
Average KL loss: 0.170822
Average total loss: 0.210052
tensor(-9.1495, device='cuda:0') tensor(4.1802, device='cuda:0') tensor(-5.5334e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.038346
Average KL loss: 0.169986
Average total loss: 0.208332
tensor(-9.1601, device='cuda:0') tensor(4.1157, device='cuda:0') tensor(-1.2227e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.038050
Average KL loss: 0.169309
Average total loss: 0.207359
tensor(-9.1700, device='cuda:0') tensor(4.0581, device='cuda:0') tensor(-1.3967e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.035519
Average KL loss: 0.168776
Average total loss: 0.204296
tensor(-9.1794, device='cuda:0') tensor(4.0064, device='cuda:0') tensor(-9.8075e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.032842
Average KL loss: 0.168337
Average total loss: 0.201178
tensor(-9.1884, device='cuda:0') tensor(3.9595, device='cuda:0') tensor(-3.7494e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.035002
Average KL loss: 0.167965
Average total loss: 0.202967
tensor(-9.1969, device='cuda:0') tensor(3.9168, device='cuda:0') tensor(-2.7599e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.034388
Average KL loss: 0.167667
Average total loss: 0.202055
tensor(-9.2051, device='cuda:0') tensor(3.8779, device='cuda:0') tensor(-1.5265e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.033549
Average KL loss: 0.167412
Average total loss: 0.200961
tensor(-9.2129, device='cuda:0') tensor(3.8420, device='cuda:0') tensor(5.9246e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.032526
Average KL loss: 0.167191
Average total loss: 0.199718
tensor(-9.2205, device='cuda:0') tensor(3.8089, device='cuda:0') tensor(-1.6325e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.030803
Average KL loss: 0.166993
Average total loss: 0.197796
tensor(-9.2278, device='cuda:0') tensor(3.7782, device='cuda:0') tensor(-2.9568e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.028830
Average KL loss: 0.166820
Average total loss: 0.195650
tensor(-9.2349, device='cuda:0') tensor(3.7496, device='cuda:0') tensor(-1.9644e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.027849
Average KL loss: 0.166657
Average total loss: 0.194506
tensor(-9.2418, device='cuda:0') tensor(3.7229, device='cuda:0') tensor(-4.5947e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.027345
Average KL loss: 0.166506
Average total loss: 0.193850
tensor(-9.2485, device='cuda:0') tensor(3.6979, device='cuda:0') tensor(-2.4225e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.027365
Average KL loss: 0.166375
Average total loss: 0.193740
tensor(-9.2550, device='cuda:0') tensor(3.6744, device='cuda:0') tensor(-7.6393e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.027985
Average KL loss: 0.166258
Average total loss: 0.194243
tensor(-9.2613, device='cuda:0') tensor(3.6525, device='cuda:0') tensor(1.0872e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.027907
Average KL loss: 0.166153
Average total loss: 0.194061
tensor(-9.2675, device='cuda:0') tensor(3.6318, device='cuda:0') tensor(-3.0984e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.027298
Average KL loss: 0.166054
Average total loss: 0.193353
tensor(-9.2736, device='cuda:0') tensor(3.6123, device='cuda:0') tensor(5.1760e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.027607
Average KL loss: 0.165963
Average total loss: 0.193570
tensor(-9.2795, device='cuda:0') tensor(3.5939, device='cuda:0') tensor(8.1749e-11, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.024759
Average KL loss: 0.165881
Average total loss: 0.190639
tensor(-9.2853, device='cuda:0') tensor(3.5763, device='cuda:0') tensor(-2.8473e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.025019
Average KL loss: 0.165795
Average total loss: 0.190814
tensor(-9.2910, device='cuda:0') tensor(3.5597, device='cuda:0') tensor(-1.0203e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.024255
Average KL loss: 0.165710
Average total loss: 0.189965
tensor(-9.2966, device='cuda:0') tensor(3.5440, device='cuda:0') tensor(1.1148e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.024120
Average KL loss: 0.165634
Average total loss: 0.189754
tensor(-9.3021, device='cuda:0') tensor(3.5290, device='cuda:0') tensor(1.5697e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.023726
Average KL loss: 0.165569
Average total loss: 0.189295
tensor(-9.3074, device='cuda:0') tensor(3.5148, device='cuda:0') tensor(-5.0202e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.023220
Average KL loss: 0.165513
Average total loss: 0.188734
tensor(-9.3127, device='cuda:0') tensor(3.5013, device='cuda:0') tensor(2.0955e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.022485
Average KL loss: 0.165446
Average total loss: 0.187931
tensor(-9.3179, device='cuda:0') tensor(3.4882, device='cuda:0') tensor(-3.2346e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.022319
Average KL loss: 0.165376
Average total loss: 0.187695
tensor(-9.3231, device='cuda:0') tensor(3.4757, device='cuda:0') tensor(1.8466e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.021622
Average KL loss: 0.165304
Average total loss: 0.186926
tensor(-9.3281, device='cuda:0') tensor(3.4637, device='cuda:0') tensor(1.0873e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.023706
Average KL loss: 0.165239
Average total loss: 0.188945
tensor(-9.3331, device='cuda:0') tensor(3.4524, device='cuda:0') tensor(-1.9327e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.019471
Average KL loss: 0.165184
Average total loss: 0.184655
tensor(-9.3380, device='cuda:0') tensor(3.4415, device='cuda:0') tensor(-9.9015e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.021517
Average KL loss: 0.165113
Average total loss: 0.186631
tensor(-9.3429, device='cuda:0') tensor(3.4309, device='cuda:0') tensor(-2.1739e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.022009
Average KL loss: 0.165050
Average total loss: 0.187059
tensor(-9.3477, device='cuda:0') tensor(3.4209, device='cuda:0') tensor(1.4206e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.020218
Average KL loss: 0.164985
Average total loss: 0.185202
tensor(-9.3524, device='cuda:0') tensor(3.4112, device='cuda:0') tensor(4.7893e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.020884
Average KL loss: 0.164920
Average total loss: 0.185804
tensor(-9.3571, device='cuda:0') tensor(3.4019, device='cuda:0') tensor(-1.2560e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.022402
Average KL loss: 0.164852
Average total loss: 0.187254
tensor(-9.3617, device='cuda:0') tensor(3.3930, device='cuda:0') tensor(-1.8617e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.019251
Average KL loss: 0.164800
Average total loss: 0.184051
tensor(-9.3662, device='cuda:0') tensor(3.3844, device='cuda:0') tensor(-1.2088e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.019107
Average KL loss: 0.164735
Average total loss: 0.183842
tensor(-9.3708, device='cuda:0') tensor(3.3760, device='cuda:0') tensor(-1.3729e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.019892
Average KL loss: 0.164659
Average total loss: 0.184551
tensor(-9.3752, device='cuda:0') tensor(3.3679, device='cuda:0') tensor(9.1407e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.019792
Average KL loss: 0.164598
Average total loss: 0.184390
tensor(-9.3796, device='cuda:0') tensor(3.3601, device='cuda:0') tensor(-8.1752e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.020331
Average KL loss: 0.164534
Average total loss: 0.184865
tensor(-9.3840, device='cuda:0') tensor(3.3526, device='cuda:0') tensor(-3.4036e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.019362
Average KL loss: 0.164465
Average total loss: 0.183827
tensor(-9.3883, device='cuda:0') tensor(3.3454, device='cuda:0') tensor(-7.3379e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.018897
Average KL loss: 0.164405
Average total loss: 0.183302
tensor(-9.3926, device='cuda:0') tensor(3.3384, device='cuda:0') tensor(2.0549e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.019040
Average KL loss: 0.164340
Average total loss: 0.183380
tensor(-9.3968, device='cuda:0') tensor(3.3317, device='cuda:0') tensor(4.0079e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.018501
Average KL loss: 0.164282
Average total loss: 0.182783
tensor(-9.4010, device='cuda:0') tensor(3.3252, device='cuda:0') tensor(1.8589e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.018054
Average KL loss: 0.164221
Average total loss: 0.182274
tensor(-9.4052, device='cuda:0') tensor(3.3190, device='cuda:0') tensor(2.3289e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.017397
Average KL loss: 0.164152
Average total loss: 0.181549
tensor(-9.4093, device='cuda:0') tensor(3.3127, device='cuda:0') tensor(-1.5173e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.019842
Average KL loss: 0.164085
Average total loss: 0.183927
tensor(-9.4134, device='cuda:0') tensor(3.3069, device='cuda:0') tensor(1.5444e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.017983
Average KL loss: 0.164017
Average total loss: 0.182001
tensor(-9.4175, device='cuda:0') tensor(3.3011, device='cuda:0') tensor(1.6586e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.018324
Average KL loss: 0.163959
Average total loss: 0.182282
tensor(-9.4215, device='cuda:0') tensor(3.2956, device='cuda:0') tensor(8.7791e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.017146
Average KL loss: 0.163887
Average total loss: 0.181033
tensor(-9.4255, device='cuda:0') tensor(3.2901, device='cuda:0') tensor(6.9457e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.019107
Average KL loss: 0.163815
Average total loss: 0.182922
tensor(-9.4294, device='cuda:0') tensor(3.2849, device='cuda:0') tensor(2.8309e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.016715
Average KL loss: 0.163746
Average total loss: 0.180461
tensor(-9.4333, device='cuda:0') tensor(3.2798, device='cuda:0') tensor(1.8931e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.016843
Average KL loss: 0.163678
Average total loss: 0.180521
tensor(-9.4372, device='cuda:0') tensor(3.2748, device='cuda:0') tensor(-2.0100e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.016352
Average KL loss: 0.163603
Average total loss: 0.179955
tensor(-9.4411, device='cuda:0') tensor(3.2699, device='cuda:0') tensor(2.2803e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.017728
Average KL loss: 0.163528
Average total loss: 0.181256
tensor(-9.4449, device='cuda:0') tensor(3.2653, device='cuda:0') tensor(1.7866e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.016656
Average KL loss: 0.163457
Average total loss: 0.180112
tensor(-9.4487, device='cuda:0') tensor(3.2608, device='cuda:0') tensor(1.2037e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.016350
Average KL loss: 0.163380
Average total loss: 0.179730
tensor(-9.4525, device='cuda:0') tensor(3.2563, device='cuda:0') tensor(7.7093e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.017143
Average KL loss: 0.163311
Average total loss: 0.180454
tensor(-9.4562, device='cuda:0') tensor(3.2521, device='cuda:0') tensor(-4.2103e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.016051
Average KL loss: 0.163243
Average total loss: 0.179294
tensor(-9.4600, device='cuda:0') tensor(3.2479, device='cuda:0') tensor(-4.3604e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.016421
Average KL loss: 0.163170
Average total loss: 0.179591
tensor(-9.4636, device='cuda:0') tensor(3.2439, device='cuda:0') tensor(3.1085e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.016070
Average KL loss: 0.163095
Average total loss: 0.179166
tensor(-9.4673, device='cuda:0') tensor(3.2400, device='cuda:0') tensor(1.3887e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.014747
Average KL loss: 0.163019
Average total loss: 0.177765
tensor(-9.4710, device='cuda:0') tensor(3.2361, device='cuda:0') tensor(8.4598e-11, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.015751
Average KL loss: 0.162939
Average total loss: 0.178690
tensor(-9.4746, device='cuda:0') tensor(3.2323, device='cuda:0') tensor(1.2341e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.015966
Average KL loss: 0.162859
Average total loss: 0.178825
tensor(-9.4782, device='cuda:0') tensor(3.2288, device='cuda:0') tensor(-1.0629e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.015348
Average KL loss: 0.162788
Average total loss: 0.178136
tensor(-9.4817, device='cuda:0') tensor(3.2253, device='cuda:0') tensor(4.7548e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.016178
Average KL loss: 0.162721
Average total loss: 0.178900
tensor(-9.4853, device='cuda:0') tensor(3.2220, device='cuda:0') tensor(4.0897e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.014830
Average KL loss: 0.162645
Average total loss: 0.177475
tensor(-9.4888, device='cuda:0') tensor(3.2185, device='cuda:0') tensor(-8.6879e-11, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.014699
Average KL loss: 0.162553
Average total loss: 0.177252
tensor(-9.4923, device='cuda:0') tensor(3.2151, device='cuda:0') tensor(1.2355e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.014632
Average KL loss: 0.162467
Average total loss: 0.177099
tensor(-9.4958, device='cuda:0') tensor(3.2119, device='cuda:0') tensor(1.5120e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.013267
Average KL loss: 0.162369
Average total loss: 0.175635
tensor(-9.4993, device='cuda:0') tensor(3.2086, device='cuda:0') tensor(1.5874e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.015446
Average KL loss: 0.162280
Average total loss: 0.177726
tensor(-9.5027, device='cuda:0') tensor(3.2056, device='cuda:0') tensor(1.4985e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.013335
Average KL loss: 0.162201
Average total loss: 0.175536
tensor(-9.5061, device='cuda:0') tensor(3.2025, device='cuda:0') tensor(2.1935e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.014168
Average KL loss: 0.162112
Average total loss: 0.176280
tensor(-9.5096, device='cuda:0') tensor(3.1995, device='cuda:0') tensor(1.9966e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.014419
Average KL loss: 0.162027
Average total loss: 0.176446
tensor(-9.5129, device='cuda:0') tensor(3.1966, device='cuda:0') tensor(-3.8548e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.014863
Average KL loss: 0.161937
Average total loss: 0.176800
tensor(-9.5163, device='cuda:0') tensor(3.1938, device='cuda:0') tensor(7.2749e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.014654
Average KL loss: 0.161842
Average total loss: 0.176496
tensor(-9.5196, device='cuda:0') tensor(3.1910, device='cuda:0') tensor(1.7095e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.013658
Average KL loss: 0.161749
Average total loss: 0.175407
tensor(-9.5230, device='cuda:0') tensor(3.1882, device='cuda:0') tensor(1.2204e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.014110
Average KL loss: 0.161656
Average total loss: 0.175767
tensor(-9.5263, device='cuda:0') tensor(3.1855, device='cuda:0') tensor(3.2794e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.014639
Average KL loss: 0.161558
Average total loss: 0.176196
tensor(-9.5296, device='cuda:0') tensor(3.1829, device='cuda:0') tensor(3.2563e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.014597
Average KL loss: 0.161467
Average total loss: 0.176064
tensor(-9.5329, device='cuda:0') tensor(3.1805, device='cuda:0') tensor(2.3142e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.014546
Average KL loss: 0.161379
Average total loss: 0.175925
tensor(-9.5361, device='cuda:0') tensor(3.1781, device='cuda:0') tensor(6.7818e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.013958
Average KL loss: 0.161284
Average total loss: 0.175242
tensor(-9.5394, device='cuda:0') tensor(3.1756, device='cuda:0') tensor(1.5409e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.013968
Average KL loss: 0.161191
Average total loss: 0.175158
tensor(-9.5426, device='cuda:0') tensor(3.1733, device='cuda:0') tensor(2.8701e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.014244
Average KL loss: 0.161104
Average total loss: 0.175347
tensor(-9.5458, device='cuda:0') tensor(3.1711, device='cuda:0') tensor(1.7886e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.013067
Average KL loss: 0.161012
Average total loss: 0.174079
tensor(-9.5490, device='cuda:0') tensor(3.1687, device='cuda:0') tensor(-3.4691e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.014041
Average KL loss: 0.160918
Average total loss: 0.174959
tensor(-9.5521, device='cuda:0') tensor(3.1665, device='cuda:0') tensor(2.1527e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.013834
Average KL loss: 0.160828
Average total loss: 0.174662
tensor(-9.5553, device='cuda:0') tensor(3.1644, device='cuda:0') tensor(2.2117e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.012823
Average KL loss: 0.160742
Average total loss: 0.173565
tensor(-9.5584, device='cuda:0') tensor(3.1623, device='cuda:0') tensor(1.2867e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.013500
Average KL loss: 0.160641
Average total loss: 0.174141
tensor(-9.5616, device='cuda:0') tensor(3.1602, device='cuda:0') tensor(8.3342e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.013875
Average KL loss: 0.160546
Average total loss: 0.174421
tensor(-9.5647, device='cuda:0') tensor(3.1582, device='cuda:0') tensor(3.6058e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.013053
Average KL loss: 0.160456
Average total loss: 0.173509
tensor(-9.5678, device='cuda:0') tensor(3.1563, device='cuda:0') tensor(-2.0918e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.014193
Average KL loss: 0.160361
Average total loss: 0.174554
tensor(-9.5708, device='cuda:0') tensor(3.1543, device='cuda:0') tensor(9.8420e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.013142
Average KL loss: 0.160261
Average total loss: 0.173404
tensor(-9.5739, device='cuda:0') tensor(3.1524, device='cuda:0') tensor(-9.9296e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.013257
Average KL loss: 0.160163
Average total loss: 0.173420
tensor(-9.5770, device='cuda:0') tensor(3.1505, device='cuda:0') tensor(1.9367e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.011994
Average KL loss: 0.160058
Average total loss: 0.172053
tensor(-9.5800, device='cuda:0') tensor(3.1486, device='cuda:0') tensor(1.2899e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.013905
Average KL loss: 0.159958
Average total loss: 0.173863
tensor(-9.5830, device='cuda:0') tensor(3.1468, device='cuda:0') tensor(1.3380e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.012434
Average KL loss: 0.159856
Average total loss: 0.172291
tensor(-9.5860, device='cuda:0') tensor(3.1450, device='cuda:0') tensor(2.5787e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.013044
Average KL loss: 0.159767
Average total loss: 0.172812
tensor(-9.5890, device='cuda:0') tensor(3.1434, device='cuda:0') tensor(2.2039e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.014255
Average KL loss: 0.159672
Average total loss: 0.173927
tensor(-9.5920, device='cuda:0') tensor(3.1418, device='cuda:0') tensor(1.8720e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.013474
Average KL loss: 0.159583
Average total loss: 0.173057
tensor(-9.5950, device='cuda:0') tensor(3.1402, device='cuda:0') tensor(5.7350e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.013485
Average KL loss: 0.159493
Average total loss: 0.172979
tensor(-9.5979, device='cuda:0') tensor(3.1387, device='cuda:0') tensor(1.1836e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.012924
Average KL loss: 0.159389
Average total loss: 0.172313
tensor(-9.6009, device='cuda:0') tensor(3.1370, device='cuda:0') tensor(-8.0241e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.013008
Average KL loss: 0.159287
Average total loss: 0.172295
tensor(-9.6038, device='cuda:0') tensor(3.1355, device='cuda:0') tensor(-8.5806e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.013172
Average KL loss: 0.159189
Average total loss: 0.172362
tensor(-9.6067, device='cuda:0') tensor(3.1340, device='cuda:0') tensor(-8.8709e-11, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.012580
Average KL loss: 0.159097
Average total loss: 0.171676
tensor(-9.6096, device='cuda:0') tensor(3.1326, device='cuda:0') tensor(2.8361e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.012369
Average KL loss: 0.158996
Average total loss: 0.171365
tensor(-9.6125, device='cuda:0') tensor(3.1312, device='cuda:0') tensor(7.1035e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.012683
Average KL loss: 0.158897
Average total loss: 0.171580
tensor(-9.6154, device='cuda:0') tensor(3.1297, device='cuda:0') tensor(2.2573e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.011465
Average KL loss: 0.158788
Average total loss: 0.170253
tensor(-9.6183, device='cuda:0') tensor(3.1281, device='cuda:0') tensor(2.2007e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.011202
Average KL loss: 0.158676
Average total loss: 0.169878
tensor(-9.6211, device='cuda:0') tensor(3.1266, device='cuda:0') tensor(-7.5844e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.011487
Average KL loss: 0.158560
Average total loss: 0.170047
tensor(-9.6240, device='cuda:0') tensor(3.1251, device='cuda:0') tensor(2.6808e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.011369
Average KL loss: 0.158448
Average total loss: 0.169816
tensor(-9.6268, device='cuda:0') tensor(3.1236, device='cuda:0') tensor(-3.5534e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.011221
Average KL loss: 0.158327
Average total loss: 0.169548
tensor(-9.6296, device='cuda:0') tensor(3.1221, device='cuda:0') tensor(1.3666e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.012139
Average KL loss: 0.158219
Average total loss: 0.170359
tensor(-9.6324, device='cuda:0') tensor(3.1207, device='cuda:0') tensor(7.9834e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.012473
Average KL loss: 0.158115
Average total loss: 0.170588
tensor(-9.6352, device='cuda:0') tensor(3.1194, device='cuda:0') tensor(3.2203e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.011756
Average KL loss: 0.158001
Average total loss: 0.169758
tensor(-9.6380, device='cuda:0') tensor(3.1180, device='cuda:0') tensor(1.0528e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.011453
Average KL loss: 0.157892
Average total loss: 0.169345
tensor(-9.6408, device='cuda:0') tensor(3.1168, device='cuda:0') tensor(2.2148e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.012542
Average KL loss: 0.157793
Average total loss: 0.170335
tensor(-9.6436, device='cuda:0') tensor(3.1157, device='cuda:0') tensor(-7.9962e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.012260
Average KL loss: 0.157692
Average total loss: 0.169953
tensor(-9.6463, device='cuda:0') tensor(3.1145, device='cuda:0') tensor(1.8660e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.012352
Average KL loss: 0.157595
Average total loss: 0.169947
tensor(-9.6491, device='cuda:0') tensor(3.1134, device='cuda:0') tensor(1.5768e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.012136
Average KL loss: 0.157504
Average total loss: 0.169640
tensor(-9.6518, device='cuda:0') tensor(3.1124, device='cuda:0') tensor(1.8729e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.012349
Average KL loss: 0.157407
Average total loss: 0.169755
tensor(-9.6545, device='cuda:0') tensor(3.1113, device='cuda:0') tensor(-1.2014e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.012530
Average KL loss: 0.157309
Average total loss: 0.169838
tensor(-9.6572, device='cuda:0') tensor(3.1104, device='cuda:0') tensor(1.2740e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.012160
Average KL loss: 0.157214
Average total loss: 0.169375
tensor(-9.6599, device='cuda:0') tensor(3.1093, device='cuda:0') tensor(9.9006e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.011131
Average KL loss: 0.157108
Average total loss: 0.168239
tensor(-9.6626, device='cuda:0') tensor(3.1082, device='cuda:0') tensor(-1.8926e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.010966
Average KL loss: 0.157005
Average total loss: 0.167971
tensor(-9.6653, device='cuda:0') tensor(3.1072, device='cuda:0') tensor(2.2997e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.010884
Average KL loss: 0.156900
Average total loss: 0.167785
tensor(-9.6680, device='cuda:0') tensor(3.1061, device='cuda:0') tensor(1.3820e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.011564
Average KL loss: 0.156788
Average total loss: 0.168352
tensor(-9.6706, device='cuda:0') tensor(3.1050, device='cuda:0') tensor(1.7583e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.010654
Average KL loss: 0.156675
Average total loss: 0.167329
tensor(-9.6733, device='cuda:0') tensor(3.1038, device='cuda:0') tensor(1.3323e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.010815
Average KL loss: 0.156559
Average total loss: 0.167373
tensor(-9.6759, device='cuda:0') tensor(3.1027, device='cuda:0') tensor(1.2888e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.011330
Average KL loss: 0.156438
Average total loss: 0.167768
tensor(-9.6786, device='cuda:0') tensor(3.1016, device='cuda:0') tensor(1.7525e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.011580
Average KL loss: 0.156325
Average total loss: 0.167906
tensor(-9.6812, device='cuda:0') tensor(3.1006, device='cuda:0') tensor(1.7987e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.011232
Average KL loss: 0.156224
Average total loss: 0.167456
tensor(-9.6838, device='cuda:0') tensor(3.0996, device='cuda:0') tensor(3.3323e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.011669
Average KL loss: 0.156114
Average total loss: 0.167784
tensor(-9.6864, device='cuda:0') tensor(3.0987, device='cuda:0') tensor(1.0298e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.009712
Average KL loss: 0.156004
Average total loss: 0.165715
tensor(-9.6890, device='cuda:0') tensor(3.0976, device='cuda:0') tensor(2.1341e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.010833
Average KL loss: 0.155886
Average total loss: 0.166719
tensor(-9.6916, device='cuda:0') tensor(3.0966, device='cuda:0') tensor(5.0906e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.011699
Average KL loss: 0.155774
Average total loss: 0.167473
tensor(-9.6942, device='cuda:0') tensor(3.0957, device='cuda:0') tensor(1.7353e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.011194
Average KL loss: 0.155672
Average total loss: 0.166866
tensor(-9.6967, device='cuda:0') tensor(3.0949, device='cuda:0') tensor(1.7506e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.011335
Average KL loss: 0.155570
Average total loss: 0.166905
tensor(-9.6993, device='cuda:0') tensor(3.0941, device='cuda:0') tensor(1.1577e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.010332
Average KL loss: 0.155477
Average total loss: 0.165809
tensor(-9.7019, device='cuda:0') tensor(3.0932, device='cuda:0') tensor(1.3967e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.011560
Average KL loss: 0.155372
Average total loss: 0.166932
tensor(-9.7044, device='cuda:0') tensor(3.0924, device='cuda:0') tensor(1.3705e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.011724
Average KL loss: 0.155271
Average total loss: 0.166995
tensor(-9.7069, device='cuda:0') tensor(3.0917, device='cuda:0') tensor(3.5286e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.011741
Average KL loss: 0.155171
Average total loss: 0.166912
tensor(-9.7094, device='cuda:0') tensor(3.0909, device='cuda:0') tensor(3.0487e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.010873
Average KL loss: 0.155061
Average total loss: 0.165933
tensor(-9.7120, device='cuda:0') tensor(3.0900, device='cuda:0') tensor(2.4803e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.010537
Average KL loss: 0.154953
Average total loss: 0.165490
tensor(-9.7145, device='cuda:0') tensor(3.0892, device='cuda:0') tensor(-7.7854e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.011192
Average KL loss: 0.154846
Average total loss: 0.166038
tensor(-9.7170, device='cuda:0') tensor(3.0884, device='cuda:0') tensor(7.2466e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.011075
Average KL loss: 0.154722
Average total loss: 0.165797
tensor(-9.7195, device='cuda:0') tensor(3.0875, device='cuda:0') tensor(2.6788e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.009996
Average KL loss: 0.154612
Average total loss: 0.164607
tensor(-9.7220, device='cuda:0') tensor(3.0867, device='cuda:0') tensor(2.6465e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.010227
Average KL loss: 0.154496
Average total loss: 0.164723
tensor(-9.7244, device='cuda:0') tensor(3.0858, device='cuda:0') tensor(1.5714e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.010884
Average KL loss: 0.154390
Average total loss: 0.165275
tensor(-9.7269, device='cuda:0') tensor(3.0850, device='cuda:0') tensor(-3.5459e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.011083
Average KL loss: 0.154287
Average total loss: 0.165369
tensor(-9.7294, device='cuda:0') tensor(3.0843, device='cuda:0') tensor(2.5209e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.011219
Average KL loss: 0.154179
Average total loss: 0.165398
tensor(-9.7318, device='cuda:0') tensor(3.0837, device='cuda:0') tensor(2.4943e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.010033
Average KL loss: 0.154076
Average total loss: 0.164108
tensor(-9.7343, device='cuda:0') tensor(3.0829, device='cuda:0') tensor(1.3981e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.011126
Average KL loss: 0.153966
Average total loss: 0.165092
tensor(-9.7367, device='cuda:0') tensor(3.0823, device='cuda:0') tensor(1.7172e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.010381
Average KL loss: 0.153862
Average total loss: 0.164243
tensor(-9.7391, device='cuda:0') tensor(3.0815, device='cuda:0') tensor(-3.3888e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.011136
Average KL loss: 0.153755
Average total loss: 0.164890
tensor(-9.7415, device='cuda:0') tensor(3.0809, device='cuda:0') tensor(-7.4858e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.010258
Average KL loss: 0.153650
Average total loss: 0.163908
tensor(-9.7440, device='cuda:0') tensor(3.0801, device='cuda:0') tensor(9.9167e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.011227
Average KL loss: 0.153546
Average total loss: 0.164772
tensor(-9.7464, device='cuda:0') tensor(3.0795, device='cuda:0') tensor(1.5061e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.009236
Average KL loss: 0.153436
Average total loss: 0.162671
tensor(-9.7488, device='cuda:0') tensor(3.0787, device='cuda:0') tensor(2.4033e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.010000
Average KL loss: 0.153318
Average total loss: 0.163318
tensor(-9.7512, device='cuda:0') tensor(3.0780, device='cuda:0') tensor(-1.5813e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.010690
Average KL loss: 0.153209
Average total loss: 0.163899
tensor(-9.7535, device='cuda:0') tensor(3.0773, device='cuda:0') tensor(3.0444e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.010901
Average KL loss: 0.153101
Average total loss: 0.164001
tensor(-9.7559, device='cuda:0') tensor(3.0767, device='cuda:0') tensor(1.9865e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.011176
Average KL loss: 0.153002
Average total loss: 0.164178
tensor(-9.7583, device='cuda:0') tensor(3.0763, device='cuda:0') tensor(3.9472e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.010536
Average KL loss: 0.152914
Average total loss: 0.163450
tensor(-9.7606, device='cuda:0') tensor(3.0758, device='cuda:0') tensor(-1.1354e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.010347
Average KL loss: 0.152808
Average total loss: 0.163154
tensor(-9.7630, device='cuda:0') tensor(3.0752, device='cuda:0') tensor(9.8725e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.010894
Average KL loss: 0.152703
Average total loss: 0.163597
tensor(-9.7653, device='cuda:0') tensor(3.0748, device='cuda:0') tensor(1.0478e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.010322
Average KL loss: 0.152594
Average total loss: 0.162916
tensor(-9.7677, device='cuda:0') tensor(3.0742, device='cuda:0') tensor(8.4435e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.009929
Average KL loss: 0.152484
Average total loss: 0.162414
tensor(-9.7700, device='cuda:0') tensor(3.0735, device='cuda:0') tensor(1.5145e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.010430
Average KL loss: 0.152381
Average total loss: 0.162811
tensor(-9.7723, device='cuda:0') tensor(3.0731, device='cuda:0') tensor(7.9851e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.010230
Average KL loss: 0.152281
Average total loss: 0.162511
tensor(-9.7746, device='cuda:0') tensor(3.0725, device='cuda:0') tensor(1.7747e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.009428
Average KL loss: 0.152174
Average total loss: 0.161602
tensor(-9.7769, device='cuda:0') tensor(3.0720, device='cuda:0') tensor(2.4741e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.010476
Average KL loss: 0.152062
Average total loss: 0.162538
tensor(-9.7793, device='cuda:0') tensor(3.0714, device='cuda:0') tensor(2.3869e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.010987
Average KL loss: 0.151961
Average total loss: 0.162947
tensor(-9.7816, device='cuda:0') tensor(3.0709, device='cuda:0') tensor(8.8513e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.010152
Average KL loss: 0.151873
Average total loss: 0.162025
tensor(-9.7838, device='cuda:0') tensor(3.0705, device='cuda:0') tensor(2.5180e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.010900
Average KL loss: 0.151776
Average total loss: 0.162676
tensor(-9.7861, device='cuda:0') tensor(3.0701, device='cuda:0') tensor(3.1527e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.010778
Average KL loss: 0.151682
Average total loss: 0.162459
tensor(-9.7884, device='cuda:0') tensor(3.0696, device='cuda:0') tensor(1.2900e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.009949
Average KL loss: 0.151575
Average total loss: 0.161524
tensor(-9.7907, device='cuda:0') tensor(3.0690, device='cuda:0') tensor(-1.2527e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.009812
Average KL loss: 0.151462
Average total loss: 0.161274
tensor(-9.7929, device='cuda:0') tensor(3.0684, device='cuda:0') tensor(2.9202e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.009665
Average KL loss: 0.151361
Average total loss: 0.161025
tensor(-9.7952, device='cuda:0') tensor(3.0680, device='cuda:0') tensor(2.4625e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.010395
Average KL loss: 0.151260
Average total loss: 0.161655
tensor(-9.7974, device='cuda:0') tensor(3.0677, device='cuda:0') tensor(1.4177e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.010777
Average KL loss: 0.151168
Average total loss: 0.161945
tensor(-9.7997, device='cuda:0') tensor(3.0674, device='cuda:0') tensor(7.6142e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.010578
Average KL loss: 0.151072
Average total loss: 0.161650
tensor(-9.8019, device='cuda:0') tensor(3.0669, device='cuda:0') tensor(2.6839e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.010127
Average KL loss: 0.150966
Average total loss: 0.161093
tensor(-9.8042, device='cuda:0') tensor(3.0664, device='cuda:0') tensor(8.4155e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.010313
Average KL loss: 0.150873
Average total loss: 0.161186
tensor(-9.8064, device='cuda:0') tensor(3.0660, device='cuda:0') tensor(8.4150e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.010012
Average KL loss: 0.150776
Average total loss: 0.160788
tensor(-9.8086, device='cuda:0') tensor(3.0656, device='cuda:0') tensor(1.3096e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.009767
Average KL loss: 0.150678
Average total loss: 0.160445
tensor(-9.8108, device='cuda:0') tensor(3.0652, device='cuda:0') tensor(7.3565e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.009967
Average KL loss: 0.150581
Average total loss: 0.160548
tensor(-9.8130, device='cuda:0') tensor(3.0648, device='cuda:0') tensor(-1.1135e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.010945
Average KL loss: 0.150479
Average total loss: 0.161424
tensor(-9.8152, device='cuda:0') tensor(3.0645, device='cuda:0') tensor(-1.2359e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.010009
Average KL loss: 0.150389
Average total loss: 0.160397
tensor(-9.8174, device='cuda:0') tensor(3.0641, device='cuda:0') tensor(1.7533e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.009518
Average KL loss: 0.150285
Average total loss: 0.159803
tensor(-9.8196, device='cuda:0') tensor(3.0636, device='cuda:0') tensor(1.4452e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.010258
Average KL loss: 0.150180
Average total loss: 0.160438
tensor(-9.8218, device='cuda:0') tensor(3.0632, device='cuda:0') tensor(1.1430e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.010896
Average KL loss: 0.150078
Average total loss: 0.160975
tensor(-9.8240, device='cuda:0') tensor(3.0628, device='cuda:0') tensor(6.4621e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.009963
Average KL loss: 0.149975
Average total loss: 0.159938
tensor(-9.8262, device='cuda:0') tensor(3.0624, device='cuda:0') tensor(1.6901e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.008995
Average KL loss: 0.149863
Average total loss: 0.158858
tensor(-9.8283, device='cuda:0') tensor(3.0620, device='cuda:0') tensor(1.8154e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.008940
Average KL loss: 0.149757
Average total loss: 0.158697
 Percentile value: 3.701120948791504
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =    1068 /    1728             ( 61.81%) | total_pruned =     660 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1946 /   36864             (  5.28%) | total_pruned =   34918 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2276 /   36864             (  6.17%) | total_pruned =   34588 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1959 /   36864             (  5.31%) | total_pruned =   34905 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2022 /   36864             (  5.49%) | total_pruned =   34842 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3128 /   73728             (  4.24%) | total_pruned =   70600 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4892 /  147456             (  3.32%) | total_pruned =  142564 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2474 /    8192             ( 30.20%) | total_pruned =    5718 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2527 /  147456             (  1.71%) | total_pruned =  144929 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2470 /  147456             (  1.68%) | total_pruned =  144986 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8453 /  294912             (  2.87%) | total_pruned =  286459 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   11218 /  589824             (  1.90%) | total_pruned =  578606 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     178 /     256             ( 69.53%) | total_pruned =      78 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5283 /   32768             ( 16.12%) | total_pruned =   27485 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     173 /     256             ( 67.58%) | total_pruned =      83 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3412 /  589824             (  0.58%) | total_pruned =  586412 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3271 /  589824             (  0.55%) | total_pruned =  586553 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     148 /     256             ( 57.81%) | total_pruned =     108 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   11751 / 1179648             (  1.00%) | total_pruned = 1167897 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     422 /     512             ( 82.42%) | total_pruned =      90 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    5752 / 2359296             (  0.24%) | total_pruned = 2353544 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     214 /     512             ( 41.80%) | total_pruned =     298 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3477 /  131072             (  2.65%) | total_pruned =  127595 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     188 /     512             ( 36.72%) | total_pruned =     324 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2581 / 2359296             (  0.11%) | total_pruned = 2356715 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     267 /     512             ( 52.15%) | total_pruned =     245 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      69 /     512             ( 13.48%) | total_pruned =     443 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     750 / 2359296             (  0.03%) | total_pruned = 2358546 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
linear.weight        | nonzeros =    3105 /    5120             ( 60.64%) | total_pruned =    2015 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 23/200 Loss: 0.000993 Accuracy: 84.29 100.00 % Best test Accuracy: 84.35%
tensor(-9.8305, device='cuda:0') tensor(3.0615, device='cuda:0') tensor(-2.6823e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.042712
Average KL loss: 0.142224
Average total loss: 0.184935
tensor(-9.8412, device='cuda:0') tensor(2.9104, device='cuda:0') tensor(-4.6882e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.042821
Average KL loss: 0.128784
Average total loss: 0.171604
tensor(-9.8508, device='cuda:0') tensor(2.7862, device='cuda:0') tensor(-2.6769e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.042197
Average KL loss: 0.117948
Average total loss: 0.160145
tensor(-9.8594, device='cuda:0') tensor(2.6816, device='cuda:0') tensor(-3.4662e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.039244
Average KL loss: 0.109682
Average total loss: 0.148926
tensor(-9.8672, device='cuda:0') tensor(2.5943, device='cuda:0') tensor(-3.9387e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.040208
Average KL loss: 0.103701
Average total loss: 0.143909
tensor(-9.8742, device='cuda:0') tensor(2.5217, device='cuda:0') tensor(-1.7845e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.039096
Average KL loss: 0.099483
Average total loss: 0.138579
tensor(-9.8806, device='cuda:0') tensor(2.4608, device='cuda:0') tensor(-8.8243e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.036197
Average KL loss: 0.096497
Average total loss: 0.132694
tensor(-9.8865, device='cuda:0') tensor(2.4092, device='cuda:0') tensor(-6.1079e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.036930
Average KL loss: 0.094344
Average total loss: 0.131274
tensor(-9.8919, device='cuda:0') tensor(2.3649, device='cuda:0') tensor(-5.6049e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.036854
Average KL loss: 0.092748
Average total loss: 0.129602
tensor(-9.8970, device='cuda:0') tensor(2.3262, device='cuda:0') tensor(-8.4809e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.034149
Average KL loss: 0.091535
Average total loss: 0.125684
tensor(-9.9018, device='cuda:0') tensor(2.2921, device='cuda:0') tensor(-4.4348e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.035960
Average KL loss: 0.090594
Average total loss: 0.126553
tensor(-9.9064, device='cuda:0') tensor(2.2618, device='cuda:0') tensor(-5.6368e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.035732
Average KL loss: 0.089850
Average total loss: 0.125583
tensor(-9.9107, device='cuda:0') tensor(2.2346, device='cuda:0') tensor(-5.2915e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.035843
Average KL loss: 0.089255
Average total loss: 0.125098
tensor(-9.9149, device='cuda:0') tensor(2.2101, device='cuda:0') tensor(-5.0978e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.031191
Average KL loss: 0.088769
Average total loss: 0.119961
tensor(-9.9189, device='cuda:0') tensor(2.1876, device='cuda:0') tensor(-7.3539e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.032280
Average KL loss: 0.088366
Average total loss: 0.120646
tensor(-9.9228, device='cuda:0') tensor(2.1671, device='cuda:0') tensor(-6.2580e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.031855
Average KL loss: 0.088029
Average total loss: 0.119885
tensor(-9.9266, device='cuda:0') tensor(2.1482, device='cuda:0') tensor(-3.8877e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.030324
Average KL loss: 0.087740
Average total loss: 0.118064
tensor(-9.9303, device='cuda:0') tensor(2.1307, device='cuda:0') tensor(-4.5257e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.031428
Average KL loss: 0.087496
Average total loss: 0.118924
tensor(-9.9338, device='cuda:0') tensor(2.1144, device='cuda:0') tensor(-5.0845e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.029240
Average KL loss: 0.087285
Average total loss: 0.116525
tensor(-9.9373, device='cuda:0') tensor(2.0992, device='cuda:0') tensor(-3.7461e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.029394
Average KL loss: 0.087104
Average total loss: 0.116499
tensor(-9.9407, device='cuda:0') tensor(2.0851, device='cuda:0') tensor(-4.4493e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.026754
Average KL loss: 0.086946
Average total loss: 0.113700
tensor(-9.9441, device='cuda:0') tensor(2.0717, device='cuda:0') tensor(-3.7718e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.026775
Average KL loss: 0.086807
Average total loss: 0.113582
tensor(-9.9474, device='cuda:0') tensor(2.0592, device='cuda:0') tensor(-5.2821e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.027898
Average KL loss: 0.086686
Average total loss: 0.114584
tensor(-9.9506, device='cuda:0') tensor(2.0475, device='cuda:0') tensor(-4.5816e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.026565
Average KL loss: 0.086582
Average total loss: 0.113146
tensor(-9.9538, device='cuda:0') tensor(2.0364, device='cuda:0') tensor(-4.3522e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.027093
Average KL loss: 0.086490
Average total loss: 0.113583
tensor(-9.9569, device='cuda:0') tensor(2.0259, device='cuda:0') tensor(-3.2151e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.026134
Average KL loss: 0.086408
Average total loss: 0.112542
tensor(-9.9600, device='cuda:0') tensor(2.0160, device='cuda:0') tensor(-4.6997e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.025677
Average KL loss: 0.086334
Average total loss: 0.112011
tensor(-9.9630, device='cuda:0') tensor(2.0065, device='cuda:0') tensor(-2.4297e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.024138
Average KL loss: 0.086268
Average total loss: 0.110406
tensor(-9.9660, device='cuda:0') tensor(1.9975, device='cuda:0') tensor(-4.3341e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.024073
Average KL loss: 0.086208
Average total loss: 0.110281
tensor(-9.9690, device='cuda:0') tensor(1.9890, device='cuda:0') tensor(-4.1136e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.024058
Average KL loss: 0.086153
Average total loss: 0.110211
tensor(-9.9719, device='cuda:0') tensor(1.9808, device='cuda:0') tensor(-5.0658e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.025027
Average KL loss: 0.086105
Average total loss: 0.111132
tensor(-9.9748, device='cuda:0') tensor(1.9731, device='cuda:0') tensor(-4.1270e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.022682
Average KL loss: 0.086064
Average total loss: 0.108746
tensor(-9.9776, device='cuda:0') tensor(1.9656, device='cuda:0') tensor(-1.7219e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.022958
Average KL loss: 0.086025
Average total loss: 0.108983
tensor(-9.9804, device='cuda:0') tensor(1.9584, device='cuda:0') tensor(-4.0644e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.024189
Average KL loss: 0.085989
Average total loss: 0.110178
tensor(-9.9832, device='cuda:0') tensor(1.9515, device='cuda:0') tensor(-2.0661e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.023274
Average KL loss: 0.085958
Average total loss: 0.109231
tensor(-9.9860, device='cuda:0') tensor(1.9449, device='cuda:0') tensor(-5.9152e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.023584
Average KL loss: 0.085928
Average total loss: 0.109512
tensor(-9.9887, device='cuda:0') tensor(1.9386, device='cuda:0') tensor(-4.8886e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.021657
Average KL loss: 0.085902
Average total loss: 0.107559
tensor(-9.9914, device='cuda:0') tensor(1.9326, device='cuda:0') tensor(-1.7008e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.021440
Average KL loss: 0.085878
Average total loss: 0.107318
tensor(-9.9941, device='cuda:0') tensor(1.9267, device='cuda:0') tensor(-2.8180e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.021610
Average KL loss: 0.085857
Average total loss: 0.107467
tensor(-9.9968, device='cuda:0') tensor(1.9211, device='cuda:0') tensor(-1.8293e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.021190
Average KL loss: 0.085835
Average total loss: 0.107026
tensor(-9.9995, device='cuda:0') tensor(1.9156, device='cuda:0') tensor(-8.6291e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.019980
Average KL loss: 0.085816
Average total loss: 0.105797
tensor(-10.0021, device='cuda:0') tensor(1.9103, device='cuda:0') tensor(-4.3481e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.020311
Average KL loss: 0.085800
Average total loss: 0.106111
tensor(-10.0047, device='cuda:0') tensor(1.9053, device='cuda:0') tensor(-2.7532e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.019451
Average KL loss: 0.085785
Average total loss: 0.105236
tensor(-10.0073, device='cuda:0') tensor(1.9003, device='cuda:0') tensor(-3.6165e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.021469
Average KL loss: 0.085770
Average total loss: 0.107239
tensor(-10.0098, device='cuda:0') tensor(1.8957, device='cuda:0') tensor(-2.4218e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.019302
Average KL loss: 0.085759
Average total loss: 0.105060
tensor(-10.0124, device='cuda:0') tensor(1.8911, device='cuda:0') tensor(-2.7126e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.018852
Average KL loss: 0.085747
Average total loss: 0.104599
tensor(-10.0149, device='cuda:0') tensor(1.8868, device='cuda:0') tensor(-2.4824e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.018633
Average KL loss: 0.085736
Average total loss: 0.104368
tensor(-10.0174, device='cuda:0') tensor(1.8824, device='cuda:0') tensor(-3.9727e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.018121
Average KL loss: 0.085725
Average total loss: 0.103846
tensor(-10.0199, device='cuda:0') tensor(1.8783, device='cuda:0') tensor(-1.4260e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.018599
Average KL loss: 0.085717
Average total loss: 0.104316
tensor(-10.0224, device='cuda:0') tensor(1.8742, device='cuda:0') tensor(-3.1356e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.018522
Average KL loss: 0.085709
Average total loss: 0.104231
tensor(-10.0249, device='cuda:0') tensor(1.8704, device='cuda:0') tensor(-3.1167e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.018105
Average KL loss: 0.085701
Average total loss: 0.103806
tensor(-10.0273, device='cuda:0') tensor(1.8667, device='cuda:0') tensor(-1.5890e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.018547
Average KL loss: 0.085695
Average total loss: 0.104243
tensor(-10.0298, device='cuda:0') tensor(1.8631, device='cuda:0') tensor(-2.3738e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.017525
Average KL loss: 0.085690
Average total loss: 0.103215
tensor(-10.0322, device='cuda:0') tensor(1.8596, device='cuda:0') tensor(-1.6385e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.017626
Average KL loss: 0.085686
Average total loss: 0.103312
tensor(-10.0346, device='cuda:0') tensor(1.8561, device='cuda:0') tensor(-1.1610e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.017262
Average KL loss: 0.085680
Average total loss: 0.102941
tensor(-10.0370, device='cuda:0') tensor(1.8528, device='cuda:0') tensor(-3.0964e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.016509
Average KL loss: 0.085674
Average total loss: 0.102184
tensor(-10.0394, device='cuda:0') tensor(1.8496, device='cuda:0') tensor(-2.6411e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.016091
Average KL loss: 0.085670
Average total loss: 0.101761
tensor(-10.0418, device='cuda:0') tensor(1.8465, device='cuda:0') tensor(-2.1997e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.016460
Average KL loss: 0.085667
Average total loss: 0.102126
tensor(-10.0441, device='cuda:0') tensor(1.8434, device='cuda:0') tensor(-3.2410e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.015798
Average KL loss: 0.085661
Average total loss: 0.101459
tensor(-10.0465, device='cuda:0') tensor(1.8404, device='cuda:0') tensor(-2.5364e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.015469
Average KL loss: 0.085655
Average total loss: 0.101125
tensor(-10.0488, device='cuda:0') tensor(1.8374, device='cuda:0') tensor(-1.5087e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.016445
Average KL loss: 0.085652
Average total loss: 0.102097
tensor(-10.0511, device='cuda:0') tensor(1.8347, device='cuda:0') tensor(-8.9592e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.015599
Average KL loss: 0.085650
Average total loss: 0.101249
tensor(-10.0535, device='cuda:0') tensor(1.8320, device='cuda:0') tensor(-2.6470e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.015585
Average KL loss: 0.085648
Average total loss: 0.101233
tensor(-10.0558, device='cuda:0') tensor(1.8293, device='cuda:0') tensor(-3.7577e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.014588
Average KL loss: 0.085644
Average total loss: 0.100232
tensor(-10.0580, device='cuda:0') tensor(1.8267, device='cuda:0') tensor(-3.8678e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.015215
Average KL loss: 0.085641
Average total loss: 0.100856
tensor(-10.0603, device='cuda:0') tensor(1.8242, device='cuda:0') tensor(-3.1554e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.015122
Average KL loss: 0.085639
Average total loss: 0.100760
tensor(-10.0626, device='cuda:0') tensor(1.8218, device='cuda:0') tensor(-1.7501e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.015620
Average KL loss: 0.085638
Average total loss: 0.101258
tensor(-10.0649, device='cuda:0') tensor(1.8195, device='cuda:0') tensor(-3.3370e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.014694
Average KL loss: 0.085639
Average total loss: 0.100333
tensor(-10.0671, device='cuda:0') tensor(1.8173, device='cuda:0') tensor(-1.3964e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.014884
Average KL loss: 0.085637
Average total loss: 0.100521
tensor(-10.0693, device='cuda:0') tensor(1.8150, device='cuda:0') tensor(-1.8861e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.014567
Average KL loss: 0.085636
Average total loss: 0.100203
tensor(-10.0716, device='cuda:0') tensor(1.8128, device='cuda:0') tensor(-1.0005e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.013979
Average KL loss: 0.085633
Average total loss: 0.099613
tensor(-10.0738, device='cuda:0') tensor(1.8107, device='cuda:0') tensor(-2.8480e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.014245
Average KL loss: 0.085632
Average total loss: 0.099877
tensor(-10.0760, device='cuda:0') tensor(1.8086, device='cuda:0') tensor(-2.5627e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.013498
Average KL loss: 0.085632
Average total loss: 0.099130
tensor(-10.0782, device='cuda:0') tensor(1.8066, device='cuda:0') tensor(-1.0642e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.012532
Average KL loss: 0.085631
Average total loss: 0.098163
tensor(-10.0804, device='cuda:0') tensor(1.8046, device='cuda:0') tensor(-1.7117e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.013762
Average KL loss: 0.085630
Average total loss: 0.099392
tensor(-10.0826, device='cuda:0') tensor(1.8027, device='cuda:0') tensor(-1.2841e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.012902
Average KL loss: 0.085629
Average total loss: 0.098532
tensor(-10.0848, device='cuda:0') tensor(1.8008, device='cuda:0') tensor(-1.2083e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.012855
Average KL loss: 0.085629
Average total loss: 0.098484
tensor(-10.0869, device='cuda:0') tensor(1.7990, device='cuda:0') tensor(-1.4201e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.013310
Average KL loss: 0.085629
Average total loss: 0.098939
tensor(-10.0891, device='cuda:0') tensor(1.7973, device='cuda:0') tensor(-1.2535e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.012359
Average KL loss: 0.085630
Average total loss: 0.097989
tensor(-10.0912, device='cuda:0') tensor(1.7956, device='cuda:0') tensor(-2.0073e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.012732
Average KL loss: 0.085630
Average total loss: 0.098362
tensor(-10.0934, device='cuda:0') tensor(1.7939, device='cuda:0') tensor(-1.7863e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.012501
Average KL loss: 0.085629
Average total loss: 0.098130
tensor(-10.0955, device='cuda:0') tensor(1.7922, device='cuda:0') tensor(-1.3249e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.012383
Average KL loss: 0.085626
Average total loss: 0.098009
tensor(-10.0976, device='cuda:0') tensor(1.7906, device='cuda:0') tensor(-1.8193e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.012054
Average KL loss: 0.085626
Average total loss: 0.097681
tensor(-10.0998, device='cuda:0') tensor(1.7890, device='cuda:0') tensor(-1.3020e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.012489
Average KL loss: 0.085627
Average total loss: 0.098116
tensor(-10.1019, device='cuda:0') tensor(1.7875, device='cuda:0') tensor(-5.7688e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.012622
Average KL loss: 0.085627
Average total loss: 0.098249
tensor(-10.1040, device='cuda:0') tensor(1.7861, device='cuda:0') tensor(-1.3226e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.012092
Average KL loss: 0.085625
Average total loss: 0.097717
tensor(-10.1061, device='cuda:0') tensor(1.7847, device='cuda:0') tensor(-2.1038e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.011275
Average KL loss: 0.085625
Average total loss: 0.096899
tensor(-10.1082, device='cuda:0') tensor(1.7833, device='cuda:0') tensor(-3.2117e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.012769
Average KL loss: 0.085623
Average total loss: 0.098392
tensor(-10.1102, device='cuda:0') tensor(1.7819, device='cuda:0') tensor(-8.8754e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.012972
Average KL loss: 0.085622
Average total loss: 0.098594
tensor(-10.1123, device='cuda:0') tensor(1.7806, device='cuda:0') tensor(-2.1456e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.010910
Average KL loss: 0.085622
Average total loss: 0.096531
tensor(-10.1144, device='cuda:0') tensor(1.7794, device='cuda:0') tensor(-6.2411e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.012363
Average KL loss: 0.085620
Average total loss: 0.097984
tensor(-10.1164, device='cuda:0') tensor(1.7781, device='cuda:0') tensor(-2.5800e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.012536
Average KL loss: 0.085620
Average total loss: 0.098156
tensor(-10.1185, device='cuda:0') tensor(1.7770, device='cuda:0') tensor(-4.1301e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.011206
Average KL loss: 0.085619
Average total loss: 0.096825
tensor(-10.1205, device='cuda:0') tensor(1.7758, device='cuda:0') tensor(-3.0650e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.010332
Average KL loss: 0.085617
Average total loss: 0.095950
tensor(-10.1226, device='cuda:0') tensor(1.7746, device='cuda:0') tensor(-1.9539e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.011558
Average KL loss: 0.085616
Average total loss: 0.097174
tensor(-10.1246, device='cuda:0') tensor(1.7735, device='cuda:0') tensor(-1.0585e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.010991
Average KL loss: 0.085615
Average total loss: 0.096607
tensor(-10.1266, device='cuda:0') tensor(1.7725, device='cuda:0') tensor(-2.2853e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.011064
Average KL loss: 0.085616
Average total loss: 0.096680
tensor(-10.1286, device='cuda:0') tensor(1.7715, device='cuda:0') tensor(-1.6727e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.010798
Average KL loss: 0.085616
Average total loss: 0.096414
tensor(-10.1306, device='cuda:0') tensor(1.7705, device='cuda:0') tensor(-5.5186e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.009895
Average KL loss: 0.085615
Average total loss: 0.095509
tensor(-10.1326, device='cuda:0') tensor(1.7694, device='cuda:0') tensor(-1.1964e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.009680
Average KL loss: 0.085613
Average total loss: 0.095293
tensor(-10.1346, device='cuda:0') tensor(1.7684, device='cuda:0') tensor(-1.2476e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.010158
Average KL loss: 0.085612
Average total loss: 0.095770
tensor(-10.1366, device='cuda:0') tensor(1.7675, device='cuda:0') tensor(-9.8776e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.010027
Average KL loss: 0.085612
Average total loss: 0.095639
tensor(-10.1386, device='cuda:0') tensor(1.7665, device='cuda:0') tensor(-1.5812e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.009475
Average KL loss: 0.085610
Average total loss: 0.095085
tensor(-10.1406, device='cuda:0') tensor(1.7656, device='cuda:0') tensor(-1.8828e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.010248
Average KL loss: 0.085606
Average total loss: 0.095855
tensor(-10.1426, device='cuda:0') tensor(1.7647, device='cuda:0') tensor(-1.1731e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.009701
Average KL loss: 0.085604
Average total loss: 0.095306
tensor(-10.1445, device='cuda:0') tensor(1.7638, device='cuda:0') tensor(-7.9385e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.009830
Average KL loss: 0.085603
Average total loss: 0.095432
tensor(-10.1465, device='cuda:0') tensor(1.7630, device='cuda:0') tensor(-1.7046e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.009755
Average KL loss: 0.085603
Average total loss: 0.095357
tensor(-10.1484, device='cuda:0') tensor(1.7623, device='cuda:0') tensor(-6.1891e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.009298
Average KL loss: 0.085602
Average total loss: 0.094900
tensor(-10.1504, device='cuda:0') tensor(1.7615, device='cuda:0') tensor(-1.0831e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.009511
Average KL loss: 0.085599
Average total loss: 0.095110
tensor(-10.1523, device='cuda:0') tensor(1.7607, device='cuda:0') tensor(-2.0033e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.009169
Average KL loss: 0.085596
Average total loss: 0.094766
tensor(-10.1543, device='cuda:0') tensor(1.7600, device='cuda:0') tensor(-9.9584e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.008986
Average KL loss: 0.085594
Average total loss: 0.094580
tensor(-10.1562, device='cuda:0') tensor(1.7592, device='cuda:0') tensor(-2.7151e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.009816
Average KL loss: 0.085593
Average total loss: 0.095409
tensor(-10.1581, device='cuda:0') tensor(1.7586, device='cuda:0') tensor(-1.5195e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.008405
Average KL loss: 0.085591
Average total loss: 0.093996
tensor(-10.1600, device='cuda:0') tensor(1.7578, device='cuda:0') tensor(-1.7187e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.008527
Average KL loss: 0.085588
Average total loss: 0.094115
tensor(-10.1619, device='cuda:0') tensor(1.7572, device='cuda:0') tensor(-1.0508e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.009472
Average KL loss: 0.085586
Average total loss: 0.095058
tensor(-10.1639, device='cuda:0') tensor(1.7566, device='cuda:0') tensor(-3.9164e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.009731
Average KL loss: 0.085586
Average total loss: 0.095317
tensor(-10.1657, device='cuda:0') tensor(1.7561, device='cuda:0') tensor(-1.4214e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.008243
Average KL loss: 0.085585
Average total loss: 0.093828
tensor(-10.1676, device='cuda:0') tensor(1.7555, device='cuda:0') tensor(-1.5852e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.008592
Average KL loss: 0.085583
Average total loss: 0.094175
tensor(-10.1695, device='cuda:0') tensor(1.7549, device='cuda:0') tensor(-1.4877e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.008530
Average KL loss: 0.085581
Average total loss: 0.094110
tensor(-10.1714, device='cuda:0') tensor(1.7544, device='cuda:0') tensor(-2.9615e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.008144
Average KL loss: 0.085577
Average total loss: 0.093721
tensor(-10.1733, device='cuda:0') tensor(1.7538, device='cuda:0') tensor(-5.1801e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.008527
Average KL loss: 0.085573
Average total loss: 0.094100
tensor(-10.1752, device='cuda:0') tensor(1.7533, device='cuda:0') tensor(-1.4455e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.008911
Average KL loss: 0.085572
Average total loss: 0.094483
tensor(-10.1770, device='cuda:0') tensor(1.7528, device='cuda:0') tensor(-6.1017e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.008626
Average KL loss: 0.085570
Average total loss: 0.094196
tensor(-10.1789, device='cuda:0') tensor(1.7523, device='cuda:0') tensor(-5.8779e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.007822
Average KL loss: 0.085566
Average total loss: 0.093389
tensor(-10.1808, device='cuda:0') tensor(1.7518, device='cuda:0') tensor(-9.2241e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.008480
Average KL loss: 0.085563
Average total loss: 0.094043
tensor(-10.1826, device='cuda:0') tensor(1.7514, device='cuda:0') tensor(-5.4847e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.008192
Average KL loss: 0.085562
Average total loss: 0.093754
tensor(-10.1845, device='cuda:0') tensor(1.7510, device='cuda:0') tensor(-1.3816e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.007914
Average KL loss: 0.085559
Average total loss: 0.093473
tensor(-10.1863, device='cuda:0') tensor(1.7505, device='cuda:0') tensor(-6.0447e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.007699
Average KL loss: 0.085556
Average total loss: 0.093255
tensor(-10.1881, device='cuda:0') tensor(1.7501, device='cuda:0') tensor(-1.2199e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.007635
Average KL loss: 0.085552
Average total loss: 0.093187
tensor(-10.1900, device='cuda:0') tensor(1.7497, device='cuda:0') tensor(-4.4618e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.007394
Average KL loss: 0.085548
Average total loss: 0.092942
tensor(-10.1918, device='cuda:0') tensor(1.7492, device='cuda:0') tensor(-5.4734e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.007578
Average KL loss: 0.085544
Average total loss: 0.093122
tensor(-10.1936, device='cuda:0') tensor(1.7489, device='cuda:0') tensor(-5.1349e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.007180
Average KL loss: 0.085540
Average total loss: 0.092720
tensor(-10.1954, device='cuda:0') tensor(1.7485, device='cuda:0') tensor(-5.4057e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.007871
Average KL loss: 0.085537
Average total loss: 0.093408
tensor(-10.1972, device='cuda:0') tensor(1.7483, device='cuda:0') tensor(-1.1183e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.007346
Average KL loss: 0.085534
Average total loss: 0.092880
tensor(-10.1990, device='cuda:0') tensor(1.7480, device='cuda:0') tensor(-3.7341e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.007084
Average KL loss: 0.085529
Average total loss: 0.092613
tensor(-10.2008, device='cuda:0') tensor(1.7477, device='cuda:0') tensor(-2.0678e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.007506
Average KL loss: 0.085525
Average total loss: 0.093031
tensor(-10.2026, device='cuda:0') tensor(1.7474, device='cuda:0') tensor(-5.7445e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.007458
Average KL loss: 0.085521
Average total loss: 0.092979
tensor(-10.2044, device='cuda:0') tensor(1.7471, device='cuda:0') tensor(-7.2341e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.007275
Average KL loss: 0.085517
Average total loss: 0.092792
tensor(-10.2062, device='cuda:0') tensor(1.7469, device='cuda:0') tensor(-1.2416e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.007717
Average KL loss: 0.085511
Average total loss: 0.093228
tensor(-10.2080, device='cuda:0') tensor(1.7468, device='cuda:0') tensor(-1.0577e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.007094
Average KL loss: 0.085506
Average total loss: 0.092600
tensor(-10.2098, device='cuda:0') tensor(1.7464, device='cuda:0') tensor(-7.2729e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.007029
Average KL loss: 0.085500
Average total loss: 0.092529
tensor(-10.2116, device='cuda:0') tensor(1.7462, device='cuda:0') tensor(-7.0143e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.006804
Average KL loss: 0.085496
Average total loss: 0.092299
tensor(-10.2133, device='cuda:0') tensor(1.7460, device='cuda:0') tensor(5.9885e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.007151
Average KL loss: 0.085491
Average total loss: 0.092642
tensor(-10.2151, device='cuda:0') tensor(1.7458, device='cuda:0') tensor(-9.6595e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.006977
Average KL loss: 0.085486
Average total loss: 0.092463
tensor(-10.2169, device='cuda:0') tensor(1.7456, device='cuda:0') tensor(-1.3134e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.006987
Average KL loss: 0.085480
Average total loss: 0.092467
tensor(-10.2186, device='cuda:0') tensor(1.7454, device='cuda:0') tensor(-1.4449e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.007296
Average KL loss: 0.085476
Average total loss: 0.092772
tensor(-10.2204, device='cuda:0') tensor(1.7453, device='cuda:0') tensor(-4.8774e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.006639
Average KL loss: 0.085471
Average total loss: 0.092110
tensor(-10.2221, device='cuda:0') tensor(1.7451, device='cuda:0') tensor(-8.5265e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.006734
Average KL loss: 0.085464
Average total loss: 0.092198
tensor(-10.2238, device='cuda:0') tensor(1.7449, device='cuda:0') tensor(-6.8731e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.006443
Average KL loss: 0.085458
Average total loss: 0.091901
tensor(-10.2256, device='cuda:0') tensor(1.7448, device='cuda:0') tensor(-3.3961e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.006488
Average KL loss: 0.085452
Average total loss: 0.091941
tensor(-10.2273, device='cuda:0') tensor(1.7447, device='cuda:0') tensor(-8.5877e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.006979
Average KL loss: 0.085447
Average total loss: 0.092426
tensor(-10.2290, device='cuda:0') tensor(1.7446, device='cuda:0') tensor(-1.9722e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.006646
Average KL loss: 0.085440
Average total loss: 0.092085
tensor(-10.2308, device='cuda:0') tensor(1.7445, device='cuda:0') tensor(-4.0400e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.006479
Average KL loss: 0.085434
Average total loss: 0.091913
tensor(-10.2325, device='cuda:0') tensor(1.7444, device='cuda:0') tensor(-3.6001e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.006399
Average KL loss: 0.085428
Average total loss: 0.091828
tensor(-10.2342, device='cuda:0') tensor(1.7443, device='cuda:0') tensor(-6.2571e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.006729
Average KL loss: 0.085423
Average total loss: 0.092152
tensor(-10.2359, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-1.3322e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.006593
Average KL loss: 0.085418
Average total loss: 0.092012
tensor(-10.2376, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-1.1097e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.006786
Average KL loss: 0.085413
Average total loss: 0.092199
tensor(-10.2393, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-5.0788e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.006429
Average KL loss: 0.085410
Average total loss: 0.091839
tensor(-10.2410, device='cuda:0') tensor(1.7443, device='cuda:0') tensor(-5.4928e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.006737
Average KL loss: 0.085405
Average total loss: 0.092142
tensor(-10.2427, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-1.6003e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.006390
Average KL loss: 0.085397
Average total loss: 0.091787
tensor(-10.2444, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-1.1235e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.005846
Average KL loss: 0.085391
Average total loss: 0.091237
tensor(-10.2461, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-6.6295e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.005581
Average KL loss: 0.085385
Average total loss: 0.090966
tensor(-10.2478, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-1.2189e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.006224
Average KL loss: 0.085379
Average total loss: 0.091602
tensor(-10.2494, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-3.2503e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.005764
Average KL loss: 0.085372
Average total loss: 0.091135
tensor(-10.2511, device='cuda:0') tensor(1.7441, device='cuda:0') tensor(-1.1412e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.005917
Average KL loss: 0.085364
Average total loss: 0.091281
tensor(-10.2528, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-2.4377e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.005926
Average KL loss: 0.085357
Average total loss: 0.091283
tensor(-10.2544, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-3.5401e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.005972
Average KL loss: 0.085352
Average total loss: 0.091323
tensor(-10.2561, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-9.6473e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.005634
Average KL loss: 0.085345
Average total loss: 0.090979
tensor(-10.2578, device='cuda:0') tensor(1.7442, device='cuda:0') tensor(-9.2383e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.006103
Average KL loss: 0.085338
Average total loss: 0.091441
tensor(-10.2594, device='cuda:0') tensor(1.7443, device='cuda:0') tensor(-9.9196e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.005611
Average KL loss: 0.085331
Average total loss: 0.090942
tensor(-10.2611, device='cuda:0') tensor(1.7443, device='cuda:0') tensor(-1.1019e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.005990
Average KL loss: 0.085323
Average total loss: 0.091313
tensor(-10.2627, device='cuda:0') tensor(1.7443, device='cuda:0') tensor(9.0392e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.005496
Average KL loss: 0.085315
Average total loss: 0.090811
tensor(-10.2644, device='cuda:0') tensor(1.7443, device='cuda:0') tensor(-9.0879e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.005387
Average KL loss: 0.085309
Average total loss: 0.090696
tensor(-10.2660, device='cuda:0') tensor(1.7443, device='cuda:0') tensor(-1.3649e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.005608
Average KL loss: 0.085301
Average total loss: 0.090909
tensor(-10.2676, device='cuda:0') tensor(1.7444, device='cuda:0') tensor(-3.1762e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.005383
Average KL loss: 0.085292
Average total loss: 0.090675
tensor(-10.2693, device='cuda:0') tensor(1.7445, device='cuda:0') tensor(-8.7148e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.005428
Average KL loss: 0.085285
Average total loss: 0.090713
tensor(-10.2709, device='cuda:0') tensor(1.7445, device='cuda:0') tensor(2.3007e-11, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.005349
Average KL loss: 0.085277
Average total loss: 0.090626
tensor(-10.2725, device='cuda:0') tensor(1.7446, device='cuda:0') tensor(-7.4049e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.005217
Average KL loss: 0.085272
Average total loss: 0.090489
tensor(-10.2742, device='cuda:0') tensor(1.7448, device='cuda:0') tensor(-4.4490e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.005220
Average KL loss: 0.085265
Average total loss: 0.090485
tensor(-10.2758, device='cuda:0') tensor(1.7448, device='cuda:0') tensor(-8.8789e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.005462
Average KL loss: 0.085258
Average total loss: 0.090719
tensor(-10.2774, device='cuda:0') tensor(1.7449, device='cuda:0') tensor(-2.8257e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.004788
Average KL loss: 0.085250
Average total loss: 0.090038
tensor(-10.2790, device='cuda:0') tensor(1.7450, device='cuda:0') tensor(-1.5276e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.005170
Average KL loss: 0.085241
Average total loss: 0.090411
tensor(-10.2806, device='cuda:0') tensor(1.7450, device='cuda:0') tensor(7.3828e-11, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.006072
Average KL loss: 0.085234
Average total loss: 0.091306
tensor(-10.2822, device='cuda:0') tensor(1.7453, device='cuda:0') tensor(-1.0928e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.005472
Average KL loss: 0.085229
Average total loss: 0.090701
tensor(-10.2838, device='cuda:0') tensor(1.7455, device='cuda:0') tensor(-2.4111e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.005394
Average KL loss: 0.085221
Average total loss: 0.090615
tensor(-10.2854, device='cuda:0') tensor(1.7457, device='cuda:0') tensor(-3.8575e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.005023
Average KL loss: 0.085212
Average total loss: 0.090235
tensor(-10.2870, device='cuda:0') tensor(1.7458, device='cuda:0') tensor(-6.2630e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.004732
Average KL loss: 0.085204
Average total loss: 0.089936
tensor(-10.2886, device='cuda:0') tensor(1.7460, device='cuda:0') tensor(-6.3635e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.005075
Average KL loss: 0.085197
Average total loss: 0.090272
tensor(-10.2902, device='cuda:0') tensor(1.7461, device='cuda:0') tensor(-5.8424e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.004882
Average KL loss: 0.085189
Average total loss: 0.090071
tensor(-10.2917, device='cuda:0') tensor(1.7463, device='cuda:0') tensor(-8.2071e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.004893
Average KL loss: 0.085180
Average total loss: 0.090073
tensor(-10.2933, device='cuda:0') tensor(1.7464, device='cuda:0') tensor(-3.3816e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.005422
Average KL loss: 0.085169
Average total loss: 0.090591
tensor(-10.2949, device='cuda:0') tensor(1.7466, device='cuda:0') tensor(-5.0207e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.005379
Average KL loss: 0.085160
Average total loss: 0.090539
tensor(-10.2965, device='cuda:0') tensor(1.7468, device='cuda:0') tensor(-4.7635e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.004422
Average KL loss: 0.085151
Average total loss: 0.089573
tensor(-10.2980, device='cuda:0') tensor(1.7469, device='cuda:0') tensor(-8.1995e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.004955
Average KL loss: 0.085142
Average total loss: 0.090097
tensor(-10.2996, device='cuda:0') tensor(1.7471, device='cuda:0') tensor(-5.9970e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.004653
Average KL loss: 0.085133
Average total loss: 0.089786
tensor(-10.3012, device='cuda:0') tensor(1.7472, device='cuda:0') tensor(-2.0215e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.005052
Average KL loss: 0.085126
Average total loss: 0.090177
tensor(-10.3027, device='cuda:0') tensor(1.7475, device='cuda:0') tensor(-2.4601e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.004956
Average KL loss: 0.085119
Average total loss: 0.090075
tensor(-10.3043, device='cuda:0') tensor(1.7477, device='cuda:0') tensor(-8.7927e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.005176
Average KL loss: 0.085111
Average total loss: 0.090288
tensor(-10.3058, device='cuda:0') tensor(1.7480, device='cuda:0') tensor(-2.3222e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.004824
Average KL loss: 0.085103
Average total loss: 0.089927
tensor(-10.3074, device='cuda:0') tensor(1.7483, device='cuda:0') tensor(-3.1381e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.004482
Average KL loss: 0.085095
Average total loss: 0.089577
 Percentile value: 5.846817398071289
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     882 /    1728             ( 51.04%) | total_pruned =     846 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     552 /   36864             (  1.50%) | total_pruned =   36312 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     623 /   36864             (  1.69%) | total_pruned =   36241 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     555 /   36864             (  1.51%) | total_pruned =   36309 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     552 /   36864             (  1.50%) | total_pruned =   36312 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     801 /   73728             (  1.09%) | total_pruned =   72927 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1196 /  147456             (  0.81%) | total_pruned =  146260 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1183 /    8192             ( 14.44%) | total_pruned =    7009 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     566 /  147456             (  0.38%) | total_pruned =  146890 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     562 /  147456             (  0.38%) | total_pruned =  146894 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1958 /  294912             (  0.66%) | total_pruned =  292954 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     184 /     256             ( 71.88%) | total_pruned =      72 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2398 /  589824             (  0.41%) | total_pruned =  587426 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1751 /   32768             (  5.34%) | total_pruned =   31017 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      85 /     256             ( 33.20%) | total_pruned =     171 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     697 /  589824             (  0.12%) | total_pruned =  589127 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      92 /     256             ( 35.94%) | total_pruned =     164 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     632 /  589824             (  0.11%) | total_pruned =  589192 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2278 / 1179648             (  0.19%) | total_pruned = 1177370 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     286 /     512             ( 55.86%) | total_pruned =     226 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1106 / 2359296             (  0.05%) | total_pruned = 2358190 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      56 /     512             ( 10.94%) | total_pruned =     456 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     804 /  131072             (  0.61%) | total_pruned =  130268 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     419 /     512             ( 81.84%) | total_pruned =      93 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      51 /     512             (  9.96%) | total_pruned =     461 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     566 / 2359296             (  0.02%) | total_pruned = 2358730 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     135 / 2359296             (  0.01%) | total_pruned = 2359161 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     402 /     512             ( 78.52%) | total_pruned =     110 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
linear.weight        | nonzeros =    2007 /    5120             ( 39.20%) | total_pruned =    3113 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 199/200 Loss: 0.119610 Accuracy: 70.92 98.91 % Best test Accuracy: 73.59%
tensor(-10.3089, device='cuda:0') tensor(1.7485, device='cuda:0') tensor(-1.3623e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.266324
Average KL loss: 0.084256
Average total loss: 0.350580
tensor(-10.3129, device='cuda:0') tensor(1.6859, device='cuda:0') tensor(-1.5350e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.274445
Average KL loss: 0.082078
Average total loss: 0.356523
tensor(-10.3171, device='cuda:0') tensor(1.6184, device='cuda:0') tensor(-1.4023e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.268248
Average KL loss: 0.078813
Average total loss: 0.347061
tensor(-10.3217, device='cuda:0') tensor(1.5420, device='cuda:0') tensor(-2.3533e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.266837
Average KL loss: 0.073910
Average total loss: 0.340747
tensor(-10.3269, device='cuda:0') tensor(1.4573, device='cuda:0') tensor(-9.4874e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.269662
Average KL loss: 0.066939
Average total loss: 0.336601
tensor(-10.3324, device='cuda:0') tensor(1.3686, device='cuda:0') tensor(-1.4141e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.271509
Average KL loss: 0.058184
Average total loss: 0.329693
tensor(-10.3379, device='cuda:0') tensor(1.2844, device='cuda:0') tensor(-1.6603e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.261265
Average KL loss: 0.049132
Average total loss: 0.310397
tensor(-10.3430, device='cuda:0') tensor(1.2134, device='cuda:0') tensor(-1.3099e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.259128
Average KL loss: 0.041811
Average total loss: 0.300939
tensor(-10.3474, device='cuda:0') tensor(1.1592, device='cuda:0') tensor(-1.2026e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.262827
Average KL loss: 0.037051
Average total loss: 0.299879
tensor(-10.3512, device='cuda:0') tensor(1.1191, device='cuda:0') tensor(-1.8524e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.248875
Average KL loss: 0.034178
Average total loss: 0.283053
tensor(-10.3545, device='cuda:0') tensor(1.0886, device='cuda:0') tensor(-1.6912e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.252257
Average KL loss: 0.032358
Average total loss: 0.284615
tensor(-10.3576, device='cuda:0') tensor(1.0643, device='cuda:0') tensor(-1.3445e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.235558
Average KL loss: 0.031122
Average total loss: 0.266679
tensor(-10.3603, device='cuda:0') tensor(1.0442, device='cuda:0') tensor(-1.0472e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.235783
Average KL loss: 0.030232
Average total loss: 0.266015
tensor(-10.3630, device='cuda:0') tensor(1.0272, device='cuda:0') tensor(-9.6073e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.238049
Average KL loss: 0.029562
Average total loss: 0.267612
tensor(-10.3655, device='cuda:0') tensor(1.0125, device='cuda:0') tensor(-1.4987e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.236443
Average KL loss: 0.029045
Average total loss: 0.265488
tensor(-10.3678, device='cuda:0') tensor(0.9996, device='cuda:0') tensor(-2.0517e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.233394
Average KL loss: 0.028635
Average total loss: 0.262029
tensor(-10.3701, device='cuda:0') tensor(0.9881, device='cuda:0') tensor(-1.2551e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.234328
Average KL loss: 0.028301
Average total loss: 0.262629
tensor(-10.3724, device='cuda:0') tensor(0.9778, device='cuda:0') tensor(-8.0647e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.229901
Average KL loss: 0.028024
Average total loss: 0.257925
tensor(-10.3746, device='cuda:0') tensor(0.9685, device='cuda:0') tensor(-1.3167e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.224351
Average KL loss: 0.027791
Average total loss: 0.252141
tensor(-10.3767, device='cuda:0') tensor(0.9599, device='cuda:0') tensor(-2.0670e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.226002
Average KL loss: 0.027592
Average total loss: 0.253594
tensor(-10.3788, device='cuda:0') tensor(0.9521, device='cuda:0') tensor(-1.9557e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.218735
Average KL loss: 0.027422
Average total loss: 0.246158
tensor(-10.3808, device='cuda:0') tensor(0.9449, device='cuda:0') tensor(-1.9093e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.221516
Average KL loss: 0.027277
Average total loss: 0.248793
tensor(-10.3828, device='cuda:0') tensor(0.9381, device='cuda:0') tensor(-1.8469e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.227972
Average KL loss: 0.027147
Average total loss: 0.255119
tensor(-10.3848, device='cuda:0') tensor(0.9318, device='cuda:0') tensor(-1.0633e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.220367
Average KL loss: 0.027031
Average total loss: 0.247398
tensor(-10.3868, device='cuda:0') tensor(0.9258, device='cuda:0') tensor(-1.1636e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.211908
Average KL loss: 0.026928
Average total loss: 0.238836
tensor(-10.3887, device='cuda:0') tensor(0.9203, device='cuda:0') tensor(-1.1532e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.206307
Average KL loss: 0.026835
Average total loss: 0.233143
tensor(-10.3906, device='cuda:0') tensor(0.9151, device='cuda:0') tensor(-9.0597e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.204130
Average KL loss: 0.026751
Average total loss: 0.230881
tensor(-10.3925, device='cuda:0') tensor(0.9102, device='cuda:0') tensor(-7.4819e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.206512
Average KL loss: 0.026674
Average total loss: 0.233186
tensor(-10.3943, device='cuda:0') tensor(0.9055, device='cuda:0') tensor(-1.5363e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.207382
Average KL loss: 0.026605
Average total loss: 0.233987
tensor(-10.3962, device='cuda:0') tensor(0.9011, device='cuda:0') tensor(-1.1355e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.204930
Average KL loss: 0.026544
Average total loss: 0.231474
tensor(-10.3980, device='cuda:0') tensor(0.8969, device='cuda:0') tensor(-1.4783e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.202371
Average KL loss: 0.026487
Average total loss: 0.228858
tensor(-10.3998, device='cuda:0') tensor(0.8930, device='cuda:0') tensor(-1.1394e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.204775
Average KL loss: 0.026434
Average total loss: 0.231209
tensor(-10.4016, device='cuda:0') tensor(0.8892, device='cuda:0') tensor(-1.2328e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.193754
Average KL loss: 0.026386
Average total loss: 0.220140
tensor(-10.4034, device='cuda:0') tensor(0.8856, device='cuda:0') tensor(-7.1604e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.199449
Average KL loss: 0.026342
Average total loss: 0.225791
tensor(-10.4052, device='cuda:0') tensor(0.8822, device='cuda:0') tensor(-8.8525e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.193205
Average KL loss: 0.026303
Average total loss: 0.219507
tensor(-10.4069, device='cuda:0') tensor(0.8789, device='cuda:0') tensor(-1.1593e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.197156
Average KL loss: 0.026266
Average total loss: 0.223422
tensor(-10.4087, device='cuda:0') tensor(0.8758, device='cuda:0') tensor(-1.3735e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.191373
Average KL loss: 0.026232
Average total loss: 0.217605
tensor(-10.4104, device='cuda:0') tensor(0.8729, device='cuda:0') tensor(-6.7331e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.194172
Average KL loss: 0.026202
Average total loss: 0.220375
tensor(-10.4121, device='cuda:0') tensor(0.8700, device='cuda:0') tensor(-8.8750e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.187541
Average KL loss: 0.026176
Average total loss: 0.213716
tensor(-10.4138, device='cuda:0') tensor(0.8673, device='cuda:0') tensor(-1.2485e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.192716
Average KL loss: 0.026152
Average total loss: 0.218868
tensor(-10.4156, device='cuda:0') tensor(0.8646, device='cuda:0') tensor(-8.5899e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.181773
Average KL loss: 0.026130
Average total loss: 0.207903
tensor(-10.4172, device='cuda:0') tensor(0.8621, device='cuda:0') tensor(-4.9913e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.185705
Average KL loss: 0.026109
Average total loss: 0.211815
tensor(-10.4189, device='cuda:0') tensor(0.8596, device='cuda:0') tensor(-1.5159e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.196534
Average KL loss: 0.026089
Average total loss: 0.222624
tensor(-10.4206, device='cuda:0') tensor(0.8572, device='cuda:0') tensor(-6.2618e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.181591
Average KL loss: 0.026070
Average total loss: 0.207661
tensor(-10.4223, device='cuda:0') tensor(0.8549, device='cuda:0') tensor(-6.3401e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.177400
Average KL loss: 0.026051
Average total loss: 0.203451
tensor(-10.4240, device='cuda:0') tensor(0.8527, device='cuda:0') tensor(-2.6386e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.179781
Average KL loss: 0.026035
Average total loss: 0.205816
tensor(-10.4256, device='cuda:0') tensor(0.8506, device='cuda:0') tensor(-9.4833e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.189941
Average KL loss: 0.026020
Average total loss: 0.215961
tensor(-10.4273, device='cuda:0') tensor(0.8485, device='cuda:0') tensor(-7.9309e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.183556
Average KL loss: 0.026006
Average total loss: 0.209562
tensor(-10.4289, device='cuda:0') tensor(0.8465, device='cuda:0') tensor(-1.1549e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.174625
Average KL loss: 0.025991
Average total loss: 0.200616
tensor(-10.4305, device='cuda:0') tensor(0.8446, device='cuda:0') tensor(-1.3996e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.169716
Average KL loss: 0.025977
Average total loss: 0.195694
tensor(-10.4322, device='cuda:0') tensor(0.8427, device='cuda:0') tensor(-8.7705e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.180817
Average KL loss: 0.025964
Average total loss: 0.206781
tensor(-10.4338, device='cuda:0') tensor(0.8408, device='cuda:0') tensor(-1.4314e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.168933
Average KL loss: 0.025951
Average total loss: 0.194884
tensor(-10.4354, device='cuda:0') tensor(0.8390, device='cuda:0') tensor(-3.1540e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.168887
Average KL loss: 0.025938
Average total loss: 0.194825
tensor(-10.4370, device='cuda:0') tensor(0.8372, device='cuda:0') tensor(-5.3736e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.167672
Average KL loss: 0.025926
Average total loss: 0.193598
tensor(-10.4386, device='cuda:0') tensor(0.8356, device='cuda:0') tensor(-9.6177e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.170566
Average KL loss: 0.025914
Average total loss: 0.196481
tensor(-10.4402, device='cuda:0') tensor(0.8339, device='cuda:0') tensor(-7.3713e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.164517
Average KL loss: 0.025904
Average total loss: 0.190421
tensor(-10.4418, device='cuda:0') tensor(0.8323, device='cuda:0') tensor(-1.2728e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.162931
Average KL loss: 0.025894
Average total loss: 0.188825
tensor(-10.4434, device='cuda:0') tensor(0.8307, device='cuda:0') tensor(-9.5424e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.169233
Average KL loss: 0.025884
Average total loss: 0.195117
tensor(-10.4450, device='cuda:0') tensor(0.8292, device='cuda:0') tensor(-6.7337e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.168338
Average KL loss: 0.025875
Average total loss: 0.194214
tensor(-10.4466, device='cuda:0') tensor(0.8277, device='cuda:0') tensor(-9.8522e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.168147
Average KL loss: 0.025867
Average total loss: 0.194014
tensor(-10.4481, device='cuda:0') tensor(0.8264, device='cuda:0') tensor(-1.5348e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.164436
Average KL loss: 0.025859
Average total loss: 0.190295
tensor(-10.4497, device='cuda:0') tensor(0.8250, device='cuda:0') tensor(-1.1023e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.163596
Average KL loss: 0.025852
Average total loss: 0.189447
tensor(-10.4513, device='cuda:0') tensor(0.8236, device='cuda:0') tensor(-6.0323e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.162300
Average KL loss: 0.025844
Average total loss: 0.188144
tensor(-10.4528, device='cuda:0') tensor(0.8223, device='cuda:0') tensor(-6.3966e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.158107
Average KL loss: 0.025837
Average total loss: 0.183945
tensor(-10.4544, device='cuda:0') tensor(0.8211, device='cuda:0') tensor(-7.3041e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.160408
Average KL loss: 0.025831
Average total loss: 0.186239
tensor(-10.4559, device='cuda:0') tensor(0.8198, device='cuda:0') tensor(-6.8802e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.163179
Average KL loss: 0.025825
Average total loss: 0.189004
tensor(-10.4575, device='cuda:0') tensor(0.8186, device='cuda:0') tensor(-4.2293e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.160321
Average KL loss: 0.025819
Average total loss: 0.186141
tensor(-10.4590, device='cuda:0') tensor(0.8175, device='cuda:0') tensor(-3.8451e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.154082
Average KL loss: 0.025814
Average total loss: 0.179896
tensor(-10.4605, device='cuda:0') tensor(0.8163, device='cuda:0') tensor(-6.4576e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.154804
Average KL loss: 0.025808
Average total loss: 0.180613
tensor(-10.4621, device='cuda:0') tensor(0.8151, device='cuda:0') tensor(-7.7764e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.156449
Average KL loss: 0.025802
Average total loss: 0.182252
tensor(-10.4636, device='cuda:0') tensor(0.8141, device='cuda:0') tensor(-8.2982e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.150715
Average KL loss: 0.025797
Average total loss: 0.176512
tensor(-10.4651, device='cuda:0') tensor(0.8130, device='cuda:0') tensor(-5.8956e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.151836
Average KL loss: 0.025791
Average total loss: 0.177627
tensor(-10.4666, device='cuda:0') tensor(0.8119, device='cuda:0') tensor(-5.7241e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.155240
Average KL loss: 0.025786
Average total loss: 0.181026
tensor(-10.4681, device='cuda:0') tensor(0.8109, device='cuda:0') tensor(-4.2368e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.161521
Average KL loss: 0.025781
Average total loss: 0.187302
tensor(-10.4696, device='cuda:0') tensor(0.8099, device='cuda:0') tensor(-4.3609e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.147540
Average KL loss: 0.025777
Average total loss: 0.173317
tensor(-10.4712, device='cuda:0') tensor(0.8089, device='cuda:0') tensor(-5.4094e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.148175
Average KL loss: 0.025773
Average total loss: 0.173947
tensor(-10.4727, device='cuda:0') tensor(0.8080, device='cuda:0') tensor(-4.0981e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.148715
Average KL loss: 0.025768
Average total loss: 0.174483
tensor(-10.4742, device='cuda:0') tensor(0.8070, device='cuda:0') tensor(-1.2836e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.157207
Average KL loss: 0.025764
Average total loss: 0.182971
tensor(-10.4756, device='cuda:0') tensor(0.8061, device='cuda:0') tensor(-1.1031e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.149096
Average KL loss: 0.025760
Average total loss: 0.174855
tensor(-10.4771, device='cuda:0') tensor(0.8052, device='cuda:0') tensor(-1.0447e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.141462
Average KL loss: 0.025755
Average total loss: 0.167217
tensor(-10.4786, device='cuda:0') tensor(0.8044, device='cuda:0') tensor(-8.3450e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.150970
Average KL loss: 0.025751
Average total loss: 0.176722
tensor(-10.4801, device='cuda:0') tensor(0.8035, device='cuda:0') tensor(-3.5367e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.151252
Average KL loss: 0.025748
Average total loss: 0.177000
tensor(-10.4816, device='cuda:0') tensor(0.8028, device='cuda:0') tensor(-9.3383e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.143211
Average KL loss: 0.025745
Average total loss: 0.168956
tensor(-10.4831, device='cuda:0') tensor(0.8020, device='cuda:0') tensor(-6.7552e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.142579
Average KL loss: 0.025742
Average total loss: 0.168321
tensor(-10.4845, device='cuda:0') tensor(0.8012, device='cuda:0') tensor(-3.5625e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.140632
Average KL loss: 0.025738
Average total loss: 0.166370
tensor(-10.4860, device='cuda:0') tensor(0.8005, device='cuda:0') tensor(-8.9408e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.146835
Average KL loss: 0.025735
Average total loss: 0.172570
tensor(-10.4875, device='cuda:0') tensor(0.7998, device='cuda:0') tensor(-4.9424e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.150342
Average KL loss: 0.025732
Average total loss: 0.176074
tensor(-10.4889, device='cuda:0') tensor(0.7991, device='cuda:0') tensor(-6.3808e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.137815
Average KL loss: 0.025729
Average total loss: 0.163544
tensor(-10.4904, device='cuda:0') tensor(0.7984, device='cuda:0') tensor(-2.2479e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.140907
Average KL loss: 0.025727
Average total loss: 0.166633
tensor(-10.4918, device='cuda:0') tensor(0.7977, device='cuda:0') tensor(-6.1076e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.144357
Average KL loss: 0.025724
Average total loss: 0.170081
tensor(-10.4933, device='cuda:0') tensor(0.7971, device='cuda:0') tensor(-5.0750e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.141942
Average KL loss: 0.025721
Average total loss: 0.167663
tensor(-10.4947, device='cuda:0') tensor(0.7964, device='cuda:0') tensor(-5.0992e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.134713
Average KL loss: 0.025719
Average total loss: 0.160432
tensor(-10.4962, device='cuda:0') tensor(0.7958, device='cuda:0') tensor(-8.4451e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.143171
Average KL loss: 0.025716
Average total loss: 0.168888
tensor(-10.4976, device='cuda:0') tensor(0.7952, device='cuda:0') tensor(-9.8663e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.137047
Average KL loss: 0.025714
Average total loss: 0.162761
tensor(-10.4991, device='cuda:0') tensor(0.7946, device='cuda:0') tensor(-4.5355e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.138359
Average KL loss: 0.025711
Average total loss: 0.164070
tensor(-10.5005, device='cuda:0') tensor(0.7940, device='cuda:0') tensor(-6.8859e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.147403
Average KL loss: 0.025709
Average total loss: 0.173112
tensor(-10.5019, device='cuda:0') tensor(0.7934, device='cuda:0') tensor(-3.6070e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.133524
Average KL loss: 0.025707
Average total loss: 0.159231
tensor(-10.5034, device='cuda:0') tensor(0.7929, device='cuda:0') tensor(-9.1361e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.134330
Average KL loss: 0.025705
Average total loss: 0.160035
tensor(-10.5048, device='cuda:0') tensor(0.7923, device='cuda:0') tensor(-4.5947e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.137001
Average KL loss: 0.025703
Average total loss: 0.162704
tensor(-10.5062, device='cuda:0') tensor(0.7918, device='cuda:0') tensor(-5.1538e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.140618
Average KL loss: 0.025701
Average total loss: 0.166319
tensor(-10.5076, device='cuda:0') tensor(0.7913, device='cuda:0') tensor(-5.4933e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.140768
Average KL loss: 0.025699
Average total loss: 0.166467
tensor(-10.5090, device='cuda:0') tensor(0.7908, device='cuda:0') tensor(-7.2157e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.137164
Average KL loss: 0.025697
Average total loss: 0.162861
tensor(-10.5104, device='cuda:0') tensor(0.7904, device='cuda:0') tensor(-3.4263e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.140212
Average KL loss: 0.025695
Average total loss: 0.165907
tensor(-10.5119, device='cuda:0') tensor(0.7899, device='cuda:0') tensor(-2.4364e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.132680
Average KL loss: 0.025693
Average total loss: 0.158373
tensor(-10.5133, device='cuda:0') tensor(0.7894, device='cuda:0') tensor(-5.0145e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.135831
Average KL loss: 0.025692
Average total loss: 0.161523
tensor(-10.5147, device='cuda:0') tensor(0.7890, device='cuda:0') tensor(-4.9714e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.135511
Average KL loss: 0.025690
Average total loss: 0.161201
tensor(-10.5161, device='cuda:0') tensor(0.7885, device='cuda:0') tensor(-3.6304e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.131818
Average KL loss: 0.025688
Average total loss: 0.157507
tensor(-10.5175, device='cuda:0') tensor(0.7880, device='cuda:0') tensor(-9.2425e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.129938
Average KL loss: 0.025687
Average total loss: 0.155625
tensor(-10.5189, device='cuda:0') tensor(0.7876, device='cuda:0') tensor(-2.7303e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.132068
Average KL loss: 0.025685
Average total loss: 0.157753
tensor(-10.5203, device='cuda:0') tensor(0.7872, device='cuda:0') tensor(-5.2719e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.136848
Average KL loss: 0.025683
Average total loss: 0.162531
tensor(-10.5216, device='cuda:0') tensor(0.7868, device='cuda:0') tensor(-4.0547e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.128392
Average KL loss: 0.025682
Average total loss: 0.154073
tensor(-10.5230, device='cuda:0') tensor(0.7864, device='cuda:0') tensor(-4.1872e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.131142
Average KL loss: 0.025680
Average total loss: 0.156822
tensor(-10.5244, device='cuda:0') tensor(0.7861, device='cuda:0') tensor(-8.9433e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.129655
Average KL loss: 0.025679
Average total loss: 0.155333
tensor(-10.5258, device='cuda:0') tensor(0.7857, device='cuda:0') tensor(-4.3601e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.121300
Average KL loss: 0.025677
Average total loss: 0.146978
tensor(-10.5272, device='cuda:0') tensor(0.7854, device='cuda:0') tensor(-3.0389e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.131562
Average KL loss: 0.025676
Average total loss: 0.157237
tensor(-10.5285, device='cuda:0') tensor(0.7850, device='cuda:0') tensor(-8.0631e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.130808
Average KL loss: 0.025674
Average total loss: 0.156482
tensor(-10.5299, device='cuda:0') tensor(0.7846, device='cuda:0') tensor(-5.3770e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.125320
Average KL loss: 0.025672
Average total loss: 0.150992
tensor(-10.5313, device='cuda:0') tensor(0.7843, device='cuda:0') tensor(-3.7090e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.130259
Average KL loss: 0.025671
Average total loss: 0.155930
tensor(-10.5327, device='cuda:0') tensor(0.7840, device='cuda:0') tensor(-6.7287e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.128015
Average KL loss: 0.025669
Average total loss: 0.153684
tensor(-10.5340, device='cuda:0') tensor(0.7837, device='cuda:0') tensor(-8.3083e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.127183
Average KL loss: 0.025668
Average total loss: 0.152851
tensor(-10.5354, device='cuda:0') tensor(0.7834, device='cuda:0') tensor(-4.8752e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.119826
Average KL loss: 0.025667
Average total loss: 0.145493
tensor(-10.5368, device='cuda:0') tensor(0.7831, device='cuda:0') tensor(-2.4260e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.124962
Average KL loss: 0.025665
Average total loss: 0.150627
tensor(-10.5381, device='cuda:0') tensor(0.7828, device='cuda:0') tensor(-8.8729e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.128715
Average KL loss: 0.025664
Average total loss: 0.154380
tensor(-10.5395, device='cuda:0') tensor(0.7825, device='cuda:0') tensor(-1.5559e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.129283
Average KL loss: 0.025663
Average total loss: 0.154946
tensor(-10.5408, device='cuda:0') tensor(0.7823, device='cuda:0') tensor(-7.0184e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.122961
Average KL loss: 0.025662
Average total loss: 0.148623
tensor(-10.5422, device='cuda:0') tensor(0.7820, device='cuda:0') tensor(-6.3047e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.132687
Average KL loss: 0.025661
Average total loss: 0.158348
tensor(-10.5435, device='cuda:0') tensor(0.7818, device='cuda:0') tensor(-4.9222e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.130040
Average KL loss: 0.025660
Average total loss: 0.155700
tensor(-10.5449, device='cuda:0') tensor(0.7816, device='cuda:0') tensor(-3.1723e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.124829
Average KL loss: 0.025659
Average total loss: 0.150487
tensor(-10.5462, device='cuda:0') tensor(0.7813, device='cuda:0') tensor(-3.6779e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.130255
Average KL loss: 0.025657
Average total loss: 0.155912
tensor(-10.5475, device='cuda:0') tensor(0.7811, device='cuda:0') tensor(-1.6554e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.132028
Average KL loss: 0.025656
Average total loss: 0.157684
tensor(-10.5489, device='cuda:0') tensor(0.7809, device='cuda:0') tensor(-1.3191e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.117124
Average KL loss: 0.025655
Average total loss: 0.142779
tensor(-10.5502, device='cuda:0') tensor(0.7808, device='cuda:0') tensor(-2.4292e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.118038
Average KL loss: 0.025654
Average total loss: 0.143692
tensor(-10.5515, device='cuda:0') tensor(0.7805, device='cuda:0') tensor(-3.8503e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.128812
Average KL loss: 0.025653
Average total loss: 0.154465
tensor(-10.5529, device='cuda:0') tensor(0.7803, device='cuda:0') tensor(-1.5309e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.116707
Average KL loss: 0.025652
Average total loss: 0.142359
tensor(-10.5542, device='cuda:0') tensor(0.7801, device='cuda:0') tensor(-2.6297e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.123238
Average KL loss: 0.025651
Average total loss: 0.148889
tensor(-10.5555, device='cuda:0') tensor(0.7800, device='cuda:0') tensor(-1.6569e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.123045
Average KL loss: 0.025650
Average total loss: 0.148694
tensor(-10.5568, device='cuda:0') tensor(0.7799, device='cuda:0') tensor(-2.2893e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.121294
Average KL loss: 0.025648
Average total loss: 0.146942
tensor(-10.5581, device='cuda:0') tensor(0.7797, device='cuda:0') tensor(-2.6154e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.124629
Average KL loss: 0.025647
Average total loss: 0.150276
tensor(-10.5595, device='cuda:0') tensor(0.7795, device='cuda:0') tensor(-2.2820e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.126713
Average KL loss: 0.025646
Average total loss: 0.152359
tensor(-10.5608, device='cuda:0') tensor(0.7793, device='cuda:0') tensor(-3.4968e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.121107
Average KL loss: 0.025645
Average total loss: 0.146752
tensor(-10.5621, device='cuda:0') tensor(0.7792, device='cuda:0') tensor(-2.4327e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.119766
Average KL loss: 0.025644
Average total loss: 0.145410
tensor(-10.5634, device='cuda:0') tensor(0.7791, device='cuda:0') tensor(-2.1067e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.131386
Average KL loss: 0.025643
Average total loss: 0.157029
tensor(-10.5647, device='cuda:0') tensor(0.7790, device='cuda:0') tensor(-3.1366e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.118785
Average KL loss: 0.025641
Average total loss: 0.144427
tensor(-10.5660, device='cuda:0') tensor(0.7789, device='cuda:0') tensor(-9.2793e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.113942
Average KL loss: 0.025640
Average total loss: 0.139582
tensor(-10.5673, device='cuda:0') tensor(0.7787, device='cuda:0') tensor(-2.6875e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.111068
Average KL loss: 0.025639
Average total loss: 0.136707
tensor(-10.5686, device='cuda:0') tensor(0.7786, device='cuda:0') tensor(-2.1090e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.109456
Average KL loss: 0.025638
Average total loss: 0.135093
tensor(-10.5699, device='cuda:0') tensor(0.7785, device='cuda:0') tensor(-1.1657e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.120028
Average KL loss: 0.025637
Average total loss: 0.145665
tensor(-10.5712, device='cuda:0') tensor(0.7784, device='cuda:0') tensor(-2.1064e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.117333
Average KL loss: 0.025636
Average total loss: 0.142968
tensor(-10.5725, device='cuda:0') tensor(0.7784, device='cuda:0') tensor(-4.7214e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.112584
Average KL loss: 0.025635
Average total loss: 0.138219
tensor(-10.5738, device='cuda:0') tensor(0.7783, device='cuda:0') tensor(-1.6443e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.120921
Average KL loss: 0.025634
Average total loss: 0.146555
tensor(-10.5750, device='cuda:0') tensor(0.7782, device='cuda:0') tensor(-1.1223e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.112107
Average KL loss: 0.025633
Average total loss: 0.137740
tensor(-10.5763, device='cuda:0') tensor(0.7782, device='cuda:0') tensor(-3.3337e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.121709
Average KL loss: 0.025632
Average total loss: 0.147341
tensor(-10.5776, device='cuda:0') tensor(0.7781, device='cuda:0') tensor(-2.0335e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.114777
Average KL loss: 0.025631
Average total loss: 0.140408
tensor(-10.5789, device='cuda:0') tensor(0.7781, device='cuda:0') tensor(-1.6188e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.118895
Average KL loss: 0.025630
Average total loss: 0.144525
tensor(-10.5802, device='cuda:0') tensor(0.7780, device='cuda:0') tensor(-1.9839e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.121453
Average KL loss: 0.025629
Average total loss: 0.147082
tensor(-10.5814, device='cuda:0') tensor(0.7780, device='cuda:0') tensor(-3.0789e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.113797
Average KL loss: 0.025628
Average total loss: 0.139425
tensor(-10.5827, device='cuda:0') tensor(0.7779, device='cuda:0') tensor(-2.4142e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.118013
Average KL loss: 0.025627
Average total loss: 0.143639
tensor(-10.5840, device='cuda:0') tensor(0.7779, device='cuda:0') tensor(-1.4275e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.113715
Average KL loss: 0.025626
Average total loss: 0.139341
tensor(-10.5841, device='cuda:0') tensor(0.7779, device='cuda:0') tensor(-5.6036e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.115785
Average KL loss: 0.025626
Average total loss: 0.141411
tensor(-10.5842, device='cuda:0') tensor(0.7779, device='cuda:0') tensor(-2.9252e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.113271
Average KL loss: 0.025626
Average total loss: 0.138897
tensor(-10.5844, device='cuda:0') tensor(0.7779, device='cuda:0') tensor(-2.3645e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.120538
Average KL loss: 0.025626
Average total loss: 0.146164
tensor(-10.5845, device='cuda:0') tensor(0.7779, device='cuda:0') tensor(-5.6190e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.112123
Average KL loss: 0.025626
Average total loss: 0.137749
tensor(-10.5846, device='cuda:0') tensor(0.7779, device='cuda:0') tensor(-5.0310e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.115021
Average KL loss: 0.025626
Average total loss: 0.140646
tensor(-10.5847, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-1.3992e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.111355
Average KL loss: 0.025626
Average total loss: 0.136981
tensor(-10.5848, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-3.9110e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.126030
Average KL loss: 0.025626
Average total loss: 0.151655
tensor(-10.5850, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-3.3654e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.115916
Average KL loss: 0.025625
Average total loss: 0.141542
tensor(-10.5851, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.1165e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.115551
Average KL loss: 0.025625
Average total loss: 0.141176
tensor(-10.5852, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.0569e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.114187
Average KL loss: 0.025625
Average total loss: 0.139812
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-1.2220e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.116091
Average KL loss: 0.025625
Average total loss: 0.141716
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.3852e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.116659
Average KL loss: 0.025625
Average total loss: 0.142284
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-3.0322e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.108368
Average KL loss: 0.025625
Average total loss: 0.133993
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.7609e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.116850
Average KL loss: 0.025625
Average total loss: 0.142475
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-3.3958e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.106780
Average KL loss: 0.025625
Average total loss: 0.132405
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.4355e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.110362
Average KL loss: 0.025625
Average total loss: 0.135987
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-4.3632e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.115704
Average KL loss: 0.025625
Average total loss: 0.141329
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-7.0118e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.114138
Average KL loss: 0.025625
Average total loss: 0.139763
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-1.5436e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.110051
Average KL loss: 0.025625
Average total loss: 0.135676
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.1797e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.110037
Average KL loss: 0.025625
Average total loss: 0.135662
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-8.3059e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.114415
Average KL loss: 0.025625
Average total loss: 0.140040
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-4.0110e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.118528
Average KL loss: 0.025625
Average total loss: 0.144153
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-5.7630e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.113011
Average KL loss: 0.025625
Average total loss: 0.138636
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-3.5840e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.109531
Average KL loss: 0.025625
Average total loss: 0.135156
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.6703e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.113376
Average KL loss: 0.025625
Average total loss: 0.139001
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.8388e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.114883
Average KL loss: 0.025625
Average total loss: 0.140508
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.8602e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.119508
Average KL loss: 0.025625
Average total loss: 0.145133
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-3.1487e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.114302
Average KL loss: 0.025625
Average total loss: 0.139927
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.4816e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.113707
Average KL loss: 0.025625
Average total loss: 0.139332
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-4.6407e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.110324
Average KL loss: 0.025625
Average total loss: 0.135950
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.2014e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.109692
Average KL loss: 0.025625
Average total loss: 0.135317
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-3.0745e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.114112
Average KL loss: 0.025625
Average total loss: 0.139737
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-5.5892e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.116738
Average KL loss: 0.025625
Average total loss: 0.142363
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-3.2288e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.111470
Average KL loss: 0.025625
Average total loss: 0.137095
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.1368e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.113957
Average KL loss: 0.025625
Average total loss: 0.139582
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-5.7263e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.120139
Average KL loss: 0.025625
Average total loss: 0.145764
tensor(-10.5853, device='cuda:0') tensor(0.7778, device='cuda:0') tensor(-2.2761e-09, device='cuda:0')
 Percentile value: 7.898762178421021
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =     675 /    1728             ( 39.06%) | total_pruned =    1053 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     227 /   36864             (  0.62%) | total_pruned =   36637 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     261 /   36864             (  0.71%) | total_pruned =   36603 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     236 /   36864             (  0.64%) | total_pruned =   36628 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     214 /   36864             (  0.58%) | total_pruned =   36650 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     271 /   73728             (  0.37%) | total_pruned =   73457 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     319 /  147456             (  0.22%) | total_pruned =  147137 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     366 /    8192             (  4.47%) | total_pruned =    7826 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     167 /  147456             (  0.11%) | total_pruned =  147289 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     137 /  147456             (  0.09%) | total_pruned =  147319 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     359 /  294912             (  0.12%) | total_pruned =  294553 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     340 /  589824             (  0.06%) | total_pruned =  589484 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     287 /   32768             (  0.88%) | total_pruned =   32481 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     132 /  589824             (  0.02%) | total_pruned =  589692 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =      94 /  589824             (  0.02%) | total_pruned =  589730 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     203 / 1179648             (  0.02%) | total_pruned = 1179445 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      73 /     512             ( 14.26%) | total_pruned =     439 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     117 / 2359296             (  0.00%) | total_pruned = 2359179 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     273 /     512             ( 53.32%) | total_pruned =     239 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      73 /  131072             (  0.06%) | total_pruned =  130999 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     172 /     512             ( 33.59%) | total_pruned =     340 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      58 / 2359296             (  0.00%) | total_pruned = 2359238 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =       4 / 2359296             (  0.00%) | total_pruned = 2359292 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     502 /    5120             (  9.80%) | total_pruned =    4618 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 157/200 Loss: 1.148232 Accuracy: 56.42 61.39 % Best test Accuracy: 56.81%
