Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/7]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/200 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.807059
Average KL loss: 0.099185
Average total loss: 1.906244
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1158e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.536392
Average KL loss: 0.187266
Average total loss: 1.723659
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.5550e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.335482
Average KL loss: 0.203975
Average total loss: 1.539457
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.5427e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.212567
Average KL loss: 0.202521
Average total loss: 1.415087
tensor(0.0006, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.1285e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.129356
Average KL loss: 0.200126
Average total loss: 1.329483
tensor(0.0007, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-8.2994e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.053372
Average KL loss: 0.193159
Average total loss: 1.246531
tensor(0.0007, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-9.0651e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.990716
Average KL loss: 0.189515
Average total loss: 1.180231
tensor(0.0008, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-1.0346e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.936735
Average KL loss: 0.190883
Average total loss: 1.127618
tensor(0.0008, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-8.4514e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.867394
Average KL loss: 0.186818
Average total loss: 1.054212
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.5210e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.837765
Average KL loss: 0.183669
Average total loss: 1.021434
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.3236e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.803425
Average KL loss: 0.180601
Average total loss: 0.984025
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.5203e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.762233
Average KL loss: 0.181105
Average total loss: 0.943337
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.8003e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.725372
Average KL loss: 0.180500
Average total loss: 0.905872
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.2455e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.705688
Average KL loss: 0.179686
Average total loss: 0.885374
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.0426e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.676358
Average KL loss: 0.178742
Average total loss: 0.855100
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.2488e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.640558
Average KL loss: 0.178544
Average total loss: 0.819103
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.3782e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.606625
Average KL loss: 0.174541
Average total loss: 0.781166
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.9983e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.600385
Average KL loss: 0.175483
Average total loss: 0.775868
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0676e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.577382
Average KL loss: 0.176672
Average total loss: 0.754053
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.7464e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.558715
Average KL loss: 0.178658
Average total loss: 0.737373
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.1693e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.541920
Average KL loss: 0.177504
Average total loss: 0.719423
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0752e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.518534
Average KL loss: 0.178593
Average total loss: 0.697127
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.5057e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.506354
Average KL loss: 0.177409
Average total loss: 0.683763
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.3033e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.494398
Average KL loss: 0.179375
Average total loss: 0.673773
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.1493e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.476142
Average KL loss: 0.179700
Average total loss: 0.655842
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.1391e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.455866
Average KL loss: 0.178950
Average total loss: 0.634816
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.3682e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.450275
Average KL loss: 0.180364
Average total loss: 0.630638
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.0559e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.438472
Average KL loss: 0.181340
Average total loss: 0.619812
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.1282e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.428657
Average KL loss: 0.183476
Average total loss: 0.612133
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.1405e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.412652
Average KL loss: 0.184110
Average total loss: 0.596762
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.3505e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.411501
Average KL loss: 0.183051
Average total loss: 0.594552
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.9416e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.396269
Average KL loss: 0.185423
Average total loss: 0.581692
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.9326e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.382219
Average KL loss: 0.184027
Average total loss: 0.566246
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.2416e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.380810
Average KL loss: 0.185709
Average total loss: 0.566519
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.2523e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.380224
Average KL loss: 0.187513
Average total loss: 0.567737
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.7453e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.364830
Average KL loss: 0.188788
Average total loss: 0.553617
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.4571e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.365615
Average KL loss: 0.192358
Average total loss: 0.557973
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.9617e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.352055
Average KL loss: 0.192461
Average total loss: 0.544516
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.2759e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.349910
Average KL loss: 0.194233
Average total loss: 0.544143
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.6210e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.332771
Average KL loss: 0.191596
Average total loss: 0.524367
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.2670e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.322691
Average KL loss: 0.190435
Average total loss: 0.513126
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.0044e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.316701
Average KL loss: 0.192265
Average total loss: 0.508967
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.1508e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.309037
Average KL loss: 0.191794
Average total loss: 0.500831
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.1331e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.320648
Average KL loss: 0.195304
Average total loss: 0.515952
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.6913e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.307518
Average KL loss: 0.197531
Average total loss: 0.505049
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.8348e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.297495
Average KL loss: 0.195246
Average total loss: 0.492741
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.9455e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.307040
Average KL loss: 0.197189
Average total loss: 0.504229
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.2557e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.292938
Average KL loss: 0.200869
Average total loss: 0.493807
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.5634e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.277423
Average KL loss: 0.199692
Average total loss: 0.477115
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.6869e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.284466
Average KL loss: 0.200903
Average total loss: 0.485369
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.2269e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.276868
Average KL loss: 0.201698
Average total loss: 0.478566
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.1950e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.269127
Average KL loss: 0.203121
Average total loss: 0.472248
tensor(0.0015, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.7374e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.268780
Average KL loss: 0.202764
Average total loss: 0.471545
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.6602e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.266839
Average KL loss: 0.203028
Average total loss: 0.469867
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-7.5060e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.262231
Average KL loss: 0.203778
Average total loss: 0.466009
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.3536e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.258842
Average KL loss: 0.204688
Average total loss: 0.463530
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.5026e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.253502
Average KL loss: 0.205340
Average total loss: 0.458842
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.9029e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.255296
Average KL loss: 0.208157
Average total loss: 0.463453
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.4473e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.247212
Average KL loss: 0.207342
Average total loss: 0.454555
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.4583e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.240889
Average KL loss: 0.208367
Average total loss: 0.449256
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.1806e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.237087
Average KL loss: 0.207449
Average total loss: 0.444536
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.7222e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.236286
Average KL loss: 0.207388
Average total loss: 0.443674
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.0600e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.240660
Average KL loss: 0.211750
Average total loss: 0.452409
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2634e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.232147
Average KL loss: 0.210598
Average total loss: 0.442745
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.0407e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.224523
Average KL loss: 0.209690
Average total loss: 0.434213
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-8.1484e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.235560
Average KL loss: 0.211457
Average total loss: 0.447017
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.2632e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.217586
Average KL loss: 0.212457
Average total loss: 0.430043
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2295e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.225713
Average KL loss: 0.213914
Average total loss: 0.439627
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.6760e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.229061
Average KL loss: 0.213877
Average total loss: 0.442938
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.1710e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.219295
Average KL loss: 0.215570
Average total loss: 0.434865
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.7053e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.221248
Average KL loss: 0.215788
Average total loss: 0.437036
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.6463e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.217305
Average KL loss: 0.216244
Average total loss: 0.433549
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.4341e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.210955
Average KL loss: 0.215536
Average total loss: 0.426492
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-7.9265e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.216271
Average KL loss: 0.218344
Average total loss: 0.434615
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(3.7528e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.202925
Average KL loss: 0.216895
Average total loss: 0.419820
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.0934e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.212403
Average KL loss: 0.218813
Average total loss: 0.431216
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.0850e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.210299
Average KL loss: 0.220755
Average total loss: 0.431053
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.6704e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.205627
Average KL loss: 0.219302
Average total loss: 0.424929
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.9027e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.202450
Average KL loss: 0.221513
Average total loss: 0.423963
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.3602e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.198652
Average KL loss: 0.219973
Average total loss: 0.418625
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-8.6931e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.195221
Average KL loss: 0.219281
Average total loss: 0.414501
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.8131e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.198325
Average KL loss: 0.219646
Average total loss: 0.417971
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-6.4182e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.192492
Average KL loss: 0.219272
Average total loss: 0.411764
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-5.9062e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.196327
Average KL loss: 0.220652
Average total loss: 0.416979
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.3770e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.190611
Average KL loss: 0.222206
Average total loss: 0.412817
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-8.9424e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.197929
Average KL loss: 0.223260
Average total loss: 0.421189
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.7825e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.188567
Average KL loss: 0.222689
Average total loss: 0.411255
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.3350e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.185629
Average KL loss: 0.222791
Average total loss: 0.408420
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.6804e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.183710
Average KL loss: 0.221060
Average total loss: 0.404769
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-9.8454e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.188986
Average KL loss: 0.224582
Average total loss: 0.413568
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1714e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.187043
Average KL loss: 0.224000
Average total loss: 0.411043
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.0405e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.183116
Average KL loss: 0.225752
Average total loss: 0.408868
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(3.6225e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.187383
Average KL loss: 0.225236
Average total loss: 0.412619
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-5.0871e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.176161
Average KL loss: 0.225162
Average total loss: 0.401323
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(4.1458e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.185668
Average KL loss: 0.226110
Average total loss: 0.411777
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1823e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.175576
Average KL loss: 0.227127
Average total loss: 0.402703
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-9.4672e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.176807
Average KL loss: 0.224252
Average total loss: 0.401058
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.5301e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.179821
Average KL loss: 0.227517
Average total loss: 0.407337
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.0387e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.171994
Average KL loss: 0.226376
Average total loss: 0.398370
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.1696e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.182151
Average KL loss: 0.227728
Average total loss: 0.409879
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.7677e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.168456
Average KL loss: 0.227924
Average total loss: 0.396380
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.8047e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.175817
Average KL loss: 0.225758
Average total loss: 0.401575
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.4577e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.171529
Average KL loss: 0.230236
Average total loss: 0.401765
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.2269e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.169237
Average KL loss: 0.227331
Average total loss: 0.396568
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.3344e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.169595
Average KL loss: 0.227030
Average total loss: 0.396625
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.8767e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.164188
Average KL loss: 0.227564
Average total loss: 0.391752
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.0248e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.168932
Average KL loss: 0.228591
Average total loss: 0.397523
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.6000e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.165910
Average KL loss: 0.229551
Average total loss: 0.395460
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.3244e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.164127
Average KL loss: 0.226335
Average total loss: 0.390462
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.8939e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.167070
Average KL loss: 0.227716
Average total loss: 0.394786
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.0560e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.170337
Average KL loss: 0.230945
Average total loss: 0.401282
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-6.6526e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.161741
Average KL loss: 0.229987
Average total loss: 0.391728
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-9.2412e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.163254
Average KL loss: 0.229954
Average total loss: 0.393207
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(2.0527e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.163210
Average KL loss: 0.230847
Average total loss: 0.394057
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-7.3006e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.158021
Average KL loss: 0.229052
Average total loss: 0.387073
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(1.1930e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.166417
Average KL loss: 0.229697
Average total loss: 0.396114
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.5153e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.165748
Average KL loss: 0.233115
Average total loss: 0.398863
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-4.6513e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.165887
Average KL loss: 0.233430
Average total loss: 0.399317
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(3.2160e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.157928
Average KL loss: 0.231227
Average total loss: 0.389155
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(6.8215e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.154485
Average KL loss: 0.229284
Average total loss: 0.383769
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-7.6395e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.155625
Average KL loss: 0.229152
Average total loss: 0.384777
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(2.5944e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.158604
Average KL loss: 0.229032
Average total loss: 0.387637
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.1190e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.157715
Average KL loss: 0.232058
Average total loss: 0.389772
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.8133e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.157833
Average KL loss: 0.231639
Average total loss: 0.389472
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.3500e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.153189
Average KL loss: 0.230401
Average total loss: 0.383589
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.6304e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.159175
Average KL loss: 0.235594
Average total loss: 0.394768
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(5.4253e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.157668
Average KL loss: 0.233618
Average total loss: 0.391286
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-9.6045e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.159794
Average KL loss: 0.234932
Average total loss: 0.394727
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.0774e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.160614
Average KL loss: 0.234984
Average total loss: 0.395598
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.1610e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.154253
Average KL loss: 0.233846
Average total loss: 0.388099
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-8.6472e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.157686
Average KL loss: 0.235569
Average total loss: 0.393255
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-4.8835e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.154858
Average KL loss: 0.232819
Average total loss: 0.387678
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.5621e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.149807
Average KL loss: 0.234041
Average total loss: 0.383848
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(8.9533e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.152601
Average KL loss: 0.233083
Average total loss: 0.385684
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.0672e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.154026
Average KL loss: 0.234128
Average total loss: 0.388154
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-4.7850e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.159618
Average KL loss: 0.238231
Average total loss: 0.397849
tensor(0.0016, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.8592e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.142910
Average KL loss: 0.227620
Average total loss: 0.370530
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(9.2778e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.151309
Average KL loss: 0.212144
Average total loss: 0.363453
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(2.4408e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.147320
Average KL loss: 0.204227
Average total loss: 0.351547
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(7.5886e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.148397
Average KL loss: 0.198986
Average total loss: 0.347383
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(7.3057e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.150280
Average KL loss: 0.195374
Average total loss: 0.345654
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(6.1297e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.155224
Average KL loss: 0.192704
Average total loss: 0.347928
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.8799e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.145883
Average KL loss: 0.190539
Average total loss: 0.336422
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.5059e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.145148
Average KL loss: 0.188691
Average total loss: 0.333838
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-9.6645e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.153055
Average KL loss: 0.187313
Average total loss: 0.340368
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.2114e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.148332
Average KL loss: 0.186243
Average total loss: 0.334576
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.1194e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.148167
Average KL loss: 0.185169
Average total loss: 0.333336
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.5450e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.148688
Average KL loss: 0.184380
Average total loss: 0.333068
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.9628e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.149513
Average KL loss: 0.183687
Average total loss: 0.333199
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.5904e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.146320
Average KL loss: 0.182995
Average total loss: 0.329316
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3732e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.151292
Average KL loss: 0.182332
Average total loss: 0.333624
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.7288e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.149852
Average KL loss: 0.181943
Average total loss: 0.331795
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.0082e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.148049
Average KL loss: 0.181506
Average total loss: 0.329555
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.1388e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.150221
Average KL loss: 0.181241
Average total loss: 0.331462
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.4935e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.149710
Average KL loss: 0.180978
Average total loss: 0.330688
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.9497e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.145694
Average KL loss: 0.180661
Average total loss: 0.326354
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.2410e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.148091
Average KL loss: 0.180261
Average total loss: 0.328352
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(7.6919e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.143940
Average KL loss: 0.179923
Average total loss: 0.323863
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.4525e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.149216
Average KL loss: 0.179591
Average total loss: 0.328807
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1190e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.146853
Average KL loss: 0.179376
Average total loss: 0.326229
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.8073e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.146650
Average KL loss: 0.179159
Average total loss: 0.325809
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.4381e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.148533
Average KL loss: 0.179077
Average total loss: 0.327609
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(5.0903e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.150763
Average KL loss: 0.178985
Average total loss: 0.329748
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3397e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.144303
Average KL loss: 0.178709
Average total loss: 0.323012
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.6915e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.147804
Average KL loss: 0.178494
Average total loss: 0.326298
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.8366e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.147946
Average KL loss: 0.178427
Average total loss: 0.326374
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.1850e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.150105
Average KL loss: 0.178309
Average total loss: 0.328413
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.3981e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.149309
Average KL loss: 0.178257
Average total loss: 0.327566
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-6.0313e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.148691
Average KL loss: 0.178164
Average total loss: 0.326855
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.7121e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.150380
Average KL loss: 0.178037
Average total loss: 0.328417
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.7112e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.152333
Average KL loss: 0.178050
Average total loss: 0.330383
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.2672e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.151242
Average KL loss: 0.178058
Average total loss: 0.329300
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1964e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.153341
Average KL loss: 0.178049
Average total loss: 0.331390
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(5.8018e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.150486
Average KL loss: 0.177973
Average total loss: 0.328459
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(4.8043e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.148168
Average KL loss: 0.177822
Average total loss: 0.325990
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.1695e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.148577
Average KL loss: 0.177577
Average total loss: 0.326154
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5610e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.152439
Average KL loss: 0.177205
Average total loss: 0.329644
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.9239e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.148372
Average KL loss: 0.176907
Average total loss: 0.325279
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-6.5382e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.148874
Average KL loss: 0.176661
Average total loss: 0.325535
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.9526e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.144449
Average KL loss: 0.176428
Average total loss: 0.320877
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.8556e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.145889
Average KL loss: 0.176222
Average total loss: 0.322112
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1828e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.150094
Average KL loss: 0.176039
Average total loss: 0.326133
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.3502e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.145606
Average KL loss: 0.175870
Average total loss: 0.321477
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.0667e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.147988
Average KL loss: 0.175722
Average total loss: 0.323710
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.3835e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.148484
Average KL loss: 0.175585
Average total loss: 0.324070
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.8706e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.146919
Average KL loss: 0.175458
Average total loss: 0.322377
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5113e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.143155
Average KL loss: 0.175330
Average total loss: 0.318485
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.3377e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.144687
Average KL loss: 0.175210
Average total loss: 0.319897
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.6213e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.146123
Average KL loss: 0.175092
Average total loss: 0.321215
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3516e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.149649
Average KL loss: 0.174986
Average total loss: 0.324635
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(9.0040e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.142598
Average KL loss: 0.174888
Average total loss: 0.317485
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.1123e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.149470
Average KL loss: 0.174792
Average total loss: 0.324262
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.1113e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.144864
Average KL loss: 0.174701
Average total loss: 0.319565
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.3838e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.144288
Average KL loss: 0.174614
Average total loss: 0.318902
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.8579e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.151849
Average KL loss: 0.174537
Average total loss: 0.326386
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.7433e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.148325
Average KL loss: 0.174455
Average total loss: 0.322780
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(4.5472e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.147037
Average KL loss: 0.174380
Average total loss: 0.321418
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.7694e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.144989
Average KL loss: 0.174305
Average total loss: 0.319295
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.2202e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.150460
Average KL loss: 0.174233
Average total loss: 0.324694
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5892e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.143727
Average KL loss: 0.174164
Average total loss: 0.317891
 Percentile value: 0.005206593684852123
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/7]: ---
conv1.weight         | nonzeros =    1300 /    1728             ( 75.23%) | total_pruned =     428 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   18694 /   36864             ( 50.71%) | total_pruned =   18170 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   19308 /   36864             ( 52.38%) | total_pruned =   17556 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   18952 /   36864             ( 51.41%) | total_pruned =   17912 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18766 /   36864             ( 50.91%) | total_pruned =   18098 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   37141 /   73728             ( 50.38%) | total_pruned =   36587 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   72406 /  147456             ( 49.10%) | total_pruned =   75050 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5256 /    8192             ( 64.16%) | total_pruned =    2936 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   66321 /  147456             ( 44.98%) | total_pruned =   81135 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   66964 /  147456             ( 45.41%) | total_pruned =   80492 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  141371 /  294912             ( 47.94%) | total_pruned =  153541 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     237 /     256             ( 92.58%) | total_pruned =      19 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  271958 /  589824             ( 46.11%) | total_pruned =  317866 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18996 /   32768             ( 57.97%) | total_pruned =   13772 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  221581 /  589824             ( 37.57%) | total_pruned =  368243 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  219229 /  589824             ( 37.17%) | total_pruned =  370595 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  499238 / 1179648             ( 42.32%) | total_pruned =  680410 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  752611 / 2359296             ( 31.90%) | total_pruned = 1606685 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     401 /     512             ( 78.32%) | total_pruned =     111 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   62974 /  131072             ( 48.05%) | total_pruned =   68098 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     404 /     512             ( 78.91%) | total_pruned =     108 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  503008 / 2359296             ( 21.32%) | total_pruned = 1856288 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  324988 / 2359296             ( 13.77%) | total_pruned = 2034308 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     131 /     512             ( 25.59%) | total_pruned =     381 | shape = torch.Size([512])
linear.weight        | nonzeros =    4272 /    5120             ( 83.44%) | total_pruned =     848 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 37/200 Loss: 0.000233 Accuracy: 86.71 100.00 % Best test Accuracy: 86.79%
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.4806e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.325225
Average KL loss: 0.203459
Average total loss: 0.528684
tensor(0.0019, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.1979e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.310229
Average KL loss: 0.233863
Average total loss: 0.544092
tensor(0.0020, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.9144e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.290585
Average KL loss: 0.241193
Average total loss: 0.531779
tensor(0.0020, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.6094e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.282016
Average KL loss: 0.247860
Average total loss: 0.529876
tensor(0.0020, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-5.7585e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.268851
Average KL loss: 0.249754
Average total loss: 0.518605
tensor(0.0020, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.3351e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.264486
Average KL loss: 0.250630
Average total loss: 0.515116
tensor(0.0020, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.2419e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.269814
Average KL loss: 0.253208
Average total loss: 0.523023
tensor(0.0020, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.9109e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.259932
Average KL loss: 0.254597
Average total loss: 0.514529
tensor(0.0020, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-4.4448e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.256337
Average KL loss: 0.256850
Average total loss: 0.513187
tensor(0.0021, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.3811e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.257354
Average KL loss: 0.256780
Average total loss: 0.514134
tensor(0.0021, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-6.6272e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.250531
Average KL loss: 0.257804
Average total loss: 0.508336
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.0061e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.249060
Average KL loss: 0.257556
Average total loss: 0.506617
tensor(0.0021, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.2122e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.248325
Average KL loss: 0.259060
Average total loss: 0.507386
tensor(0.0021, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(6.0908e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.242355
Average KL loss: 0.259520
Average total loss: 0.501876
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.9143e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.247616
Average KL loss: 0.261966
Average total loss: 0.509582
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.0296e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.246670
Average KL loss: 0.263848
Average total loss: 0.510518
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-9.2636e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.238423
Average KL loss: 0.263582
Average total loss: 0.502005
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(1.6383e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.249042
Average KL loss: 0.264252
Average total loss: 0.513293
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(5.5001e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.235646
Average KL loss: 0.264090
Average total loss: 0.499735
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(2.3414e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.230532
Average KL loss: 0.262322
Average total loss: 0.492854
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-9.5816e-11, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.228984
Average KL loss: 0.263165
Average total loss: 0.492149
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-8.1859e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.238992
Average KL loss: 0.264363
Average total loss: 0.503355
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.2246e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.229391
Average KL loss: 0.264903
Average total loss: 0.494294
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.9183e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.223004
Average KL loss: 0.263595
Average total loss: 0.486599
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.8025e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.230140
Average KL loss: 0.264689
Average total loss: 0.494829
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.6336e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.223284
Average KL loss: 0.264624
Average total loss: 0.487908
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.1642e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.229827
Average KL loss: 0.267827
Average total loss: 0.497655
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.8571e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.227504
Average KL loss: 0.268352
Average total loss: 0.495856
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(6.6310e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.220333
Average KL loss: 0.265451
Average total loss: 0.485784
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.2389e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.223510
Average KL loss: 0.266124
Average total loss: 0.489634
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.9614e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.222339
Average KL loss: 0.267672
Average total loss: 0.490011
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(5.1302e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.219926
Average KL loss: 0.268036
Average total loss: 0.487962
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.1326e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.224086
Average KL loss: 0.268872
Average total loss: 0.492958
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.6322e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.221991
Average KL loss: 0.269583
Average total loss: 0.491574
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.9467e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.219208
Average KL loss: 0.271413
Average total loss: 0.490621
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4742e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.220884
Average KL loss: 0.271010
Average total loss: 0.491894
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.6360e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.207368
Average KL loss: 0.268000
Average total loss: 0.475368
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.1609e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.213365
Average KL loss: 0.267388
Average total loss: 0.480753
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.5191e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.208087
Average KL loss: 0.266313
Average total loss: 0.474401
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.9068e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.216782
Average KL loss: 0.267355
Average total loss: 0.484137
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.2820e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.216597
Average KL loss: 0.271894
Average total loss: 0.488492
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.9658e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.211947
Average KL loss: 0.271483
Average total loss: 0.483430
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.4993e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.210695
Average KL loss: 0.270227
Average total loss: 0.480922
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.9649e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.219916
Average KL loss: 0.272079
Average total loss: 0.491996
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.1794e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.211401
Average KL loss: 0.271888
Average total loss: 0.483289
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.5397e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.212841
Average KL loss: 0.271201
Average total loss: 0.484041
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.9712e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.211245
Average KL loss: 0.272502
Average total loss: 0.483746
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.2125e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.212545
Average KL loss: 0.272076
Average total loss: 0.484621
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(8.1360e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.209412
Average KL loss: 0.273796
Average total loss: 0.483208
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.4625e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.207710
Average KL loss: 0.273626
Average total loss: 0.481336
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.3349e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.202468
Average KL loss: 0.268110
Average total loss: 0.470578
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(6.0229e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.206636
Average KL loss: 0.258679
Average total loss: 0.465315
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.5901e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.208559
Average KL loss: 0.251886
Average total loss: 0.460444
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.2862e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.204462
Average KL loss: 0.246844
Average total loss: 0.451306
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.6740e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.205490
Average KL loss: 0.242879
Average total loss: 0.448370
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.7313e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.205947
Average KL loss: 0.239585
Average total loss: 0.445533
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(2.1693e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.207734
Average KL loss: 0.236849
Average total loss: 0.444582
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.8546e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.208975
Average KL loss: 0.234583
Average total loss: 0.443558
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.9206e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.205637
Average KL loss: 0.232570
Average total loss: 0.438207
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.7507e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.207153
Average KL loss: 0.230803
Average total loss: 0.437956
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.1182e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.208295
Average KL loss: 0.229410
Average total loss: 0.437706
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(4.2473e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.200885
Average KL loss: 0.228028
Average total loss: 0.428913
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(2.4885e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.204464
Average KL loss: 0.226755
Average total loss: 0.431220
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(7.0129e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.207526
Average KL loss: 0.225725
Average total loss: 0.433251
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.0810e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.204140
Average KL loss: 0.224774
Average total loss: 0.428914
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-4.7924e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.204125
Average KL loss: 0.223865
Average total loss: 0.427990
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.7096e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.205890
Average KL loss: 0.223034
Average total loss: 0.428925
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.5267e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.207732
Average KL loss: 0.222460
Average total loss: 0.430192
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.8729e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.203340
Average KL loss: 0.221814
Average total loss: 0.425154
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(6.4587e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.198519
Average KL loss: 0.221180
Average total loss: 0.419698
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.0357e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.205943
Average KL loss: 0.220657
Average total loss: 0.426600
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.2947e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.198730
Average KL loss: 0.220112
Average total loss: 0.418842
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.3286e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.204965
Average KL loss: 0.219672
Average total loss: 0.424637
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.1457e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.203380
Average KL loss: 0.219337
Average total loss: 0.422717
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3677e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.207158
Average KL loss: 0.218997
Average total loss: 0.426155
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.2174e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.208340
Average KL loss: 0.218664
Average total loss: 0.427004
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.2340e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.208424
Average KL loss: 0.218351
Average total loss: 0.426776
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.7154e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.200459
Average KL loss: 0.218096
Average total loss: 0.418555
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(6.1340e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.202347
Average KL loss: 0.217765
Average total loss: 0.420112
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.5489e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.201559
Average KL loss: 0.217474
Average total loss: 0.419033
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.6678e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.199146
Average KL loss: 0.217185
Average total loss: 0.416331
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.3079e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.207782
Average KL loss: 0.216887
Average total loss: 0.424669
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.2330e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.206317
Average KL loss: 0.216737
Average total loss: 0.423054
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.2009e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.203825
Average KL loss: 0.216558
Average total loss: 0.420383
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4772e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.212480
Average KL loss: 0.216370
Average total loss: 0.428850
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0273e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.204344
Average KL loss: 0.216254
Average total loss: 0.420598
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.4909e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.200530
Average KL loss: 0.216117
Average total loss: 0.416647
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.2032e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.203397
Average KL loss: 0.215932
Average total loss: 0.419328
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.2335e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.206308
Average KL loss: 0.215813
Average total loss: 0.422121
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.0934e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.200126
Average KL loss: 0.215704
Average total loss: 0.415830
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.3040e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.205192
Average KL loss: 0.215489
Average total loss: 0.420682
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(5.0769e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.212792
Average KL loss: 0.215434
Average total loss: 0.428226
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(5.9499e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.199218
Average KL loss: 0.215405
Average total loss: 0.414624
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.6079e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.201645
Average KL loss: 0.215248
Average total loss: 0.416893
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.5142e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.207829
Average KL loss: 0.215197
Average total loss: 0.423026
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.4883e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.205509
Average KL loss: 0.215164
Average total loss: 0.420673
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(9.9038e-11, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.204015
Average KL loss: 0.215071
Average total loss: 0.419086
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.9276e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.202480
Average KL loss: 0.214955
Average total loss: 0.417435
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9489e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.198455
Average KL loss: 0.214827
Average total loss: 0.413283
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.9629e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.204247
Average KL loss: 0.214782
Average total loss: 0.419029
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.1711e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.204321
Average KL loss: 0.214673
Average total loss: 0.418994
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3518e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.205663
Average KL loss: 0.214573
Average total loss: 0.420236
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.5926e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.206526
Average KL loss: 0.214514
Average total loss: 0.421039
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.6243e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.196483
Average KL loss: 0.214523
Average total loss: 0.411006
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.4856e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.205189
Average KL loss: 0.214428
Average total loss: 0.419618
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.3501e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.199834
Average KL loss: 0.214381
Average total loss: 0.414215
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3273e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.197513
Average KL loss: 0.214302
Average total loss: 0.411816
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.7161e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.202019
Average KL loss: 0.214203
Average total loss: 0.416222
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.1507e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.201035
Average KL loss: 0.214101
Average total loss: 0.415136
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.9378e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.206805
Average KL loss: 0.213995
Average total loss: 0.420800
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(5.9144e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.199827
Average KL loss: 0.213968
Average total loss: 0.413795
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.7214e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.196953
Average KL loss: 0.213831
Average total loss: 0.410784
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(5.9753e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.194318
Average KL loss: 0.213689
Average total loss: 0.408007
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.5707e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.207970
Average KL loss: 0.213663
Average total loss: 0.421633
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(9.4012e-11, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.200680
Average KL loss: 0.213719
Average total loss: 0.414399
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9660e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.196488
Average KL loss: 0.213675
Average total loss: 0.410163
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0706e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.207062
Average KL loss: 0.213668
Average total loss: 0.420730
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.8127e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.199161
Average KL loss: 0.213696
Average total loss: 0.412856
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.2257e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.202086
Average KL loss: 0.213569
Average total loss: 0.415655
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.9003e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.198614
Average KL loss: 0.213526
Average total loss: 0.412140
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.8039e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.206994
Average KL loss: 0.213490
Average total loss: 0.420485
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.6239e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.207009
Average KL loss: 0.213574
Average total loss: 0.420583
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.3738e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.199620
Average KL loss: 0.213536
Average total loss: 0.413156
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.6727e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.205673
Average KL loss: 0.213519
Average total loss: 0.419192
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.3126e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.202544
Average KL loss: 0.213470
Average total loss: 0.416014
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(7.7553e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.200106
Average KL loss: 0.213326
Average total loss: 0.413432
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.2710e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.196177
Average KL loss: 0.213179
Average total loss: 0.409357
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.6973e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.204705
Average KL loss: 0.213044
Average total loss: 0.417749
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.8002e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.199291
Average KL loss: 0.212923
Average total loss: 0.412214
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.1935e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.199765
Average KL loss: 0.212799
Average total loss: 0.412563
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.0508e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.200781
Average KL loss: 0.212686
Average total loss: 0.413467
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.5405e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.198806
Average KL loss: 0.212580
Average total loss: 0.411386
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.4888e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.199044
Average KL loss: 0.212474
Average total loss: 0.411518
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.8993e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.205458
Average KL loss: 0.212374
Average total loss: 0.417832
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.6962e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.197332
Average KL loss: 0.212283
Average total loss: 0.409615
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.8703e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.200808
Average KL loss: 0.212233
Average total loss: 0.413041
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4471e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.200853
Average KL loss: 0.212222
Average total loss: 0.413075
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.7260e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.206843
Average KL loss: 0.212212
Average total loss: 0.419055
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.1727e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.206310
Average KL loss: 0.212202
Average total loss: 0.418512
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.5907e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.204470
Average KL loss: 0.212192
Average total loss: 0.416662
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.0390e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.194673
Average KL loss: 0.212181
Average total loss: 0.406854
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.5819e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.201465
Average KL loss: 0.212170
Average total loss: 0.413635
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.5954e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.207618
Average KL loss: 0.212160
Average total loss: 0.419778
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.4838e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.203726
Average KL loss: 0.212151
Average total loss: 0.415877
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.9858e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.199919
Average KL loss: 0.212141
Average total loss: 0.412060
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.2587e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.198411
Average KL loss: 0.212130
Average total loss: 0.410541
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.3413e-12, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.199002
Average KL loss: 0.212120
Average total loss: 0.411122
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.0065e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.205811
Average KL loss: 0.212109
Average total loss: 0.417921
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.7068e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.198097
Average KL loss: 0.212100
Average total loss: 0.410197
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.0568e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.201521
Average KL loss: 0.212090
Average total loss: 0.413611
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.7538e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.204179
Average KL loss: 0.212080
Average total loss: 0.416259
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.9100e-09, device='cuda:0')
 Percentile value: 0.023410207778215408
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/7]: ---
conv1.weight         | nonzeros =    1069 /    1728             ( 61.86%) | total_pruned =     659 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    9215 /   36864             ( 25.00%) | total_pruned =   27649 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    9950 /   36864             ( 26.99%) | total_pruned =   26914 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    9370 /   36864             ( 25.42%) | total_pruned =   27494 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9172 /   36864             ( 24.88%) | total_pruned =   27692 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   17861 /   73728             ( 24.23%) | total_pruned =   55867 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   32794 /  147456             ( 22.24%) | total_pruned =  114662 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3523 /    8192             ( 43.01%) | total_pruned =    4669 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   25414 /  147456             ( 17.23%) | total_pruned =  122042 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   26130 /  147456             ( 17.72%) | total_pruned =  121326 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   62080 /  294912             ( 21.05%) | total_pruned =  232832 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  110864 /  589824             ( 18.80%) | total_pruned =  478960 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   11164 /   32768             ( 34.07%) | total_pruned =   21604 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     204 /     256             ( 79.69%) | total_pruned =      52 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   62899 /  589824             ( 10.66%) | total_pruned =  526925 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   63568 /  589824             ( 10.78%) | total_pruned =  526256 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  180337 / 1179648             ( 15.29%) | total_pruned =  999311 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     386 /     512             ( 75.39%) | total_pruned =     126 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  194390 / 2359296             (  8.24%) | total_pruned = 2164906 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     349 /     512             ( 68.16%) | total_pruned =     163 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   26583 /  131072             ( 20.28%) | total_pruned =  104489 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     479 /     512             ( 93.55%) | total_pruned =      33 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     364 /     512             ( 71.09%) | total_pruned =     148 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   90424 / 2359296             (  3.83%) | total_pruned = 2268872 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     407 /     512             ( 79.49%) | total_pruned =     105 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     227 /     512             ( 44.34%) | total_pruned =     285 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   48306 / 2359296             (  2.05%) | total_pruned = 2310990 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
linear.weight        | nonzeros =    3483 /    5120             ( 68.03%) | total_pruned =    1637 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 32/200 Loss: 0.000176 Accuracy: 86.84 100.00 % Best test Accuracy: 86.92%
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.5156e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.502207
Average KL loss: 0.220599
Average total loss: 0.722806
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2316e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.448764
Average KL loss: 0.249178
Average total loss: 0.697942
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.6907e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.417055
Average KL loss: 0.264909
Average total loss: 0.681964
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.5431e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.418603
Average KL loss: 0.275085
Average total loss: 0.693687
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.5859e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.400009
Average KL loss: 0.282668
Average total loss: 0.682677
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.5083e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.398790
Average KL loss: 0.286715
Average total loss: 0.685506
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.0903e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.385439
Average KL loss: 0.291755
Average total loss: 0.677194
tensor(0.0026, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2146e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.375625
Average KL loss: 0.293874
Average total loss: 0.669499
tensor(0.0026, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.7226e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.378120
Average KL loss: 0.295341
Average total loss: 0.673462
tensor(0.0026, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(4.2907e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.378108
Average KL loss: 0.296909
Average total loss: 0.675017
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1981e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.368416
Average KL loss: 0.299710
Average total loss: 0.668126
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.0230e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.374432
Average KL loss: 0.300552
Average total loss: 0.674983
tensor(0.0027, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-9.2813e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.371416
Average KL loss: 0.303044
Average total loss: 0.674460
tensor(0.0027, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(3.6305e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.362878
Average KL loss: 0.304548
Average total loss: 0.667426
tensor(0.0027, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.1857e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.358287
Average KL loss: 0.303795
Average total loss: 0.662081
tensor(0.0027, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.6577e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.362411
Average KL loss: 0.305468
Average total loss: 0.667879
tensor(0.0027, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.1447e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.361727
Average KL loss: 0.307303
Average total loss: 0.669030
tensor(0.0027, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.7136e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.361985
Average KL loss: 0.307409
Average total loss: 0.669394
tensor(0.0027, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.1472e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.355020
Average KL loss: 0.309319
Average total loss: 0.664339
tensor(0.0027, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.8403e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.353640
Average KL loss: 0.309913
Average total loss: 0.663553
tensor(0.0027, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.9002e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.350563
Average KL loss: 0.310001
Average total loss: 0.660564
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.9688e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.354575
Average KL loss: 0.310755
Average total loss: 0.665330
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.0493e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.347227
Average KL loss: 0.310596
Average total loss: 0.657823
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.1402e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.335603
Average KL loss: 0.310980
Average total loss: 0.646584
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.9942e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.352585
Average KL loss: 0.311023
Average total loss: 0.663608
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.8057e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.346389
Average KL loss: 0.312045
Average total loss: 0.658434
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0311e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.361677
Average KL loss: 0.313175
Average total loss: 0.674852
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(7.2498e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.349199
Average KL loss: 0.316018
Average total loss: 0.665217
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(4.4602e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.350144
Average KL loss: 0.316261
Average total loss: 0.666405
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.8924e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.350323
Average KL loss: 0.315997
Average total loss: 0.666320
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(1.5092e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.344491
Average KL loss: 0.317355
Average total loss: 0.661846
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.5465e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.347406
Average KL loss: 0.317663
Average total loss: 0.665069
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(1.3277e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.329349
Average KL loss: 0.317205
Average total loss: 0.646555
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.4771e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.339803
Average KL loss: 0.315886
Average total loss: 0.655689
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.7750e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.343625
Average KL loss: 0.316963
Average total loss: 0.660588
tensor(0.0027, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(3.9488e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.341417
Average KL loss: 0.316457
Average total loss: 0.657874
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(2.9844e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.334859
Average KL loss: 0.312344
Average total loss: 0.647202
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(3.6811e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.317432
Average KL loss: 0.308625
Average total loss: 0.626056
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5800e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.330477
Average KL loss: 0.305316
Average total loss: 0.635793
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(3.5417e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.328795
Average KL loss: 0.302442
Average total loss: 0.631238
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.5838e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.328713
Average KL loss: 0.299873
Average total loss: 0.628586
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.1507e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.337695
Average KL loss: 0.297546
Average total loss: 0.635240
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.4776e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.342249
Average KL loss: 0.295514
Average total loss: 0.637763
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.0052e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.323886
Average KL loss: 0.293629
Average total loss: 0.617515
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(3.4507e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.329818
Average KL loss: 0.291803
Average total loss: 0.621621
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.1771e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.322167
Average KL loss: 0.290164
Average total loss: 0.612330
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.4085e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.335355
Average KL loss: 0.288535
Average total loss: 0.623890
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(5.7700e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.328453
Average KL loss: 0.287087
Average total loss: 0.615539
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4529e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.336156
Average KL loss: 0.285722
Average total loss: 0.621879
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(4.9134e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.328256
Average KL loss: 0.284526
Average total loss: 0.612782
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.8603e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.330691
Average KL loss: 0.283394
Average total loss: 0.614085
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.3065e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.326954
Average KL loss: 0.282305
Average total loss: 0.609259
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.5581e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.328114
Average KL loss: 0.281297
Average total loss: 0.609411
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.5416e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.343046
Average KL loss: 0.280365
Average total loss: 0.623411
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.4983e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.333566
Average KL loss: 0.279531
Average total loss: 0.613097
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(7.6168e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.318320
Average KL loss: 0.278651
Average total loss: 0.596972
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.0772e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.330168
Average KL loss: 0.277777
Average total loss: 0.607944
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(2.9681e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.331808
Average KL loss: 0.277036
Average total loss: 0.608843
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.4750e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.330030
Average KL loss: 0.276351
Average total loss: 0.606382
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.0532e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.330925
Average KL loss: 0.275669
Average total loss: 0.606594
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.3108e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.326902
Average KL loss: 0.275071
Average total loss: 0.601973
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0270e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.327794
Average KL loss: 0.274431
Average total loss: 0.602226
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.3877e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.329866
Average KL loss: 0.273902
Average total loss: 0.603768
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.5821e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.331584
Average KL loss: 0.273394
Average total loss: 0.604979
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(2.3159e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.329427
Average KL loss: 0.272843
Average total loss: 0.602270
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(6.1953e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.333119
Average KL loss: 0.272434
Average total loss: 0.605553
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.0100e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.323787
Average KL loss: 0.271997
Average total loss: 0.595784
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.4810e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.327184
Average KL loss: 0.271476
Average total loss: 0.598660
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4122e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.340781
Average KL loss: 0.271088
Average total loss: 0.611868
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2058e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.328323
Average KL loss: 0.270757
Average total loss: 0.599080
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.0934e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.329800
Average KL loss: 0.270446
Average total loss: 0.600246
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.8563e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.328632
Average KL loss: 0.270134
Average total loss: 0.598766
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.3620e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.338502
Average KL loss: 0.269815
Average total loss: 0.608317
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0830e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.334069
Average KL loss: 0.269522
Average total loss: 0.603592
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.7480e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.329234
Average KL loss: 0.269251
Average total loss: 0.598485
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2656e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.336817
Average KL loss: 0.268889
Average total loss: 0.605706
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.8858e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.329452
Average KL loss: 0.268597
Average total loss: 0.598049
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.9028e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.331016
Average KL loss: 0.268282
Average total loss: 0.599298
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.3439e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.326212
Average KL loss: 0.268124
Average total loss: 0.594336
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4781e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.329757
Average KL loss: 0.268050
Average total loss: 0.597807
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.2586e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.333861
Average KL loss: 0.267973
Average total loss: 0.601835
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(8.4893e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.332027
Average KL loss: 0.267899
Average total loss: 0.599927
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.1890e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.336504
Average KL loss: 0.267830
Average total loss: 0.604334
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.5083e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.327767
Average KL loss: 0.267758
Average total loss: 0.595525
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0323e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.323890
Average KL loss: 0.267687
Average total loss: 0.591577
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.0885e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.333564
Average KL loss: 0.267622
Average total loss: 0.601186
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(4.7656e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.326348
Average KL loss: 0.267550
Average total loss: 0.593898
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.6738e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.334785
Average KL loss: 0.267489
Average total loss: 0.602274
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(4.9090e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.328644
Average KL loss: 0.267428
Average total loss: 0.596072
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(6.4998e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.329022
Average KL loss: 0.267357
Average total loss: 0.596379
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.3348e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.323498
Average KL loss: 0.267292
Average total loss: 0.590789
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.3006e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.330285
Average KL loss: 0.267221
Average total loss: 0.597507
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(5.1828e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.330233
Average KL loss: 0.267153
Average total loss: 0.597385
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.4394e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.327747
Average KL loss: 0.267088
Average total loss: 0.594835
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(8.6042e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.330206
Average KL loss: 0.267027
Average total loss: 0.597232
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.4137e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.329927
Average KL loss: 0.266969
Average total loss: 0.596896
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.6310e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.337504
Average KL loss: 0.266906
Average total loss: 0.604410
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(8.7095e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.330006
Average KL loss: 0.266846
Average total loss: 0.596851
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(8.8949e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.327243
Average KL loss: 0.266783
Average total loss: 0.594027
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.9639e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.334946
Average KL loss: 0.266730
Average total loss: 0.601677
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(4.4316e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.329025
Average KL loss: 0.266669
Average total loss: 0.595694
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.3924e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.334511
Average KL loss: 0.266609
Average total loss: 0.601120
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(8.6652e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.316742
Average KL loss: 0.266577
Average total loss: 0.583319
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.3977e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.336757
Average KL loss: 0.266570
Average total loss: 0.603327
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.1444e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.336676
Average KL loss: 0.266564
Average total loss: 0.603240
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.9512e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.328628
Average KL loss: 0.266558
Average total loss: 0.595186
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.4550e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.334391
Average KL loss: 0.266552
Average total loss: 0.600943
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.0436e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.323695
Average KL loss: 0.266545
Average total loss: 0.590240
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1956e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.324062
Average KL loss: 0.266539
Average total loss: 0.590600
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.0474e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.330925
Average KL loss: 0.266532
Average total loss: 0.597456
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.2668e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.334872
Average KL loss: 0.266527
Average total loss: 0.601399
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.8390e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.325925
Average KL loss: 0.266521
Average total loss: 0.592446
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(5.3178e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.330572
Average KL loss: 0.266514
Average total loss: 0.597085
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.5878e-09, device='cuda:0')
 Percentile value: 0.09010935127735135
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/7]: ---
conv1.weight         | nonzeros =     909 /    1728             ( 52.60%) | total_pruned =     819 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4281 /   36864             ( 11.61%) | total_pruned =   32583 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4837 /   36864             ( 13.12%) | total_pruned =   32027 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4346 /   36864             ( 11.79%) | total_pruned =   32518 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4346 /   36864             ( 11.79%) | total_pruned =   32518 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8023 /   73728             ( 10.88%) | total_pruned =   65705 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   13370 /  147456             (  9.07%) | total_pruned =  134086 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2349 /    8192             ( 28.67%) | total_pruned =    5843 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8427 /  147456             (  5.71%) | total_pruned =  139029 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    8906 /  147456             (  6.04%) | total_pruned =  138550 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23899 /  294912             (  8.10%) | total_pruned =  271013 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   37340 /  589824             (  6.33%) | total_pruned =  552484 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6237 /   32768             ( 19.03%) | total_pruned =   26531 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     159 /     256             ( 62.11%) | total_pruned =      97 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   16888 /  589824             (  2.86%) | total_pruned =  572936 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   17108 /  589824             (  2.90%) | total_pruned =  572716 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     109 /     256             ( 42.58%) | total_pruned =     147 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   51576 / 1179648             (  4.37%) | total_pruned = 1128072 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     301 /     512             ( 58.79%) | total_pruned =     211 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   41955 / 2359296             (  1.78%) | total_pruned = 2317341 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     299 /     512             ( 58.40%) | total_pruned =     213 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9197 /  131072             (  7.02%) | total_pruned =  121875 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     440 /     512             ( 85.94%) | total_pruned =      72 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     329 /     512             ( 64.26%) | total_pruned =     183 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   18941 / 2359296             (  0.80%) | total_pruned = 2340355 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     389 /     512             ( 75.98%) | total_pruned =     123 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     146 /     512             ( 28.52%) | total_pruned =     366 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    9497 / 2359296             (  0.40%) | total_pruned = 2349799 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      56 /     512             ( 10.94%) | total_pruned =     456 | shape = torch.Size([512])
linear.weight        | nonzeros =    2631 /    5120             ( 51.39%) | total_pruned =    2489 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 31/200 Loss: 0.000061 Accuracy: 86.12 100.00 % Best test Accuracy: 86.72%
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.4814e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.934497
Average KL loss: 0.255503
Average total loss: 1.190000
tensor(0.0031, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-5.7108e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.815817
Average KL loss: 0.274104
Average total loss: 1.089922
tensor(0.0032, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.0088e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.765544
Average KL loss: 0.291545
Average total loss: 1.057088
tensor(0.0032, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.7072e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.754055
Average KL loss: 0.305752
Average total loss: 1.059807
tensor(0.0033, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.3649e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.729100
Average KL loss: 0.318190
Average total loss: 1.047290
tensor(0.0033, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.0845e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.703451
Average KL loss: 0.328600
Average total loss: 1.032051
tensor(0.0033, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.0517e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.673323
Average KL loss: 0.335538
Average total loss: 1.008861
tensor(0.0033, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.5286e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.666671
Average KL loss: 0.341699
Average total loss: 1.008369
tensor(0.0033, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(1.0639e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.671557
Average KL loss: 0.347226
Average total loss: 1.018783
tensor(0.0033, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.2340e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.667788
Average KL loss: 0.352966
Average total loss: 1.020754
tensor(0.0033, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.2257e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.658293
Average KL loss: 0.357709
Average total loss: 1.016002
tensor(0.0033, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.6862e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.666293
Average KL loss: 0.362031
Average total loss: 1.028324
tensor(0.0033, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-6.3143e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.651392
Average KL loss: 0.366278
Average total loss: 1.017670
tensor(0.0033, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.7586e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.639104
Average KL loss: 0.368747
Average total loss: 1.007850
tensor(0.0033, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(9.1407e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.623649
Average KL loss: 0.370486
Average total loss: 0.994135
tensor(0.0033, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.0629e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.630864
Average KL loss: 0.372496
Average total loss: 1.003360
tensor(0.0033, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3779e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.632691
Average KL loss: 0.375150
Average total loss: 1.007841
tensor(0.0033, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(1.8840e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.611396
Average KL loss: 0.377552
Average total loss: 0.988948
tensor(0.0033, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.8052e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.609759
Average KL loss: 0.377892
Average total loss: 0.987651
tensor(0.0033, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(1.2694e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.617770
Average KL loss: 0.379259
Average total loss: 0.997029
tensor(0.0033, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(1.8255e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.598541
Average KL loss: 0.380379
Average total loss: 0.978919
tensor(0.0033, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(5.3461e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.602647
Average KL loss: 0.382075
Average total loss: 0.984723
tensor(0.0033, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.7477e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.607903
Average KL loss: 0.383631
Average total loss: 0.991533
tensor(0.0033, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(2.7502e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.590144
Average KL loss: 0.384860
Average total loss: 0.975004
tensor(0.0033, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.9448e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.593895
Average KL loss: 0.385293
Average total loss: 0.979188
tensor(0.0033, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(1.5591e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.591472
Average KL loss: 0.385053
Average total loss: 0.976526
tensor(0.0033, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.3494e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.588986
Average KL loss: 0.386114
Average total loss: 0.975101
tensor(0.0033, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0450e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.590232
Average KL loss: 0.387073
Average total loss: 0.977305
tensor(0.0033, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(3.0927e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.588728
Average KL loss: 0.388445
Average total loss: 0.977173
tensor(0.0033, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5148e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.603103
Average KL loss: 0.389416
Average total loss: 0.992519
tensor(0.0033, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-9.4381e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.582158
Average KL loss: 0.390457
Average total loss: 0.972614
tensor(0.0033, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.6385e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.587271
Average KL loss: 0.390369
Average total loss: 0.977641
tensor(0.0033, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.3382e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.589936
Average KL loss: 0.391707
Average total loss: 0.981643
tensor(0.0033, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.1595e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.596801
Average KL loss: 0.392636
Average total loss: 0.989437
tensor(0.0033, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(1.4309e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.580535
Average KL loss: 0.393814
Average total loss: 0.974349
tensor(0.0033, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1067e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.577443
Average KL loss: 0.394224
Average total loss: 0.971667
tensor(0.0033, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.1409e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.570325
Average KL loss: 0.393842
Average total loss: 0.964167
tensor(0.0033, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(2.7716e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.568255
Average KL loss: 0.393734
Average total loss: 0.961989
tensor(0.0033, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.6000e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.549360
Average KL loss: 0.393729
Average total loss: 0.943090
tensor(0.0033, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-9.2431e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.573851
Average KL loss: 0.393426
Average total loss: 0.967277
tensor(0.0033, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(3.2241e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.592688
Average KL loss: 0.394581
Average total loss: 0.987269
tensor(0.0033, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(3.2665e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.577837
Average KL loss: 0.396628
Average total loss: 0.974465
tensor(0.0033, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(4.6616e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.575319
Average KL loss: 0.396700
Average total loss: 0.972019
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.3098e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.547845
Average KL loss: 0.396638
Average total loss: 0.944482
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.4607e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.574966
Average KL loss: 0.395878
Average total loss: 0.970845
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(6.9196e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.563045
Average KL loss: 0.396827
Average total loss: 0.959872
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.3779e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.557303
Average KL loss: 0.397480
Average total loss: 0.954783
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.0705e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.563720
Average KL loss: 0.398517
Average total loss: 0.962238
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.7203e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.566652
Average KL loss: 0.398289
Average total loss: 0.964942
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.6194e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.564257
Average KL loss: 0.399043
Average total loss: 0.963300
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-6.5567e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.566644
Average KL loss: 0.399324
Average total loss: 0.965968
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(6.0911e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.567524
Average KL loss: 0.398148
Average total loss: 0.965672
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(5.5209e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.566387
Average KL loss: 0.396863
Average total loss: 0.963250
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.9521e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.569978
Average KL loss: 0.395755
Average total loss: 0.965733
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(2.0485e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.537753
Average KL loss: 0.394623
Average total loss: 0.932376
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.7284e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.556092
Average KL loss: 0.393443
Average total loss: 0.949535
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(5.3017e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.564821
Average KL loss: 0.392377
Average total loss: 0.957199
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.4548e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.561880
Average KL loss: 0.391519
Average total loss: 0.953400
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.6681e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.560535
Average KL loss: 0.390544
Average total loss: 0.951079
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-4.4194e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.574287
Average KL loss: 0.389647
Average total loss: 0.963934
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(7.9881e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.549588
Average KL loss: 0.388804
Average total loss: 0.938392
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.1983e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.568735
Average KL loss: 0.387936
Average total loss: 0.956671
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.7420e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.563263
Average KL loss: 0.387233
Average total loss: 0.950495
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(9.0148e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.568628
Average KL loss: 0.386472
Average total loss: 0.955099
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.9054e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.550613
Average KL loss: 0.385741
Average total loss: 0.936354
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.5994e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.550626
Average KL loss: 0.385005
Average total loss: 0.935631
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.4330e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.569652
Average KL loss: 0.384561
Average total loss: 0.954212
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.4945e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.577671
Average KL loss: 0.384479
Average total loss: 0.962150
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.2226e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.566884
Average KL loss: 0.384401
Average total loss: 0.951285
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.0756e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.560628
Average KL loss: 0.384325
Average total loss: 0.944953
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(6.7530e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.557660
Average KL loss: 0.384236
Average total loss: 0.941897
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(4.1456e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.564511
Average KL loss: 0.384153
Average total loss: 0.948665
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.2351e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.565320
Average KL loss: 0.384069
Average total loss: 0.949390
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.1218e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.553870
Average KL loss: 0.383981
Average total loss: 0.937852
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.8282e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.568829
Average KL loss: 0.383897
Average total loss: 0.952726
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.4407e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.545164
Average KL loss: 0.383803
Average total loss: 0.928967
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.7795e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.561142
Average KL loss: 0.383713
Average total loss: 0.944855
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.2739e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.575393
Average KL loss: 0.383631
Average total loss: 0.959024
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(8.0760e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.550485
Average KL loss: 0.383547
Average total loss: 0.934031
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.1065e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.556339
Average KL loss: 0.383458
Average total loss: 0.939797
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.9787e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.560835
Average KL loss: 0.383373
Average total loss: 0.944208
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(4.2064e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.563821
Average KL loss: 0.383291
Average total loss: 0.947113
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.4101e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.557730
Average KL loss: 0.383205
Average total loss: 0.940935
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(8.2950e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.560193
Average KL loss: 0.383126
Average total loss: 0.943319
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(5.2213e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.558984
Average KL loss: 0.383042
Average total loss: 0.942027
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.0494e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.552433
Average KL loss: 0.382953
Average total loss: 0.935386
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.1648e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.550814
Average KL loss: 0.382872
Average total loss: 0.933685
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.1889e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.543493
Average KL loss: 0.382823
Average total loss: 0.926316
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-8.8829e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.557545
Average KL loss: 0.382815
Average total loss: 0.940359
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.7449e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.552602
Average KL loss: 0.382806
Average total loss: 0.935407
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.4562e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.564420
Average KL loss: 0.382797
Average total loss: 0.947218
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(4.0588e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.544156
Average KL loss: 0.382788
Average total loss: 0.926944
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(8.4527e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.557100
Average KL loss: 0.382779
Average total loss: 0.939879
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.1025e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.574623
Average KL loss: 0.382770
Average total loss: 0.957393
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.5937e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.547177
Average KL loss: 0.382762
Average total loss: 0.929939
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.7646e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.539573
Average KL loss: 0.382754
Average total loss: 0.922326
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.7500e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.565209
Average KL loss: 0.382745
Average total loss: 0.947954
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-4.5523e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.548657
Average KL loss: 0.382736
Average total loss: 0.931393
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.5086e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.545414
Average KL loss: 0.382727
Average total loss: 0.928141
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.3621e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.563104
Average KL loss: 0.382718
Average total loss: 0.945821
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.0277e-11, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.564050
Average KL loss: 0.382709
Average total loss: 0.946759
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-7.8006e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.542513
Average KL loss: 0.382701
Average total loss: 0.925214
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.5712e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.544859
Average KL loss: 0.382693
Average total loss: 0.927552
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.4529e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.557775
Average KL loss: 0.382684
Average total loss: 0.940459
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-7.7674e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.557807
Average KL loss: 0.382676
Average total loss: 0.940482
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.6844e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.547903
Average KL loss: 0.382667
Average total loss: 0.930570
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.7152e-09, device='cuda:0')
 Percentile value: 0.3669720649719238
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/7]: ---
conv1.weight         | nonzeros =     807 /    1728             ( 46.70%) | total_pruned =     921 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1787 /   36864             (  4.85%) | total_pruned =   35077 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2178 /   36864             (  5.91%) | total_pruned =   34686 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1963 /   36864             (  5.32%) | total_pruned =   34901 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1885 /   36864             (  5.11%) | total_pruned =   34979 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3287 /   73728             (  4.46%) | total_pruned =   70441 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4841 /  147456             (  3.28%) | total_pruned =  142615 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1473 /    8192             ( 17.98%) | total_pruned =    6719 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2595 /  147456             (  1.76%) | total_pruned =  144861 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2633 /  147456             (  1.79%) | total_pruned =  144823 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7924 /  294912             (  2.69%) | total_pruned =  286988 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   10499 /  589824             (  1.78%) | total_pruned =  579325 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2883 /   32768             (  8.80%) | total_pruned =   29885 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3877 /  589824             (  0.66%) | total_pruned =  585947 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     204 /     256             ( 79.69%) | total_pruned =      52 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3835 /  589824             (  0.65%) | total_pruned =  585989 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12123 / 1179648             (  1.03%) | total_pruned = 1167525 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     186 /     512             ( 36.33%) | total_pruned =     326 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    9191 / 2359296             (  0.39%) | total_pruned = 2350105 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     464 /     512             ( 90.62%) | total_pruned =      48 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     250 /     512             ( 48.83%) | total_pruned =     262 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2598 /  131072             (  1.98%) | total_pruned =  128474 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     333 /     512             ( 65.04%) | total_pruned =     179 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     265 /     512             ( 51.76%) | total_pruned =     247 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    4381 / 2359296             (  0.19%) | total_pruned = 2354915 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     306 /     512             ( 59.77%) | total_pruned =     206 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      58 /     512             ( 11.33%) | total_pruned =     454 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2354 / 2359296             (  0.10%) | total_pruned = 2356942 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     392 /     512             ( 76.56%) | total_pruned =     120 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
linear.weight        | nonzeros =    1764 /    5120             ( 34.45%) | total_pruned =    3356 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 35/200 Loss: 0.000825 Accuracy: 84.41 100.00 % Best test Accuracy: 85.29%
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.1428e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.913812
Average KL loss: 0.348313
Average total loss: 2.262125
tensor(0.0035, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-5.5754e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.689011
Average KL loss: 0.349437
Average total loss: 2.038447
tensor(0.0035, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-8.2481e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.602871
Average KL loss: 0.361446
Average total loss: 1.964317
tensor(0.0035, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.0633e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.531602
Average KL loss: 0.374032
Average total loss: 1.905634
tensor(0.0036, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.9298e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.472596
Average KL loss: 0.385679
Average total loss: 1.858275
tensor(0.0036, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.4495e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.395220
Average KL loss: 0.396692
Average total loss: 1.791913
tensor(0.0036, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-4.0277e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.395603
Average KL loss: 0.406471
Average total loss: 1.802074
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.6543e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.269136
Average KL loss: 0.415959
Average total loss: 1.685096
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.8077e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.278360
Average KL loss: 0.423514
Average total loss: 1.701873
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.1268e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.272536
Average KL loss: 0.431764
Average total loss: 1.704300
tensor(0.0037, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.3151e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.209175
Average KL loss: 0.438922
Average total loss: 1.648097
tensor(0.0037, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.3008e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.269244
Average KL loss: 0.445421
Average total loss: 1.714666
tensor(0.0037, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.5299e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.210886
Average KL loss: 0.453056
Average total loss: 1.663941
tensor(0.0037, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.0010e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.184550
Average KL loss: 0.459633
Average total loss: 1.644183
tensor(0.0037, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.7915e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.179453
Average KL loss: 0.465436
Average total loss: 1.644889
tensor(0.0037, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-7.2847e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.156367
Average KL loss: 0.470388
Average total loss: 1.626755
tensor(0.0037, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-9.1061e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.140979
Average KL loss: 0.475351
Average total loss: 1.616330
tensor(0.0037, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(8.0981e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.161637
Average KL loss: 0.480407
Average total loss: 1.642044
tensor(0.0038, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(9.2866e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.059192
Average KL loss: 0.484721
Average total loss: 1.543913
tensor(0.0038, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.2250e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.081263
Average KL loss: 0.487602
Average total loss: 1.568866
tensor(0.0038, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.4853e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.121499
Average KL loss: 0.491478
Average total loss: 1.612978
tensor(0.0038, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.7206e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.039787
Average KL loss: 0.495473
Average total loss: 1.535261
tensor(0.0038, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.5904e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.059591
Average KL loss: 0.498544
Average total loss: 1.558135
tensor(0.0038, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.2830e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.008971
Average KL loss: 0.501421
Average total loss: 1.510392
tensor(0.0038, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.4881e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.063899
Average KL loss: 0.503644
Average total loss: 1.567543
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.0138e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.034019
Average KL loss: 0.506197
Average total loss: 1.540216
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.2612e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.002621
Average KL loss: 0.508396
Average total loss: 1.511017
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3953e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.004206
Average KL loss: 0.510584
Average total loss: 1.514790
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.9085e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.019597
Average KL loss: 0.512877
Average total loss: 1.532474
tensor(0.0038, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.0749e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.991293
Average KL loss: 0.515246
Average total loss: 1.506539
tensor(0.0038, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.8599e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.032576
Average KL loss: 0.517710
Average total loss: 1.550287
tensor(0.0038, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.9486e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.040095
Average KL loss: 0.520690
Average total loss: 1.560785
tensor(0.0038, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.8501e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.989136
Average KL loss: 0.523582
Average total loss: 1.512718
tensor(0.0038, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.7560e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.946683
Average KL loss: 0.524780
Average total loss: 1.471463
tensor(0.0038, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.4969e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.964151
Average KL loss: 0.525556
Average total loss: 1.489708
tensor(0.0038, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.1760e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.957536
Average KL loss: 0.526417
Average total loss: 1.483953
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.2898e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.962254
Average KL loss: 0.527613
Average total loss: 1.489867
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(2.3719e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.964547
Average KL loss: 0.529570
Average total loss: 1.494117
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.0372e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.982790
Average KL loss: 0.530770
Average total loss: 1.513560
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.9999e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.953759
Average KL loss: 0.531608
Average total loss: 1.485367
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.3502e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.943390
Average KL loss: 0.532786
Average total loss: 1.476176
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(2.3735e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.941106
Average KL loss: 0.533987
Average total loss: 1.475093
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.9666e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.934095
Average KL loss: 0.535123
Average total loss: 1.469217
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(5.5313e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.969177
Average KL loss: 0.536372
Average total loss: 1.505549
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.0606e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.950824
Average KL loss: 0.538203
Average total loss: 1.489027
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.9155e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.952260
Average KL loss: 0.540016
Average total loss: 1.492277
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.2724e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.936878
Average KL loss: 0.541423
Average total loss: 1.478301
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.7570e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.941765
Average KL loss: 0.541999
Average total loss: 1.483764
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.5561e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.922254
Average KL loss: 0.543209
Average total loss: 1.465462
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.0108e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.900105
Average KL loss: 0.544205
Average total loss: 1.444310
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.3434e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.926494
Average KL loss: 0.545258
Average total loss: 1.471751
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.2231e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.920544
Average KL loss: 0.546505
Average total loss: 1.467049
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(6.1478e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.924990
Average KL loss: 0.548142
Average total loss: 1.473132
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.7780e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.885211
Average KL loss: 0.548863
Average total loss: 1.434074
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(9.0372e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.911841
Average KL loss: 0.548766
Average total loss: 1.460607
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.6066e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.877205
Average KL loss: 0.549082
Average total loss: 1.426287
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.6970e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.901095
Average KL loss: 0.548983
Average total loss: 1.450078
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.0373e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.917773
Average KL loss: 0.549941
Average total loss: 1.467714
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.8477e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.902863
Average KL loss: 0.551228
Average total loss: 1.454091
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.5191e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.871696
Average KL loss: 0.551428
Average total loss: 1.423124
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(5.3247e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.883405
Average KL loss: 0.551490
Average total loss: 1.434895
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.4255e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.882070
Average KL loss: 0.551538
Average total loss: 1.433608
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.3460e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.886331
Average KL loss: 0.552438
Average total loss: 1.438769
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.8435e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.886496
Average KL loss: 0.553552
Average total loss: 1.440048
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.2652e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.866260
Average KL loss: 0.553849
Average total loss: 1.420108
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(7.2365e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.883168
Average KL loss: 0.554089
Average total loss: 1.437258
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.8794e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.869410
Average KL loss: 0.554922
Average total loss: 1.424332
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(8.7071e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.896719
Average KL loss: 0.555579
Average total loss: 1.452298
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.0986e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.875421
Average KL loss: 0.556959
Average total loss: 1.432380
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.4760e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.870556
Average KL loss: 0.557269
Average total loss: 1.427825
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(7.5557e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.850741
Average KL loss: 0.557333
Average total loss: 1.408073
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.7433e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.876935
Average KL loss: 0.557738
Average total loss: 1.434672
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.9994e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.866733
Average KL loss: 0.558388
Average total loss: 1.425121
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.2812e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.849833
Average KL loss: 0.558802
Average total loss: 1.408635
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(8.3094e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.881785
Average KL loss: 0.558650
Average total loss: 1.440436
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1678e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.853561
Average KL loss: 0.558720
Average total loss: 1.412281
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.5409e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.836210
Average KL loss: 0.558818
Average total loss: 1.395028
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(9.9624e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.866575
Average KL loss: 0.558802
Average total loss: 1.425377
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.2085e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.847216
Average KL loss: 0.559663
Average total loss: 1.406879
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.2558e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.840535
Average KL loss: 0.559952
Average total loss: 1.400487
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.5870e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.840042
Average KL loss: 0.559670
Average total loss: 1.399712
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6137e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.854619
Average KL loss: 0.560018
Average total loss: 1.414637
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.4126e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.831867
Average KL loss: 0.559935
Average total loss: 1.391802
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.1153e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.847423
Average KL loss: 0.559399
Average total loss: 1.406822
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1131e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.812512
Average KL loss: 0.559553
Average total loss: 1.372064
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.6166e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.858327
Average KL loss: 0.559456
Average total loss: 1.417784
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.6467e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.822558
Average KL loss: 0.559934
Average total loss: 1.382492
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.8959e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.820586
Average KL loss: 0.560133
Average total loss: 1.380720
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.5585e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.858404
Average KL loss: 0.560288
Average total loss: 1.418692
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.0345e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.815822
Average KL loss: 0.560549
Average total loss: 1.376371
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.2794e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.817600
Average KL loss: 0.560587
Average total loss: 1.378187
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(4.4383e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.844824
Average KL loss: 0.560819
Average total loss: 1.405643
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(5.3162e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.833880
Average KL loss: 0.560881
Average total loss: 1.394762
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.5165e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.837930
Average KL loss: 0.560990
Average total loss: 1.398920
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.2578e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.854235
Average KL loss: 0.561938
Average total loss: 1.416173
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(5.2642e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.821295
Average KL loss: 0.562556
Average total loss: 1.383851
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.7314e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.814510
Average KL loss: 0.562346
Average total loss: 1.376856
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.3329e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.810792
Average KL loss: 0.562009
Average total loss: 1.372801
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.4852e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.803310
Average KL loss: 0.561647
Average total loss: 1.364958
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.1154e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.816775
Average KL loss: 0.561323
Average total loss: 1.378097
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.5184e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.831931
Average KL loss: 0.560994
Average total loss: 1.392926
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.5153e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.841259
Average KL loss: 0.560742
Average total loss: 1.402001
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8569e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.839374
Average KL loss: 0.560508
Average total loss: 1.399883
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.1774e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.835643
Average KL loss: 0.560297
Average total loss: 1.395940
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.1639e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.796744
Average KL loss: 0.560009
Average total loss: 1.356752
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0164e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.825285
Average KL loss: 0.559703
Average total loss: 1.384988
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.6832e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.793171
Average KL loss: 0.559447
Average total loss: 1.352618
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.1430e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.810555
Average KL loss: 0.559113
Average total loss: 1.369668
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.4879e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.810615
Average KL loss: 0.558824
Average total loss: 1.369439
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.1862e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.806548
Average KL loss: 0.558582
Average total loss: 1.365130
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.1617e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.817969
Average KL loss: 0.558305
Average total loss: 1.376273
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.1480e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.823409
Average KL loss: 0.558070
Average total loss: 1.381479
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(7.5062e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.831852
Average KL loss: 0.557867
Average total loss: 1.389720
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.2385e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.815555
Average KL loss: 0.557527
Average total loss: 1.373082
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(4.0396e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.817368
Average KL loss: 0.557216
Average total loss: 1.374583
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.1240e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.824384
Average KL loss: 0.556942
Average total loss: 1.381327
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(7.8958e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.813793
Average KL loss: 0.556714
Average total loss: 1.370508
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.5035e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.809747
Average KL loss: 0.556444
Average total loss: 1.366191
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.2086e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.813479
Average KL loss: 0.556310
Average total loss: 1.369789
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.2745e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.816282
Average KL loss: 0.556280
Average total loss: 1.372562
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.2590e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.824737
Average KL loss: 0.556247
Average total loss: 1.380984
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.4002e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.823539
Average KL loss: 0.556220
Average total loss: 1.379759
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.0631e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.799520
Average KL loss: 0.556192
Average total loss: 1.355712
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.2717e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.811212
Average KL loss: 0.556164
Average total loss: 1.367376
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.8879e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.816908
Average KL loss: 0.556138
Average total loss: 1.373047
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.6278e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.808624
Average KL loss: 0.556111
Average total loss: 1.364735
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.0106e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.807619
Average KL loss: 0.556082
Average total loss: 1.363701
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.2476e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.827313
Average KL loss: 0.556050
Average total loss: 1.383363
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.1819e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.808485
Average KL loss: 0.556023
Average total loss: 1.364508
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.2636e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.814656
Average KL loss: 0.556008
Average total loss: 1.370663
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.6016e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.827389
Average KL loss: 0.556005
Average total loss: 1.383393
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.2353e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.809958
Average KL loss: 0.556002
Average total loss: 1.365960
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.1249e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.814084
Average KL loss: 0.556000
Average total loss: 1.370083
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.4138e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.802213
Average KL loss: 0.555997
Average total loss: 1.358210
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(8.3229e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.827382
Average KL loss: 0.555994
Average total loss: 1.383376
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.3618e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.810058
Average KL loss: 0.555991
Average total loss: 1.366049
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.4751e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.805927
Average KL loss: 0.555988
Average total loss: 1.361915
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.5088e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.808544
Average KL loss: 0.555985
Average total loss: 1.364529
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.3767e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.810684
Average KL loss: 0.555982
Average total loss: 1.366666
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.8959e-09, device='cuda:0')
 Percentile value: 1.3421180248260496
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/7]: ---
conv1.weight         | nonzeros =     655 /    1728             ( 37.91%) | total_pruned =    1073 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     709 /   36864             (  1.92%) | total_pruned =   36155 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     892 /   36864             (  2.42%) | total_pruned =   35972 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     753 /   36864             (  2.04%) | total_pruned =   36111 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     752 /   36864             (  2.04%) | total_pruned =   36112 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1193 /   73728             (  1.62%) | total_pruned =   72535 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1536 /  147456             (  1.04%) | total_pruned =  145920 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     744 /    8192             (  9.08%) | total_pruned =    7448 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     780 /  147456             (  0.53%) | total_pruned =  146676 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     732 /  147456             (  0.50%) | total_pruned =  146724 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2172 /  294912             (  0.74%) | total_pruned =  292740 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2497 /  589824             (  0.42%) | total_pruned =  587327 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     937 /   32768             (  2.86%) | total_pruned =   31831 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     862 /  589824             (  0.15%) | total_pruned =  588962 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     842 /  589824             (  0.14%) | total_pruned =  588982 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2459 / 1179648             (  0.21%) | total_pruned = 1177189 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     427 /     512             ( 83.40%) | total_pruned =      85 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      71 /     512             ( 13.87%) | total_pruned =     441 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1888 / 2359296             (  0.08%) | total_pruned = 2357408 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     339 /     512             ( 66.21%) | total_pruned =     173 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     156 /     512             ( 30.47%) | total_pruned =     356 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     563 /  131072             (  0.43%) | total_pruned =  130509 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     194 /     512             ( 37.89%) | total_pruned =     318 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     155 /     512             ( 30.27%) | total_pruned =     357 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     882 / 2359296             (  0.04%) | total_pruned = 2358414 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     178 /     512             ( 34.77%) | total_pruned =     334 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     431 / 2359296             (  0.02%) | total_pruned = 2358865 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
linear.weight        | nonzeros =     860 /    5120             ( 16.80%) | total_pruned =    4260 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 154/200 Loss: 0.038812 Accuracy: 79.14 99.99 % Best test Accuracy: 82.29%
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.9114e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 4.221969
Average KL loss: 0.501669
Average total loss: 4.723638
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.5620e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 3.864675
Average KL loss: 0.473705
Average total loss: 4.338381
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.7095e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 3.532938
Average KL loss: 0.471916
Average total loss: 4.004854
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.9876e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 3.310354
Average KL loss: 0.474741
Average total loss: 3.785095
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.6796e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 3.162364
Average KL loss: 0.479062
Average total loss: 3.641426
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1945e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 3.186472
Average KL loss: 0.483619
Average total loss: 3.670091
tensor(0.0033, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.6049e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 3.046107
Average KL loss: 0.488648
Average total loss: 3.534754
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1892e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.971128
Average KL loss: 0.493891
Average total loss: 3.465019
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0705e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.863702
Average KL loss: 0.498926
Average total loss: 3.362628
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.1498e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.786516
Average KL loss: 0.503725
Average total loss: 3.290241
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.3475e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.748038
Average KL loss: 0.508254
Average total loss: 3.256291
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.9252e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.677241
Average KL loss: 0.513042
Average total loss: 3.190283
tensor(0.0034, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2346e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.568764
Average KL loss: 0.517884
Average total loss: 3.086648
tensor(0.0034, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.7670e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.629335
Average KL loss: 0.522325
Average total loss: 3.151660
tensor(0.0034, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.9394e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.566938
Average KL loss: 0.526799
Average total loss: 3.093737
tensor(0.0034, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.7221e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.536138
Average KL loss: 0.531055
Average total loss: 3.067193
tensor(0.0034, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.0408e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.419097
Average KL loss: 0.535153
Average total loss: 2.954250
tensor(0.0034, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.3632e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.380530
Average KL loss: 0.539237
Average total loss: 2.919767
tensor(0.0034, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.8284e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.397064
Average KL loss: 0.543344
Average total loss: 2.940408
tensor(0.0034, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.4051e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.334966
Average KL loss: 0.547286
Average total loss: 2.882252
tensor(0.0034, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.4027e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.214999
Average KL loss: 0.551002
Average total loss: 2.766001
tensor(0.0035, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-9.8782e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.324430
Average KL loss: 0.554702
Average total loss: 2.879132
tensor(0.0035, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-9.1236e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.237313
Average KL loss: 0.558430
Average total loss: 2.795743
tensor(0.0035, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-5.7641e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.192084
Average KL loss: 0.562132
Average total loss: 2.754217
tensor(0.0035, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(3.5180e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.148967
Average KL loss: 0.565445
Average total loss: 2.714412
tensor(0.0035, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.8148e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.144949
Average KL loss: 0.568762
Average total loss: 2.713711
tensor(0.0035, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-6.7803e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.074660
Average KL loss: 0.572101
Average total loss: 2.646761
tensor(0.0035, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-6.7225e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.084289
Average KL loss: 0.575317
Average total loss: 2.659606
tensor(0.0035, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-2.1895e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.036069
Average KL loss: 0.578622
Average total loss: 2.614691
tensor(0.0035, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-3.1481e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.040484
Average KL loss: 0.581649
Average total loss: 2.622133
tensor(0.0035, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.0786e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.962915
Average KL loss: 0.584935
Average total loss: 2.547850
tensor(0.0036, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.0866e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.029304
Average KL loss: 0.587964
Average total loss: 2.617267
tensor(0.0036, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-3.0692e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.955107
Average KL loss: 0.590973
Average total loss: 2.546080
tensor(0.0036, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.3043e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.932858
Average KL loss: 0.593777
Average total loss: 2.526635
tensor(0.0036, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.7387e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 2.019432
Average KL loss: 0.596665
Average total loss: 2.616098
tensor(0.0036, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-5.2021e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.894865
Average KL loss: 0.599711
Average total loss: 2.494576
tensor(0.0036, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-4.5985e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.879397
Average KL loss: 0.602335
Average total loss: 2.481732
tensor(0.0036, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.1314e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.943576
Average KL loss: 0.604898
Average total loss: 2.548474
tensor(0.0036, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.0738e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.899753
Average KL loss: 0.607987
Average total loss: 2.507740
tensor(0.0036, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.3743e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.816703
Average KL loss: 0.610727
Average total loss: 2.427429
tensor(0.0036, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-7.9727e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.866503
Average KL loss: 0.613178
Average total loss: 2.479681
tensor(0.0036, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-3.5843e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.840289
Average KL loss: 0.615726
Average total loss: 2.456015
tensor(0.0036, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.1854e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.808591
Average KL loss: 0.618339
Average total loss: 2.426930
tensor(0.0037, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-6.4774e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.764690
Average KL loss: 0.620591
Average total loss: 2.385281
tensor(0.0037, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-5.7770e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.717007
Average KL loss: 0.622769
Average total loss: 2.339777
tensor(0.0037, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-6.6751e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.792225
Average KL loss: 0.625097
Average total loss: 2.417322
tensor(0.0037, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-6.2982e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.797004
Average KL loss: 0.627702
Average total loss: 2.424706
tensor(0.0037, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-5.5979e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.768386
Average KL loss: 0.630345
Average total loss: 2.398731
tensor(0.0037, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.9675e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.718386
Average KL loss: 0.632839
Average total loss: 2.351225
tensor(0.0037, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-5.3661e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.709459
Average KL loss: 0.634965
Average total loss: 2.344424
tensor(0.0037, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-5.9543e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.691194
Average KL loss: 0.637271
Average total loss: 2.328465
tensor(0.0037, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(1.4741e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.718357
Average KL loss: 0.639595
Average total loss: 2.357952
tensor(0.0037, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.7068e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.630586
Average KL loss: 0.641568
Average total loss: 2.272154
tensor(0.0037, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-6.0941e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.626071
Average KL loss: 0.643656
Average total loss: 2.269726
tensor(0.0037, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-4.9031e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.588491
Average KL loss: 0.645818
Average total loss: 2.234309
tensor(0.0037, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-9.6762e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.643987
Average KL loss: 0.647769
Average total loss: 2.291757
tensor(0.0038, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-5.0367e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.602414
Average KL loss: 0.649599
Average total loss: 2.252013
tensor(0.0038, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.5196e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.587153
Average KL loss: 0.651453
Average total loss: 2.238607
tensor(0.0038, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.2778e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.629017
Average KL loss: 0.653258
Average total loss: 2.282275
tensor(0.0038, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-5.2594e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.549484
Average KL loss: 0.655038
Average total loss: 2.204522
tensor(0.0038, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(2.1131e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.559849
Average KL loss: 0.656766
Average total loss: 2.216616
tensor(0.0038, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.6414e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.533923
Average KL loss: 0.658496
Average total loss: 2.192419
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.6848e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.530362
Average KL loss: 0.660224
Average total loss: 2.190586
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-7.0169e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.555249
Average KL loss: 0.661864
Average total loss: 2.217113
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-9.1831e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.516407
Average KL loss: 0.663589
Average total loss: 2.179996
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.1877e-07, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.465563
Average KL loss: 0.665317
Average total loss: 2.130881
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-4.8014e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.514995
Average KL loss: 0.667005
Average total loss: 2.182000
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.6905e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.481058
Average KL loss: 0.668689
Average total loss: 2.149747
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(4.7663e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.517803
Average KL loss: 0.670288
Average total loss: 2.188090
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5023e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.498086
Average KL loss: 0.672053
Average total loss: 2.170140
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.4565e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.488558
Average KL loss: 0.673647
Average total loss: 2.162205
tensor(0.0038, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.0402e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.450325
Average KL loss: 0.675163
Average total loss: 2.125489
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-6.4693e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.460286
Average KL loss: 0.676453
Average total loss: 2.136739
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.4817e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.449604
Average KL loss: 0.677830
Average total loss: 2.127434
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.0268e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.466113
Average KL loss: 0.679210
Average total loss: 2.145323
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.4381e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.424681
Average KL loss: 0.680791
Average total loss: 2.105473
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.1189e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.418588
Average KL loss: 0.682082
Average total loss: 2.100670
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.7525e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.414681
Average KL loss: 0.683359
Average total loss: 2.098040
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.2296e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.362455
Average KL loss: 0.684563
Average total loss: 2.047018
tensor(0.0039, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.8643e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.439028
Average KL loss: 0.685752
Average total loss: 2.124780
tensor(0.0039, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.3546e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.362005
Average KL loss: 0.687127
Average total loss: 2.049132
tensor(0.0039, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-6.0684e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.388103
Average KL loss: 0.688360
Average total loss: 2.076463
tensor(0.0039, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.2811e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.359226
Average KL loss: 0.689601
Average total loss: 2.048828
tensor(0.0039, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.5861e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.397784
Average KL loss: 0.690939
Average total loss: 2.088723
tensor(0.0039, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.4666e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.343031
Average KL loss: 0.692370
Average total loss: 2.035401
tensor(0.0039, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-4.7675e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.374364
Average KL loss: 0.693786
Average total loss: 2.068150
tensor(0.0039, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-8.4811e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.341630
Average KL loss: 0.695168
Average total loss: 2.036798
tensor(0.0039, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.2716e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.312078
Average KL loss: 0.696061
Average total loss: 2.008139
tensor(0.0039, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.2534e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.307736
Average KL loss: 0.697107
Average total loss: 2.004843
tensor(0.0039, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-2.6927e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.379683
Average KL loss: 0.698306
Average total loss: 2.077989
tensor(0.0040, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.2253e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.306089
Average KL loss: 0.699624
Average total loss: 2.005713
tensor(0.0040, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.0222e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.289060
Average KL loss: 0.700687
Average total loss: 1.989746
tensor(0.0040, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-4.6936e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.280039
Average KL loss: 0.701614
Average total loss: 1.981653
tensor(0.0040, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-3.2163e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.351276
Average KL loss: 0.702752
Average total loss: 2.054027
tensor(0.0040, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.7019e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.278819
Average KL loss: 0.704062
Average total loss: 1.982880
tensor(0.0040, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.2987e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.255077
Average KL loss: 0.705131
Average total loss: 1.960208
tensor(0.0040, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-8.4055e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.267576
Average KL loss: 0.706073
Average total loss: 1.973649
tensor(0.0040, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.4685e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.278878
Average KL loss: 0.706897
Average total loss: 1.985775
tensor(0.0040, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.1038e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.247062
Average KL loss: 0.707784
Average total loss: 1.954846
tensor(0.0040, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(1.0134e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.277320
Average KL loss: 0.708888
Average total loss: 1.986209
tensor(0.0040, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.2991e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.264850
Average KL loss: 0.709954
Average total loss: 1.974804
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-9.6844e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.215209
Average KL loss: 0.710785
Average total loss: 1.925994
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.5176e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.264080
Average KL loss: 0.711777
Average total loss: 1.975858
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.1097e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.210292
Average KL loss: 0.712540
Average total loss: 1.922832
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.8029e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.224423
Average KL loss: 0.713349
Average total loss: 1.937772
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.7215e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.226326
Average KL loss: 0.714350
Average total loss: 1.940677
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.9619e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.208350
Average KL loss: 0.715249
Average total loss: 1.923599
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-4.1042e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.233413
Average KL loss: 0.716201
Average total loss: 1.949614
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.8641e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.202338
Average KL loss: 0.717232
Average total loss: 1.919570
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.5921e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.189621
Average KL loss: 0.718114
Average total loss: 1.907735
tensor(0.0040, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.1699e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.195329
Average KL loss: 0.719018
Average total loss: 1.914347
tensor(0.0041, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.8652e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.176294
Average KL loss: 0.719757
Average total loss: 1.896051
tensor(0.0041, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-4.7691e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.190016
Average KL loss: 0.720668
Average total loss: 1.910685
tensor(0.0041, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.3613e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.171187
Average KL loss: 0.721491
Average total loss: 1.892678
tensor(0.0041, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.6810e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.192570
Average KL loss: 0.722491
Average total loss: 1.915061
tensor(0.0041, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.8947e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.167411
Average KL loss: 0.723377
Average total loss: 1.890788
tensor(0.0041, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.6626e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.152325
Average KL loss: 0.724292
Average total loss: 1.876617
tensor(0.0041, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.4241e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.174066
Average KL loss: 0.725035
Average total loss: 1.899101
tensor(0.0041, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-9.4743e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.159321
Average KL loss: 0.725932
Average total loss: 1.885252
tensor(0.0041, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.3798e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.144720
Average KL loss: 0.726459
Average total loss: 1.871179
tensor(0.0041, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(9.9923e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.134493
Average KL loss: 0.727020
Average total loss: 1.861513
tensor(0.0041, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(3.3363e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.142830
Average KL loss: 0.727697
Average total loss: 1.870526
tensor(0.0041, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9399e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.109485
Average KL loss: 0.728563
Average total loss: 1.838049
tensor(0.0041, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.1004e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.137127
Average KL loss: 0.729199
Average total loss: 1.866326
tensor(0.0041, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.5933e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.155976
Average KL loss: 0.730142
Average total loss: 1.886118
tensor(0.0041, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.2960e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.127204
Average KL loss: 0.730994
Average total loss: 1.858198
tensor(0.0041, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-3.2714e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.119666
Average KL loss: 0.731457
Average total loss: 1.851123
tensor(0.0041, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.7745e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.103325
Average KL loss: 0.731753
Average total loss: 1.835078
tensor(0.0041, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.7099e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.112242
Average KL loss: 0.732122
Average total loss: 1.844364
tensor(0.0041, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(1.7908e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.076947
Average KL loss: 0.732507
Average total loss: 1.809454
tensor(0.0041, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.1589e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.082675
Average KL loss: 0.732975
Average total loss: 1.815650
tensor(0.0041, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.5359e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.096977
Average KL loss: 0.733643
Average total loss: 1.830620
tensor(0.0041, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4789e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.099355
Average KL loss: 0.734220
Average total loss: 1.833574
tensor(0.0041, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.5539e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.084271
Average KL loss: 0.734846
Average total loss: 1.819117
tensor(0.0042, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-4.9462e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.066521
Average KL loss: 0.735461
Average total loss: 1.801982
tensor(0.0042, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-6.6016e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.116774
Average KL loss: 0.736180
Average total loss: 1.852954
tensor(0.0042, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-3.4888e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.067679
Average KL loss: 0.736904
Average total loss: 1.804583
tensor(0.0042, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-3.8989e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.107389
Average KL loss: 0.737523
Average total loss: 1.844911
tensor(0.0042, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-2.3284e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.074035
Average KL loss: 0.738303
Average total loss: 1.812338
tensor(0.0042, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-1.6686e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.066770
Average KL loss: 0.739044
Average total loss: 1.805814
tensor(0.0042, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-7.4247e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.067295
Average KL loss: 0.739644
Average total loss: 1.806939
tensor(0.0042, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.4809e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.064784
Average KL loss: 0.740045
Average total loss: 1.804829
tensor(0.0042, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.1289e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.087112
Average KL loss: 0.740551
Average total loss: 1.827663
tensor(0.0042, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.8916e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.104400
Average KL loss: 0.741339
Average total loss: 1.845739
tensor(0.0042, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.4382e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.049543
Average KL loss: 0.742122
Average total loss: 1.791665
tensor(0.0042, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(1.3964e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.046003
Average KL loss: 0.742742
Average total loss: 1.788745
tensor(0.0042, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.2472e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.059340
Average KL loss: 0.743527
Average total loss: 1.802867
tensor(0.0042, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(3.2798e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.016795
Average KL loss: 0.743992
Average total loss: 1.760787
tensor(0.0042, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-1.9454e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.046056
Average KL loss: 0.744377
Average total loss: 1.790433
tensor(0.0042, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-1.3479e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.025169
Average KL loss: 0.744893
Average total loss: 1.770061
tensor(0.0042, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-2.9195e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.064926
Average KL loss: 0.745550
Average total loss: 1.810476
tensor(0.0042, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(6.9987e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.036513
Average KL loss: 0.745943
Average total loss: 1.782456
tensor(0.0042, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-2.5025e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.035756
Average KL loss: 0.746677
Average total loss: 1.782434
tensor(0.0042, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-2.2324e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.012502
Average KL loss: 0.747324
Average total loss: 1.759826
tensor(0.0042, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(3.9684e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.023111
Average KL loss: 0.747487
Average total loss: 1.770597
tensor(0.0042, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-1.3994e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.018075
Average KL loss: 0.747885
Average total loss: 1.765960
tensor(0.0042, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-2.3195e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.994587
Average KL loss: 0.748309
Average total loss: 1.742897
tensor(0.0042, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(5.2619e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.011353
Average KL loss: 0.748815
Average total loss: 1.760168
tensor(0.0042, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-6.2374e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.002541
Average KL loss: 0.749395
Average total loss: 1.751936
tensor(0.0042, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-7.1186e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.986321
Average KL loss: 0.749821
Average total loss: 1.736143
tensor(0.0042, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-6.2708e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.998029
Average KL loss: 0.750093
Average total loss: 1.748122
tensor(0.0043, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(1.0079e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.987295
Average KL loss: 0.750466
Average total loss: 1.737761
tensor(0.0043, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-2.6932e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.034748
Average KL loss: 0.751121
Average total loss: 1.785869
tensor(0.0043, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-3.8413e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.987171
Average KL loss: 0.751750
Average total loss: 1.738921
tensor(0.0043, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-2.6827e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.985927
Average KL loss: 0.752212
Average total loss: 1.738139
tensor(0.0043, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(2.5293e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.966187
Average KL loss: 0.752610
Average total loss: 1.718797
tensor(0.0043, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(1.2235e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.973286
Average KL loss: 0.752825
Average total loss: 1.726111
tensor(0.0043, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-3.3123e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.974782
Average KL loss: 0.753328
Average total loss: 1.728110
tensor(0.0043, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-7.7035e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.947227
Average KL loss: 0.753689
Average total loss: 1.700916
tensor(0.0043, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-3.9639e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.978312
Average KL loss: 0.753980
Average total loss: 1.732292
tensor(0.0043, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.8848e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.969726
Average KL loss: 0.754551
Average total loss: 1.724278
tensor(0.0043, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-7.1284e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.940869
Average KL loss: 0.754852
Average total loss: 1.695721
tensor(0.0043, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-4.0585e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.958707
Average KL loss: 0.754977
Average total loss: 1.713684
tensor(0.0043, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.8851e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.953827
Average KL loss: 0.755285
Average total loss: 1.709112
tensor(0.0043, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.4398e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.964008
Average KL loss: 0.755633
Average total loss: 1.719641
tensor(0.0043, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-8.5728e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.946712
Average KL loss: 0.756070
Average total loss: 1.702782
tensor(0.0043, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-7.0600e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.955976
Average KL loss: 0.756423
Average total loss: 1.712399
tensor(0.0043, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-2.9560e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.950470
Average KL loss: 0.756691
Average total loss: 1.707161
tensor(0.0043, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-2.1461e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.957239
Average KL loss: 0.757160
Average total loss: 1.714399
tensor(0.0043, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-5.1184e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.946346
Average KL loss: 0.757409
Average total loss: 1.703755
tensor(0.0043, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.4241e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.915705
Average KL loss: 0.757889
Average total loss: 1.673594
tensor(0.0043, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(8.1206e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.914327
Average KL loss: 0.758388
Average total loss: 1.672714
tensor(0.0043, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(4.0362e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.909574
Average KL loss: 0.758567
Average total loss: 1.668141
tensor(0.0043, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.1132e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.940632
Average KL loss: 0.758763
Average total loss: 1.699395
tensor(0.0043, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-7.0428e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.929184
Average KL loss: 0.759042
Average total loss: 1.688225
tensor(0.0043, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.1915e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.939549
Average KL loss: 0.759235
Average total loss: 1.698784
tensor(0.0043, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.2857e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.927820
Average KL loss: 0.759598
Average total loss: 1.687417
tensor(0.0043, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(4.0503e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.919654
Average KL loss: 0.759959
Average total loss: 1.679614
tensor(0.0043, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.4348e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.921297
Average KL loss: 0.760662
Average total loss: 1.681959
tensor(0.0044, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.0401e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.909533
Average KL loss: 0.761148
Average total loss: 1.670681
tensor(0.0044, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-9.0315e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.914943
Average KL loss: 0.761438
Average total loss: 1.676381
tensor(0.0044, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.3362e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.912985
Average KL loss: 0.761726
Average total loss: 1.674711
tensor(0.0044, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-4.6349e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.919706
Average KL loss: 0.761984
Average total loss: 1.681691
tensor(0.0044, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.4309e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.926635
Average KL loss: 0.762414
Average total loss: 1.689049
tensor(0.0044, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-2.0819e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.887531
Average KL loss: 0.762676
Average total loss: 1.650207
tensor(0.0044, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.1161e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.911961
Average KL loss: 0.762673
Average total loss: 1.674634
tensor(0.0044, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.3688e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.910789
Average KL loss: 0.762672
Average total loss: 1.673462
tensor(0.0044, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.1513e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.901277
Average KL loss: 0.762692
Average total loss: 1.663968
tensor(0.0044, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(1.5396e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.904008
Average KL loss: 0.762698
Average total loss: 1.666706
tensor(0.0044, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(1.1922e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.898887
Average KL loss: 0.762695
Average total loss: 1.661582
 Percentile value: 4.693220853805541
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/7]: ---
conv1.weight         | nonzeros =     505 /    1728             ( 29.22%) | total_pruned =    1223 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
bn1.bias             | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     276 /   36864             (  0.75%) | total_pruned =   36588 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     296 /   36864             (  0.80%) | total_pruned =   36568 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     261 /   36864             (  0.71%) | total_pruned =   36603 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     236 /   36864             (  0.64%) | total_pruned =   36628 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     315 /   73728             (  0.43%) | total_pruned =   73413 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     412 /  147456             (  0.28%) | total_pruned =  147044 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     231 /    8192             (  2.82%) | total_pruned =    7961 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     215 /  147456             (  0.15%) | total_pruned =  147241 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     208 /  147456             (  0.14%) | total_pruned =  147248 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     428 /  294912             (  0.15%) | total_pruned =  294484 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     224 /     256             ( 87.50%) | total_pruned =      32 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     464 /  589824             (  0.08%) | total_pruned =  589360 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     169 /   32768             (  0.52%) | total_pruned =   32599 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     188 /  589824             (  0.03%) | total_pruned =  589636 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     182 /  589824             (  0.03%) | total_pruned =  589642 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     115 /     256             ( 44.92%) | total_pruned =     141 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     442 / 1179648             (  0.04%) | total_pruned = 1179206 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     262 /     512             ( 51.17%) | total_pruned =     250 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     375 / 2359296             (  0.02%) | total_pruned = 2358921 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     184 /     512             ( 35.94%) | total_pruned =     328 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      83 /  131072             (  0.06%) | total_pruned =  130989 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      68 /     512             ( 13.28%) | total_pruned =     444 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     120 / 2359296             (  0.01%) | total_pruned = 2359176 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      66 /     512             ( 12.89%) | total_pruned =     446 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      54 / 2359296             (  0.00%) | total_pruned = 2359242 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      38 /     512             (  7.42%) | total_pruned =     474 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     307 /    5120             (  6.00%) | total_pruned =    4813 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 156/200 Loss: 0.578376 Accuracy: 71.95 79.16 % Best test Accuracy: 72.19%
