Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/8]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2560e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302782
Average KL loss: 0.000003
Average total loss: 2.302784
tensor(5.2437e-05, device='cuda:0') tensor(4.9094e-06, device='cuda:0') tensor(-2.4284e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.303061
Average KL loss: 0.000003
Average total loss: 2.303065
tensor(0.0001, device='cuda:0') tensor(1.2362e-05, device='cuda:0') tensor(-2.2978e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.302860
Average KL loss: 0.000005
Average total loss: 2.302864
tensor(0.0002, device='cuda:0') tensor(2.2339e-05, device='cuda:0') tensor(-1.7419e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.302792
Average KL loss: 0.000006
Average total loss: 2.302798
tensor(0.0002, device='cuda:0') tensor(3.5034e-05, device='cuda:0') tensor(-4.1102e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.302996
Average KL loss: 0.000008
Average total loss: 2.303004
tensor(0.0003, device='cuda:0') tensor(5.0899e-05, device='cuda:0') tensor(-4.6270e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.302704
Average KL loss: 0.000011
Average total loss: 2.302715
tensor(0.0004, device='cuda:0') tensor(6.7302e-05, device='cuda:0') tensor(9.6186e-11, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.302292
Average KL loss: 0.000013
Average total loss: 2.302305
tensor(0.0005, device='cuda:0') tensor(8.7845e-05, device='cuda:0') tensor(-1.4988e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.302135
Average KL loss: 0.000016
Average total loss: 2.302152
tensor(0.0006, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-6.0084e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.302095
Average KL loss: 0.000021
Average total loss: 2.302115
tensor(0.0007, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-7.4218e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.301589
Average KL loss: 0.000026
Average total loss: 2.301615
tensor(0.0009, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-5.4725e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.301555
Average KL loss: 0.000032
Average total loss: 2.301587
tensor(0.0010, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-1.9223e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.301023
Average KL loss: 0.000041
Average total loss: 2.301064
tensor(0.0012, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.6775e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.299628
Average KL loss: 0.000052
Average total loss: 2.299680
tensor(0.0015, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-3.4856e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.298697
Average KL loss: 0.000070
Average total loss: 2.298766
tensor(0.0019, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.6275e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.297051
Average KL loss: 0.000091
Average total loss: 2.297143
tensor(0.0023, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.3500e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.291838
Average KL loss: 0.000125
Average total loss: 2.291963
tensor(0.0029, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0342e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.288439
Average KL loss: 0.000173
Average total loss: 2.288612
tensor(0.0036, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.0873e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.278239
Average KL loss: 0.000240
Average total loss: 2.278480
tensor(0.0046, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.8361e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.254708
Average KL loss: 0.000338
Average total loss: 2.255047
tensor(0.0059, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.3192e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.228390
Average KL loss: 0.000477
Average total loss: 2.228867
tensor(0.0077, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.5437e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.189236
Average KL loss: 0.000660
Average total loss: 2.189896
tensor(0.0098, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.7870e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.143879
Average KL loss: 0.000893
Average total loss: 2.144772
tensor(0.0123, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.2959e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.078008
Average KL loss: 0.001164
Average total loss: 2.079172
tensor(0.0152, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-9.1040e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.026992
Average KL loss: 0.001472
Average total loss: 2.028464
tensor(0.0183, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.1278e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.960836
Average KL loss: 0.001808
Average total loss: 1.962645
tensor(0.0215, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.1626e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.876796
Average KL loss: 0.002159
Average total loss: 1.878956
tensor(0.0249, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-1.1560e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.822626
Average KL loss: 0.002507
Average total loss: 1.825132
tensor(0.0282, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-1.1101e-07, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.754981
Average KL loss: 0.002839
Average total loss: 1.757819
tensor(0.0312, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-9.9777e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.688415
Average KL loss: 0.003161
Average total loss: 1.691576
tensor(0.0343, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.1082e-07, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.637122
Average KL loss: 0.003478
Average total loss: 1.640600
tensor(0.0371, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.1028e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.588398
Average KL loss: 0.003772
Average total loss: 1.592170
tensor(0.0397, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-1.2945e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.527881
Average KL loss: 0.004053
Average total loss: 1.531934
tensor(0.0423, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.2218e-07, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.488223
Average KL loss: 0.004318
Average total loss: 1.492541
tensor(0.0446, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-1.2844e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.458196
Average KL loss: 0.004576
Average total loss: 1.462772
tensor(0.0469, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.1906e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.407816
Average KL loss: 0.004833
Average total loss: 1.412649
tensor(0.0490, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-1.0690e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.362519
Average KL loss: 0.005071
Average total loss: 1.367590
tensor(0.0511, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.1350e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.314574
Average KL loss: 0.005301
Average total loss: 1.319875
tensor(0.0530, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-1.2047e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.285523
Average KL loss: 0.005519
Average total loss: 1.291042
tensor(0.0549, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.1620e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.259207
Average KL loss: 0.005726
Average total loss: 1.264933
tensor(0.0566, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-1.1629e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.223196
Average KL loss: 0.005935
Average total loss: 1.229130
tensor(0.0583, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-1.1046e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.183804
Average KL loss: 0.006133
Average total loss: 1.189937
tensor(0.0599, device='cuda:0') tensor(0.0419, device='cuda:0') tensor(-1.2831e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.174943
Average KL loss: 0.006324
Average total loss: 1.181267
tensor(0.0615, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-9.9277e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.122505
Average KL loss: 0.006508
Average total loss: 1.129013
tensor(0.0629, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-1.0159e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.109479
Average KL loss: 0.006693
Average total loss: 1.116172
tensor(0.0644, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-1.0477e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.085231
Average KL loss: 0.006874
Average total loss: 1.092105
tensor(0.0657, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.1195e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.062590
Average KL loss: 0.007042
Average total loss: 1.069633
tensor(0.0670, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-9.0589e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.037532
Average KL loss: 0.007198
Average total loss: 1.044730
tensor(0.0682, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-1.0433e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.012418
Average KL loss: 0.007344
Average total loss: 1.019762
tensor(0.0693, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(-9.8072e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.010576
Average KL loss: 0.007490
Average total loss: 1.018066
tensor(0.0704, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-9.8434e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.973405
Average KL loss: 0.007630
Average total loss: 0.981035
tensor(0.0715, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-9.0496e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.961710
Average KL loss: 0.007768
Average total loss: 0.969478
tensor(0.0726, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(-1.0113e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.951661
Average KL loss: 0.007901
Average total loss: 0.959562
tensor(0.0736, device='cuda:0') tensor(0.0532, device='cuda:0') tensor(-8.9806e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.933103
Average KL loss: 0.008026
Average total loss: 0.941129
tensor(0.0745, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(-8.4506e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.943446
Average KL loss: 0.008146
Average total loss: 0.951592
tensor(0.0754, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(-8.3890e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.900275
Average KL loss: 0.008267
Average total loss: 0.908542
tensor(0.0763, device='cuda:0') tensor(0.0555, device='cuda:0') tensor(-8.3146e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.896883
Average KL loss: 0.008383
Average total loss: 0.905266
tensor(0.0772, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-8.5569e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.881620
Average KL loss: 0.008499
Average total loss: 0.890119
tensor(0.0780, device='cuda:0') tensor(0.0570, device='cuda:0') tensor(-8.7846e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.874644
Average KL loss: 0.008608
Average total loss: 0.883252
tensor(0.0789, device='cuda:0') tensor(0.0577, device='cuda:0') tensor(-8.0874e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.853611
Average KL loss: 0.008712
Average total loss: 0.862323
tensor(0.0796, device='cuda:0') tensor(0.0584, device='cuda:0') tensor(-8.6062e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.861821
Average KL loss: 0.008816
Average total loss: 0.870636
tensor(0.0803, device='cuda:0') tensor(0.0591, device='cuda:0') tensor(-7.6659e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.818016
Average KL loss: 0.008915
Average total loss: 0.826931
tensor(0.0811, device='cuda:0') tensor(0.0597, device='cuda:0') tensor(-7.0246e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.832140
Average KL loss: 0.009007
Average total loss: 0.841148
tensor(0.0818, device='cuda:0') tensor(0.0603, device='cuda:0') tensor(-8.6419e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.800444
Average KL loss: 0.009097
Average total loss: 0.809541
tensor(0.0824, device='cuda:0') tensor(0.0609, device='cuda:0') tensor(-8.0101e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.789272
Average KL loss: 0.009176
Average total loss: 0.798448
tensor(0.0831, device='cuda:0') tensor(0.0614, device='cuda:0') tensor(-6.4742e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.787589
Average KL loss: 0.009258
Average total loss: 0.796847
tensor(0.0837, device='cuda:0') tensor(0.0619, device='cuda:0') tensor(-7.7203e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.788144
Average KL loss: 0.009336
Average total loss: 0.797480
tensor(0.0843, device='cuda:0') tensor(0.0624, device='cuda:0') tensor(-9.0063e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.761168
Average KL loss: 0.009413
Average total loss: 0.770581
tensor(0.0849, device='cuda:0') tensor(0.0629, device='cuda:0') tensor(-6.9066e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.753083
Average KL loss: 0.009483
Average total loss: 0.762566
tensor(0.0854, device='cuda:0') tensor(0.0634, device='cuda:0') tensor(-7.3932e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.749882
Average KL loss: 0.009555
Average total loss: 0.759437
tensor(0.0860, device='cuda:0') tensor(0.0638, device='cuda:0') tensor(-7.3076e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.741518
Average KL loss: 0.009621
Average total loss: 0.751139
tensor(0.0865, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-7.6260e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.725912
Average KL loss: 0.009689
Average total loss: 0.735601
tensor(0.0871, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-6.5967e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.737903
Average KL loss: 0.009758
Average total loss: 0.747662
tensor(0.0876, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-6.8141e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.718367
Average KL loss: 0.009824
Average total loss: 0.728192
tensor(0.0881, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-6.9938e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.691668
Average KL loss: 0.009885
Average total loss: 0.701554
tensor(0.0886, device='cuda:0') tensor(0.0660, device='cuda:0') tensor(-7.4191e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.702257
Average KL loss: 0.009944
Average total loss: 0.712201
tensor(0.0891, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-6.7506e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.693184
Average KL loss: 0.010003
Average total loss: 0.703186
tensor(0.0896, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-7.8680e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.686039
Average KL loss: 0.010061
Average total loss: 0.696100
tensor(0.0901, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(-6.1984e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.682236
Average KL loss: 0.010113
Average total loss: 0.692349
tensor(0.0905, device='cuda:0') tensor(0.0675, device='cuda:0') tensor(-6.1393e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.663676
Average KL loss: 0.010163
Average total loss: 0.673839
tensor(0.0909, device='cuda:0') tensor(0.0678, device='cuda:0') tensor(-5.4280e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.663035
Average KL loss: 0.010214
Average total loss: 0.673249
tensor(0.0913, device='cuda:0') tensor(0.0682, device='cuda:0') tensor(-6.0707e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.659464
Average KL loss: 0.010263
Average total loss: 0.669728
tensor(0.0917, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-5.5832e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.645958
Average KL loss: 0.010311
Average total loss: 0.656269
tensor(0.0922, device='cuda:0') tensor(0.0688, device='cuda:0') tensor(-6.0368e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.645272
Average KL loss: 0.010359
Average total loss: 0.655630
tensor(0.0925, device='cuda:0') tensor(0.0691, device='cuda:0') tensor(-5.7640e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.643736
Average KL loss: 0.010404
Average total loss: 0.654140
tensor(0.0929, device='cuda:0') tensor(0.0694, device='cuda:0') tensor(-7.4312e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.624841
Average KL loss: 0.010445
Average total loss: 0.635286
tensor(0.0933, device='cuda:0') tensor(0.0697, device='cuda:0') tensor(-6.3581e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.617505
Average KL loss: 0.010485
Average total loss: 0.627991
tensor(0.0936, device='cuda:0') tensor(0.0700, device='cuda:0') tensor(-5.6980e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.624012
Average KL loss: 0.010524
Average total loss: 0.634536
tensor(0.0940, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-7.2060e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.604290
Average KL loss: 0.010561
Average total loss: 0.614851
tensor(0.0943, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-4.9707e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.599831
Average KL loss: 0.010598
Average total loss: 0.610429
tensor(0.0947, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-6.1140e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.595947
Average KL loss: 0.010637
Average total loss: 0.606584
tensor(0.0950, device='cuda:0') tensor(0.0710, device='cuda:0') tensor(-5.8352e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.609867
Average KL loss: 0.010677
Average total loss: 0.620544
tensor(0.0953, device='cuda:0') tensor(0.0713, device='cuda:0') tensor(-6.3204e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.588755
Average KL loss: 0.010714
Average total loss: 0.599469
tensor(0.0957, device='cuda:0') tensor(0.0715, device='cuda:0') tensor(-5.1083e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.577606
Average KL loss: 0.010746
Average total loss: 0.588352
tensor(0.0960, device='cuda:0') tensor(0.0717, device='cuda:0') tensor(-5.3026e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.584604
Average KL loss: 0.010777
Average total loss: 0.595381
tensor(0.0963, device='cuda:0') tensor(0.0720, device='cuda:0') tensor(-5.6447e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.580700
Average KL loss: 0.010809
Average total loss: 0.591509
tensor(0.0966, device='cuda:0') tensor(0.0722, device='cuda:0') tensor(-5.0215e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.563892
Average KL loss: 0.010842
Average total loss: 0.574734
tensor(0.0968, device='cuda:0') tensor(0.0724, device='cuda:0') tensor(-5.6791e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.567755
Average KL loss: 0.010873
Average total loss: 0.578628
tensor(0.0971, device='cuda:0') tensor(0.0726, device='cuda:0') tensor(-5.3471e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.557897
Average KL loss: 0.010905
Average total loss: 0.568801
tensor(0.0974, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(-5.3645e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.554786
Average KL loss: 0.010935
Average total loss: 0.565721
tensor(0.0977, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(-5.3570e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.551956
Average KL loss: 0.010967
Average total loss: 0.562924
tensor(0.0980, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(-4.7583e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.536098
Average KL loss: 0.010996
Average total loss: 0.547095
tensor(0.0982, device='cuda:0') tensor(0.0735, device='cuda:0') tensor(-4.1959e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.537848
Average KL loss: 0.011023
Average total loss: 0.548871
tensor(0.0985, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(-5.3787e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.538108
Average KL loss: 0.011051
Average total loss: 0.549158
tensor(0.0987, device='cuda:0') tensor(0.0739, device='cuda:0') tensor(-5.0942e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.517211
Average KL loss: 0.011080
Average total loss: 0.528291
tensor(0.0990, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(-5.2897e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.514099
Average KL loss: 0.011106
Average total loss: 0.525205
tensor(0.0993, device='cuda:0') tensor(0.0743, device='cuda:0') tensor(-5.5849e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.508278
Average KL loss: 0.011132
Average total loss: 0.519410
tensor(0.0995, device='cuda:0') tensor(0.0745, device='cuda:0') tensor(-4.9687e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.514460
Average KL loss: 0.011155
Average total loss: 0.525614
tensor(0.0997, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-6.6354e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.511445
Average KL loss: 0.011178
Average total loss: 0.522624
tensor(0.1000, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(-4.1659e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.503200
Average KL loss: 0.011201
Average total loss: 0.514401
tensor(0.1002, device='cuda:0') tensor(0.0750, device='cuda:0') tensor(-6.6064e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.495631
Average KL loss: 0.011223
Average total loss: 0.506854
tensor(0.1004, device='cuda:0') tensor(0.0752, device='cuda:0') tensor(-4.8071e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.494367
Average KL loss: 0.011243
Average total loss: 0.505610
tensor(0.1006, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(-4.2352e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.487318
Average KL loss: 0.011268
Average total loss: 0.498586
tensor(0.1008, device='cuda:0') tensor(0.0755, device='cuda:0') tensor(-3.8899e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.490805
Average KL loss: 0.011289
Average total loss: 0.502094
tensor(0.1010, device='cuda:0') tensor(0.0757, device='cuda:0') tensor(-4.7966e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.480864
Average KL loss: 0.011310
Average total loss: 0.492174
tensor(0.1012, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(-5.8399e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.473734
Average KL loss: 0.011333
Average total loss: 0.485067
tensor(0.1014, device='cuda:0') tensor(0.0760, device='cuda:0') tensor(-4.8343e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.477271
Average KL loss: 0.011353
Average total loss: 0.488623
tensor(0.1016, device='cuda:0') tensor(0.0762, device='cuda:0') tensor(-4.7156e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.463876
Average KL loss: 0.011374
Average total loss: 0.475250
tensor(0.1018, device='cuda:0') tensor(0.0764, device='cuda:0') tensor(-3.8355e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.470197
Average KL loss: 0.011393
Average total loss: 0.481590
tensor(0.1020, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-3.9773e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.462612
Average KL loss: 0.011415
Average total loss: 0.474027
tensor(0.1022, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(-3.6065e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.454537
Average KL loss: 0.011434
Average total loss: 0.465971
tensor(0.1023, device='cuda:0') tensor(0.0768, device='cuda:0') tensor(-4.3698e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.459499
Average KL loss: 0.011453
Average total loss: 0.470952
tensor(0.1025, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(-3.9264e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.460097
Average KL loss: 0.011475
Average total loss: 0.471572
tensor(0.1027, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-5.2826e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.455022
Average KL loss: 0.011497
Average total loss: 0.466519
tensor(0.1029, device='cuda:0') tensor(0.0773, device='cuda:0') tensor(-3.9048e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.437226
Average KL loss: 0.011516
Average total loss: 0.448741
tensor(0.1031, device='cuda:0') tensor(0.0775, device='cuda:0') tensor(-3.9626e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.444017
Average KL loss: 0.011537
Average total loss: 0.455554
tensor(0.1033, device='cuda:0') tensor(0.0777, device='cuda:0') tensor(-4.4026e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.430666
Average KL loss: 0.011554
Average total loss: 0.442220
tensor(0.1034, device='cuda:0') tensor(0.0778, device='cuda:0') tensor(-5.5350e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.438680
Average KL loss: 0.011571
Average total loss: 0.450252
tensor(0.1036, device='cuda:0') tensor(0.0780, device='cuda:0') tensor(-3.9296e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.434419
Average KL loss: 0.011588
Average total loss: 0.446007
tensor(0.1037, device='cuda:0') tensor(0.0781, device='cuda:0') tensor(-3.4224e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.429674
Average KL loss: 0.011606
Average total loss: 0.441279
tensor(0.1039, device='cuda:0') tensor(0.0783, device='cuda:0') tensor(-4.4228e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.419661
Average KL loss: 0.011621
Average total loss: 0.431282
tensor(0.1040, device='cuda:0') tensor(0.0784, device='cuda:0') tensor(-4.3947e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.428414
Average KL loss: 0.011635
Average total loss: 0.440049
tensor(0.1041, device='cuda:0') tensor(0.0785, device='cuda:0') tensor(-3.9331e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.415394
Average KL loss: 0.011653
Average total loss: 0.427048
tensor(0.1043, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(-3.4167e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.421289
Average KL loss: 0.011669
Average total loss: 0.432958
tensor(0.1044, device='cuda:0') tensor(0.0788, device='cuda:0') tensor(-3.9095e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.418565
Average KL loss: 0.011687
Average total loss: 0.430252
tensor(0.1046, device='cuda:0') tensor(0.0790, device='cuda:0') tensor(-3.8546e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.403593
Average KL loss: 0.011707
Average total loss: 0.415300
tensor(0.1047, device='cuda:0') tensor(0.0792, device='cuda:0') tensor(-3.2510e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.402057
Average KL loss: 0.011725
Average total loss: 0.413781
tensor(0.1049, device='cuda:0') tensor(0.0793, device='cuda:0') tensor(-4.3433e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.402786
Average KL loss: 0.011741
Average total loss: 0.414527
tensor(0.1050, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-3.6399e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.403517
Average KL loss: 0.011759
Average total loss: 0.415275
tensor(0.1052, device='cuda:0') tensor(0.0796, device='cuda:0') tensor(-3.6841e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.394542
Average KL loss: 0.011778
Average total loss: 0.406320
tensor(0.1053, device='cuda:0') tensor(0.0798, device='cuda:0') tensor(-3.6068e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.388695
Average KL loss: 0.011794
Average total loss: 0.400489
tensor(0.1055, device='cuda:0') tensor(0.0799, device='cuda:0') tensor(-3.9570e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.391904
Average KL loss: 0.011812
Average total loss: 0.403716
tensor(0.1056, device='cuda:0') tensor(0.0801, device='cuda:0') tensor(-3.7694e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.390773
Average KL loss: 0.011831
Average total loss: 0.402605
tensor(0.1057, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(-4.8706e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.383954
Average KL loss: 0.011851
Average total loss: 0.395805
tensor(0.1059, device='cuda:0') tensor(0.0804, device='cuda:0') tensor(-3.5165e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.387443
Average KL loss: 0.011868
Average total loss: 0.399311
tensor(0.1060, device='cuda:0') tensor(0.0806, device='cuda:0') tensor(-3.6974e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.378571
Average KL loss: 0.011886
Average total loss: 0.390458
tensor(0.1062, device='cuda:0') tensor(0.0807, device='cuda:0') tensor(-4.5867e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.375014
Average KL loss: 0.011901
Average total loss: 0.386916
tensor(0.1063, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-4.1506e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.375922
Average KL loss: 0.011915
Average total loss: 0.387838
tensor(0.1064, device='cuda:0') tensor(0.0810, device='cuda:0') tensor(-2.9509e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.371884
Average KL loss: 0.011931
Average total loss: 0.383814
tensor(0.1065, device='cuda:0') tensor(0.0812, device='cuda:0') tensor(-3.7746e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.358621
Average KL loss: 0.011947
Average total loss: 0.370568
tensor(0.1066, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(-3.5062e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.363627
Average KL loss: 0.011963
Average total loss: 0.375590
tensor(0.1067, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(-3.8647e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.364885
Average KL loss: 0.011978
Average total loss: 0.376863
tensor(0.1068, device='cuda:0') tensor(0.0816, device='cuda:0') tensor(-3.6977e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.361827
Average KL loss: 0.011995
Average total loss: 0.373822
tensor(0.1069, device='cuda:0') tensor(0.0818, device='cuda:0') tensor(-2.9257e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.348775
Average KL loss: 0.012011
Average total loss: 0.360786
tensor(0.1071, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(-4.9586e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.359857
Average KL loss: 0.012026
Average total loss: 0.371883
tensor(0.1072, device='cuda:0') tensor(0.0821, device='cuda:0') tensor(-2.7573e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.360838
Average KL loss: 0.012041
Average total loss: 0.372880
tensor(0.1073, device='cuda:0') tensor(0.0822, device='cuda:0') tensor(-3.1459e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.338734
Average KL loss: 0.012058
Average total loss: 0.350792
tensor(0.1074, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-3.5937e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.340272
Average KL loss: 0.012073
Average total loss: 0.352345
tensor(0.1075, device='cuda:0') tensor(0.0825, device='cuda:0') tensor(-3.5165e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.344528
Average KL loss: 0.012088
Average total loss: 0.356616
tensor(0.1076, device='cuda:0') tensor(0.0827, device='cuda:0') tensor(-3.7886e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.345659
Average KL loss: 0.012104
Average total loss: 0.357763
tensor(0.1077, device='cuda:0') tensor(0.0828, device='cuda:0') tensor(-3.1108e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.346521
Average KL loss: 0.012122
Average total loss: 0.358643
tensor(0.1078, device='cuda:0') tensor(0.0830, device='cuda:0') tensor(-2.6935e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.334022
Average KL loss: 0.012139
Average total loss: 0.346161
tensor(0.1080, device='cuda:0') tensor(0.0832, device='cuda:0') tensor(-3.2735e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.338651
Average KL loss: 0.012157
Average total loss: 0.350808
tensor(0.1081, device='cuda:0') tensor(0.0833, device='cuda:0') tensor(-2.5171e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.338435
Average KL loss: 0.012176
Average total loss: 0.350612
tensor(0.1082, device='cuda:0') tensor(0.0835, device='cuda:0') tensor(-2.9760e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.329578
Average KL loss: 0.012193
Average total loss: 0.341771
tensor(0.1083, device='cuda:0') tensor(0.0836, device='cuda:0') tensor(-3.0861e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.329269
Average KL loss: 0.012208
Average total loss: 0.341477
tensor(0.1084, device='cuda:0') tensor(0.0838, device='cuda:0') tensor(-3.8242e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.332057
Average KL loss: 0.012225
Average total loss: 0.344282
tensor(0.1085, device='cuda:0') tensor(0.0840, device='cuda:0') tensor(-3.5359e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.323253
Average KL loss: 0.012242
Average total loss: 0.335494
tensor(0.1086, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(-2.6098e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.319390
Average KL loss: 0.012256
Average total loss: 0.331646
tensor(0.1086, device='cuda:0') tensor(0.0843, device='cuda:0') tensor(-2.8035e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.316822
Average KL loss: 0.012269
Average total loss: 0.329091
tensor(0.1087, device='cuda:0') tensor(0.0844, device='cuda:0') tensor(-2.4492e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.314377
Average KL loss: 0.012285
Average total loss: 0.326663
tensor(0.1088, device='cuda:0') tensor(0.0846, device='cuda:0') tensor(-3.3799e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.312484
Average KL loss: 0.012302
Average total loss: 0.324786
tensor(0.1089, device='cuda:0') tensor(0.0848, device='cuda:0') tensor(-3.9625e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.316508
Average KL loss: 0.012319
Average total loss: 0.328827
tensor(0.1090, device='cuda:0') tensor(0.0849, device='cuda:0') tensor(-2.9664e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.306736
Average KL loss: 0.012335
Average total loss: 0.319071
tensor(0.1091, device='cuda:0') tensor(0.0851, device='cuda:0') tensor(-3.1953e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.307770
Average KL loss: 0.012351
Average total loss: 0.320122
tensor(0.1092, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(-3.3919e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.305910
Average KL loss: 0.012367
Average total loss: 0.318277
tensor(0.1093, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(-3.3277e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.305828
Average KL loss: 0.012384
Average total loss: 0.318212
tensor(0.1094, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-3.1915e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.303062
Average KL loss: 0.012398
Average total loss: 0.315461
tensor(0.1095, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-2.6913e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.302358
Average KL loss: 0.012415
Average total loss: 0.314774
tensor(0.1096, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-3.0135e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.293768
Average KL loss: 0.012432
Average total loss: 0.306200
tensor(0.1097, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-3.2251e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.296840
Average KL loss: 0.012448
Average total loss: 0.309289
tensor(0.1097, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-2.5867e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.298300
Average KL loss: 0.012462
Average total loss: 0.310763
tensor(0.1098, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-3.0759e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.291494
Average KL loss: 0.012477
Average total loss: 0.303971
tensor(0.1099, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-2.3297e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.291590
Average KL loss: 0.012492
Average total loss: 0.304082
tensor(0.1100, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(-2.3931e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.287956
Average KL loss: 0.012509
Average total loss: 0.300465
tensor(0.1101, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(-3.9025e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.290542
Average KL loss: 0.012526
Average total loss: 0.303068
tensor(0.1102, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-2.7281e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.285326
Average KL loss: 0.012541
Average total loss: 0.297867
tensor(0.1102, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-2.5779e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.284800
Average KL loss: 0.012556
Average total loss: 0.297356
tensor(0.1103, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-2.8620e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.286384
Average KL loss: 0.012572
Average total loss: 0.298956
tensor(0.1104, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.6476e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.276331
Average KL loss: 0.012588
Average total loss: 0.288920
tensor(0.1105, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-2.2992e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.274025
Average KL loss: 0.012604
Average total loss: 0.286629
tensor(0.1106, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-2.4467e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.273480
Average KL loss: 0.012619
Average total loss: 0.286099
tensor(0.1107, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-2.3386e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.274319
Average KL loss: 0.012636
Average total loss: 0.286955
tensor(0.1108, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(-2.6445e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.268172
Average KL loss: 0.012651
Average total loss: 0.280824
tensor(0.1108, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(-2.6594e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.272361
Average KL loss: 0.012668
Average total loss: 0.285029
tensor(0.1109, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-3.2320e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.272756
Average KL loss: 0.012684
Average total loss: 0.285440
tensor(0.1110, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-3.1632e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.270418
Average KL loss: 0.012700
Average total loss: 0.283118
tensor(0.1111, device='cuda:0') tensor(0.0888, device='cuda:0') tensor(-2.4435e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.263307
Average KL loss: 0.012716
Average total loss: 0.276022
tensor(0.1112, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-2.2101e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.263601
Average KL loss: 0.012731
Average total loss: 0.276332
tensor(0.1112, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(-2.4796e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.264375
Average KL loss: 0.012746
Average total loss: 0.277122
tensor(0.1113, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-2.3486e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.262295
Average KL loss: 0.012762
Average total loss: 0.275057
 Percentile value: 0.4966977715492248
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/8]: ---
conv1.weight         | nonzeros =     407 /    1728             ( 23.55%) | total_pruned =    1321 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4638 /   36864             ( 12.58%) | total_pruned =   32226 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   10638 /   36864             ( 28.86%) | total_pruned =   26226 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   10267 /   36864             ( 27.85%) | total_pruned =   26597 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   13971 /   36864             ( 37.90%) | total_pruned =   22893 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   31152 /   73728             ( 42.25%) | total_pruned =   42576 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   61681 /  147456             ( 41.83%) | total_pruned =   85775 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3870 /    8192             ( 47.24%) | total_pruned =    4322 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   47111 /  147456             ( 31.95%) | total_pruned =  100345 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   46630 /  147456             ( 31.62%) | total_pruned =  100826 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  110429 /  294912             ( 37.44%) | total_pruned =  184483 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  211459 /  589824             ( 35.85%) | total_pruned =  378365 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   13820 /   32768             ( 42.18%) | total_pruned =   18948 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  188183 /  589824             ( 31.90%) | total_pruned =  401641 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  173680 /  589824             ( 29.45%) | total_pruned =  416144 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  365358 / 1179648             ( 30.97%) | total_pruned =  814290 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  647849 / 2359296             ( 27.46%) | total_pruned = 1711447 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     308 /     512             ( 60.16%) | total_pruned =     204 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   37731 /  131072             ( 28.79%) | total_pruned =   93341 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     305 /     512             ( 59.57%) | total_pruned =     207 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  543383 / 2359296             ( 23.03%) | total_pruned = 1815913 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  820276 / 2359296             ( 34.77%) | total_pruned = 1539020 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    4918 /    5120             ( 96.05%) | total_pruned =     202 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 54/100 Loss: 0.010756 Accuracy: 89.57 100.00 % Best test Accuracy: 89.57%
tensor(0.1114, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-1.4910e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.570995
Average KL loss: 0.012559
Average total loss: 0.583553
tensor(0.1113, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-8.2218e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.553108
Average KL loss: 0.012195
Average total loss: 0.565303
tensor(0.1115, device='cuda:0') tensor(0.0836, device='cuda:0') tensor(-1.0497e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.531514
Average KL loss: 0.011873
Average total loss: 0.543387
tensor(0.1117, device='cuda:0') tensor(0.0812, device='cuda:0') tensor(-6.9458e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.513201
Average KL loss: 0.011585
Average total loss: 0.524786
tensor(0.1118, device='cuda:0') tensor(0.0791, device='cuda:0') tensor(-7.0104e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.503549
Average KL loss: 0.011329
Average total loss: 0.514878
tensor(0.1120, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-6.7019e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.499603
Average KL loss: 0.011099
Average total loss: 0.510703
tensor(0.1121, device='cuda:0') tensor(0.0755, device='cuda:0') tensor(-6.3339e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.461455
Average KL loss: 0.010892
Average total loss: 0.472346
tensor(0.1123, device='cuda:0') tensor(0.0740, device='cuda:0') tensor(-9.0729e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.468967
Average KL loss: 0.010707
Average total loss: 0.479674
tensor(0.1124, device='cuda:0') tensor(0.0727, device='cuda:0') tensor(-6.5428e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.432132
Average KL loss: 0.010543
Average total loss: 0.442675
tensor(0.1125, device='cuda:0') tensor(0.0714, device='cuda:0') tensor(-7.8135e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.440820
Average KL loss: 0.010393
Average total loss: 0.451213
tensor(0.1126, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-5.2107e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.435055
Average KL loss: 0.010259
Average total loss: 0.445314
tensor(0.1126, device='cuda:0') tensor(0.0694, device='cuda:0') tensor(-6.9044e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.452470
Average KL loss: 0.010138
Average total loss: 0.462609
tensor(0.1127, device='cuda:0') tensor(0.0686, device='cuda:0') tensor(-7.0274e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.412628
Average KL loss: 0.010031
Average total loss: 0.422659
tensor(0.1127, device='cuda:0') tensor(0.0678, device='cuda:0') tensor(-5.8532e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.404761
Average KL loss: 0.009936
Average total loss: 0.414697
tensor(0.1127, device='cuda:0') tensor(0.0671, device='cuda:0') tensor(-7.3923e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.395342
Average KL loss: 0.009851
Average total loss: 0.405193
tensor(0.1128, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-5.0184e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.401520
Average KL loss: 0.009775
Average total loss: 0.411295
tensor(0.1128, device='cuda:0') tensor(0.0661, device='cuda:0') tensor(-6.1255e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.399892
Average KL loss: 0.009709
Average total loss: 0.409601
tensor(0.1128, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-5.0460e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.383394
Average KL loss: 0.009650
Average total loss: 0.393044
tensor(0.1127, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-5.0617e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.371989
Average KL loss: 0.009598
Average total loss: 0.381587
tensor(0.1127, device='cuda:0') tensor(0.0649, device='cuda:0') tensor(-5.6395e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.363666
Average KL loss: 0.009551
Average total loss: 0.373216
tensor(0.1127, device='cuda:0') tensor(0.0646, device='cuda:0') tensor(-4.4992e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.383394
Average KL loss: 0.009510
Average total loss: 0.392903
tensor(0.1126, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-5.0687e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.351846
Average KL loss: 0.009473
Average total loss: 0.361320
tensor(0.1126, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-4.4724e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.361969
Average KL loss: 0.009443
Average total loss: 0.371412
tensor(0.1125, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-4.6720e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.362521
Average KL loss: 0.009416
Average total loss: 0.371937
tensor(0.1124, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-4.7803e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.354569
Average KL loss: 0.009394
Average total loss: 0.363963
tensor(0.1124, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-6.1610e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.355310
Average KL loss: 0.009376
Average total loss: 0.364686
tensor(0.1123, device='cuda:0') tensor(0.0638, device='cuda:0') tensor(-4.2799e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.358925
Average KL loss: 0.009359
Average total loss: 0.368285
tensor(0.1122, device='cuda:0') tensor(0.0638, device='cuda:0') tensor(-5.1151e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.346715
Average KL loss: 0.009346
Average total loss: 0.356060
tensor(0.1121, device='cuda:0') tensor(0.0637, device='cuda:0') tensor(-3.6791e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.334264
Average KL loss: 0.009335
Average total loss: 0.343599
tensor(0.1120, device='cuda:0') tensor(0.0637, device='cuda:0') tensor(-5.1037e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.352722
Average KL loss: 0.009327
Average total loss: 0.362048
tensor(0.1119, device='cuda:0') tensor(0.0638, device='cuda:0') tensor(-4.1926e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.335950
Average KL loss: 0.009322
Average total loss: 0.345271
tensor(0.1118, device='cuda:0') tensor(0.0638, device='cuda:0') tensor(-6.3266e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.327178
Average KL loss: 0.009318
Average total loss: 0.336496
tensor(0.1117, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-5.0913e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.326997
Average KL loss: 0.009317
Average total loss: 0.336314
tensor(0.1117, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-4.7075e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.329687
Average KL loss: 0.009317
Average total loss: 0.339004
tensor(0.1115, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-4.4080e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.322011
Average KL loss: 0.009317
Average total loss: 0.331329
tensor(0.1115, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-5.0034e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.319491
Average KL loss: 0.009321
Average total loss: 0.328811
tensor(0.1114, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-3.8707e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.319691
Average KL loss: 0.009324
Average total loss: 0.329015
tensor(0.1112, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-3.8205e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.312994
Average KL loss: 0.009328
Average total loss: 0.322323
tensor(0.1112, device='cuda:0') tensor(0.0645, device='cuda:0') tensor(-4.2450e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.320354
Average KL loss: 0.009336
Average total loss: 0.329690
tensor(0.1111, device='cuda:0') tensor(0.0646, device='cuda:0') tensor(-3.5696e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.321032
Average KL loss: 0.009344
Average total loss: 0.330376
tensor(0.1110, device='cuda:0') tensor(0.0648, device='cuda:0') tensor(-3.0049e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.294981
Average KL loss: 0.009352
Average total loss: 0.304333
tensor(0.1109, device='cuda:0') tensor(0.0649, device='cuda:0') tensor(-3.9856e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.297602
Average KL loss: 0.009362
Average total loss: 0.306964
tensor(0.1108, device='cuda:0') tensor(0.0651, device='cuda:0') tensor(-4.5685e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.295848
Average KL loss: 0.009372
Average total loss: 0.305220
tensor(0.1107, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-6.9012e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.292691
Average KL loss: 0.009382
Average total loss: 0.302074
tensor(0.1106, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-3.8135e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.287184
Average KL loss: 0.009394
Average total loss: 0.296578
tensor(0.1105, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-4.6788e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.308640
Average KL loss: 0.009407
Average total loss: 0.318046
tensor(0.1105, device='cuda:0') tensor(0.0657, device='cuda:0') tensor(-3.7676e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.294947
Average KL loss: 0.009417
Average total loss: 0.304364
tensor(0.1104, device='cuda:0') tensor(0.0659, device='cuda:0') tensor(-4.4754e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.288537
Average KL loss: 0.009429
Average total loss: 0.297966
tensor(0.1103, device='cuda:0') tensor(0.0661, device='cuda:0') tensor(-4.0689e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.278813
Average KL loss: 0.009442
Average total loss: 0.288255
tensor(0.1102, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-3.5828e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.270484
Average KL loss: 0.009454
Average total loss: 0.279939
tensor(0.1101, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-3.4781e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.274937
Average KL loss: 0.009466
Average total loss: 0.284404
tensor(0.1100, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-3.0348e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.275537
Average KL loss: 0.009480
Average total loss: 0.285018
tensor(0.1100, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-3.0901e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.267734
Average KL loss: 0.009495
Average total loss: 0.277229
tensor(0.1099, device='cuda:0') tensor(0.0670, device='cuda:0') tensor(-3.4503e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.272827
Average KL loss: 0.009510
Average total loss: 0.282337
tensor(0.1098, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(-4.4917e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.269469
Average KL loss: 0.009524
Average total loss: 0.278993
tensor(0.1098, device='cuda:0') tensor(0.0674, device='cuda:0') tensor(-3.0832e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.264122
Average KL loss: 0.009539
Average total loss: 0.273661
tensor(0.1097, device='cuda:0') tensor(0.0675, device='cuda:0') tensor(-3.5060e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.270310
Average KL loss: 0.009556
Average total loss: 0.279866
tensor(0.1097, device='cuda:0') tensor(0.0678, device='cuda:0') tensor(-3.6898e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.258208
Average KL loss: 0.009571
Average total loss: 0.267780
tensor(0.1096, device='cuda:0') tensor(0.0679, device='cuda:0') tensor(-2.9666e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.254524
Average KL loss: 0.009587
Average total loss: 0.264112
tensor(0.1096, device='cuda:0') tensor(0.0681, device='cuda:0') tensor(-3.7069e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.256087
Average KL loss: 0.009603
Average total loss: 0.265690
tensor(0.1095, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-3.7463e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.253801
Average KL loss: 0.009619
Average total loss: 0.263419
tensor(0.1095, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-3.0743e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.255722
Average KL loss: 0.009634
Average total loss: 0.265356
tensor(0.1094, device='cuda:0') tensor(0.0687, device='cuda:0') tensor(-3.5828e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.249435
Average KL loss: 0.009648
Average total loss: 0.259084
tensor(0.1094, device='cuda:0') tensor(0.0689, device='cuda:0') tensor(-2.2208e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.258395
Average KL loss: 0.009665
Average total loss: 0.268060
tensor(0.1093, device='cuda:0') tensor(0.0691, device='cuda:0') tensor(-3.3967e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.236013
Average KL loss: 0.009681
Average total loss: 0.245694
tensor(0.1093, device='cuda:0') tensor(0.0693, device='cuda:0') tensor(-3.6396e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.257134
Average KL loss: 0.009696
Average total loss: 0.266830
tensor(0.1093, device='cuda:0') tensor(0.0695, device='cuda:0') tensor(-3.8105e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.256393
Average KL loss: 0.009714
Average total loss: 0.266107
tensor(0.1092, device='cuda:0') tensor(0.0697, device='cuda:0') tensor(-2.9132e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.246049
Average KL loss: 0.009730
Average total loss: 0.255779
tensor(0.1092, device='cuda:0') tensor(0.0699, device='cuda:0') tensor(-2.8755e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.234531
Average KL loss: 0.009746
Average total loss: 0.244277
tensor(0.1091, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-2.5910e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.247026
Average KL loss: 0.009762
Average total loss: 0.256788
tensor(0.1091, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-2.8304e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.234664
Average KL loss: 0.009779
Average total loss: 0.244442
tensor(0.1091, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-2.7570e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.238767
Average KL loss: 0.009794
Average total loss: 0.248561
tensor(0.1091, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-3.4239e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.240258
Average KL loss: 0.009810
Average total loss: 0.250068
tensor(0.1090, device='cuda:0') tensor(0.0709, device='cuda:0') tensor(-2.7917e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.236100
Average KL loss: 0.009826
Average total loss: 0.245926
tensor(0.1090, device='cuda:0') tensor(0.0711, device='cuda:0') tensor(-2.8111e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.229031
Average KL loss: 0.009841
Average total loss: 0.238872
tensor(0.1090, device='cuda:0') tensor(0.0712, device='cuda:0') tensor(-2.4605e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.217902
Average KL loss: 0.009857
Average total loss: 0.227758
tensor(0.1090, device='cuda:0') tensor(0.0714, device='cuda:0') tensor(-3.7646e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.224835
Average KL loss: 0.009873
Average total loss: 0.234708
tensor(0.1089, device='cuda:0') tensor(0.0716, device='cuda:0') tensor(-3.8267e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.223733
Average KL loss: 0.009889
Average total loss: 0.233622
tensor(0.1089, device='cuda:0') tensor(0.0718, device='cuda:0') tensor(-3.3812e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.224573
Average KL loss: 0.009905
Average total loss: 0.234478
tensor(0.1089, device='cuda:0') tensor(0.0720, device='cuda:0') tensor(-3.3778e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.226088
Average KL loss: 0.009921
Average total loss: 0.236009
tensor(0.1089, device='cuda:0') tensor(0.0722, device='cuda:0') tensor(-3.1808e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.216981
Average KL loss: 0.009937
Average total loss: 0.226917
tensor(0.1089, device='cuda:0') tensor(0.0724, device='cuda:0') tensor(-3.7247e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.218331
Average KL loss: 0.009953
Average total loss: 0.228284
tensor(0.1089, device='cuda:0') tensor(0.0726, device='cuda:0') tensor(-2.6604e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.217812
Average KL loss: 0.009970
Average total loss: 0.227782
tensor(0.1088, device='cuda:0') tensor(0.0728, device='cuda:0') tensor(-4.2474e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.214794
Average KL loss: 0.009985
Average total loss: 0.224779
tensor(0.1088, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(-2.4989e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.206014
Average KL loss: 0.010001
Average total loss: 0.216015
tensor(0.1088, device='cuda:0') tensor(0.0732, device='cuda:0') tensor(-2.4527e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.207276
Average KL loss: 0.010015
Average total loss: 0.217291
tensor(0.1088, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(-2.4198e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.207022
Average KL loss: 0.010029
Average total loss: 0.217051
tensor(0.1088, device='cuda:0') tensor(0.0735, device='cuda:0') tensor(-2.9551e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.210770
Average KL loss: 0.010044
Average total loss: 0.220814
tensor(0.1088, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(-2.8043e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.207169
Average KL loss: 0.010060
Average total loss: 0.217229
tensor(0.1088, device='cuda:0') tensor(0.0739, device='cuda:0') tensor(-2.7385e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.210094
Average KL loss: 0.010074
Average total loss: 0.220169
tensor(0.1087, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(-2.2541e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.211803
Average KL loss: 0.010090
Average total loss: 0.221893
tensor(0.1087, device='cuda:0') tensor(0.0743, device='cuda:0') tensor(-3.0471e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.199736
Average KL loss: 0.010106
Average total loss: 0.209842
tensor(0.1087, device='cuda:0') tensor(0.0745, device='cuda:0') tensor(-2.8542e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.205033
Average KL loss: 0.010121
Average total loss: 0.215155
tensor(0.1087, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-2.4004e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.207754
Average KL loss: 0.010136
Average total loss: 0.217889
tensor(0.1087, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(-3.6014e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.205465
Average KL loss: 0.010151
Average total loss: 0.215615
tensor(0.1087, device='cuda:0') tensor(0.0750, device='cuda:0') tensor(-3.2569e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.204203
Average KL loss: 0.010166
Average total loss: 0.214369
tensor(0.1087, device='cuda:0') tensor(0.0752, device='cuda:0') tensor(-2.3490e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.205591
Average KL loss: 0.010182
Average total loss: 0.215773
tensor(0.1087, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(-2.1440e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.201291
Average KL loss: 0.010197
Average total loss: 0.211488
tensor(0.1087, device='cuda:0') tensor(0.0756, device='cuda:0') tensor(-3.1301e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.195224
Average KL loss: 0.010212
Average total loss: 0.205435
tensor(0.1087, device='cuda:0') tensor(0.0758, device='cuda:0') tensor(-2.1556e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.194398
Average KL loss: 0.010225
Average total loss: 0.204623
tensor(0.1087, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(-2.5887e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.190571
Average KL loss: 0.010239
Average total loss: 0.200811
tensor(0.1087, device='cuda:0') tensor(0.0761, device='cuda:0') tensor(-2.5161e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.189512
Average KL loss: 0.010254
Average total loss: 0.199766
tensor(0.1087, device='cuda:0') tensor(0.0763, device='cuda:0') tensor(-2.3691e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.196465
Average KL loss: 0.010269
Average total loss: 0.206734
tensor(0.1087, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-1.9761e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.191008
Average KL loss: 0.010284
Average total loss: 0.201293
tensor(0.1087, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(-2.1798e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.195691
Average KL loss: 0.010299
Average total loss: 0.205990
tensor(0.1087, device='cuda:0') tensor(0.0768, device='cuda:0') tensor(-2.6061e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.179770
Average KL loss: 0.010312
Average total loss: 0.190083
tensor(0.1087, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(-2.2565e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.181755
Average KL loss: 0.010326
Average total loss: 0.192081
tensor(0.1087, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-1.9246e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.178332
Average KL loss: 0.010340
Average total loss: 0.188671
tensor(0.1087, device='cuda:0') tensor(0.0774, device='cuda:0') tensor(-2.1934e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.189447
Average KL loss: 0.010355
Average total loss: 0.199801
tensor(0.1087, device='cuda:0') tensor(0.0776, device='cuda:0') tensor(-3.5928e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.186551
Average KL loss: 0.010370
Average total loss: 0.196921
tensor(0.1087, device='cuda:0') tensor(0.0777, device='cuda:0') tensor(-1.7008e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.174631
Average KL loss: 0.010384
Average total loss: 0.185015
tensor(0.1087, device='cuda:0') tensor(0.0779, device='cuda:0') tensor(-2.1278e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.175978
Average KL loss: 0.010397
Average total loss: 0.186376
tensor(0.1087, device='cuda:0') tensor(0.0781, device='cuda:0') tensor(-2.1080e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.181899
Average KL loss: 0.010411
Average total loss: 0.192309
tensor(0.1087, device='cuda:0') tensor(0.0783, device='cuda:0') tensor(-2.9562e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.172985
Average KL loss: 0.010426
Average total loss: 0.183411
tensor(0.1087, device='cuda:0') tensor(0.0784, device='cuda:0') tensor(-2.2060e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.178439
Average KL loss: 0.010440
Average total loss: 0.188879
tensor(0.1087, device='cuda:0') tensor(0.0786, device='cuda:0') tensor(-1.8653e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.176150
Average KL loss: 0.010454
Average total loss: 0.186604
tensor(0.1087, device='cuda:0') tensor(0.0788, device='cuda:0') tensor(-2.3306e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.177259
Average KL loss: 0.010467
Average total loss: 0.187726
tensor(0.1087, device='cuda:0') tensor(0.0790, device='cuda:0') tensor(-2.2905e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.172490
Average KL loss: 0.010481
Average total loss: 0.182971
tensor(0.1087, device='cuda:0') tensor(0.0792, device='cuda:0') tensor(-2.6330e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.174878
Average KL loss: 0.010495
Average total loss: 0.185373
tensor(0.1087, device='cuda:0') tensor(0.0793, device='cuda:0') tensor(-2.3600e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.170188
Average KL loss: 0.010509
Average total loss: 0.180697
tensor(0.1087, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-1.9555e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.169351
Average KL loss: 0.010523
Average total loss: 0.179874
tensor(0.1087, device='cuda:0') tensor(0.0797, device='cuda:0') tensor(-1.8663e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.170542
Average KL loss: 0.010537
Average total loss: 0.181078
tensor(0.1087, device='cuda:0') tensor(0.0799, device='cuda:0') tensor(-1.9294e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.166689
Average KL loss: 0.010549
Average total loss: 0.177239
tensor(0.1087, device='cuda:0') tensor(0.0800, device='cuda:0') tensor(-2.3977e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.162886
Average KL loss: 0.010562
Average total loss: 0.173448
tensor(0.1087, device='cuda:0') tensor(0.0802, device='cuda:0') tensor(-2.4648e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.158032
Average KL loss: 0.010574
Average total loss: 0.168606
tensor(0.1087, device='cuda:0') tensor(0.0804, device='cuda:0') tensor(-2.2341e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.161790
Average KL loss: 0.010586
Average total loss: 0.172376
tensor(0.1087, device='cuda:0') tensor(0.0805, device='cuda:0') tensor(-1.7412e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.164073
Average KL loss: 0.010599
Average total loss: 0.174672
tensor(0.1087, device='cuda:0') tensor(0.0807, device='cuda:0') tensor(-2.4333e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.162547
Average KL loss: 0.010611
Average total loss: 0.173158
tensor(0.1087, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-2.4184e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.163588
Average KL loss: 0.010623
Average total loss: 0.174210
tensor(0.1087, device='cuda:0') tensor(0.0810, device='cuda:0') tensor(-2.4689e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.162196
Average KL loss: 0.010635
Average total loss: 0.172831
tensor(0.1086, device='cuda:0') tensor(0.0812, device='cuda:0') tensor(-1.5728e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.156233
Average KL loss: 0.010647
Average total loss: 0.166880
tensor(0.1086, device='cuda:0') tensor(0.0814, device='cuda:0') tensor(-2.6029e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.159623
Average KL loss: 0.010660
Average total loss: 0.170283
tensor(0.1086, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(-1.9040e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.166490
Average KL loss: 0.010673
Average total loss: 0.177164
tensor(0.1087, device='cuda:0') tensor(0.0817, device='cuda:0') tensor(-1.8352e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.158670
Average KL loss: 0.010688
Average total loss: 0.169359
tensor(0.1087, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(-2.0305e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.155901
Average KL loss: 0.010702
Average total loss: 0.166603
tensor(0.1087, device='cuda:0') tensor(0.0821, device='cuda:0') tensor(-1.6949e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.160836
Average KL loss: 0.010714
Average total loss: 0.171550
tensor(0.1087, device='cuda:0') tensor(0.0822, device='cuda:0') tensor(-1.8457e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.154155
Average KL loss: 0.010725
Average total loss: 0.164880
tensor(0.1087, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-2.3266e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.149983
Average KL loss: 0.010738
Average total loss: 0.160721
tensor(0.1087, device='cuda:0') tensor(0.0825, device='cuda:0') tensor(-2.1029e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.153397
Average KL loss: 0.010750
Average total loss: 0.164147
tensor(0.1087, device='cuda:0') tensor(0.0827, device='cuda:0') tensor(-1.6353e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.148522
Average KL loss: 0.010762
Average total loss: 0.159284
tensor(0.1087, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(-1.5350e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.156753
Average KL loss: 0.010774
Average total loss: 0.167527
tensor(0.1087, device='cuda:0') tensor(0.0831, device='cuda:0') tensor(-2.3529e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.144810
Average KL loss: 0.010787
Average total loss: 0.155597
tensor(0.1087, device='cuda:0') tensor(0.0832, device='cuda:0') tensor(-1.6430e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.153645
Average KL loss: 0.010799
Average total loss: 0.164444
tensor(0.1087, device='cuda:0') tensor(0.0834, device='cuda:0') tensor(-1.4958e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.156231
Average KL loss: 0.010812
Average total loss: 0.167043
tensor(0.1087, device='cuda:0') tensor(0.0836, device='cuda:0') tensor(-1.8384e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.152941
Average KL loss: 0.010824
Average total loss: 0.163765
tensor(0.1087, device='cuda:0') tensor(0.0837, device='cuda:0') tensor(-1.4328e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.148522
Average KL loss: 0.010837
Average total loss: 0.159359
tensor(0.1087, device='cuda:0') tensor(0.0839, device='cuda:0') tensor(-2.4725e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.140482
Average KL loss: 0.010849
Average total loss: 0.151331
tensor(0.1087, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(-2.4188e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.143084
Average KL loss: 0.010859
Average total loss: 0.153943
tensor(0.1087, device='cuda:0') tensor(0.0842, device='cuda:0') tensor(-2.1154e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.147203
Average KL loss: 0.010870
Average total loss: 0.158074
tensor(0.1087, device='cuda:0') tensor(0.0844, device='cuda:0') tensor(-1.7875e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.139584
Average KL loss: 0.010883
Average total loss: 0.150467
tensor(0.1087, device='cuda:0') tensor(0.0845, device='cuda:0') tensor(-1.7121e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.140369
Average KL loss: 0.010894
Average total loss: 0.151263
tensor(0.1087, device='cuda:0') tensor(0.0847, device='cuda:0') tensor(-2.4359e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.140056
Average KL loss: 0.010905
Average total loss: 0.150961
tensor(0.1087, device='cuda:0') tensor(0.0849, device='cuda:0') tensor(-2.4041e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.137634
Average KL loss: 0.010916
Average total loss: 0.148550
tensor(0.1087, device='cuda:0') tensor(0.0850, device='cuda:0') tensor(-2.2012e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.144669
Average KL loss: 0.010928
Average total loss: 0.155596
tensor(0.1087, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(-1.5992e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.142183
Average KL loss: 0.010939
Average total loss: 0.153122
tensor(0.1087, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-1.5982e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.138895
Average KL loss: 0.010951
Average total loss: 0.149845
tensor(0.1087, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.4625e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.135675
Average KL loss: 0.010961
Average total loss: 0.146636
tensor(0.1087, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-1.7544e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.132217
Average KL loss: 0.010971
Average total loss: 0.143188
tensor(0.1087, device='cuda:0') tensor(0.0858, device='cuda:0') tensor(-1.4290e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.132586
Average KL loss: 0.010982
Average total loss: 0.143568
tensor(0.1087, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-1.9437e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.142152
Average KL loss: 0.010994
Average total loss: 0.153146
tensor(0.1087, device='cuda:0') tensor(0.0861, device='cuda:0') tensor(-2.1410e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.131281
Average KL loss: 0.011005
Average total loss: 0.142286
tensor(0.1087, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-2.0157e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.133864
Average KL loss: 0.011017
Average total loss: 0.144881
tensor(0.1087, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-1.6830e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.133605
Average KL loss: 0.011029
Average total loss: 0.144634
tensor(0.1087, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(-1.8317e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.131659
Average KL loss: 0.011041
Average total loss: 0.142700
tensor(0.1087, device='cuda:0') tensor(0.0868, device='cuda:0') tensor(-1.3134e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.129372
Average KL loss: 0.011052
Average total loss: 0.140424
tensor(0.1087, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-1.5634e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.124600
Average KL loss: 0.011063
Average total loss: 0.135662
tensor(0.1087, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(-1.4195e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.130627
Average KL loss: 0.011071
Average total loss: 0.141699
tensor(0.1087, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-1.6248e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.124045
Average KL loss: 0.011083
Average total loss: 0.135128
tensor(0.1087, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-1.4202e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.125926
Average KL loss: 0.011094
Average total loss: 0.137020
tensor(0.1087, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(-1.9383e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.132762
Average KL loss: 0.011105
Average total loss: 0.143867
tensor(0.1087, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-1.1192e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.121711
Average KL loss: 0.011115
Average total loss: 0.132826
tensor(0.1087, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(-1.0601e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.125008
Average KL loss: 0.011125
Average total loss: 0.136133
tensor(0.1087, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-1.4539e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.128248
Average KL loss: 0.011135
Average total loss: 0.139383
tensor(0.1087, device='cuda:0') tensor(0.0882, device='cuda:0') tensor(-1.1439e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.127904
Average KL loss: 0.011146
Average total loss: 0.139050
tensor(0.1087, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(-1.8397e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.123622
Average KL loss: 0.011155
Average total loss: 0.134777
tensor(0.1087, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-1.5938e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.123492
Average KL loss: 0.011165
Average total loss: 0.134657
tensor(0.1087, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-2.1016e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.120720
Average KL loss: 0.011176
Average total loss: 0.131895
tensor(0.1087, device='cuda:0') tensor(0.0888, device='cuda:0') tensor(-1.5056e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.121492
Average KL loss: 0.011186
Average total loss: 0.132677
tensor(0.1087, device='cuda:0') tensor(0.0889, device='cuda:0') tensor(-1.3909e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.122301
Average KL loss: 0.011196
Average total loss: 0.133497
tensor(0.1087, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(-1.6734e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.120371
Average KL loss: 0.011206
Average total loss: 0.131577
tensor(0.1087, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.3589e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.121662
Average KL loss: 0.011217
Average total loss: 0.132879
tensor(0.1087, device='cuda:0') tensor(0.0894, device='cuda:0') tensor(-1.4982e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.117482
Average KL loss: 0.011227
Average total loss: 0.128709
tensor(0.1087, device='cuda:0') tensor(0.0896, device='cuda:0') tensor(-1.5707e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.118086
Average KL loss: 0.011238
Average total loss: 0.129324
tensor(0.1087, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(-1.4403e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.116561
Average KL loss: 0.011248
Average total loss: 0.127808
tensor(0.1087, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(-1.6742e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.116812
Average KL loss: 0.011257
Average total loss: 0.128069
tensor(0.1086, device='cuda:0') tensor(0.0900, device='cuda:0') tensor(-1.2038e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.117679
Average KL loss: 0.011265
Average total loss: 0.128945
tensor(0.1086, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(-1.7125e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.113852
Average KL loss: 0.011275
Average total loss: 0.125128
tensor(0.1086, device='cuda:0') tensor(0.0903, device='cuda:0') tensor(-1.9625e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.114553
Average KL loss: 0.011285
Average total loss: 0.125838
tensor(0.1086, device='cuda:0') tensor(0.0905, device='cuda:0') tensor(-1.4050e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.115490
Average KL loss: 0.011295
Average total loss: 0.126785
tensor(0.1086, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(-1.2331e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.112965
Average KL loss: 0.011305
Average total loss: 0.124270
tensor(0.1086, device='cuda:0') tensor(0.0908, device='cuda:0') tensor(-1.5409e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.111348
Average KL loss: 0.011314
Average total loss: 0.122662
tensor(0.1086, device='cuda:0') tensor(0.0909, device='cuda:0') tensor(-1.3462e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.113556
Average KL loss: 0.011324
Average total loss: 0.124880
tensor(0.1086, device='cuda:0') tensor(0.0911, device='cuda:0') tensor(-9.9410e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.111901
Average KL loss: 0.011333
Average total loss: 0.123234
tensor(0.1086, device='cuda:0') tensor(0.0912, device='cuda:0') tensor(-1.4760e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.111716
Average KL loss: 0.011342
Average total loss: 0.123058
tensor(0.1086, device='cuda:0') tensor(0.0914, device='cuda:0') tensor(-1.2814e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.108843
Average KL loss: 0.011351
Average total loss: 0.120194
tensor(0.1086, device='cuda:0') tensor(0.0915, device='cuda:0') tensor(-1.6155e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.110372
Average KL loss: 0.011360
Average total loss: 0.121733
tensor(0.1086, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.2537e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.109231
Average KL loss: 0.011369
Average total loss: 0.120600
tensor(0.1086, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-1.5355e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.111875
Average KL loss: 0.011378
Average total loss: 0.123253
tensor(0.1086, device='cuda:0') tensor(0.0919, device='cuda:0') tensor(-1.9462e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.110122
Average KL loss: 0.011388
Average total loss: 0.121510
tensor(0.1086, device='cuda:0') tensor(0.0921, device='cuda:0') tensor(-1.7300e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.107688
Average KL loss: 0.011397
Average total loss: 0.119086
 Percentile value: 0.9690293788909912
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/8]: ---
conv1.weight         | nonzeros =     203 /    1728             ( 11.75%) | total_pruned =    1525 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     746 /   36864             (  2.02%) | total_pruned =   36118 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1908 /   36864             (  5.18%) | total_pruned =   34956 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2930 /   36864             (  7.95%) | total_pruned =   33934 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4965 /   36864             ( 13.47%) | total_pruned =   31899 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   12687 /   73728             ( 17.21%) | total_pruned =   61041 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   25347 /  147456             ( 17.19%) | total_pruned =  122109 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1925 /    8192             ( 23.50%) | total_pruned =    6267 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   16430 /  147456             ( 11.14%) | total_pruned =  131026 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   17279 /  147456             ( 11.72%) | total_pruned =  130177 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   48658 /  294912             ( 16.50%) | total_pruned =  246254 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   82927 /  589824             ( 14.06%) | total_pruned =  506897 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6352 /   32768             ( 19.38%) | total_pruned =   26416 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   63246 /  589824             ( 10.72%) | total_pruned =  526578 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   57196 /  589824             (  9.70%) | total_pruned =  532628 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  125064 / 1179648             ( 10.60%) | total_pruned = 1054584 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  183301 / 2359296             (  7.77%) | total_pruned = 2175995 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     278 /     512             ( 54.30%) | total_pruned =     234 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    8174 /  131072             (  6.24%) | total_pruned =  122898 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     422 /     512             ( 82.42%) | total_pruned =      90 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     273 /     512             ( 53.32%) | total_pruned =     239 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  113052 / 2359296             (  4.79%) | total_pruned = 2246244 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     430 /     512             ( 83.98%) | total_pruned =      82 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  223372 / 2359296             (  9.47%) | total_pruned = 2135924 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
linear.weight        | nonzeros =    4684 /    5120             ( 91.48%) | total_pruned =     436 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 49/100 Loss: 0.010516 Accuracy: 89.64 100.00 % Best test Accuracy: 89.64%
tensor(0.1086, device='cuda:0') tensor(0.0922, device='cuda:0') tensor(-2.9291e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.241208
Average KL loss: 0.011292
Average total loss: 0.252500
tensor(0.1066, device='cuda:0') tensor(0.0910, device='cuda:0') tensor(-3.5129e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.217251
Average KL loss: 0.011112
Average total loss: 0.228363
tensor(0.1047, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(-4.0440e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.225346
Average KL loss: 0.010953
Average total loss: 0.236300
tensor(0.1029, device='cuda:0') tensor(0.0894, device='cuda:0') tensor(-3.8042e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.209115
Average KL loss: 0.010812
Average total loss: 0.219927
tensor(0.1013, device='cuda:0') tensor(0.0888, device='cuda:0') tensor(-3.5764e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.209508
Average KL loss: 0.010685
Average total loss: 0.220193
tensor(0.0997, device='cuda:0') tensor(0.0882, device='cuda:0') tensor(-2.5449e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.217132
Average KL loss: 0.010571
Average total loss: 0.227703
tensor(0.0982, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-2.2906e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.200113
Average KL loss: 0.010468
Average total loss: 0.210582
tensor(0.0968, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-3.2055e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.202409
Average KL loss: 0.010377
Average total loss: 0.212786
tensor(0.0955, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(-2.8562e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.202368
Average KL loss: 0.010295
Average total loss: 0.212662
tensor(0.0942, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(-3.0900e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.193893
Average KL loss: 0.010221
Average total loss: 0.204114
tensor(0.0931, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-3.5245e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.199537
Average KL loss: 0.010155
Average total loss: 0.209692
tensor(0.0919, device='cuda:0') tensor(0.0861, device='cuda:0') tensor(-2.3659e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.188360
Average KL loss: 0.010096
Average total loss: 0.198456
tensor(0.0909, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-3.1375e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.184004
Average KL loss: 0.010043
Average total loss: 0.194047
tensor(0.0899, device='cuda:0') tensor(0.0858, device='cuda:0') tensor(-3.0031e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.180021
Average KL loss: 0.009996
Average total loss: 0.190017
tensor(0.0890, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-2.4539e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.179904
Average KL loss: 0.009954
Average total loss: 0.189858
tensor(0.0882, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-2.1443e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.183138
Average KL loss: 0.009916
Average total loss: 0.193055
tensor(0.0874, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(-2.3597e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.182627
Average KL loss: 0.009883
Average total loss: 0.192510
tensor(0.0866, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(-2.1696e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.179884
Average KL loss: 0.009854
Average total loss: 0.189737
tensor(0.0859, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-3.4585e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.173470
Average KL loss: 0.009827
Average total loss: 0.183297
tensor(0.0852, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-5.5346e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.186596
Average KL loss: 0.009804
Average total loss: 0.196400
tensor(0.0846, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-3.5176e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.175439
Average KL loss: 0.009784
Average total loss: 0.185223
tensor(0.0841, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-2.8566e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.181682
Average KL loss: 0.009766
Average total loss: 0.191447
tensor(0.0835, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-2.7731e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.179106
Average KL loss: 0.009750
Average total loss: 0.188856
tensor(0.0830, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-2.6368e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.170822
Average KL loss: 0.009736
Average total loss: 0.180557
tensor(0.0826, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-2.2987e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.171647
Average KL loss: 0.009723
Average total loss: 0.181369
tensor(0.0821, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-1.9940e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.165520
Average KL loss: 0.009711
Average total loss: 0.175231
tensor(0.0817, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(-2.5547e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.161097
Average KL loss: 0.009700
Average total loss: 0.170797
tensor(0.0814, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(-1.8685e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.164095
Average KL loss: 0.009691
Average total loss: 0.173786
tensor(0.0810, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(-2.0662e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.162470
Average KL loss: 0.009683
Average total loss: 0.172153
tensor(0.0807, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-2.1231e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.167495
Average KL loss: 0.009675
Average total loss: 0.177170
tensor(0.0804, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-2.4451e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.161990
Average KL loss: 0.009669
Average total loss: 0.171659
tensor(0.0801, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-2.4149e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.165062
Average KL loss: 0.009664
Average total loss: 0.174726
tensor(0.0798, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.9291e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.160778
Average KL loss: 0.009660
Average total loss: 0.170438
tensor(0.0796, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-2.2659e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.150797
Average KL loss: 0.009656
Average total loss: 0.160453
tensor(0.0794, device='cuda:0') tensor(0.0858, device='cuda:0') tensor(-1.7300e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.154528
Average KL loss: 0.009654
Average total loss: 0.164181
tensor(0.0792, device='cuda:0') tensor(0.0858, device='cuda:0') tensor(-2.2671e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.165169
Average KL loss: 0.009651
Average total loss: 0.174820
tensor(0.0790, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-1.7364e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.152204
Average KL loss: 0.009649
Average total loss: 0.161853
tensor(0.0788, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-2.6186e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.152830
Average KL loss: 0.009647
Average total loss: 0.162477
tensor(0.0786, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-2.1089e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.156209
Average KL loss: 0.009647
Average total loss: 0.165856
tensor(0.0785, device='cuda:0') tensor(0.0861, device='cuda:0') tensor(-2.3890e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.153065
Average KL loss: 0.009646
Average total loss: 0.162711
tensor(0.0783, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-2.1614e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.149756
Average KL loss: 0.009646
Average total loss: 0.159403
tensor(0.0782, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-1.8918e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.151185
Average KL loss: 0.009646
Average total loss: 0.160831
tensor(0.0781, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-2.2252e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.153013
Average KL loss: 0.009646
Average total loss: 0.162659
tensor(0.0779, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-1.6696e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.146349
Average KL loss: 0.009647
Average total loss: 0.155996
tensor(0.0778, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-2.0203e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.142467
Average KL loss: 0.009647
Average total loss: 0.152115
tensor(0.0777, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(-1.8801e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.148718
Average KL loss: 0.009649
Average total loss: 0.158367
tensor(0.0776, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(-1.7228e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.145923
Average KL loss: 0.009651
Average total loss: 0.155573
tensor(0.0776, device='cuda:0') tensor(0.0868, device='cuda:0') tensor(-2.0603e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.144502
Average KL loss: 0.009653
Average total loss: 0.154155
tensor(0.0775, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(-1.8450e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.142763
Average KL loss: 0.009655
Average total loss: 0.152419
tensor(0.0774, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-1.5146e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.147264
Average KL loss: 0.009657
Average total loss: 0.156921
tensor(0.0773, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-1.8808e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.139719
Average KL loss: 0.009659
Average total loss: 0.149379
tensor(0.0773, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(-1.9127e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.144633
Average KL loss: 0.009662
Average total loss: 0.154295
tensor(0.0772, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-1.9613e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.137894
Average KL loss: 0.009665
Average total loss: 0.147559
tensor(0.0772, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-1.8673e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.139364
Average KL loss: 0.009667
Average total loss: 0.149031
tensor(0.0771, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-1.5748e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.143379
Average KL loss: 0.009670
Average total loss: 0.153049
tensor(0.0771, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.9221e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.142436
Average KL loss: 0.009673
Average total loss: 0.152109
tensor(0.0770, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(-2.4934e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.135490
Average KL loss: 0.009676
Average total loss: 0.145166
tensor(0.0770, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-1.6981e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.133401
Average KL loss: 0.009680
Average total loss: 0.143080
tensor(0.0769, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-4.1125e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.141671
Average KL loss: 0.009683
Average total loss: 0.151354
tensor(0.0769, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(-2.3769e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.140707
Average KL loss: 0.009687
Average total loss: 0.150394
tensor(0.0769, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-2.5320e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.140778
Average KL loss: 0.009691
Average total loss: 0.150469
tensor(0.0768, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(-1.9172e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.134790
Average KL loss: 0.009694
Average total loss: 0.144484
tensor(0.0768, device='cuda:0') tensor(0.0882, device='cuda:0') tensor(-2.1466e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.140387
Average KL loss: 0.009698
Average total loss: 0.150086
tensor(0.0768, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(-1.2833e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.134568
Average KL loss: 0.009702
Average total loss: 0.144270
tensor(0.0767, device='cuda:0') tensor(0.0884, device='cuda:0') tensor(-1.5744e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.132255
Average KL loss: 0.009706
Average total loss: 0.141961
tensor(0.0767, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-2.2624e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.134188
Average KL loss: 0.009710
Average total loss: 0.143898
tensor(0.0767, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-1.3673e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.125728
Average KL loss: 0.009714
Average total loss: 0.135442
tensor(0.0767, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-1.6187e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.130940
Average KL loss: 0.009718
Average total loss: 0.140657
tensor(0.0767, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(-1.9089e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.126714
Average KL loss: 0.009721
Average total loss: 0.136436
tensor(0.0766, device='cuda:0') tensor(0.0888, device='cuda:0') tensor(-1.7709e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.122700
Average KL loss: 0.009726
Average total loss: 0.132426
tensor(0.0766, device='cuda:0') tensor(0.0889, device='cuda:0') tensor(-1.2953e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.122482
Average KL loss: 0.009730
Average total loss: 0.132212
tensor(0.0766, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-2.1094e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.130901
Average KL loss: 0.009734
Average total loss: 0.140635
tensor(0.0766, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(-1.5537e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.123045
Average KL loss: 0.009739
Average total loss: 0.132784
tensor(0.0766, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(-1.4608e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.126268
Average KL loss: 0.009743
Average total loss: 0.136012
tensor(0.0766, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.3416e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.128927
Average KL loss: 0.009748
Average total loss: 0.138675
tensor(0.0766, device='cuda:0') tensor(0.0894, device='cuda:0') tensor(-1.7568e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.126947
Average KL loss: 0.009753
Average total loss: 0.136700
tensor(0.0766, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-1.3780e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.129988
Average KL loss: 0.009758
Average total loss: 0.139746
tensor(0.0766, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(-1.7799e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.124524
Average KL loss: 0.009763
Average total loss: 0.134287
tensor(0.0765, device='cuda:0') tensor(0.0898, device='cuda:0') tensor(-1.3914e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.122301
Average KL loss: 0.009767
Average total loss: 0.132068
tensor(0.0765, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(-2.0383e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.120682
Average KL loss: 0.009773
Average total loss: 0.130455
tensor(0.0765, device='cuda:0') tensor(0.0900, device='cuda:0') tensor(-1.8272e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.123020
Average KL loss: 0.009777
Average total loss: 0.132797
tensor(0.0765, device='cuda:0') tensor(0.0901, device='cuda:0') tensor(-1.8213e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.130002
Average KL loss: 0.009781
Average total loss: 0.139784
tensor(0.0765, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(-1.4229e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.120566
Average KL loss: 0.009786
Average total loss: 0.130352
tensor(0.0765, device='cuda:0') tensor(0.0903, device='cuda:0') tensor(-1.8700e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.123737
Average KL loss: 0.009792
Average total loss: 0.133529
tensor(0.0765, device='cuda:0') tensor(0.0904, device='cuda:0') tensor(-1.4925e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.117933
Average KL loss: 0.009797
Average total loss: 0.127730
tensor(0.0765, device='cuda:0') tensor(0.0905, device='cuda:0') tensor(-2.1206e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.121661
Average KL loss: 0.009802
Average total loss: 0.131463
tensor(0.0765, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(-1.3613e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.117813
Average KL loss: 0.009807
Average total loss: 0.127620
tensor(0.0765, device='cuda:0') tensor(0.0907, device='cuda:0') tensor(-1.5990e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.123949
Average KL loss: 0.009812
Average total loss: 0.133761
tensor(0.0765, device='cuda:0') tensor(0.0908, device='cuda:0') tensor(-1.6454e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.117722
Average KL loss: 0.009817
Average total loss: 0.127539
tensor(0.0765, device='cuda:0') tensor(0.0909, device='cuda:0') tensor(-2.0835e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.111671
Average KL loss: 0.009822
Average total loss: 0.121493
tensor(0.0765, device='cuda:0') tensor(0.0910, device='cuda:0') tensor(-1.3235e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.111304
Average KL loss: 0.009826
Average total loss: 0.121130
tensor(0.0765, device='cuda:0') tensor(0.0911, device='cuda:0') tensor(-1.3160e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.119873
Average KL loss: 0.009831
Average total loss: 0.129704
tensor(0.0765, device='cuda:0') tensor(0.0912, device='cuda:0') tensor(-1.3789e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.113152
Average KL loss: 0.009837
Average total loss: 0.122989
tensor(0.0765, device='cuda:0') tensor(0.0913, device='cuda:0') tensor(-1.4014e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.121148
Average KL loss: 0.009842
Average total loss: 0.130990
tensor(0.0765, device='cuda:0') tensor(0.0914, device='cuda:0') tensor(-1.7542e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.117135
Average KL loss: 0.009847
Average total loss: 0.126982
tensor(0.0765, device='cuda:0') tensor(0.0915, device='cuda:0') tensor(-1.3041e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.111847
Average KL loss: 0.009853
Average total loss: 0.121700
tensor(0.0765, device='cuda:0') tensor(0.0916, device='cuda:0') tensor(-1.8354e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.111047
Average KL loss: 0.009857
Average total loss: 0.120904
tensor(0.0765, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-2.9547e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.117759
Average KL loss: 0.009863
Average total loss: 0.127621
tensor(0.0765, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-1.5271e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.108863
Average KL loss: 0.009868
Average total loss: 0.118731
tensor(0.0765, device='cuda:0') tensor(0.0919, device='cuda:0') tensor(-1.1728e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.118316
Average KL loss: 0.009873
Average total loss: 0.128188
tensor(0.0765, device='cuda:0') tensor(0.0921, device='cuda:0') tensor(-1.2001e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.110316
Average KL loss: 0.009878
Average total loss: 0.120195
tensor(0.0765, device='cuda:0') tensor(0.0922, device='cuda:0') tensor(-1.2427e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.108818
Average KL loss: 0.009884
Average total loss: 0.118702
tensor(0.0765, device='cuda:0') tensor(0.0923, device='cuda:0') tensor(-1.4314e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.105908
Average KL loss: 0.009888
Average total loss: 0.115796
tensor(0.0765, device='cuda:0') tensor(0.0924, device='cuda:0') tensor(-1.6010e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.109834
Average KL loss: 0.009893
Average total loss: 0.119726
tensor(0.0765, device='cuda:0') tensor(0.0925, device='cuda:0') tensor(-1.6786e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.108800
Average KL loss: 0.009898
Average total loss: 0.118697
tensor(0.0765, device='cuda:0') tensor(0.0926, device='cuda:0') tensor(-1.1747e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.107448
Average KL loss: 0.009903
Average total loss: 0.117351
tensor(0.0765, device='cuda:0') tensor(0.0927, device='cuda:0') tensor(-1.3366e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.103847
Average KL loss: 0.009908
Average total loss: 0.113755
tensor(0.0765, device='cuda:0') tensor(0.0928, device='cuda:0') tensor(-1.3957e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.104758
Average KL loss: 0.009913
Average total loss: 0.114671
tensor(0.0765, device='cuda:0') tensor(0.0929, device='cuda:0') tensor(-1.3220e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.107305
Average KL loss: 0.009918
Average total loss: 0.117222
tensor(0.0765, device='cuda:0') tensor(0.0930, device='cuda:0') tensor(-1.3579e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.106756
Average KL loss: 0.009923
Average total loss: 0.116679
tensor(0.0765, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(-1.3243e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.103345
Average KL loss: 0.009928
Average total loss: 0.113272
tensor(0.0766, device='cuda:0') tensor(0.0932, device='cuda:0') tensor(-1.4125e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.104342
Average KL loss: 0.009933
Average total loss: 0.114275
tensor(0.0766, device='cuda:0') tensor(0.0933, device='cuda:0') tensor(-1.0099e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.104948
Average KL loss: 0.009938
Average total loss: 0.114886
tensor(0.0766, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-1.3325e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.104027
Average KL loss: 0.009944
Average total loss: 0.113970
tensor(0.0766, device='cuda:0') tensor(0.0935, device='cuda:0') tensor(-1.4813e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.111003
Average KL loss: 0.009949
Average total loss: 0.120953
tensor(0.0766, device='cuda:0') tensor(0.0936, device='cuda:0') tensor(-1.5981e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.107888
Average KL loss: 0.009955
Average total loss: 0.117843
tensor(0.0766, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(-1.0208e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.101395
Average KL loss: 0.009960
Average total loss: 0.111355
tensor(0.0766, device='cuda:0') tensor(0.0938, device='cuda:0') tensor(-1.1693e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.101979
Average KL loss: 0.009965
Average total loss: 0.111944
tensor(0.0766, device='cuda:0') tensor(0.0939, device='cuda:0') tensor(-1.2831e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.105490
Average KL loss: 0.009970
Average total loss: 0.115461
tensor(0.0766, device='cuda:0') tensor(0.0940, device='cuda:0') tensor(-1.0082e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.104000
Average KL loss: 0.009976
Average total loss: 0.113976
tensor(0.0766, device='cuda:0') tensor(0.0941, device='cuda:0') tensor(-1.1313e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.101970
Average KL loss: 0.009981
Average total loss: 0.111951
tensor(0.0766, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(-1.5024e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.102662
Average KL loss: 0.009987
Average total loss: 0.112649
tensor(0.0766, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(-1.2143e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.108991
Average KL loss: 0.009992
Average total loss: 0.118983
tensor(0.0766, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(-1.0048e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.096790
Average KL loss: 0.009997
Average total loss: 0.106787
tensor(0.0766, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(-1.2037e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.096766
Average KL loss: 0.010001
Average total loss: 0.106767
tensor(0.0766, device='cuda:0') tensor(0.0947, device='cuda:0') tensor(-1.0725e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.100719
Average KL loss: 0.010006
Average total loss: 0.110725
tensor(0.0766, device='cuda:0') tensor(0.0948, device='cuda:0') tensor(-1.2301e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.097622
Average KL loss: 0.010012
Average total loss: 0.107634
tensor(0.0766, device='cuda:0') tensor(0.0949, device='cuda:0') tensor(-1.3783e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.100009
Average KL loss: 0.010017
Average total loss: 0.110026
tensor(0.0766, device='cuda:0') tensor(0.0950, device='cuda:0') tensor(-9.8935e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.094468
Average KL loss: 0.010022
Average total loss: 0.104490
tensor(0.0767, device='cuda:0') tensor(0.0951, device='cuda:0') tensor(-1.2371e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.100626
Average KL loss: 0.010027
Average total loss: 0.110653
tensor(0.0767, device='cuda:0') tensor(0.0952, device='cuda:0') tensor(-1.0931e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.094176
Average KL loss: 0.010033
Average total loss: 0.104208
tensor(0.0767, device='cuda:0') tensor(0.0953, device='cuda:0') tensor(-1.2018e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.101248
Average KL loss: 0.010038
Average total loss: 0.111287
tensor(0.0767, device='cuda:0') tensor(0.0954, device='cuda:0') tensor(-1.3887e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.099069
Average KL loss: 0.010045
Average total loss: 0.109113
tensor(0.0767, device='cuda:0') tensor(0.0955, device='cuda:0') tensor(-1.1860e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.093800
Average KL loss: 0.010050
Average total loss: 0.103849
tensor(0.0767, device='cuda:0') tensor(0.0956, device='cuda:0') tensor(-7.1786e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.096422
Average KL loss: 0.010055
Average total loss: 0.106477
tensor(0.0767, device='cuda:0') tensor(0.0957, device='cuda:0') tensor(-1.7212e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.094174
Average KL loss: 0.010060
Average total loss: 0.104234
tensor(0.0767, device='cuda:0') tensor(0.0958, device='cuda:0') tensor(-1.1461e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.095140
Average KL loss: 0.010065
Average total loss: 0.105205
tensor(0.0767, device='cuda:0') tensor(0.0959, device='cuda:0') tensor(-1.2762e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.094919
Average KL loss: 0.010069
Average total loss: 0.104988
tensor(0.0767, device='cuda:0') tensor(0.0960, device='cuda:0') tensor(-1.1571e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.092424
Average KL loss: 0.010074
Average total loss: 0.102498
tensor(0.0767, device='cuda:0') tensor(0.0961, device='cuda:0') tensor(-1.1592e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.096854
Average KL loss: 0.010079
Average total loss: 0.106932
tensor(0.0767, device='cuda:0') tensor(0.0962, device='cuda:0') tensor(-9.0499e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.093430
Average KL loss: 0.010084
Average total loss: 0.103514
tensor(0.0767, device='cuda:0') tensor(0.0963, device='cuda:0') tensor(-1.2953e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.090837
Average KL loss: 0.010089
Average total loss: 0.100926
tensor(0.0767, device='cuda:0') tensor(0.0964, device='cuda:0') tensor(-1.1271e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.096058
Average KL loss: 0.010093
Average total loss: 0.106151
tensor(0.0767, device='cuda:0') tensor(0.0965, device='cuda:0') tensor(-1.1439e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.092192
Average KL loss: 0.010098
Average total loss: 0.102290
tensor(0.0768, device='cuda:0') tensor(0.0966, device='cuda:0') tensor(-1.2160e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.092597
Average KL loss: 0.010103
Average total loss: 0.102700
tensor(0.0768, device='cuda:0') tensor(0.0968, device='cuda:0') tensor(-9.1937e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.090092
Average KL loss: 0.010108
Average total loss: 0.100200
tensor(0.0768, device='cuda:0') tensor(0.0968, device='cuda:0') tensor(-7.7769e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.091732
Average KL loss: 0.010112
Average total loss: 0.101844
tensor(0.0768, device='cuda:0') tensor(0.0969, device='cuda:0') tensor(-1.0966e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.091454
Average KL loss: 0.010117
Average total loss: 0.101570
tensor(0.0768, device='cuda:0') tensor(0.0970, device='cuda:0') tensor(-1.6207e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.091423
Average KL loss: 0.010121
Average total loss: 0.101544
tensor(0.0768, device='cuda:0') tensor(0.0971, device='cuda:0') tensor(-1.2440e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.089077
Average KL loss: 0.010126
Average total loss: 0.099203
tensor(0.0768, device='cuda:0') tensor(0.0973, device='cuda:0') tensor(-1.0816e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.089356
Average KL loss: 0.010131
Average total loss: 0.099487
tensor(0.0768, device='cuda:0') tensor(0.0974, device='cuda:0') tensor(-1.5358e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.088851
Average KL loss: 0.010136
Average total loss: 0.098987
tensor(0.0768, device='cuda:0') tensor(0.0975, device='cuda:0') tensor(-8.7120e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.084698
Average KL loss: 0.010141
Average total loss: 0.094839
tensor(0.0768, device='cuda:0') tensor(0.0976, device='cuda:0') tensor(-1.0128e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.090410
Average KL loss: 0.010145
Average total loss: 0.100556
tensor(0.0768, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(-9.8144e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.088305
Average KL loss: 0.010151
Average total loss: 0.098455
tensor(0.0768, device='cuda:0') tensor(0.0978, device='cuda:0') tensor(-1.5033e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.084739
Average KL loss: 0.010155
Average total loss: 0.094894
tensor(0.0768, device='cuda:0') tensor(0.0979, device='cuda:0') tensor(-7.9895e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.087102
Average KL loss: 0.010159
Average total loss: 0.097261
tensor(0.0768, device='cuda:0') tensor(0.0980, device='cuda:0') tensor(-1.3139e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.089990
Average KL loss: 0.010164
Average total loss: 0.100154
tensor(0.0768, device='cuda:0') tensor(0.0981, device='cuda:0') tensor(-7.0961e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.083631
Average KL loss: 0.010169
Average total loss: 0.093800
tensor(0.0768, device='cuda:0') tensor(0.0982, device='cuda:0') tensor(-1.2586e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.083767
Average KL loss: 0.010173
Average total loss: 0.093941
tensor(0.0768, device='cuda:0') tensor(0.0983, device='cuda:0') tensor(-1.2297e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.088252
Average KL loss: 0.010179
Average total loss: 0.098431
tensor(0.0769, device='cuda:0') tensor(0.0984, device='cuda:0') tensor(-1.1078e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.085388
Average KL loss: 0.010184
Average total loss: 0.095572
tensor(0.0769, device='cuda:0') tensor(0.0985, device='cuda:0') tensor(-1.0946e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.083571
Average KL loss: 0.010188
Average total loss: 0.093759
tensor(0.0769, device='cuda:0') tensor(0.0986, device='cuda:0') tensor(-1.0245e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.084016
Average KL loss: 0.010192
Average total loss: 0.094208
tensor(0.0769, device='cuda:0') tensor(0.0987, device='cuda:0') tensor(-1.0113e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.085861
Average KL loss: 0.010197
Average total loss: 0.096058
tensor(0.0769, device='cuda:0') tensor(0.0988, device='cuda:0') tensor(-9.1540e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.085730
Average KL loss: 0.010202
Average total loss: 0.095932
tensor(0.0769, device='cuda:0') tensor(0.0989, device='cuda:0') tensor(-1.1646e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.081904
Average KL loss: 0.010207
Average total loss: 0.092111
tensor(0.0769, device='cuda:0') tensor(0.0990, device='cuda:0') tensor(-8.2015e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.083724
Average KL loss: 0.010211
Average total loss: 0.093935
tensor(0.0769, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-8.6326e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.085740
Average KL loss: 0.010216
Average total loss: 0.095956
tensor(0.0769, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-1.0296e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.081320
Average KL loss: 0.010220
Average total loss: 0.091540
tensor(0.0769, device='cuda:0') tensor(0.0993, device='cuda:0') tensor(-8.2517e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.081478
Average KL loss: 0.010225
Average total loss: 0.091703
tensor(0.0769, device='cuda:0') tensor(0.0994, device='cuda:0') tensor(-9.6156e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.081645
Average KL loss: 0.010229
Average total loss: 0.091874
tensor(0.0769, device='cuda:0') tensor(0.0995, device='cuda:0') tensor(-8.1825e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.079161
Average KL loss: 0.010233
Average total loss: 0.089394
tensor(0.0769, device='cuda:0') tensor(0.0995, device='cuda:0') tensor(-1.0198e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.082172
Average KL loss: 0.010237
Average total loss: 0.092409
tensor(0.0769, device='cuda:0') tensor(0.0996, device='cuda:0') tensor(-1.1886e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.082019
Average KL loss: 0.010242
Average total loss: 0.092260
tensor(0.0769, device='cuda:0') tensor(0.0997, device='cuda:0') tensor(-9.3095e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.083780
Average KL loss: 0.010246
Average total loss: 0.094026
tensor(0.0769, device='cuda:0') tensor(0.0998, device='cuda:0') tensor(-9.1778e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.081874
Average KL loss: 0.010251
Average total loss: 0.092125
tensor(0.0769, device='cuda:0') tensor(0.0999, device='cuda:0') tensor(-1.6633e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.079067
Average KL loss: 0.010256
Average total loss: 0.089323
tensor(0.0770, device='cuda:0') tensor(0.1000, device='cuda:0') tensor(-1.2787e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.079227
Average KL loss: 0.010260
Average total loss: 0.089487
tensor(0.0770, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-9.3728e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.076980
Average KL loss: 0.010264
Average total loss: 0.087243
tensor(0.0770, device='cuda:0') tensor(0.1002, device='cuda:0') tensor(-9.2543e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.076332
Average KL loss: 0.010267
Average total loss: 0.086599
tensor(0.0770, device='cuda:0') tensor(0.1003, device='cuda:0') tensor(-1.3041e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.079691
Average KL loss: 0.010272
Average total loss: 0.089962
tensor(0.0770, device='cuda:0') tensor(0.1004, device='cuda:0') tensor(-1.7946e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.082576
Average KL loss: 0.010277
Average total loss: 0.092853
tensor(0.0770, device='cuda:0') tensor(0.1005, device='cuda:0') tensor(-1.5289e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.080030
Average KL loss: 0.010282
Average total loss: 0.090312
tensor(0.0770, device='cuda:0') tensor(0.1006, device='cuda:0') tensor(-1.0913e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.075595
Average KL loss: 0.010286
Average total loss: 0.085881
tensor(0.0770, device='cuda:0') tensor(0.1007, device='cuda:0') tensor(-8.0572e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.075401
Average KL loss: 0.010290
Average total loss: 0.085692
tensor(0.0770, device='cuda:0') tensor(0.1008, device='cuda:0') tensor(-6.9632e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.074876
Average KL loss: 0.010294
Average total loss: 0.085170
tensor(0.0770, device='cuda:0') tensor(0.1009, device='cuda:0') tensor(-8.4175e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.076946
Average KL loss: 0.010297
Average total loss: 0.087244
tensor(0.0770, device='cuda:0') tensor(0.1010, device='cuda:0') tensor(-8.2245e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.077263
Average KL loss: 0.010302
Average total loss: 0.087565
tensor(0.0770, device='cuda:0') tensor(0.1011, device='cuda:0') tensor(-9.9473e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.077282
Average KL loss: 0.010306
Average total loss: 0.087587
tensor(0.0770, device='cuda:0') tensor(0.1012, device='cuda:0') tensor(-7.4165e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.073833
Average KL loss: 0.010310
Average total loss: 0.084143
tensor(0.0770, device='cuda:0') tensor(0.1013, device='cuda:0') tensor(-8.1508e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.075872
Average KL loss: 0.010313
Average total loss: 0.086185
tensor(0.0770, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-6.7158e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.077641
Average KL loss: 0.010318
Average total loss: 0.087959
tensor(0.0770, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-9.5879e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.080294
Average KL loss: 0.010322
Average total loss: 0.090616
tensor(0.0770, device='cuda:0') tensor(0.1016, device='cuda:0') tensor(-8.6463e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.077867
Average KL loss: 0.010327
Average total loss: 0.088194
tensor(0.0770, device='cuda:0') tensor(0.1017, device='cuda:0') tensor(-1.0230e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.076000
Average KL loss: 0.010332
Average total loss: 0.086331
tensor(0.0770, device='cuda:0') tensor(0.1017, device='cuda:0') tensor(-7.8987e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.072317
Average KL loss: 0.010336
Average total loss: 0.082652
tensor(0.0770, device='cuda:0') tensor(0.1018, device='cuda:0') tensor(-1.0854e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.074854
Average KL loss: 0.010340
Average total loss: 0.085195
tensor(0.0770, device='cuda:0') tensor(0.1019, device='cuda:0') tensor(-1.1730e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.073210
Average KL loss: 0.010345
Average total loss: 0.083554
tensor(0.0771, device='cuda:0') tensor(0.1020, device='cuda:0') tensor(-7.4629e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.072297
Average KL loss: 0.010349
Average total loss: 0.082645
 Percentile value: 1.696758198738098
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/8]: ---
conv1.weight         | nonzeros =     139 /    1728             (  8.04%) | total_pruned =    1589 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     246 /   36864             (  0.67%) | total_pruned =   36618 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     664 /   36864             (  1.80%) | total_pruned =   36200 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1027 /   36864             (  2.79%) | total_pruned =   35837 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2107 /   36864             (  5.72%) | total_pruned =   34757 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    5002 /   73728             (  6.78%) | total_pruned =   68726 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    8253 /  147456             (  5.60%) | total_pruned =  139203 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1029 /    8192             ( 12.56%) | total_pruned =    7163 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4539 /  147456             (  3.08%) | total_pruned =  142917 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    5370 /  147456             (  3.64%) | total_pruned =  142086 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   14179 /  294912             (  4.81%) | total_pruned =  280733 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   19052 /  589824             (  3.23%) | total_pruned =  570772 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2297 /   32768             (  7.01%) | total_pruned =   30471 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   13046 /  589824             (  2.21%) | total_pruned =  576778 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   13144 /  589824             (  2.23%) | total_pruned =  576680 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     224 /     256             ( 87.50%) | total_pruned =      32 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   26405 / 1179648             (  2.24%) | total_pruned = 1153243 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      28 /     512             (  5.47%) | total_pruned =     484 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   42838 / 2359296             (  1.82%) | total_pruned = 2316458 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     464 /     512             ( 90.62%) | total_pruned =      48 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     248 /     512             ( 48.44%) | total_pruned =     264 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1719 /  131072             (  1.31%) | total_pruned =  129353 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     305 /     512             ( 59.57%) | total_pruned =     207 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     249 /     512             ( 48.63%) | total_pruned =     263 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   35570 / 2359296             (  1.51%) | total_pruned = 2323726 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     262 /     512             ( 51.17%) | total_pruned =     250 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   95891 / 2359296             (  4.06%) | total_pruned = 2263405 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     460 /     512             ( 89.84%) | total_pruned =      52 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     455 /     512             ( 88.87%) | total_pruned =      57 | shape = torch.Size([512])
linear.weight        | nonzeros =    4297 /    5120             ( 83.93%) | total_pruned =     823 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 66/100 Loss: 0.017485 Accuracy: 88.35 100.00 % Best test Accuracy: 88.46%
tensor(0.0771, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-3.7582e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.276973
Average KL loss: 0.010212
Average total loss: 0.287186
tensor(0.0754, device='cuda:0') tensor(0.0997, device='cuda:0') tensor(-3.0020e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.267487
Average KL loss: 0.009950
Average total loss: 0.277437
tensor(0.0739, device='cuda:0') tensor(0.0976, device='cuda:0') tensor(-4.0896e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.275210
Average KL loss: 0.009701
Average total loss: 0.284911
tensor(0.0724, device='cuda:0') tensor(0.0956, device='cuda:0') tensor(-3.9544e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.272291
Average KL loss: 0.009464
Average total loss: 0.281755
tensor(0.0709, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(-3.7140e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.266607
Average KL loss: 0.009240
Average total loss: 0.275847
tensor(0.0695, device='cuda:0') tensor(0.0919, device='cuda:0') tensor(-3.3214e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.265159
Average KL loss: 0.009027
Average total loss: 0.274186
tensor(0.0681, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(-4.1941e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.254397
Average KL loss: 0.008825
Average total loss: 0.263222
tensor(0.0667, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-3.0442e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.258530
Average KL loss: 0.008634
Average total loss: 0.267164
tensor(0.0654, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(-3.0340e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.252620
Average KL loss: 0.008453
Average total loss: 0.261073
tensor(0.0642, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-2.9378e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.253280
Average KL loss: 0.008282
Average total loss: 0.261562
tensor(0.0629, device='cuda:0') tensor(0.0843, device='cuda:0') tensor(-2.9474e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.250053
Average KL loss: 0.008121
Average total loss: 0.258174
tensor(0.0617, device='cuda:0') tensor(0.0831, device='cuda:0') tensor(-2.8921e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.254077
Average KL loss: 0.007969
Average total loss: 0.262046
tensor(0.0606, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(-3.7217e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.252614
Average KL loss: 0.007826
Average total loss: 0.260440
tensor(0.0595, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(-4.1753e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.242714
Average KL loss: 0.007692
Average total loss: 0.250406
tensor(0.0584, device='cuda:0') tensor(0.0797, device='cuda:0') tensor(-2.5787e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.235370
Average KL loss: 0.007565
Average total loss: 0.242935
tensor(0.0573, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(-2.4181e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.240788
Average KL loss: 0.007446
Average total loss: 0.248234
tensor(0.0563, device='cuda:0') tensor(0.0778, device='cuda:0') tensor(-2.6765e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.232792
Average KL loss: 0.007334
Average total loss: 0.240127
tensor(0.0554, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(-2.8242e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.226099
Average KL loss: 0.007230
Average total loss: 0.233329
tensor(0.0544, device='cuda:0') tensor(0.0761, device='cuda:0') tensor(-3.7098e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.231204
Average KL loss: 0.007131
Average total loss: 0.238335
tensor(0.0535, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(-3.0699e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.231810
Average KL loss: 0.007039
Average total loss: 0.238848
tensor(0.0527, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-2.6336e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.233818
Average KL loss: 0.006952
Average total loss: 0.240770
tensor(0.0518, device='cuda:0') tensor(0.0740, device='cuda:0') tensor(-2.4074e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.227313
Average KL loss: 0.006871
Average total loss: 0.234184
tensor(0.0510, device='cuda:0') tensor(0.0734, device='cuda:0') tensor(-2.9141e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.224256
Average KL loss: 0.006795
Average total loss: 0.231051
tensor(0.0503, device='cuda:0') tensor(0.0728, device='cuda:0') tensor(-2.7523e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.219291
Average KL loss: 0.006724
Average total loss: 0.226015
tensor(0.0495, device='cuda:0') tensor(0.0722, device='cuda:0') tensor(-2.5737e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.231439
Average KL loss: 0.006658
Average total loss: 0.238097
tensor(0.0488, device='cuda:0') tensor(0.0717, device='cuda:0') tensor(-2.9912e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.224924
Average KL loss: 0.006595
Average total loss: 0.231520
tensor(0.0481, device='cuda:0') tensor(0.0712, device='cuda:0') tensor(-3.0714e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.224041
Average KL loss: 0.006537
Average total loss: 0.230578
tensor(0.0475, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-3.0663e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.223748
Average KL loss: 0.006482
Average total loss: 0.230230
tensor(0.0468, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-3.6365e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.222335
Average KL loss: 0.006431
Average total loss: 0.228766
tensor(0.0462, device='cuda:0') tensor(0.0699, device='cuda:0') tensor(-2.8160e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.219256
Average KL loss: 0.006383
Average total loss: 0.225639
tensor(0.0457, device='cuda:0') tensor(0.0695, device='cuda:0') tensor(-2.5564e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.215370
Average KL loss: 0.006338
Average total loss: 0.221708
tensor(0.0451, device='cuda:0') tensor(0.0692, device='cuda:0') tensor(-2.6201e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.211432
Average KL loss: 0.006295
Average total loss: 0.217728
tensor(0.0446, device='cuda:0') tensor(0.0688, device='cuda:0') tensor(-2.7353e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.220317
Average KL loss: 0.006256
Average total loss: 0.226573
tensor(0.0441, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-3.3047e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.221146
Average KL loss: 0.006218
Average total loss: 0.227365
tensor(0.0436, device='cuda:0') tensor(0.0682, device='cuda:0') tensor(-2.4629e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.210191
Average KL loss: 0.006183
Average total loss: 0.216374
tensor(0.0432, device='cuda:0') tensor(0.0679, device='cuda:0') tensor(-3.0855e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.207879
Average KL loss: 0.006150
Average total loss: 0.214029
tensor(0.0427, device='cuda:0') tensor(0.0677, device='cuda:0') tensor(-2.9863e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.206130
Average KL loss: 0.006119
Average total loss: 0.212249
tensor(0.0423, device='cuda:0') tensor(0.0674, device='cuda:0') tensor(-3.1423e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.207463
Average KL loss: 0.006090
Average total loss: 0.213553
tensor(0.0419, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(-1.8938e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.199004
Average KL loss: 0.006062
Average total loss: 0.205066
tensor(0.0415, device='cuda:0') tensor(0.0670, device='cuda:0') tensor(-4.0601e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.209323
Average KL loss: 0.006036
Average total loss: 0.215359
tensor(0.0412, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-2.2070e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.210422
Average KL loss: 0.006012
Average total loss: 0.216434
tensor(0.0408, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-3.0955e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.208554
Average KL loss: 0.005989
Average total loss: 0.214543
tensor(0.0405, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-2.0338e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.198817
Average KL loss: 0.005967
Average total loss: 0.204785
tensor(0.0402, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-2.0496e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.192837
Average KL loss: 0.005947
Average total loss: 0.198784
tensor(0.0399, device='cuda:0') tensor(0.0661, device='cuda:0') tensor(-2.5152e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.197415
Average KL loss: 0.005927
Average total loss: 0.203342
tensor(0.0396, device='cuda:0') tensor(0.0659, device='cuda:0') tensor(-2.3260e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.190000
Average KL loss: 0.005909
Average total loss: 0.195909
tensor(0.0393, device='cuda:0') tensor(0.0658, device='cuda:0') tensor(-2.1638e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.192870
Average KL loss: 0.005892
Average total loss: 0.198761
tensor(0.0391, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-2.8546e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.195188
Average KL loss: 0.005875
Average total loss: 0.201063
tensor(0.0389, device='cuda:0') tensor(0.0655, device='cuda:0') tensor(-2.2927e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.182301
Average KL loss: 0.005859
Average total loss: 0.188161
tensor(0.0386, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-2.0100e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.197988
Average KL loss: 0.005844
Average total loss: 0.203833
tensor(0.0384, device='cuda:0') tensor(0.0653, device='cuda:0') tensor(-2.7828e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.194004
Average KL loss: 0.005830
Average total loss: 0.199834
tensor(0.0382, device='cuda:0') tensor(0.0651, device='cuda:0') tensor(-2.4828e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.191017
Average KL loss: 0.005816
Average total loss: 0.196834
tensor(0.0380, device='cuda:0') tensor(0.0650, device='cuda:0') tensor(-2.6858e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.193124
Average KL loss: 0.005804
Average total loss: 0.198928
tensor(0.0378, device='cuda:0') tensor(0.0650, device='cuda:0') tensor(-2.0980e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.188331
Average KL loss: 0.005792
Average total loss: 0.194123
tensor(0.0376, device='cuda:0') tensor(0.0649, device='cuda:0') tensor(-2.3909e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.192805
Average KL loss: 0.005781
Average total loss: 0.198585
tensor(0.0375, device='cuda:0') tensor(0.0648, device='cuda:0') tensor(-2.1359e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.179566
Average KL loss: 0.005770
Average total loss: 0.185336
tensor(0.0373, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-1.9697e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.192276
Average KL loss: 0.005760
Average total loss: 0.198036
tensor(0.0372, device='cuda:0') tensor(0.0646, device='cuda:0') tensor(-2.3597e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.188288
Average KL loss: 0.005751
Average total loss: 0.194038
tensor(0.0370, device='cuda:0') tensor(0.0646, device='cuda:0') tensor(-2.4509e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.186005
Average KL loss: 0.005741
Average total loss: 0.191747
tensor(0.0369, device='cuda:0') tensor(0.0645, device='cuda:0') tensor(-2.5403e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.184251
Average KL loss: 0.005733
Average total loss: 0.189983
tensor(0.0367, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-2.1770e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.188825
Average KL loss: 0.005724
Average total loss: 0.194550
tensor(0.0366, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-2.7883e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.180029
Average KL loss: 0.005716
Average total loss: 0.185745
tensor(0.0365, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-1.9317e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.178744
Average KL loss: 0.005709
Average total loss: 0.184452
tensor(0.0364, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-2.7343e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.181311
Average KL loss: 0.005701
Average total loss: 0.187012
tensor(0.0363, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-2.3875e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.180171
Average KL loss: 0.005694
Average total loss: 0.185866
tensor(0.0362, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-2.3376e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.181355
Average KL loss: 0.005688
Average total loss: 0.187043
tensor(0.0361, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-2.5310e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.180309
Average KL loss: 0.005682
Average total loss: 0.185991
tensor(0.0360, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-2.6609e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.178323
Average KL loss: 0.005676
Average total loss: 0.184000
tensor(0.0359, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-2.7424e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.174975
Average KL loss: 0.005671
Average total loss: 0.180646
tensor(0.0358, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-2.1116e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.169239
Average KL loss: 0.005666
Average total loss: 0.174905
tensor(0.0358, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-1.6743e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.176732
Average KL loss: 0.005661
Average total loss: 0.182393
tensor(0.0357, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-1.8096e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.171161
Average KL loss: 0.005656
Average total loss: 0.176818
tensor(0.0356, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-3.5599e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.175119
Average KL loss: 0.005652
Average total loss: 0.180771
tensor(0.0355, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-1.6906e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.177127
Average KL loss: 0.005648
Average total loss: 0.182775
tensor(0.0355, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-2.1164e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.170112
Average KL loss: 0.005644
Average total loss: 0.175756
tensor(0.0354, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-2.0712e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.169961
Average KL loss: 0.005640
Average total loss: 0.175601
tensor(0.0354, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-1.4432e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.176909
Average KL loss: 0.005636
Average total loss: 0.182545
tensor(0.0353, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-1.5198e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.161214
Average KL loss: 0.005633
Average total loss: 0.166846
tensor(0.0353, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-2.2113e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.174767
Average KL loss: 0.005629
Average total loss: 0.180397
tensor(0.0352, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-1.9656e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.164268
Average KL loss: 0.005626
Average total loss: 0.169894
tensor(0.0352, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-2.0947e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.164190
Average KL loss: 0.005623
Average total loss: 0.169813
tensor(0.0351, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-2.1831e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.165151
Average KL loss: 0.005621
Average total loss: 0.170771
tensor(0.0351, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-3.3044e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.178003
Average KL loss: 0.005618
Average total loss: 0.183622
tensor(0.0350, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-2.2870e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.173693
Average KL loss: 0.005616
Average total loss: 0.179309
tensor(0.0350, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-1.7325e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.161015
Average KL loss: 0.005614
Average total loss: 0.166629
tensor(0.0350, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-1.4775e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.169478
Average KL loss: 0.005611
Average total loss: 0.175089
tensor(0.0349, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-1.8242e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.166592
Average KL loss: 0.005609
Average total loss: 0.172201
tensor(0.0349, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-2.3408e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.165933
Average KL loss: 0.005607
Average total loss: 0.171540
tensor(0.0349, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-1.7668e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.160636
Average KL loss: 0.005606
Average total loss: 0.166241
tensor(0.0348, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-1.6808e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.165769
Average KL loss: 0.005604
Average total loss: 0.171373
tensor(0.0348, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-1.8119e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.163919
Average KL loss: 0.005603
Average total loss: 0.169522
tensor(0.0348, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-1.2131e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.160579
Average KL loss: 0.005602
Average total loss: 0.166181
tensor(0.0348, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-2.0504e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.162151
Average KL loss: 0.005601
Average total loss: 0.167752
tensor(0.0347, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-1.5664e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.161967
Average KL loss: 0.005599
Average total loss: 0.167566
tensor(0.0347, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-1.7328e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.163056
Average KL loss: 0.005599
Average total loss: 0.168655
tensor(0.0347, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-1.6025e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.163117
Average KL loss: 0.005598
Average total loss: 0.168714
tensor(0.0347, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-2.4043e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.162777
Average KL loss: 0.005597
Average total loss: 0.168374
tensor(0.0347, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-1.5243e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.157212
Average KL loss: 0.005596
Average total loss: 0.162808
tensor(0.0346, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-1.8510e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.153713
Average KL loss: 0.005596
Average total loss: 0.159309
tensor(0.0346, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-2.3621e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.148871
Average KL loss: 0.005595
Average total loss: 0.154466
tensor(0.0346, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-1.6775e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.152349
Average KL loss: 0.005594
Average total loss: 0.157943
tensor(0.0346, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-1.9690e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.158989
Average KL loss: 0.005594
Average total loss: 0.164583
tensor(0.0346, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-1.8390e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.152241
Average KL loss: 0.005594
Average total loss: 0.157835
tensor(0.0346, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-1.4249e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.151430
Average KL loss: 0.005594
Average total loss: 0.157024
tensor(0.0345, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-1.8987e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.149402
Average KL loss: 0.005593
Average total loss: 0.154995
tensor(0.0345, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-1.8817e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.147691
Average KL loss: 0.005593
Average total loss: 0.153285
tensor(0.0345, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-1.6518e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.157838
Average KL loss: 0.005593
Average total loss: 0.163431
tensor(0.0345, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-1.2300e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.155232
Average KL loss: 0.005593
Average total loss: 0.160824
tensor(0.0345, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-1.7818e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.146561
Average KL loss: 0.005593
Average total loss: 0.152154
tensor(0.0345, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-1.8676e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.157003
Average KL loss: 0.005593
Average total loss: 0.162597
tensor(0.0345, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-2.4571e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.159505
Average KL loss: 0.005594
Average total loss: 0.165099
tensor(0.0345, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-1.7218e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.148617
Average KL loss: 0.005594
Average total loss: 0.154211
tensor(0.0345, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-2.0746e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.150042
Average KL loss: 0.005595
Average total loss: 0.155637
tensor(0.0345, device='cuda:0') tensor(0.0645, device='cuda:0') tensor(-1.5843e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.152594
Average KL loss: 0.005595
Average total loss: 0.158189
tensor(0.0345, device='cuda:0') tensor(0.0645, device='cuda:0') tensor(-2.0679e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.150712
Average KL loss: 0.005595
Average total loss: 0.156308
tensor(0.0344, device='cuda:0') tensor(0.0645, device='cuda:0') tensor(-1.5666e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.144987
Average KL loss: 0.005596
Average total loss: 0.150583
tensor(0.0344, device='cuda:0') tensor(0.0646, device='cuda:0') tensor(-1.3776e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.139278
Average KL loss: 0.005596
Average total loss: 0.144875
tensor(0.0344, device='cuda:0') tensor(0.0646, device='cuda:0') tensor(-1.9100e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.146143
Average KL loss: 0.005597
Average total loss: 0.151740
tensor(0.0344, device='cuda:0') tensor(0.0646, device='cuda:0') tensor(-1.8261e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.145321
Average KL loss: 0.005597
Average total loss: 0.150919
tensor(0.0344, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-1.7776e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.136753
Average KL loss: 0.005598
Average total loss: 0.142351
tensor(0.0344, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-1.4219e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.144782
Average KL loss: 0.005599
Average total loss: 0.150380
tensor(0.0344, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-1.2783e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.136789
Average KL loss: 0.005600
Average total loss: 0.142389
tensor(0.0344, device='cuda:0') tensor(0.0648, device='cuda:0') tensor(-2.6261e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.141893
Average KL loss: 0.005600
Average total loss: 0.147493
tensor(0.0344, device='cuda:0') tensor(0.0648, device='cuda:0') tensor(-1.3786e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.136884
Average KL loss: 0.005601
Average total loss: 0.142485
tensor(0.0344, device='cuda:0') tensor(0.0648, device='cuda:0') tensor(-1.8750e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.141981
Average KL loss: 0.005602
Average total loss: 0.147583
tensor(0.0344, device='cuda:0') tensor(0.0649, device='cuda:0') tensor(-1.3503e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.141550
Average KL loss: 0.005603
Average total loss: 0.147153
tensor(0.0344, device='cuda:0') tensor(0.0649, device='cuda:0') tensor(-1.8265e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.138983
Average KL loss: 0.005604
Average total loss: 0.144588
tensor(0.0344, device='cuda:0') tensor(0.0650, device='cuda:0') tensor(-1.6917e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.138547
Average KL loss: 0.005605
Average total loss: 0.144152
tensor(0.0344, device='cuda:0') tensor(0.0650, device='cuda:0') tensor(-2.2936e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.132413
Average KL loss: 0.005606
Average total loss: 0.138019
tensor(0.0344, device='cuda:0') tensor(0.0650, device='cuda:0') tensor(-1.5219e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.136269
Average KL loss: 0.005607
Average total loss: 0.141876
tensor(0.0344, device='cuda:0') tensor(0.0651, device='cuda:0') tensor(-1.5005e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.135561
Average KL loss: 0.005608
Average total loss: 0.141169
tensor(0.0344, device='cuda:0') tensor(0.0651, device='cuda:0') tensor(-1.1336e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.131542
Average KL loss: 0.005609
Average total loss: 0.137150
tensor(0.0344, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-1.2630e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.136796
Average KL loss: 0.005610
Average total loss: 0.142406
tensor(0.0344, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-1.7052e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.134945
Average KL loss: 0.005611
Average total loss: 0.140556
tensor(0.0344, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-1.6431e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.133845
Average KL loss: 0.005612
Average total loss: 0.139458
tensor(0.0344, device='cuda:0') tensor(0.0653, device='cuda:0') tensor(-1.4732e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.133283
Average KL loss: 0.005613
Average total loss: 0.138897
tensor(0.0344, device='cuda:0') tensor(0.0653, device='cuda:0') tensor(-1.6610e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.131054
Average KL loss: 0.005615
Average total loss: 0.136669
tensor(0.0344, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-1.5074e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.129020
Average KL loss: 0.005616
Average total loss: 0.134636
tensor(0.0344, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-1.7584e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.135003
Average KL loss: 0.005617
Average total loss: 0.140621
tensor(0.0344, device='cuda:0') tensor(0.0655, device='cuda:0') tensor(-1.4025e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.129981
Average KL loss: 0.005619
Average total loss: 0.135599
tensor(0.0344, device='cuda:0') tensor(0.0655, device='cuda:0') tensor(-1.5018e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.130197
Average KL loss: 0.005620
Average total loss: 0.135817
tensor(0.0344, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-1.8083e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.126597
Average KL loss: 0.005621
Average total loss: 0.132218
tensor(0.0344, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-1.6150e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.131372
Average KL loss: 0.005623
Average total loss: 0.136995
tensor(0.0344, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-1.5737e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.132662
Average KL loss: 0.005624
Average total loss: 0.138286
tensor(0.0344, device='cuda:0') tensor(0.0657, device='cuda:0') tensor(-1.1143e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.137248
Average KL loss: 0.005626
Average total loss: 0.142874
tensor(0.0344, device='cuda:0') tensor(0.0657, device='cuda:0') tensor(-1.6059e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.136981
Average KL loss: 0.005627
Average total loss: 0.142608
tensor(0.0344, device='cuda:0') tensor(0.0658, device='cuda:0') tensor(-1.6534e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.131088
Average KL loss: 0.005629
Average total loss: 0.136717
tensor(0.0344, device='cuda:0') tensor(0.0658, device='cuda:0') tensor(-1.3739e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.125643
Average KL loss: 0.005631
Average total loss: 0.131273
tensor(0.0344, device='cuda:0') tensor(0.0659, device='cuda:0') tensor(-1.5187e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.126096
Average KL loss: 0.005632
Average total loss: 0.131728
tensor(0.0344, device='cuda:0') tensor(0.0659, device='cuda:0') tensor(-1.3178e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.129300
Average KL loss: 0.005633
Average total loss: 0.134934
tensor(0.0344, device='cuda:0') tensor(0.0660, device='cuda:0') tensor(-1.4655e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.129442
Average KL loss: 0.005635
Average total loss: 0.135077
tensor(0.0345, device='cuda:0') tensor(0.0660, device='cuda:0') tensor(-1.4446e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.128437
Average KL loss: 0.005637
Average total loss: 0.134073
tensor(0.0345, device='cuda:0') tensor(0.0661, device='cuda:0') tensor(-2.0863e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.126351
Average KL loss: 0.005638
Average total loss: 0.131989
tensor(0.0345, device='cuda:0') tensor(0.0661, device='cuda:0') tensor(-1.3332e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.122843
Average KL loss: 0.005640
Average total loss: 0.128483
tensor(0.0345, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.6115e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.125983
Average KL loss: 0.005641
Average total loss: 0.131625
tensor(0.0345, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.4783e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.120974
Average KL loss: 0.005643
Average total loss: 0.126617
tensor(0.0345, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-2.5156e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.124350
Average KL loss: 0.005645
Average total loss: 0.129995
tensor(0.0345, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-1.3395e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.127556
Average KL loss: 0.005647
Average total loss: 0.133203
tensor(0.0345, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.6628e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.129529
Average KL loss: 0.005648
Average total loss: 0.135177
tensor(0.0345, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.5574e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.121131
Average KL loss: 0.005650
Average total loss: 0.126780
tensor(0.0345, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.2570e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.128504
Average KL loss: 0.005652
Average total loss: 0.134155
tensor(0.0345, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.6723e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.122259
Average KL loss: 0.005653
Average total loss: 0.127912
tensor(0.0345, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-1.4633e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.123718
Average KL loss: 0.005655
Average total loss: 0.129373
tensor(0.0345, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-1.3878e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.119531
Average KL loss: 0.005657
Average total loss: 0.125188
tensor(0.0345, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-1.3905e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.127075
Average KL loss: 0.005659
Average total loss: 0.132734
tensor(0.0345, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-1.6853e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.126279
Average KL loss: 0.005660
Average total loss: 0.131939
tensor(0.0345, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-1.6892e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.120326
Average KL loss: 0.005662
Average total loss: 0.125989
tensor(0.0345, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-1.1599e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.121548
Average KL loss: 0.005664
Average total loss: 0.127212
tensor(0.0345, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-1.4525e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.117637
Average KL loss: 0.005666
Average total loss: 0.123303
tensor(0.0345, device='cuda:0') tensor(0.0670, device='cuda:0') tensor(-1.1725e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.122205
Average KL loss: 0.005668
Average total loss: 0.127873
tensor(0.0346, device='cuda:0') tensor(0.0670, device='cuda:0') tensor(-1.5474e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.121172
Average KL loss: 0.005671
Average total loss: 0.126843
tensor(0.0346, device='cuda:0') tensor(0.0671, device='cuda:0') tensor(-1.5257e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.115477
Average KL loss: 0.005672
Average total loss: 0.121149
tensor(0.0346, device='cuda:0') tensor(0.0671, device='cuda:0') tensor(-1.2705e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.120842
Average KL loss: 0.005674
Average total loss: 0.126517
tensor(0.0346, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(-1.0202e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.121337
Average KL loss: 0.005676
Average total loss: 0.127013
tensor(0.0346, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(-1.4320e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.118516
Average KL loss: 0.005678
Average total loss: 0.124195
tensor(0.0346, device='cuda:0') tensor(0.0673, device='cuda:0') tensor(-1.4962e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.119514
Average KL loss: 0.005680
Average total loss: 0.125194
tensor(0.0346, device='cuda:0') tensor(0.0673, device='cuda:0') tensor(-1.2218e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.122713
Average KL loss: 0.005682
Average total loss: 0.128395
tensor(0.0346, device='cuda:0') tensor(0.0674, device='cuda:0') tensor(-1.6012e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.117071
Average KL loss: 0.005684
Average total loss: 0.122755
tensor(0.0346, device='cuda:0') tensor(0.0674, device='cuda:0') tensor(-1.1412e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.113280
Average KL loss: 0.005686
Average total loss: 0.118966
tensor(0.0346, device='cuda:0') tensor(0.0675, device='cuda:0') tensor(-1.2478e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.114700
Average KL loss: 0.005688
Average total loss: 0.120388
tensor(0.0346, device='cuda:0') tensor(0.0676, device='cuda:0') tensor(-9.9942e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.114936
Average KL loss: 0.005690
Average total loss: 0.120625
tensor(0.0346, device='cuda:0') tensor(0.0676, device='cuda:0') tensor(-1.0037e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.113291
Average KL loss: 0.005692
Average total loss: 0.118982
tensor(0.0346, device='cuda:0') tensor(0.0677, device='cuda:0') tensor(-8.4066e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.123445
Average KL loss: 0.005693
Average total loss: 0.129138
tensor(0.0346, device='cuda:0') tensor(0.0677, device='cuda:0') tensor(-1.1006e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.117769
Average KL loss: 0.005695
Average total loss: 0.123464
tensor(0.0346, device='cuda:0') tensor(0.0678, device='cuda:0') tensor(-1.1022e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.108114
Average KL loss: 0.005697
Average total loss: 0.113811
tensor(0.0346, device='cuda:0') tensor(0.0678, device='cuda:0') tensor(-8.6713e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.115812
Average KL loss: 0.005699
Average total loss: 0.121511
tensor(0.0347, device='cuda:0') tensor(0.0679, device='cuda:0') tensor(-1.3615e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.111822
Average KL loss: 0.005701
Average total loss: 0.117523
tensor(0.0347, device='cuda:0') tensor(0.0679, device='cuda:0') tensor(-1.5532e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.113012
Average KL loss: 0.005703
Average total loss: 0.118715
tensor(0.0347, device='cuda:0') tensor(0.0680, device='cuda:0') tensor(-1.1815e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.110460
Average KL loss: 0.005705
Average total loss: 0.116165
tensor(0.0347, device='cuda:0') tensor(0.0680, device='cuda:0') tensor(-1.3374e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.107200
Average KL loss: 0.005707
Average total loss: 0.112907
tensor(0.0347, device='cuda:0') tensor(0.0681, device='cuda:0') tensor(-8.7138e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.110717
Average KL loss: 0.005709
Average total loss: 0.116426
tensor(0.0347, device='cuda:0') tensor(0.0682, device='cuda:0') tensor(-1.2391e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.111000
Average KL loss: 0.005711
Average total loss: 0.116711
tensor(0.0347, device='cuda:0') tensor(0.0682, device='cuda:0') tensor(-1.1302e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.111351
Average KL loss: 0.005713
Average total loss: 0.117064
tensor(0.0347, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-1.0877e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.114508
Average KL loss: 0.005715
Average total loss: 0.120224
tensor(0.0347, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-1.7197e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.115492
Average KL loss: 0.005717
Average total loss: 0.121210
tensor(0.0347, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-1.5705e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.111359
Average KL loss: 0.005720
Average total loss: 0.117079
tensor(0.0347, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-1.3703e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.106690
Average KL loss: 0.005722
Average total loss: 0.112412
tensor(0.0347, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-1.1200e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.106548
Average KL loss: 0.005724
Average total loss: 0.112272
tensor(0.0347, device='cuda:0') tensor(0.0686, device='cuda:0') tensor(-1.3235e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.104217
Average KL loss: 0.005726
Average total loss: 0.109943
tensor(0.0348, device='cuda:0') tensor(0.0686, device='cuda:0') tensor(-1.1383e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.107381
Average KL loss: 0.005728
Average total loss: 0.113109
 Percentile value: 2.4085350036621094
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/8]: ---
conv1.weight         | nonzeros =     119 /    1728             (  6.89%) | total_pruned =    1609 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     102 /   36864             (  0.28%) | total_pruned =   36762 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     261 /   36864             (  0.71%) | total_pruned =   36603 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     455 /   36864             (  1.23%) | total_pruned =   36409 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     993 /   36864             (  2.69%) | total_pruned =   35871 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2022 /   73728             (  2.74%) | total_pruned =   71706 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2861 /  147456             (  1.94%) | total_pruned =  144595 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     563 /    8192             (  6.87%) | total_pruned =    7629 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1539 /  147456             (  1.04%) | total_pruned =  145917 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1954 /  147456             (  1.33%) | total_pruned =  145502 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    4745 /  294912             (  1.61%) | total_pruned =  290167 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5435 /  589824             (  0.92%) | total_pruned =  584389 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     897 /   32768             (  2.74%) | total_pruned =   31871 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     187 /     256             ( 73.05%) | total_pruned =      69 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3557 /  589824             (  0.60%) | total_pruned =  586267 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3535 /  589824             (  0.60%) | total_pruned =  586289 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    6795 / 1179648             (  0.58%) | total_pruned = 1172853 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   10533 / 2359296             (  0.45%) | total_pruned = 2348763 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     379 /     512             ( 74.02%) | total_pruned =     133 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     542 /  131072             (  0.41%) | total_pruned =  130530 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     155 /     512             ( 30.27%) | total_pruned =     357 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     197 /     512             ( 38.48%) | total_pruned =     315 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   11525 / 2359296             (  0.49%) | total_pruned = 2347771 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     178 /     512             ( 34.77%) | total_pruned =     334 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   25598 / 2359296             (  1.08%) | total_pruned = 2333698 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     285 /     512             ( 55.66%) | total_pruned =     227 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     269 /     512             ( 52.54%) | total_pruned =     243 | shape = torch.Size([512])
linear.weight        | nonzeros =    2502 /    5120             ( 48.87%) | total_pruned =    2618 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 82/100 Loss: 0.071129 Accuracy: 85.82 99.98 % Best test Accuracy: 86.52%
tensor(0.0348, device='cuda:0') tensor(0.0687, device='cuda:0') tensor(-4.6784e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.461806
Average KL loss: 0.005676
Average total loss: 0.467482
tensor(0.0343, device='cuda:0') tensor(0.0674, device='cuda:0') tensor(-4.5706e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.441201
Average KL loss: 0.005572
Average total loss: 0.446773
tensor(0.0338, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-4.3945e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.436101
Average KL loss: 0.005470
Average total loss: 0.441571
tensor(0.0333, device='cuda:0') tensor(0.0650, device='cuda:0') tensor(-3.7887e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.425736
Average KL loss: 0.005370
Average total loss: 0.431106
tensor(0.0329, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-4.3566e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.417690
Average KL loss: 0.005271
Average total loss: 0.422961
tensor(0.0324, device='cuda:0') tensor(0.0629, device='cuda:0') tensor(-5.7100e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.419007
Average KL loss: 0.005174
Average total loss: 0.424181
tensor(0.0319, device='cuda:0') tensor(0.0618, device='cuda:0') tensor(-3.9502e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.417015
Average KL loss: 0.005079
Average total loss: 0.422094
tensor(0.0315, device='cuda:0') tensor(0.0608, device='cuda:0') tensor(-3.6570e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.413429
Average KL loss: 0.004986
Average total loss: 0.418415
tensor(0.0311, device='cuda:0') tensor(0.0598, device='cuda:0') tensor(-3.4867e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.401848
Average KL loss: 0.004895
Average total loss: 0.406743
tensor(0.0306, device='cuda:0') tensor(0.0589, device='cuda:0') tensor(-3.6789e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.414909
Average KL loss: 0.004805
Average total loss: 0.419714
tensor(0.0302, device='cuda:0') tensor(0.0580, device='cuda:0') tensor(-4.5870e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.409991
Average KL loss: 0.004718
Average total loss: 0.414709
tensor(0.0298, device='cuda:0') tensor(0.0571, device='cuda:0') tensor(-4.2409e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.413483
Average KL loss: 0.004633
Average total loss: 0.418117
tensor(0.0293, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-4.8203e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.401855
Average KL loss: 0.004551
Average total loss: 0.406406
tensor(0.0289, device='cuda:0') tensor(0.0555, device='cuda:0') tensor(-4.1009e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.399893
Average KL loss: 0.004470
Average total loss: 0.404363
tensor(0.0285, device='cuda:0') tensor(0.0547, device='cuda:0') tensor(-4.2344e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.395966
Average KL loss: 0.004392
Average total loss: 0.400359
tensor(0.0281, device='cuda:0') tensor(0.0539, device='cuda:0') tensor(-3.3120e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.390821
Average KL loss: 0.004317
Average total loss: 0.395138
tensor(0.0277, device='cuda:0') tensor(0.0532, device='cuda:0') tensor(-3.9727e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.428919
Average KL loss: 0.004243
Average total loss: 0.433162
tensor(0.0273, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-3.1522e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.387151
Average KL loss: 0.004172
Average total loss: 0.391323
tensor(0.0270, device='cuda:0') tensor(0.0519, device='cuda:0') tensor(-4.2576e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.407260
Average KL loss: 0.004104
Average total loss: 0.411363
tensor(0.0266, device='cuda:0') tensor(0.0512, device='cuda:0') tensor(-3.7766e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.388853
Average KL loss: 0.004037
Average total loss: 0.392891
tensor(0.0262, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-3.9763e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.387791
Average KL loss: 0.003974
Average total loss: 0.391765
tensor(0.0259, device='cuda:0') tensor(0.0500, device='cuda:0') tensor(-2.9158e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.389985
Average KL loss: 0.003912
Average total loss: 0.393898
tensor(0.0255, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-3.1962e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.382593
Average KL loss: 0.003853
Average total loss: 0.386447
tensor(0.0252, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-2.3624e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.383435
Average KL loss: 0.003797
Average total loss: 0.387232
tensor(0.0248, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-4.0592e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.379694
Average KL loss: 0.003742
Average total loss: 0.383436
tensor(0.0245, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-2.4761e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.374456
Average KL loss: 0.003690
Average total loss: 0.378147
tensor(0.0242, device='cuda:0') tensor(0.0475, device='cuda:0') tensor(-3.4298e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.377053
Average KL loss: 0.003641
Average total loss: 0.380694
tensor(0.0239, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-3.1689e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.363548
Average KL loss: 0.003593
Average total loss: 0.367141
tensor(0.0236, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-3.1700e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.377899
Average KL loss: 0.003548
Average total loss: 0.381447
tensor(0.0233, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-3.2468e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.374477
Average KL loss: 0.003505
Average total loss: 0.377981
tensor(0.0230, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(-3.4269e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.372434
Average KL loss: 0.003463
Average total loss: 0.375897
tensor(0.0227, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-3.6105e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.357591
Average KL loss: 0.003424
Average total loss: 0.361015
tensor(0.0224, device='cuda:0') tensor(0.0452, device='cuda:0') tensor(-3.6161e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.356997
Average KL loss: 0.003387
Average total loss: 0.360384
tensor(0.0222, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(-2.9793e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.360807
Average KL loss: 0.003352
Average total loss: 0.364159
tensor(0.0219, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-3.8490e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.345256
Average KL loss: 0.003318
Average total loss: 0.348574
tensor(0.0216, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-2.7840e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.361264
Average KL loss: 0.003286
Average total loss: 0.364550
tensor(0.0214, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-4.0963e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.358119
Average KL loss: 0.003256
Average total loss: 0.361375
tensor(0.0211, device='cuda:0') tensor(0.0438, device='cuda:0') tensor(-3.2334e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.347003
Average KL loss: 0.003227
Average total loss: 0.350230
tensor(0.0209, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-2.3455e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.364183
Average KL loss: 0.003200
Average total loss: 0.367384
tensor(0.0207, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(-3.4899e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.353701
Average KL loss: 0.003175
Average total loss: 0.356876
tensor(0.0205, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-3.3927e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.370987
Average KL loss: 0.003151
Average total loss: 0.374138
tensor(0.0203, device='cuda:0') tensor(0.0429, device='cuda:0') tensor(-2.8019e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.350111
Average KL loss: 0.003128
Average total loss: 0.353240
tensor(0.0201, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-2.6621e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.336994
Average KL loss: 0.003107
Average total loss: 0.340101
tensor(0.0199, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-2.6450e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.343205
Average KL loss: 0.003087
Average total loss: 0.346292
tensor(0.0197, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-2.4697e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.348956
Average KL loss: 0.003068
Average total loss: 0.352023
tensor(0.0195, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-2.7675e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.345206
Average KL loss: 0.003050
Average total loss: 0.348255
tensor(0.0193, device='cuda:0') tensor(0.0421, device='cuda:0') tensor(-3.7310e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.332222
Average KL loss: 0.003033
Average total loss: 0.335255
tensor(0.0191, device='cuda:0') tensor(0.0419, device='cuda:0') tensor(-4.6713e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.342276
Average KL loss: 0.003017
Average total loss: 0.345293
tensor(0.0190, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-2.9219e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.329020
Average KL loss: 0.003002
Average total loss: 0.332022
tensor(0.0188, device='cuda:0') tensor(0.0417, device='cuda:0') tensor(-2.6875e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.329310
Average KL loss: 0.002988
Average total loss: 0.332298
tensor(0.0186, device='cuda:0') tensor(0.0415, device='cuda:0') tensor(-2.6263e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.333139
Average KL loss: 0.002975
Average total loss: 0.336114
tensor(0.0185, device='cuda:0') tensor(0.0414, device='cuda:0') tensor(-2.1881e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.329056
Average KL loss: 0.002962
Average total loss: 0.332018
tensor(0.0183, device='cuda:0') tensor(0.0413, device='cuda:0') tensor(-3.4428e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.330119
Average KL loss: 0.002950
Average total loss: 0.333069
tensor(0.0182, device='cuda:0') tensor(0.0412, device='cuda:0') tensor(-2.8062e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.326329
Average KL loss: 0.002939
Average total loss: 0.329269
tensor(0.0181, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(-3.1559e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.315624
Average KL loss: 0.002929
Average total loss: 0.318553
tensor(0.0180, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(-3.2400e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.347988
Average KL loss: 0.002919
Average total loss: 0.350907
tensor(0.0178, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-4.5207e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.317750
Average KL loss: 0.002910
Average total loss: 0.320660
tensor(0.0177, device='cuda:0') tensor(0.0409, device='cuda:0') tensor(-3.5818e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.328783
Average KL loss: 0.002901
Average total loss: 0.331685
tensor(0.0176, device='cuda:0') tensor(0.0408, device='cuda:0') tensor(-2.9640e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.321480
Average KL loss: 0.002893
Average total loss: 0.324373
tensor(0.0175, device='cuda:0') tensor(0.0408, device='cuda:0') tensor(-2.7348e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.334476
Average KL loss: 0.002886
Average total loss: 0.337362
tensor(0.0174, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-2.5135e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.319859
Average KL loss: 0.002878
Average total loss: 0.322738
tensor(0.0173, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-2.4971e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.320497
Average KL loss: 0.002872
Average total loss: 0.323368
tensor(0.0172, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-2.8589e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.306864
Average KL loss: 0.002865
Average total loss: 0.309729
tensor(0.0171, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-2.3833e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.339400
Average KL loss: 0.002859
Average total loss: 0.342259
tensor(0.0170, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-2.5957e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.309577
Average KL loss: 0.002853
Average total loss: 0.312430
tensor(0.0169, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-2.1724e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.310343
Average KL loss: 0.002848
Average total loss: 0.313191
tensor(0.0168, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.6712e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.311652
Average KL loss: 0.002843
Average total loss: 0.314495
tensor(0.0168, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-3.3877e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.308234
Average KL loss: 0.002838
Average total loss: 0.311073
tensor(0.0167, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-3.1721e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.320237
Average KL loss: 0.002834
Average total loss: 0.323070
tensor(0.0166, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-2.5189e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.311832
Average KL loss: 0.002829
Average total loss: 0.314661
tensor(0.0166, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-2.7746e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.304247
Average KL loss: 0.002825
Average total loss: 0.307072
tensor(0.0165, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-2.5083e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.317121
Average KL loss: 0.002821
Average total loss: 0.319943
tensor(0.0164, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.6126e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.316418
Average KL loss: 0.002818
Average total loss: 0.319236
tensor(0.0164, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.4286e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.301238
Average KL loss: 0.002814
Average total loss: 0.304053
tensor(0.0163, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.8732e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.305712
Average KL loss: 0.002811
Average total loss: 0.308523
tensor(0.0163, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.5363e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.292405
Average KL loss: 0.002808
Average total loss: 0.295213
tensor(0.0162, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.3602e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.308672
Average KL loss: 0.002805
Average total loss: 0.311477
tensor(0.0162, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.7956e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.336956
Average KL loss: 0.002802
Average total loss: 0.339759
tensor(0.0161, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.5375e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.298924
Average KL loss: 0.002799
Average total loss: 0.301724
tensor(0.0161, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.9120e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.288000
Average KL loss: 0.002797
Average total loss: 0.290797
tensor(0.0161, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-3.5451e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.299663
Average KL loss: 0.002795
Average total loss: 0.302457
tensor(0.0160, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-3.5752e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.292892
Average KL loss: 0.002792
Average total loss: 0.295684
tensor(0.0160, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.5185e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.299061
Average KL loss: 0.002790
Average total loss: 0.301851
tensor(0.0159, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.6225e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.289667
Average KL loss: 0.002788
Average total loss: 0.292456
tensor(0.0159, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.1431e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.296552
Average KL loss: 0.002786
Average total loss: 0.299338
tensor(0.0159, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.5804e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.313618
Average KL loss: 0.002784
Average total loss: 0.316403
tensor(0.0159, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-2.3136e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.294063
Average KL loss: 0.002783
Average total loss: 0.296845
tensor(0.0158, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-2.0606e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.287030
Average KL loss: 0.002781
Average total loss: 0.289811
tensor(0.0158, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-2.3979e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.290793
Average KL loss: 0.002779
Average total loss: 0.293572
tensor(0.0158, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-2.4366e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.282794
Average KL loss: 0.002778
Average total loss: 0.285572
tensor(0.0158, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-2.5790e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.307969
Average KL loss: 0.002776
Average total loss: 0.310746
tensor(0.0157, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-1.9354e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.281106
Average KL loss: 0.002775
Average total loss: 0.283881
tensor(0.0157, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-2.8799e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.279658
Average KL loss: 0.002773
Average total loss: 0.282432
tensor(0.0157, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-2.5869e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.293045
Average KL loss: 0.002772
Average total loss: 0.295817
tensor(0.0157, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-1.7945e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.317774
Average KL loss: 0.002771
Average total loss: 0.320545
tensor(0.0156, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-2.3871e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.301541
Average KL loss: 0.002770
Average total loss: 0.304311
tensor(0.0156, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-2.7829e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.294117
Average KL loss: 0.002769
Average total loss: 0.296885
tensor(0.0156, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.4575e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.277105
Average KL loss: 0.002768
Average total loss: 0.279873
tensor(0.0156, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.3029e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.284013
Average KL loss: 0.002767
Average total loss: 0.286780
tensor(0.0156, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.2647e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.278406
Average KL loss: 0.002766
Average total loss: 0.281172
tensor(0.0156, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.6276e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.284351
Average KL loss: 0.002765
Average total loss: 0.287116
tensor(0.0156, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.4738e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.273905
Average KL loss: 0.002764
Average total loss: 0.276669
tensor(0.0155, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.6026e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.262590
Average KL loss: 0.002764
Average total loss: 0.265354
tensor(0.0155, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.4606e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.279444
Average KL loss: 0.002763
Average total loss: 0.282207
tensor(0.0155, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.4709e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.273949
Average KL loss: 0.002762
Average total loss: 0.276711
tensor(0.0155, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.6597e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.269868
Average KL loss: 0.002762
Average total loss: 0.272630
tensor(0.0155, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-1.8348e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.303134
Average KL loss: 0.002761
Average total loss: 0.305895
tensor(0.0155, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.2857e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.266568
Average KL loss: 0.002760
Average total loss: 0.269329
tensor(0.0155, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.8900e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.279249
Average KL loss: 0.002760
Average total loss: 0.282009
tensor(0.0155, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-1.8389e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.281644
Average KL loss: 0.002759
Average total loss: 0.284403
tensor(0.0155, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.3784e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.274729
Average KL loss: 0.002759
Average total loss: 0.277488
tensor(0.0155, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-1.7479e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.256865
Average KL loss: 0.002759
Average total loss: 0.259623
tensor(0.0155, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-1.6196e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.262605
Average KL loss: 0.002758
Average total loss: 0.265363
tensor(0.0155, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.0546e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.299617
Average KL loss: 0.002758
Average total loss: 0.302375
tensor(0.0154, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.1819e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.266509
Average KL loss: 0.002757
Average total loss: 0.269267
tensor(0.0154, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-1.7409e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.266590
Average KL loss: 0.002757
Average total loss: 0.269347
tensor(0.0154, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-1.7075e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.263348
Average KL loss: 0.002757
Average total loss: 0.266105
tensor(0.0154, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-2.0418e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.295571
Average KL loss: 0.002756
Average total loss: 0.298327
tensor(0.0154, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-1.8888e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.263701
Average KL loss: 0.002756
Average total loss: 0.266457
tensor(0.0154, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-2.0835e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.258896
Average KL loss: 0.002756
Average total loss: 0.261652
tensor(0.0154, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-2.2829e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.287252
Average KL loss: 0.002756
Average total loss: 0.290007
tensor(0.0154, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-1.6715e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.260728
Average KL loss: 0.002755
Average total loss: 0.263483
tensor(0.0154, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-2.1301e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.286485
Average KL loss: 0.002755
Average total loss: 0.289240
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.8096e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.266585
Average KL loss: 0.002755
Average total loss: 0.269340
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.8974e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.256638
Average KL loss: 0.002755
Average total loss: 0.259393
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.2905e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.253535
Average KL loss: 0.002755
Average total loss: 0.256290
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.0674e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.257665
Average KL loss: 0.002755
Average total loss: 0.260420
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.8606e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.268882
Average KL loss: 0.002755
Average total loss: 0.271637
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.3767e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.263018
Average KL loss: 0.002755
Average total loss: 0.265773
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.0259e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.262057
Average KL loss: 0.002755
Average total loss: 0.264811
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.1840e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.251598
Average KL loss: 0.002755
Average total loss: 0.254352
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.2328e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.253497
Average KL loss: 0.002755
Average total loss: 0.256252
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.7826e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.262198
Average KL loss: 0.002755
Average total loss: 0.264953
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.5804e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.265689
Average KL loss: 0.002755
Average total loss: 0.268444
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.3670e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.252138
Average KL loss: 0.002755
Average total loss: 0.254893
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.5049e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.262279
Average KL loss: 0.002755
Average total loss: 0.265034
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.7287e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.252109
Average KL loss: 0.002755
Average total loss: 0.254864
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.1215e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.271351
Average KL loss: 0.002755
Average total loss: 0.274106
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.3443e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.253450
Average KL loss: 0.002755
Average total loss: 0.256205
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.0991e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.252356
Average KL loss: 0.002755
Average total loss: 0.255111
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.6441e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.283289
Average KL loss: 0.002755
Average total loss: 0.286044
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.4618e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.248796
Average KL loss: 0.002755
Average total loss: 0.251551
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.9884e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.291310
Average KL loss: 0.002755
Average total loss: 0.294064
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.4533e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.277804
Average KL loss: 0.002755
Average total loss: 0.280558
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.1722e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.249492
Average KL loss: 0.002755
Average total loss: 0.252247
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-3.0800e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.255539
Average KL loss: 0.002755
Average total loss: 0.258294
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.6680e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.262900
Average KL loss: 0.002755
Average total loss: 0.265655
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.0053e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.269972
Average KL loss: 0.002755
Average total loss: 0.272727
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-3.1230e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.264968
Average KL loss: 0.002755
Average total loss: 0.267723
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.7084e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.247908
Average KL loss: 0.002755
Average total loss: 0.250663
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.8561e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.244708
Average KL loss: 0.002755
Average total loss: 0.247463
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.6329e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.250627
Average KL loss: 0.002755
Average total loss: 0.253382
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.8448e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.247125
Average KL loss: 0.002755
Average total loss: 0.249879
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.1823e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.253234
Average KL loss: 0.002755
Average total loss: 0.255989
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.2824e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.248421
Average KL loss: 0.002755
Average total loss: 0.251176
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.3752e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.248906
Average KL loss: 0.002755
Average total loss: 0.251661
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.6815e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.282146
Average KL loss: 0.002755
Average total loss: 0.284901
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.6007e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.262970
Average KL loss: 0.002755
Average total loss: 0.265725
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.7393e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.246050
Average KL loss: 0.002755
Average total loss: 0.248804
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.2478e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.261752
Average KL loss: 0.002755
Average total loss: 0.264507
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.1363e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.276923
Average KL loss: 0.002755
Average total loss: 0.279678
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.5180e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.249692
Average KL loss: 0.002755
Average total loss: 0.252446
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.2031e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.250766
Average KL loss: 0.002755
Average total loss: 0.253521
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.6865e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.260265
Average KL loss: 0.002755
Average total loss: 0.263019
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.8264e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.255051
Average KL loss: 0.002755
Average total loss: 0.257805
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.9852e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.279271
Average KL loss: 0.002755
Average total loss: 0.282026
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.8551e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.274416
Average KL loss: 0.002755
Average total loss: 0.277171
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.8756e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.251111
Average KL loss: 0.002755
Average total loss: 0.253866
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-7.2959e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.262624
Average KL loss: 0.002755
Average total loss: 0.265379
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.6124e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.262749
Average KL loss: 0.002755
Average total loss: 0.265504
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.6884e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.258059
Average KL loss: 0.002755
Average total loss: 0.260814
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.9377e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.260445
Average KL loss: 0.002755
Average total loss: 0.263199
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.1340e-08, device='cuda:0')
 Percentile value: 3.1793706893920897
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/8]: ---
conv1.weight         | nonzeros =      70 /    1728             (  4.05%) | total_pruned =    1658 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      30 /   36864             (  0.08%) | total_pruned =   36834 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      88 /   36864             (  0.24%) | total_pruned =   36776 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     194 /   36864             (  0.53%) | total_pruned =   36670 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     355 /   36864             (  0.96%) | total_pruned =   36509 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     591 /   73728             (  0.80%) | total_pruned =   73137 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     811 /  147456             (  0.55%) | total_pruned =  146645 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     256 /    8192             (  3.12%) | total_pruned =    7936 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     504 /  147456             (  0.34%) | total_pruned =  146952 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     592 /  147456             (  0.40%) | total_pruned =  146864 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1301 /  294912             (  0.44%) | total_pruned =  293611 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1349 /  589824             (  0.23%) | total_pruned =  588475 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     263 /   32768             (  0.80%) | total_pruned =   32505 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     146 /     256             ( 57.03%) | total_pruned =     110 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     867 /  589824             (  0.15%) | total_pruned =  588957 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     809 /  589824             (  0.14%) | total_pruned =  589015 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1360 / 1179648             (  0.12%) | total_pruned = 1178288 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2207 / 2359296             (  0.09%) | total_pruned = 2357089 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     265 /     512             ( 51.76%) | total_pruned =     247 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     129 /     512             ( 25.20%) | total_pruned =     383 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     214 /  131072             (  0.16%) | total_pruned =  130858 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      66 /     512             ( 12.89%) | total_pruned =     446 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     123 /     512             ( 24.02%) | total_pruned =     389 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2987 / 2359296             (  0.13%) | total_pruned = 2356309 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     157 /     512             ( 30.66%) | total_pruned =     355 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    7736 / 2359296             (  0.33%) | total_pruned = 2351560 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     259 /     512             ( 50.59%) | total_pruned =     253 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
linear.weight        | nonzeros =    1388 /    5120             ( 27.11%) | total_pruned =    3732 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 99/100 Loss: 0.561339 Accuracy: 77.75 86.53 % Best test Accuracy: 78.20%
tensor(0.0154, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.9320e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.855526
Average KL loss: 0.002738
Average total loss: 0.858263
tensor(0.0152, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-3.6535e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.848786
Average KL loss: 0.002703
Average total loss: 0.851489
tensor(0.0151, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-5.3809e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.850827
Average KL loss: 0.002669
Average total loss: 0.853496
tensor(0.0149, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-3.7058e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.857859
Average KL loss: 0.002634
Average total loss: 0.860493
tensor(0.0148, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-2.3086e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.830719
Average KL loss: 0.002599
Average total loss: 0.833318
tensor(0.0146, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-2.2714e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.857503
Average KL loss: 0.002563
Average total loss: 0.860067
tensor(0.0144, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-2.6989e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.838784
Average KL loss: 0.002528
Average total loss: 0.841312
tensor(0.0143, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-3.8756e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.836560
Average KL loss: 0.002492
Average total loss: 0.839052
tensor(0.0141, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-4.8632e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.824192
Average KL loss: 0.002456
Average total loss: 0.826648
tensor(0.0140, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-3.7581e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.866704
Average KL loss: 0.002420
Average total loss: 0.869124
tensor(0.0138, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-4.0869e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.868781
Average KL loss: 0.002384
Average total loss: 0.871164
tensor(0.0136, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-2.3277e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.839947
Average KL loss: 0.002347
Average total loss: 0.842294
tensor(0.0135, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-4.1360e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.820495
Average KL loss: 0.002311
Average total loss: 0.822806
tensor(0.0133, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.8173e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.846025
Average KL loss: 0.002274
Average total loss: 0.848299
tensor(0.0132, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-3.4798e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.815042
Average KL loss: 0.002238
Average total loss: 0.817280
tensor(0.0130, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-2.3213e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.847550
Average KL loss: 0.002202
Average total loss: 0.849752
tensor(0.0128, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-2.7312e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.809195
Average KL loss: 0.002165
Average total loss: 0.811361
tensor(0.0127, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-2.2651e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.825211
Average KL loss: 0.002129
Average total loss: 0.827340
tensor(0.0125, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-2.6940e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.797449
Average KL loss: 0.002093
Average total loss: 0.799543
tensor(0.0124, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-2.4263e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.818590
Average KL loss: 0.002058
Average total loss: 0.820648
tensor(0.0122, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.8145e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.805290
Average KL loss: 0.002022
Average total loss: 0.807312
tensor(0.0121, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-3.3180e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.808841
Average KL loss: 0.001987
Average total loss: 0.810828
tensor(0.0119, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-2.8306e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.797542
Average KL loss: 0.001952
Average total loss: 0.799495
tensor(0.0118, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-2.4075e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.803976
Average KL loss: 0.001918
Average total loss: 0.805894
tensor(0.0116, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-2.3663e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.793002
Average KL loss: 0.001884
Average total loss: 0.794887
tensor(0.0115, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-2.3311e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.840650
Average KL loss: 0.001851
Average total loss: 0.842501
tensor(0.0113, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-4.2638e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.813948
Average KL loss: 0.001818
Average total loss: 0.815765
tensor(0.0112, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-2.7931e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.812363
Average KL loss: 0.001785
Average total loss: 0.814148
tensor(0.0110, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-3.5113e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.810297
Average KL loss: 0.001753
Average total loss: 0.812050
tensor(0.0109, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.9550e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.807568
Average KL loss: 0.001722
Average total loss: 0.809289
tensor(0.0107, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-3.9522e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.798039
Average KL loss: 0.001691
Average total loss: 0.799730
tensor(0.0106, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-9.0611e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.792549
Average KL loss: 0.001661
Average total loss: 0.794210
tensor(0.0104, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-7.7455e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.798774
Average KL loss: 0.001632
Average total loss: 0.800406
tensor(0.0103, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-2.5508e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.775404
Average KL loss: 0.001603
Average total loss: 0.777007
tensor(0.0102, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-5.2580e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.773518
Average KL loss: 0.001575
Average total loss: 0.775094
tensor(0.0100, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-2.6983e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.769249
Average KL loss: 0.001548
Average total loss: 0.770798
tensor(0.0099, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.8512e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.786241
Average KL loss: 0.001522
Average total loss: 0.787763
tensor(0.0098, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.7131e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.778354
Average KL loss: 0.001496
Average total loss: 0.779850
tensor(0.0096, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-3.2245e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.757130
Average KL loss: 0.001471
Average total loss: 0.758601
tensor(0.0095, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-3.3409e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.776336
Average KL loss: 0.001447
Average total loss: 0.777783
tensor(0.0094, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-2.3269e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.785653
Average KL loss: 0.001424
Average total loss: 0.787077
tensor(0.0093, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-4.2301e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.816373
Average KL loss: 0.001402
Average total loss: 0.817775
tensor(0.0091, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-2.9838e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.784266
Average KL loss: 0.001380
Average total loss: 0.785646
tensor(0.0090, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-3.4963e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.803823
Average KL loss: 0.001359
Average total loss: 0.805182
tensor(0.0089, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-2.4769e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.750525
Average KL loss: 0.001339
Average total loss: 0.751864
tensor(0.0088, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-3.2665e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.759473
Average KL loss: 0.001320
Average total loss: 0.760793
tensor(0.0087, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-3.3865e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.754645
Average KL loss: 0.001301
Average total loss: 0.755946
tensor(0.0086, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-1.8119e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.760148
Average KL loss: 0.001283
Average total loss: 0.761431
tensor(0.0085, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.6297e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.767834
Average KL loss: 0.001266
Average total loss: 0.769100
tensor(0.0084, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-3.4182e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.761581
Average KL loss: 0.001250
Average total loss: 0.762831
tensor(0.0083, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-2.4822e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.745981
Average KL loss: 0.001235
Average total loss: 0.747216
tensor(0.0082, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-2.4295e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.756838
Average KL loss: 0.001220
Average total loss: 0.758058
tensor(0.0081, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.3846e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.767257
Average KL loss: 0.001206
Average total loss: 0.768463
tensor(0.0080, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-2.6780e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.754058
Average KL loss: 0.001192
Average total loss: 0.755250
tensor(0.0079, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-2.5080e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.747304
Average KL loss: 0.001179
Average total loss: 0.748483
tensor(0.0078, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-3.5579e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.752033
Average KL loss: 0.001167
Average total loss: 0.753200
tensor(0.0077, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-2.7143e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.731547
Average KL loss: 0.001155
Average total loss: 0.732702
tensor(0.0076, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-3.4139e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.755125
Average KL loss: 0.001144
Average total loss: 0.756269
tensor(0.0075, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-2.8455e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.728373
Average KL loss: 0.001134
Average total loss: 0.729507
tensor(0.0074, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-3.4244e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.778328
Average KL loss: 0.001124
Average total loss: 0.779453
tensor(0.0074, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-2.2164e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.760087
Average KL loss: 0.001115
Average total loss: 0.761202
tensor(0.0073, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-2.4138e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.749248
Average KL loss: 0.001106
Average total loss: 0.750354
tensor(0.0072, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-2.7666e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.734311
Average KL loss: 0.001098
Average total loss: 0.735409
tensor(0.0071, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.8974e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.747264
Average KL loss: 0.001090
Average total loss: 0.748354
tensor(0.0071, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.1388e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.739096
Average KL loss: 0.001082
Average total loss: 0.740178
tensor(0.0070, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.6132e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.750386
Average KL loss: 0.001075
Average total loss: 0.751461
tensor(0.0069, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-7.5144e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.736731
Average KL loss: 0.001068
Average total loss: 0.737799
tensor(0.0069, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-2.2798e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.733157
Average KL loss: 0.001062
Average total loss: 0.734219
tensor(0.0068, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-4.1291e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.725464
Average KL loss: 0.001056
Average total loss: 0.726521
tensor(0.0067, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.1694e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.744397
Average KL loss: 0.001050
Average total loss: 0.745447
tensor(0.0067, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.4324e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.728569
Average KL loss: 0.001045
Average total loss: 0.729614
tensor(0.0066, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.9419e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.730861
Average KL loss: 0.001040
Average total loss: 0.731901
tensor(0.0066, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-2.3025e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.716634
Average KL loss: 0.001035
Average total loss: 0.717669
tensor(0.0065, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-2.0787e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.732878
Average KL loss: 0.001031
Average total loss: 0.733909
tensor(0.0065, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-1.5031e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.732123
Average KL loss: 0.001027
Average total loss: 0.733149
tensor(0.0064, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-2.2094e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.721455
Average KL loss: 0.001023
Average total loss: 0.722478
tensor(0.0064, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.8896e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.708166
Average KL loss: 0.001019
Average total loss: 0.709184
tensor(0.0063, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-2.0557e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.706906
Average KL loss: 0.001015
Average total loss: 0.707922
tensor(0.0063, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-3.4734e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.760238
Average KL loss: 0.001012
Average total loss: 0.761250
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.2734e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.725634
Average KL loss: 0.001009
Average total loss: 0.726643
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.2327e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.734989
Average KL loss: 0.001006
Average total loss: 0.735995
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.9830e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.722633
Average KL loss: 0.001003
Average total loss: 0.723636
tensor(0.0061, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.0755e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.723620
Average KL loss: 0.001000
Average total loss: 0.724620
tensor(0.0061, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.9483e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.734664
Average KL loss: 0.000998
Average total loss: 0.735662
tensor(0.0061, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.0258e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.730217
Average KL loss: 0.000995
Average total loss: 0.731212
tensor(0.0060, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-3.0111e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.732871
Average KL loss: 0.000993
Average total loss: 0.733863
tensor(0.0060, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.8447e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.726553
Average KL loss: 0.000991
Average total loss: 0.727543
tensor(0.0060, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.6467e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.694544
Average KL loss: 0.000988
Average total loss: 0.695532
tensor(0.0059, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-3.5077e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.732997
Average KL loss: 0.000986
Average total loss: 0.733984
tensor(0.0059, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-2.2685e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.736762
Average KL loss: 0.000984
Average total loss: 0.737746
tensor(0.0059, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-2.1161e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.715652
Average KL loss: 0.000983
Average total loss: 0.716635
tensor(0.0059, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-2.0696e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.720091
Average KL loss: 0.000981
Average total loss: 0.721071
tensor(0.0058, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-1.7364e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.712616
Average KL loss: 0.000979
Average total loss: 0.713595
tensor(0.0058, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-1.9786e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.745501
Average KL loss: 0.000977
Average total loss: 0.746478
tensor(0.0058, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-3.0283e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.708674
Average KL loss: 0.000976
Average total loss: 0.709649
tensor(0.0058, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.5817e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.713132
Average KL loss: 0.000974
Average total loss: 0.714106
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.5677e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.735890
Average KL loss: 0.000973
Average total loss: 0.736863
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.3115e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.698424
Average KL loss: 0.000971
Average total loss: 0.699395
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.5767e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.700546
Average KL loss: 0.000970
Average total loss: 0.701516
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.0442e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.683654
Average KL loss: 0.000969
Average total loss: 0.684623
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.1767e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.719451
Average KL loss: 0.000969
Average total loss: 0.720420
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.0429e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.708268
Average KL loss: 0.000969
Average total loss: 0.709238
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.4445e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.704333
Average KL loss: 0.000969
Average total loss: 0.705302
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.4078e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.697222
Average KL loss: 0.000969
Average total loss: 0.698191
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.6261e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.712147
Average KL loss: 0.000969
Average total loss: 0.713116
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.8566e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.700834
Average KL loss: 0.000969
Average total loss: 0.701803
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.8403e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.701585
Average KL loss: 0.000968
Average total loss: 0.702554
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.6079e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.697883
Average KL loss: 0.000968
Average total loss: 0.698851
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-5.9618e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.691391
Average KL loss: 0.000968
Average total loss: 0.692359
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.0954e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.716675
Average KL loss: 0.000968
Average total loss: 0.717643
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.0995e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.695027
Average KL loss: 0.000968
Average total loss: 0.695994
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.3220e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.715648
Average KL loss: 0.000968
Average total loss: 0.716616
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.4101e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.708356
Average KL loss: 0.000968
Average total loss: 0.709324
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.2329e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.710688
Average KL loss: 0.000968
Average total loss: 0.711656
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.0829e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.694370
Average KL loss: 0.000968
Average total loss: 0.695338
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.4464e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.696946
Average KL loss: 0.000968
Average total loss: 0.697914
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.1459e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.708555
Average KL loss: 0.000968
Average total loss: 0.709523
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.2312e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.705402
Average KL loss: 0.000968
Average total loss: 0.706370
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.8986e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.693892
Average KL loss: 0.000968
Average total loss: 0.694860
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.6724e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.696409
Average KL loss: 0.000968
Average total loss: 0.697377
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.9462e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.709869
Average KL loss: 0.000968
Average total loss: 0.710836
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.9876e-08, device='cuda:0')
 Percentile value: 4.208246278762817
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/8]: ---
conv1.weight         | nonzeros =      56 /    1728             (  3.24%) | total_pruned =    1672 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      13 /   36864             (  0.04%) | total_pruned =   36851 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      41 /   36864             (  0.11%) | total_pruned =   36823 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      78 /   36864             (  0.21%) | total_pruned =   36786 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      85 /   36864             (  0.23%) | total_pruned =   36779 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     114 /   73728             (  0.15%) | total_pruned =   73614 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     152 /  147456             (  0.10%) | total_pruned =  147304 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      72 /    8192             (  0.88%) | total_pruned =    8120 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     139 /  147456             (  0.09%) | total_pruned =  147317 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     133 /  147456             (  0.09%) | total_pruned =  147323 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     274 /  294912             (  0.09%) | total_pruned =  294638 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     236 /  589824             (  0.04%) | total_pruned =  589588 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     184 /     256             ( 71.88%) | total_pruned =      72 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      66 /   32768             (  0.20%) | total_pruned =   32702 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     162 /  589824             (  0.03%) | total_pruned =  589662 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     144 /  589824             (  0.02%) | total_pruned =  589680 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     183 / 1179648             (  0.02%) | total_pruned = 1179465 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     153 /     512             ( 29.88%) | total_pruned =     359 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     452 / 2359296             (  0.02%) | total_pruned = 2358844 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     157 /     512             ( 30.66%) | total_pruned =     355 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     100 /  131072             (  0.08%) | total_pruned =  130972 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     595 / 2359296             (  0.03%) | total_pruned = 2358701 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     140 /     512             ( 27.34%) | total_pruned =     372 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2318 / 2359296             (  0.10%) | total_pruned = 2356978 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      97 /     512             ( 18.95%) | total_pruned =     415 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      60 /     512             ( 11.72%) | total_pruned =     452 | shape = torch.Size([512])
linear.weight        | nonzeros =     857 /    5120             ( 16.74%) | total_pruned =    4263 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 99/100 Loss: 1.056749 Accuracy: 56.02 56.97 % Best test Accuracy: 56.21%
tensor(0.0057, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.9517e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.391319
Average KL loss: 0.000964
Average total loss: 1.392283
tensor(0.0056, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.6436e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.392522
Average KL loss: 0.000957
Average total loss: 1.393478
tensor(0.0055, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.0948e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.384837
Average KL loss: 0.000949
Average total loss: 1.385786
tensor(0.0055, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.6080e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.375787
Average KL loss: 0.000942
Average total loss: 1.376729
tensor(0.0054, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-1.2570e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.379164
Average KL loss: 0.000934
Average total loss: 1.380098
tensor(0.0054, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-1.2183e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.391087
Average KL loss: 0.000926
Average total loss: 1.392014
tensor(0.0053, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.9359e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.376610
Average KL loss: 0.000919
Average total loss: 1.377528
tensor(0.0053, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-3.5536e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.398085
Average KL loss: 0.000911
Average total loss: 1.398996
tensor(0.0052, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-2.0533e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.370714
Average KL loss: 0.000903
Average total loss: 1.371617
tensor(0.0052, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.3563e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.364712
Average KL loss: 0.000895
Average total loss: 1.365606
tensor(0.0051, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-8.4739e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.375272
Average KL loss: 0.000886
Average total loss: 1.376159
tensor(0.0051, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-4.5880e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.370529
Average KL loss: 0.000878
Average total loss: 1.371407
tensor(0.0050, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-1.3639e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.363398
Average KL loss: 0.000869
Average total loss: 1.364267
tensor(0.0050, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-9.7913e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.390918
Average KL loss: 0.000861
Average total loss: 1.391779
tensor(0.0049, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.6274e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.384664
Average KL loss: 0.000852
Average total loss: 1.385516
tensor(0.0049, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-8.9612e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.371257
Average KL loss: 0.000843
Average total loss: 1.372100
tensor(0.0048, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-8.0013e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.375475
Average KL loss: 0.000834
Average total loss: 1.376310
tensor(0.0048, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.4181e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.351111
Average KL loss: 0.000825
Average total loss: 1.351936
tensor(0.0047, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.0114e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.389442
Average KL loss: 0.000816
Average total loss: 1.390258
tensor(0.0047, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9239e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.372905
Average KL loss: 0.000807
Average total loss: 1.373711
tensor(0.0046, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-8.8551e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.376940
Average KL loss: 0.000797
Average total loss: 1.377737
tensor(0.0046, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.0895e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.384088
Average KL loss: 0.000787
Average total loss: 1.384875
tensor(0.0045, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.1666e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.368199
Average KL loss: 0.000778
Average total loss: 1.368977
tensor(0.0045, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-7.9745e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.362726
Average KL loss: 0.000768
Average total loss: 1.363494
tensor(0.0044, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-7.7376e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.371812
Average KL loss: 0.000758
Average total loss: 1.372570
tensor(0.0044, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.3103e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.356399
Average KL loss: 0.000748
Average total loss: 1.357147
tensor(0.0043, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.7702e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.372897
Average KL loss: 0.000738
Average total loss: 1.373635
tensor(0.0043, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.9127e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.350700
Average KL loss: 0.000728
Average total loss: 1.351428
tensor(0.0042, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0147e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.354706
Average KL loss: 0.000718
Average total loss: 1.355423
tensor(0.0042, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.5975e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.372841
Average KL loss: 0.000708
Average total loss: 1.373549
tensor(0.0041, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-9.4349e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.354555
Average KL loss: 0.000697
Average total loss: 1.355253
tensor(0.0041, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.1311e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.355850
Average KL loss: 0.000687
Average total loss: 1.356537
tensor(0.0040, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.4277e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.345119
Average KL loss: 0.000677
Average total loss: 1.345795
tensor(0.0040, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-5.7180e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.355151
Average KL loss: 0.000666
Average total loss: 1.355817
tensor(0.0039, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.1455e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.356105
Average KL loss: 0.000656
Average total loss: 1.356761
tensor(0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.9027e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.347918
Average KL loss: 0.000645
Average total loss: 1.348563
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.0322e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.347072
Average KL loss: 0.000635
Average total loss: 1.347708
tensor(0.0038, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.1548e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.397598
Average KL loss: 0.000625
Average total loss: 1.398223
tensor(0.0038, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-9.2453e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.379748
Average KL loss: 0.000614
Average total loss: 1.380363
tensor(0.0037, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.5913e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.367575
Average KL loss: 0.000604
Average total loss: 1.368179
tensor(0.0037, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-6.4747e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.353950
Average KL loss: 0.000594
Average total loss: 1.354543
tensor(0.0036, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.0539e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.345022
Average KL loss: 0.000584
Average total loss: 1.345606
tensor(0.0036, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.7938e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.375696
Average KL loss: 0.000574
Average total loss: 1.376269
tensor(0.0035, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.9423e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.386954
Average KL loss: 0.000564
Average total loss: 1.387518
tensor(0.0035, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-9.5507e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.366193
Average KL loss: 0.000554
Average total loss: 1.366747
tensor(0.0034, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-7.3674e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.345950
Average KL loss: 0.000544
Average total loss: 1.346494
tensor(0.0034, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.4697e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.365230
Average KL loss: 0.000534
Average total loss: 1.365764
tensor(0.0034, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.9423e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.359086
Average KL loss: 0.000525
Average total loss: 1.359610
tensor(0.0033, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-7.0644e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.349409
Average KL loss: 0.000515
Average total loss: 1.349924
tensor(0.0033, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-6.5240e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.370408
Average KL loss: 0.000506
Average total loss: 1.370914
tensor(0.0032, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.5926e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.352633
Average KL loss: 0.000497
Average total loss: 1.353130
tensor(0.0032, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-7.7542e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.342855
Average KL loss: 0.000488
Average total loss: 1.343343
tensor(0.0031, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.0625e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.348877
Average KL loss: 0.000479
Average total loss: 1.349356
tensor(0.0031, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.3065e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.362171
Average KL loss: 0.000470
Average total loss: 1.362642
tensor(0.0031, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.6577e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.339227
Average KL loss: 0.000462
Average total loss: 1.339689
tensor(0.0030, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-9.2779e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.353352
Average KL loss: 0.000454
Average total loss: 1.353806
tensor(0.0030, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.6607e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.347556
Average KL loss: 0.000446
Average total loss: 1.348002
tensor(0.0029, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.0154e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.350575
Average KL loss: 0.000438
Average total loss: 1.351013
tensor(0.0029, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.2926e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.333794
Average KL loss: 0.000430
Average total loss: 1.334224
tensor(0.0029, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8393e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.326463
Average KL loss: 0.000423
Average total loss: 1.326886
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.8424e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.357329
Average KL loss: 0.000416
Average total loss: 1.357745
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.6690e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.352377
Average KL loss: 0.000409
Average total loss: 1.352786
tensor(0.0027, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.7581e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.337222
Average KL loss: 0.000402
Average total loss: 1.337624
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.9892e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.343154
Average KL loss: 0.000395
Average total loss: 1.343549
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.5921e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.340331
Average KL loss: 0.000389
Average total loss: 1.340720
tensor(0.0026, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.2446e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.354637
Average KL loss: 0.000383
Average total loss: 1.355020
tensor(0.0026, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.9715e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.357881
Average KL loss: 0.000377
Average total loss: 1.358258
tensor(0.0026, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3598e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.345503
Average KL loss: 0.000371
Average total loss: 1.345875
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4072e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.328143
Average KL loss: 0.000366
Average total loss: 1.328509
tensor(0.0025, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.9072e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.347087
Average KL loss: 0.000360
Average total loss: 1.347447
tensor(0.0025, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.2610e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.357604
Average KL loss: 0.000355
Average total loss: 1.357959
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.7334e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.349837
Average KL loss: 0.000352
Average total loss: 1.350189
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.2984e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.346394
Average KL loss: 0.000352
Average total loss: 1.346745
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.1298e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.332238
Average KL loss: 0.000351
Average total loss: 1.332590
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.3304e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.318832
Average KL loss: 0.000351
Average total loss: 1.319183
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.1047e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.350965
Average KL loss: 0.000350
Average total loss: 1.351315
tensor(0.0024, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.4351e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.354365
Average KL loss: 0.000350
Average total loss: 1.354715
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.1564e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.358897
Average KL loss: 0.000349
Average total loss: 1.359247
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.4945e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.332780
Average KL loss: 0.000349
Average total loss: 1.333129
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.2138e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.324062
Average KL loss: 0.000348
Average total loss: 1.324411
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.7089e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.333500
Average KL loss: 0.000348
Average total loss: 1.333848
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.0516e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.324223
Average KL loss: 0.000348
Average total loss: 1.324571
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.8390e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.350218
Average KL loss: 0.000347
Average total loss: 1.350565
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.2150e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.329477
Average KL loss: 0.000347
Average total loss: 1.329824
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.1197e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.333191
Average KL loss: 0.000346
Average total loss: 1.333537
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.8104e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.341621
Average KL loss: 0.000346
Average total loss: 1.341967
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.4066e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.374959
Average KL loss: 0.000345
Average total loss: 1.375304
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.3814e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.358155
Average KL loss: 0.000345
Average total loss: 1.358500
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.7843e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.347019
Average KL loss: 0.000345
Average total loss: 1.347365
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.8899e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.338192
Average KL loss: 0.000345
Average total loss: 1.338537
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.0002e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.363699
Average KL loss: 0.000345
Average total loss: 1.364044
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.5651e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.344981
Average KL loss: 0.000345
Average total loss: 1.345326
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.0138e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.346346
Average KL loss: 0.000345
Average total loss: 1.346691
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.0483e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.353150
Average KL loss: 0.000345
Average total loss: 1.353495
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.6712e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.361925
Average KL loss: 0.000345
Average total loss: 1.362270
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.7629e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.331205
Average KL loss: 0.000345
Average total loss: 1.331550
tensor(0.0024, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.0200e-09, device='cuda:0')
 Percentile value: 4.79100923538208
Non-zero model percentage: 0.02187183126807213%, Non-zero mask percentage: 0.02187183126807213%

--- Pruning Level [7/8]: ---
conv1.weight         | nonzeros =      43 /    1728             (  2.49%) | total_pruned =    1685 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       5 /   36864             (  0.01%) | total_pruned =   36859 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       9 /   36864             (  0.02%) | total_pruned =   36855 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       8 /   36864             (  0.02%) | total_pruned =   36856 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       6 /   36864             (  0.02%) | total_pruned =   36858 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       2 /   73728             (  0.00%) | total_pruned =   73726 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =      10 /  147456             (  0.01%) | total_pruned =  147446 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      16 /    8192             (  0.20%) | total_pruned =    8176 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       6 /  147456             (  0.00%) | total_pruned =  147450 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =      10 /  147456             (  0.01%) | total_pruned =  147446 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =      10 /  294912             (  0.00%) | total_pruned =  294902 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     115 /     256             ( 44.92%) | total_pruned =     141 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       6 /  589824             (  0.00%) | total_pruned =  589818 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       5 /   32768             (  0.02%) | total_pruned =   32763 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       3 /  589824             (  0.00%) | total_pruned =  589821 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       7 /  589824             (  0.00%) | total_pruned =  589817 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =      14 / 1179648             (  0.00%) | total_pruned = 1179634 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     114 / 2359296             (  0.00%) | total_pruned = 2359182 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      38 /     512             (  7.42%) | total_pruned =     474 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      32 /  131072             (  0.02%) | total_pruned =  131040 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      38 /     512             (  7.42%) | total_pruned =     474 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      66 / 2359296             (  0.00%) | total_pruned = 2359230 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     126 /     512             ( 24.61%) | total_pruned =     386 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     519 / 2359296             (  0.02%) | total_pruned = 2358777 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      66 /     512             ( 12.89%) | total_pruned =     446 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      37 /     512             (  7.23%) | total_pruned =     475 | shape = torch.Size([512])
linear.weight        | nonzeros =     498 /    5120             (  9.73%) | total_pruned =    4622 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 2445, pruned : 11176317, total: 11178762, Compression rate :    4572.09x  ( 99.98% pruned)
Train Epoch: 99/100 Loss: 1.765287 Accuracy: 31.72 31.52 % Best test Accuracy: 31.97%
