Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2560e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302421
Average KL loss: 0.000030
Average total loss: 2.302451
tensor(0.0007, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-8.2324e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.297203
Average KL loss: 0.000167
Average total loss: 2.297370
tensor(0.0035, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.8850e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.143323
Average KL loss: 0.001181
Average total loss: 2.144504
tensor(0.0213, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-8.3641e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.579244
Average KL loss: 0.004773
Average total loss: 1.584018
tensor(0.0506, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-1.3324e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.156164
Average KL loss: 0.008383
Average total loss: 1.164547
tensor(0.0693, device='cuda:0') tensor(0.0680, device='cuda:0') tensor(-9.3565e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.896000
Average KL loss: 0.010911
Average total loss: 0.906911
tensor(0.0809, device='cuda:0') tensor(0.0820, device='cuda:0') tensor(-7.6923e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.755201
Average KL loss: 0.012547
Average total loss: 0.767747
tensor(0.0882, device='cuda:0') tensor(0.0909, device='cuda:0') tensor(-6.2198e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.654762
Average KL loss: 0.013609
Average total loss: 0.668371
tensor(0.0935, device='cuda:0') tensor(0.0973, device='cuda:0') tensor(-4.2866e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.579746
Average KL loss: 0.014363
Average total loss: 0.594109
tensor(0.0972, device='cuda:0') tensor(0.1018, device='cuda:0') tensor(-4.6336e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.529098
Average KL loss: 0.014904
Average total loss: 0.544002
tensor(0.1002, device='cuda:0') tensor(0.1055, device='cuda:0') tensor(-4.1520e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.492237
Average KL loss: 0.015383
Average total loss: 0.507620
tensor(0.1030, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-4.3237e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.463605
Average KL loss: 0.015832
Average total loss: 0.479437
tensor(0.1050, device='cuda:0') tensor(0.1125, device='cuda:0') tensor(-3.0381e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.430374
Average KL loss: 0.016240
Average total loss: 0.446614
tensor(0.1071, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-3.9063e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.390284
Average KL loss: 0.016581
Average total loss: 0.406864
tensor(0.1086, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-5.2340e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.368797
Average KL loss: 0.016881
Average total loss: 0.385678
tensor(0.1101, device='cuda:0') tensor(0.1205, device='cuda:0') tensor(-4.0495e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.345256
Average KL loss: 0.017177
Average total loss: 0.362433
tensor(0.1113, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(-2.9872e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.326996
Average KL loss: 0.017462
Average total loss: 0.344458
tensor(0.1128, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-4.1281e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.305700
Average KL loss: 0.017740
Average total loss: 0.323440
tensor(0.1138, device='cuda:0') tensor(0.1277, device='cuda:0') tensor(-2.8233e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.290583
Average KL loss: 0.018007
Average total loss: 0.308591
tensor(0.1150, device='cuda:0') tensor(0.1301, device='cuda:0') tensor(-2.5681e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.275988
Average KL loss: 0.018263
Average total loss: 0.294252
tensor(0.1160, device='cuda:0') tensor(0.1322, device='cuda:0') tensor(-2.7757e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.264859
Average KL loss: 0.018515
Average total loss: 0.283375
tensor(0.1168, device='cuda:0') tensor(0.1345, device='cuda:0') tensor(-2.5192e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.248978
Average KL loss: 0.018768
Average total loss: 0.267746
tensor(0.1178, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(-2.3692e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.240694
Average KL loss: 0.019014
Average total loss: 0.259708
tensor(0.1185, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-2.4852e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.227421
Average KL loss: 0.019258
Average total loss: 0.246679
tensor(0.1192, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(-2.3178e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.222810
Average KL loss: 0.019469
Average total loss: 0.242280
tensor(0.1198, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-2.1148e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.209409
Average KL loss: 0.019698
Average total loss: 0.229107
tensor(0.1206, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(-2.5552e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.202060
Average KL loss: 0.019898
Average total loss: 0.221958
tensor(0.1211, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(-1.8906e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.196103
Average KL loss: 0.020101
Average total loss: 0.216205
tensor(0.1216, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(-1.7847e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.182052
Average KL loss: 0.020287
Average total loss: 0.202339
tensor(0.1220, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(-1.9692e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.181550
Average KL loss: 0.020457
Average total loss: 0.202008
tensor(0.1225, device='cuda:0') tensor(0.1528, device='cuda:0') tensor(-1.7478e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.171331
Average KL loss: 0.020629
Average total loss: 0.191960
tensor(0.1230, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(-1.5077e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.162731
Average KL loss: 0.020784
Average total loss: 0.183515
tensor(0.1233, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(-1.4295e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.161432
Average KL loss: 0.020925
Average total loss: 0.182357
tensor(0.1236, device='cuda:0') tensor(0.1576, device='cuda:0') tensor(-1.5592e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.158957
Average KL loss: 0.021090
Average total loss: 0.180046
tensor(0.1240, device='cuda:0') tensor(0.1594, device='cuda:0') tensor(-1.7454e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.148707
Average KL loss: 0.021236
Average total loss: 0.169943
tensor(0.1242, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-1.5034e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.147180
Average KL loss: 0.021360
Average total loss: 0.168540
tensor(0.1243, device='cuda:0') tensor(0.1623, device='cuda:0') tensor(-1.6173e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.137722
Average KL loss: 0.021486
Average total loss: 0.159208
tensor(0.1246, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(-1.2932e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.134117
Average KL loss: 0.021598
Average total loss: 0.155715
tensor(0.1247, device='cuda:0') tensor(0.1649, device='cuda:0') tensor(-1.5123e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.129823
Average KL loss: 0.021698
Average total loss: 0.151521
tensor(0.1248, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-1.2915e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.129326
Average KL loss: 0.021806
Average total loss: 0.151133
tensor(0.1251, device='cuda:0') tensor(0.1675, device='cuda:0') tensor(-1.2426e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.121782
Average KL loss: 0.021907
Average total loss: 0.143689
tensor(0.1251, device='cuda:0') tensor(0.1686, device='cuda:0') tensor(-1.1998e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.120048
Average KL loss: 0.022003
Average total loss: 0.142051
tensor(0.1253, device='cuda:0') tensor(0.1699, device='cuda:0') tensor(-1.1957e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.114585
Average KL loss: 0.022083
Average total loss: 0.136668
tensor(0.1253, device='cuda:0') tensor(0.1708, device='cuda:0') tensor(-1.1209e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.113822
Average KL loss: 0.022174
Average total loss: 0.135996
tensor(0.1255, device='cuda:0') tensor(0.1720, device='cuda:0') tensor(-1.1891e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.108297
Average KL loss: 0.022250
Average total loss: 0.130547
tensor(0.1254, device='cuda:0') tensor(0.1730, device='cuda:0') tensor(-1.0203e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.105496
Average KL loss: 0.022307
Average total loss: 0.127803
tensor(0.1254, device='cuda:0') tensor(0.1740, device='cuda:0') tensor(-8.0844e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.103948
Average KL loss: 0.022371
Average total loss: 0.126319
tensor(0.1254, device='cuda:0') tensor(0.1750, device='cuda:0') tensor(-1.0046e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.099396
Average KL loss: 0.022439
Average total loss: 0.121834
tensor(0.1254, device='cuda:0') tensor(0.1758, device='cuda:0') tensor(-1.0772e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.101471
Average KL loss: 0.022499
Average total loss: 0.123970
tensor(0.1255, device='cuda:0') tensor(0.1768, device='cuda:0') tensor(-1.1110e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.093330
Average KL loss: 0.022548
Average total loss: 0.115877
tensor(0.1253, device='cuda:0') tensor(0.1775, device='cuda:0') tensor(-9.8423e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.095483
Average KL loss: 0.022575
Average total loss: 0.118058
tensor(0.1252, device='cuda:0') tensor(0.1782, device='cuda:0') tensor(-7.7177e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.091381
Average KL loss: 0.022627
Average total loss: 0.114007
tensor(0.1253, device='cuda:0') tensor(0.1791, device='cuda:0') tensor(-9.2378e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.090271
Average KL loss: 0.022669
Average total loss: 0.112940
tensor(0.1251, device='cuda:0') tensor(0.1799, device='cuda:0') tensor(-7.0178e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.087598
Average KL loss: 0.022710
Average total loss: 0.110308
tensor(0.1251, device='cuda:0') tensor(0.1806, device='cuda:0') tensor(-6.4814e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.083174
Average KL loss: 0.022731
Average total loss: 0.105906
tensor(0.1249, device='cuda:0') tensor(0.1811, device='cuda:0') tensor(-7.2284e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.083076
Average KL loss: 0.022752
Average total loss: 0.105828
tensor(0.1249, device='cuda:0') tensor(0.1818, device='cuda:0') tensor(-1.0395e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.081693
Average KL loss: 0.022780
Average total loss: 0.104473
tensor(0.1247, device='cuda:0') tensor(0.1824, device='cuda:0') tensor(-8.2467e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.078493
Average KL loss: 0.022798
Average total loss: 0.101291
tensor(0.1246, device='cuda:0') tensor(0.1830, device='cuda:0') tensor(-5.8192e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.076347
Average KL loss: 0.022814
Average total loss: 0.099161
tensor(0.1245, device='cuda:0') tensor(0.1835, device='cuda:0') tensor(-6.0368e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.077642
Average KL loss: 0.022823
Average total loss: 0.100464
tensor(0.1243, device='cuda:0') tensor(0.1841, device='cuda:0') tensor(-6.6384e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.074115
Average KL loss: 0.022846
Average total loss: 0.096961
tensor(0.1242, device='cuda:0') tensor(0.1846, device='cuda:0') tensor(-6.5722e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.073233
Average KL loss: 0.022854
Average total loss: 0.096087
tensor(0.1240, device='cuda:0') tensor(0.1851, device='cuda:0') tensor(-6.3970e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.070640
Average KL loss: 0.022854
Average total loss: 0.093494
tensor(0.1238, device='cuda:0') tensor(0.1854, device='cuda:0') tensor(-5.0423e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.068869
Average KL loss: 0.022848
Average total loss: 0.091717
tensor(0.1236, device='cuda:0') tensor(0.1859, device='cuda:0') tensor(-6.2936e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.068955
Average KL loss: 0.022850
Average total loss: 0.091805
tensor(0.1235, device='cuda:0') tensor(0.1863, device='cuda:0') tensor(-7.6254e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.066335
Average KL loss: 0.022848
Average total loss: 0.089183
tensor(0.1232, device='cuda:0') tensor(0.1866, device='cuda:0') tensor(-5.3634e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.063863
Average KL loss: 0.022814
Average total loss: 0.086677
tensor(0.1230, device='cuda:0') tensor(0.1866, device='cuda:0') tensor(-5.8858e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.064912
Average KL loss: 0.022788
Average total loss: 0.087700
tensor(0.1228, device='cuda:0') tensor(0.1870, device='cuda:0') tensor(-5.7582e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.063550
Average KL loss: 0.022785
Average total loss: 0.086334
tensor(0.1226, device='cuda:0') tensor(0.1873, device='cuda:0') tensor(-6.0389e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.062659
Average KL loss: 0.022778
Average total loss: 0.085436
tensor(0.1224, device='cuda:0') tensor(0.1877, device='cuda:0') tensor(-4.8723e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.061156
Average KL loss: 0.022763
Average total loss: 0.083919
tensor(0.1223, device='cuda:0') tensor(0.1880, device='cuda:0') tensor(-3.1509e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.061508
Average KL loss: 0.022760
Average total loss: 0.084268
tensor(0.1222, device='cuda:0') tensor(0.1884, device='cuda:0') tensor(-5.4749e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.061494
Average KL loss: 0.022763
Average total loss: 0.084257
tensor(0.1220, device='cuda:0') tensor(0.1887, device='cuda:0') tensor(-4.4355e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.058548
Average KL loss: 0.022759
Average total loss: 0.081307
tensor(0.1218, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-5.5459e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.056393
Average KL loss: 0.022735
Average total loss: 0.079128
tensor(0.1216, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-5.3413e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.056403
Average KL loss: 0.022697
Average total loss: 0.079100
tensor(0.1214, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(-3.6442e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.054392
Average KL loss: 0.022673
Average total loss: 0.077065
tensor(0.1211, device='cuda:0') tensor(0.1894, device='cuda:0') tensor(-4.5074e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.055205
Average KL loss: 0.022638
Average total loss: 0.077843
tensor(0.1209, device='cuda:0') tensor(0.1896, device='cuda:0') tensor(-3.4333e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.054357
Average KL loss: 0.022622
Average total loss: 0.076979
tensor(0.1207, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-2.8994e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.052594
Average KL loss: 0.022593
Average total loss: 0.075186
tensor(0.1205, device='cuda:0') tensor(0.1899, device='cuda:0') tensor(-3.6429e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.050563
Average KL loss: 0.022552
Average total loss: 0.073115
tensor(0.1202, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-5.0549e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.052915
Average KL loss: 0.022506
Average total loss: 0.075420
tensor(0.1199, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(-3.9820e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.051566
Average KL loss: 0.022482
Average total loss: 0.074049
tensor(0.1197, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-3.1951e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.049338
Average KL loss: 0.022449
Average total loss: 0.071788
tensor(0.1195, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-1.9735e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.049604
Average KL loss: 0.022412
Average total loss: 0.072016
tensor(0.1193, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-3.7549e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.049272
Average KL loss: 0.022380
Average total loss: 0.071653
tensor(0.1191, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-2.8531e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.046556
Average KL loss: 0.022341
Average total loss: 0.068897
tensor(0.1189, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-3.8220e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.047070
Average KL loss: 0.022293
Average total loss: 0.069362
tensor(0.1187, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-3.1298e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.046384
Average KL loss: 0.022254
Average total loss: 0.068637
tensor(0.1184, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-2.9169e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.045461
Average KL loss: 0.022206
Average total loss: 0.067667
tensor(0.1181, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-3.6373e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.046633
Average KL loss: 0.022176
Average total loss: 0.068809
tensor(0.1180, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-3.6865e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.044850
Average KL loss: 0.022142
Average total loss: 0.066991
tensor(0.1177, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-1.8121e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.044776
Average KL loss: 0.022086
Average total loss: 0.066862
tensor(0.1174, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-3.1587e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.044511
Average KL loss: 0.022056
Average total loss: 0.066567
tensor(0.1171, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-2.6744e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.043611
Average KL loss: 0.022025
Average total loss: 0.065636
tensor(0.1169, device='cuda:0') tensor(0.1906, device='cuda:0') tensor(-2.3424e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.042050
Average KL loss: 0.021981
Average total loss: 0.064031
tensor(0.1167, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-1.8830e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.042743
Average KL loss: 0.021917
Average total loss: 0.064660
tensor(0.1164, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-2.1468e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.041863
Average KL loss: 0.021875
Average total loss: 0.063737
tensor(0.1162, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-3.7653e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.041563
Average KL loss: 0.021834
Average total loss: 0.063397
tensor(0.1160, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-1.9447e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.040785
Average KL loss: 0.021782
Average total loss: 0.062567
tensor(0.1156, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-1.9293e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.040299
Average KL loss: 0.021723
Average total loss: 0.062022
tensor(0.1154, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(-1.8969e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.040081
Average KL loss: 0.021677
Average total loss: 0.061758
tensor(0.1152, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(-3.6100e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.040266
Average KL loss: 0.021633
Average total loss: 0.061899
tensor(0.1149, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(-1.8022e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.039340
Average KL loss: 0.021601
Average total loss: 0.060941
tensor(0.1148, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(-1.5315e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.037463
Average KL loss: 0.021542
Average total loss: 0.059005
tensor(0.1145, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-2.0150e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.038153
Average KL loss: 0.021469
Average total loss: 0.059622
tensor(0.1142, device='cuda:0') tensor(0.1896, device='cuda:0') tensor(-2.1646e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.037825
Average KL loss: 0.021410
Average total loss: 0.059234
tensor(0.1139, device='cuda:0') tensor(0.1894, device='cuda:0') tensor(-3.1083e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.037690
Average KL loss: 0.021353
Average total loss: 0.059043
tensor(0.1136, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(-9.8956e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.036979
Average KL loss: 0.021308
Average total loss: 0.058287
tensor(0.1134, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(-1.6127e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.037300
Average KL loss: 0.021250
Average total loss: 0.058550
tensor(0.1131, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-2.7978e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.036292
Average KL loss: 0.021196
Average total loss: 0.057489
tensor(0.1128, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-1.1382e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.036027
Average KL loss: 0.021143
Average total loss: 0.057170
tensor(0.1126, device='cuda:0') tensor(0.1888, device='cuda:0') tensor(-2.3930e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.035866
Average KL loss: 0.021097
Average total loss: 0.056963
tensor(0.1124, device='cuda:0') tensor(0.1888, device='cuda:0') tensor(-1.8818e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.035462
Average KL loss: 0.021044
Average total loss: 0.056506
tensor(0.1121, device='cuda:0') tensor(0.1886, device='cuda:0') tensor(-1.1580e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.034803
Average KL loss: 0.020977
Average total loss: 0.055780
tensor(0.1118, device='cuda:0') tensor(0.1884, device='cuda:0') tensor(-9.1823e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.035292
Average KL loss: 0.020927
Average total loss: 0.056219
tensor(0.1116, device='cuda:0') tensor(0.1884, device='cuda:0') tensor(-1.8799e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.034874
Average KL loss: 0.020888
Average total loss: 0.055762
tensor(0.1114, device='cuda:0') tensor(0.1883, device='cuda:0') tensor(-1.7716e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.034520
Average KL loss: 0.020850
Average total loss: 0.055371
tensor(0.1112, device='cuda:0') tensor(0.1883, device='cuda:0') tensor(-1.7095e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.033540
Average KL loss: 0.020798
Average total loss: 0.054338
tensor(0.1110, device='cuda:0') tensor(0.1881, device='cuda:0') tensor(-1.6787e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.033798
Average KL loss: 0.020735
Average total loss: 0.054533
tensor(0.1108, device='cuda:0') tensor(0.1879, device='cuda:0') tensor(-1.5712e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.034271
Average KL loss: 0.020694
Average total loss: 0.054965
tensor(0.1106, device='cuda:0') tensor(0.1880, device='cuda:0') tensor(-2.2779e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.034005
Average KL loss: 0.020667
Average total loss: 0.054672
tensor(0.1105, device='cuda:0') tensor(0.1881, device='cuda:0') tensor(-2.2004e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.033066
Average KL loss: 0.020630
Average total loss: 0.053696
tensor(0.1102, device='cuda:0') tensor(0.1880, device='cuda:0') tensor(-1.2198e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.032588
Average KL loss: 0.020577
Average total loss: 0.053165
tensor(0.1100, device='cuda:0') tensor(0.1878, device='cuda:0') tensor(-8.5414e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.032569
Average KL loss: 0.020514
Average total loss: 0.053083
tensor(0.1097, device='cuda:0') tensor(0.1876, device='cuda:0') tensor(-2.0806e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.032179
Average KL loss: 0.020470
Average total loss: 0.052649
tensor(0.1095, device='cuda:0') tensor(0.1876, device='cuda:0') tensor(-1.1018e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.032881
Average KL loss: 0.020418
Average total loss: 0.053298
tensor(0.1092, device='cuda:0') tensor(0.1875, device='cuda:0') tensor(-1.1100e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.031991
Average KL loss: 0.020386
Average total loss: 0.052376
tensor(0.1090, device='cuda:0') tensor(0.1875, device='cuda:0') tensor(-4.9060e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.031572
Average KL loss: 0.020335
Average total loss: 0.051906
tensor(0.1088, device='cuda:0') tensor(0.1874, device='cuda:0') tensor(-1.2307e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.030571
Average KL loss: 0.020276
Average total loss: 0.050847
tensor(0.1085, device='cuda:0') tensor(0.1871, device='cuda:0') tensor(-9.1474e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.031110
Average KL loss: 0.020205
Average total loss: 0.051315
tensor(0.1081, device='cuda:0') tensor(0.1869, device='cuda:0') tensor(-1.4495e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.031097
Average KL loss: 0.020158
Average total loss: 0.051254
tensor(0.1080, device='cuda:0') tensor(0.1869, device='cuda:0') tensor(-1.6189e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.031276
Average KL loss: 0.020123
Average total loss: 0.051400
tensor(0.1078, device='cuda:0') tensor(0.1869, device='cuda:0') tensor(-1.8843e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.030551
Average KL loss: 0.020077
Average total loss: 0.050628
tensor(0.1076, device='cuda:0') tensor(0.1867, device='cuda:0') tensor(-1.2001e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.030673
Average KL loss: 0.020035
Average total loss: 0.050708
tensor(0.1075, device='cuda:0') tensor(0.1867, device='cuda:0') tensor(-1.1732e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.029877
Average KL loss: 0.019993
Average total loss: 0.049870
tensor(0.1073, device='cuda:0') tensor(0.1866, device='cuda:0') tensor(-1.2232e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.029532
Average KL loss: 0.019937
Average total loss: 0.049468
tensor(0.1070, device='cuda:0') tensor(0.1863, device='cuda:0') tensor(-3.7792e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.028946
Average KL loss: 0.019867
Average total loss: 0.048812
tensor(0.1067, device='cuda:0') tensor(0.1861, device='cuda:0') tensor(-3.9736e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.028959
Average KL loss: 0.019787
Average total loss: 0.048746
tensor(0.1062, device='cuda:0') tensor(0.1857, device='cuda:0') tensor(-8.7594e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.029551
Average KL loss: 0.019733
Average total loss: 0.049284
tensor(0.1062, device='cuda:0') tensor(0.1856, device='cuda:0') tensor(-1.3002e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.029050
Average KL loss: 0.019684
Average total loss: 0.048734
tensor(0.1060, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-3.4717e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.028690
Average KL loss: 0.019630
Average total loss: 0.048321
tensor(0.1057, device='cuda:0') tensor(0.1853, device='cuda:0') tensor(-4.3373e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.028658
Average KL loss: 0.019575
Average total loss: 0.048233
tensor(0.1055, device='cuda:0') tensor(0.1852, device='cuda:0') tensor(-7.7295e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.028389
Average KL loss: 0.019520
Average total loss: 0.047909
tensor(0.1052, device='cuda:0') tensor(0.1850, device='cuda:0') tensor(-1.6197e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.028143
Average KL loss: 0.019467
Average total loss: 0.047610
tensor(0.1050, device='cuda:0') tensor(0.1848, device='cuda:0') tensor(-7.4393e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.027935
Average KL loss: 0.019403
Average total loss: 0.047338
tensor(0.1047, device='cuda:0') tensor(0.1845, device='cuda:0') tensor(-4.7208e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.028350
Average KL loss: 0.019354
Average total loss: 0.047704
tensor(0.1046, device='cuda:0') tensor(0.1845, device='cuda:0') tensor(-8.6300e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.027834
Average KL loss: 0.019310
Average total loss: 0.047144
tensor(0.1043, device='cuda:0') tensor(0.1844, device='cuda:0') tensor(-2.7646e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.027331
Average KL loss: 0.019269
Average total loss: 0.046599
tensor(0.1041, device='cuda:0') tensor(0.1843, device='cuda:0') tensor(-1.2251e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.028165
Average KL loss: 0.019220
Average total loss: 0.047385
tensor(0.1039, device='cuda:0') tensor(0.1843, device='cuda:0') tensor(-1.2916e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.026825
Average KL loss: 0.019179
Average total loss: 0.046003
tensor(0.1036, device='cuda:0') tensor(0.1840, device='cuda:0') tensor(-1.1266e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.026900
Average KL loss: 0.019111
Average total loss: 0.046011
tensor(0.1034, device='cuda:0') tensor(0.1838, device='cuda:0') tensor(-7.0656e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.026916
Average KL loss: 0.019049
Average total loss: 0.045965
tensor(0.1032, device='cuda:0') tensor(0.1836, device='cuda:0') tensor(-4.5057e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.027432
Average KL loss: 0.019003
Average total loss: 0.046434
tensor(0.1030, device='cuda:0') tensor(0.1836, device='cuda:0') tensor(-6.8034e-11, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.026399
Average KL loss: 0.018980
Average total loss: 0.045379
tensor(0.1028, device='cuda:0') tensor(0.1836, device='cuda:0') tensor(-4.1535e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.026124
Average KL loss: 0.018915
Average total loss: 0.045039
tensor(0.1025, device='cuda:0') tensor(0.1832, device='cuda:0') tensor(-7.9280e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.026281
Average KL loss: 0.018837
Average total loss: 0.045118
tensor(0.1022, device='cuda:0') tensor(0.1830, device='cuda:0') tensor(-1.0104e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.026194
Average KL loss: 0.018792
Average total loss: 0.044986
tensor(0.1021, device='cuda:0') tensor(0.1829, device='cuda:0') tensor(-7.4756e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.026505
Average KL loss: 0.018749
Average total loss: 0.045254
tensor(0.1019, device='cuda:0') tensor(0.1829, device='cuda:0') tensor(-1.2986e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.026558
Average KL loss: 0.018713
Average total loss: 0.045271
tensor(0.1017, device='cuda:0') tensor(0.1828, device='cuda:0') tensor(-1.1207e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.025588
Average KL loss: 0.018681
Average total loss: 0.044269
tensor(0.1015, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-8.7652e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.025443
Average KL loss: 0.018613
Average total loss: 0.044056
tensor(0.1012, device='cuda:0') tensor(0.1824, device='cuda:0') tensor(-7.0274e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.025809
Average KL loss: 0.018555
Average total loss: 0.044365
tensor(0.1011, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(-3.7933e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.025646
Average KL loss: 0.018520
Average total loss: 0.044166
tensor(0.1009, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(-5.6098e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.025541
Average KL loss: 0.018476
Average total loss: 0.044017
tensor(0.1007, device='cuda:0') tensor(0.1822, device='cuda:0') tensor(-1.3772e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.024951
Average KL loss: 0.018429
Average total loss: 0.043380
tensor(0.1004, device='cuda:0') tensor(0.1820, device='cuda:0') tensor(-1.7520e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.024827
Average KL loss: 0.018364
Average total loss: 0.043192
tensor(0.1002, device='cuda:0') tensor(0.1818, device='cuda:0') tensor(-6.3302e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.025348
Average KL loss: 0.018328
Average total loss: 0.043676
tensor(0.1000, device='cuda:0') tensor(0.1818, device='cuda:0') tensor(-4.2952e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.025413
Average KL loss: 0.018282
Average total loss: 0.043695
tensor(0.0999, device='cuda:0') tensor(0.1817, device='cuda:0') tensor(-8.7848e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.024820
Average KL loss: 0.018251
Average total loss: 0.043071
tensor(0.0997, device='cuda:0') tensor(0.1817, device='cuda:0') tensor(-9.1965e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.024599
Average KL loss: 0.018215
Average total loss: 0.042814
tensor(0.0995, device='cuda:0') tensor(0.1816, device='cuda:0') tensor(-4.5763e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.024520
Average KL loss: 0.018157
Average total loss: 0.042677
tensor(0.0993, device='cuda:0') tensor(0.1814, device='cuda:0') tensor(-4.6790e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.024191
Average KL loss: 0.018100
Average total loss: 0.042291
tensor(0.0990, device='cuda:0') tensor(0.1812, device='cuda:0') tensor(-4.3954e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.024047
Average KL loss: 0.018036
Average total loss: 0.042083
tensor(0.0987, device='cuda:0') tensor(0.1810, device='cuda:0') tensor(-3.7877e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.024203
Average KL loss: 0.017990
Average total loss: 0.042194
tensor(0.0986, device='cuda:0') tensor(0.1809, device='cuda:0') tensor(-1.1093e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.024712
Average KL loss: 0.017969
Average total loss: 0.042681
tensor(0.0984, device='cuda:0') tensor(0.1811, device='cuda:0') tensor(-5.7131e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.023821
Average KL loss: 0.017931
Average total loss: 0.041751
tensor(0.0982, device='cuda:0') tensor(0.1809, device='cuda:0') tensor(-2.1758e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.023825
Average KL loss: 0.017877
Average total loss: 0.041702
tensor(0.0980, device='cuda:0') tensor(0.1808, device='cuda:0') tensor(-7.5088e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.024046
Average KL loss: 0.017838
Average total loss: 0.041885
tensor(0.0978, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-1.0225e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.024340
Average KL loss: 0.017796
Average total loss: 0.042137
tensor(0.0977, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-7.3838e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.023531
Average KL loss: 0.017776
Average total loss: 0.041306
tensor(0.0975, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-1.7010e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.023659
Average KL loss: 0.017733
Average total loss: 0.041392
tensor(0.0973, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-3.5741e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.023289
Average KL loss: 0.017688
Average total loss: 0.040977
tensor(0.0971, device='cuda:0') tensor(0.1804, device='cuda:0') tensor(-2.8486e-11, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.023798
Average KL loss: 0.017639
Average total loss: 0.041437
tensor(0.0969, device='cuda:0') tensor(0.1805, device='cuda:0') tensor(-4.2761e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.023493
Average KL loss: 0.017626
Average total loss: 0.041118
tensor(0.0969, device='cuda:0') tensor(0.1805, device='cuda:0') tensor(-8.8671e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.023747
Average KL loss: 0.017597
Average total loss: 0.041344
tensor(0.0967, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-4.5159e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.023785
Average KL loss: 0.017591
Average total loss: 0.041376
tensor(0.0966, device='cuda:0') tensor(0.1810, device='cuda:0') tensor(-3.3847e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.023320
Average KL loss: 0.017568
Average total loss: 0.040888
tensor(0.0964, device='cuda:0') tensor(0.1810, device='cuda:0') tensor(-1.7788e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.023072
Average KL loss: 0.017536
Average total loss: 0.040609
tensor(0.0962, device='cuda:0') tensor(0.1808, device='cuda:0') tensor(-3.6788e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.023291
Average KL loss: 0.017490
Average total loss: 0.040782
tensor(0.0961, device='cuda:0') tensor(0.1810, device='cuda:0') tensor(-5.7587e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.022616
Average KL loss: 0.017472
Average total loss: 0.040088
tensor(0.0958, device='cuda:0') tensor(0.1809, device='cuda:0') tensor(-4.6509e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.022799
Average KL loss: 0.017414
Average total loss: 0.040213
tensor(0.0957, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-1.4559e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.022520
Average KL loss: 0.017371
Average total loss: 0.039891
tensor(0.0954, device='cuda:0') tensor(0.1806, device='cuda:0') tensor(-3.5797e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.022502
Average KL loss: 0.017330
Average total loss: 0.039832
tensor(0.0952, device='cuda:0') tensor(0.1805, device='cuda:0') tensor(-4.9815e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.022464
Average KL loss: 0.017286
Average total loss: 0.039750
tensor(0.0950, device='cuda:0') tensor(0.1804, device='cuda:0') tensor(-3.2137e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.022671
Average KL loss: 0.017241
Average total loss: 0.039912
tensor(0.0949, device='cuda:0') tensor(0.1803, device='cuda:0') tensor(-2.2255e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.022264
Average KL loss: 0.017203
Average total loss: 0.039467
tensor(0.0947, device='cuda:0') tensor(0.1802, device='cuda:0') tensor(-1.9757e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.022528
Average KL loss: 0.017164
Average total loss: 0.039691
tensor(0.0945, device='cuda:0') tensor(0.1802, device='cuda:0') tensor(-2.4814e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.022474
Average KL loss: 0.017135
Average total loss: 0.039608
tensor(0.0945, device='cuda:0') tensor(0.1802, device='cuda:0') tensor(-5.8333e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.022398
Average KL loss: 0.017116
Average total loss: 0.039514
 Percentile value: 0.10119744390249252
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =     513 /    1728             ( 29.69%) | total_pruned =    1215 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
bn1.bias             | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6977 /   36864             ( 18.93%) | total_pruned =   29887 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   16571 /   36864             ( 44.95%) | total_pruned =   20293 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   16725 /   36864             ( 45.37%) | total_pruned =   20139 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   19711 /   36864             ( 53.47%) | total_pruned =   17153 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   43350 /   73728             ( 58.80%) | total_pruned =   30378 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   86428 /  147456             ( 58.61%) | total_pruned =   61028 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5353 /    8192             ( 65.34%) | total_pruned =    2839 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   74619 /  147456             ( 50.60%) | total_pruned =   72837 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   74903 /  147456             ( 50.80%) | total_pruned =   72553 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  167923 /  294912             ( 56.94%) | total_pruned =  126989 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     157 /     256             ( 61.33%) | total_pruned =      99 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  330877 /  589824             ( 56.10%) | total_pruned =  258947 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19754 /   32768             ( 60.28%) | total_pruned =   13014 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  316401 /  589824             ( 53.64%) | total_pruned =  273423 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      61 /     256             ( 23.83%) | total_pruned =     195 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  301944 /  589824             ( 51.19%) | total_pruned =  287880 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  607734 / 1179648             ( 51.52%) | total_pruned =  571914 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     303 /     512             ( 59.18%) | total_pruned =     209 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1098687 / 2359296             ( 46.57%) | total_pruned = 1260609 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     425 /     512             ( 83.01%) | total_pruned =      87 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   61867 /  131072             ( 47.20%) | total_pruned =   69205 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     420 /     512             ( 82.03%) | total_pruned =      92 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  976441 / 2359296             ( 41.39%) | total_pruned = 1382855 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1349858 / 2359296             ( 57.21%) | total_pruned = 1009438 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5090 /    5120             ( 99.41%) | total_pruned =      30 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 60/100 Loss: 0.013044 Accuracy: 89.28 100.00 % Best test Accuracy: 89.28%
tensor(0.0944, device='cuda:0') tensor(0.1804, device='cuda:0') tensor(-4.9936e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.203813
Average KL loss: 0.015223
Average total loss: 0.219036
tensor(0.1017, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-2.4273e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.152133
Average KL loss: 0.012977
Average total loss: 0.165110
tensor(0.1049, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(-2.3614e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.135079
Average KL loss: 0.011931
Average total loss: 0.147010
tensor(0.1056, device='cuda:0') tensor(0.1234, device='cuda:0') tensor(-1.4927e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.122001
Average KL loss: 0.011449
Average total loss: 0.133450
tensor(0.1057, device='cuda:0') tensor(0.1196, device='cuda:0') tensor(-1.6538e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.110616
Average KL loss: 0.011250
Average total loss: 0.121866
tensor(0.1056, device='cuda:0') tensor(0.1179, device='cuda:0') tensor(-1.5160e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.106141
Average KL loss: 0.011212
Average total loss: 0.117353
tensor(0.1055, device='cuda:0') tensor(0.1174, device='cuda:0') tensor(-1.4506e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.098151
Average KL loss: 0.011256
Average total loss: 0.109406
tensor(0.1054, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-1.1688e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.091571
Average KL loss: 0.011345
Average total loss: 0.102915
tensor(0.1054, device='cuda:0') tensor(0.1182, device='cuda:0') tensor(-1.0057e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.089563
Average KL loss: 0.011446
Average total loss: 0.101008
tensor(0.1054, device='cuda:0') tensor(0.1190, device='cuda:0') tensor(-9.3058e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.081081
Average KL loss: 0.011573
Average total loss: 0.092654
tensor(0.1055, device='cuda:0') tensor(0.1199, device='cuda:0') tensor(-1.0492e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.077824
Average KL loss: 0.011690
Average total loss: 0.089514
tensor(0.1055, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-1.1279e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.076466
Average KL loss: 0.011801
Average total loss: 0.088267
tensor(0.1056, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-1.1303e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.073652
Average KL loss: 0.011921
Average total loss: 0.085573
tensor(0.1057, device='cuda:0') tensor(0.1229, device='cuda:0') tensor(-8.4455e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.071753
Average KL loss: 0.012041
Average total loss: 0.083793
tensor(0.1058, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-7.5179e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.066645
Average KL loss: 0.012153
Average total loss: 0.078798
tensor(0.1058, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-7.5293e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.063414
Average KL loss: 0.012247
Average total loss: 0.075661
tensor(0.1058, device='cuda:0') tensor(0.1260, device='cuda:0') tensor(-7.5182e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.062934
Average KL loss: 0.012332
Average total loss: 0.075266
tensor(0.1058, device='cuda:0') tensor(0.1269, device='cuda:0') tensor(-7.7545e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.061760
Average KL loss: 0.012427
Average total loss: 0.074187
tensor(0.1059, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-6.4706e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.058759
Average KL loss: 0.012518
Average total loss: 0.071277
tensor(0.1059, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-8.4032e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.056793
Average KL loss: 0.012595
Average total loss: 0.069388
tensor(0.1058, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-6.4148e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.057989
Average KL loss: 0.012677
Average total loss: 0.070666
tensor(0.1059, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-5.9877e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.053795
Average KL loss: 0.012751
Average total loss: 0.066546
tensor(0.1058, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-5.2717e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.052914
Average KL loss: 0.012819
Average total loss: 0.065733
tensor(0.1057, device='cuda:0') tensor(0.1324, device='cuda:0') tensor(-7.8567e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.049615
Average KL loss: 0.012880
Average total loss: 0.062495
tensor(0.1056, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(-5.4034e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.051291
Average KL loss: 0.012937
Average total loss: 0.064229
tensor(0.1055, device='cuda:0') tensor(0.1340, device='cuda:0') tensor(-5.5648e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.048795
Average KL loss: 0.012999
Average total loss: 0.061793
tensor(0.1055, device='cuda:0') tensor(0.1348, device='cuda:0') tensor(-6.9894e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.047705
Average KL loss: 0.013053
Average total loss: 0.060758
tensor(0.1053, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-4.7281e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.046779
Average KL loss: 0.013100
Average total loss: 0.059880
tensor(0.1052, device='cuda:0') tensor(0.1363, device='cuda:0') tensor(-3.2282e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.046049
Average KL loss: 0.013155
Average total loss: 0.059203
tensor(0.1051, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(-5.0044e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.045059
Average KL loss: 0.013198
Average total loss: 0.058257
tensor(0.1050, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-6.2161e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.044002
Average KL loss: 0.013245
Average total loss: 0.057247
tensor(0.1049, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(-4.9149e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.043461
Average KL loss: 0.013287
Average total loss: 0.056748
tensor(0.1048, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-2.6829e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.041737
Average KL loss: 0.013323
Average total loss: 0.055060
tensor(0.1046, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(-3.3395e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.041619
Average KL loss: 0.013357
Average total loss: 0.054976
tensor(0.1045, device='cuda:0') tensor(0.1403, device='cuda:0') tensor(-6.5683e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.041365
Average KL loss: 0.013393
Average total loss: 0.054758
tensor(0.1043, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-4.1277e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.038805
Average KL loss: 0.013433
Average total loss: 0.052237
tensor(0.1042, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(-3.7085e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.039648
Average KL loss: 0.013461
Average total loss: 0.053109
tensor(0.1041, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-2.8254e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.040051
Average KL loss: 0.013500
Average total loss: 0.053551
tensor(0.1039, device='cuda:0') tensor(0.1428, device='cuda:0') tensor(-4.3069e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.037855
Average KL loss: 0.013530
Average total loss: 0.051385
tensor(0.1038, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-2.4345e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.036164
Average KL loss: 0.013559
Average total loss: 0.049723
tensor(0.1036, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(-3.5024e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.036641
Average KL loss: 0.013578
Average total loss: 0.050219
tensor(0.1034, device='cuda:0') tensor(0.1444, device='cuda:0') tensor(-4.1422e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.035406
Average KL loss: 0.013595
Average total loss: 0.049001
tensor(0.1032, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(-3.3377e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.035434
Average KL loss: 0.013606
Average total loss: 0.049040
tensor(0.1030, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(-2.4833e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.034540
Average KL loss: 0.013626
Average total loss: 0.048166
tensor(0.1028, device='cuda:0') tensor(0.1457, device='cuda:0') tensor(-2.6830e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.035627
Average KL loss: 0.013642
Average total loss: 0.049269
tensor(0.1027, device='cuda:0') tensor(0.1462, device='cuda:0') tensor(-1.9282e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.035268
Average KL loss: 0.013669
Average total loss: 0.048937
tensor(0.1025, device='cuda:0') tensor(0.1468, device='cuda:0') tensor(-1.2559e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.032490
Average KL loss: 0.013693
Average total loss: 0.046183
tensor(0.1023, device='cuda:0') tensor(0.1472, device='cuda:0') tensor(-1.7062e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.032898
Average KL loss: 0.013699
Average total loss: 0.046597
tensor(0.1021, device='cuda:0') tensor(0.1477, device='cuda:0') tensor(-1.1328e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.032705
Average KL loss: 0.013719
Average total loss: 0.046424
tensor(0.1019, device='cuda:0') tensor(0.1481, device='cuda:0') tensor(-2.7634e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.031757
Average KL loss: 0.013727
Average total loss: 0.045485
tensor(0.1017, device='cuda:0') tensor(0.1485, device='cuda:0') tensor(-1.2771e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.030716
Average KL loss: 0.013726
Average total loss: 0.044442
tensor(0.1015, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(-1.1155e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.030239
Average KL loss: 0.013725
Average total loss: 0.043963
tensor(0.1013, device='cuda:0') tensor(0.1491, device='cuda:0') tensor(-1.6131e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.030153
Average KL loss: 0.013729
Average total loss: 0.043882
tensor(0.1011, device='cuda:0') tensor(0.1494, device='cuda:0') tensor(-2.3816e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.030686
Average KL loss: 0.013736
Average total loss: 0.044422
tensor(0.1009, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-1.9575e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.030186
Average KL loss: 0.013747
Average total loss: 0.043933
tensor(0.1007, device='cuda:0') tensor(0.1503, device='cuda:0') tensor(-2.7228e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.029873
Average KL loss: 0.013758
Average total loss: 0.043631
tensor(0.1005, device='cuda:0') tensor(0.1507, device='cuda:0') tensor(-1.7241e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.029624
Average KL loss: 0.013765
Average total loss: 0.043389
tensor(0.1003, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(-1.9788e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.029053
Average KL loss: 0.013771
Average total loss: 0.042823
tensor(0.1001, device='cuda:0') tensor(0.1514, device='cuda:0') tensor(-3.6319e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.029074
Average KL loss: 0.013777
Average total loss: 0.042850
tensor(0.0999, device='cuda:0') tensor(0.1517, device='cuda:0') tensor(-1.0916e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.028173
Average KL loss: 0.013778
Average total loss: 0.041951
tensor(0.0997, device='cuda:0') tensor(0.1520, device='cuda:0') tensor(-1.9196e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.028631
Average KL loss: 0.013775
Average total loss: 0.042405
tensor(0.0995, device='cuda:0') tensor(0.1524, device='cuda:0') tensor(-1.6162e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.028629
Average KL loss: 0.013788
Average total loss: 0.042417
tensor(0.0994, device='cuda:0') tensor(0.1528, device='cuda:0') tensor(-9.6084e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.027592
Average KL loss: 0.013798
Average total loss: 0.041390
tensor(0.0991, device='cuda:0') tensor(0.1531, device='cuda:0') tensor(-1.5114e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.027247
Average KL loss: 0.013799
Average total loss: 0.041046
tensor(0.0989, device='cuda:0') tensor(0.1534, device='cuda:0') tensor(-6.5968e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.026946
Average KL loss: 0.013797
Average total loss: 0.040743
tensor(0.0987, device='cuda:0') tensor(0.1537, device='cuda:0') tensor(-1.7334e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.028535
Average KL loss: 0.013798
Average total loss: 0.042333
tensor(0.0986, device='cuda:0') tensor(0.1541, device='cuda:0') tensor(-8.2839e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.025985
Average KL loss: 0.013806
Average total loss: 0.039791
tensor(0.0983, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(-9.6860e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.026773
Average KL loss: 0.013801
Average total loss: 0.040574
tensor(0.0981, device='cuda:0') tensor(0.1547, device='cuda:0') tensor(-1.9013e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.025983
Average KL loss: 0.013812
Average total loss: 0.039795
tensor(0.0980, device='cuda:0') tensor(0.1551, device='cuda:0') tensor(-1.8909e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.026121
Average KL loss: 0.013810
Average total loss: 0.039931
tensor(0.0977, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-1.3596e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.025157
Average KL loss: 0.013799
Average total loss: 0.038957
tensor(0.0975, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(-1.7288e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.027308
Average KL loss: 0.013798
Average total loss: 0.041106
tensor(0.0973, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(-1.0809e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.024615
Average KL loss: 0.013806
Average total loss: 0.038421
tensor(0.0971, device='cuda:0') tensor(0.1562, device='cuda:0') tensor(-1.0498e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.024581
Average KL loss: 0.013797
Average total loss: 0.038378
tensor(0.0969, device='cuda:0') tensor(0.1565, device='cuda:0') tensor(-1.3790e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.024797
Average KL loss: 0.013790
Average total loss: 0.038586
tensor(0.0967, device='cuda:0') tensor(0.1567, device='cuda:0') tensor(-1.3953e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.024401
Average KL loss: 0.013784
Average total loss: 0.038185
tensor(0.0965, device='cuda:0') tensor(0.1569, device='cuda:0') tensor(-1.2385e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.024064
Average KL loss: 0.013776
Average total loss: 0.037840
tensor(0.0962, device='cuda:0') tensor(0.1572, device='cuda:0') tensor(-1.1577e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.023540
Average KL loss: 0.013765
Average total loss: 0.037304
tensor(0.0960, device='cuda:0') tensor(0.1573, device='cuda:0') tensor(-1.4648e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.023749
Average KL loss: 0.013752
Average total loss: 0.037502
tensor(0.0958, device='cuda:0') tensor(0.1575, device='cuda:0') tensor(-2.1309e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.023223
Average KL loss: 0.013740
Average total loss: 0.036962
tensor(0.0956, device='cuda:0') tensor(0.1576, device='cuda:0') tensor(-7.2452e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.023361
Average KL loss: 0.013729
Average total loss: 0.037090
tensor(0.0954, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(-5.0868e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.022681
Average KL loss: 0.013718
Average total loss: 0.036399
tensor(0.0951, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-8.0436e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.022956
Average KL loss: 0.013704
Average total loss: 0.036660
tensor(0.0949, device='cuda:0') tensor(0.1582, device='cuda:0') tensor(-6.6529e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.023330
Average KL loss: 0.013695
Average total loss: 0.037024
tensor(0.0947, device='cuda:0') tensor(0.1584, device='cuda:0') tensor(-9.2631e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.022900
Average KL loss: 0.013693
Average total loss: 0.036592
tensor(0.0945, device='cuda:0') tensor(0.1587, device='cuda:0') tensor(-1.0580e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.022808
Average KL loss: 0.013687
Average total loss: 0.036495
tensor(0.0943, device='cuda:0') tensor(0.1589, device='cuda:0') tensor(-3.1425e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.022931
Average KL loss: 0.013680
Average total loss: 0.036611
tensor(0.0941, device='cuda:0') tensor(0.1592, device='cuda:0') tensor(-8.4295e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.022469
Average KL loss: 0.013676
Average total loss: 0.036145
tensor(0.0940, device='cuda:0') tensor(0.1594, device='cuda:0') tensor(-1.0103e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.023293
Average KL loss: 0.013671
Average total loss: 0.036963
tensor(0.0938, device='cuda:0') tensor(0.1597, device='cuda:0') tensor(-7.0412e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.021789
Average KL loss: 0.013674
Average total loss: 0.035463
tensor(0.0936, device='cuda:0') tensor(0.1600, device='cuda:0') tensor(-4.2777e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.021543
Average KL loss: 0.013660
Average total loss: 0.035203
tensor(0.0934, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(-3.7523e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.021815
Average KL loss: 0.013644
Average total loss: 0.035459
tensor(0.0931, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(-4.8272e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.021203
Average KL loss: 0.013632
Average total loss: 0.034835
tensor(0.0929, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(-8.8109e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.021428
Average KL loss: 0.013617
Average total loss: 0.035045
tensor(0.0927, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(-1.1168e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.021710
Average KL loss: 0.013606
Average total loss: 0.035316
tensor(0.0925, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-6.0533e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.021262
Average KL loss: 0.013601
Average total loss: 0.034863
tensor(0.0923, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(-1.0466e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.021645
Average KL loss: 0.013601
Average total loss: 0.035245
tensor(0.0921, device='cuda:0') tensor(0.1613, device='cuda:0') tensor(-1.3408e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.020971
Average KL loss: 0.013596
Average total loss: 0.034568
tensor(0.0919, device='cuda:0') tensor(0.1615, device='cuda:0') tensor(-7.7897e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.020750
Average KL loss: 0.013582
Average total loss: 0.034332
tensor(0.0917, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-8.0129e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.020477
Average KL loss: 0.013567
Average total loss: 0.034044
tensor(0.0915, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(-8.3132e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.020702
Average KL loss: 0.013550
Average total loss: 0.034252
tensor(0.0913, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-2.4330e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.020268
Average KL loss: 0.013539
Average total loss: 0.033807
tensor(0.0911, device='cuda:0') tensor(0.1621, device='cuda:0') tensor(-2.1493e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.020576
Average KL loss: 0.013520
Average total loss: 0.034096
tensor(0.0909, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(-6.5474e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.021846
Average KL loss: 0.013514
Average total loss: 0.035360
tensor(0.0907, device='cuda:0') tensor(0.1625, device='cuda:0') tensor(-1.0722e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.020076
Average KL loss: 0.013534
Average total loss: 0.033610
tensor(0.0906, device='cuda:0') tensor(0.1629, device='cuda:0') tensor(-1.0344e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.020245
Average KL loss: 0.013524
Average total loss: 0.033769
tensor(0.0904, device='cuda:0') tensor(0.1631, device='cuda:0') tensor(-8.9281e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.019869
Average KL loss: 0.013507
Average total loss: 0.033376
tensor(0.0902, device='cuda:0') tensor(0.1632, device='cuda:0') tensor(-5.2991e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.019827
Average KL loss: 0.013489
Average total loss: 0.033316
tensor(0.0899, device='cuda:0') tensor(0.1633, device='cuda:0') tensor(-7.9513e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.019826
Average KL loss: 0.013479
Average total loss: 0.033305
tensor(0.0898, device='cuda:0') tensor(0.1635, device='cuda:0') tensor(-4.4387e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.019465
Average KL loss: 0.013464
Average total loss: 0.032930
tensor(0.0895, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(-3.2294e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.019347
Average KL loss: 0.013443
Average total loss: 0.032790
tensor(0.0893, device='cuda:0') tensor(0.1637, device='cuda:0') tensor(-9.9265e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.019558
Average KL loss: 0.013434
Average total loss: 0.032992
tensor(0.0891, device='cuda:0') tensor(0.1639, device='cuda:0') tensor(-5.1309e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.019039
Average KL loss: 0.013419
Average total loss: 0.032457
tensor(0.0889, device='cuda:0') tensor(0.1640, device='cuda:0') tensor(-8.8351e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.019172
Average KL loss: 0.013399
Average total loss: 0.032571
tensor(0.0887, device='cuda:0') tensor(0.1641, device='cuda:0') tensor(-1.1328e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.019344
Average KL loss: 0.013389
Average total loss: 0.032734
tensor(0.0885, device='cuda:0') tensor(0.1643, device='cuda:0') tensor(-3.8635e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.019061
Average KL loss: 0.013373
Average total loss: 0.032433
tensor(0.0883, device='cuda:0') tensor(0.1644, device='cuda:0') tensor(-7.5319e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.019446
Average KL loss: 0.013365
Average total loss: 0.032811
tensor(0.0882, device='cuda:0') tensor(0.1647, device='cuda:0') tensor(-7.8157e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.018878
Average KL loss: 0.013360
Average total loss: 0.032238
tensor(0.0880, device='cuda:0') tensor(0.1648, device='cuda:0') tensor(-6.1397e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.018523
Average KL loss: 0.013343
Average total loss: 0.031866
tensor(0.0878, device='cuda:0') tensor(0.1649, device='cuda:0') tensor(-1.3877e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.018657
Average KL loss: 0.013325
Average total loss: 0.031982
tensor(0.0876, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-3.7847e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.018967
Average KL loss: 0.013320
Average total loss: 0.032287
tensor(0.0874, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(-1.2691e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.018471
Average KL loss: 0.013305
Average total loss: 0.031776
tensor(0.0872, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(-5.4279e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.018819
Average KL loss: 0.013289
Average total loss: 0.032108
tensor(0.0871, device='cuda:0') tensor(0.1655, device='cuda:0') tensor(-6.4217e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.017951
Average KL loss: 0.013276
Average total loss: 0.031227
tensor(0.0868, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(1.1757e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.018502
Average KL loss: 0.013247
Average total loss: 0.031750
tensor(0.0866, device='cuda:0') tensor(0.1657, device='cuda:0') tensor(-4.9449e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.018255
Average KL loss: 0.013236
Average total loss: 0.031490
tensor(0.0864, device='cuda:0') tensor(0.1658, device='cuda:0') tensor(-3.0123e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.018234
Average KL loss: 0.013223
Average total loss: 0.031457
tensor(0.0863, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(-1.0580e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.017576
Average KL loss: 0.013206
Average total loss: 0.030782
tensor(0.0860, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(2.4740e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.019836
Average KL loss: 0.013190
Average total loss: 0.033026
tensor(0.0859, device='cuda:0') tensor(0.1664, device='cuda:0') tensor(-2.3485e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.017987
Average KL loss: 0.013208
Average total loss: 0.031195
tensor(0.0857, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-2.6578e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.018393
Average KL loss: 0.013199
Average total loss: 0.031591
tensor(0.0856, device='cuda:0') tensor(0.1669, device='cuda:0') tensor(-2.4628e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.017842
Average KL loss: 0.013203
Average total loss: 0.031045
tensor(0.0854, device='cuda:0') tensor(0.1671, device='cuda:0') tensor(-9.0795e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.017734
Average KL loss: 0.013183
Average total loss: 0.030917
tensor(0.0852, device='cuda:0') tensor(0.1671, device='cuda:0') tensor(-2.5512e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.017504
Average KL loss: 0.013166
Average total loss: 0.030670
tensor(0.0850, device='cuda:0') tensor(0.1672, device='cuda:0') tensor(-2.1058e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.017160
Average KL loss: 0.013140
Average total loss: 0.030300
tensor(0.0848, device='cuda:0') tensor(0.1672, device='cuda:0') tensor(4.9374e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.017389
Average KL loss: 0.013111
Average total loss: 0.030500
tensor(0.0846, device='cuda:0') tensor(0.1672, device='cuda:0') tensor(-3.6407e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.017239
Average KL loss: 0.013088
Average total loss: 0.030327
tensor(0.0844, device='cuda:0') tensor(0.1673, device='cuda:0') tensor(-5.3837e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.017373
Average KL loss: 0.013070
Average total loss: 0.030443
tensor(0.0842, device='cuda:0') tensor(0.1674, device='cuda:0') tensor(-6.7498e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.017284
Average KL loss: 0.013052
Average total loss: 0.030336
tensor(0.0841, device='cuda:0') tensor(0.1675, device='cuda:0') tensor(1.1812e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.017389
Average KL loss: 0.013039
Average total loss: 0.030428
tensor(0.0839, device='cuda:0') tensor(0.1676, device='cuda:0') tensor(1.1490e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.017996
Average KL loss: 0.013032
Average total loss: 0.031027
tensor(0.0838, device='cuda:0') tensor(0.1679, device='cuda:0') tensor(-2.6743e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.017012
Average KL loss: 0.013044
Average total loss: 0.030055
tensor(0.0837, device='cuda:0') tensor(0.1682, device='cuda:0') tensor(-3.2191e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.016861
Average KL loss: 0.013022
Average total loss: 0.029884
tensor(0.0835, device='cuda:0') tensor(0.1681, device='cuda:0') tensor(-6.8325e-11, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.017286
Average KL loss: 0.012999
Average total loss: 0.030285
tensor(0.0833, device='cuda:0') tensor(0.1683, device='cuda:0') tensor(-2.3380e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.017156
Average KL loss: 0.012992
Average total loss: 0.030148
tensor(0.0832, device='cuda:0') tensor(0.1684, device='cuda:0') tensor(-3.2095e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.016927
Average KL loss: 0.012983
Average total loss: 0.029910
tensor(0.0830, device='cuda:0') tensor(0.1686, device='cuda:0') tensor(2.7976e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.016757
Average KL loss: 0.012969
Average total loss: 0.029726
tensor(0.0828, device='cuda:0') tensor(0.1687, device='cuda:0') tensor(-4.5558e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.016993
Average KL loss: 0.012949
Average total loss: 0.029942
tensor(0.0826, device='cuda:0') tensor(0.1688, device='cuda:0') tensor(-3.2996e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.016854
Average KL loss: 0.012943
Average total loss: 0.029797
tensor(0.0825, device='cuda:0') tensor(0.1690, device='cuda:0') tensor(-1.2548e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.016757
Average KL loss: 0.012926
Average total loss: 0.029683
tensor(0.0823, device='cuda:0') tensor(0.1690, device='cuda:0') tensor(7.3761e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.016517
Average KL loss: 0.012906
Average total loss: 0.029423
tensor(0.0821, device='cuda:0') tensor(0.1691, device='cuda:0') tensor(7.9495e-11, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.016948
Average KL loss: 0.012890
Average total loss: 0.029838
tensor(0.0820, device='cuda:0') tensor(0.1693, device='cuda:0') tensor(1.2427e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.016476
Average KL loss: 0.012882
Average total loss: 0.029357
tensor(0.0818, device='cuda:0') tensor(0.1694, device='cuda:0') tensor(-1.5726e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.016426
Average KL loss: 0.012867
Average total loss: 0.029293
tensor(0.0817, device='cuda:0') tensor(0.1695, device='cuda:0') tensor(1.4886e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.016363
Average KL loss: 0.012841
Average total loss: 0.029204
tensor(0.0815, device='cuda:0') tensor(0.1695, device='cuda:0') tensor(-3.0680e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.016733
Average KL loss: 0.012830
Average total loss: 0.029563
tensor(0.0813, device='cuda:0') tensor(0.1696, device='cuda:0') tensor(-1.2167e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.016469
Average KL loss: 0.012825
Average total loss: 0.029294
tensor(0.0812, device='cuda:0') tensor(0.1698, device='cuda:0') tensor(-3.2900e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.016493
Average KL loss: 0.012811
Average total loss: 0.029304
tensor(0.0811, device='cuda:0') tensor(0.1699, device='cuda:0') tensor(1.2444e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.016395
Average KL loss: 0.012802
Average total loss: 0.029197
tensor(0.0809, device='cuda:0') tensor(0.1701, device='cuda:0') tensor(-9.2276e-11, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.016460
Average KL loss: 0.012793
Average total loss: 0.029252
tensor(0.0808, device='cuda:0') tensor(0.1703, device='cuda:0') tensor(6.7914e-11, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.016123
Average KL loss: 0.012788
Average total loss: 0.028911
tensor(0.0806, device='cuda:0') tensor(0.1704, device='cuda:0') tensor(-4.4528e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.016469
Average KL loss: 0.012776
Average total loss: 0.029245
tensor(0.0805, device='cuda:0') tensor(0.1706, device='cuda:0') tensor(-1.1902e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.016359
Average KL loss: 0.012769
Average total loss: 0.029128
tensor(0.0804, device='cuda:0') tensor(0.1708, device='cuda:0') tensor(-9.2319e-11, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.016015
Average KL loss: 0.012759
Average total loss: 0.028774
tensor(0.0802, device='cuda:0') tensor(0.1708, device='cuda:0') tensor(-2.4974e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.016179
Average KL loss: 0.012741
Average total loss: 0.028920
tensor(0.0801, device='cuda:0') tensor(0.1710, device='cuda:0') tensor(1.3819e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.016086
Average KL loss: 0.012734
Average total loss: 0.028819
tensor(0.0799, device='cuda:0') tensor(0.1711, device='cuda:0') tensor(5.1107e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.015936
Average KL loss: 0.012726
Average total loss: 0.028662
tensor(0.0798, device='cuda:0') tensor(0.1713, device='cuda:0') tensor(-6.7180e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.015900
Average KL loss: 0.012711
Average total loss: 0.028610
tensor(0.0796, device='cuda:0') tensor(0.1714, device='cuda:0') tensor(-5.2324e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.016131
Average KL loss: 0.012694
Average total loss: 0.028826
tensor(0.0794, device='cuda:0') tensor(0.1715, device='cuda:0') tensor(-1.8672e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.016016
Average KL loss: 0.012689
Average total loss: 0.028704
tensor(0.0793, device='cuda:0') tensor(0.1716, device='cuda:0') tensor(-2.9115e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.015808
Average KL loss: 0.012677
Average total loss: 0.028485
tensor(0.0792, device='cuda:0') tensor(0.1717, device='cuda:0') tensor(-1.2101e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.015749
Average KL loss: 0.012660
Average total loss: 0.028409
tensor(0.0790, device='cuda:0') tensor(0.1719, device='cuda:0') tensor(-2.2516e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.015875
Average KL loss: 0.012652
Average total loss: 0.028527
tensor(0.0789, device='cuda:0') tensor(0.1721, device='cuda:0') tensor(4.9163e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.015567
Average KL loss: 0.012640
Average total loss: 0.028207
tensor(0.0787, device='cuda:0') tensor(0.1721, device='cuda:0') tensor(-3.5950e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.016155
Average KL loss: 0.012626
Average total loss: 0.028781
tensor(0.0786, device='cuda:0') tensor(0.1724, device='cuda:0') tensor(-7.8903e-11, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.015705
Average KL loss: 0.012633
Average total loss: 0.028338
tensor(0.0785, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(5.7924e-11, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.015738
Average KL loss: 0.012621
Average total loss: 0.028359
tensor(0.0783, device='cuda:0') tensor(0.1727, device='cuda:0') tensor(-2.4757e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.015476
Average KL loss: 0.012613
Average total loss: 0.028089
tensor(0.0783, device='cuda:0') tensor(0.1728, device='cuda:0') tensor(1.4759e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.015439
Average KL loss: 0.012594
Average total loss: 0.028032
tensor(0.0781, device='cuda:0') tensor(0.1729, device='cuda:0') tensor(-1.8054e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.015342
Average KL loss: 0.012572
Average total loss: 0.027915
tensor(0.0779, device='cuda:0') tensor(0.1729, device='cuda:0') tensor(-2.1660e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.015555
Average KL loss: 0.012559
Average total loss: 0.028114
tensor(0.0778, device='cuda:0') tensor(0.1731, device='cuda:0') tensor(-3.1952e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.015383
Average KL loss: 0.012545
Average total loss: 0.027928
tensor(0.0777, device='cuda:0') tensor(0.1732, device='cuda:0') tensor(-1.9890e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.015520
Average KL loss: 0.012537
Average total loss: 0.028057
tensor(0.0775, device='cuda:0') tensor(0.1734, device='cuda:0') tensor(-7.5343e-11, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.015748
Average KL loss: 0.012535
Average total loss: 0.028283
tensor(0.0775, device='cuda:0') tensor(0.1736, device='cuda:0') tensor(7.2185e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.015154
Average KL loss: 0.012531
Average total loss: 0.027685
tensor(0.0773, device='cuda:0') tensor(0.1737, device='cuda:0') tensor(-1.5326e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.015060
Average KL loss: 0.012504
Average total loss: 0.027565
tensor(0.0772, device='cuda:0') tensor(0.1736, device='cuda:0') tensor(5.2291e-11, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.015509
Average KL loss: 0.012489
Average total loss: 0.027998
tensor(0.0770, device='cuda:0') tensor(0.1739, device='cuda:0') tensor(-8.5085e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.015361
Average KL loss: 0.012498
Average total loss: 0.027860
tensor(0.0770, device='cuda:0') tensor(0.1742, device='cuda:0') tensor(-3.7876e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.015209
Average KL loss: 0.012493
Average total loss: 0.027702
tensor(0.0768, device='cuda:0') tensor(0.1743, device='cuda:0') tensor(-1.5184e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.015248
Average KL loss: 0.012483
Average total loss: 0.027731
tensor(0.0767, device='cuda:0') tensor(0.1744, device='cuda:0') tensor(1.1100e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.015114
Average KL loss: 0.012467
Average total loss: 0.027581
tensor(0.0766, device='cuda:0') tensor(0.1745, device='cuda:0') tensor(8.9298e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.015118
Average KL loss: 0.012452
Average total loss: 0.027570
tensor(0.0765, device='cuda:0') tensor(0.1746, device='cuda:0') tensor(-9.2519e-11, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.015208
Average KL loss: 0.012438
Average total loss: 0.027646
tensor(0.0763, device='cuda:0') tensor(0.1747, device='cuda:0') tensor(1.0482e-12, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.014957
Average KL loss: 0.012430
Average total loss: 0.027387
tensor(0.0762, device='cuda:0') tensor(0.1748, device='cuda:0') tensor(-1.8572e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.015113
Average KL loss: 0.012417
Average total loss: 0.027530
tensor(0.0761, device='cuda:0') tensor(0.1749, device='cuda:0') tensor(-2.1697e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.015129
Average KL loss: 0.012414
Average total loss: 0.027543
tensor(0.0760, device='cuda:0') tensor(0.1752, device='cuda:0') tensor(3.2403e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.014964
Average KL loss: 0.012408
Average total loss: 0.027373
tensor(0.0759, device='cuda:0') tensor(0.1753, device='cuda:0') tensor(-5.6923e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.014975
Average KL loss: 0.012401
Average total loss: 0.027375
tensor(0.0757, device='cuda:0') tensor(0.1755, device='cuda:0') tensor(-2.4661e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.014943
Average KL loss: 0.012395
Average total loss: 0.027338
tensor(0.0757, device='cuda:0') tensor(0.1756, device='cuda:0') tensor(2.5930e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.014778
Average KL loss: 0.012380
Average total loss: 0.027159
 Percentile value: 0.0829022005200386
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =     248 /    1728             ( 14.35%) | total_pruned =    1480 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.bias             | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1841 /   36864             (  4.99%) | total_pruned =   35023 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    6251 /   36864             ( 16.96%) | total_pruned =   30613 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    7298 /   36864             ( 19.80%) | total_pruned =   29566 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    8661 /   36864             ( 23.49%) | total_pruned =   28203 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   24280 /   73728             ( 32.93%) | total_pruned =   49448 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   46044 /  147456             ( 31.23%) | total_pruned =  101412 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2948 /    8192             ( 35.99%) | total_pruned =    5244 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   32832 /  147456             ( 22.27%) | total_pruned =  114624 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   33937 /  147456             ( 23.02%) | total_pruned =  113519 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   91765 /  294912             ( 31.12%) | total_pruned =  203147 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  151291 /  589824             ( 25.65%) | total_pruned =  438533 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     132 /     256             ( 51.56%) | total_pruned =     124 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   10333 /   32768             ( 31.53%) | total_pruned =   22435 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  137332 /  589824             ( 23.28%) | total_pruned =  452492 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  144133 /  589824             ( 24.44%) | total_pruned =  445691 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  286191 / 1179648             ( 24.26%) | total_pruned =  893457 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     441 /     512             ( 86.13%) | total_pruned =      71 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     228 /     512             ( 44.53%) | total_pruned =     284 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  607684 / 2359296             ( 25.76%) | total_pruned = 1751612 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   30189 /  131072             ( 23.03%) | total_pruned =  100883 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     465 /     512             ( 90.82%) | total_pruned =      47 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  425586 / 2359296             ( 18.04%) | total_pruned = 1933710 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     481 /     512             ( 93.95%) | total_pruned =      31 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  734292 / 2359296             ( 31.12%) | total_pruned = 1625004 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4933 /    5120             ( 96.35%) | total_pruned =     187 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 48/100 Loss: 0.017505 Accuracy: 88.04 100.00 % Best test Accuracy: 88.20%
tensor(0.0755, device='cuda:0') tensor(0.1756, device='cuda:0') tensor(-3.9421e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.218393
Average KL loss: 0.011644
Average total loss: 0.230037
tensor(0.0793, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(-3.0441e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.185780
Average KL loss: 0.010819
Average total loss: 0.196599
tensor(0.0813, device='cuda:0') tensor(0.1533, device='cuda:0') tensor(-2.5839e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.162830
Average KL loss: 0.010422
Average total loss: 0.173252
tensor(0.0820, device='cuda:0') tensor(0.1494, device='cuda:0') tensor(-2.9800e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.152891
Average KL loss: 0.010233
Average total loss: 0.163125
tensor(0.0823, device='cuda:0') tensor(0.1476, device='cuda:0') tensor(-2.1637e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.144825
Average KL loss: 0.010177
Average total loss: 0.155001
tensor(0.0825, device='cuda:0') tensor(0.1469, device='cuda:0') tensor(-2.2282e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.132505
Average KL loss: 0.010196
Average total loss: 0.142701
tensor(0.0827, device='cuda:0') tensor(0.1469, device='cuda:0') tensor(-1.5387e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.123477
Average KL loss: 0.010254
Average total loss: 0.133731
tensor(0.0828, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(-1.4544e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.118299
Average KL loss: 0.010333
Average total loss: 0.128632
tensor(0.0831, device='cuda:0') tensor(0.1479, device='cuda:0') tensor(-1.4036e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.110670
Average KL loss: 0.010430
Average total loss: 0.121100
tensor(0.0834, device='cuda:0') tensor(0.1487, device='cuda:0') tensor(-1.2356e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.112401
Average KL loss: 0.010539
Average total loss: 0.122940
tensor(0.0837, device='cuda:0') tensor(0.1496, device='cuda:0') tensor(-1.1118e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.105076
Average KL loss: 0.010650
Average total loss: 0.115726
tensor(0.0841, device='cuda:0') tensor(0.1506, device='cuda:0') tensor(-1.4276e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.102109
Average KL loss: 0.010764
Average total loss: 0.112874
tensor(0.0845, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-1.3003e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.099227
Average KL loss: 0.010874
Average total loss: 0.110102
tensor(0.0848, device='cuda:0') tensor(0.1527, device='cuda:0') tensor(-1.0823e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.092270
Average KL loss: 0.010981
Average total loss: 0.103251
tensor(0.0852, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(-1.0895e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.091155
Average KL loss: 0.011081
Average total loss: 0.102236
tensor(0.0855, device='cuda:0') tensor(0.1546, device='cuda:0') tensor(-9.4157e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.090550
Average KL loss: 0.011180
Average total loss: 0.101731
tensor(0.0859, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(-1.1488e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.086926
Average KL loss: 0.011279
Average total loss: 0.098205
tensor(0.0862, device='cuda:0') tensor(0.1566, device='cuda:0') tensor(-8.2464e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.083453
Average KL loss: 0.011369
Average total loss: 0.094822
tensor(0.0865, device='cuda:0') tensor(0.1575, device='cuda:0') tensor(-9.9972e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.081396
Average KL loss: 0.011456
Average total loss: 0.092852
tensor(0.0868, device='cuda:0') tensor(0.1584, device='cuda:0') tensor(-9.2149e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.078318
Average KL loss: 0.011535
Average total loss: 0.089853
tensor(0.0871, device='cuda:0') tensor(0.1593, device='cuda:0') tensor(-7.9206e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.077181
Average KL loss: 0.011618
Average total loss: 0.088800
tensor(0.0873, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(-8.0532e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.073786
Average KL loss: 0.011698
Average total loss: 0.085484
tensor(0.0876, device='cuda:0') tensor(0.1612, device='cuda:0') tensor(-7.4149e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.070644
Average KL loss: 0.011773
Average total loss: 0.082417
tensor(0.0878, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-8.0389e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.069980
Average KL loss: 0.011843
Average total loss: 0.081824
tensor(0.0880, device='cuda:0') tensor(0.1628, device='cuda:0') tensor(-6.4883e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.069498
Average KL loss: 0.011909
Average total loss: 0.081408
tensor(0.0882, device='cuda:0') tensor(0.1637, device='cuda:0') tensor(-7.6526e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.065344
Average KL loss: 0.011982
Average total loss: 0.077327
tensor(0.0885, device='cuda:0') tensor(0.1645, device='cuda:0') tensor(-9.2565e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.065822
Average KL loss: 0.012044
Average total loss: 0.077866
tensor(0.0886, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(-7.4496e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.065415
Average KL loss: 0.012105
Average total loss: 0.077520
tensor(0.0888, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-4.6475e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.064111
Average KL loss: 0.012165
Average total loss: 0.076276
tensor(0.0890, device='cuda:0') tensor(0.1669, device='cuda:0') tensor(-7.5932e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.061798
Average KL loss: 0.012220
Average total loss: 0.074019
tensor(0.0891, device='cuda:0') tensor(0.1676, device='cuda:0') tensor(-8.0877e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.061299
Average KL loss: 0.012279
Average total loss: 0.073579
tensor(0.0893, device='cuda:0') tensor(0.1684, device='cuda:0') tensor(-6.0190e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.059480
Average KL loss: 0.012331
Average total loss: 0.071811
tensor(0.0894, device='cuda:0') tensor(0.1691, device='cuda:0') tensor(-5.4626e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.056633
Average KL loss: 0.012380
Average total loss: 0.069013
tensor(0.0895, device='cuda:0') tensor(0.1698, device='cuda:0') tensor(-6.1709e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.057764
Average KL loss: 0.012428
Average total loss: 0.070191
tensor(0.0897, device='cuda:0') tensor(0.1705, device='cuda:0') tensor(-7.5362e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.056485
Average KL loss: 0.012482
Average total loss: 0.068967
tensor(0.0898, device='cuda:0') tensor(0.1712, device='cuda:0') tensor(-6.5313e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.054786
Average KL loss: 0.012530
Average total loss: 0.067315
tensor(0.0899, device='cuda:0') tensor(0.1719, device='cuda:0') tensor(-7.2716e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.053772
Average KL loss: 0.012576
Average total loss: 0.066348
tensor(0.0900, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-8.3509e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.052780
Average KL loss: 0.012623
Average total loss: 0.065403
tensor(0.0901, device='cuda:0') tensor(0.1733, device='cuda:0') tensor(-5.4378e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.052119
Average KL loss: 0.012663
Average total loss: 0.064782
tensor(0.0902, device='cuda:0') tensor(0.1739, device='cuda:0') tensor(-7.9224e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.050970
Average KL loss: 0.012703
Average total loss: 0.063672
tensor(0.0903, device='cuda:0') tensor(0.1745, device='cuda:0') tensor(-5.7451e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.050454
Average KL loss: 0.012743
Average total loss: 0.063196
tensor(0.0904, device='cuda:0') tensor(0.1751, device='cuda:0') tensor(-6.6866e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.049604
Average KL loss: 0.012782
Average total loss: 0.062386
tensor(0.0904, device='cuda:0') tensor(0.1758, device='cuda:0') tensor(-6.7785e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.048157
Average KL loss: 0.012820
Average total loss: 0.060977
tensor(0.0905, device='cuda:0') tensor(0.1764, device='cuda:0') tensor(-5.1985e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.047724
Average KL loss: 0.012854
Average total loss: 0.060578
tensor(0.0906, device='cuda:0') tensor(0.1769, device='cuda:0') tensor(-5.8514e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.046542
Average KL loss: 0.012889
Average total loss: 0.059431
tensor(0.0906, device='cuda:0') tensor(0.1775, device='cuda:0') tensor(-2.8650e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.046295
Average KL loss: 0.012920
Average total loss: 0.059214
tensor(0.0906, device='cuda:0') tensor(0.1781, device='cuda:0') tensor(-3.8016e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.044664
Average KL loss: 0.012949
Average total loss: 0.057613
tensor(0.0906, device='cuda:0') tensor(0.1786, device='cuda:0') tensor(-4.6638e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.044220
Average KL loss: 0.012977
Average total loss: 0.057198
tensor(0.0907, device='cuda:0') tensor(0.1791, device='cuda:0') tensor(-4.9612e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.045580
Average KL loss: 0.013006
Average total loss: 0.058586
tensor(0.0908, device='cuda:0') tensor(0.1797, device='cuda:0') tensor(-4.1628e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.043529
Average KL loss: 0.013041
Average total loss: 0.056570
tensor(0.0908, device='cuda:0') tensor(0.1803, device='cuda:0') tensor(-3.2600e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.043124
Average KL loss: 0.013071
Average total loss: 0.056195
tensor(0.0908, device='cuda:0') tensor(0.1808, device='cuda:0') tensor(-4.6926e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.042746
Average KL loss: 0.013096
Average total loss: 0.055842
tensor(0.0909, device='cuda:0') tensor(0.1813, device='cuda:0') tensor(-4.0064e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.041892
Average KL loss: 0.013128
Average total loss: 0.055020
tensor(0.0909, device='cuda:0') tensor(0.1819, device='cuda:0') tensor(-4.0263e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.041662
Average KL loss: 0.013155
Average total loss: 0.054817
tensor(0.0909, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(-4.6700e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.041062
Average KL loss: 0.013179
Average total loss: 0.054241
tensor(0.0909, device='cuda:0') tensor(0.1829, device='cuda:0') tensor(-4.0425e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.040595
Average KL loss: 0.013206
Average total loss: 0.053801
tensor(0.0910, device='cuda:0') tensor(0.1834, device='cuda:0') tensor(-3.0476e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.039635
Average KL loss: 0.013231
Average total loss: 0.052867
tensor(0.0909, device='cuda:0') tensor(0.1839, device='cuda:0') tensor(-2.8350e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.038980
Average KL loss: 0.013249
Average total loss: 0.052229
tensor(0.0910, device='cuda:0') tensor(0.1843, device='cuda:0') tensor(-3.1478e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.038937
Average KL loss: 0.013273
Average total loss: 0.052209
tensor(0.0910, device='cuda:0') tensor(0.1848, device='cuda:0') tensor(-2.9695e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.039261
Average KL loss: 0.013295
Average total loss: 0.052556
tensor(0.0910, device='cuda:0') tensor(0.1853, device='cuda:0') tensor(-3.5274e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.037516
Average KL loss: 0.013320
Average total loss: 0.050836
tensor(0.0910, device='cuda:0') tensor(0.1858, device='cuda:0') tensor(-3.1937e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.037873
Average KL loss: 0.013339
Average total loss: 0.051212
tensor(0.0910, device='cuda:0') tensor(0.1862, device='cuda:0') tensor(-3.2254e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.036911
Average KL loss: 0.013358
Average total loss: 0.050270
tensor(0.0910, device='cuda:0') tensor(0.1867, device='cuda:0') tensor(-2.7280e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.036952
Average KL loss: 0.013379
Average total loss: 0.050331
tensor(0.0910, device='cuda:0') tensor(0.1872, device='cuda:0') tensor(-2.3498e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.035788
Average KL loss: 0.013400
Average total loss: 0.049188
tensor(0.0910, device='cuda:0') tensor(0.1876, device='cuda:0') tensor(-3.1175e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.035904
Average KL loss: 0.013412
Average total loss: 0.049316
tensor(0.0910, device='cuda:0') tensor(0.1880, device='cuda:0') tensor(-2.5937e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.035078
Average KL loss: 0.013431
Average total loss: 0.048508
tensor(0.0909, device='cuda:0') tensor(0.1884, device='cuda:0') tensor(-3.5986e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.035256
Average KL loss: 0.013447
Average total loss: 0.048703
tensor(0.0909, device='cuda:0') tensor(0.1889, device='cuda:0') tensor(-2.2752e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.035267
Average KL loss: 0.013464
Average total loss: 0.048731
tensor(0.0909, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(-3.1802e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.034585
Average KL loss: 0.013480
Average total loss: 0.048065
tensor(0.0909, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-2.7390e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.034342
Average KL loss: 0.013496
Average total loss: 0.047838
tensor(0.0909, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(-2.5534e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.033929
Average KL loss: 0.013512
Average total loss: 0.047441
tensor(0.0908, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-2.1981e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.033618
Average KL loss: 0.013526
Average total loss: 0.047144
tensor(0.0908, device='cuda:0') tensor(0.1910, device='cuda:0') tensor(-2.4736e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.033629
Average KL loss: 0.013543
Average total loss: 0.047172
tensor(0.0908, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-2.0036e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.032532
Average KL loss: 0.013559
Average total loss: 0.046091
tensor(0.0908, device='cuda:0') tensor(0.1918, device='cuda:0') tensor(-1.9246e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.032288
Average KL loss: 0.013570
Average total loss: 0.045858
tensor(0.0907, device='cuda:0') tensor(0.1921, device='cuda:0') tensor(-2.2018e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.031621
Average KL loss: 0.013581
Average total loss: 0.045202
tensor(0.0907, device='cuda:0') tensor(0.1925, device='cuda:0') tensor(-2.7184e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.031197
Average KL loss: 0.013589
Average total loss: 0.044786
tensor(0.0907, device='cuda:0') tensor(0.1928, device='cuda:0') tensor(-1.9483e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.032425
Average KL loss: 0.013600
Average total loss: 0.046025
tensor(0.0906, device='cuda:0') tensor(0.1932, device='cuda:0') tensor(-2.7809e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.031069
Average KL loss: 0.013615
Average total loss: 0.044684
tensor(0.0906, device='cuda:0') tensor(0.1936, device='cuda:0') tensor(-2.1602e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.030298
Average KL loss: 0.013623
Average total loss: 0.043921
tensor(0.0905, device='cuda:0') tensor(0.1939, device='cuda:0') tensor(-2.5985e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.031384
Average KL loss: 0.013628
Average total loss: 0.045012
tensor(0.0905, device='cuda:0') tensor(0.1942, device='cuda:0') tensor(-2.9412e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.030261
Average KL loss: 0.013638
Average total loss: 0.043899
tensor(0.0904, device='cuda:0') tensor(0.1946, device='cuda:0') tensor(-2.3234e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.030398
Average KL loss: 0.013645
Average total loss: 0.044044
tensor(0.0904, device='cuda:0') tensor(0.1949, device='cuda:0') tensor(-1.7571e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.029388
Average KL loss: 0.013654
Average total loss: 0.043042
tensor(0.0903, device='cuda:0') tensor(0.1952, device='cuda:0') tensor(-1.9829e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.029456
Average KL loss: 0.013663
Average total loss: 0.043119
tensor(0.0903, device='cuda:0') tensor(0.1956, device='cuda:0') tensor(-1.9558e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.029560
Average KL loss: 0.013671
Average total loss: 0.043231
tensor(0.0902, device='cuda:0') tensor(0.1959, device='cuda:0') tensor(-1.7286e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.029401
Average KL loss: 0.013680
Average total loss: 0.043081
tensor(0.0902, device='cuda:0') tensor(0.1963, device='cuda:0') tensor(-2.2673e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.028414
Average KL loss: 0.013687
Average total loss: 0.042101
tensor(0.0901, device='cuda:0') tensor(0.1966, device='cuda:0') tensor(-1.8295e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.027476
Average KL loss: 0.013688
Average total loss: 0.041164
tensor(0.0901, device='cuda:0') tensor(0.1968, device='cuda:0') tensor(-1.0805e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.027936
Average KL loss: 0.013689
Average total loss: 0.041625
tensor(0.0900, device='cuda:0') tensor(0.1971, device='cuda:0') tensor(-1.4437e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.028824
Average KL loss: 0.013696
Average total loss: 0.042520
tensor(0.0900, device='cuda:0') tensor(0.1975, device='cuda:0') tensor(-2.1978e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.028238
Average KL loss: 0.013704
Average total loss: 0.041942
tensor(0.0899, device='cuda:0') tensor(0.1978, device='cuda:0') tensor(-1.2892e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.027758
Average KL loss: 0.013710
Average total loss: 0.041469
tensor(0.0899, device='cuda:0') tensor(0.1981, device='cuda:0') tensor(-2.1729e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.027423
Average KL loss: 0.013715
Average total loss: 0.041138
tensor(0.0898, device='cuda:0') tensor(0.1984, device='cuda:0') tensor(-1.4106e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.027475
Average KL loss: 0.013716
Average total loss: 0.041191
tensor(0.0897, device='cuda:0') tensor(0.1987, device='cuda:0') tensor(-1.8930e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.026906
Average KL loss: 0.013724
Average total loss: 0.040630
tensor(0.0897, device='cuda:0') tensor(0.1990, device='cuda:0') tensor(-1.0193e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.026985
Average KL loss: 0.013728
Average total loss: 0.040713
tensor(0.0896, device='cuda:0') tensor(0.1993, device='cuda:0') tensor(-1.9845e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.025913
Average KL loss: 0.013734
Average total loss: 0.039646
tensor(0.0896, device='cuda:0') tensor(0.1995, device='cuda:0') tensor(-2.1545e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.026538
Average KL loss: 0.013735
Average total loss: 0.040273
tensor(0.0895, device='cuda:0') tensor(0.1998, device='cuda:0') tensor(-9.1078e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.026026
Average KL loss: 0.013736
Average total loss: 0.039762
tensor(0.0894, device='cuda:0') tensor(0.2001, device='cuda:0') tensor(-1.5884e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.025511
Average KL loss: 0.013742
Average total loss: 0.039252
tensor(0.0893, device='cuda:0') tensor(0.2004, device='cuda:0') tensor(-1.2602e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.025561
Average KL loss: 0.013740
Average total loss: 0.039301
tensor(0.0893, device='cuda:0') tensor(0.2006, device='cuda:0') tensor(-2.5253e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.025484
Average KL loss: 0.013740
Average total loss: 0.039224
tensor(0.0892, device='cuda:0') tensor(0.2008, device='cuda:0') tensor(-5.8300e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.025763
Average KL loss: 0.013740
Average total loss: 0.039503
tensor(0.0891, device='cuda:0') tensor(0.2011, device='cuda:0') tensor(-1.1115e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.025576
Average KL loss: 0.013745
Average total loss: 0.039321
tensor(0.0891, device='cuda:0') tensor(0.2014, device='cuda:0') tensor(-1.4478e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.024764
Average KL loss: 0.013749
Average total loss: 0.038513
tensor(0.0890, device='cuda:0') tensor(0.2017, device='cuda:0') tensor(-6.0931e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.025142
Average KL loss: 0.013748
Average total loss: 0.038890
tensor(0.0889, device='cuda:0') tensor(0.2020, device='cuda:0') tensor(-1.2583e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.024709
Average KL loss: 0.013747
Average total loss: 0.038456
tensor(0.0888, device='cuda:0') tensor(0.2021, device='cuda:0') tensor(-1.1464e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.024403
Average KL loss: 0.013745
Average total loss: 0.038149
tensor(0.0887, device='cuda:0') tensor(0.2024, device='cuda:0') tensor(-1.3449e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.024640
Average KL loss: 0.013746
Average total loss: 0.038386
tensor(0.0887, device='cuda:0') tensor(0.2027, device='cuda:0') tensor(-1.7374e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.024536
Average KL loss: 0.013748
Average total loss: 0.038285
tensor(0.0886, device='cuda:0') tensor(0.2029, device='cuda:0') tensor(-6.6107e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.023872
Average KL loss: 0.013750
Average total loss: 0.037622
tensor(0.0885, device='cuda:0') tensor(0.2031, device='cuda:0') tensor(-1.1951e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.023938
Average KL loss: 0.013748
Average total loss: 0.037687
tensor(0.0885, device='cuda:0') tensor(0.2034, device='cuda:0') tensor(-1.0831e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.024200
Average KL loss: 0.013751
Average total loss: 0.037951
tensor(0.0884, device='cuda:0') tensor(0.2037, device='cuda:0') tensor(-1.5891e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.024189
Average KL loss: 0.013753
Average total loss: 0.037942
tensor(0.0883, device='cuda:0') tensor(0.2040, device='cuda:0') tensor(-1.8096e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.023826
Average KL loss: 0.013758
Average total loss: 0.037584
tensor(0.0883, device='cuda:0') tensor(0.2043, device='cuda:0') tensor(-1.5377e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.023820
Average KL loss: 0.013758
Average total loss: 0.037578
tensor(0.0882, device='cuda:0') tensor(0.2045, device='cuda:0') tensor(-4.5416e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.023147
Average KL loss: 0.013759
Average total loss: 0.036905
tensor(0.0881, device='cuda:0') tensor(0.2047, device='cuda:0') tensor(-8.9252e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.022853
Average KL loss: 0.013756
Average total loss: 0.036609
tensor(0.0880, device='cuda:0') tensor(0.2050, device='cuda:0') tensor(-1.0582e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.022761
Average KL loss: 0.013751
Average total loss: 0.036512
tensor(0.0879, device='cuda:0') tensor(0.2051, device='cuda:0') tensor(-4.8776e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.022597
Average KL loss: 0.013745
Average total loss: 0.036342
tensor(0.0879, device='cuda:0') tensor(0.2053, device='cuda:0') tensor(-9.0187e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.022978
Average KL loss: 0.013744
Average total loss: 0.036722
tensor(0.0878, device='cuda:0') tensor(0.2056, device='cuda:0') tensor(-8.2452e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.022650
Average KL loss: 0.013742
Average total loss: 0.036393
tensor(0.0877, device='cuda:0') tensor(0.2058, device='cuda:0') tensor(-5.2265e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.022406
Average KL loss: 0.013739
Average total loss: 0.036145
tensor(0.0876, device='cuda:0') tensor(0.2060, device='cuda:0') tensor(-7.1895e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.022509
Average KL loss: 0.013736
Average total loss: 0.036244
tensor(0.0875, device='cuda:0') tensor(0.2062, device='cuda:0') tensor(-9.5449e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.022452
Average KL loss: 0.013733
Average total loss: 0.036185
tensor(0.0874, device='cuda:0') tensor(0.2065, device='cuda:0') tensor(-5.3428e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.022390
Average KL loss: 0.013733
Average total loss: 0.036123
tensor(0.0874, device='cuda:0') tensor(0.2067, device='cuda:0') tensor(-3.6450e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.021913
Average KL loss: 0.013734
Average total loss: 0.035647
tensor(0.0873, device='cuda:0') tensor(0.2069, device='cuda:0') tensor(-1.0531e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.022003
Average KL loss: 0.013730
Average total loss: 0.035733
tensor(0.0872, device='cuda:0') tensor(0.2071, device='cuda:0') tensor(-1.0332e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.021912
Average KL loss: 0.013727
Average total loss: 0.035639
tensor(0.0871, device='cuda:0') tensor(0.2074, device='cuda:0') tensor(-1.7110e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.021813
Average KL loss: 0.013727
Average total loss: 0.035541
tensor(0.0871, device='cuda:0') tensor(0.2076, device='cuda:0') tensor(-7.0108e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.022017
Average KL loss: 0.013724
Average total loss: 0.035741
tensor(0.0870, device='cuda:0') tensor(0.2078, device='cuda:0') tensor(-3.5776e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.021433
Average KL loss: 0.013722
Average total loss: 0.035155
tensor(0.0869, device='cuda:0') tensor(0.2080, device='cuda:0') tensor(-7.4074e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.021732
Average KL loss: 0.013719
Average total loss: 0.035452
tensor(0.0868, device='cuda:0') tensor(0.2083, device='cuda:0') tensor(-8.6263e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.021274
Average KL loss: 0.013719
Average total loss: 0.034992
tensor(0.0868, device='cuda:0') tensor(0.2085, device='cuda:0') tensor(-2.8370e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.021250
Average KL loss: 0.013711
Average total loss: 0.034962
tensor(0.0866, device='cuda:0') tensor(0.2086, device='cuda:0') tensor(-1.6098e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.021823
Average KL loss: 0.013710
Average total loss: 0.035533
tensor(0.0866, device='cuda:0') tensor(0.2089, device='cuda:0') tensor(-7.5999e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.021070
Average KL loss: 0.013712
Average total loss: 0.034783
tensor(0.0865, device='cuda:0') tensor(0.2092, device='cuda:0') tensor(-9.4018e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.021025
Average KL loss: 0.013709
Average total loss: 0.034734
tensor(0.0864, device='cuda:0') tensor(0.2094, device='cuda:0') tensor(-3.8605e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.021288
Average KL loss: 0.013702
Average total loss: 0.034990
tensor(0.0864, device='cuda:0') tensor(0.2096, device='cuda:0') tensor(-8.3646e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.020702
Average KL loss: 0.013704
Average total loss: 0.034405
tensor(0.0863, device='cuda:0') tensor(0.2098, device='cuda:0') tensor(-5.0106e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.020558
Average KL loss: 0.013697
Average total loss: 0.034255
tensor(0.0862, device='cuda:0') tensor(0.2100, device='cuda:0') tensor(-5.3487e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.020459
Average KL loss: 0.013691
Average total loss: 0.034150
tensor(0.0861, device='cuda:0') tensor(0.2101, device='cuda:0') tensor(-7.1841e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.020012
Average KL loss: 0.013681
Average total loss: 0.033693
tensor(0.0860, device='cuda:0') tensor(0.2102, device='cuda:0') tensor(-4.0047e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.020445
Average KL loss: 0.013670
Average total loss: 0.034115
tensor(0.0859, device='cuda:0') tensor(0.2104, device='cuda:0') tensor(-4.9949e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.020214
Average KL loss: 0.013665
Average total loss: 0.033880
tensor(0.0858, device='cuda:0') tensor(0.2106, device='cuda:0') tensor(-1.0948e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.019608
Average KL loss: 0.013656
Average total loss: 0.033264
tensor(0.0857, device='cuda:0') tensor(0.2107, device='cuda:0') tensor(-2.8872e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.020328
Average KL loss: 0.013648
Average total loss: 0.033976
tensor(0.0856, device='cuda:0') tensor(0.2109, device='cuda:0') tensor(-5.0906e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.019984
Average KL loss: 0.013639
Average total loss: 0.033623
tensor(0.0855, device='cuda:0') tensor(0.2110, device='cuda:0') tensor(-5.2110e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.020163
Average KL loss: 0.013635
Average total loss: 0.033798
tensor(0.0855, device='cuda:0') tensor(0.2113, device='cuda:0') tensor(-3.6770e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.019970
Average KL loss: 0.013632
Average total loss: 0.033602
tensor(0.0854, device='cuda:0') tensor(0.2114, device='cuda:0') tensor(-1.2883e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.019543
Average KL loss: 0.013628
Average total loss: 0.033171
tensor(0.0853, device='cuda:0') tensor(0.2116, device='cuda:0') tensor(-3.5057e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.019587
Average KL loss: 0.013618
Average total loss: 0.033205
tensor(0.0852, device='cuda:0') tensor(0.2117, device='cuda:0') tensor(-5.4459e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.019627
Average KL loss: 0.013610
Average total loss: 0.033237
tensor(0.0851, device='cuda:0') tensor(0.2119, device='cuda:0') tensor(-4.8342e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.019655
Average KL loss: 0.013605
Average total loss: 0.033260
tensor(0.0850, device='cuda:0') tensor(0.2121, device='cuda:0') tensor(-4.4305e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.019403
Average KL loss: 0.013600
Average total loss: 0.033003
tensor(0.0849, device='cuda:0') tensor(0.2123, device='cuda:0') tensor(-4.5363e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.019634
Average KL loss: 0.013590
Average total loss: 0.033224
tensor(0.0848, device='cuda:0') tensor(0.2124, device='cuda:0') tensor(-5.0806e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.019198
Average KL loss: 0.013590
Average total loss: 0.032788
tensor(0.0847, device='cuda:0') tensor(0.2126, device='cuda:0') tensor(-4.9676e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.019372
Average KL loss: 0.013582
Average total loss: 0.032954
tensor(0.0847, device='cuda:0') tensor(0.2128, device='cuda:0') tensor(-1.7087e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.019047
Average KL loss: 0.013576
Average total loss: 0.032623
tensor(0.0846, device='cuda:0') tensor(0.2129, device='cuda:0') tensor(-5.2744e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.018732
Average KL loss: 0.013565
Average total loss: 0.032298
tensor(0.0845, device='cuda:0') tensor(0.2131, device='cuda:0') tensor(-2.2193e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.018951
Average KL loss: 0.013554
Average total loss: 0.032506
tensor(0.0844, device='cuda:0') tensor(0.2132, device='cuda:0') tensor(-3.5305e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.018794
Average KL loss: 0.013547
Average total loss: 0.032341
tensor(0.0843, device='cuda:0') tensor(0.2133, device='cuda:0') tensor(7.7200e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.019063
Average KL loss: 0.013538
Average total loss: 0.032601
tensor(0.0842, device='cuda:0') tensor(0.2135, device='cuda:0') tensor(-1.6014e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.019058
Average KL loss: 0.013537
Average total loss: 0.032595
tensor(0.0841, device='cuda:0') tensor(0.2137, device='cuda:0') tensor(-5.5377e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.018857
Average KL loss: 0.013534
Average total loss: 0.032390
tensor(0.0841, device='cuda:0') tensor(0.2139, device='cuda:0') tensor(-1.3859e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.018831
Average KL loss: 0.013529
Average total loss: 0.032360
tensor(0.0840, device='cuda:0') tensor(0.2141, device='cuda:0') tensor(-6.5799e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.018561
Average KL loss: 0.013527
Average total loss: 0.032087
tensor(0.0839, device='cuda:0') tensor(0.2143, device='cuda:0') tensor(-1.8627e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.018587
Average KL loss: 0.013519
Average total loss: 0.032105
tensor(0.0838, device='cuda:0') tensor(0.2145, device='cuda:0') tensor(-1.4985e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.018803
Average KL loss: 0.013514
Average total loss: 0.032317
tensor(0.0838, device='cuda:0') tensor(0.2147, device='cuda:0') tensor(-4.0499e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.018254
Average KL loss: 0.013511
Average total loss: 0.031765
tensor(0.0837, device='cuda:0') tensor(0.2149, device='cuda:0') tensor(-7.0426e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.018359
Average KL loss: 0.013501
Average total loss: 0.031860
tensor(0.0836, device='cuda:0') tensor(0.2150, device='cuda:0') tensor(-4.5687e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.018262
Average KL loss: 0.013493
Average total loss: 0.031755
tensor(0.0835, device='cuda:0') tensor(0.2152, device='cuda:0') tensor(-3.4702e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.018440
Average KL loss: 0.013485
Average total loss: 0.031924
tensor(0.0834, device='cuda:0') tensor(0.2153, device='cuda:0') tensor(-2.0549e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.017976
Average KL loss: 0.013476
Average total loss: 0.031451
tensor(0.0833, device='cuda:0') tensor(0.2154, device='cuda:0') tensor(-1.1539e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.018329
Average KL loss: 0.013467
Average total loss: 0.031796
tensor(0.0832, device='cuda:0') tensor(0.2156, device='cuda:0') tensor(-1.5463e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.017716
Average KL loss: 0.013461
Average total loss: 0.031177
tensor(0.0831, device='cuda:0') tensor(0.2158, device='cuda:0') tensor(-4.0077e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.018232
Average KL loss: 0.013450
Average total loss: 0.031682
tensor(0.0831, device='cuda:0') tensor(0.2159, device='cuda:0') tensor(-8.4048e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.017713
Average KL loss: 0.013441
Average total loss: 0.031154
tensor(0.0830, device='cuda:0') tensor(0.2160, device='cuda:0') tensor(-6.1189e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.018063
Average KL loss: 0.013432
Average total loss: 0.031495
tensor(0.0829, device='cuda:0') tensor(0.2162, device='cuda:0') tensor(-4.7329e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.017706
Average KL loss: 0.013424
Average total loss: 0.031131
tensor(0.0828, device='cuda:0') tensor(0.2163, device='cuda:0') tensor(-2.2440e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.017827
Average KL loss: 0.013414
Average total loss: 0.031241
tensor(0.0827, device='cuda:0') tensor(0.2165, device='cuda:0') tensor(-7.6923e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.017968
Average KL loss: 0.013410
Average total loss: 0.031378
tensor(0.0826, device='cuda:0') tensor(0.2167, device='cuda:0') tensor(-3.3135e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.018014
Average KL loss: 0.013409
Average total loss: 0.031424
tensor(0.0826, device='cuda:0') tensor(0.2169, device='cuda:0') tensor(-1.5877e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.017491
Average KL loss: 0.013404
Average total loss: 0.030895
tensor(0.0824, device='cuda:0') tensor(0.2171, device='cuda:0') tensor(-1.7745e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.017391
Average KL loss: 0.013392
Average total loss: 0.030784
tensor(0.0823, device='cuda:0') tensor(0.2172, device='cuda:0') tensor(-6.2096e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.017593
Average KL loss: 0.013380
Average total loss: 0.030974
tensor(0.0823, device='cuda:0') tensor(0.2173, device='cuda:0') tensor(-4.5293e-11, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.017219
Average KL loss: 0.013371
Average total loss: 0.030590
tensor(0.0822, device='cuda:0') tensor(0.2174, device='cuda:0') tensor(-2.5842e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.017729
Average KL loss: 0.013362
Average total loss: 0.031091
tensor(0.0821, device='cuda:0') tensor(0.2176, device='cuda:0') tensor(-4.1796e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.017411
Average KL loss: 0.013361
Average total loss: 0.030772
tensor(0.0820, device='cuda:0') tensor(0.2178, device='cuda:0') tensor(-4.1911e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.018003
Average KL loss: 0.013359
Average total loss: 0.031362
tensor(0.0820, device='cuda:0') tensor(0.2181, device='cuda:0') tensor(-3.4733e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.017477
Average KL loss: 0.013360
Average total loss: 0.030837
tensor(0.0819, device='cuda:0') tensor(0.2182, device='cuda:0') tensor(-3.2112e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.017322
Average KL loss: 0.013350
Average total loss: 0.030672
tensor(0.0818, device='cuda:0') tensor(0.2184, device='cuda:0') tensor(-3.4445e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.017432
Average KL loss: 0.013342
Average total loss: 0.030774
tensor(0.0817, device='cuda:0') tensor(0.2185, device='cuda:0') tensor(-1.7701e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.017171
Average KL loss: 0.013334
Average total loss: 0.030505
tensor(0.0817, device='cuda:0') tensor(0.2187, device='cuda:0') tensor(-7.1350e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.017550
Average KL loss: 0.013329
Average total loss: 0.030879
tensor(0.0816, device='cuda:0') tensor(0.2189, device='cuda:0') tensor(-1.0959e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.017369
Average KL loss: 0.013327
Average total loss: 0.030696
tensor(0.0815, device='cuda:0') tensor(0.2191, device='cuda:0') tensor(-2.6244e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.016846
Average KL loss: 0.013322
Average total loss: 0.030168
tensor(0.0814, device='cuda:0') tensor(0.2193, device='cuda:0') tensor(-5.7842e-11, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.016990
Average KL loss: 0.013311
Average total loss: 0.030301
 Percentile value: 0.2489193230867386
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =     198 /    1728             ( 11.46%) | total_pruned =    1530 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     834 /   36864             (  2.26%) | total_pruned =   36030 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2476 /   36864             (  6.72%) | total_pruned =   34388 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3124 /   36864             (  8.47%) | total_pruned =   33740 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4362 /   36864             ( 11.83%) | total_pruned =   32502 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   14541 /   73728             ( 19.72%) | total_pruned =   59187 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   28312 /  147456             ( 19.20%) | total_pruned =  119144 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1964 /    8192             ( 23.97%) | total_pruned =    6228 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   16496 /  147456             ( 11.19%) | total_pruned =  130960 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   16545 /  147456             ( 11.22%) | total_pruned =  130911 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   57114 /  294912             ( 19.37%) | total_pruned =  237798 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   79174 /  589824             ( 13.42%) | total_pruned =  510650 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     101 /     256             ( 39.45%) | total_pruned =     155 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6538 /   32768             ( 19.95%) | total_pruned =   26230 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   66885 /  589824             ( 11.34%) | total_pruned =  522939 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   69081 /  589824             ( 11.71%) | total_pruned =  520743 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  147258 / 1179648             ( 12.48%) | total_pruned = 1032390 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     169 /     512             ( 33.01%) | total_pruned =     343 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  290131 / 2359296             ( 12.30%) | total_pruned = 2069165 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     480 /     512             ( 93.75%) | total_pruned =      32 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     356 /     512             ( 69.53%) | total_pruned =     156 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   11794 /  131072             (  9.00%) | total_pruned =  119278 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     368 /     512             ( 71.88%) | total_pruned =     144 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     353 /     512             ( 68.95%) | total_pruned =     159 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  187226 / 2359296             (  7.94%) | total_pruned = 2172070 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     372 /     512             ( 72.66%) | total_pruned =     140 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  382716 / 2359296             ( 16.22%) | total_pruned = 1976580 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
linear.weight        | nonzeros =    4828 /    5120             ( 94.30%) | total_pruned =     292 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 51/100 Loss: 0.016607 Accuracy: 86.36 100.00 % Best test Accuracy: 86.44%
tensor(0.0813, device='cuda:0') tensor(0.2194, device='cuda:0') tensor(-3.2292e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.212866
Average KL loss: 0.012708
Average total loss: 0.225574
tensor(0.0809, device='cuda:0') tensor(0.2046, device='cuda:0') tensor(-2.4098e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.185342
Average KL loss: 0.011938
Average total loss: 0.197279
tensor(0.0804, device='cuda:0') tensor(0.1965, device='cuda:0') tensor(-1.8298e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.168675
Average KL loss: 0.011458
Average total loss: 0.180133
tensor(0.0796, device='cuda:0') tensor(0.1911, device='cuda:0') tensor(-2.1500e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.163133
Average KL loss: 0.011143
Average total loss: 0.174276
tensor(0.0787, device='cuda:0') tensor(0.1874, device='cuda:0') tensor(-1.8580e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.155045
Average KL loss: 0.010927
Average total loss: 0.165972
tensor(0.0778, device='cuda:0') tensor(0.1850, device='cuda:0') tensor(-1.6298e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.144713
Average KL loss: 0.010787
Average total loss: 0.155499
tensor(0.0771, device='cuda:0') tensor(0.1834, device='cuda:0') tensor(-1.4107e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.141633
Average KL loss: 0.010706
Average total loss: 0.152339
tensor(0.0766, device='cuda:0') tensor(0.1825, device='cuda:0') tensor(-1.4046e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.131448
Average KL loss: 0.010673
Average total loss: 0.142121
tensor(0.0762, device='cuda:0') tensor(0.1821, device='cuda:0') tensor(-1.4159e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.126301
Average KL loss: 0.010669
Average total loss: 0.136970
tensor(0.0760, device='cuda:0') tensor(0.1820, device='cuda:0') tensor(-1.6804e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.121725
Average KL loss: 0.010686
Average total loss: 0.132410
tensor(0.0759, device='cuda:0') tensor(0.1820, device='cuda:0') tensor(-1.6392e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.119027
Average KL loss: 0.010718
Average total loss: 0.129745
tensor(0.0759, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(-1.6865e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.116465
Average KL loss: 0.010765
Average total loss: 0.127230
tensor(0.0760, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-1.0574e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.111661
Average KL loss: 0.010810
Average total loss: 0.122471
tensor(0.0761, device='cuda:0') tensor(0.1831, device='cuda:0') tensor(-1.3615e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.107921
Average KL loss: 0.010858
Average total loss: 0.118779
tensor(0.0762, device='cuda:0') tensor(0.1835, device='cuda:0') tensor(-1.1059e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.104792
Average KL loss: 0.010910
Average total loss: 0.115702
tensor(0.0764, device='cuda:0') tensor(0.1840, device='cuda:0') tensor(-1.0249e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.101701
Average KL loss: 0.010958
Average total loss: 0.112659
tensor(0.0765, device='cuda:0') tensor(0.1844, device='cuda:0') tensor(-1.4252e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.096358
Average KL loss: 0.011008
Average total loss: 0.107365
tensor(0.0767, device='cuda:0') tensor(0.1850, device='cuda:0') tensor(-8.7737e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.095126
Average KL loss: 0.011062
Average total loss: 0.106188
tensor(0.0769, device='cuda:0') tensor(0.1856, device='cuda:0') tensor(-1.0273e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.092434
Average KL loss: 0.011112
Average total loss: 0.103546
tensor(0.0770, device='cuda:0') tensor(0.1861, device='cuda:0') tensor(-1.2327e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.093102
Average KL loss: 0.011160
Average total loss: 0.104262
tensor(0.0772, device='cuda:0') tensor(0.1866, device='cuda:0') tensor(-9.6438e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.088970
Average KL loss: 0.011213
Average total loss: 0.100183
tensor(0.0774, device='cuda:0') tensor(0.1872, device='cuda:0') tensor(-1.2748e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.086377
Average KL loss: 0.011262
Average total loss: 0.097639
tensor(0.0775, device='cuda:0') tensor(0.1878, device='cuda:0') tensor(-9.0835e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.085333
Average KL loss: 0.011309
Average total loss: 0.096641
tensor(0.0777, device='cuda:0') tensor(0.1884, device='cuda:0') tensor(-9.0323e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.080483
Average KL loss: 0.011355
Average total loss: 0.091838
tensor(0.0778, device='cuda:0') tensor(0.1889, device='cuda:0') tensor(-8.8817e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.080497
Average KL loss: 0.011399
Average total loss: 0.091896
tensor(0.0780, device='cuda:0') tensor(0.1895, device='cuda:0') tensor(-9.9708e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.078068
Average KL loss: 0.011445
Average total loss: 0.089512
tensor(0.0781, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(-8.5321e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.075980
Average KL loss: 0.011485
Average total loss: 0.087465
tensor(0.0783, device='cuda:0') tensor(0.1906, device='cuda:0') tensor(-9.4919e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.075198
Average KL loss: 0.011527
Average total loss: 0.086725
tensor(0.0784, device='cuda:0') tensor(0.1912, device='cuda:0') tensor(-7.8552e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.074321
Average KL loss: 0.011568
Average total loss: 0.085889
tensor(0.0785, device='cuda:0') tensor(0.1918, device='cuda:0') tensor(-9.4197e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.073777
Average KL loss: 0.011611
Average total loss: 0.085388
tensor(0.0787, device='cuda:0') tensor(0.1924, device='cuda:0') tensor(-1.1820e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.071256
Average KL loss: 0.011653
Average total loss: 0.082908
tensor(0.0788, device='cuda:0') tensor(0.1929, device='cuda:0') tensor(-7.3695e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.069774
Average KL loss: 0.011691
Average total loss: 0.081465
tensor(0.0790, device='cuda:0') tensor(0.1935, device='cuda:0') tensor(-7.0983e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.069964
Average KL loss: 0.011730
Average total loss: 0.081695
tensor(0.0791, device='cuda:0') tensor(0.1941, device='cuda:0') tensor(-7.6356e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.066370
Average KL loss: 0.011767
Average total loss: 0.078137
tensor(0.0792, device='cuda:0') tensor(0.1946, device='cuda:0') tensor(-8.0823e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.064885
Average KL loss: 0.011802
Average total loss: 0.076687
tensor(0.0793, device='cuda:0') tensor(0.1951, device='cuda:0') tensor(-6.5118e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.065035
Average KL loss: 0.011839
Average total loss: 0.076873
tensor(0.0794, device='cuda:0') tensor(0.1957, device='cuda:0') tensor(-6.7817e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.064570
Average KL loss: 0.011870
Average total loss: 0.076441
tensor(0.0795, device='cuda:0') tensor(0.1962, device='cuda:0') tensor(-7.5200e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.067343
Average KL loss: 0.011905
Average total loss: 0.079248
tensor(0.0796, device='cuda:0') tensor(0.1967, device='cuda:0') tensor(-9.4846e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.062164
Average KL loss: 0.011940
Average total loss: 0.074105
tensor(0.0797, device='cuda:0') tensor(0.1973, device='cuda:0') tensor(-6.5408e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.061470
Average KL loss: 0.011975
Average total loss: 0.073445
tensor(0.0798, device='cuda:0') tensor(0.1978, device='cuda:0') tensor(-6.0444e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.059753
Average KL loss: 0.012008
Average total loss: 0.071760
tensor(0.0799, device='cuda:0') tensor(0.1984, device='cuda:0') tensor(-5.3310e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.056954
Average KL loss: 0.012041
Average total loss: 0.068994
tensor(0.0800, device='cuda:0') tensor(0.1989, device='cuda:0') tensor(-6.9345e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.055715
Average KL loss: 0.012069
Average total loss: 0.067783
tensor(0.0801, device='cuda:0') tensor(0.1993, device='cuda:0') tensor(-5.8614e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.057046
Average KL loss: 0.012099
Average total loss: 0.069145
tensor(0.0802, device='cuda:0') tensor(0.1999, device='cuda:0') tensor(-3.3769e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.055747
Average KL loss: 0.012132
Average total loss: 0.067879
tensor(0.0803, device='cuda:0') tensor(0.2004, device='cuda:0') tensor(-5.5347e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.055728
Average KL loss: 0.012160
Average total loss: 0.067888
tensor(0.0803, device='cuda:0') tensor(0.2009, device='cuda:0') tensor(-3.9138e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.051975
Average KL loss: 0.012183
Average total loss: 0.064158
tensor(0.0804, device='cuda:0') tensor(0.2013, device='cuda:0') tensor(-4.7946e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.053638
Average KL loss: 0.012210
Average total loss: 0.065848
tensor(0.0805, device='cuda:0') tensor(0.2018, device='cuda:0') tensor(-4.8762e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.052924
Average KL loss: 0.012240
Average total loss: 0.065163
tensor(0.0805, device='cuda:0') tensor(0.2024, device='cuda:0') tensor(-3.6590e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.050589
Average KL loss: 0.012266
Average total loss: 0.062856
tensor(0.0806, device='cuda:0') tensor(0.2028, device='cuda:0') tensor(-5.6281e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.050157
Average KL loss: 0.012291
Average total loss: 0.062448
tensor(0.0807, device='cuda:0') tensor(0.2033, device='cuda:0') tensor(-5.5842e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.050069
Average KL loss: 0.012315
Average total loss: 0.062384
tensor(0.0807, device='cuda:0') tensor(0.2038, device='cuda:0') tensor(-4.6535e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.048661
Average KL loss: 0.012337
Average total loss: 0.060997
tensor(0.0808, device='cuda:0') tensor(0.2042, device='cuda:0') tensor(-5.4562e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.049504
Average KL loss: 0.012361
Average total loss: 0.061865
tensor(0.0808, device='cuda:0') tensor(0.2047, device='cuda:0') tensor(-3.0410e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.047228
Average KL loss: 0.012384
Average total loss: 0.059611
tensor(0.0809, device='cuda:0') tensor(0.2051, device='cuda:0') tensor(-4.1559e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.047771
Average KL loss: 0.012406
Average total loss: 0.060177
tensor(0.0809, device='cuda:0') tensor(0.2056, device='cuda:0') tensor(-4.3032e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.047845
Average KL loss: 0.012432
Average total loss: 0.060276
tensor(0.0810, device='cuda:0') tensor(0.2061, device='cuda:0') tensor(-2.7494e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.046639
Average KL loss: 0.012457
Average total loss: 0.059095
tensor(0.0811, device='cuda:0') tensor(0.2065, device='cuda:0') tensor(-3.9184e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.045910
Average KL loss: 0.012481
Average total loss: 0.058391
tensor(0.0811, device='cuda:0') tensor(0.2070, device='cuda:0') tensor(-3.5679e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.044620
Average KL loss: 0.012501
Average total loss: 0.057121
tensor(0.0812, device='cuda:0') tensor(0.2074, device='cuda:0') tensor(-3.7041e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.044407
Average KL loss: 0.012519
Average total loss: 0.056926
tensor(0.0812, device='cuda:0') tensor(0.2079, device='cuda:0') tensor(-3.9990e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.046081
Average KL loss: 0.012541
Average total loss: 0.058623
tensor(0.0812, device='cuda:0') tensor(0.2083, device='cuda:0') tensor(-4.0686e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.043048
Average KL loss: 0.012561
Average total loss: 0.055609
tensor(0.0813, device='cuda:0') tensor(0.2088, device='cuda:0') tensor(-3.5975e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.041574
Average KL loss: 0.012577
Average total loss: 0.054151
tensor(0.0813, device='cuda:0') tensor(0.2091, device='cuda:0') tensor(-3.8765e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.041999
Average KL loss: 0.012593
Average total loss: 0.054591
tensor(0.0813, device='cuda:0') tensor(0.2095, device='cuda:0') tensor(-3.2391e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.041946
Average KL loss: 0.012610
Average total loss: 0.054555
tensor(0.0813, device='cuda:0') tensor(0.2099, device='cuda:0') tensor(-3.4595e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.041199
Average KL loss: 0.012627
Average total loss: 0.053826
tensor(0.0814, device='cuda:0') tensor(0.2103, device='cuda:0') tensor(-3.2304e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.040958
Average KL loss: 0.012645
Average total loss: 0.053603
tensor(0.0814, device='cuda:0') tensor(0.2107, device='cuda:0') tensor(-2.9285e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.040536
Average KL loss: 0.012662
Average total loss: 0.053198
tensor(0.0815, device='cuda:0') tensor(0.2112, device='cuda:0') tensor(-2.5430e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.040794
Average KL loss: 0.012681
Average total loss: 0.053475
tensor(0.0815, device='cuda:0') tensor(0.2116, device='cuda:0') tensor(-1.8089e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.038940
Average KL loss: 0.012700
Average total loss: 0.051640
tensor(0.0816, device='cuda:0') tensor(0.2120, device='cuda:0') tensor(-2.7242e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.038235
Average KL loss: 0.012714
Average total loss: 0.050949
tensor(0.0815, device='cuda:0') tensor(0.2124, device='cuda:0') tensor(-3.3103e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.038750
Average KL loss: 0.012727
Average total loss: 0.051477
tensor(0.0816, device='cuda:0') tensor(0.2127, device='cuda:0') tensor(-2.7710e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.038255
Average KL loss: 0.012743
Average total loss: 0.050998
tensor(0.0816, device='cuda:0') tensor(0.2131, device='cuda:0') tensor(-2.7418e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.037445
Average KL loss: 0.012758
Average total loss: 0.050203
tensor(0.0816, device='cuda:0') tensor(0.2135, device='cuda:0') tensor(-3.0597e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.037472
Average KL loss: 0.012771
Average total loss: 0.050243
tensor(0.0816, device='cuda:0') tensor(0.2139, device='cuda:0') tensor(-4.2431e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.037268
Average KL loss: 0.012785
Average total loss: 0.050053
tensor(0.0816, device='cuda:0') tensor(0.2143, device='cuda:0') tensor(-2.7175e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.036293
Average KL loss: 0.012799
Average total loss: 0.049093
tensor(0.0817, device='cuda:0') tensor(0.2147, device='cuda:0') tensor(-2.0763e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.035669
Average KL loss: 0.012811
Average total loss: 0.048480
tensor(0.0817, device='cuda:0') tensor(0.2151, device='cuda:0') tensor(-3.4505e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.035683
Average KL loss: 0.012826
Average total loss: 0.048508
tensor(0.0817, device='cuda:0') tensor(0.2154, device='cuda:0') tensor(-1.7695e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.035822
Average KL loss: 0.012838
Average total loss: 0.048660
tensor(0.0817, device='cuda:0') tensor(0.2158, device='cuda:0') tensor(-2.4978e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.034625
Average KL loss: 0.012849
Average total loss: 0.047474
tensor(0.0817, device='cuda:0') tensor(0.2161, device='cuda:0') tensor(-2.0158e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.035707
Average KL loss: 0.012859
Average total loss: 0.048566
tensor(0.0817, device='cuda:0') tensor(0.2165, device='cuda:0') tensor(-3.7435e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.034562
Average KL loss: 0.012876
Average total loss: 0.047438
tensor(0.0817, device='cuda:0') tensor(0.2169, device='cuda:0') tensor(-1.3931e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.033379
Average KL loss: 0.012883
Average total loss: 0.046262
tensor(0.0817, device='cuda:0') tensor(0.2172, device='cuda:0') tensor(-2.8480e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.034293
Average KL loss: 0.012894
Average total loss: 0.047187
tensor(0.0817, device='cuda:0') tensor(0.2175, device='cuda:0') tensor(-2.5085e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.033913
Average KL loss: 0.012907
Average total loss: 0.046821
tensor(0.0817, device='cuda:0') tensor(0.2179, device='cuda:0') tensor(-1.7266e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.033265
Average KL loss: 0.012919
Average total loss: 0.046184
tensor(0.0817, device='cuda:0') tensor(0.2183, device='cuda:0') tensor(-1.4112e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.032381
Average KL loss: 0.012930
Average total loss: 0.045311
tensor(0.0817, device='cuda:0') tensor(0.2186, device='cuda:0') tensor(-2.9402e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.032289
Average KL loss: 0.012938
Average total loss: 0.045227
tensor(0.0817, device='cuda:0') tensor(0.2190, device='cuda:0') tensor(-2.2107e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.032291
Average KL loss: 0.012947
Average total loss: 0.045238
tensor(0.0817, device='cuda:0') tensor(0.2193, device='cuda:0') tensor(-1.5779e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.032536
Average KL loss: 0.012957
Average total loss: 0.045493
tensor(0.0817, device='cuda:0') tensor(0.2196, device='cuda:0') tensor(-2.2001e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.032154
Average KL loss: 0.012970
Average total loss: 0.045124
tensor(0.0818, device='cuda:0') tensor(0.2200, device='cuda:0') tensor(-1.2271e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.031536
Average KL loss: 0.012981
Average total loss: 0.044517
tensor(0.0818, device='cuda:0') tensor(0.2204, device='cuda:0') tensor(-1.3598e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.031201
Average KL loss: 0.012990
Average total loss: 0.044191
tensor(0.0818, device='cuda:0') tensor(0.2207, device='cuda:0') tensor(-2.1503e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.031312
Average KL loss: 0.012999
Average total loss: 0.044310
tensor(0.0818, device='cuda:0') tensor(0.2210, device='cuda:0') tensor(-2.1834e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.030523
Average KL loss: 0.013008
Average total loss: 0.043531
tensor(0.0818, device='cuda:0') tensor(0.2214, device='cuda:0') tensor(-2.1833e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.029256
Average KL loss: 0.013013
Average total loss: 0.042268
tensor(0.0817, device='cuda:0') tensor(0.2216, device='cuda:0') tensor(-2.3162e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.030447
Average KL loss: 0.013018
Average total loss: 0.043466
tensor(0.0817, device='cuda:0') tensor(0.2219, device='cuda:0') tensor(-2.4624e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.029697
Average KL loss: 0.013027
Average total loss: 0.042724
tensor(0.0817, device='cuda:0') tensor(0.2223, device='cuda:0') tensor(-1.7403e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.029474
Average KL loss: 0.013032
Average total loss: 0.042506
tensor(0.0817, device='cuda:0') tensor(0.2226, device='cuda:0') tensor(-9.7498e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.029440
Average KL loss: 0.013039
Average total loss: 0.042479
tensor(0.0817, device='cuda:0') tensor(0.2229, device='cuda:0') tensor(-1.8296e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.028901
Average KL loss: 0.013046
Average total loss: 0.041947
tensor(0.0817, device='cuda:0') tensor(0.2232, device='cuda:0') tensor(-2.2816e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.028601
Average KL loss: 0.013053
Average total loss: 0.041654
tensor(0.0817, device='cuda:0') tensor(0.2235, device='cuda:0') tensor(-1.7205e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.028442
Average KL loss: 0.013057
Average total loss: 0.041500
tensor(0.0816, device='cuda:0') tensor(0.2238, device='cuda:0') tensor(-1.4994e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.029272
Average KL loss: 0.013062
Average total loss: 0.042334
tensor(0.0816, device='cuda:0') tensor(0.2241, device='cuda:0') tensor(-2.2089e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.028412
Average KL loss: 0.013072
Average total loss: 0.041483
tensor(0.0816, device='cuda:0') tensor(0.2244, device='cuda:0') tensor(-1.0692e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.028477
Average KL loss: 0.013077
Average total loss: 0.041554
tensor(0.0816, device='cuda:0') tensor(0.2247, device='cuda:0') tensor(-2.5418e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.028746
Average KL loss: 0.013085
Average total loss: 0.041831
tensor(0.0816, device='cuda:0') tensor(0.2251, device='cuda:0') tensor(-1.2867e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.027861
Average KL loss: 0.013093
Average total loss: 0.040953
tensor(0.0816, device='cuda:0') tensor(0.2254, device='cuda:0') tensor(-9.6092e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.027667
Average KL loss: 0.013097
Average total loss: 0.040764
tensor(0.0816, device='cuda:0') tensor(0.2257, device='cuda:0') tensor(-1.2090e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.026596
Average KL loss: 0.013101
Average total loss: 0.039697
tensor(0.0815, device='cuda:0') tensor(0.2260, device='cuda:0') tensor(-1.9386e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.027287
Average KL loss: 0.013103
Average total loss: 0.040390
tensor(0.0815, device='cuda:0') tensor(0.2262, device='cuda:0') tensor(-1.3437e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.026896
Average KL loss: 0.013108
Average total loss: 0.040004
tensor(0.0815, device='cuda:0') tensor(0.2265, device='cuda:0') tensor(-2.1579e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.026196
Average KL loss: 0.013110
Average total loss: 0.039306
tensor(0.0815, device='cuda:0') tensor(0.2268, device='cuda:0') tensor(-1.9810e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.026703
Average KL loss: 0.013112
Average total loss: 0.039816
tensor(0.0814, device='cuda:0') tensor(0.2271, device='cuda:0') tensor(-1.7296e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.026569
Average KL loss: 0.013118
Average total loss: 0.039687
tensor(0.0814, device='cuda:0') tensor(0.2274, device='cuda:0') tensor(-1.4350e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.025801
Average KL loss: 0.013123
Average total loss: 0.038924
tensor(0.0814, device='cuda:0') tensor(0.2277, device='cuda:0') tensor(-1.3755e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.025483
Average KL loss: 0.013124
Average total loss: 0.038606
tensor(0.0814, device='cuda:0') tensor(0.2279, device='cuda:0') tensor(-9.6667e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.025459
Average KL loss: 0.013125
Average total loss: 0.038585
tensor(0.0814, device='cuda:0') tensor(0.2282, device='cuda:0') tensor(-1.4848e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.025984
Average KL loss: 0.013127
Average total loss: 0.039111
tensor(0.0813, device='cuda:0') tensor(0.2285, device='cuda:0') tensor(-8.9470e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.025275
Average KL loss: 0.013130
Average total loss: 0.038406
tensor(0.0813, device='cuda:0') tensor(0.2288, device='cuda:0') tensor(-1.0873e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.025393
Average KL loss: 0.013135
Average total loss: 0.038528
tensor(0.0813, device='cuda:0') tensor(0.2291, device='cuda:0') tensor(-7.3112e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.025187
Average KL loss: 0.013137
Average total loss: 0.038323
tensor(0.0812, device='cuda:0') tensor(0.2293, device='cuda:0') tensor(-6.0805e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.024611
Average KL loss: 0.013139
Average total loss: 0.037750
tensor(0.0812, device='cuda:0') tensor(0.2296, device='cuda:0') tensor(-1.7302e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.025058
Average KL loss: 0.013140
Average total loss: 0.038199
tensor(0.0812, device='cuda:0') tensor(0.2299, device='cuda:0') tensor(-1.4743e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.024415
Average KL loss: 0.013144
Average total loss: 0.037558
tensor(0.0812, device='cuda:0') tensor(0.2301, device='cuda:0') tensor(-7.0306e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.024291
Average KL loss: 0.013145
Average total loss: 0.037436
tensor(0.0811, device='cuda:0') tensor(0.2304, device='cuda:0') tensor(-9.7129e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.024371
Average KL loss: 0.013146
Average total loss: 0.037517
tensor(0.0811, device='cuda:0') tensor(0.2306, device='cuda:0') tensor(-1.6608e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.023859
Average KL loss: 0.013150
Average total loss: 0.037009
tensor(0.0811, device='cuda:0') tensor(0.2309, device='cuda:0') tensor(-1.1852e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.024000
Average KL loss: 0.013152
Average total loss: 0.037152
tensor(0.0811, device='cuda:0') tensor(0.2312, device='cuda:0') tensor(-7.8563e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.024307
Average KL loss: 0.013151
Average total loss: 0.037458
tensor(0.0810, device='cuda:0') tensor(0.2314, device='cuda:0') tensor(-7.8497e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.023629
Average KL loss: 0.013154
Average total loss: 0.036783
tensor(0.0810, device='cuda:0') tensor(0.2317, device='cuda:0') tensor(-6.7103e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.023676
Average KL loss: 0.013154
Average total loss: 0.036830
tensor(0.0809, device='cuda:0') tensor(0.2319, device='cuda:0') tensor(-9.4716e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.023890
Average KL loss: 0.013155
Average total loss: 0.037046
tensor(0.0809, device='cuda:0') tensor(0.2322, device='cuda:0') tensor(-1.2058e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.023069
Average KL loss: 0.013158
Average total loss: 0.036227
tensor(0.0809, device='cuda:0') tensor(0.2324, device='cuda:0') tensor(-7.2620e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.023690
Average KL loss: 0.013160
Average total loss: 0.036850
tensor(0.0809, device='cuda:0') tensor(0.2327, device='cuda:0') tensor(-7.2057e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.023423
Average KL loss: 0.013161
Average total loss: 0.036584
tensor(0.0808, device='cuda:0') tensor(0.2330, device='cuda:0') tensor(-1.1167e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.022997
Average KL loss: 0.013163
Average total loss: 0.036160
tensor(0.0808, device='cuda:0') tensor(0.2333, device='cuda:0') tensor(-9.2420e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.023203
Average KL loss: 0.013166
Average total loss: 0.036369
tensor(0.0808, device='cuda:0') tensor(0.2335, device='cuda:0') tensor(-9.7615e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.022754
Average KL loss: 0.013166
Average total loss: 0.035920
tensor(0.0808, device='cuda:0') tensor(0.2338, device='cuda:0') tensor(-6.4973e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.022474
Average KL loss: 0.013165
Average total loss: 0.035639
tensor(0.0807, device='cuda:0') tensor(0.2340, device='cuda:0') tensor(-1.2878e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.022440
Average KL loss: 0.013166
Average total loss: 0.035607
tensor(0.0807, device='cuda:0') tensor(0.2343, device='cuda:0') tensor(-9.0142e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.022159
Average KL loss: 0.013165
Average total loss: 0.035324
tensor(0.0806, device='cuda:0') tensor(0.2345, device='cuda:0') tensor(-6.0189e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.021847
Average KL loss: 0.013162
Average total loss: 0.035009
tensor(0.0806, device='cuda:0') tensor(0.2347, device='cuda:0') tensor(-5.7922e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.021982
Average KL loss: 0.013158
Average total loss: 0.035140
tensor(0.0805, device='cuda:0') tensor(0.2349, device='cuda:0') tensor(-7.2009e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.021826
Average KL loss: 0.013157
Average total loss: 0.034983
tensor(0.0805, device='cuda:0') tensor(0.2351, device='cuda:0') tensor(-8.7311e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.022351
Average KL loss: 0.013161
Average total loss: 0.035512
tensor(0.0805, device='cuda:0') tensor(0.2354, device='cuda:0') tensor(-3.7385e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.021585
Average KL loss: 0.013160
Average total loss: 0.034745
tensor(0.0805, device='cuda:0') tensor(0.2356, device='cuda:0') tensor(-7.5468e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.021407
Average KL loss: 0.013159
Average total loss: 0.034565
tensor(0.0804, device='cuda:0') tensor(0.2358, device='cuda:0') tensor(-8.6986e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.021727
Average KL loss: 0.013159
Average total loss: 0.034885
tensor(0.0804, device='cuda:0') tensor(0.2361, device='cuda:0') tensor(-6.3522e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.021291
Average KL loss: 0.013157
Average total loss: 0.034448
tensor(0.0803, device='cuda:0') tensor(0.2363, device='cuda:0') tensor(-8.0667e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.021382
Average KL loss: 0.013153
Average total loss: 0.034536
tensor(0.0803, device='cuda:0') tensor(0.2365, device='cuda:0') tensor(-5.8515e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.020955
Average KL loss: 0.013153
Average total loss: 0.034108
tensor(0.0803, device='cuda:0') tensor(0.2367, device='cuda:0') tensor(-6.4037e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.021025
Average KL loss: 0.013150
Average total loss: 0.034175
tensor(0.0802, device='cuda:0') tensor(0.2370, device='cuda:0') tensor(-5.9136e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.021146
Average KL loss: 0.013150
Average total loss: 0.034296
tensor(0.0802, device='cuda:0') tensor(0.2372, device='cuda:0') tensor(-6.1399e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.020906
Average KL loss: 0.013147
Average total loss: 0.034053
tensor(0.0801, device='cuda:0') tensor(0.2374, device='cuda:0') tensor(-8.7924e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.020855
Average KL loss: 0.013144
Average total loss: 0.033999
tensor(0.0801, device='cuda:0') tensor(0.2376, device='cuda:0') tensor(-1.5239e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.020698
Average KL loss: 0.013143
Average total loss: 0.033841
tensor(0.0801, device='cuda:0') tensor(0.2379, device='cuda:0') tensor(-5.8045e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.020386
Average KL loss: 0.013141
Average total loss: 0.033527
tensor(0.0800, device='cuda:0') tensor(0.2381, device='cuda:0') tensor(-5.0250e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.020643
Average KL loss: 0.013139
Average total loss: 0.033782
tensor(0.0800, device='cuda:0') tensor(0.2383, device='cuda:0') tensor(-7.4032e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.020743
Average KL loss: 0.013138
Average total loss: 0.033881
tensor(0.0799, device='cuda:0') tensor(0.2386, device='cuda:0') tensor(-2.8056e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.020332
Average KL loss: 0.013138
Average total loss: 0.033470
tensor(0.0799, device='cuda:0') tensor(0.2388, device='cuda:0') tensor(-4.3722e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.020157
Average KL loss: 0.013133
Average total loss: 0.033290
tensor(0.0798, device='cuda:0') tensor(0.2390, device='cuda:0') tensor(-3.6547e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.020019
Average KL loss: 0.013131
Average total loss: 0.033149
tensor(0.0798, device='cuda:0') tensor(0.2392, device='cuda:0') tensor(-5.6200e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.020056
Average KL loss: 0.013125
Average total loss: 0.033181
tensor(0.0797, device='cuda:0') tensor(0.2394, device='cuda:0') tensor(-2.6850e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.019970
Average KL loss: 0.013123
Average total loss: 0.033092
tensor(0.0797, device='cuda:0') tensor(0.2396, device='cuda:0') tensor(-6.8275e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.019782
Average KL loss: 0.013121
Average total loss: 0.032903
tensor(0.0796, device='cuda:0') tensor(0.2398, device='cuda:0') tensor(-7.8026e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.019590
Average KL loss: 0.013116
Average total loss: 0.032707
tensor(0.0796, device='cuda:0') tensor(0.2400, device='cuda:0') tensor(-3.6420e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.019779
Average KL loss: 0.013112
Average total loss: 0.032892
tensor(0.0795, device='cuda:0') tensor(0.2403, device='cuda:0') tensor(-2.1107e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.019579
Average KL loss: 0.013108
Average total loss: 0.032688
tensor(0.0795, device='cuda:0') tensor(0.2404, device='cuda:0') tensor(-1.0518e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.019260
Average KL loss: 0.013106
Average total loss: 0.032366
tensor(0.0795, device='cuda:0') tensor(0.2406, device='cuda:0') tensor(-5.7274e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.019571
Average KL loss: 0.013103
Average total loss: 0.032674
tensor(0.0794, device='cuda:0') tensor(0.2408, device='cuda:0') tensor(-3.5178e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.019533
Average KL loss: 0.013100
Average total loss: 0.032633
tensor(0.0794, device='cuda:0') tensor(0.2411, device='cuda:0') tensor(-5.1490e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.019517
Average KL loss: 0.013098
Average total loss: 0.032615
tensor(0.0793, device='cuda:0') tensor(0.2413, device='cuda:0') tensor(-5.9528e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.019283
Average KL loss: 0.013095
Average total loss: 0.032378
tensor(0.0793, device='cuda:0') tensor(0.2415, device='cuda:0') tensor(-3.8591e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.019073
Average KL loss: 0.013092
Average total loss: 0.032165
tensor(0.0792, device='cuda:0') tensor(0.2417, device='cuda:0') tensor(-4.3821e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.018994
Average KL loss: 0.013088
Average total loss: 0.032082
tensor(0.0792, device='cuda:0') tensor(0.2419, device='cuda:0') tensor(-1.6626e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.019155
Average KL loss: 0.013085
Average total loss: 0.032240
tensor(0.0791, device='cuda:0') tensor(0.2421, device='cuda:0') tensor(-2.2352e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.018873
Average KL loss: 0.013081
Average total loss: 0.031954
tensor(0.0791, device='cuda:0') tensor(0.2423, device='cuda:0') tensor(-6.1240e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.018879
Average KL loss: 0.013077
Average total loss: 0.031956
tensor(0.0791, device='cuda:0') tensor(0.2425, device='cuda:0') tensor(-1.6105e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.018726
Average KL loss: 0.013074
Average total loss: 0.031800
tensor(0.0790, device='cuda:0') tensor(0.2427, device='cuda:0') tensor(-3.7708e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.019063
Average KL loss: 0.013072
Average total loss: 0.032135
tensor(0.0790, device='cuda:0') tensor(0.2430, device='cuda:0') tensor(-4.0337e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.018559
Average KL loss: 0.013070
Average total loss: 0.031629
tensor(0.0789, device='cuda:0') tensor(0.2432, device='cuda:0') tensor(-5.5308e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.018970
Average KL loss: 0.013067
Average total loss: 0.032037
tensor(0.0789, device='cuda:0') tensor(0.2434, device='cuda:0') tensor(-3.3012e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.018260
Average KL loss: 0.013065
Average total loss: 0.031325
tensor(0.0788, device='cuda:0') tensor(0.2436, device='cuda:0') tensor(-5.2015e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.018639
Average KL loss: 0.013060
Average total loss: 0.031699
tensor(0.0788, device='cuda:0') tensor(0.2439, device='cuda:0') tensor(-3.6544e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.018250
Average KL loss: 0.013058
Average total loss: 0.031308
tensor(0.0788, device='cuda:0') tensor(0.2441, device='cuda:0') tensor(-5.6678e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.018807
Average KL loss: 0.013055
Average total loss: 0.031863
tensor(0.0787, device='cuda:0') tensor(0.2443, device='cuda:0') tensor(-3.5659e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.018388
Average KL loss: 0.013057
Average total loss: 0.031445
tensor(0.0787, device='cuda:0') tensor(0.2446, device='cuda:0') tensor(-4.2362e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.018772
Average KL loss: 0.013055
Average total loss: 0.031827
tensor(0.0786, device='cuda:0') tensor(0.2448, device='cuda:0') tensor(-3.0909e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.018012
Average KL loss: 0.013052
Average total loss: 0.031064
tensor(0.0786, device='cuda:0') tensor(0.2450, device='cuda:0') tensor(-2.6352e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.018035
Average KL loss: 0.013044
Average total loss: 0.031079
tensor(0.0785, device='cuda:0') tensor(0.2452, device='cuda:0') tensor(-7.2552e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.018307
Average KL loss: 0.013041
Average total loss: 0.031348
tensor(0.0785, device='cuda:0') tensor(0.2455, device='cuda:0') tensor(-1.9377e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.017736
Average KL loss: 0.013038
Average total loss: 0.030774
tensor(0.0785, device='cuda:0') tensor(0.2456, device='cuda:0') tensor(-2.3148e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.018111
Average KL loss: 0.013032
Average total loss: 0.031143
tensor(0.0784, device='cuda:0') tensor(0.2458, device='cuda:0') tensor(-3.6255e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.017851
Average KL loss: 0.013027
Average total loss: 0.030878
tensor(0.0784, device='cuda:0') tensor(0.2461, device='cuda:0') tensor(-3.0432e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.017547
Average KL loss: 0.013021
Average total loss: 0.030568
tensor(0.0783, device='cuda:0') tensor(0.2462, device='cuda:0') tensor(4.4793e-12, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.017672
Average KL loss: 0.013014
Average total loss: 0.030686
tensor(0.0783, device='cuda:0') tensor(0.2464, device='cuda:0') tensor(-3.4478e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.017583
Average KL loss: 0.013008
Average total loss: 0.030591
 Percentile value: 0.7763556241989136
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =     168 /    1728             (  9.72%) | total_pruned =    1560 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     434 /   36864             (  1.18%) | total_pruned =   36430 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     793 /   36864             (  2.15%) | total_pruned =   36071 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1220 /   36864             (  3.31%) | total_pruned =   35644 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2647 /   36864             (  7.18%) | total_pruned =   34217 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    9411 /   73728             ( 12.76%) | total_pruned =   64317 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   17578 /  147456             ( 11.92%) | total_pruned =  129878 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1358 /    8192             ( 16.58%) | total_pruned =    6834 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   10110 /  147456             (  6.86%) | total_pruned =  137346 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    9752 /  147456             (  6.61%) | total_pruned =  137704 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   36365 /  294912             ( 12.33%) | total_pruned =  258547 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     167 /     256             ( 65.23%) | total_pruned =      89 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      68 /     256             ( 26.56%) | total_pruned =     188 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   47595 /  589824             (  8.07%) | total_pruned =  542229 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4254 /   32768             ( 12.98%) | total_pruned =   28514 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      72 /     256             ( 28.12%) | total_pruned =     184 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   37418 /  589824             (  6.34%) | total_pruned =  552406 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     187 /     256             ( 73.05%) | total_pruned =      69 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   36116 /  589824             (  6.12%) | total_pruned =  553708 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   86460 / 1179648             (  7.33%) | total_pruned = 1093188 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     338 /     512             ( 66.02%) | total_pruned =     174 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     132 /     512             ( 25.78%) | total_pruned =     380 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  138042 / 2359296             (  5.85%) | total_pruned = 2221254 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     436 /     512             ( 85.16%) | total_pruned =      76 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     319 /     512             ( 62.30%) | total_pruned =     193 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4550 /  131072             (  3.47%) | total_pruned =  126522 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     250 /     512             ( 48.83%) | total_pruned =     262 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     320 /     512             ( 62.50%) | total_pruned =     192 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   74656 / 2359296             (  3.16%) | total_pruned = 2284640 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     304 /     512             ( 59.38%) | total_pruned =     208 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  170190 / 2359296             (  7.21%) | total_pruned = 2189106 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     479 /     512             ( 93.55%) | total_pruned =      33 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
linear.weight        | nonzeros =    4603 /    5120             ( 89.90%) | total_pruned =     517 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 43/100 Loss: 0.020793 Accuracy: 85.78 100.00 % Best test Accuracy: 86.03%
tensor(0.0782, device='cuda:0') tensor(0.2466, device='cuda:0') tensor(-1.9668e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.159794
Average KL loss: 0.012628
Average total loss: 0.172422
tensor(0.0773, device='cuda:0') tensor(0.2349, device='cuda:0') tensor(-1.4152e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.141360
Average KL loss: 0.012152
Average total loss: 0.153512
tensor(0.0768, device='cuda:0') tensor(0.2287, device='cuda:0') tensor(-1.4408e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.133363
Average KL loss: 0.011829
Average total loss: 0.145192
tensor(0.0762, device='cuda:0') tensor(0.2242, device='cuda:0') tensor(-1.6124e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.129466
Average KL loss: 0.011586
Average total loss: 0.141052
tensor(0.0754, device='cuda:0') tensor(0.2208, device='cuda:0') tensor(-1.2969e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.121809
Average KL loss: 0.011399
Average total loss: 0.133209
tensor(0.0747, device='cuda:0') tensor(0.2183, device='cuda:0') tensor(-1.4678e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.117810
Average KL loss: 0.011261
Average total loss: 0.129071
tensor(0.0741, device='cuda:0') tensor(0.2165, device='cuda:0') tensor(-1.3311e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.112130
Average KL loss: 0.011158
Average total loss: 0.123288
tensor(0.0735, device='cuda:0') tensor(0.2152, device='cuda:0') tensor(-1.0180e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.107991
Average KL loss: 0.011089
Average total loss: 0.119080
tensor(0.0730, device='cuda:0') tensor(0.2143, device='cuda:0') tensor(-9.4589e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.104115
Average KL loss: 0.011045
Average total loss: 0.115159
tensor(0.0727, device='cuda:0') tensor(0.2138, device='cuda:0') tensor(-8.9045e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.102243
Average KL loss: 0.011021
Average total loss: 0.113264
tensor(0.0724, device='cuda:0') tensor(0.2134, device='cuda:0') tensor(-1.1746e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.099407
Average KL loss: 0.011015
Average total loss: 0.110422
tensor(0.0723, device='cuda:0') tensor(0.2133, device='cuda:0') tensor(-9.6974e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.094325
Average KL loss: 0.011018
Average total loss: 0.105343
tensor(0.0722, device='cuda:0') tensor(0.2133, device='cuda:0') tensor(-8.5856e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.091535
Average KL loss: 0.011028
Average total loss: 0.102563
tensor(0.0721, device='cuda:0') tensor(0.2134, device='cuda:0') tensor(-8.1478e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.090668
Average KL loss: 0.011041
Average total loss: 0.101709
tensor(0.0721, device='cuda:0') tensor(0.2135, device='cuda:0') tensor(-8.7768e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.086325
Average KL loss: 0.011058
Average total loss: 0.097383
tensor(0.0721, device='cuda:0') tensor(0.2137, device='cuda:0') tensor(-7.7186e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.086533
Average KL loss: 0.011078
Average total loss: 0.097611
tensor(0.0721, device='cuda:0') tensor(0.2139, device='cuda:0') tensor(-6.7834e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.084626
Average KL loss: 0.011098
Average total loss: 0.095724
tensor(0.0721, device='cuda:0') tensor(0.2141, device='cuda:0') tensor(-3.6847e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.081949
Average KL loss: 0.011118
Average total loss: 0.093068
tensor(0.0722, device='cuda:0') tensor(0.2144, device='cuda:0') tensor(-6.7790e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.083061
Average KL loss: 0.011140
Average total loss: 0.094202
tensor(0.0722, device='cuda:0') tensor(0.2147, device='cuda:0') tensor(-6.0482e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.080779
Average KL loss: 0.011160
Average total loss: 0.091940
tensor(0.0723, device='cuda:0') tensor(0.2149, device='cuda:0') tensor(-6.1762e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.077459
Average KL loss: 0.011181
Average total loss: 0.088640
tensor(0.0723, device='cuda:0') tensor(0.2152, device='cuda:0') tensor(-6.8694e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.075378
Average KL loss: 0.011201
Average total loss: 0.086579
tensor(0.0724, device='cuda:0') tensor(0.2155, device='cuda:0') tensor(-7.0743e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.074823
Average KL loss: 0.011222
Average total loss: 0.086045
tensor(0.0724, device='cuda:0') tensor(0.2159, device='cuda:0') tensor(-5.4928e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.075214
Average KL loss: 0.011243
Average total loss: 0.086457
tensor(0.0725, device='cuda:0') tensor(0.2162, device='cuda:0') tensor(-5.9652e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.072179
Average KL loss: 0.011262
Average total loss: 0.083441
tensor(0.0725, device='cuda:0') tensor(0.2165, device='cuda:0') tensor(-4.7910e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.071262
Average KL loss: 0.011282
Average total loss: 0.082544
tensor(0.0726, device='cuda:0') tensor(0.2168, device='cuda:0') tensor(-5.9077e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.069797
Average KL loss: 0.011302
Average total loss: 0.081100
tensor(0.0726, device='cuda:0') tensor(0.2171, device='cuda:0') tensor(-5.7671e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.068328
Average KL loss: 0.011323
Average total loss: 0.079650
tensor(0.0727, device='cuda:0') tensor(0.2175, device='cuda:0') tensor(-5.7988e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.067361
Average KL loss: 0.011342
Average total loss: 0.078703
tensor(0.0728, device='cuda:0') tensor(0.2178, device='cuda:0') tensor(-3.1928e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.066116
Average KL loss: 0.011361
Average total loss: 0.077477
tensor(0.0728, device='cuda:0') tensor(0.2182, device='cuda:0') tensor(-5.4796e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.063291
Average KL loss: 0.011377
Average total loss: 0.074668
tensor(0.0728, device='cuda:0') tensor(0.2185, device='cuda:0') tensor(-4.5875e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.062899
Average KL loss: 0.011393
Average total loss: 0.074291
tensor(0.0729, device='cuda:0') tensor(0.2188, device='cuda:0') tensor(-5.9223e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.061704
Average KL loss: 0.011411
Average total loss: 0.073115
tensor(0.0729, device='cuda:0') tensor(0.2191, device='cuda:0') tensor(-6.1867e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.060559
Average KL loss: 0.011426
Average total loss: 0.071986
tensor(0.0730, device='cuda:0') tensor(0.2194, device='cuda:0') tensor(-4.9926e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.061222
Average KL loss: 0.011442
Average total loss: 0.072664
tensor(0.0730, device='cuda:0') tensor(0.2198, device='cuda:0') tensor(-4.1867e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.060351
Average KL loss: 0.011459
Average total loss: 0.071810
tensor(0.0731, device='cuda:0') tensor(0.2201, device='cuda:0') tensor(-6.1721e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.059266
Average KL loss: 0.011477
Average total loss: 0.070743
tensor(0.0731, device='cuda:0') tensor(0.2205, device='cuda:0') tensor(-6.7279e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.056543
Average KL loss: 0.011494
Average total loss: 0.068037
tensor(0.0732, device='cuda:0') tensor(0.2208, device='cuda:0') tensor(-4.4042e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.057803
Average KL loss: 0.011510
Average total loss: 0.069314
tensor(0.0732, device='cuda:0') tensor(0.2212, device='cuda:0') tensor(-3.7281e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.057163
Average KL loss: 0.011527
Average total loss: 0.068690
tensor(0.0733, device='cuda:0') tensor(0.2216, device='cuda:0') tensor(-4.5235e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.055459
Average KL loss: 0.011543
Average total loss: 0.067002
tensor(0.0733, device='cuda:0') tensor(0.2219, device='cuda:0') tensor(-5.1728e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.055139
Average KL loss: 0.011558
Average total loss: 0.066697
tensor(0.0734, device='cuda:0') tensor(0.2223, device='cuda:0') tensor(-4.9248e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.054032
Average KL loss: 0.011576
Average total loss: 0.065608
tensor(0.0734, device='cuda:0') tensor(0.2227, device='cuda:0') tensor(-4.3372e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.053409
Average KL loss: 0.011591
Average total loss: 0.064999
tensor(0.0734, device='cuda:0') tensor(0.2230, device='cuda:0') tensor(-2.9480e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.053036
Average KL loss: 0.011606
Average total loss: 0.064642
tensor(0.0735, device='cuda:0') tensor(0.2234, device='cuda:0') tensor(-5.2144e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.051825
Average KL loss: 0.011620
Average total loss: 0.063444
tensor(0.0735, device='cuda:0') tensor(0.2237, device='cuda:0') tensor(-3.7610e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.051499
Average KL loss: 0.011633
Average total loss: 0.063132
tensor(0.0736, device='cuda:0') tensor(0.2241, device='cuda:0') tensor(-4.2546e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.050587
Average KL loss: 0.011646
Average total loss: 0.062233
tensor(0.0736, device='cuda:0') tensor(0.2245, device='cuda:0') tensor(-4.6519e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.049751
Average KL loss: 0.011659
Average total loss: 0.061410
tensor(0.0736, device='cuda:0') tensor(0.2248, device='cuda:0') tensor(-3.6116e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.048942
Average KL loss: 0.011674
Average total loss: 0.060616
tensor(0.0737, device='cuda:0') tensor(0.2252, device='cuda:0') tensor(-2.8997e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.049483
Average KL loss: 0.011689
Average total loss: 0.061171
tensor(0.0737, device='cuda:0') tensor(0.2256, device='cuda:0') tensor(-4.4432e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.047592
Average KL loss: 0.011703
Average total loss: 0.059295
tensor(0.0738, device='cuda:0') tensor(0.2260, device='cuda:0') tensor(-3.7262e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.047842
Average KL loss: 0.011714
Average total loss: 0.059556
tensor(0.0738, device='cuda:0') tensor(0.2263, device='cuda:0') tensor(-2.4639e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.046298
Average KL loss: 0.011729
Average total loss: 0.058027
tensor(0.0738, device='cuda:0') tensor(0.2267, device='cuda:0') tensor(-3.4145e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.045517
Average KL loss: 0.011743
Average total loss: 0.057260
tensor(0.0739, device='cuda:0') tensor(0.2271, device='cuda:0') tensor(-3.2576e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.045357
Average KL loss: 0.011755
Average total loss: 0.057112
tensor(0.0739, device='cuda:0') tensor(0.2274, device='cuda:0') tensor(-3.2124e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.044866
Average KL loss: 0.011766
Average total loss: 0.056632
tensor(0.0739, device='cuda:0') tensor(0.2277, device='cuda:0') tensor(-3.5386e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.044309
Average KL loss: 0.011776
Average total loss: 0.056086
tensor(0.0740, device='cuda:0') tensor(0.2281, device='cuda:0') tensor(-1.9147e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.043206
Average KL loss: 0.011787
Average total loss: 0.054993
tensor(0.0740, device='cuda:0') tensor(0.2285, device='cuda:0') tensor(-3.9816e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.043587
Average KL loss: 0.011799
Average total loss: 0.055386
tensor(0.0740, device='cuda:0') tensor(0.2288, device='cuda:0') tensor(-3.5767e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.044257
Average KL loss: 0.011811
Average total loss: 0.056068
tensor(0.0741, device='cuda:0') tensor(0.2292, device='cuda:0') tensor(-3.1266e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.043359
Average KL loss: 0.011824
Average total loss: 0.055182
tensor(0.0741, device='cuda:0') tensor(0.2296, device='cuda:0') tensor(-3.2531e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.042696
Average KL loss: 0.011835
Average total loss: 0.054531
tensor(0.0741, device='cuda:0') tensor(0.2300, device='cuda:0') tensor(-2.6208e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.042062
Average KL loss: 0.011846
Average total loss: 0.053907
tensor(0.0741, device='cuda:0') tensor(0.2303, device='cuda:0') tensor(-2.9767e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.040620
Average KL loss: 0.011857
Average total loss: 0.052476
tensor(0.0742, device='cuda:0') tensor(0.2307, device='cuda:0') tensor(-2.8527e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.039986
Average KL loss: 0.011868
Average total loss: 0.051853
tensor(0.0742, device='cuda:0') tensor(0.2310, device='cuda:0') tensor(-3.9081e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.040370
Average KL loss: 0.011878
Average total loss: 0.052247
tensor(0.0742, device='cuda:0') tensor(0.2314, device='cuda:0') tensor(-2.8309e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.039250
Average KL loss: 0.011886
Average total loss: 0.051136
tensor(0.0742, device='cuda:0') tensor(0.2317, device='cuda:0') tensor(-1.9072e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.038722
Average KL loss: 0.011892
Average total loss: 0.050614
tensor(0.0743, device='cuda:0') tensor(0.2320, device='cuda:0') tensor(-2.0116e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.039255
Average KL loss: 0.011901
Average total loss: 0.051157
tensor(0.0743, device='cuda:0') tensor(0.2324, device='cuda:0') tensor(-2.4663e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.037700
Average KL loss: 0.011911
Average total loss: 0.049610
tensor(0.0743, device='cuda:0') tensor(0.2327, device='cuda:0') tensor(-1.9512e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.038001
Average KL loss: 0.011919
Average total loss: 0.049920
tensor(0.0743, device='cuda:0') tensor(0.2331, device='cuda:0') tensor(-1.9095e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.038018
Average KL loss: 0.011929
Average total loss: 0.049948
tensor(0.0744, device='cuda:0') tensor(0.2334, device='cuda:0') tensor(-2.0713e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.037977
Average KL loss: 0.011939
Average total loss: 0.049916
tensor(0.0744, device='cuda:0') tensor(0.2338, device='cuda:0') tensor(-2.0349e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.038387
Average KL loss: 0.011948
Average total loss: 0.050335
tensor(0.0744, device='cuda:0') tensor(0.2342, device='cuda:0') tensor(-2.7600e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.036342
Average KL loss: 0.011959
Average total loss: 0.048300
tensor(0.0744, device='cuda:0') tensor(0.2345, device='cuda:0') tensor(-2.1292e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.036865
Average KL loss: 0.011968
Average total loss: 0.048833
tensor(0.0745, device='cuda:0') tensor(0.2349, device='cuda:0') tensor(-1.6345e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.036994
Average KL loss: 0.011976
Average total loss: 0.048970
tensor(0.0745, device='cuda:0') tensor(0.2352, device='cuda:0') tensor(-2.0155e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.035325
Average KL loss: 0.011985
Average total loss: 0.047310
tensor(0.0745, device='cuda:0') tensor(0.2356, device='cuda:0') tensor(-2.7124e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.036011
Average KL loss: 0.011991
Average total loss: 0.048002
tensor(0.0745, device='cuda:0') tensor(0.2359, device='cuda:0') tensor(-1.7320e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.035468
Average KL loss: 0.011996
Average total loss: 0.047465
tensor(0.0745, device='cuda:0') tensor(0.2362, device='cuda:0') tensor(-2.3860e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.034357
Average KL loss: 0.012002
Average total loss: 0.046359
tensor(0.0745, device='cuda:0') tensor(0.2365, device='cuda:0') tensor(-2.4659e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.035106
Average KL loss: 0.012007
Average total loss: 0.047114
tensor(0.0745, device='cuda:0') tensor(0.2369, device='cuda:0') tensor(-2.2225e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.034399
Average KL loss: 0.012016
Average total loss: 0.046415
tensor(0.0746, device='cuda:0') tensor(0.2372, device='cuda:0') tensor(-2.0023e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.033568
Average KL loss: 0.012023
Average total loss: 0.045591
tensor(0.0746, device='cuda:0') tensor(0.2375, device='cuda:0') tensor(-1.9599e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.033984
Average KL loss: 0.012028
Average total loss: 0.046013
tensor(0.0746, device='cuda:0') tensor(0.2379, device='cuda:0') tensor(-1.7928e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.033978
Average KL loss: 0.012034
Average total loss: 0.046012
tensor(0.0746, device='cuda:0') tensor(0.2382, device='cuda:0') tensor(-1.7622e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.033107
Average KL loss: 0.012042
Average total loss: 0.045149
tensor(0.0746, device='cuda:0') tensor(0.2385, device='cuda:0') tensor(-2.1600e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.032199
Average KL loss: 0.012048
Average total loss: 0.044248
tensor(0.0746, device='cuda:0') tensor(0.2389, device='cuda:0') tensor(-1.6179e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.032322
Average KL loss: 0.012053
Average total loss: 0.044375
tensor(0.0746, device='cuda:0') tensor(0.2392, device='cuda:0') tensor(-1.5320e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.032776
Average KL loss: 0.012059
Average total loss: 0.044835
tensor(0.0746, device='cuda:0') tensor(0.2395, device='cuda:0') tensor(-1.0842e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.031692
Average KL loss: 0.012065
Average total loss: 0.043757
tensor(0.0746, device='cuda:0') tensor(0.2399, device='cuda:0') tensor(-1.9929e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.031769
Average KL loss: 0.012070
Average total loss: 0.043839
tensor(0.0746, device='cuda:0') tensor(0.2402, device='cuda:0') tensor(-1.0639e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.031418
Average KL loss: 0.012075
Average total loss: 0.043494
tensor(0.0746, device='cuda:0') tensor(0.2405, device='cuda:0') tensor(-1.4585e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.031935
Average KL loss: 0.012081
Average total loss: 0.044016
tensor(0.0746, device='cuda:0') tensor(0.2408, device='cuda:0') tensor(-1.4580e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.031598
Average KL loss: 0.012086
Average total loss: 0.043684
tensor(0.0747, device='cuda:0') tensor(0.2412, device='cuda:0') tensor(-1.0979e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.030644
Average KL loss: 0.012092
Average total loss: 0.042736
tensor(0.0747, device='cuda:0') tensor(0.2415, device='cuda:0') tensor(-1.9596e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.031220
Average KL loss: 0.012097
Average total loss: 0.043317
tensor(0.0747, device='cuda:0') tensor(0.2419, device='cuda:0') tensor(-1.1699e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.030805
Average KL loss: 0.012103
Average total loss: 0.042908
tensor(0.0747, device='cuda:0') tensor(0.2422, device='cuda:0') tensor(-3.9495e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.030326
Average KL loss: 0.012110
Average total loss: 0.042436
tensor(0.0747, device='cuda:0') tensor(0.2426, device='cuda:0') tensor(-1.1618e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.029487
Average KL loss: 0.012113
Average total loss: 0.041600
tensor(0.0747, device='cuda:0') tensor(0.2429, device='cuda:0') tensor(-1.2995e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.029696
Average KL loss: 0.012118
Average total loss: 0.041814
tensor(0.0747, device='cuda:0') tensor(0.2432, device='cuda:0') tensor(-1.4641e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.029876
Average KL loss: 0.012124
Average total loss: 0.042001
tensor(0.0747, device='cuda:0') tensor(0.2436, device='cuda:0') tensor(-1.3895e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.030052
Average KL loss: 0.012130
Average total loss: 0.042183
tensor(0.0747, device='cuda:0') tensor(0.2439, device='cuda:0') tensor(-1.4722e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.029085
Average KL loss: 0.012135
Average total loss: 0.041220
tensor(0.0747, device='cuda:0') tensor(0.2443, device='cuda:0') tensor(-1.1742e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.028469
Average KL loss: 0.012138
Average total loss: 0.040607
tensor(0.0747, device='cuda:0') tensor(0.2446, device='cuda:0') tensor(-1.3323e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.028680
Average KL loss: 0.012141
Average total loss: 0.040821
tensor(0.0747, device='cuda:0') tensor(0.2449, device='cuda:0') tensor(-1.6029e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.028412
Average KL loss: 0.012146
Average total loss: 0.040558
tensor(0.0747, device='cuda:0') tensor(0.2452, device='cuda:0') tensor(-1.0935e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.028206
Average KL loss: 0.012149
Average total loss: 0.040355
tensor(0.0747, device='cuda:0') tensor(0.2455, device='cuda:0') tensor(-1.2077e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.027957
Average KL loss: 0.012151
Average total loss: 0.040108
tensor(0.0747, device='cuda:0') tensor(0.2459, device='cuda:0') tensor(-1.1753e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.027621
Average KL loss: 0.012155
Average total loss: 0.039776
tensor(0.0747, device='cuda:0') tensor(0.2462, device='cuda:0') tensor(-1.2623e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.027849
Average KL loss: 0.012158
Average total loss: 0.040007
tensor(0.0747, device='cuda:0') tensor(0.2465, device='cuda:0') tensor(-1.5024e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.027425
Average KL loss: 0.012161
Average total loss: 0.039586
tensor(0.0747, device='cuda:0') tensor(0.2468, device='cuda:0') tensor(-1.2701e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.027650
Average KL loss: 0.012165
Average total loss: 0.039815
tensor(0.0748, device='cuda:0') tensor(0.2472, device='cuda:0') tensor(-1.1363e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.026763
Average KL loss: 0.012168
Average total loss: 0.038931
tensor(0.0747, device='cuda:0') tensor(0.2475, device='cuda:0') tensor(-2.2320e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.026911
Average KL loss: 0.012171
Average total loss: 0.039082
tensor(0.0747, device='cuda:0') tensor(0.2478, device='cuda:0') tensor(-1.6321e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.027234
Average KL loss: 0.012173
Average total loss: 0.039407
tensor(0.0747, device='cuda:0') tensor(0.2481, device='cuda:0') tensor(-1.8633e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.026386
Average KL loss: 0.012178
Average total loss: 0.038564
tensor(0.0747, device='cuda:0') tensor(0.2484, device='cuda:0') tensor(-1.2000e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.026470
Average KL loss: 0.012179
Average total loss: 0.038649
tensor(0.0747, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.5815e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.026131
Average KL loss: 0.012182
Average total loss: 0.038314
tensor(0.0747, device='cuda:0') tensor(0.2491, device='cuda:0') tensor(-1.0350e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.025962
Average KL loss: 0.012186
Average total loss: 0.038148
tensor(0.0747, device='cuda:0') tensor(0.2494, device='cuda:0') tensor(-1.2147e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.025835
Average KL loss: 0.012188
Average total loss: 0.038023
tensor(0.0747, device='cuda:0') tensor(0.2497, device='cuda:0') tensor(-1.0206e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.025799
Average KL loss: 0.012190
Average total loss: 0.037989
tensor(0.0747, device='cuda:0') tensor(0.2500, device='cuda:0') tensor(-7.8730e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.025303
Average KL loss: 0.012193
Average total loss: 0.037496
tensor(0.0747, device='cuda:0') tensor(0.2504, device='cuda:0') tensor(-1.4765e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.025238
Average KL loss: 0.012196
Average total loss: 0.037434
tensor(0.0747, device='cuda:0') tensor(0.2507, device='cuda:0') tensor(-1.0657e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.025329
Average KL loss: 0.012198
Average total loss: 0.037527
tensor(0.0747, device='cuda:0') tensor(0.2510, device='cuda:0') tensor(-1.2432e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.025087
Average KL loss: 0.012201
Average total loss: 0.037288
tensor(0.0747, device='cuda:0') tensor(0.2514, device='cuda:0') tensor(-7.2604e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.025106
Average KL loss: 0.012203
Average total loss: 0.037309
tensor(0.0747, device='cuda:0') tensor(0.2517, device='cuda:0') tensor(-6.2067e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.024618
Average KL loss: 0.012204
Average total loss: 0.036823
tensor(0.0747, device='cuda:0') tensor(0.2520, device='cuda:0') tensor(-1.3159e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.024780
Average KL loss: 0.012206
Average total loss: 0.036986
tensor(0.0747, device='cuda:0') tensor(0.2523, device='cuda:0') tensor(-9.0895e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.024820
Average KL loss: 0.012208
Average total loss: 0.037027
tensor(0.0747, device='cuda:0') tensor(0.2526, device='cuda:0') tensor(-7.1825e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.024257
Average KL loss: 0.012209
Average total loss: 0.036467
tensor(0.0747, device='cuda:0') tensor(0.2529, device='cuda:0') tensor(-7.6913e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.024290
Average KL loss: 0.012209
Average total loss: 0.036499
tensor(0.0747, device='cuda:0') tensor(0.2532, device='cuda:0') tensor(-5.0510e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.024410
Average KL loss: 0.012211
Average total loss: 0.036621
tensor(0.0747, device='cuda:0') tensor(0.2535, device='cuda:0') tensor(-5.3800e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.023946
Average KL loss: 0.012214
Average total loss: 0.036159
tensor(0.0747, device='cuda:0') tensor(0.2539, device='cuda:0') tensor(-9.9433e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.023997
Average KL loss: 0.012215
Average total loss: 0.036212
tensor(0.0747, device='cuda:0') tensor(0.2542, device='cuda:0') tensor(-1.2320e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.023760
Average KL loss: 0.012217
Average total loss: 0.035977
tensor(0.0747, device='cuda:0') tensor(0.2545, device='cuda:0') tensor(-1.1414e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.024647
Average KL loss: 0.012220
Average total loss: 0.036867
tensor(0.0747, device='cuda:0') tensor(0.2549, device='cuda:0') tensor(-9.9857e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.023936
Average KL loss: 0.012221
Average total loss: 0.036157
tensor(0.0747, device='cuda:0') tensor(0.2552, device='cuda:0') tensor(-8.7057e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.023570
Average KL loss: 0.012222
Average total loss: 0.035792
tensor(0.0747, device='cuda:0') tensor(0.2554, device='cuda:0') tensor(-1.4315e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.023478
Average KL loss: 0.012223
Average total loss: 0.035702
tensor(0.0747, device='cuda:0') tensor(0.2558, device='cuda:0') tensor(-1.0700e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.023417
Average KL loss: 0.012224
Average total loss: 0.035640
tensor(0.0746, device='cuda:0') tensor(0.2561, device='cuda:0') tensor(-6.4524e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.023332
Average KL loss: 0.012225
Average total loss: 0.035556
tensor(0.0746, device='cuda:0') tensor(0.2564, device='cuda:0') tensor(-6.4410e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.022872
Average KL loss: 0.012226
Average total loss: 0.035098
tensor(0.0746, device='cuda:0') tensor(0.2567, device='cuda:0') tensor(-6.9435e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.022718
Average KL loss: 0.012225
Average total loss: 0.034943
tensor(0.0746, device='cuda:0') tensor(0.2570, device='cuda:0') tensor(-5.5660e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.022547
Average KL loss: 0.012224
Average total loss: 0.034771
tensor(0.0746, device='cuda:0') tensor(0.2573, device='cuda:0') tensor(-9.7710e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.022838
Average KL loss: 0.012224
Average total loss: 0.035062
tensor(0.0746, device='cuda:0') tensor(0.2576, device='cuda:0') tensor(-4.6700e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.022532
Average KL loss: 0.012225
Average total loss: 0.034757
tensor(0.0746, device='cuda:0') tensor(0.2579, device='cuda:0') tensor(-8.4062e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.022488
Average KL loss: 0.012226
Average total loss: 0.034715
tensor(0.0746, device='cuda:0') tensor(0.2583, device='cuda:0') tensor(-5.8767e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.022455
Average KL loss: 0.012228
Average total loss: 0.034684
tensor(0.0746, device='cuda:0') tensor(0.2586, device='cuda:0') tensor(-5.5353e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.022292
Average KL loss: 0.012229
Average total loss: 0.034521
tensor(0.0746, device='cuda:0') tensor(0.2589, device='cuda:0') tensor(-8.2500e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.022180
Average KL loss: 0.012230
Average total loss: 0.034410
tensor(0.0746, device='cuda:0') tensor(0.2592, device='cuda:0') tensor(-6.2850e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.022074
Average KL loss: 0.012231
Average total loss: 0.034305
tensor(0.0746, device='cuda:0') tensor(0.2595, device='cuda:0') tensor(-8.4583e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.021955
Average KL loss: 0.012231
Average total loss: 0.034186
tensor(0.0746, device='cuda:0') tensor(0.2598, device='cuda:0') tensor(-6.6378e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.021735
Average KL loss: 0.012231
Average total loss: 0.033966
tensor(0.0745, device='cuda:0') tensor(0.2601, device='cuda:0') tensor(-5.7132e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.021395
Average KL loss: 0.012229
Average total loss: 0.033624
tensor(0.0745, device='cuda:0') tensor(0.2604, device='cuda:0') tensor(-7.5362e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.021719
Average KL loss: 0.012229
Average total loss: 0.033948
tensor(0.0745, device='cuda:0') tensor(0.2607, device='cuda:0') tensor(-4.1289e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.021653
Average KL loss: 0.012230
Average total loss: 0.033883
tensor(0.0745, device='cuda:0') tensor(0.2610, device='cuda:0') tensor(-5.5304e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.021159
Average KL loss: 0.012230
Average total loss: 0.033389
tensor(0.0745, device='cuda:0') tensor(0.2613, device='cuda:0') tensor(-9.8041e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.021209
Average KL loss: 0.012228
Average total loss: 0.033437
tensor(0.0745, device='cuda:0') tensor(0.2616, device='cuda:0') tensor(-5.7448e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.021197
Average KL loss: 0.012228
Average total loss: 0.033425
tensor(0.0745, device='cuda:0') tensor(0.2619, device='cuda:0') tensor(-7.9167e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.021250
Average KL loss: 0.012227
Average total loss: 0.033477
tensor(0.0745, device='cuda:0') tensor(0.2623, device='cuda:0') tensor(-5.0440e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.020799
Average KL loss: 0.012227
Average total loss: 0.033026
tensor(0.0744, device='cuda:0') tensor(0.2626, device='cuda:0') tensor(-9.8081e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.020992
Average KL loss: 0.012225
Average total loss: 0.033217
tensor(0.0744, device='cuda:0') tensor(0.2629, device='cuda:0') tensor(-2.9980e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.021021
Average KL loss: 0.012226
Average total loss: 0.033247
tensor(0.0744, device='cuda:0') tensor(0.2632, device='cuda:0') tensor(-2.6884e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.020860
Average KL loss: 0.012227
Average total loss: 0.033087
tensor(0.0744, device='cuda:0') tensor(0.2635, device='cuda:0') tensor(-3.1084e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.020657
Average KL loss: 0.012227
Average total loss: 0.032884
tensor(0.0744, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-5.4139e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.020595
Average KL loss: 0.012226
Average total loss: 0.032820
tensor(0.0744, device='cuda:0') tensor(0.2641, device='cuda:0') tensor(-5.2353e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.020651
Average KL loss: 0.012225
Average total loss: 0.032876
tensor(0.0744, device='cuda:0') tensor(0.2644, device='cuda:0') tensor(-3.7339e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.020380
Average KL loss: 0.012224
Average total loss: 0.032604
tensor(0.0744, device='cuda:0') tensor(0.2647, device='cuda:0') tensor(-4.9338e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.019982
Average KL loss: 0.012223
Average total loss: 0.032205
tensor(0.0743, device='cuda:0') tensor(0.2650, device='cuda:0') tensor(-3.2998e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.020119
Average KL loss: 0.012221
Average total loss: 0.032340
tensor(0.0743, device='cuda:0') tensor(0.2653, device='cuda:0') tensor(-5.0882e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.020448
Average KL loss: 0.012220
Average total loss: 0.032668
tensor(0.0743, device='cuda:0') tensor(0.2656, device='cuda:0') tensor(-4.6209e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.020444
Average KL loss: 0.012220
Average total loss: 0.032664
tensor(0.0743, device='cuda:0') tensor(0.2659, device='cuda:0') tensor(-5.4539e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.019904
Average KL loss: 0.012219
Average total loss: 0.032123
tensor(0.0743, device='cuda:0') tensor(0.2662, device='cuda:0') tensor(-4.9921e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.019942
Average KL loss: 0.012217
Average total loss: 0.032159
tensor(0.0743, device='cuda:0') tensor(0.2665, device='cuda:0') tensor(-6.4154e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.019795
Average KL loss: 0.012216
Average total loss: 0.032011
tensor(0.0743, device='cuda:0') tensor(0.2668, device='cuda:0') tensor(-2.6777e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.019737
Average KL loss: 0.012214
Average total loss: 0.031951
tensor(0.0742, device='cuda:0') tensor(0.2671, device='cuda:0') tensor(-5.9644e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.020060
Average KL loss: 0.012213
Average total loss: 0.032273
tensor(0.0742, device='cuda:0') tensor(0.2674, device='cuda:0') tensor(-3.4012e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.019799
Average KL loss: 0.012212
Average total loss: 0.032011
tensor(0.0742, device='cuda:0') tensor(0.2677, device='cuda:0') tensor(-3.9167e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.019425
Average KL loss: 0.012210
Average total loss: 0.031636
tensor(0.0742, device='cuda:0') tensor(0.2679, device='cuda:0') tensor(-3.9039e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.019599
Average KL loss: 0.012207
Average total loss: 0.031806
tensor(0.0742, device='cuda:0') tensor(0.2682, device='cuda:0') tensor(-6.1640e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.019179
Average KL loss: 0.012208
Average total loss: 0.031387
tensor(0.0742, device='cuda:0') tensor(0.2685, device='cuda:0') tensor(-3.5154e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.019672
Average KL loss: 0.012206
Average total loss: 0.031878
tensor(0.0742, device='cuda:0') tensor(0.2689, device='cuda:0') tensor(-3.4369e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.019298
Average KL loss: 0.012205
Average total loss: 0.031503
tensor(0.0742, device='cuda:0') tensor(0.2691, device='cuda:0') tensor(-5.4997e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.019171
Average KL loss: 0.012203
Average total loss: 0.031374
tensor(0.0741, device='cuda:0') tensor(0.2694, device='cuda:0') tensor(-1.6570e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.019089
Average KL loss: 0.012201
Average total loss: 0.031290
tensor(0.0741, device='cuda:0') tensor(0.2697, device='cuda:0') tensor(-2.3827e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.018953
Average KL loss: 0.012198
Average total loss: 0.031151
tensor(0.0741, device='cuda:0') tensor(0.2700, device='cuda:0') tensor(-5.6573e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.019078
Average KL loss: 0.012197
Average total loss: 0.031275
tensor(0.0741, device='cuda:0') tensor(0.2704, device='cuda:0') tensor(-5.1626e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.019244
Average KL loss: 0.012197
Average total loss: 0.031441
tensor(0.0741, device='cuda:0') tensor(0.2707, device='cuda:0') tensor(-3.5394e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.018648
Average KL loss: 0.012196
Average total loss: 0.030844
tensor(0.0741, device='cuda:0') tensor(0.2710, device='cuda:0') tensor(-1.8945e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.019038
Average KL loss: 0.012193
Average total loss: 0.031231
tensor(0.0741, device='cuda:0') tensor(0.2713, device='cuda:0') tensor(-2.9129e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.018598
Average KL loss: 0.012191
Average total loss: 0.030789
tensor(0.0740, device='cuda:0') tensor(0.2716, device='cuda:0') tensor(-7.0109e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.018757
Average KL loss: 0.012189
Average total loss: 0.030946
tensor(0.0740, device='cuda:0') tensor(0.2719, device='cuda:0') tensor(-2.4348e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.018940
Average KL loss: 0.012188
Average total loss: 0.031128
tensor(0.0740, device='cuda:0') tensor(0.2722, device='cuda:0') tensor(-2.0525e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.018488
Average KL loss: 0.012187
Average total loss: 0.030675
tensor(0.0740, device='cuda:0') tensor(0.2725, device='cuda:0') tensor(-3.6082e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.018266
Average KL loss: 0.012185
Average total loss: 0.030451
tensor(0.0740, device='cuda:0') tensor(0.2728, device='cuda:0') tensor(-1.8669e-12, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.018414
Average KL loss: 0.012182
Average total loss: 0.030596
tensor(0.0740, device='cuda:0') tensor(0.2731, device='cuda:0') tensor(-4.8556e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.018172
Average KL loss: 0.012180
Average total loss: 0.030351
tensor(0.0740, device='cuda:0') tensor(0.2734, device='cuda:0') tensor(-3.5761e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.018367
Average KL loss: 0.012176
Average total loss: 0.030543
 Percentile value: 2.13041353225708
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =     143 /    1728             (  8.28%) | total_pruned =    1585 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     325 /   36864             (  0.88%) | total_pruned =   36539 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     581 /   36864             (  1.58%) | total_pruned =   36283 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     831 /   36864             (  2.25%) | total_pruned =   36033 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1676 /   36864             (  4.55%) | total_pruned =   35188 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    5953 /   73728             (  8.07%) | total_pruned =   67775 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   11860 /  147456             (  8.04%) | total_pruned =  135596 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     939 /    8192             ( 11.46%) | total_pruned =    7253 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    7009 /  147456             (  4.75%) | total_pruned =  140447 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    6251 /  147456             (  4.24%) | total_pruned =  141205 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   27307 /  294912             (  9.26%) | total_pruned =  267605 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     159 /     256             ( 62.11%) | total_pruned =      97 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   31804 /  589824             (  5.39%) | total_pruned =  558020 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      73 /     256             ( 28.52%) | total_pruned =     183 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3028 /   32768             (  9.24%) | total_pruned =   29740 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     115 /     256             ( 44.92%) | total_pruned =     141 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      58 /     256             ( 22.66%) | total_pruned =     198 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   22437 /  589824             (  3.80%) | total_pruned =  567387 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   20124 /  589824             (  3.41%) | total_pruned =  569700 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     138 /     256             ( 53.91%) | total_pruned =     118 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   50103 / 1179648             (  4.25%) | total_pruned = 1129545 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     307 /     512             ( 59.96%) | total_pruned =     205 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     104 /     512             ( 20.31%) | total_pruned =     408 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   59299 / 2359296             (  2.51%) | total_pruned = 2299997 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     405 /     512             ( 79.10%) | total_pruned =     107 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     298 /     512             ( 58.20%) | total_pruned =     214 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1656 /  131072             (  1.26%) | total_pruned =  129416 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     162 /     512             ( 31.64%) | total_pruned =     350 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     299 /     512             ( 58.40%) | total_pruned =     213 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   28012 / 2359296             (  1.19%) | total_pruned = 2331284 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   61488 / 2359296             (  2.61%) | total_pruned = 2297808 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     455 /     512             ( 88.87%) | total_pruned =      57 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
linear.weight        | nonzeros =    4128 /    5120             ( 80.62%) | total_pruned =     992 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 43/100 Loss: 0.019897 Accuracy: 86.11 100.00 % Best test Accuracy: 86.23%
tensor(0.0739, device='cuda:0') tensor(0.2736, device='cuda:0') tensor(-4.2613e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.051116
Average KL loss: 0.011927
Average total loss: 0.063042
tensor(0.0724, device='cuda:0') tensor(0.2639, device='cuda:0') tensor(-4.3222e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.048789
Average KL loss: 0.011654
Average total loss: 0.060443
tensor(0.0719, device='cuda:0') tensor(0.2596, device='cuda:0') tensor(-3.1107e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.047349
Average KL loss: 0.011479
Average total loss: 0.058828
tensor(0.0715, device='cuda:0') tensor(0.2565, device='cuda:0') tensor(-3.6067e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.046311
Average KL loss: 0.011344
Average total loss: 0.057655
tensor(0.0711, device='cuda:0') tensor(0.2542, device='cuda:0') tensor(-4.3093e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.045630
Average KL loss: 0.011234
Average total loss: 0.056864
tensor(0.0707, device='cuda:0') tensor(0.2523, device='cuda:0') tensor(-3.8767e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.044343
Average KL loss: 0.011142
Average total loss: 0.055484
tensor(0.0703, device='cuda:0') tensor(0.2508, device='cuda:0') tensor(-3.3417e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.042696
Average KL loss: 0.011064
Average total loss: 0.053760
tensor(0.0699, device='cuda:0') tensor(0.2497, device='cuda:0') tensor(-3.3255e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.042827
Average KL loss: 0.011003
Average total loss: 0.053829
tensor(0.0696, device='cuda:0') tensor(0.2488, device='cuda:0') tensor(-2.9527e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.041208
Average KL loss: 0.010954
Average total loss: 0.052162
tensor(0.0693, device='cuda:0') tensor(0.2482, device='cuda:0') tensor(-2.6138e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.040323
Average KL loss: 0.010915
Average total loss: 0.051237
tensor(0.0691, device='cuda:0') tensor(0.2477, device='cuda:0') tensor(-2.6382e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.038671
Average KL loss: 0.010886
Average total loss: 0.049557
tensor(0.0689, device='cuda:0') tensor(0.2474, device='cuda:0') tensor(-2.4679e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.039414
Average KL loss: 0.010864
Average total loss: 0.050278
tensor(0.0687, device='cuda:0') tensor(0.2473, device='cuda:0') tensor(-2.8334e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.038902
Average KL loss: 0.010849
Average total loss: 0.049751
tensor(0.0686, device='cuda:0') tensor(0.2472, device='cuda:0') tensor(-2.4090e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.037461
Average KL loss: 0.010839
Average total loss: 0.048300
tensor(0.0685, device='cuda:0') tensor(0.2471, device='cuda:0') tensor(-2.3340e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.038027
Average KL loss: 0.010832
Average total loss: 0.048859
tensor(0.0684, device='cuda:0') tensor(0.2472, device='cuda:0') tensor(-2.3495e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.036503
Average KL loss: 0.010828
Average total loss: 0.047331
tensor(0.0684, device='cuda:0') tensor(0.2472, device='cuda:0') tensor(-2.3393e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.036455
Average KL loss: 0.010825
Average total loss: 0.047280
tensor(0.0683, device='cuda:0') tensor(0.2473, device='cuda:0') tensor(-1.8598e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.036192
Average KL loss: 0.010824
Average total loss: 0.047016
tensor(0.0683, device='cuda:0') tensor(0.2475, device='cuda:0') tensor(-2.4545e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.035504
Average KL loss: 0.010824
Average total loss: 0.046328
tensor(0.0683, device='cuda:0') tensor(0.2476, device='cuda:0') tensor(-2.5379e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.035084
Average KL loss: 0.010824
Average total loss: 0.045908
tensor(0.0683, device='cuda:0') tensor(0.2478, device='cuda:0') tensor(-1.9457e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.034602
Average KL loss: 0.010824
Average total loss: 0.045426
tensor(0.0683, device='cuda:0') tensor(0.2480, device='cuda:0') tensor(-1.6773e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.033145
Average KL loss: 0.010825
Average total loss: 0.043970
tensor(0.0683, device='cuda:0') tensor(0.2481, device='cuda:0') tensor(-2.4536e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.032989
Average KL loss: 0.010825
Average total loss: 0.043814
tensor(0.0682, device='cuda:0') tensor(0.2483, device='cuda:0') tensor(-2.2993e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.033025
Average KL loss: 0.010826
Average total loss: 0.043851
tensor(0.0682, device='cuda:0') tensor(0.2485, device='cuda:0') tensor(-2.3658e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.033437
Average KL loss: 0.010827
Average total loss: 0.044264
tensor(0.0682, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-2.1818e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.031570
Average KL loss: 0.010829
Average total loss: 0.042399
tensor(0.0682, device='cuda:0') tensor(0.2489, device='cuda:0') tensor(-2.4597e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.031781
Average KL loss: 0.010831
Average total loss: 0.042611
tensor(0.0682, device='cuda:0') tensor(0.2491, device='cuda:0') tensor(-1.4944e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.031588
Average KL loss: 0.010831
Average total loss: 0.042419
tensor(0.0682, device='cuda:0') tensor(0.2493, device='cuda:0') tensor(-1.7787e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.031469
Average KL loss: 0.010832
Average total loss: 0.042301
tensor(0.0682, device='cuda:0') tensor(0.2495, device='cuda:0') tensor(-1.7160e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.030459
Average KL loss: 0.010832
Average total loss: 0.041291
tensor(0.0682, device='cuda:0') tensor(0.2497, device='cuda:0') tensor(-1.5749e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.030849
Average KL loss: 0.010832
Average total loss: 0.041681
tensor(0.0682, device='cuda:0') tensor(0.2500, device='cuda:0') tensor(-2.1894e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.029858
Average KL loss: 0.010834
Average total loss: 0.040692
tensor(0.0682, device='cuda:0') tensor(0.2502, device='cuda:0') tensor(-2.1624e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.030032
Average KL loss: 0.010836
Average total loss: 0.040868
tensor(0.0682, device='cuda:0') tensor(0.2505, device='cuda:0') tensor(-1.5478e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.029820
Average KL loss: 0.010837
Average total loss: 0.040657
tensor(0.0683, device='cuda:0') tensor(0.2507, device='cuda:0') tensor(-1.5902e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.029666
Average KL loss: 0.010839
Average total loss: 0.040504
tensor(0.0683, device='cuda:0') tensor(0.2510, device='cuda:0') tensor(-1.4618e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.029095
Average KL loss: 0.010840
Average total loss: 0.039935
tensor(0.0683, device='cuda:0') tensor(0.2512, device='cuda:0') tensor(-1.4355e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.028230
Average KL loss: 0.010839
Average total loss: 0.039068
tensor(0.0682, device='cuda:0') tensor(0.2514, device='cuda:0') tensor(-1.8040e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.028738
Average KL loss: 0.010840
Average total loss: 0.039577
tensor(0.0683, device='cuda:0') tensor(0.2517, device='cuda:0') tensor(-1.8754e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.028224
Average KL loss: 0.010841
Average total loss: 0.039065
tensor(0.0683, device='cuda:0') tensor(0.2519, device='cuda:0') tensor(-1.4525e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.028325
Average KL loss: 0.010841
Average total loss: 0.039166
tensor(0.0683, device='cuda:0') tensor(0.2521, device='cuda:0') tensor(-1.2513e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.027357
Average KL loss: 0.010841
Average total loss: 0.038198
tensor(0.0683, device='cuda:0') tensor(0.2524, device='cuda:0') tensor(-1.4789e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.028068
Average KL loss: 0.010842
Average total loss: 0.038910
tensor(0.0683, device='cuda:0') tensor(0.2526, device='cuda:0') tensor(-9.0610e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.027186
Average KL loss: 0.010843
Average total loss: 0.038029
tensor(0.0683, device='cuda:0') tensor(0.2529, device='cuda:0') tensor(-1.3111e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.026997
Average KL loss: 0.010844
Average total loss: 0.037841
tensor(0.0683, device='cuda:0') tensor(0.2531, device='cuda:0') tensor(-1.3314e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.027421
Average KL loss: 0.010846
Average total loss: 0.038267
tensor(0.0683, device='cuda:0') tensor(0.2534, device='cuda:0') tensor(-1.7116e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.026777
Average KL loss: 0.010846
Average total loss: 0.037623
tensor(0.0683, device='cuda:0') tensor(0.2537, device='cuda:0') tensor(-1.4961e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.026614
Average KL loss: 0.010846
Average total loss: 0.037460
tensor(0.0683, device='cuda:0') tensor(0.2539, device='cuda:0') tensor(-1.0505e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.026476
Average KL loss: 0.010846
Average total loss: 0.037322
tensor(0.0683, device='cuda:0') tensor(0.2542, device='cuda:0') tensor(-1.6615e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.025976
Average KL loss: 0.010845
Average total loss: 0.036821
tensor(0.0683, device='cuda:0') tensor(0.2544, device='cuda:0') tensor(-8.3296e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.026277
Average KL loss: 0.010844
Average total loss: 0.037121
tensor(0.0683, device='cuda:0') tensor(0.2547, device='cuda:0') tensor(-1.5780e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.025690
Average KL loss: 0.010844
Average total loss: 0.036534
tensor(0.0683, device='cuda:0') tensor(0.2549, device='cuda:0') tensor(-7.7026e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.025709
Average KL loss: 0.010843
Average total loss: 0.036552
tensor(0.0683, device='cuda:0') tensor(0.2551, device='cuda:0') tensor(-8.6467e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.025447
Average KL loss: 0.010842
Average total loss: 0.036289
tensor(0.0683, device='cuda:0') tensor(0.2554, device='cuda:0') tensor(-1.3982e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.025315
Average KL loss: 0.010842
Average total loss: 0.036157
tensor(0.0683, device='cuda:0') tensor(0.2556, device='cuda:0') tensor(-8.8412e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.025349
Average KL loss: 0.010842
Average total loss: 0.036191
tensor(0.0683, device='cuda:0') tensor(0.2559, device='cuda:0') tensor(-1.1784e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.025175
Average KL loss: 0.010842
Average total loss: 0.036017
tensor(0.0683, device='cuda:0') tensor(0.2562, device='cuda:0') tensor(-1.1517e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.024627
Average KL loss: 0.010842
Average total loss: 0.035470
tensor(0.0683, device='cuda:0') tensor(0.2564, device='cuda:0') tensor(-1.0048e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.024301
Average KL loss: 0.010842
Average total loss: 0.035142
tensor(0.0683, device='cuda:0') tensor(0.2567, device='cuda:0') tensor(-8.6160e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.024331
Average KL loss: 0.010841
Average total loss: 0.035172
tensor(0.0683, device='cuda:0') tensor(0.2569, device='cuda:0') tensor(-1.6128e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.024109
Average KL loss: 0.010840
Average total loss: 0.034948
tensor(0.0683, device='cuda:0') tensor(0.2571, device='cuda:0') tensor(-7.8092e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.024032
Average KL loss: 0.010839
Average total loss: 0.034871
tensor(0.0683, device='cuda:0') tensor(0.2574, device='cuda:0') tensor(-8.2949e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.024213
Average KL loss: 0.010838
Average total loss: 0.035051
tensor(0.0683, device='cuda:0') tensor(0.2576, device='cuda:0') tensor(-1.0217e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.023562
Average KL loss: 0.010837
Average total loss: 0.034398
tensor(0.0683, device='cuda:0') tensor(0.2578, device='cuda:0') tensor(-1.0984e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.023663
Average KL loss: 0.010835
Average total loss: 0.034498
tensor(0.0683, device='cuda:0') tensor(0.2581, device='cuda:0') tensor(-7.8546e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.023182
Average KL loss: 0.010833
Average total loss: 0.034016
tensor(0.0682, device='cuda:0') tensor(0.2583, device='cuda:0') tensor(-8.6410e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.023633
Average KL loss: 0.010831
Average total loss: 0.034464
tensor(0.0682, device='cuda:0') tensor(0.2586, device='cuda:0') tensor(-5.4775e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.022959
Average KL loss: 0.010830
Average total loss: 0.033789
tensor(0.0682, device='cuda:0') tensor(0.2589, device='cuda:0') tensor(-1.1743e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.022821
Average KL loss: 0.010828
Average total loss: 0.033648
tensor(0.0682, device='cuda:0') tensor(0.2591, device='cuda:0') tensor(-6.4251e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.022830
Average KL loss: 0.010826
Average total loss: 0.033656
tensor(0.0682, device='cuda:0') tensor(0.2593, device='cuda:0') tensor(-9.8386e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.022681
Average KL loss: 0.010825
Average total loss: 0.033506
tensor(0.0682, device='cuda:0') tensor(0.2596, device='cuda:0') tensor(-9.8541e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.022831
Average KL loss: 0.010824
Average total loss: 0.033655
tensor(0.0682, device='cuda:0') tensor(0.2599, device='cuda:0') tensor(-8.1816e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.022750
Average KL loss: 0.010823
Average total loss: 0.033573
tensor(0.0682, device='cuda:0') tensor(0.2601, device='cuda:0') tensor(-8.3431e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.022088
Average KL loss: 0.010822
Average total loss: 0.032910
tensor(0.0682, device='cuda:0') tensor(0.2604, device='cuda:0') tensor(-6.3468e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.022713
Average KL loss: 0.010821
Average total loss: 0.033534
tensor(0.0682, device='cuda:0') tensor(0.2606, device='cuda:0') tensor(-7.8930e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.022259
Average KL loss: 0.010819
Average total loss: 0.033078
tensor(0.0682, device='cuda:0') tensor(0.2609, device='cuda:0') tensor(-6.2562e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.021825
Average KL loss: 0.010818
Average total loss: 0.032643
tensor(0.0682, device='cuda:0') tensor(0.2611, device='cuda:0') tensor(-7.1305e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.021712
Average KL loss: 0.010815
Average total loss: 0.032527
tensor(0.0682, device='cuda:0') tensor(0.2614, device='cuda:0') tensor(-9.9869e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.021929
Average KL loss: 0.010814
Average total loss: 0.032743
tensor(0.0682, device='cuda:0') tensor(0.2617, device='cuda:0') tensor(-4.9793e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.021737
Average KL loss: 0.010812
Average total loss: 0.032549
tensor(0.0682, device='cuda:0') tensor(0.2619, device='cuda:0') tensor(-5.3405e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.021632
Average KL loss: 0.010810
Average total loss: 0.032443
tensor(0.0682, device='cuda:0') tensor(0.2622, device='cuda:0') tensor(-8.5971e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.021349
Average KL loss: 0.010809
Average total loss: 0.032158
tensor(0.0682, device='cuda:0') tensor(0.2624, device='cuda:0') tensor(-7.1876e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.021853
Average KL loss: 0.010806
Average total loss: 0.032659
tensor(0.0682, device='cuda:0') tensor(0.2627, device='cuda:0') tensor(-3.7748e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.020998
Average KL loss: 0.010804
Average total loss: 0.031802
tensor(0.0682, device='cuda:0') tensor(0.2629, device='cuda:0') tensor(-8.1297e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.021177
Average KL loss: 0.010803
Average total loss: 0.031980
tensor(0.0682, device='cuda:0') tensor(0.2632, device='cuda:0') tensor(-3.4394e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.021101
Average KL loss: 0.010800
Average total loss: 0.031901
tensor(0.0682, device='cuda:0') tensor(0.2634, device='cuda:0') tensor(-9.8915e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.021005
Average KL loss: 0.010798
Average total loss: 0.031803
tensor(0.0682, device='cuda:0') tensor(0.2637, device='cuda:0') tensor(-6.7052e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.021051
Average KL loss: 0.010796
Average total loss: 0.031847
tensor(0.0682, device='cuda:0') tensor(0.2639, device='cuda:0') tensor(-6.3351e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.020535
Average KL loss: 0.010793
Average total loss: 0.031328
tensor(0.0681, device='cuda:0') tensor(0.2642, device='cuda:0') tensor(-4.0500e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.020495
Average KL loss: 0.010790
Average total loss: 0.031285
tensor(0.0681, device='cuda:0') tensor(0.2644, device='cuda:0') tensor(-7.4223e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.020417
Average KL loss: 0.010788
Average total loss: 0.031205
tensor(0.0681, device='cuda:0') tensor(0.2646, device='cuda:0') tensor(-7.5255e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.020664
Average KL loss: 0.010786
Average total loss: 0.031451
tensor(0.0681, device='cuda:0') tensor(0.2649, device='cuda:0') tensor(-7.9609e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.020558
Average KL loss: 0.010785
Average total loss: 0.031343
tensor(0.0681, device='cuda:0') tensor(0.2652, device='cuda:0') tensor(-7.1058e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.020460
Average KL loss: 0.010784
Average total loss: 0.031244
tensor(0.0681, device='cuda:0') tensor(0.2655, device='cuda:0') tensor(-5.8919e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.020232
Average KL loss: 0.010781
Average total loss: 0.031014
tensor(0.0681, device='cuda:0') tensor(0.2657, device='cuda:0') tensor(-4.7328e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.019891
Average KL loss: 0.010779
Average total loss: 0.030671
tensor(0.0681, device='cuda:0') tensor(0.2660, device='cuda:0') tensor(-6.3266e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.020141
Average KL loss: 0.010777
Average total loss: 0.030918
tensor(0.0681, device='cuda:0') tensor(0.2662, device='cuda:0') tensor(-4.4663e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.020024
Average KL loss: 0.010774
Average total loss: 0.030798
tensor(0.0681, device='cuda:0') tensor(0.2665, device='cuda:0') tensor(-5.5203e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.019838
Average KL loss: 0.010772
Average total loss: 0.030610
tensor(0.0681, device='cuda:0') tensor(0.2668, device='cuda:0') tensor(-5.1006e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.019627
Average KL loss: 0.010771
Average total loss: 0.030397
tensor(0.0681, device='cuda:0') tensor(0.2670, device='cuda:0') tensor(-3.0700e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.019752
Average KL loss: 0.010767
Average total loss: 0.030519
tensor(0.0681, device='cuda:0') tensor(0.2673, device='cuda:0') tensor(-6.2970e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.019877
Average KL loss: 0.010766
Average total loss: 0.030643
tensor(0.0681, device='cuda:0') tensor(0.2675, device='cuda:0') tensor(-5.2400e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.019752
Average KL loss: 0.010765
Average total loss: 0.030517
tensor(0.0681, device='cuda:0') tensor(0.2678, device='cuda:0') tensor(-3.0712e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.019336
Average KL loss: 0.010762
Average total loss: 0.030099
tensor(0.0681, device='cuda:0') tensor(0.2681, device='cuda:0') tensor(-5.7350e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.019523
Average KL loss: 0.010759
Average total loss: 0.030282
tensor(0.0681, device='cuda:0') tensor(0.2683, device='cuda:0') tensor(-8.7529e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.019086
Average KL loss: 0.010756
Average total loss: 0.029842
tensor(0.0680, device='cuda:0') tensor(0.2685, device='cuda:0') tensor(-4.4692e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.019289
Average KL loss: 0.010753
Average total loss: 0.030042
tensor(0.0680, device='cuda:0') tensor(0.2688, device='cuda:0') tensor(-6.2917e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.019284
Average KL loss: 0.010750
Average total loss: 0.030034
tensor(0.0680, device='cuda:0') tensor(0.2690, device='cuda:0') tensor(-4.0331e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.019051
Average KL loss: 0.010747
Average total loss: 0.029798
tensor(0.0680, device='cuda:0') tensor(0.2693, device='cuda:0') tensor(-5.3430e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.018925
Average KL loss: 0.010745
Average total loss: 0.029669
tensor(0.0680, device='cuda:0') tensor(0.2695, device='cuda:0') tensor(-3.7970e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.019098
Average KL loss: 0.010742
Average total loss: 0.029840
tensor(0.0680, device='cuda:0') tensor(0.2698, device='cuda:0') tensor(-3.1094e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.018714
Average KL loss: 0.010739
Average total loss: 0.029453
tensor(0.0680, device='cuda:0') tensor(0.2701, device='cuda:0') tensor(-3.4704e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.019018
Average KL loss: 0.010737
Average total loss: 0.029755
tensor(0.0680, device='cuda:0') tensor(0.2703, device='cuda:0') tensor(-4.4425e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.018721
Average KL loss: 0.010733
Average total loss: 0.029454
tensor(0.0680, device='cuda:0') tensor(0.2706, device='cuda:0') tensor(-4.0987e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.018269
Average KL loss: 0.010729
Average total loss: 0.028998
tensor(0.0680, device='cuda:0') tensor(0.2708, device='cuda:0') tensor(-4.7360e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.018637
Average KL loss: 0.010726
Average total loss: 0.029363
tensor(0.0679, device='cuda:0') tensor(0.2711, device='cuda:0') tensor(-5.8932e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.018717
Average KL loss: 0.010723
Average total loss: 0.029439
tensor(0.0679, device='cuda:0') tensor(0.2713, device='cuda:0') tensor(-2.8733e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.018303
Average KL loss: 0.010720
Average total loss: 0.029023
tensor(0.0679, device='cuda:0') tensor(0.2716, device='cuda:0') tensor(-2.2550e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.018488
Average KL loss: 0.010717
Average total loss: 0.029205
tensor(0.0679, device='cuda:0') tensor(0.2719, device='cuda:0') tensor(-4.0981e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.018480
Average KL loss: 0.010716
Average total loss: 0.029195
tensor(0.0679, device='cuda:0') tensor(0.2721, device='cuda:0') tensor(-4.7440e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.018159
Average KL loss: 0.010713
Average total loss: 0.028872
tensor(0.0679, device='cuda:0') tensor(0.2724, device='cuda:0') tensor(-6.4023e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.018083
Average KL loss: 0.010710
Average total loss: 0.028793
tensor(0.0679, device='cuda:0') tensor(0.2727, device='cuda:0') tensor(-4.4038e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.018194
Average KL loss: 0.010707
Average total loss: 0.028901
tensor(0.0679, device='cuda:0') tensor(0.2729, device='cuda:0') tensor(-3.9650e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.018195
Average KL loss: 0.010704
Average total loss: 0.028899
tensor(0.0679, device='cuda:0') tensor(0.2732, device='cuda:0') tensor(-4.0164e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.018171
Average KL loss: 0.010701
Average total loss: 0.028872
tensor(0.0679, device='cuda:0') tensor(0.2735, device='cuda:0') tensor(-2.3362e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.017939
Average KL loss: 0.010699
Average total loss: 0.028638
tensor(0.0679, device='cuda:0') tensor(0.2738, device='cuda:0') tensor(-5.4932e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.017984
Average KL loss: 0.010695
Average total loss: 0.028679
tensor(0.0679, device='cuda:0') tensor(0.2740, device='cuda:0') tensor(-2.6321e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.018015
Average KL loss: 0.010692
Average total loss: 0.028707
tensor(0.0679, device='cuda:0') tensor(0.2743, device='cuda:0') tensor(-2.9292e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.017564
Average KL loss: 0.010690
Average total loss: 0.028254
tensor(0.0679, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-3.2603e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.018194
Average KL loss: 0.010687
Average total loss: 0.028881
tensor(0.0679, device='cuda:0') tensor(0.2748, device='cuda:0') tensor(-3.8133e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.017599
Average KL loss: 0.010684
Average total loss: 0.028284
tensor(0.0679, device='cuda:0') tensor(0.2751, device='cuda:0') tensor(-7.7434e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.017607
Average KL loss: 0.010681
Average total loss: 0.028288
tensor(0.0678, device='cuda:0') tensor(0.2754, device='cuda:0') tensor(-2.1465e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.017519
Average KL loss: 0.010676
Average total loss: 0.028195
tensor(0.0678, device='cuda:0') tensor(0.2756, device='cuda:0') tensor(-3.1030e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.017556
Average KL loss: 0.010673
Average total loss: 0.028229
tensor(0.0678, device='cuda:0') tensor(0.2759, device='cuda:0') tensor(-1.7662e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.017383
Average KL loss: 0.010670
Average total loss: 0.028053
tensor(0.0678, device='cuda:0') tensor(0.2762, device='cuda:0') tensor(-2.5551e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.017339
Average KL loss: 0.010666
Average total loss: 0.028005
tensor(0.0678, device='cuda:0') tensor(0.2764, device='cuda:0') tensor(-1.7586e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.017363
Average KL loss: 0.010662
Average total loss: 0.028024
tensor(0.0678, device='cuda:0') tensor(0.2766, device='cuda:0') tensor(-1.5047e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.017346
Average KL loss: 0.010659
Average total loss: 0.028005
tensor(0.0678, device='cuda:0') tensor(0.2769, device='cuda:0') tensor(-1.8721e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.017168
Average KL loss: 0.010656
Average total loss: 0.027824
tensor(0.0678, device='cuda:0') tensor(0.2772, device='cuda:0') tensor(-1.8022e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.017280
Average KL loss: 0.010653
Average total loss: 0.027933
tensor(0.0678, device='cuda:0') tensor(0.2775, device='cuda:0') tensor(-2.0830e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.017029
Average KL loss: 0.010650
Average total loss: 0.027679
tensor(0.0678, device='cuda:0') tensor(0.2777, device='cuda:0') tensor(-3.2411e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.017286
Average KL loss: 0.010646
Average total loss: 0.027932
tensor(0.0677, device='cuda:0') tensor(0.2780, device='cuda:0') tensor(-1.6627e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.017120
Average KL loss: 0.010643
Average total loss: 0.027764
tensor(0.0677, device='cuda:0') tensor(0.2783, device='cuda:0') tensor(-2.5425e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.016986
Average KL loss: 0.010640
Average total loss: 0.027626
tensor(0.0677, device='cuda:0') tensor(0.2785, device='cuda:0') tensor(-2.8801e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.016944
Average KL loss: 0.010636
Average total loss: 0.027580
tensor(0.0677, device='cuda:0') tensor(0.2788, device='cuda:0') tensor(-1.9271e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.016964
Average KL loss: 0.010632
Average total loss: 0.027596
tensor(0.0677, device='cuda:0') tensor(0.2790, device='cuda:0') tensor(-2.0138e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.017059
Average KL loss: 0.010628
Average total loss: 0.027687
tensor(0.0677, device='cuda:0') tensor(0.2793, device='cuda:0') tensor(-2.2814e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.016874
Average KL loss: 0.010626
Average total loss: 0.027500
tensor(0.0677, device='cuda:0') tensor(0.2796, device='cuda:0') tensor(-2.2663e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.016637
Average KL loss: 0.010622
Average total loss: 0.027259
tensor(0.0677, device='cuda:0') tensor(0.2798, device='cuda:0') tensor(-2.9066e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.016762
Average KL loss: 0.010618
Average total loss: 0.027381
tensor(0.0677, device='cuda:0') tensor(0.2801, device='cuda:0') tensor(-1.5864e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.016864
Average KL loss: 0.010615
Average total loss: 0.027479
tensor(0.0677, device='cuda:0') tensor(0.2804, device='cuda:0') tensor(-4.0592e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.016816
Average KL loss: 0.010613
Average total loss: 0.027429
tensor(0.0677, device='cuda:0') tensor(0.2807, device='cuda:0') tensor(-1.6286e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.016640
Average KL loss: 0.010609
Average total loss: 0.027249
tensor(0.0676, device='cuda:0') tensor(0.2809, device='cuda:0') tensor(-9.4793e-11, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.016569
Average KL loss: 0.010605
Average total loss: 0.027174
tensor(0.0676, device='cuda:0') tensor(0.2812, device='cuda:0') tensor(-3.0659e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.016850
Average KL loss: 0.010602
Average total loss: 0.027451
tensor(0.0676, device='cuda:0') tensor(0.2815, device='cuda:0') tensor(-1.9794e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.016469
Average KL loss: 0.010598
Average total loss: 0.027067
tensor(0.0676, device='cuda:0') tensor(0.2817, device='cuda:0') tensor(-4.5955e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.016641
Average KL loss: 0.010595
Average total loss: 0.027236
tensor(0.0676, device='cuda:0') tensor(0.2820, device='cuda:0') tensor(-1.7187e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.016636
Average KL loss: 0.010593
Average total loss: 0.027228
tensor(0.0676, device='cuda:0') tensor(0.2823, device='cuda:0') tensor(-1.0145e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.016453
Average KL loss: 0.010590
Average total loss: 0.027043
tensor(0.0676, device='cuda:0') tensor(0.2826, device='cuda:0') tensor(-2.4295e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.017552
Average KL loss: 0.010587
Average total loss: 0.028139
tensor(0.0676, device='cuda:0') tensor(0.2829, device='cuda:0') tensor(-1.7573e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.016263
Average KL loss: 0.010586
Average total loss: 0.026849
tensor(0.0676, device='cuda:0') tensor(0.2832, device='cuda:0') tensor(-1.4407e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.016319
Average KL loss: 0.010582
Average total loss: 0.026900
tensor(0.0676, device='cuda:0') tensor(0.2834, device='cuda:0') tensor(-1.5927e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.016260
Average KL loss: 0.010577
Average total loss: 0.026837
tensor(0.0676, device='cuda:0') tensor(0.2837, device='cuda:0') tensor(-2.1916e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.016381
Average KL loss: 0.010574
Average total loss: 0.026955
tensor(0.0676, device='cuda:0') tensor(0.2840, device='cuda:0') tensor(-3.6592e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.016375
Average KL loss: 0.010572
Average total loss: 0.026947
tensor(0.0676, device='cuda:0') tensor(0.2843, device='cuda:0') tensor(-1.7683e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.016231
Average KL loss: 0.010569
Average total loss: 0.026801
tensor(0.0675, device='cuda:0') tensor(0.2846, device='cuda:0') tensor(-1.8626e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.016148
Average KL loss: 0.010566
Average total loss: 0.026715
tensor(0.0675, device='cuda:0') tensor(0.2849, device='cuda:0') tensor(-1.0828e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.016281
Average KL loss: 0.010564
Average total loss: 0.026845
tensor(0.0675, device='cuda:0') tensor(0.2852, device='cuda:0') tensor(-1.2064e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.016264
Average KL loss: 0.010560
Average total loss: 0.026824
tensor(0.0675, device='cuda:0') tensor(0.2854, device='cuda:0') tensor(-4.4963e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.015937
Average KL loss: 0.010557
Average total loss: 0.026494
tensor(0.0675, device='cuda:0') tensor(0.2857, device='cuda:0') tensor(-9.2652e-11, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.015926
Average KL loss: 0.010554
Average total loss: 0.026480
tensor(0.0675, device='cuda:0') tensor(0.2860, device='cuda:0') tensor(-1.8308e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.016030
Average KL loss: 0.010550
Average total loss: 0.026580
tensor(0.0675, device='cuda:0') tensor(0.2863, device='cuda:0') tensor(-1.7025e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.015771
Average KL loss: 0.010547
Average total loss: 0.026318
tensor(0.0675, device='cuda:0') tensor(0.2865, device='cuda:0') tensor(-1.4665e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.016003
Average KL loss: 0.010542
Average total loss: 0.026546
tensor(0.0675, device='cuda:0') tensor(0.2868, device='cuda:0') tensor(-5.2423e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.015706
Average KL loss: 0.010539
Average total loss: 0.026245
tensor(0.0675, device='cuda:0') tensor(0.2871, device='cuda:0') tensor(-5.6116e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.015697
Average KL loss: 0.010535
Average total loss: 0.026232
tensor(0.0675, device='cuda:0') tensor(0.2873, device='cuda:0') tensor(-1.8605e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.015796
Average KL loss: 0.010532
Average total loss: 0.026328
tensor(0.0675, device='cuda:0') tensor(0.2876, device='cuda:0') tensor(-1.6554e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.015939
Average KL loss: 0.010529
Average total loss: 0.026467
tensor(0.0674, device='cuda:0') tensor(0.2879, device='cuda:0') tensor(-1.6959e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.015693
Average KL loss: 0.010525
Average total loss: 0.026218
tensor(0.0674, device='cuda:0') tensor(0.2881, device='cuda:0') tensor(-1.3615e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.015693
Average KL loss: 0.010522
Average total loss: 0.026215
tensor(0.0674, device='cuda:0') tensor(0.2884, device='cuda:0') tensor(-2.0421e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.015825
Average KL loss: 0.010518
Average total loss: 0.026343
tensor(0.0674, device='cuda:0') tensor(0.2887, device='cuda:0') tensor(-1.6859e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.015821
Average KL loss: 0.010517
Average total loss: 0.026338
tensor(0.0674, device='cuda:0') tensor(0.2890, device='cuda:0') tensor(-1.2760e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.015708
Average KL loss: 0.010514
Average total loss: 0.026223
tensor(0.0674, device='cuda:0') tensor(0.2894, device='cuda:0') tensor(-1.4248e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.015596
Average KL loss: 0.010512
Average total loss: 0.026107
tensor(0.0674, device='cuda:0') tensor(0.2896, device='cuda:0') tensor(-1.5197e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.015560
Average KL loss: 0.010508
Average total loss: 0.026068
tensor(0.0674, device='cuda:0') tensor(0.2899, device='cuda:0') tensor(-9.9390e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.015599
Average KL loss: 0.010506
Average total loss: 0.026105
tensor(0.0674, device='cuda:0') tensor(0.2902, device='cuda:0') tensor(-2.0624e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.015509
Average KL loss: 0.010503
Average total loss: 0.026011
tensor(0.0674, device='cuda:0') tensor(0.2905, device='cuda:0') tensor(-8.6501e-11, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.015355
Average KL loss: 0.010500
Average total loss: 0.025855
tensor(0.0674, device='cuda:0') tensor(0.2908, device='cuda:0') tensor(-3.0276e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.015357
Average KL loss: 0.010496
Average total loss: 0.025853
tensor(0.0674, device='cuda:0') tensor(0.2910, device='cuda:0') tensor(-1.3104e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.015388
Average KL loss: 0.010492
Average total loss: 0.025880
tensor(0.0674, device='cuda:0') tensor(0.2913, device='cuda:0') tensor(-2.2834e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.015238
Average KL loss: 0.010489
Average total loss: 0.025727
tensor(0.0674, device='cuda:0') tensor(0.2916, device='cuda:0') tensor(-1.4178e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.015305
Average KL loss: 0.010485
Average total loss: 0.025790
tensor(0.0674, device='cuda:0') tensor(0.2918, device='cuda:0') tensor(-1.9468e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.016179
Average KL loss: 0.010481
Average total loss: 0.026660
tensor(0.0673, device='cuda:0') tensor(0.2921, device='cuda:0') tensor(-1.1523e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.015351
Average KL loss: 0.010480
Average total loss: 0.025831
tensor(0.0673, device='cuda:0') tensor(0.2924, device='cuda:0') tensor(-1.0364e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.015383
Average KL loss: 0.010477
Average total loss: 0.025860
tensor(0.0673, device='cuda:0') tensor(0.2927, device='cuda:0') tensor(-2.8373e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.015444
Average KL loss: 0.010475
Average total loss: 0.025919
tensor(0.0673, device='cuda:0') tensor(0.2930, device='cuda:0') tensor(-1.3221e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.015400
Average KL loss: 0.010472
Average total loss: 0.025872
tensor(0.0673, device='cuda:0') tensor(0.2933, device='cuda:0') tensor(-1.0078e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.015528
Average KL loss: 0.010470
Average total loss: 0.025998
tensor(0.0673, device='cuda:0') tensor(0.2936, device='cuda:0') tensor(-1.0623e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.015213
Average KL loss: 0.010467
Average total loss: 0.025680
tensor(0.0673, device='cuda:0') tensor(0.2939, device='cuda:0') tensor(-1.3491e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.015218
Average KL loss: 0.010464
Average total loss: 0.025682
tensor(0.0673, device='cuda:0') tensor(0.2942, device='cuda:0') tensor(-1.3573e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.015080
Average KL loss: 0.010461
Average total loss: 0.025541
 Percentile value: 3.7929532527923584
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =     142 /    1728             (  8.22%) | total_pruned =    1586 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     245 /   36864             (  0.66%) | total_pruned =   36619 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     377 /   36864             (  1.02%) | total_pruned =   36487 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     590 /   36864             (  1.60%) | total_pruned =   36274 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1106 /   36864             (  3.00%) | total_pruned =   35758 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3608 /   73728             (  4.89%) | total_pruned =   70120 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    7729 /  147456             (  5.24%) | total_pruned =  139727 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     717 /    8192             (  8.75%) | total_pruned =    7475 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4716 /  147456             (  3.20%) | total_pruned =  142740 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4067 /  147456             (  2.76%) | total_pruned =  143389 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   17851 /  294912             (  6.05%) | total_pruned =  277061 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   20852 /  589824             (  3.54%) | total_pruned =  568972 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      68 /     256             ( 26.56%) | total_pruned =     188 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2100 /   32768             (  6.41%) | total_pruned =   30668 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   13536 /  589824             (  2.29%) | total_pruned =  576288 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   11425 /  589824             (  1.94%) | total_pruned =  578399 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     130 /     256             ( 50.78%) | total_pruned =     126 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   26547 / 1179648             (  2.25%) | total_pruned = 1153101 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     284 /     512             ( 55.47%) | total_pruned =     228 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      80 /     512             ( 15.62%) | total_pruned =     432 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   21504 / 2359296             (  0.91%) | total_pruned = 2337792 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     362 /     512             ( 70.70%) | total_pruned =     150 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     272 /     512             ( 53.12%) | total_pruned =     240 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     633 /  131072             (  0.48%) | total_pruned =  130439 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     107 /     512             ( 20.90%) | total_pruned =     405 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     273 /     512             ( 53.32%) | total_pruned =     239 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   11296 / 2359296             (  0.48%) | total_pruned = 2348000 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     186 /     512             ( 36.33%) | total_pruned =     326 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   18469 / 2359296             (  0.78%) | total_pruned = 2340827 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     429 /     512             ( 83.79%) | total_pruned =      83 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     367 /     512             ( 71.68%) | total_pruned =     145 | shape = torch.Size([512])
linear.weight        | nonzeros =    3215 /    5120             ( 62.79%) | total_pruned =    1905 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 44/100 Loss: 0.029701 Accuracy: 85.43 99.99 % Best test Accuracy: 85.51%
tensor(0.0673, device='cuda:0') tensor(0.2945, device='cuda:0') tensor(-7.9265e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.024532
Average KL loss: 0.010184
Average total loss: 0.034716
tensor(0.0647, device='cuda:0') tensor(0.2834, device='cuda:0') tensor(-8.2805e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.023810
Average KL loss: 0.009801
Average total loss: 0.033611
tensor(0.0630, device='cuda:0') tensor(0.2780, device='cuda:0') tensor(-1.2565e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.024036
Average KL loss: 0.009559
Average total loss: 0.033595
tensor(0.0618, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(-1.0153e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.023985
Average KL loss: 0.009403
Average total loss: 0.033388
tensor(0.0609, device='cuda:0') tensor(0.2720, device='cuda:0') tensor(-7.6035e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.023192
Average KL loss: 0.009295
Average total loss: 0.032488
tensor(0.0602, device='cuda:0') tensor(0.2700, device='cuda:0') tensor(-6.8443e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.023440
Average KL loss: 0.009213
Average total loss: 0.032653
tensor(0.0597, device='cuda:0') tensor(0.2684, device='cuda:0') tensor(-1.0154e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.022932
Average KL loss: 0.009145
Average total loss: 0.032077
tensor(0.0592, device='cuda:0') tensor(0.2670, device='cuda:0') tensor(-9.0253e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.022993
Average KL loss: 0.009086
Average total loss: 0.032079
tensor(0.0589, device='cuda:0') tensor(0.2659, device='cuda:0') tensor(-1.0398e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.022743
Average KL loss: 0.009033
Average total loss: 0.031776
tensor(0.0585, device='cuda:0') tensor(0.2649, device='cuda:0') tensor(-5.8718e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.022389
Average KL loss: 0.008987
Average total loss: 0.031376
tensor(0.0583, device='cuda:0') tensor(0.2641, device='cuda:0') tensor(-9.4299e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.022080
Average KL loss: 0.008946
Average total loss: 0.031026
tensor(0.0580, device='cuda:0') tensor(0.2634, device='cuda:0') tensor(-7.4632e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.022049
Average KL loss: 0.008911
Average total loss: 0.030960
tensor(0.0578, device='cuda:0') tensor(0.2628, device='cuda:0') tensor(-8.5143e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.021791
Average KL loss: 0.008879
Average total loss: 0.030670
tensor(0.0577, device='cuda:0') tensor(0.2624, device='cuda:0') tensor(-6.4295e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.021958
Average KL loss: 0.008852
Average total loss: 0.030810
tensor(0.0575, device='cuda:0') tensor(0.2620, device='cuda:0') tensor(-6.6463e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.021718
Average KL loss: 0.008827
Average total loss: 0.030545
tensor(0.0574, device='cuda:0') tensor(0.2617, device='cuda:0') tensor(-5.9101e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.021457
Average KL loss: 0.008805
Average total loss: 0.030262
tensor(0.0573, device='cuda:0') tensor(0.2614, device='cuda:0') tensor(-8.4693e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.021725
Average KL loss: 0.008785
Average total loss: 0.030510
tensor(0.0572, device='cuda:0') tensor(0.2612, device='cuda:0') tensor(-6.9711e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.021359
Average KL loss: 0.008768
Average total loss: 0.030127
tensor(0.0571, device='cuda:0') tensor(0.2610, device='cuda:0') tensor(-1.0851e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.021513
Average KL loss: 0.008752
Average total loss: 0.030265
tensor(0.0570, device='cuda:0') tensor(0.2609, device='cuda:0') tensor(-6.9917e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.021056
Average KL loss: 0.008737
Average total loss: 0.029792
tensor(0.0569, device='cuda:0') tensor(0.2609, device='cuda:0') tensor(-5.4433e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.021070
Average KL loss: 0.008723
Average total loss: 0.029793
tensor(0.0569, device='cuda:0') tensor(0.2608, device='cuda:0') tensor(-4.7693e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.020680
Average KL loss: 0.008711
Average total loss: 0.029391
tensor(0.0568, device='cuda:0') tensor(0.2608, device='cuda:0') tensor(-5.5071e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.020500
Average KL loss: 0.008698
Average total loss: 0.029198
tensor(0.0568, device='cuda:0') tensor(0.2608, device='cuda:0') tensor(-5.7040e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.021681
Average KL loss: 0.008686
Average total loss: 0.030367
tensor(0.0567, device='cuda:0') tensor(0.2608, device='cuda:0') tensor(-4.3544e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.020142
Average KL loss: 0.008675
Average total loss: 0.028817
tensor(0.0567, device='cuda:0') tensor(0.2608, device='cuda:0') tensor(-5.1777e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.020424
Average KL loss: 0.008665
Average total loss: 0.029089
tensor(0.0567, device='cuda:0') tensor(0.2608, device='cuda:0') tensor(-4.6692e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.020442
Average KL loss: 0.008654
Average total loss: 0.029096
tensor(0.0566, device='cuda:0') tensor(0.2609, device='cuda:0') tensor(-4.8480e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.020187
Average KL loss: 0.008645
Average total loss: 0.028832
tensor(0.0566, device='cuda:0') tensor(0.2610, device='cuda:0') tensor(-6.3627e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.020039
Average KL loss: 0.008636
Average total loss: 0.028675
tensor(0.0566, device='cuda:0') tensor(0.2611, device='cuda:0') tensor(-1.0697e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.019955
Average KL loss: 0.008627
Average total loss: 0.028582
tensor(0.0565, device='cuda:0') tensor(0.2612, device='cuda:0') tensor(-5.8366e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.019830
Average KL loss: 0.008619
Average total loss: 0.028449
tensor(0.0565, device='cuda:0') tensor(0.2613, device='cuda:0') tensor(-6.9793e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.019713
Average KL loss: 0.008611
Average total loss: 0.028323
tensor(0.0565, device='cuda:0') tensor(0.2614, device='cuda:0') tensor(-4.6442e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.019607
Average KL loss: 0.008602
Average total loss: 0.028209
tensor(0.0565, device='cuda:0') tensor(0.2615, device='cuda:0') tensor(-4.4319e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.019562
Average KL loss: 0.008594
Average total loss: 0.028156
tensor(0.0564, device='cuda:0') tensor(0.2617, device='cuda:0') tensor(-3.7317e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.019356
Average KL loss: 0.008586
Average total loss: 0.027943
tensor(0.0564, device='cuda:0') tensor(0.2618, device='cuda:0') tensor(-4.2866e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.019369
Average KL loss: 0.008579
Average total loss: 0.027948
tensor(0.0564, device='cuda:0') tensor(0.2620, device='cuda:0') tensor(-5.8421e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.019377
Average KL loss: 0.008572
Average total loss: 0.027949
tensor(0.0564, device='cuda:0') tensor(0.2621, device='cuda:0') tensor(-4.6587e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.019268
Average KL loss: 0.008565
Average total loss: 0.027833
tensor(0.0564, device='cuda:0') tensor(0.2622, device='cuda:0') tensor(-5.1015e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.019711
Average KL loss: 0.008558
Average total loss: 0.028269
tensor(0.0564, device='cuda:0') tensor(0.2624, device='cuda:0') tensor(-5.7793e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.019538
Average KL loss: 0.008552
Average total loss: 0.028090
tensor(0.0564, device='cuda:0') tensor(0.2626, device='cuda:0') tensor(-4.4303e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.018791
Average KL loss: 0.008545
Average total loss: 0.027335
tensor(0.0563, device='cuda:0') tensor(0.2627, device='cuda:0') tensor(-5.1661e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.019230
Average KL loss: 0.008538
Average total loss: 0.027767
tensor(0.0563, device='cuda:0') tensor(0.2629, device='cuda:0') tensor(-4.0823e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.018974
Average KL loss: 0.008532
Average total loss: 0.027506
tensor(0.0563, device='cuda:0') tensor(0.2631, device='cuda:0') tensor(-2.4666e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.018910
Average KL loss: 0.008525
Average total loss: 0.027435
tensor(0.0563, device='cuda:0') tensor(0.2633, device='cuda:0') tensor(-4.3970e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.018626
Average KL loss: 0.008519
Average total loss: 0.027144
tensor(0.0563, device='cuda:0') tensor(0.2634, device='cuda:0') tensor(-4.4733e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.022971
Average KL loss: 0.008512
Average total loss: 0.031483
tensor(0.0563, device='cuda:0') tensor(0.2636, device='cuda:0') tensor(-1.9400e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.020513
Average KL loss: 0.008507
Average total loss: 0.029020
tensor(0.0563, device='cuda:0') tensor(0.2638, device='cuda:0') tensor(-2.7493e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.018590
Average KL loss: 0.008501
Average total loss: 0.027091
tensor(0.0563, device='cuda:0') tensor(0.2640, device='cuda:0') tensor(-4.3288e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.018707
Average KL loss: 0.008495
Average total loss: 0.027203
tensor(0.0563, device='cuda:0') tensor(0.2642, device='cuda:0') tensor(-2.4809e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.018458
Average KL loss: 0.008490
Average total loss: 0.026948
tensor(0.0563, device='cuda:0') tensor(0.2644, device='cuda:0') tensor(-4.2525e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.018387
Average KL loss: 0.008483
Average total loss: 0.026870
tensor(0.0562, device='cuda:0') tensor(0.2646, device='cuda:0') tensor(-3.1093e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.018305
Average KL loss: 0.008477
Average total loss: 0.026783
tensor(0.0562, device='cuda:0') tensor(0.2648, device='cuda:0') tensor(-3.1206e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.018642
Average KL loss: 0.008471
Average total loss: 0.027113
tensor(0.0562, device='cuda:0') tensor(0.2650, device='cuda:0') tensor(-3.3897e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.018255
Average KL loss: 0.008466
Average total loss: 0.026721
tensor(0.0562, device='cuda:0') tensor(0.2652, device='cuda:0') tensor(-4.5584e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.019927
Average KL loss: 0.008460
Average total loss: 0.028387
tensor(0.0562, device='cuda:0') tensor(0.2655, device='cuda:0') tensor(-3.0313e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.018234
Average KL loss: 0.008455
Average total loss: 0.026689
tensor(0.0562, device='cuda:0') tensor(0.2657, device='cuda:0') tensor(-3.6022e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.018137
Average KL loss: 0.008450
Average total loss: 0.026587
tensor(0.0562, device='cuda:0') tensor(0.2659, device='cuda:0') tensor(-2.0936e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.018333
Average KL loss: 0.008445
Average total loss: 0.026777
tensor(0.0562, device='cuda:0') tensor(0.2662, device='cuda:0') tensor(-5.2558e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.017944
Average KL loss: 0.008440
Average total loss: 0.026384
tensor(0.0562, device='cuda:0') tensor(0.2664, device='cuda:0') tensor(-1.6814e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.017905
Average KL loss: 0.008434
Average total loss: 0.026340
tensor(0.0562, device='cuda:0') tensor(0.2667, device='cuda:0') tensor(-3.4431e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.017969
Average KL loss: 0.008429
Average total loss: 0.026398
tensor(0.0562, device='cuda:0') tensor(0.2669, device='cuda:0') tensor(-3.5246e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.017963
Average KL loss: 0.008425
Average total loss: 0.026388
tensor(0.0562, device='cuda:0') tensor(0.2671, device='cuda:0') tensor(-2.1432e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.018212
Average KL loss: 0.008419
Average total loss: 0.026631
tensor(0.0562, device='cuda:0') tensor(0.2674, device='cuda:0') tensor(-2.7313e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.017804
Average KL loss: 0.008414
Average total loss: 0.026218
tensor(0.0562, device='cuda:0') tensor(0.2676, device='cuda:0') tensor(-3.1782e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.018185
Average KL loss: 0.008410
Average total loss: 0.026595
tensor(0.0562, device='cuda:0') tensor(0.2679, device='cuda:0') tensor(-3.1454e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.017601
Average KL loss: 0.008405
Average total loss: 0.026006
tensor(0.0562, device='cuda:0') tensor(0.2681, device='cuda:0') tensor(-1.5529e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.017927
Average KL loss: 0.008400
Average total loss: 0.026328
tensor(0.0562, device='cuda:0') tensor(0.2683, device='cuda:0') tensor(-3.7265e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.017866
Average KL loss: 0.008395
Average total loss: 0.026261
tensor(0.0562, device='cuda:0') tensor(0.2686, device='cuda:0') tensor(-2.3097e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.017555
Average KL loss: 0.008390
Average total loss: 0.025945
tensor(0.0562, device='cuda:0') tensor(0.2689, device='cuda:0') tensor(-2.1014e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.017676
Average KL loss: 0.008386
Average total loss: 0.026062
tensor(0.0562, device='cuda:0') tensor(0.2691, device='cuda:0') tensor(-2.9423e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.017552
Average KL loss: 0.008381
Average total loss: 0.025933
tensor(0.0562, device='cuda:0') tensor(0.2693, device='cuda:0') tensor(-2.4566e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.017292
Average KL loss: 0.008376
Average total loss: 0.025667
tensor(0.0562, device='cuda:0') tensor(0.2696, device='cuda:0') tensor(-2.8003e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.017393
Average KL loss: 0.008371
Average total loss: 0.025764
tensor(0.0562, device='cuda:0') tensor(0.2698, device='cuda:0') tensor(-2.1767e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.017311
Average KL loss: 0.008366
Average total loss: 0.025677
tensor(0.0562, device='cuda:0') tensor(0.2700, device='cuda:0') tensor(-1.7217e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.017370
Average KL loss: 0.008361
Average total loss: 0.025731
tensor(0.0562, device='cuda:0') tensor(0.2703, device='cuda:0') tensor(-1.9688e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.017428
Average KL loss: 0.008356
Average total loss: 0.025784
tensor(0.0562, device='cuda:0') tensor(0.2706, device='cuda:0') tensor(-1.9701e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.017271
Average KL loss: 0.008351
Average total loss: 0.025622
tensor(0.0562, device='cuda:0') tensor(0.2708, device='cuda:0') tensor(-1.5078e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.017137
Average KL loss: 0.008347
Average total loss: 0.025483
tensor(0.0562, device='cuda:0') tensor(0.2710, device='cuda:0') tensor(-2.9336e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.017109
Average KL loss: 0.008342
Average total loss: 0.025450
tensor(0.0562, device='cuda:0') tensor(0.2713, device='cuda:0') tensor(-2.6887e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.017176
Average KL loss: 0.008337
Average total loss: 0.025513
tensor(0.0562, device='cuda:0') tensor(0.2715, device='cuda:0') tensor(-1.5076e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.017084
Average KL loss: 0.008332
Average total loss: 0.025416
tensor(0.0562, device='cuda:0') tensor(0.2718, device='cuda:0') tensor(-2.7359e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.016967
Average KL loss: 0.008328
Average total loss: 0.025295
tensor(0.0562, device='cuda:0') tensor(0.2720, device='cuda:0') tensor(-2.3164e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.017348
Average KL loss: 0.008324
Average total loss: 0.025671
tensor(0.0562, device='cuda:0') tensor(0.2723, device='cuda:0') tensor(-2.2162e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.017064
Average KL loss: 0.008319
Average total loss: 0.025384
tensor(0.0562, device='cuda:0') tensor(0.2726, device='cuda:0') tensor(-2.5159e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.017163
Average KL loss: 0.008315
Average total loss: 0.025478
tensor(0.0562, device='cuda:0') tensor(0.2728, device='cuda:0') tensor(-1.2388e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.016980
Average KL loss: 0.008311
Average total loss: 0.025291
tensor(0.0562, device='cuda:0') tensor(0.2730, device='cuda:0') tensor(-2.3109e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.017092
Average KL loss: 0.008306
Average total loss: 0.025398
tensor(0.0562, device='cuda:0') tensor(0.2733, device='cuda:0') tensor(-2.1726e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.016963
Average KL loss: 0.008302
Average total loss: 0.025265
tensor(0.0562, device='cuda:0') tensor(0.2735, device='cuda:0') tensor(-2.7217e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.016840
Average KL loss: 0.008298
Average total loss: 0.025137
tensor(0.0562, device='cuda:0') tensor(0.2738, device='cuda:0') tensor(-1.9280e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.017178
Average KL loss: 0.008293
Average total loss: 0.025471
tensor(0.0562, device='cuda:0') tensor(0.2741, device='cuda:0') tensor(-1.6412e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.016705
Average KL loss: 0.008289
Average total loss: 0.024994
tensor(0.0562, device='cuda:0') tensor(0.2743, device='cuda:0') tensor(-2.4043e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.016735
Average KL loss: 0.008285
Average total loss: 0.025020
tensor(0.0562, device='cuda:0') tensor(0.2746, device='cuda:0') tensor(-2.0987e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.016649
Average KL loss: 0.008281
Average total loss: 0.024930
tensor(0.0562, device='cuda:0') tensor(0.2749, device='cuda:0') tensor(-1.8366e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.016518
Average KL loss: 0.008276
Average total loss: 0.024795
tensor(0.0562, device='cuda:0') tensor(0.2751, device='cuda:0') tensor(-2.1880e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.016682
Average KL loss: 0.008272
Average total loss: 0.024954
tensor(0.0562, device='cuda:0') tensor(0.2754, device='cuda:0') tensor(-3.6737e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.016458
Average KL loss: 0.008268
Average total loss: 0.024726
tensor(0.0562, device='cuda:0') tensor(0.2756, device='cuda:0') tensor(-2.2143e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.016586
Average KL loss: 0.008264
Average total loss: 0.024850
tensor(0.0562, device='cuda:0') tensor(0.2759, device='cuda:0') tensor(-1.4633e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.016588
Average KL loss: 0.008260
Average total loss: 0.024847
tensor(0.0562, device='cuda:0') tensor(0.2762, device='cuda:0') tensor(-2.1518e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.016502
Average KL loss: 0.008256
Average total loss: 0.024757
tensor(0.0562, device='cuda:0') tensor(0.2764, device='cuda:0') tensor(-1.3607e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.016442
Average KL loss: 0.008251
Average total loss: 0.024693
tensor(0.0562, device='cuda:0') tensor(0.2767, device='cuda:0') tensor(-3.4558e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.016489
Average KL loss: 0.008247
Average total loss: 0.024736
tensor(0.0562, device='cuda:0') tensor(0.2769, device='cuda:0') tensor(-2.4023e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.016597
Average KL loss: 0.008243
Average total loss: 0.024839
tensor(0.0562, device='cuda:0') tensor(0.2772, device='cuda:0') tensor(-1.8708e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.016552
Average KL loss: 0.008238
Average total loss: 0.024790
tensor(0.0562, device='cuda:0') tensor(0.2775, device='cuda:0') tensor(-2.2319e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.016496
Average KL loss: 0.008234
Average total loss: 0.024730
tensor(0.0562, device='cuda:0') tensor(0.2778, device='cuda:0') tensor(-2.8619e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.016290
Average KL loss: 0.008230
Average total loss: 0.024520
tensor(0.0562, device='cuda:0') tensor(0.2780, device='cuda:0') tensor(-1.7506e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.016692
Average KL loss: 0.008226
Average total loss: 0.024918
tensor(0.0562, device='cuda:0') tensor(0.2783, device='cuda:0') tensor(-1.9404e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.016194
Average KL loss: 0.008222
Average total loss: 0.024416
tensor(0.0562, device='cuda:0') tensor(0.2786, device='cuda:0') tensor(-2.0096e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.016544
Average KL loss: 0.008218
Average total loss: 0.024762
tensor(0.0562, device='cuda:0') tensor(0.2789, device='cuda:0') tensor(-1.5822e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.016263
Average KL loss: 0.008215
Average total loss: 0.024478
tensor(0.0562, device='cuda:0') tensor(0.2792, device='cuda:0') tensor(-1.5230e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.016106
Average KL loss: 0.008211
Average total loss: 0.024317
tensor(0.0562, device='cuda:0') tensor(0.2794, device='cuda:0') tensor(-1.5185e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.016113
Average KL loss: 0.008207
Average total loss: 0.024320
tensor(0.0562, device='cuda:0') tensor(0.2797, device='cuda:0') tensor(-1.4176e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.016249
Average KL loss: 0.008203
Average total loss: 0.024452
tensor(0.0562, device='cuda:0') tensor(0.2799, device='cuda:0') tensor(-1.5154e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.016042
Average KL loss: 0.008199
Average total loss: 0.024241
tensor(0.0562, device='cuda:0') tensor(0.2802, device='cuda:0') tensor(-1.4927e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.016126
Average KL loss: 0.008195
Average total loss: 0.024321
tensor(0.0562, device='cuda:0') tensor(0.2805, device='cuda:0') tensor(-2.6055e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.016108
Average KL loss: 0.008191
Average total loss: 0.024299
tensor(0.0562, device='cuda:0') tensor(0.2808, device='cuda:0') tensor(-1.7678e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.016084
Average KL loss: 0.008187
Average total loss: 0.024271
tensor(0.0562, device='cuda:0') tensor(0.2811, device='cuda:0') tensor(-1.8663e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.016169
Average KL loss: 0.008183
Average total loss: 0.024352
tensor(0.0562, device='cuda:0') tensor(0.2814, device='cuda:0') tensor(-1.3031e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.016307
Average KL loss: 0.008180
Average total loss: 0.024488
tensor(0.0562, device='cuda:0') tensor(0.2817, device='cuda:0') tensor(-1.0817e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.016126
Average KL loss: 0.008177
Average total loss: 0.024303
tensor(0.0562, device='cuda:0') tensor(0.2819, device='cuda:0') tensor(-1.7574e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.016019
Average KL loss: 0.008173
Average total loss: 0.024192
tensor(0.0562, device='cuda:0') tensor(0.2822, device='cuda:0') tensor(-9.9006e-11, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.016017
Average KL loss: 0.008169
Average total loss: 0.024186
tensor(0.0562, device='cuda:0') tensor(0.2825, device='cuda:0') tensor(-4.6115e-11, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.015966
Average KL loss: 0.008166
Average total loss: 0.024132
tensor(0.0562, device='cuda:0') tensor(0.2828, device='cuda:0') tensor(-1.9704e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.015827
Average KL loss: 0.008162
Average total loss: 0.023989
tensor(0.0562, device='cuda:0') tensor(0.2831, device='cuda:0') tensor(-2.1183e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.015926
Average KL loss: 0.008159
Average total loss: 0.024085
tensor(0.0562, device='cuda:0') tensor(0.2834, device='cuda:0') tensor(-8.7051e-11, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.015896
Average KL loss: 0.008155
Average total loss: 0.024051
tensor(0.0562, device='cuda:0') tensor(0.2836, device='cuda:0') tensor(-1.5292e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.015774
Average KL loss: 0.008152
Average total loss: 0.023926
tensor(0.0563, device='cuda:0') tensor(0.2839, device='cuda:0') tensor(-1.8807e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.015966
Average KL loss: 0.008148
Average total loss: 0.024115
tensor(0.0563, device='cuda:0') tensor(0.2842, device='cuda:0') tensor(-2.3230e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.015711
Average KL loss: 0.008145
Average total loss: 0.023856
tensor(0.0563, device='cuda:0') tensor(0.2845, device='cuda:0') tensor(-1.6113e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.015721
Average KL loss: 0.008142
Average total loss: 0.023863
tensor(0.0563, device='cuda:0') tensor(0.2848, device='cuda:0') tensor(-8.4288e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.015957
Average KL loss: 0.008139
Average total loss: 0.024096
tensor(0.0563, device='cuda:0') tensor(0.2851, device='cuda:0') tensor(-8.3021e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.016253
Average KL loss: 0.008136
Average total loss: 0.024389
tensor(0.0563, device='cuda:0') tensor(0.2854, device='cuda:0') tensor(-1.1326e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.015845
Average KL loss: 0.008133
Average total loss: 0.023978
tensor(0.0563, device='cuda:0') tensor(0.2857, device='cuda:0') tensor(-1.3865e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.015665
Average KL loss: 0.008130
Average total loss: 0.023795
tensor(0.0563, device='cuda:0') tensor(0.2860, device='cuda:0') tensor(-1.6867e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.015901
Average KL loss: 0.008127
Average total loss: 0.024027
tensor(0.0563, device='cuda:0') tensor(0.2863, device='cuda:0') tensor(-1.4741e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.015686
Average KL loss: 0.008123
Average total loss: 0.023810
tensor(0.0563, device='cuda:0') tensor(0.2865, device='cuda:0') tensor(-9.4949e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.015883
Average KL loss: 0.008120
Average total loss: 0.024004
tensor(0.0563, device='cuda:0') tensor(0.2868, device='cuda:0') tensor(-8.0173e-11, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.015604
Average KL loss: 0.008118
Average total loss: 0.023722
tensor(0.0563, device='cuda:0') tensor(0.2871, device='cuda:0') tensor(-1.1435e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.015602
Average KL loss: 0.008115
Average total loss: 0.023717
tensor(0.0563, device='cuda:0') tensor(0.2874, device='cuda:0') tensor(-1.1163e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.015644
Average KL loss: 0.008112
Average total loss: 0.023756
tensor(0.0563, device='cuda:0') tensor(0.2877, device='cuda:0') tensor(-7.6089e-11, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.015471
Average KL loss: 0.008109
Average total loss: 0.023580
tensor(0.0563, device='cuda:0') tensor(0.2880, device='cuda:0') tensor(-6.1739e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.015453
Average KL loss: 0.008106
Average total loss: 0.023559
tensor(0.0563, device='cuda:0') tensor(0.2882, device='cuda:0') tensor(-1.1080e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.015766
Average KL loss: 0.008103
Average total loss: 0.023868
tensor(0.0563, device='cuda:0') tensor(0.2886, device='cuda:0') tensor(-8.3877e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.015560
Average KL loss: 0.008100
Average total loss: 0.023660
tensor(0.0563, device='cuda:0') tensor(0.2889, device='cuda:0') tensor(-1.1257e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.015533
Average KL loss: 0.008097
Average total loss: 0.023630
tensor(0.0563, device='cuda:0') tensor(0.2892, device='cuda:0') tensor(-7.6794e-11, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.015372
Average KL loss: 0.008094
Average total loss: 0.023466
tensor(0.0563, device='cuda:0') tensor(0.2895, device='cuda:0') tensor(-8.9436e-11, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.015577
Average KL loss: 0.008091
Average total loss: 0.023668
tensor(0.0564, device='cuda:0') tensor(0.2897, device='cuda:0') tensor(-5.2545e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.015311
Average KL loss: 0.008088
Average total loss: 0.023399
tensor(0.0564, device='cuda:0') tensor(0.2900, device='cuda:0') tensor(-1.0279e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.015331
Average KL loss: 0.008085
Average total loss: 0.023417
tensor(0.0564, device='cuda:0') tensor(0.2904, device='cuda:0') tensor(-6.2519e-11, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.015419
Average KL loss: 0.008083
Average total loss: 0.023502
tensor(0.0564, device='cuda:0') tensor(0.2906, device='cuda:0') tensor(-7.7477e-11, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.015626
Average KL loss: 0.008080
Average total loss: 0.023706
tensor(0.0564, device='cuda:0') tensor(0.2909, device='cuda:0') tensor(-1.1275e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.015367
Average KL loss: 0.008077
Average total loss: 0.023444
tensor(0.0564, device='cuda:0') tensor(0.2913, device='cuda:0') tensor(-5.2059e-12, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.015628
Average KL loss: 0.008074
Average total loss: 0.023703
tensor(0.0564, device='cuda:0') tensor(0.2916, device='cuda:0') tensor(-1.1284e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.015239
Average KL loss: 0.008072
Average total loss: 0.023311
tensor(0.0564, device='cuda:0') tensor(0.2918, device='cuda:0') tensor(-6.4027e-11, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.015363
Average KL loss: 0.008069
Average total loss: 0.023431
tensor(0.0564, device='cuda:0') tensor(0.2921, device='cuda:0') tensor(-1.1414e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.015348
Average KL loss: 0.008066
Average total loss: 0.023414
tensor(0.0564, device='cuda:0') tensor(0.2925, device='cuda:0') tensor(-7.1639e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.015476
Average KL loss: 0.008063
Average total loss: 0.023539
tensor(0.0564, device='cuda:0') tensor(0.2927, device='cuda:0') tensor(-1.1329e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.015372
Average KL loss: 0.008061
Average total loss: 0.023433
tensor(0.0564, device='cuda:0') tensor(0.2930, device='cuda:0') tensor(-2.5648e-11, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.015475
Average KL loss: 0.008058
Average total loss: 0.023533
tensor(0.0564, device='cuda:0') tensor(0.2933, device='cuda:0') tensor(-7.3272e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.015396
Average KL loss: 0.008056
Average total loss: 0.023452
tensor(0.0564, device='cuda:0') tensor(0.2937, device='cuda:0') tensor(-4.5253e-11, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.015173
Average KL loss: 0.008053
Average total loss: 0.023226
tensor(0.0564, device='cuda:0') tensor(0.2939, device='cuda:0') tensor(-1.0767e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.015095
Average KL loss: 0.008050
Average total loss: 0.023146
tensor(0.0565, device='cuda:0') tensor(0.2943, device='cuda:0') tensor(-5.1479e-11, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.015186
Average KL loss: 0.008048
Average total loss: 0.023234
tensor(0.0565, device='cuda:0') tensor(0.2945, device='cuda:0') tensor(-7.0083e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.015066
Average KL loss: 0.008044
Average total loss: 0.023110
tensor(0.0565, device='cuda:0') tensor(0.2948, device='cuda:0') tensor(-4.9460e-11, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.015156
Average KL loss: 0.008041
Average total loss: 0.023198
tensor(0.0565, device='cuda:0') tensor(0.2951, device='cuda:0') tensor(-3.7350e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.015131
Average KL loss: 0.008038
Average total loss: 0.023169
tensor(0.0565, device='cuda:0') tensor(0.2953, device='cuda:0') tensor(-6.7096e-11, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.015173
Average KL loss: 0.008036
Average total loss: 0.023209
tensor(0.0565, device='cuda:0') tensor(0.2956, device='cuda:0') tensor(-1.3114e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.015087
Average KL loss: 0.008034
Average total loss: 0.023120
tensor(0.0565, device='cuda:0') tensor(0.2959, device='cuda:0') tensor(-8.2453e-11, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.015078
Average KL loss: 0.008031
Average total loss: 0.023109
tensor(0.0565, device='cuda:0') tensor(0.2962, device='cuda:0') tensor(-8.5177e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.015082
Average KL loss: 0.008029
Average total loss: 0.023111
tensor(0.0565, device='cuda:0') tensor(0.2965, device='cuda:0') tensor(-1.4799e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.015161
Average KL loss: 0.008027
Average total loss: 0.023187
tensor(0.0565, device='cuda:0') tensor(0.2968, device='cuda:0') tensor(-7.1338e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.015195
Average KL loss: 0.008024
Average total loss: 0.023220
tensor(0.0565, device='cuda:0') tensor(0.2970, device='cuda:0') tensor(-6.5069e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.014964
Average KL loss: 0.008022
Average total loss: 0.022986
tensor(0.0565, device='cuda:0') tensor(0.2973, device='cuda:0') tensor(-1.5256e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.014957
Average KL loss: 0.008019
Average total loss: 0.022976
tensor(0.0565, device='cuda:0') tensor(0.2976, device='cuda:0') tensor(-7.5926e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.015053
Average KL loss: 0.008016
Average total loss: 0.023070
tensor(0.0565, device='cuda:0') tensor(0.2979, device='cuda:0') tensor(-3.3988e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.015015
Average KL loss: 0.008014
Average total loss: 0.023029
tensor(0.0565, device='cuda:0') tensor(0.2982, device='cuda:0') tensor(-5.1106e-11, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.015262
Average KL loss: 0.008012
Average total loss: 0.023274
tensor(0.0565, device='cuda:0') tensor(0.2985, device='cuda:0') tensor(-3.0274e-11, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.015031
Average KL loss: 0.008010
Average total loss: 0.023041
tensor(0.0565, device='cuda:0') tensor(0.2988, device='cuda:0') tensor(-1.3431e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.015167
Average KL loss: 0.008008
Average total loss: 0.023175
tensor(0.0566, device='cuda:0') tensor(0.2992, device='cuda:0') tensor(-8.4587e-11, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.015078
Average KL loss: 0.008006
Average total loss: 0.023084
tensor(0.0566, device='cuda:0') tensor(0.2995, device='cuda:0') tensor(-9.6660e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.015057
Average KL loss: 0.008004
Average total loss: 0.023061
tensor(0.0566, device='cuda:0') tensor(0.2997, device='cuda:0') tensor(-1.5248e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.015123
Average KL loss: 0.008002
Average total loss: 0.023124
tensor(0.0566, device='cuda:0') tensor(0.3001, device='cuda:0') tensor(-7.8331e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.014877
Average KL loss: 0.007999
Average total loss: 0.022876
tensor(0.0566, device='cuda:0') tensor(0.3003, device='cuda:0') tensor(-8.5282e-11, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.014960
Average KL loss: 0.007997
Average total loss: 0.022957
tensor(0.0566, device='cuda:0') tensor(0.3006, device='cuda:0') tensor(-7.0459e-11, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.014903
Average KL loss: 0.007995
Average total loss: 0.022898
tensor(0.0566, device='cuda:0') tensor(0.3009, device='cuda:0') tensor(-4.2273e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.014874
Average KL loss: 0.007992
Average total loss: 0.022866
tensor(0.0566, device='cuda:0') tensor(0.3012, device='cuda:0') tensor(-2.2145e-11, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.015063
Average KL loss: 0.007990
Average total loss: 0.023053
tensor(0.0566, device='cuda:0') tensor(0.3014, device='cuda:0') tensor(-1.1304e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.015071
Average KL loss: 0.007987
Average total loss: 0.023058
tensor(0.0566, device='cuda:0') tensor(0.3017, device='cuda:0') tensor(-3.7550e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.014945
Average KL loss: 0.007985
Average total loss: 0.022930
tensor(0.0566, device='cuda:0') tensor(0.3020, device='cuda:0') tensor(-7.4828e-12, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.014936
Average KL loss: 0.007983
Average total loss: 0.022919
tensor(0.0566, device='cuda:0') tensor(0.3023, device='cuda:0') tensor(-5.2240e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.015019
Average KL loss: 0.007981
Average total loss: 0.023000
tensor(0.0566, device='cuda:0') tensor(0.3026, device='cuda:0') tensor(-7.0402e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.015200
Average KL loss: 0.007979
Average total loss: 0.023179
tensor(0.0566, device='cuda:0') tensor(0.3029, device='cuda:0') tensor(-4.5819e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.014820
Average KL loss: 0.007977
Average total loss: 0.022798
tensor(0.0567, device='cuda:0') tensor(0.3032, device='cuda:0') tensor(-4.2075e-11, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.014678
Average KL loss: 0.007975
Average total loss: 0.022653
tensor(0.0567, device='cuda:0') tensor(0.3035, device='cuda:0') tensor(-4.0475e-11, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.014773
Average KL loss: 0.007973
Average total loss: 0.022745
tensor(0.0567, device='cuda:0') tensor(0.3038, device='cuda:0') tensor(-7.6145e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.014879
Average KL loss: 0.007970
Average total loss: 0.022849
tensor(0.0567, device='cuda:0') tensor(0.3040, device='cuda:0') tensor(-4.4815e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.014686
Average KL loss: 0.007969
Average total loss: 0.022654
tensor(0.0567, device='cuda:0') tensor(0.3043, device='cuda:0') tensor(-3.1784e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.014841
Average KL loss: 0.007967
Average total loss: 0.022808
tensor(0.0567, device='cuda:0') tensor(0.3046, device='cuda:0') tensor(-5.9502e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.014830
Average KL loss: 0.007965
Average total loss: 0.022795
tensor(0.0567, device='cuda:0') tensor(0.3049, device='cuda:0') tensor(-1.1129e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.014757
Average KL loss: 0.007964
Average total loss: 0.022721
tensor(0.0567, device='cuda:0') tensor(0.3052, device='cuda:0') tensor(-6.2724e-11, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.014700
Average KL loss: 0.007962
Average total loss: 0.022662
 Percentile value: 5.519760608673096
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =     130 /    1728             (  7.52%) | total_pruned =    1598 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     166 /   36864             (  0.45%) | total_pruned =   36698 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     273 /   36864             (  0.74%) | total_pruned =   36591 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     387 /   36864             (  1.05%) | total_pruned =   36477 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     756 /   36864             (  2.05%) | total_pruned =   36108 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1867 /   73728             (  2.53%) | total_pruned =   71861 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4280 /  147456             (  2.90%) | total_pruned =  143176 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     471 /    8192             (  5.75%) | total_pruned =    7721 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2671 /  147456             (  1.81%) | total_pruned =  144785 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2460 /  147456             (  1.67%) | total_pruned =  144996 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8980 /  294912             (  3.04%) | total_pruned =  285932 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     150 /     256             ( 58.59%) | total_pruned =     106 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      44 /     256             ( 17.19%) | total_pruned =     212 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   11419 /  589824             (  1.94%) | total_pruned =  578405 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      66 /     256             ( 25.78%) | total_pruned =     190 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1265 /   32768             (  3.86%) | total_pruned =   31503 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     103 /     256             ( 40.23%) | total_pruned =     153 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      50 /     256             ( 19.53%) | total_pruned =     206 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6851 /  589824             (  1.16%) | total_pruned =  582973 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     161 /     256             ( 62.89%) | total_pruned =      95 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    5517 /  589824             (  0.94%) | total_pruned =  584307 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      78 /     256             ( 30.47%) | total_pruned =     178 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   10974 / 1179648             (  0.93%) | total_pruned = 1168674 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     267 /     512             ( 52.15%) | total_pruned =     245 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    8811 / 2359296             (  0.37%) | total_pruned = 2350485 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     310 /     512             ( 60.55%) | total_pruned =     202 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     234 /     512             ( 45.70%) | total_pruned =     278 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     268 /  131072             (  0.20%) | total_pruned =  130804 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    5485 / 2359296             (  0.23%) | total_pruned = 2353811 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     148 /     512             ( 28.91%) | total_pruned =     364 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    8433 / 2359296             (  0.36%) | total_pruned = 2350863 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     394 /     512             ( 76.95%) | total_pruned =     118 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     282 /     512             ( 55.08%) | total_pruned =     230 | shape = torch.Size([512])
linear.weight        | nonzeros =    2385 /    5120             ( 46.58%) | total_pruned =    2735 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 60/100 Loss: 0.021114 Accuracy: 83.69 99.99 % Best test Accuracy: 84.63%
tensor(0.0567, device='cuda:0') tensor(0.3055, device='cuda:0') tensor(-3.6106e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.022397
Average KL loss: 0.007817
Average total loss: 0.030214
tensor(0.0550, device='cuda:0') tensor(0.2945, device='cuda:0') tensor(-1.9738e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.022141
Average KL loss: 0.007535
Average total loss: 0.029676
tensor(0.0534, device='cuda:0') tensor(0.2859, device='cuda:0') tensor(-2.2555e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.022324
Average KL loss: 0.007263
Average total loss: 0.029587
tensor(0.0519, device='cuda:0') tensor(0.2786, device='cuda:0') tensor(-3.1579e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.022147
Average KL loss: 0.006991
Average total loss: 0.029139
tensor(0.0504, device='cuda:0') tensor(0.2722, device='cuda:0') tensor(-1.4843e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.022248
Average KL loss: 0.006722
Average total loss: 0.028970
tensor(0.0490, device='cuda:0') tensor(0.2668, device='cuda:0') tensor(-1.8614e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.022064
Average KL loss: 0.006459
Average total loss: 0.028523
tensor(0.0477, device='cuda:0') tensor(0.2622, device='cuda:0') tensor(-2.3422e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.022655
Average KL loss: 0.006216
Average total loss: 0.028871
tensor(0.0465, device='cuda:0') tensor(0.2586, device='cuda:0') tensor(-2.1952e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.022386
Average KL loss: 0.006006
Average total loss: 0.028391
tensor(0.0455, device='cuda:0') tensor(0.2558, device='cuda:0') tensor(-2.4669e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.022123
Average KL loss: 0.005841
Average total loss: 0.027964
tensor(0.0446, device='cuda:0') tensor(0.2537, device='cuda:0') tensor(-3.2781e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.021575
Average KL loss: 0.005726
Average total loss: 0.027300
tensor(0.0439, device='cuda:0') tensor(0.2522, device='cuda:0') tensor(-2.9479e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.021763
Average KL loss: 0.005650
Average total loss: 0.027413
tensor(0.0434, device='cuda:0') tensor(0.2510, device='cuda:0') tensor(-2.4595e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.022001
Average KL loss: 0.005599
Average total loss: 0.027601
tensor(0.0430, device='cuda:0') tensor(0.2500, device='cuda:0') tensor(-3.1045e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.022662
Average KL loss: 0.005562
Average total loss: 0.028224
tensor(0.0427, device='cuda:0') tensor(0.2492, device='cuda:0') tensor(-3.0145e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.021805
Average KL loss: 0.005532
Average total loss: 0.027337
tensor(0.0424, device='cuda:0') tensor(0.2485, device='cuda:0') tensor(-2.2638e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.022053
Average KL loss: 0.005506
Average total loss: 0.027559
tensor(0.0422, device='cuda:0') tensor(0.2479, device='cuda:0') tensor(-2.9070e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.022116
Average KL loss: 0.005482
Average total loss: 0.027599
tensor(0.0420, device='cuda:0') tensor(0.2474, device='cuda:0') tensor(-3.2152e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.021928
Average KL loss: 0.005461
Average total loss: 0.027389
tensor(0.0419, device='cuda:0') tensor(0.2469, device='cuda:0') tensor(-4.0844e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.021767
Average KL loss: 0.005441
Average total loss: 0.027208
tensor(0.0418, device='cuda:0') tensor(0.2465, device='cuda:0') tensor(-2.1545e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.021682
Average KL loss: 0.005423
Average total loss: 0.027105
tensor(0.0417, device='cuda:0') tensor(0.2461, device='cuda:0') tensor(-2.3104e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.021743
Average KL loss: 0.005407
Average total loss: 0.027150
tensor(0.0416, device='cuda:0') tensor(0.2458, device='cuda:0') tensor(-2.3068e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.021581
Average KL loss: 0.005392
Average total loss: 0.026972
tensor(0.0415, device='cuda:0') tensor(0.2455, device='cuda:0') tensor(-2.0896e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.021548
Average KL loss: 0.005378
Average total loss: 0.026926
tensor(0.0414, device='cuda:0') tensor(0.2453, device='cuda:0') tensor(-3.2330e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.021470
Average KL loss: 0.005365
Average total loss: 0.026835
tensor(0.0413, device='cuda:0') tensor(0.2451, device='cuda:0') tensor(-4.0007e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.021333
Average KL loss: 0.005353
Average total loss: 0.026687
tensor(0.0413, device='cuda:0') tensor(0.2449, device='cuda:0') tensor(-2.8778e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.022159
Average KL loss: 0.005342
Average total loss: 0.027501
tensor(0.0412, device='cuda:0') tensor(0.2448, device='cuda:0') tensor(-2.8738e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.021338
Average KL loss: 0.005331
Average total loss: 0.026669
tensor(0.0412, device='cuda:0') tensor(0.2447, device='cuda:0') tensor(-2.6200e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.021562
Average KL loss: 0.005321
Average total loss: 0.026883
tensor(0.0411, device='cuda:0') tensor(0.2446, device='cuda:0') tensor(-2.7529e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.021481
Average KL loss: 0.005312
Average total loss: 0.026793
tensor(0.0411, device='cuda:0') tensor(0.2445, device='cuda:0') tensor(-1.9034e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.021590
Average KL loss: 0.005303
Average total loss: 0.026893
tensor(0.0410, device='cuda:0') tensor(0.2444, device='cuda:0') tensor(-1.8586e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.021119
Average KL loss: 0.005294
Average total loss: 0.026413
tensor(0.0410, device='cuda:0') tensor(0.2443, device='cuda:0') tensor(-1.5605e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.021692
Average KL loss: 0.005286
Average total loss: 0.026978
tensor(0.0410, device='cuda:0') tensor(0.2443, device='cuda:0') tensor(-2.1014e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.021206
Average KL loss: 0.005278
Average total loss: 0.026484
tensor(0.0409, device='cuda:0') tensor(0.2442, device='cuda:0') tensor(-1.8907e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.021218
Average KL loss: 0.005271
Average total loss: 0.026489
tensor(0.0409, device='cuda:0') tensor(0.2442, device='cuda:0') tensor(-1.5677e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.021255
Average KL loss: 0.005264
Average total loss: 0.026520
tensor(0.0409, device='cuda:0') tensor(0.2442, device='cuda:0') tensor(-2.6642e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.021040
Average KL loss: 0.005258
Average total loss: 0.026298
tensor(0.0408, device='cuda:0') tensor(0.2442, device='cuda:0') tensor(-3.0538e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.021477
Average KL loss: 0.005251
Average total loss: 0.026728
tensor(0.0408, device='cuda:0') tensor(0.2442, device='cuda:0') tensor(-1.4897e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.021224
Average KL loss: 0.005245
Average total loss: 0.026469
tensor(0.0408, device='cuda:0') tensor(0.2443, device='cuda:0') tensor(-4.9198e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.020851
Average KL loss: 0.005239
Average total loss: 0.026090
tensor(0.0408, device='cuda:0') tensor(0.2443, device='cuda:0') tensor(-3.7757e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.020890
Average KL loss: 0.005233
Average total loss: 0.026122
tensor(0.0408, device='cuda:0') tensor(0.2444, device='cuda:0') tensor(-2.3380e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.020842
Average KL loss: 0.005227
Average total loss: 0.026069
tensor(0.0407, device='cuda:0') tensor(0.2445, device='cuda:0') tensor(-1.3945e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.021559
Average KL loss: 0.005222
Average total loss: 0.026781
tensor(0.0407, device='cuda:0') tensor(0.2445, device='cuda:0') tensor(-2.8368e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.021552
Average KL loss: 0.005217
Average total loss: 0.026770
tensor(0.0407, device='cuda:0') tensor(0.2446, device='cuda:0') tensor(-2.1883e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.021343
Average KL loss: 0.005212
Average total loss: 0.026556
tensor(0.0407, device='cuda:0') tensor(0.2447, device='cuda:0') tensor(-3.0058e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.020716
Average KL loss: 0.005208
Average total loss: 0.025924
tensor(0.0407, device='cuda:0') tensor(0.2448, device='cuda:0') tensor(-1.7444e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.020706
Average KL loss: 0.005203
Average total loss: 0.025909
tensor(0.0407, device='cuda:0') tensor(0.2449, device='cuda:0') tensor(-2.0472e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.021165
Average KL loss: 0.005199
Average total loss: 0.026364
tensor(0.0407, device='cuda:0') tensor(0.2450, device='cuda:0') tensor(-2.0246e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.020718
Average KL loss: 0.005194
Average total loss: 0.025912
tensor(0.0407, device='cuda:0') tensor(0.2451, device='cuda:0') tensor(-2.4389e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.020645
Average KL loss: 0.005190
Average total loss: 0.025835
tensor(0.0407, device='cuda:0') tensor(0.2452, device='cuda:0') tensor(-1.8770e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.020450
Average KL loss: 0.005186
Average total loss: 0.025636
tensor(0.0406, device='cuda:0') tensor(0.2453, device='cuda:0') tensor(-2.1913e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.021496
Average KL loss: 0.005182
Average total loss: 0.026678
tensor(0.0406, device='cuda:0') tensor(0.2455, device='cuda:0') tensor(-4.2549e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.020395
Average KL loss: 0.005179
Average total loss: 0.025573
tensor(0.0406, device='cuda:0') tensor(0.2456, device='cuda:0') tensor(-1.8885e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.020795
Average KL loss: 0.005175
Average total loss: 0.025969
tensor(0.0406, device='cuda:0') tensor(0.2457, device='cuda:0') tensor(-1.5775e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.020755
Average KL loss: 0.005171
Average total loss: 0.025926
tensor(0.0406, device='cuda:0') tensor(0.2458, device='cuda:0') tensor(-2.2785e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.021287
Average KL loss: 0.005167
Average total loss: 0.026455
tensor(0.0406, device='cuda:0') tensor(0.2459, device='cuda:0') tensor(-1.4568e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.020611
Average KL loss: 0.005164
Average total loss: 0.025775
tensor(0.0406, device='cuda:0') tensor(0.2461, device='cuda:0') tensor(-2.0381e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.020846
Average KL loss: 0.005161
Average total loss: 0.026006
tensor(0.0406, device='cuda:0') tensor(0.2462, device='cuda:0') tensor(-1.1910e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.020317
Average KL loss: 0.005157
Average total loss: 0.025475
tensor(0.0406, device='cuda:0') tensor(0.2463, device='cuda:0') tensor(-1.5765e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.020525
Average KL loss: 0.005154
Average total loss: 0.025679
tensor(0.0406, device='cuda:0') tensor(0.2465, device='cuda:0') tensor(-5.5794e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.020504
Average KL loss: 0.005151
Average total loss: 0.025654
tensor(0.0406, device='cuda:0') tensor(0.2466, device='cuda:0') tensor(-2.1260e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.020692
Average KL loss: 0.005147
Average total loss: 0.025839
tensor(0.0406, device='cuda:0') tensor(0.2468, device='cuda:0') tensor(-1.1124e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.020441
Average KL loss: 0.005144
Average total loss: 0.025585
tensor(0.0406, device='cuda:0') tensor(0.2469, device='cuda:0') tensor(-1.3745e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.020392
Average KL loss: 0.005141
Average total loss: 0.025533
tensor(0.0406, device='cuda:0') tensor(0.2471, device='cuda:0') tensor(-9.6889e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.021471
Average KL loss: 0.005138
Average total loss: 0.026609
tensor(0.0406, device='cuda:0') tensor(0.2473, device='cuda:0') tensor(-1.4623e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.021129
Average KL loss: 0.005135
Average total loss: 0.026265
tensor(0.0406, device='cuda:0') tensor(0.2474, device='cuda:0') tensor(-5.6378e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.020996
Average KL loss: 0.005133
Average total loss: 0.026128
tensor(0.0406, device='cuda:0') tensor(0.2476, device='cuda:0') tensor(-1.8846e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.020549
Average KL loss: 0.005130
Average total loss: 0.025679
tensor(0.0406, device='cuda:0') tensor(0.2478, device='cuda:0') tensor(-1.2361e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.020436
Average KL loss: 0.005127
Average total loss: 0.025563
tensor(0.0406, device='cuda:0') tensor(0.2479, device='cuda:0') tensor(-1.4683e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.020637
Average KL loss: 0.005124
Average total loss: 0.025761
tensor(0.0406, device='cuda:0') tensor(0.2481, device='cuda:0') tensor(-1.3650e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.020458
Average KL loss: 0.005123
Average total loss: 0.025581
tensor(0.0406, device='cuda:0') tensor(0.2481, device='cuda:0') tensor(-1.4905e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.020482
Average KL loss: 0.005122
Average total loss: 0.025605
tensor(0.0406, device='cuda:0') tensor(0.2481, device='cuda:0') tensor(-6.0127e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.020475
Average KL loss: 0.005122
Average total loss: 0.025597
tensor(0.0406, device='cuda:0') tensor(0.2481, device='cuda:0') tensor(-2.2626e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.020945
Average KL loss: 0.005122
Average total loss: 0.026067
tensor(0.0406, device='cuda:0') tensor(0.2481, device='cuda:0') tensor(-1.6112e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.020748
Average KL loss: 0.005122
Average total loss: 0.025869
tensor(0.0406, device='cuda:0') tensor(0.2481, device='cuda:0') tensor(-1.2671e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.020381
Average KL loss: 0.005121
Average total loss: 0.025502
tensor(0.0406, device='cuda:0') tensor(0.2482, device='cuda:0') tensor(-2.7174e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.020347
Average KL loss: 0.005121
Average total loss: 0.025468
tensor(0.0406, device='cuda:0') tensor(0.2482, device='cuda:0') tensor(-1.6000e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.020500
Average KL loss: 0.005121
Average total loss: 0.025621
tensor(0.0406, device='cuda:0') tensor(0.2482, device='cuda:0') tensor(-8.2411e-11, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.020436
Average KL loss: 0.005121
Average total loss: 0.025557
tensor(0.0406, device='cuda:0') tensor(0.2482, device='cuda:0') tensor(-1.2387e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.020980
Average KL loss: 0.005121
Average total loss: 0.026100
tensor(0.0406, device='cuda:0') tensor(0.2482, device='cuda:0') tensor(-1.3521e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.020429
Average KL loss: 0.005120
Average total loss: 0.025549
tensor(0.0406, device='cuda:0') tensor(0.2482, device='cuda:0') tensor(-1.7463e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.020664
Average KL loss: 0.005120
Average total loss: 0.025784
tensor(0.0406, device='cuda:0') tensor(0.2483, device='cuda:0') tensor(-1.3313e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.020318
Average KL loss: 0.005120
Average total loss: 0.025438
tensor(0.0406, device='cuda:0') tensor(0.2483, device='cuda:0') tensor(-7.0323e-11, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.020643
Average KL loss: 0.005120
Average total loss: 0.025763
tensor(0.0406, device='cuda:0') tensor(0.2483, device='cuda:0') tensor(-8.8085e-11, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.020155
Average KL loss: 0.005120
Average total loss: 0.025274
tensor(0.0406, device='cuda:0') tensor(0.2483, device='cuda:0') tensor(-1.5071e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.020268
Average KL loss: 0.005119
Average total loss: 0.025388
tensor(0.0406, device='cuda:0') tensor(0.2483, device='cuda:0') tensor(-1.2428e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.020505
Average KL loss: 0.005119
Average total loss: 0.025624
tensor(0.0406, device='cuda:0') tensor(0.2483, device='cuda:0') tensor(-5.8613e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.020310
Average KL loss: 0.005119
Average total loss: 0.025429
tensor(0.0406, device='cuda:0') tensor(0.2484, device='cuda:0') tensor(-1.5613e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.020421
Average KL loss: 0.005119
Average total loss: 0.025540
tensor(0.0406, device='cuda:0') tensor(0.2484, device='cuda:0') tensor(-1.5262e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.021123
Average KL loss: 0.005119
Average total loss: 0.026242
tensor(0.0406, device='cuda:0') tensor(0.2484, device='cuda:0') tensor(-2.2273e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.020662
Average KL loss: 0.005118
Average total loss: 0.025780
tensor(0.0406, device='cuda:0') tensor(0.2484, device='cuda:0') tensor(-2.0708e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.020171
Average KL loss: 0.005118
Average total loss: 0.025290
tensor(0.0406, device='cuda:0') tensor(0.2484, device='cuda:0') tensor(-1.1015e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.020120
Average KL loss: 0.005118
Average total loss: 0.025238
tensor(0.0406, device='cuda:0') tensor(0.2484, device='cuda:0') tensor(-5.0372e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.020529
Average KL loss: 0.005118
Average total loss: 0.025647
tensor(0.0406, device='cuda:0') tensor(0.2485, device='cuda:0') tensor(-1.1462e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.020325
Average KL loss: 0.005118
Average total loss: 0.025443
tensor(0.0406, device='cuda:0') tensor(0.2485, device='cuda:0') tensor(-1.2541e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.020645
Average KL loss: 0.005117
Average total loss: 0.025762
tensor(0.0406, device='cuda:0') tensor(0.2485, device='cuda:0') tensor(-4.4825e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.020161
Average KL loss: 0.005117
Average total loss: 0.025279
tensor(0.0406, device='cuda:0') tensor(0.2485, device='cuda:0') tensor(-3.1198e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.019998
Average KL loss: 0.005117
Average total loss: 0.025115
tensor(0.0406, device='cuda:0') tensor(0.2485, device='cuda:0') tensor(-1.4692e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.020856
Average KL loss: 0.005117
Average total loss: 0.025972
tensor(0.0406, device='cuda:0') tensor(0.2485, device='cuda:0') tensor(-1.8960e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.020272
Average KL loss: 0.005117
Average total loss: 0.025388
tensor(0.0406, device='cuda:0') tensor(0.2486, device='cuda:0') tensor(-2.0286e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.021195
Average KL loss: 0.005116
Average total loss: 0.026311
tensor(0.0406, device='cuda:0') tensor(0.2486, device='cuda:0') tensor(-1.3857e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.020001
Average KL loss: 0.005116
Average total loss: 0.025117
tensor(0.0406, device='cuda:0') tensor(0.2486, device='cuda:0') tensor(-9.8883e-11, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.020479
Average KL loss: 0.005116
Average total loss: 0.025596
tensor(0.0406, device='cuda:0') tensor(0.2486, device='cuda:0') tensor(-1.6796e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.020228
Average KL loss: 0.005116
Average total loss: 0.025344
tensor(0.0406, device='cuda:0') tensor(0.2486, device='cuda:0') tensor(-1.9126e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.020664
Average KL loss: 0.005116
Average total loss: 0.025780
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-2.8008e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.020078
Average KL loss: 0.005116
Average total loss: 0.025194
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.2508e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.020275
Average KL loss: 0.005115
Average total loss: 0.025391
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.4921e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.020284
Average KL loss: 0.005115
Average total loss: 0.025399
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-2.2311e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.020135
Average KL loss: 0.005115
Average total loss: 0.025250
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.7699e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.020236
Average KL loss: 0.005115
Average total loss: 0.025350
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-6.2945e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.020174
Average KL loss: 0.005115
Average total loss: 0.025289
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.2347e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.020304
Average KL loss: 0.005115
Average total loss: 0.025418
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.7508e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.020237
Average KL loss: 0.005115
Average total loss: 0.025352
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.5054e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.020320
Average KL loss: 0.005115
Average total loss: 0.025434
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-8.2288e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.020539
Average KL loss: 0.005115
Average total loss: 0.025654
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.5125e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.020651
Average KL loss: 0.005115
Average total loss: 0.025766
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-2.2135e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.020308
Average KL loss: 0.005115
Average total loss: 0.025423
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.6899e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.020538
Average KL loss: 0.005115
Average total loss: 0.025653
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-2.6289e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.020580
Average KL loss: 0.005115
Average total loss: 0.025695
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.2134e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.020291
Average KL loss: 0.005115
Average total loss: 0.025405
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-2.0830e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.020222
Average KL loss: 0.005115
Average total loss: 0.025336
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-9.4043e-11, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.020460
Average KL loss: 0.005115
Average total loss: 0.025574
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.8380e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.020395
Average KL loss: 0.005115
Average total loss: 0.025509
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.3446e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.020310
Average KL loss: 0.005115
Average total loss: 0.025425
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.3559e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.020958
Average KL loss: 0.005115
Average total loss: 0.026073
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-2.5525e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.020152
Average KL loss: 0.005115
Average total loss: 0.025267
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-2.1397e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.020342
Average KL loss: 0.005115
Average total loss: 0.025457
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-9.3808e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.020400
Average KL loss: 0.005115
Average total loss: 0.025515
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-4.1053e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.020475
Average KL loss: 0.005115
Average total loss: 0.025589
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.4835e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.020524
Average KL loss: 0.005115
Average total loss: 0.025639
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-1.8051e-10, device='cuda:0')
 Percentile value: 6.435195207595825
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =     126 /    1728             (  7.29%) | total_pruned =    1602 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     138 /   36864             (  0.37%) | total_pruned =   36726 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     205 /   36864             (  0.56%) | total_pruned =   36659 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     222 /   36864             (  0.60%) | total_pruned =   36642 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     469 /   36864             (  1.27%) | total_pruned =   36395 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1005 /   73728             (  1.36%) | total_pruned =   72723 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2225 /  147456             (  1.51%) | total_pruned =  145231 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     330 /    8192             (  4.03%) | total_pruned =    7862 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1474 /  147456             (  1.00%) | total_pruned =  145982 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1393 /  147456             (  0.94%) | total_pruned =  146063 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    4072 /  294912             (  1.38%) | total_pruned =  290840 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     148 /     256             ( 57.81%) | total_pruned =     108 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      41 /     256             ( 16.02%) | total_pruned =     215 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5246 /  589824             (  0.89%) | total_pruned =  584578 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      65 /     256             ( 25.39%) | total_pruned =     191 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     671 /   32768             (  2.05%) | total_pruned =   32097 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      88 /     256             ( 34.38%) | total_pruned =     168 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      50 /     256             ( 19.53%) | total_pruned =     206 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2896 /  589824             (  0.49%) | total_pruned =  586928 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2316 /  589824             (  0.39%) | total_pruned =  587508 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    3985 / 1179648             (  0.34%) | total_pruned = 1175663 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     260 /     512             ( 50.78%) | total_pruned =     252 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      56 /     512             ( 10.94%) | total_pruned =     456 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    3808 / 2359296             (  0.16%) | total_pruned = 2355488 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     297 /     512             ( 58.01%) | total_pruned =     215 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     209 /     512             ( 40.82%) | total_pruned =     303 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     118 /  131072             (  0.09%) | total_pruned =  130954 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     201 /     512             ( 39.26%) | total_pruned =     311 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2917 / 2359296             (  0.12%) | total_pruned = 2356379 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     139 /     512             ( 27.15%) | total_pruned =     373 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    4838 / 2359296             (  0.21%) | total_pruned = 2354458 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     375 /     512             ( 73.24%) | total_pruned =     137 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     222 /     512             ( 43.36%) | total_pruned =     290 | shape = torch.Size([512])
linear.weight        | nonzeros =    2009 /    5120             ( 39.24%) | total_pruned =    3111 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 99/100 Loss: 0.190029 Accuracy: 78.54 98.41 % Best test Accuracy: 81.67%
tensor(0.0406, device='cuda:0') tensor(0.2487, device='cuda:0') tensor(-6.6276e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.109164
Average KL loss: 0.005093
Average total loss: 0.114257
tensor(0.0400, device='cuda:0') tensor(0.2431, device='cuda:0') tensor(-1.4877e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.110135
Average KL loss: 0.005046
Average total loss: 0.115180
tensor(0.0393, device='cuda:0') tensor(0.2377, device='cuda:0') tensor(-2.4185e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.109633
Average KL loss: 0.004993
Average total loss: 0.114625
tensor(0.0387, device='cuda:0') tensor(0.2324, device='cuda:0') tensor(-1.3743e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.109591
Average KL loss: 0.004931
Average total loss: 0.114522
tensor(0.0380, device='cuda:0') tensor(0.2271, device='cuda:0') tensor(-3.7338e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.110094
Average KL loss: 0.004859
Average total loss: 0.114953
tensor(0.0373, device='cuda:0') tensor(0.2216, device='cuda:0') tensor(-8.0148e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.112014
Average KL loss: 0.004773
Average total loss: 0.116787
tensor(0.0365, device='cuda:0') tensor(0.2162, device='cuda:0') tensor(-1.0334e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.112015
Average KL loss: 0.004673
Average total loss: 0.116688
tensor(0.0356, device='cuda:0') tensor(0.2106, device='cuda:0') tensor(-1.0784e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.109361
Average KL loss: 0.004556
Average total loss: 0.113917
tensor(0.0347, device='cuda:0') tensor(0.2050, device='cuda:0') tensor(-1.5280e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.110053
Average KL loss: 0.004423
Average total loss: 0.114476
tensor(0.0337, device='cuda:0') tensor(0.1995, device='cuda:0') tensor(-1.7710e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.109502
Average KL loss: 0.004275
Average total loss: 0.113777
tensor(0.0327, device='cuda:0') tensor(0.1942, device='cuda:0') tensor(-7.9273e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.107724
Average KL loss: 0.004114
Average total loss: 0.111838
tensor(0.0317, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-9.8793e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.109582
Average KL loss: 0.003944
Average total loss: 0.113526
tensor(0.0307, device='cuda:0') tensor(0.1842, device='cuda:0') tensor(-3.5563e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.111127
Average KL loss: 0.003769
Average total loss: 0.114896
tensor(0.0296, device='cuda:0') tensor(0.1798, device='cuda:0') tensor(-3.4634e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.109714
Average KL loss: 0.003594
Average total loss: 0.113309
tensor(0.0287, device='cuda:0') tensor(0.1758, device='cuda:0') tensor(-1.2770e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.108848
Average KL loss: 0.003426
Average total loss: 0.112274
tensor(0.0277, device='cuda:0') tensor(0.1724, device='cuda:0') tensor(-1.3350e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.108480
Average KL loss: 0.003269
Average total loss: 0.111749
tensor(0.0269, device='cuda:0') tensor(0.1696, device='cuda:0') tensor(-7.9714e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.108456
Average KL loss: 0.003132
Average total loss: 0.111588
tensor(0.0262, device='cuda:0') tensor(0.1673, device='cuda:0') tensor(-5.0858e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.107211
Average KL loss: 0.003018
Average total loss: 0.110230
tensor(0.0255, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(-1.2484e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.108218
Average KL loss: 0.002933
Average total loss: 0.111151
tensor(0.0250, device='cuda:0') tensor(0.1640, device='cuda:0') tensor(-3.9639e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.109804
Average KL loss: 0.002873
Average total loss: 0.112677
tensor(0.0246, device='cuda:0') tensor(0.1628, device='cuda:0') tensor(-6.2482e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.108000
Average KL loss: 0.002829
Average total loss: 0.110829
tensor(0.0243, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(-2.6077e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.107164
Average KL loss: 0.002796
Average total loss: 0.109959
tensor(0.0241, device='cuda:0') tensor(0.1609, device='cuda:0') tensor(-2.1698e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.109804
Average KL loss: 0.002766
Average total loss: 0.112570
tensor(0.0239, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(-2.9034e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.108935
Average KL loss: 0.002740
Average total loss: 0.111675
tensor(0.0237, device='cuda:0') tensor(0.1593, device='cuda:0') tensor(-9.4624e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.107532
Average KL loss: 0.002716
Average total loss: 0.110247
tensor(0.0235, device='cuda:0') tensor(0.1586, device='cuda:0') tensor(-7.4433e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.108625
Average KL loss: 0.002693
Average total loss: 0.111318
tensor(0.0234, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(-1.3300e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.108288
Average KL loss: 0.002673
Average total loss: 0.110961
tensor(0.0232, device='cuda:0') tensor(0.1573, device='cuda:0') tensor(-9.8237e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.108151
Average KL loss: 0.002654
Average total loss: 0.110805
tensor(0.0231, device='cuda:0') tensor(0.1567, device='cuda:0') tensor(-1.0824e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.107676
Average KL loss: 0.002636
Average total loss: 0.110312
tensor(0.0230, device='cuda:0') tensor(0.1562, device='cuda:0') tensor(-5.7744e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.107368
Average KL loss: 0.002619
Average total loss: 0.109987
tensor(0.0229, device='cuda:0') tensor(0.1557, device='cuda:0') tensor(-3.9415e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.109319
Average KL loss: 0.002603
Average total loss: 0.111922
tensor(0.0228, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-2.9049e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.108592
Average KL loss: 0.002588
Average total loss: 0.111181
tensor(0.0227, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(-1.1624e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.104885
Average KL loss: 0.002575
Average total loss: 0.107460
tensor(0.0226, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(-1.0905e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.108247
Average KL loss: 0.002562
Average total loss: 0.110809
tensor(0.0225, device='cuda:0') tensor(0.1541, device='cuda:0') tensor(-8.3774e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.107892
Average KL loss: 0.002550
Average total loss: 0.110442
tensor(0.0224, device='cuda:0') tensor(0.1538, device='cuda:0') tensor(-8.5231e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.107886
Average KL loss: 0.002539
Average total loss: 0.110425
tensor(0.0223, device='cuda:0') tensor(0.1535, device='cuda:0') tensor(-1.2285e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.111245
Average KL loss: 0.002530
Average total loss: 0.113775
tensor(0.0223, device='cuda:0') tensor(0.1532, device='cuda:0') tensor(-1.3166e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.105509
Average KL loss: 0.002520
Average total loss: 0.108030
tensor(0.0222, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(-5.0381e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.104872
Average KL loss: 0.002512
Average total loss: 0.107384
tensor(0.0222, device='cuda:0') tensor(0.1527, device='cuda:0') tensor(-1.2812e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.111107
Average KL loss: 0.002503
Average total loss: 0.113610
tensor(0.0221, device='cuda:0') tensor(0.1524, device='cuda:0') tensor(-1.3203e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.105728
Average KL loss: 0.002496
Average total loss: 0.108224
tensor(0.0221, device='cuda:0') tensor(0.1522, device='cuda:0') tensor(-5.7782e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.105177
Average KL loss: 0.002489
Average total loss: 0.107666
tensor(0.0220, device='cuda:0') tensor(0.1520, device='cuda:0') tensor(-7.2976e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.106684
Average KL loss: 0.002482
Average total loss: 0.109167
tensor(0.0220, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-5.3282e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.107308
Average KL loss: 0.002476
Average total loss: 0.109784
tensor(0.0219, device='cuda:0') tensor(0.1517, device='cuda:0') tensor(-1.4971e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.106987
Average KL loss: 0.002470
Average total loss: 0.109457
tensor(0.0219, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-5.9407e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.105318
Average KL loss: 0.002464
Average total loss: 0.107782
tensor(0.0219, device='cuda:0') tensor(0.1514, device='cuda:0') tensor(-8.5093e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.103853
Average KL loss: 0.002459
Average total loss: 0.106312
tensor(0.0218, device='cuda:0') tensor(0.1512, device='cuda:0') tensor(-3.3982e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.105232
Average KL loss: 0.002453
Average total loss: 0.107685
tensor(0.0218, device='cuda:0') tensor(0.1511, device='cuda:0') tensor(-4.5053e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.105463
Average KL loss: 0.002448
Average total loss: 0.107911
tensor(0.0218, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(-8.0747e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.105101
Average KL loss: 0.002443
Average total loss: 0.107544
tensor(0.0217, device='cuda:0') tensor(0.1508, device='cuda:0') tensor(-2.1370e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.104531
Average KL loss: 0.002438
Average total loss: 0.106968
tensor(0.0217, device='cuda:0') tensor(0.1507, device='cuda:0') tensor(-3.1639e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.105049
Average KL loss: 0.002433
Average total loss: 0.107482
tensor(0.0217, device='cuda:0') tensor(0.1507, device='cuda:0') tensor(-2.3985e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.106009
Average KL loss: 0.002428
Average total loss: 0.108437
tensor(0.0216, device='cuda:0') tensor(0.1506, device='cuda:0') tensor(-4.6907e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.103787
Average KL loss: 0.002424
Average total loss: 0.106211
tensor(0.0216, device='cuda:0') tensor(0.1505, device='cuda:0') tensor(-5.5309e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.106363
Average KL loss: 0.002419
Average total loss: 0.108782
tensor(0.0216, device='cuda:0') tensor(0.1504, device='cuda:0') tensor(-9.2498e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.103779
Average KL loss: 0.002415
Average total loss: 0.106193
tensor(0.0216, device='cuda:0') tensor(0.1503, device='cuda:0') tensor(-1.1857e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.106222
Average KL loss: 0.002411
Average total loss: 0.108633
tensor(0.0215, device='cuda:0') tensor(0.1503, device='cuda:0') tensor(-5.0221e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.105388
Average KL loss: 0.002407
Average total loss: 0.107795
tensor(0.0215, device='cuda:0') tensor(0.1502, device='cuda:0') tensor(-5.8346e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.105867
Average KL loss: 0.002404
Average total loss: 0.108270
tensor(0.0215, device='cuda:0') tensor(0.1501, device='cuda:0') tensor(-8.2468e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.104444
Average KL loss: 0.002400
Average total loss: 0.106844
tensor(0.0215, device='cuda:0') tensor(0.1501, device='cuda:0') tensor(-8.0448e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.107519
Average KL loss: 0.002396
Average total loss: 0.109916
tensor(0.0215, device='cuda:0') tensor(0.1500, device='cuda:0') tensor(-8.3217e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.104893
Average KL loss: 0.002393
Average total loss: 0.107286
tensor(0.0214, device='cuda:0') tensor(0.1500, device='cuda:0') tensor(-6.6505e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.107128
Average KL loss: 0.002390
Average total loss: 0.109517
tensor(0.0214, device='cuda:0') tensor(0.1499, device='cuda:0') tensor(-5.4426e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.105408
Average KL loss: 0.002387
Average total loss: 0.107795
tensor(0.0214, device='cuda:0') tensor(0.1499, device='cuda:0') tensor(-1.8281e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.102925
Average KL loss: 0.002384
Average total loss: 0.105309
tensor(0.0214, device='cuda:0') tensor(0.1499, device='cuda:0') tensor(-3.0035e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.103936
Average KL loss: 0.002381
Average total loss: 0.106318
tensor(0.0214, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-4.1474e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.105346
Average KL loss: 0.002378
Average total loss: 0.107724
tensor(0.0214, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-2.2231e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.103831
Average KL loss: 0.002376
Average total loss: 0.106207
tensor(0.0213, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-6.2000e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.103151
Average KL loss: 0.002373
Average total loss: 0.105524
tensor(0.0213, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-2.0056e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.104386
Average KL loss: 0.002371
Average total loss: 0.106757
tensor(0.0213, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-9.5163e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.104033
Average KL loss: 0.002369
Average total loss: 0.106402
tensor(0.0213, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-6.3411e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.103938
Average KL loss: 0.002366
Average total loss: 0.106304
tensor(0.0213, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-4.8003e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.103854
Average KL loss: 0.002364
Average total loss: 0.106218
tensor(0.0213, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-4.5099e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.104686
Average KL loss: 0.002361
Average total loss: 0.107047
tensor(0.0213, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-5.9734e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.103596
Average KL loss: 0.002359
Average total loss: 0.105955
tensor(0.0213, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-9.5930e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.103837
Average KL loss: 0.002357
Average total loss: 0.106194
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-9.0430e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.105016
Average KL loss: 0.002356
Average total loss: 0.107372
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.1723e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.103244
Average KL loss: 0.002355
Average total loss: 0.105600
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(7.6429e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.102833
Average KL loss: 0.002355
Average total loss: 0.105188
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-2.4852e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.103094
Average KL loss: 0.002355
Average total loss: 0.105449
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-7.8084e-11, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.102874
Average KL loss: 0.002355
Average total loss: 0.105229
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-6.1304e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.106948
Average KL loss: 0.002355
Average total loss: 0.109303
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-5.5624e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.102316
Average KL loss: 0.002355
Average total loss: 0.104671
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-8.7579e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.103366
Average KL loss: 0.002354
Average total loss: 0.105721
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-2.5087e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.104489
Average KL loss: 0.002354
Average total loss: 0.106843
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-6.0026e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.104779
Average KL loss: 0.002354
Average total loss: 0.107133
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.0040e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.103174
Average KL loss: 0.002354
Average total loss: 0.105528
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-6.2880e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.101083
Average KL loss: 0.002354
Average total loss: 0.103436
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-6.6159e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.102595
Average KL loss: 0.002353
Average total loss: 0.104948
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-7.5223e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.102936
Average KL loss: 0.002353
Average total loss: 0.105290
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-9.5762e-11, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.101968
Average KL loss: 0.002353
Average total loss: 0.104322
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.1996e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.102637
Average KL loss: 0.002353
Average total loss: 0.104990
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.7282e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.106688
Average KL loss: 0.002353
Average total loss: 0.109040
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-4.6117e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.101354
Average KL loss: 0.002353
Average total loss: 0.103706
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.4823e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.103854
Average KL loss: 0.002353
Average total loss: 0.106206
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-4.7609e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.104376
Average KL loss: 0.002352
Average total loss: 0.106729
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.7645e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.102013
Average KL loss: 0.002352
Average total loss: 0.104366
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-3.5095e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.102874
Average KL loss: 0.002352
Average total loss: 0.105226
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-7.1496e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.104537
Average KL loss: 0.002352
Average total loss: 0.106889
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.8204e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.101573
Average KL loss: 0.002352
Average total loss: 0.103924
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-8.2342e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.102907
Average KL loss: 0.002352
Average total loss: 0.105259
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-4.6613e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.102485
Average KL loss: 0.002352
Average total loss: 0.104837
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-4.5762e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.103226
Average KL loss: 0.002352
Average total loss: 0.105578
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-8.1532e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.103189
Average KL loss: 0.002352
Average total loss: 0.105540
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.6618e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.105417
Average KL loss: 0.002352
Average total loss: 0.107769
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-3.9309e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.101771
Average KL loss: 0.002352
Average total loss: 0.104123
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-7.4369e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.106880
Average KL loss: 0.002352
Average total loss: 0.109232
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-5.8630e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.101874
Average KL loss: 0.002352
Average total loss: 0.104225
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.2051e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.104401
Average KL loss: 0.002352
Average total loss: 0.106752
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.1541e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.103675
Average KL loss: 0.002352
Average total loss: 0.106026
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-8.5446e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.102822
Average KL loss: 0.002352
Average total loss: 0.105174
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-8.4695e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.102460
Average KL loss: 0.002352
Average total loss: 0.104812
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-2.8499e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.102128
Average KL loss: 0.002352
Average total loss: 0.104480
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-4.8631e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.101540
Average KL loss: 0.002352
Average total loss: 0.103892
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-5.2252e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.103137
Average KL loss: 0.002352
Average total loss: 0.105489
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.0426e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.104197
Average KL loss: 0.002352
Average total loss: 0.106549
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-7.1637e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.102933
Average KL loss: 0.002352
Average total loss: 0.105285
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-3.0778e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.104027
Average KL loss: 0.002352
Average total loss: 0.106378
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-8.7720e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.105118
Average KL loss: 0.002352
Average total loss: 0.107469
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-1.2968e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.103911
Average KL loss: 0.002352
Average total loss: 0.106262
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-6.2919e-10, device='cuda:0')
 Percentile value: 7.211537599563599
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =     121 /    1728             (  7.00%) | total_pruned =    1607 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     109 /   36864             (  0.30%) | total_pruned =   36755 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     146 /   36864             (  0.40%) | total_pruned =   36718 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     151 /   36864             (  0.41%) | total_pruned =   36713 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     238 /   36864             (  0.65%) | total_pruned =   36626 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     539 /   73728             (  0.73%) | total_pruned =   73189 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1119 /  147456             (  0.76%) | total_pruned =  146337 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     213 /    8192             (  2.60%) | total_pruned =    7979 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     853 /  147456             (  0.58%) | total_pruned =  146603 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     846 /  147456             (  0.57%) | total_pruned =  146610 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1985 /  294912             (  0.67%) | total_pruned =  292927 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2240 /  589824             (  0.38%) | total_pruned =  587584 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      54 /     256             ( 21.09%) | total_pruned =     202 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     339 /   32768             (  1.03%) | total_pruned =   32429 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      76 /     256             ( 29.69%) | total_pruned =     180 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1270 /  589824             (  0.22%) | total_pruned =  588554 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     136 /     256             ( 53.12%) | total_pruned =     120 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1074 /  589824             (  0.18%) | total_pruned =  588750 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1540 / 1179648             (  0.13%) | total_pruned = 1178108 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     248 /     512             ( 48.44%) | total_pruned =     264 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1352 / 2359296             (  0.06%) | total_pruned = 2357944 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     259 /     512             ( 50.59%) | total_pruned =     253 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     155 /     512             ( 30.27%) | total_pruned =     357 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      30 /  131072             (  0.02%) | total_pruned =  131042 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1167 / 2359296             (  0.05%) | total_pruned = 2358129 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     125 /     512             ( 24.41%) | total_pruned =     387 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2167 / 2359296             (  0.09%) | total_pruned = 2357129 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     355 /     512             ( 69.34%) | total_pruned =     157 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
linear.weight        | nonzeros =    1554 /    5120             ( 30.35%) | total_pruned =    3566 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.394208 Accuracy: 76.99 90.19 % Best test Accuracy: 78.46%
tensor(0.0212, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-4.1835e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.341907
Average KL loss: 0.002348
Average total loss: 0.344256
tensor(0.0211, device='cuda:0') tensor(0.1481, device='cuda:0') tensor(-3.0085e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.340217
Average KL loss: 0.002342
Average total loss: 0.342559
tensor(0.0209, device='cuda:0') tensor(0.1466, device='cuda:0') tensor(-3.8021e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.338134
Average KL loss: 0.002335
Average total loss: 0.340469
tensor(0.0208, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(-5.4710e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.340307
Average KL loss: 0.002327
Average total loss: 0.342634
tensor(0.0206, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(-9.8182e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.339654
Average KL loss: 0.002319
Average total loss: 0.341973
tensor(0.0205, device='cuda:0') tensor(0.1422, device='cuda:0') tensor(-8.5696e-11, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.339700
Average KL loss: 0.002309
Average total loss: 0.342010
tensor(0.0203, device='cuda:0') tensor(0.1407, device='cuda:0') tensor(-4.8604e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.341133
Average KL loss: 0.002299
Average total loss: 0.343431
tensor(0.0202, device='cuda:0') tensor(0.1392, device='cuda:0') tensor(-4.9512e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.339973
Average KL loss: 0.002286
Average total loss: 0.342259
tensor(0.0200, device='cuda:0') tensor(0.1376, device='cuda:0') tensor(-1.2657e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.338784
Average KL loss: 0.002272
Average total loss: 0.341056
tensor(0.0198, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-1.6526e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.338359
Average KL loss: 0.002256
Average total loss: 0.340616
tensor(0.0196, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(-1.1809e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.339687
Average KL loss: 0.002238
Average total loss: 0.341926
tensor(0.0194, device='cuda:0') tensor(0.1328, device='cuda:0') tensor(-1.7855e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.340016
Average KL loss: 0.002218
Average total loss: 0.342235
tensor(0.0192, device='cuda:0') tensor(0.1312, device='cuda:0') tensor(-4.6162e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.340219
Average KL loss: 0.002196
Average total loss: 0.342415
tensor(0.0190, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-6.7516e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.340706
Average KL loss: 0.002171
Average total loss: 0.342877
tensor(0.0187, device='cuda:0') tensor(0.1278, device='cuda:0') tensor(-3.3122e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.338293
Average KL loss: 0.002157
Average total loss: 0.340450
tensor(0.0187, device='cuda:0') tensor(0.1276, device='cuda:0') tensor(-1.2049e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.338065
Average KL loss: 0.002154
Average total loss: 0.340219
tensor(0.0187, device='cuda:0') tensor(0.1274, device='cuda:0') tensor(-4.4528e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.339710
Average KL loss: 0.002151
Average total loss: 0.341861
tensor(0.0187, device='cuda:0') tensor(0.1272, device='cuda:0') tensor(-6.7428e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.340276
Average KL loss: 0.002149
Average total loss: 0.342424
tensor(0.0186, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-1.7965e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.339888
Average KL loss: 0.002146
Average total loss: 0.342034
tensor(0.0186, device='cuda:0') tensor(0.1269, device='cuda:0') tensor(-3.3114e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.339143
Average KL loss: 0.002144
Average total loss: 0.341287
tensor(0.0186, device='cuda:0') tensor(0.1267, device='cuda:0') tensor(-1.5353e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.342281
Average KL loss: 0.002141
Average total loss: 0.344423
tensor(0.0186, device='cuda:0') tensor(0.1266, device='cuda:0') tensor(-1.5663e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.338525
Average KL loss: 0.002139
Average total loss: 0.340664
tensor(0.0186, device='cuda:0') tensor(0.1264, device='cuda:0') tensor(-9.1438e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.339987
Average KL loss: 0.002137
Average total loss: 0.342123
tensor(0.0185, device='cuda:0') tensor(0.1263, device='cuda:0') tensor(-8.3435e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.339325
Average KL loss: 0.002134
Average total loss: 0.341459
tensor(0.0185, device='cuda:0') tensor(0.1261, device='cuda:0') tensor(-2.7983e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.343339
Average KL loss: 0.002132
Average total loss: 0.345471
tensor(0.0185, device='cuda:0') tensor(0.1259, device='cuda:0') tensor(-3.0421e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.340748
Average KL loss: 0.002129
Average total loss: 0.342877
tensor(0.0185, device='cuda:0') tensor(0.1258, device='cuda:0') tensor(-7.6640e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.342022
Average KL loss: 0.002127
Average total loss: 0.344148
tensor(0.0184, device='cuda:0') tensor(0.1256, device='cuda:0') tensor(-3.5643e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.345312
Average KL loss: 0.002125
Average total loss: 0.347438
tensor(0.0184, device='cuda:0') tensor(0.1256, device='cuda:0') tensor(-4.3880e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.339375
Average KL loss: 0.002125
Average total loss: 0.341500
tensor(0.0184, device='cuda:0') tensor(0.1256, device='cuda:0') tensor(-2.1768e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.341514
Average KL loss: 0.002125
Average total loss: 0.343639
tensor(0.0184, device='cuda:0') tensor(0.1256, device='cuda:0') tensor(-3.0015e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.343996
Average KL loss: 0.002125
Average total loss: 0.346121
tensor(0.0184, device='cuda:0') tensor(0.1256, device='cuda:0') tensor(-8.8299e-11, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.340741
Average KL loss: 0.002124
Average total loss: 0.342865
tensor(0.0184, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-5.1938e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.340559
Average KL loss: 0.002124
Average total loss: 0.342683
tensor(0.0184, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-1.4255e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.339590
Average KL loss: 0.002124
Average total loss: 0.341714
tensor(0.0184, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-2.3879e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.341346
Average KL loss: 0.002124
Average total loss: 0.343469
tensor(0.0184, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-1.1447e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.341143
Average KL loss: 0.002123
Average total loss: 0.343267
tensor(0.0184, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-1.8688e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.339938
Average KL loss: 0.002123
Average total loss: 0.342061
tensor(0.0184, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-1.1155e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.341254
Average KL loss: 0.002123
Average total loss: 0.343377
tensor(0.0184, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-3.8786e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.339511
Average KL loss: 0.002123
Average total loss: 0.341634
tensor(0.0184, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-5.8257e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.339194
Average KL loss: 0.002123
Average total loss: 0.341316
tensor(0.0184, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-3.2046e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.339703
Average KL loss: 0.002123
Average total loss: 0.341826
tensor(0.0184, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-1.5314e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.341864
Average KL loss: 0.002123
Average total loss: 0.343987
tensor(0.0184, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-9.2104e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.338555
Average KL loss: 0.002123
Average total loss: 0.340678
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.3682e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.340226
Average KL loss: 0.002123
Average total loss: 0.342349
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-9.8020e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.339783
Average KL loss: 0.002123
Average total loss: 0.341905
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-1.2193e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.342420
Average KL loss: 0.002123
Average total loss: 0.344543
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-1.4779e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.337765
Average KL loss: 0.002123
Average total loss: 0.339888
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.0034e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.339241
Average KL loss: 0.002123
Average total loss: 0.341364
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-1.0115e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.338037
Average KL loss: 0.002123
Average total loss: 0.340160
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.0712e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.340281
Average KL loss: 0.002123
Average total loss: 0.342403
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.7069e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.340067
Average KL loss: 0.002123
Average total loss: 0.342190
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-1.5881e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.342563
Average KL loss: 0.002123
Average total loss: 0.344686
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-9.5800e-11, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.340351
Average KL loss: 0.002123
Average total loss: 0.342474
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-4.6770e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.341901
Average KL loss: 0.002122
Average total loss: 0.344023
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-1.1865e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.339709
Average KL loss: 0.002122
Average total loss: 0.341831
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.8177e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.340347
Average KL loss: 0.002122
Average total loss: 0.342469
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(1.2414e-12, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.344579
Average KL loss: 0.002122
Average total loss: 0.346702
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.9226e-10, device='cuda:0')
 Percentile value: 7.771735668182373
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =     114 /    1728             (  6.60%) | total_pruned =    1614 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      74 /   36864             (  0.20%) | total_pruned =   36790 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      91 /   36864             (  0.25%) | total_pruned =   36773 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      95 /   36864             (  0.26%) | total_pruned =   36769 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     126 /   36864             (  0.34%) | total_pruned =   36738 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     280 /   73728             (  0.38%) | total_pruned =   73448 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     429 /  147456             (  0.29%) | total_pruned =  147027 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     127 /    8192             (  1.55%) | total_pruned =    8065 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     395 /  147456             (  0.27%) | total_pruned =  147061 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     366 /  147456             (  0.25%) | total_pruned =  147090 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     669 /  294912             (  0.23%) | total_pruned =  294243 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     754 /  589824             (  0.13%) | total_pruned =  589070 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     106 /     256             ( 41.41%) | total_pruned =     150 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     139 /   32768             (  0.42%) | total_pruned =   32629 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     412 /  589824             (  0.07%) | total_pruned =  589412 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     132 /     256             ( 51.56%) | total_pruned =     124 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     349 /  589824             (  0.06%) | total_pruned =  589475 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     434 / 1179648             (  0.04%) | total_pruned = 1179214 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     238 /     512             ( 46.48%) | total_pruned =     274 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     479 / 2359296             (  0.02%) | total_pruned = 2358817 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     235 /     512             ( 45.90%) | total_pruned =     277 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     137 /     512             ( 26.76%) | total_pruned =     375 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       8 /  131072             (  0.01%) | total_pruned =  131064 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     141 /     512             ( 27.54%) | total_pruned =     371 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     458 / 2359296             (  0.02%) | total_pruned = 2358838 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     119 /     512             ( 23.24%) | total_pruned =     393 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1186 / 2359296             (  0.05%) | total_pruned = 2358110 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     348 /     512             ( 67.97%) | total_pruned =     164 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     132 /     512             ( 25.78%) | total_pruned =     380 | shape = torch.Size([512])
linear.weight        | nonzeros =    1359 /    5120             ( 26.54%) | total_pruned =    3761 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.718440 Accuracy: 68.81 72.59 % Best test Accuracy: 69.67%
tensor(0.0184, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-6.7157e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.764337
Average KL loss: 0.002111
Average total loss: 0.766448
tensor(0.0182, device='cuda:0') tensor(0.1234, device='cuda:0') tensor(-5.8779e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.758999
Average KL loss: 0.002087
Average total loss: 0.761086
tensor(0.0179, device='cuda:0') tensor(0.1214, device='cuda:0') tensor(-1.7397e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.757878
Average KL loss: 0.002062
Average total loss: 0.759940
tensor(0.0176, device='cuda:0') tensor(0.1193, device='cuda:0') tensor(-2.2757e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.758160
Average KL loss: 0.002033
Average total loss: 0.760193
tensor(0.0174, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-1.6902e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.760553
Average KL loss: 0.002003
Average total loss: 0.762556
tensor(0.0171, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(1.6881e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.760137
Average KL loss: 0.001969
Average total loss: 0.762106
tensor(0.0168, device='cuda:0') tensor(0.1131, device='cuda:0') tensor(-1.7407e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.760584
Average KL loss: 0.001932
Average total loss: 0.762516
tensor(0.0165, device='cuda:0') tensor(0.1110, device='cuda:0') tensor(-3.2739e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.758954
Average KL loss: 0.001893
Average total loss: 0.760847
tensor(0.0161, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(4.1286e-12, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.760985
Average KL loss: 0.001851
Average total loss: 0.762836
tensor(0.0158, device='cuda:0') tensor(0.1068, device='cuda:0') tensor(-4.4911e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.758003
Average KL loss: 0.001808
Average total loss: 0.759811
tensor(0.0155, device='cuda:0') tensor(0.1048, device='cuda:0') tensor(-4.1947e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.758292
Average KL loss: 0.001764
Average total loss: 0.760056
tensor(0.0152, device='cuda:0') tensor(0.1029, device='cuda:0') tensor(6.0414e-11, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.758878
Average KL loss: 0.001719
Average total loss: 0.760598
tensor(0.0148, device='cuda:0') tensor(0.1010, device='cuda:0') tensor(-1.9712e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.759786
Average KL loss: 0.001675
Average total loss: 0.761462
tensor(0.0145, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-2.7485e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.765929
Average KL loss: 0.001632
Average total loss: 0.767561
tensor(0.0142, device='cuda:0') tensor(0.0975, device='cuda:0') tensor(-1.4435e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.758883
Average KL loss: 0.001590
Average total loss: 0.760472
tensor(0.0139, device='cuda:0') tensor(0.0958, device='cuda:0') tensor(-6.0706e-11, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.758869
Average KL loss: 0.001550
Average total loss: 0.760419
tensor(0.0136, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(1.0537e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.760023
Average KL loss: 0.001515
Average total loss: 0.761538
tensor(0.0134, device='cuda:0') tensor(0.0929, device='cuda:0') tensor(-8.2802e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.764048
Average KL loss: 0.001485
Average total loss: 0.765533
tensor(0.0131, device='cuda:0') tensor(0.0916, device='cuda:0') tensor(3.2505e-11, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.759155
Average KL loss: 0.001461
Average total loss: 0.760616
tensor(0.0129, device='cuda:0') tensor(0.0903, device='cuda:0') tensor(-4.3394e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.760581
Average KL loss: 0.001442
Average total loss: 0.762023
tensor(0.0127, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(3.9276e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.760433
Average KL loss: 0.001426
Average total loss: 0.761859
tensor(0.0126, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-1.8792e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.760019
Average KL loss: 0.001417
Average total loss: 0.761437
tensor(0.0126, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(1.4251e-12, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.760630
Average KL loss: 0.001416
Average total loss: 0.762046
tensor(0.0125, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.8825e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.762140
Average KL loss: 0.001414
Average total loss: 0.763555
tensor(0.0125, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-8.3886e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.759922
Average KL loss: 0.001413
Average total loss: 0.761335
tensor(0.0125, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-1.2888e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.759333
Average KL loss: 0.001412
Average total loss: 0.760744
tensor(0.0125, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(1.5626e-11, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.760556
Average KL loss: 0.001410
Average total loss: 0.761966
tensor(0.0125, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-9.7664e-11, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.759991
Average KL loss: 0.001409
Average total loss: 0.761400
tensor(0.0125, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(3.5806e-11, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.758971
Average KL loss: 0.001408
Average total loss: 0.760379
tensor(0.0124, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(-3.8431e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.759685
Average KL loss: 0.001406
Average total loss: 0.761092
tensor(0.0124, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(-3.5878e-12, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.760461
Average KL loss: 0.001405
Average total loss: 0.761866
tensor(0.0124, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-7.3654e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.766152
Average KL loss: 0.001404
Average total loss: 0.767556
tensor(0.0124, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-2.0523e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.762329
Average KL loss: 0.001403
Average total loss: 0.763732
tensor(0.0124, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-9.1314e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.759592
Average KL loss: 0.001403
Average total loss: 0.760995
tensor(0.0124, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-4.8453e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.760317
Average KL loss: 0.001403
Average total loss: 0.761719
tensor(0.0124, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(8.8882e-12, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.765008
Average KL loss: 0.001403
Average total loss: 0.766411
tensor(0.0124, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-4.2011e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.760308
Average KL loss: 0.001403
Average total loss: 0.761710
tensor(0.0124, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-2.9638e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.760323
Average KL loss: 0.001402
Average total loss: 0.761725
tensor(0.0124, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(4.7883e-11, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.759552
Average KL loss: 0.001402
Average total loss: 0.760955
tensor(0.0124, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(1.2933e-11, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.759014
Average KL loss: 0.001402
Average total loss: 0.760416
tensor(0.0124, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(1.6806e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.761836
Average KL loss: 0.001402
Average total loss: 0.763238
tensor(0.0124, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-7.9956e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.758897
Average KL loss: 0.001402
Average total loss: 0.760299
tensor(0.0124, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-5.9379e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.761711
Average KL loss: 0.001402
Average total loss: 0.763112
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-2.7138e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.757313
Average KL loss: 0.001402
Average total loss: 0.758714
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-1.6800e-11, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.759725
Average KL loss: 0.001402
Average total loss: 0.761126
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-2.3490e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.760304
Average KL loss: 0.001402
Average total loss: 0.761706
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(8.7076e-12, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.759345
Average KL loss: 0.001402
Average total loss: 0.760746
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-5.1830e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.762427
Average KL loss: 0.001402
Average total loss: 0.763828
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-2.3989e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.757909
Average KL loss: 0.001402
Average total loss: 0.759310
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-9.3598e-11, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.760028
Average KL loss: 0.001402
Average total loss: 0.761430
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(4.4030e-12, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.759078
Average KL loss: 0.001402
Average total loss: 0.760479
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(4.2551e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.760064
Average KL loss: 0.001402
Average total loss: 0.761466
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-7.4984e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.757774
Average KL loss: 0.001402
Average total loss: 0.759176
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-3.9450e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.757767
Average KL loss: 0.001402
Average total loss: 0.759169
tensor(0.0124, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-4.8758e-10, device='cuda:0')
 Percentile value: 8.496530532836914
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =      97 /    1728             (  5.61%) | total_pruned =    1631 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      39 /   36864             (  0.11%) | total_pruned =   36825 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      47 /   36864             (  0.13%) | total_pruned =   36817 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      52 /   36864             (  0.14%) | total_pruned =   36812 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      49 /   36864             (  0.13%) | total_pruned =   36815 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     103 /   73728             (  0.14%) | total_pruned =   73625 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     125 /  147456             (  0.08%) | total_pruned =  147331 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      76 /    8192             (  0.93%) | total_pruned =    8116 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     132 /  147456             (  0.09%) | total_pruned =  147324 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     111 /  147456             (  0.08%) | total_pruned =  147345 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     152 /  294912             (  0.05%) | total_pruned =  294760 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     153 /  589824             (  0.03%) | total_pruned =  589671 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      49 /   32768             (  0.15%) | total_pruned =   32719 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =      74 /  589824             (  0.01%) | total_pruned =  589750 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     121 /     256             ( 47.27%) | total_pruned =     135 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =      65 /  589824             (  0.01%) | total_pruned =  589759 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      91 /     256             ( 35.55%) | total_pruned =     165 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =      80 / 1179648             (  0.01%) | total_pruned = 1179568 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     206 /     512             ( 40.23%) | total_pruned =     306 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     145 / 2359296             (  0.01%) | total_pruned = 2359151 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     205 /     512             ( 40.04%) | total_pruned =     307 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       3 /  131072             (  0.00%) | total_pruned =  131069 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     101 /     512             ( 19.73%) | total_pruned =     411 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     140 / 2359296             (  0.01%) | total_pruned = 2359156 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     451 / 2359296             (  0.02%) | total_pruned = 2358845 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     335 /     512             ( 65.43%) | total_pruned =     177 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
linear.weight        | nonzeros =    1084 /    5120             ( 21.17%) | total_pruned =    4036 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 1.430964 Accuracy: 48.68 49.60 % Best test Accuracy: 48.78%
