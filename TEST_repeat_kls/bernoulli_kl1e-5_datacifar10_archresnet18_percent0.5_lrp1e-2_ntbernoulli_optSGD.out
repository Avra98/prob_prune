Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2495e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302564
Average KL loss: 0.000500
Average total loss: 2.303064
tensor(7.6487e-05, device='cuda:0') tensor(3.5076e-05, device='cuda:0') tensor(-3.8485e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.301695
Average KL loss: 0.001069
Average total loss: 2.302764
tensor(0.0003, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-1.3330e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.282632
Average KL loss: 0.004838
Average total loss: 2.287470
tensor(0.0018, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.7959e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.006642
Average KL loss: 0.039386
Average total loss: 2.046029
tensor(0.0096, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.2844e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.444332
Average KL loss: 0.106510
Average total loss: 1.550842
tensor(0.0133, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-9.4699e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.050513
Average KL loss: 0.139389
Average total loss: 1.189902
tensor(0.0139, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-7.3141e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.853224
Average KL loss: 0.146624
Average total loss: 0.999848
tensor(0.0134, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-5.8211e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.737139
Average KL loss: 0.145759
Average total loss: 0.882899
tensor(0.0132, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-2.9181e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.650316
Average KL loss: 0.143699
Average total loss: 0.794015
tensor(0.0127, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.7861e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.597376
Average KL loss: 0.140005
Average total loss: 0.737382
tensor(0.0124, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-3.5607e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.559680
Average KL loss: 0.137209
Average total loss: 0.696889
tensor(0.0123, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-3.3669e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.539250
Average KL loss: 0.135701
Average total loss: 0.674951
tensor(0.0120, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.9774e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.498233
Average KL loss: 0.134435
Average total loss: 0.632668
tensor(0.0120, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.8701e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.462583
Average KL loss: 0.131944
Average total loss: 0.594527
tensor(0.0117, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.6733e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.438513
Average KL loss: 0.129735
Average total loss: 0.568248
tensor(0.0116, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-3.3913e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.421607
Average KL loss: 0.127925
Average total loss: 0.549532
tensor(0.0116, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.3345e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.402548
Average KL loss: 0.126253
Average total loss: 0.528802
tensor(0.0115, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-3.1518e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.385932
Average KL loss: 0.124723
Average total loss: 0.510655
tensor(0.0113, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-2.3247e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.372559
Average KL loss: 0.123239
Average total loss: 0.495798
tensor(0.0113, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.8899e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.360962
Average KL loss: 0.121612
Average total loss: 0.482574
tensor(0.0112, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.6826e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.351820
Average KL loss: 0.120835
Average total loss: 0.472656
tensor(0.0112, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.8407e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.334454
Average KL loss: 0.119843
Average total loss: 0.454297
tensor(0.0112, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.9755e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.330196
Average KL loss: 0.119264
Average total loss: 0.449459
tensor(0.0111, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.1628e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.316995
Average KL loss: 0.118542
Average total loss: 0.435537
tensor(0.0110, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.5594e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.316221
Average KL loss: 0.117440
Average total loss: 0.433661
tensor(0.0110, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.6141e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.303528
Average KL loss: 0.116897
Average total loss: 0.420425
tensor(0.0110, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.0436e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.294821
Average KL loss: 0.116214
Average total loss: 0.411035
tensor(0.0110, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.4228e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.294668
Average KL loss: 0.115550
Average total loss: 0.410218
tensor(0.0110, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.6191e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.275515
Average KL loss: 0.114529
Average total loss: 0.390043
tensor(0.0108, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.7645e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.279202
Average KL loss: 0.113496
Average total loss: 0.392698
tensor(0.0108, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.4536e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.269773
Average KL loss: 0.112866
Average total loss: 0.382639
tensor(0.0108, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.2158e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.261288
Average KL loss: 0.111971
Average total loss: 0.373259
tensor(0.0108, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-8.8445e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.260588
Average KL loss: 0.111195
Average total loss: 0.371784
tensor(0.0107, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.5584e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.259452
Average KL loss: 0.111320
Average total loss: 0.370772
tensor(0.0108, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-7.5467e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.251179
Average KL loss: 0.110552
Average total loss: 0.361732
tensor(0.0107, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.2371e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.249211
Average KL loss: 0.110356
Average total loss: 0.359567
tensor(0.0107, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.1239e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.240621
Average KL loss: 0.109680
Average total loss: 0.350301
tensor(0.0107, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-7.3965e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.239300
Average KL loss: 0.109155
Average total loss: 0.348455
tensor(0.0107, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.1758e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.232368
Average KL loss: 0.108896
Average total loss: 0.341264
tensor(0.0107, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-8.7357e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.237194
Average KL loss: 0.108880
Average total loss: 0.346074
tensor(0.0107, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.8926e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.226131
Average KL loss: 0.108298
Average total loss: 0.334429
tensor(0.0107, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.7866e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.225679
Average KL loss: 0.107592
Average total loss: 0.333271
tensor(0.0107, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.0621e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.220496
Average KL loss: 0.107039
Average total loss: 0.327535
tensor(0.0107, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.2760e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.221924
Average KL loss: 0.106903
Average total loss: 0.328827
tensor(0.0107, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-7.9839e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.215022
Average KL loss: 0.106556
Average total loss: 0.321578
tensor(0.0106, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.6431e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.212421
Average KL loss: 0.106221
Average total loss: 0.318642
tensor(0.0107, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-2.6877e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.213750
Average KL loss: 0.105828
Average total loss: 0.319578
tensor(0.0107, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.8351e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.207954
Average KL loss: 0.106147
Average total loss: 0.314101
tensor(0.0107, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-9.7096e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.209205
Average KL loss: 0.105555
Average total loss: 0.314760
tensor(0.0106, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-9.2697e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.201605
Average KL loss: 0.105178
Average total loss: 0.306783
tensor(0.0106, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-6.1854e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.203634
Average KL loss: 0.104791
Average total loss: 0.308425
tensor(0.0106, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-6.7955e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.201259
Average KL loss: 0.104495
Average total loss: 0.305754
tensor(0.0106, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.2037e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.200895
Average KL loss: 0.104371
Average total loss: 0.305266
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-7.3664e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.194829
Average KL loss: 0.104563
Average total loss: 0.299392
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-8.2347e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.190186
Average KL loss: 0.103683
Average total loss: 0.293870
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-7.2331e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.192425
Average KL loss: 0.103628
Average total loss: 0.296053
tensor(0.0107, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-8.9003e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.192378
Average KL loss: 0.103495
Average total loss: 0.295873
tensor(0.0107, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-7.7739e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.185988
Average KL loss: 0.103042
Average total loss: 0.289030
tensor(0.0106, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-5.7787e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.185983
Average KL loss: 0.102868
Average total loss: 0.288851
tensor(0.0107, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.5726e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.187530
Average KL loss: 0.102887
Average total loss: 0.290417
tensor(0.0106, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.4548e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.181874
Average KL loss: 0.102761
Average total loss: 0.284635
tensor(0.0106, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.7312e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.182940
Average KL loss: 0.102400
Average total loss: 0.285340
tensor(0.0107, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-5.0262e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.180391
Average KL loss: 0.102317
Average total loss: 0.282708
tensor(0.0106, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.6666e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.178004
Average KL loss: 0.102136
Average total loss: 0.280141
tensor(0.0106, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.4630e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.178429
Average KL loss: 0.101901
Average total loss: 0.280330
tensor(0.0106, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-6.5493e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.176254
Average KL loss: 0.101581
Average total loss: 0.277834
tensor(0.0106, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.2553e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.171436
Average KL loss: 0.100969
Average total loss: 0.272405
tensor(0.0107, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.4758e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.174391
Average KL loss: 0.100904
Average total loss: 0.275295
tensor(0.0106, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.9303e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.174126
Average KL loss: 0.101081
Average total loss: 0.275207
tensor(0.0106, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.8292e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.172571
Average KL loss: 0.101363
Average total loss: 0.273935
tensor(0.0106, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.9867e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.172196
Average KL loss: 0.101540
Average total loss: 0.273736
tensor(0.0107, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(2.1698e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.171307
Average KL loss: 0.101518
Average total loss: 0.272825
tensor(0.0106, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.6367e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.171666
Average KL loss: 0.101483
Average total loss: 0.273148
tensor(0.0107, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.9029e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.167767
Average KL loss: 0.101391
Average total loss: 0.269158
tensor(0.0107, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-4.6315e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.164638
Average KL loss: 0.100851
Average total loss: 0.265489
tensor(0.0106, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.4123e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.164945
Average KL loss: 0.100463
Average total loss: 0.265408
tensor(0.0107, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.7286e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.163332
Average KL loss: 0.100505
Average total loss: 0.263837
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.2660e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.164677
Average KL loss: 0.100462
Average total loss: 0.265139
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.6419e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.161558
Average KL loss: 0.100600
Average total loss: 0.262158
tensor(0.0106, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.0041e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.161499
Average KL loss: 0.100252
Average total loss: 0.261751
tensor(0.0107, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.9843e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.157930
Average KL loss: 0.100193
Average total loss: 0.258123
tensor(0.0106, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.4387e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.161412
Average KL loss: 0.100008
Average total loss: 0.261420
tensor(0.0106, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-5.7085e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.160924
Average KL loss: 0.100285
Average total loss: 0.261208
tensor(0.0106, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.6761e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.158146
Average KL loss: 0.100120
Average total loss: 0.258265
tensor(0.0107, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.8419e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.158239
Average KL loss: 0.100271
Average total loss: 0.258510
tensor(0.0107, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.6433e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.158332
Average KL loss: 0.100229
Average total loss: 0.258561
tensor(0.0107, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.1905e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.154110
Average KL loss: 0.100096
Average total loss: 0.254206
tensor(0.0107, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.7583e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.156293
Average KL loss: 0.099710
Average total loss: 0.256002
tensor(0.0107, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.5104e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.152861
Average KL loss: 0.099843
Average total loss: 0.252704
tensor(0.0107, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.5939e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.154069
Average KL loss: 0.099536
Average total loss: 0.253605
tensor(0.0107, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.3257e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.152916
Average KL loss: 0.099761
Average total loss: 0.252678
tensor(0.0107, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-4.9510e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.151247
Average KL loss: 0.099556
Average total loss: 0.250803
tensor(0.0107, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.3727e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.152220
Average KL loss: 0.099424
Average total loss: 0.251644
tensor(0.0107, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.9681e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.151915
Average KL loss: 0.099694
Average total loss: 0.251609
tensor(0.0107, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(3.6134e-11, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.151946
Average KL loss: 0.099866
Average total loss: 0.251812
tensor(0.0107, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.1153e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.149003
Average KL loss: 0.099500
Average total loss: 0.248503
tensor(0.0107, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.7590e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.149994
Average KL loss: 0.099307
Average total loss: 0.249301
tensor(0.0107, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(4.8766e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.149718
Average KL loss: 0.099514
Average total loss: 0.249232
tensor(0.0107, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.6639e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.148058
Average KL loss: 0.099349
Average total loss: 0.247407
tensor(0.0107, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.0299e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.148045
Average KL loss: 0.099394
Average total loss: 0.247439
tensor(0.0107, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.3734e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.147105
Average KL loss: 0.099140
Average total loss: 0.246245
tensor(0.0106, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-6.1595e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.147648
Average KL loss: 0.099276
Average total loss: 0.246924
tensor(0.0106, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-5.0141e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.145933
Average KL loss: 0.099014
Average total loss: 0.244947
tensor(0.0106, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-8.1983e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.148665
Average KL loss: 0.099323
Average total loss: 0.247988
tensor(0.0107, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-7.4238e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.141160
Average KL loss: 0.099126
Average total loss: 0.240285
tensor(0.0107, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-2.5719e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.143483
Average KL loss: 0.098940
Average total loss: 0.242423
tensor(0.0106, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-9.7711e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.143464
Average KL loss: 0.098851
Average total loss: 0.242315
tensor(0.0107, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-3.4925e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.144339
Average KL loss: 0.098792
Average total loss: 0.243131
tensor(0.0107, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.2250e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.142865
Average KL loss: 0.099283
Average total loss: 0.242148
tensor(0.0107, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-3.2516e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.142792
Average KL loss: 0.099108
Average total loss: 0.241901
tensor(0.0106, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-2.1319e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.140531
Average KL loss: 0.098905
Average total loss: 0.239436
tensor(0.0107, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(2.8490e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.141103
Average KL loss: 0.098577
Average total loss: 0.239680
tensor(0.0106, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.6779e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.140750
Average KL loss: 0.098782
Average total loss: 0.239532
tensor(0.0106, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-7.6456e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.141860
Average KL loss: 0.098792
Average total loss: 0.240651
tensor(0.0106, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(1.4308e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.139076
Average KL loss: 0.098853
Average total loss: 0.237929
tensor(0.0106, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-5.4494e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.142094
Average KL loss: 0.098804
Average total loss: 0.240898
tensor(0.0106, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(4.8459e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.141122
Average KL loss: 0.099010
Average total loss: 0.240132
tensor(0.0106, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-2.8428e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.138782
Average KL loss: 0.098923
Average total loss: 0.237704
tensor(0.0106, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(6.9124e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.138701
Average KL loss: 0.098674
Average total loss: 0.237374
tensor(0.0106, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.1235e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.138555
Average KL loss: 0.098573
Average total loss: 0.237128
tensor(0.0106, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.0242e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.140295
Average KL loss: 0.098744
Average total loss: 0.239040
tensor(0.0107, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-3.7390e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.138721
Average KL loss: 0.099100
Average total loss: 0.237822
tensor(0.0106, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-4.8196e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.136878
Average KL loss: 0.098804
Average total loss: 0.235682
tensor(0.0106, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-1.5130e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.138007
Average KL loss: 0.098730
Average total loss: 0.236737
tensor(0.0107, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-8.7487e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.137395
Average KL loss: 0.098794
Average total loss: 0.236189
tensor(0.0106, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-2.2471e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.136747
Average KL loss: 0.098811
Average total loss: 0.235558
tensor(0.0107, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-6.4143e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.137932
Average KL loss: 0.098643
Average total loss: 0.236576
tensor(0.0107, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-8.3280e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.137960
Average KL loss: 0.099253
Average total loss: 0.237213
tensor(0.0107, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(1.7124e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.135366
Average KL loss: 0.099149
Average total loss: 0.234514
tensor(0.0106, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.8124e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.134990
Average KL loss: 0.098961
Average total loss: 0.233951
tensor(0.0106, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-1.0508e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.135223
Average KL loss: 0.098711
Average total loss: 0.233934
tensor(0.0107, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-7.1163e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.135545
Average KL loss: 0.099045
Average total loss: 0.234590
tensor(0.0107, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.6853e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.136011
Average KL loss: 0.099040
Average total loss: 0.235051
tensor(0.0107, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(5.6815e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.135323
Average KL loss: 0.098813
Average total loss: 0.234136
tensor(0.0107, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.2994e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.135480
Average KL loss: 0.099058
Average total loss: 0.234538
tensor(0.0107, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.0000e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.133636
Average KL loss: 0.098960
Average total loss: 0.232596
tensor(0.0107, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-7.2795e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.135387
Average KL loss: 0.099083
Average total loss: 0.234469
tensor(0.0107, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.4875e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.132790
Average KL loss: 0.099066
Average total loss: 0.231856
tensor(0.0106, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-8.4984e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.132469
Average KL loss: 0.098924
Average total loss: 0.231393
tensor(0.0106, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.7925e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.131093
Average KL loss: 0.098715
Average total loss: 0.229808
tensor(0.0107, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.1236e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.132477
Average KL loss: 0.098617
Average total loss: 0.231094
tensor(0.0107, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.4687e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.132405
Average KL loss: 0.098382
Average total loss: 0.230787
tensor(0.0106, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(3.9400e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.133711
Average KL loss: 0.098675
Average total loss: 0.232386
tensor(0.0106, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-2.9745e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.132492
Average KL loss: 0.098879
Average total loss: 0.231372
tensor(0.0107, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-2.2167e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.132412
Average KL loss: 0.099044
Average total loss: 0.231456
tensor(0.0107, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(2.4374e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.132159
Average KL loss: 0.098740
Average total loss: 0.230899
tensor(0.0106, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-8.1472e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.131354
Average KL loss: 0.098665
Average total loss: 0.230019
tensor(0.0107, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(1.4786e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.131613
Average KL loss: 0.098868
Average total loss: 0.230481
tensor(0.0106, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(6.0522e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.128837
Average KL loss: 0.098691
Average total loss: 0.227528
tensor(0.0107, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.0329e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.131643
Average KL loss: 0.098561
Average total loss: 0.230204
tensor(0.0107, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-2.0246e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.131208
Average KL loss: 0.098700
Average total loss: 0.229908
tensor(0.0107, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-1.2002e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.130435
Average KL loss: 0.098986
Average total loss: 0.229422
tensor(0.0107, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.5300e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.130097
Average KL loss: 0.098504
Average total loss: 0.228600
tensor(0.0107, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(1.0880e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.129431
Average KL loss: 0.098887
Average total loss: 0.228318
tensor(0.0107, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(1.2609e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.130057
Average KL loss: 0.099167
Average total loss: 0.229224
tensor(0.0107, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.8203e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.128454
Average KL loss: 0.098650
Average total loss: 0.227104
tensor(0.0107, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.5809e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.127743
Average KL loss: 0.098033
Average total loss: 0.225776
tensor(0.0107, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.4410e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.129113
Average KL loss: 0.098270
Average total loss: 0.227383
tensor(0.0107, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(6.8866e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.129482
Average KL loss: 0.098600
Average total loss: 0.228082
tensor(0.0107, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-1.2111e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.128964
Average KL loss: 0.098558
Average total loss: 0.227522
tensor(0.0107, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-7.8264e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.127787
Average KL loss: 0.098492
Average total loss: 0.226279
tensor(0.0107, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.9323e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.126841
Average KL loss: 0.098564
Average total loss: 0.225405
tensor(0.0107, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.3081e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.127436
Average KL loss: 0.098188
Average total loss: 0.225624
tensor(0.0107, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-2.4387e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.127832
Average KL loss: 0.098341
Average total loss: 0.226173
tensor(0.0107, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.3279e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.128439
Average KL loss: 0.098586
Average total loss: 0.227026
tensor(0.0107, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.1384e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.126644
Average KL loss: 0.098519
Average total loss: 0.225163
tensor(0.0106, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.5120e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.127284
Average KL loss: 0.098488
Average total loss: 0.225772
tensor(0.0107, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-7.1320e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.126771
Average KL loss: 0.098399
Average total loss: 0.225170
tensor(0.0106, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(3.3613e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.129075
Average KL loss: 0.098430
Average total loss: 0.227505
tensor(0.0107, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-1.0284e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.126040
Average KL loss: 0.098654
Average total loss: 0.224694
tensor(0.0107, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(6.4055e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.125921
Average KL loss: 0.098355
Average total loss: 0.224277
tensor(0.0107, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-8.5788e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.126847
Average KL loss: 0.098434
Average total loss: 0.225281
tensor(0.0107, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(4.8553e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.125048
Average KL loss: 0.098286
Average total loss: 0.223334
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.0315e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.124365
Average KL loss: 0.097974
Average total loss: 0.222338
tensor(0.0106, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-3.8978e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.126596
Average KL loss: 0.098147
Average total loss: 0.224744
tensor(0.0107, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(5.2515e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.126425
Average KL loss: 0.098549
Average total loss: 0.224974
tensor(0.0107, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.8284e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.124599
Average KL loss: 0.098512
Average total loss: 0.223111
tensor(0.0107, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(9.6623e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.125169
Average KL loss: 0.098222
Average total loss: 0.223390
tensor(0.0107, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.2758e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.126715
Average KL loss: 0.098595
Average total loss: 0.225310
tensor(0.0107, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.1160e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.126356
Average KL loss: 0.098706
Average total loss: 0.225062
tensor(0.0107, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.3962e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.125176
Average KL loss: 0.098846
Average total loss: 0.224021
tensor(0.0107, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(1.3091e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.125398
Average KL loss: 0.098801
Average total loss: 0.224199
tensor(0.0107, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(6.8943e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.125241
Average KL loss: 0.098792
Average total loss: 0.224033
tensor(0.0107, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(2.0465e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.125953
Average KL loss: 0.098806
Average total loss: 0.224759
tensor(0.0107, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-8.9131e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.126171
Average KL loss: 0.099003
Average total loss: 0.225173
tensor(0.0107, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.6468e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.124003
Average KL loss: 0.097839
Average total loss: 0.221842
tensor(0.0107, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.0247e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.124168
Average KL loss: 0.095978
Average total loss: 0.220147
tensor(0.0107, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-5.2381e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.124132
Average KL loss: 0.094656
Average total loss: 0.218788
tensor(0.0107, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(8.7250e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.122286
Average KL loss: 0.093625
Average total loss: 0.215911
tensor(0.0107, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(7.2177e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.122762
Average KL loss: 0.092770
Average total loss: 0.215532
tensor(0.0107, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.0024e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.122101
Average KL loss: 0.092040
Average total loss: 0.214141
tensor(0.0107, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(9.8727e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.122740
Average KL loss: 0.091405
Average total loss: 0.214145
tensor(0.0107, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(1.2235e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.121205
Average KL loss: 0.090840
Average total loss: 0.212045
tensor(0.0107, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(3.8293e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.121845
Average KL loss: 0.090334
Average total loss: 0.212179
tensor(0.0107, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.7419e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.122182
Average KL loss: 0.089873
Average total loss: 0.212054
tensor(0.0107, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-5.3790e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.122593
Average KL loss: 0.089470
Average total loss: 0.212063
tensor(0.0107, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-5.4101e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.122677
Average KL loss: 0.089099
Average total loss: 0.211776
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-5.7147e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.123040
Average KL loss: 0.088774
Average total loss: 0.211814
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(1.5860e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.123771
Average KL loss: 0.088484
Average total loss: 0.212256
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.8158e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.123274
Average KL loss: 0.088240
Average total loss: 0.211514
 Percentile value: 0.007405836600810289
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =     500 /    1728             ( 28.94%) | total_pruned =    1228 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6769 /   36864             ( 18.36%) | total_pruned =   30095 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   16128 /   36864             ( 43.75%) | total_pruned =   20736 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   16129 /   36864             ( 43.75%) | total_pruned =   20735 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18881 /   36864             ( 51.22%) | total_pruned =   17983 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   41278 /   73728             ( 55.99%) | total_pruned =   32450 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   83170 /  147456             ( 56.40%) | total_pruned =   64286 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5202 /    8192             ( 63.50%) | total_pruned =    2990 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   73389 /  147456             ( 49.77%) | total_pruned =   74067 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   73618 /  147456             ( 49.93%) | total_pruned =   73838 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  160484 /  294912             ( 54.42%) | total_pruned =  134428 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  319030 /  589824             ( 54.09%) | total_pruned =  270794 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19039 /   32768             ( 58.10%) | total_pruned =   13729 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  306655 /  589824             ( 51.99%) | total_pruned =  283169 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  296673 /  589824             ( 50.30%) | total_pruned =  293151 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     144 /     256             ( 56.25%) | total_pruned =     112 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  606275 / 1179648             ( 51.39%) | total_pruned =  573373 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     143 /     512             ( 27.93%) | total_pruned =     369 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1105143 / 2359296             ( 46.84%) | total_pruned = 1254153 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     318 /     512             ( 62.11%) | total_pruned =     194 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   61397 /  131072             ( 46.84%) | total_pruned =   69675 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     324 /     512             ( 63.28%) | total_pruned =     188 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1043189 / 2359296             ( 44.22%) | total_pruned = 1316107 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1324202 / 2359296             ( 56.13%) | total_pruned = 1035094 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5088 /    5120             ( 99.38%) | total_pruned =      32 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 57/100 Loss: 0.015838 Accuracy: 88.19 100.00 % Best test Accuracy: 88.21%
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.9699e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.783979
Average KL loss: 0.087582
Average total loss: 0.871561
tensor(0.0137, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-8.0862e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.523726
Average KL loss: 0.103565
Average total loss: 0.627291
tensor(0.0140, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-4.7887e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.447369
Average KL loss: 0.110341
Average total loss: 0.557710
tensor(0.0140, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-3.8508e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.401165
Average KL loss: 0.113453
Average total loss: 0.514618
tensor(0.0139, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.6191e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.363948
Average KL loss: 0.115135
Average total loss: 0.479084
tensor(0.0139, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.6136e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.344066
Average KL loss: 0.116182
Average total loss: 0.460249
tensor(0.0138, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.5841e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.331513
Average KL loss: 0.117036
Average total loss: 0.448549
tensor(0.0137, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.8842e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.309055
Average KL loss: 0.117592
Average total loss: 0.426647
tensor(0.0137, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.0558e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.301472
Average KL loss: 0.118295
Average total loss: 0.419767
tensor(0.0136, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-2.8167e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.290870
Average KL loss: 0.119354
Average total loss: 0.410225
tensor(0.0136, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.7785e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.285074
Average KL loss: 0.120178
Average total loss: 0.405252
tensor(0.0136, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-1.0711e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.271965
Average KL loss: 0.120840
Average total loss: 0.392804
tensor(0.0136, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-1.8045e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.271556
Average KL loss: 0.120927
Average total loss: 0.392483
tensor(0.0135, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-1.9557e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.262478
Average KL loss: 0.121618
Average total loss: 0.384096
tensor(0.0135, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-1.1035e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.255356
Average KL loss: 0.122111
Average total loss: 0.377467
tensor(0.0135, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-6.2940e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.252006
Average KL loss: 0.122575
Average total loss: 0.374580
tensor(0.0136, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-1.6680e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.246347
Average KL loss: 0.122636
Average total loss: 0.368983
tensor(0.0135, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-1.0537e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.237970
Average KL loss: 0.122810
Average total loss: 0.360780
tensor(0.0135, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-6.4551e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.238689
Average KL loss: 0.123246
Average total loss: 0.361935
tensor(0.0135, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-5.1208e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.232770
Average KL loss: 0.123345
Average total loss: 0.356115
tensor(0.0135, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-3.7442e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.223882
Average KL loss: 0.123195
Average total loss: 0.347076
tensor(0.0135, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.0203e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.228235
Average KL loss: 0.123288
Average total loss: 0.351523
tensor(0.0135, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-9.1816e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.227193
Average KL loss: 0.123694
Average total loss: 0.350887
tensor(0.0135, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-2.4563e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.218977
Average KL loss: 0.123765
Average total loss: 0.342742
tensor(0.0134, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-8.0517e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.216965
Average KL loss: 0.123792
Average total loss: 0.340756
tensor(0.0134, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.5525e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.222387
Average KL loss: 0.124032
Average total loss: 0.346419
tensor(0.0134, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-6.2264e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.211500
Average KL loss: 0.124370
Average total loss: 0.335870
tensor(0.0134, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-6.7239e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.208985
Average KL loss: 0.124095
Average total loss: 0.333079
tensor(0.0134, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-4.9635e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.209479
Average KL loss: 0.124204
Average total loss: 0.333683
tensor(0.0133, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-6.2276e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.205364
Average KL loss: 0.124103
Average total loss: 0.329467
tensor(0.0134, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-4.0658e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.203757
Average KL loss: 0.124362
Average total loss: 0.328119
tensor(0.0133, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-3.3083e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.205459
Average KL loss: 0.124399
Average total loss: 0.329858
tensor(0.0134, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.5858e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.200204
Average KL loss: 0.124505
Average total loss: 0.324709
tensor(0.0133, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-2.1996e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.198197
Average KL loss: 0.124296
Average total loss: 0.322493
tensor(0.0133, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.4580e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.197348
Average KL loss: 0.124440
Average total loss: 0.321788
tensor(0.0133, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-4.8286e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.194689
Average KL loss: 0.124199
Average total loss: 0.318888
tensor(0.0133, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-8.8935e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.191316
Average KL loss: 0.124094
Average total loss: 0.315410
tensor(0.0132, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-5.0680e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.193909
Average KL loss: 0.124029
Average total loss: 0.317938
tensor(0.0132, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-3.2605e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.189676
Average KL loss: 0.124207
Average total loss: 0.313883
tensor(0.0132, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.8615e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.189527
Average KL loss: 0.124134
Average total loss: 0.313661
tensor(0.0132, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.9424e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.185856
Average KL loss: 0.124289
Average total loss: 0.310145
tensor(0.0132, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.8229e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.184046
Average KL loss: 0.124037
Average total loss: 0.308083
tensor(0.0132, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-5.1125e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.188549
Average KL loss: 0.124124
Average total loss: 0.312673
tensor(0.0132, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-3.5024e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.185256
Average KL loss: 0.124435
Average total loss: 0.309692
tensor(0.0132, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-3.7218e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.180465
Average KL loss: 0.124019
Average total loss: 0.304484
tensor(0.0131, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-2.2957e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.178862
Average KL loss: 0.123703
Average total loss: 0.302565
tensor(0.0131, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-3.0912e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.180495
Average KL loss: 0.123548
Average total loss: 0.304042
tensor(0.0131, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-9.2512e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.178915
Average KL loss: 0.123699
Average total loss: 0.302614
tensor(0.0131, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-5.8888e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.178211
Average KL loss: 0.123777
Average total loss: 0.301988
tensor(0.0131, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-1.8328e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.176828
Average KL loss: 0.123981
Average total loss: 0.300808
tensor(0.0131, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-4.3756e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.172839
Average KL loss: 0.123805
Average total loss: 0.296645
tensor(0.0131, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-2.7153e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.175827
Average KL loss: 0.123577
Average total loss: 0.299404
tensor(0.0131, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(5.2612e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.171615
Average KL loss: 0.123627
Average total loss: 0.295242
tensor(0.0131, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(5.7069e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.173480
Average KL loss: 0.123575
Average total loss: 0.297055
tensor(0.0130, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-5.7116e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.173733
Average KL loss: 0.123733
Average total loss: 0.297465
tensor(0.0130, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-5.6756e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.169180
Average KL loss: 0.123710
Average total loss: 0.292890
tensor(0.0130, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-1.8879e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.172383
Average KL loss: 0.123719
Average total loss: 0.296103
tensor(0.0130, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-1.8113e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.170157
Average KL loss: 0.123765
Average total loss: 0.293922
tensor(0.0130, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-8.9188e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.166017
Average KL loss: 0.123645
Average total loss: 0.289662
tensor(0.0130, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-2.3473e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.166964
Average KL loss: 0.123528
Average total loss: 0.290492
tensor(0.0130, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.9223e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.165773
Average KL loss: 0.123373
Average total loss: 0.289146
tensor(0.0130, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(2.9544e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.165838
Average KL loss: 0.123333
Average total loss: 0.289171
tensor(0.0130, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.2070e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.167317
Average KL loss: 0.123426
Average total loss: 0.290743
tensor(0.0130, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(2.6079e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.164840
Average KL loss: 0.123486
Average total loss: 0.288326
tensor(0.0130, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-5.2689e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.164399
Average KL loss: 0.123364
Average total loss: 0.287763
tensor(0.0130, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(6.1632e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.161466
Average KL loss: 0.123196
Average total loss: 0.284662
tensor(0.0129, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-2.6735e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.161268
Average KL loss: 0.123059
Average total loss: 0.284327
tensor(0.0129, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-6.9407e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.161695
Average KL loss: 0.123091
Average total loss: 0.284786
tensor(0.0129, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.7918e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.161788
Average KL loss: 0.123081
Average total loss: 0.284869
tensor(0.0129, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-6.1027e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.163021
Average KL loss: 0.123194
Average total loss: 0.286214
tensor(0.0129, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.4737e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.161142
Average KL loss: 0.123324
Average total loss: 0.284466
tensor(0.0129, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(1.2940e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.160030
Average KL loss: 0.123276
Average total loss: 0.283305
tensor(0.0129, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(5.9682e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.159602
Average KL loss: 0.123287
Average total loss: 0.282889
tensor(0.0129, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-3.3317e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.158603
Average KL loss: 0.123139
Average total loss: 0.281742
tensor(0.0129, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-7.9415e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.156279
Average KL loss: 0.123089
Average total loss: 0.279368
tensor(0.0128, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-1.5375e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.158845
Average KL loss: 0.122924
Average total loss: 0.281769
tensor(0.0128, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-2.1919e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.157851
Average KL loss: 0.122892
Average total loss: 0.280743
tensor(0.0128, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(6.9105e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.156369
Average KL loss: 0.122936
Average total loss: 0.279304
tensor(0.0128, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-9.8393e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.155983
Average KL loss: 0.123053
Average total loss: 0.279036
tensor(0.0128, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-1.2132e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.154515
Average KL loss: 0.122873
Average total loss: 0.277389
tensor(0.0128, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(2.4051e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.154964
Average KL loss: 0.122789
Average total loss: 0.277753
tensor(0.0128, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(5.0502e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.155559
Average KL loss: 0.122927
Average total loss: 0.278485
tensor(0.0128, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-3.0933e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.155639
Average KL loss: 0.122814
Average total loss: 0.278453
tensor(0.0128, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-9.7087e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.155998
Average KL loss: 0.122773
Average total loss: 0.278771
tensor(0.0127, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-1.5138e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.154591
Average KL loss: 0.122749
Average total loss: 0.277340
tensor(0.0127, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-2.1352e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.152391
Average KL loss: 0.122606
Average total loss: 0.274997
tensor(0.0128, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-1.3973e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.152531
Average KL loss: 0.122615
Average total loss: 0.275146
tensor(0.0127, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-1.7944e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.154354
Average KL loss: 0.122662
Average total loss: 0.277016
tensor(0.0127, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-2.1545e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.152790
Average KL loss: 0.122776
Average total loss: 0.275565
tensor(0.0128, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-2.2818e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.152461
Average KL loss: 0.122776
Average total loss: 0.275237
tensor(0.0128, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-1.8779e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.151080
Average KL loss: 0.122807
Average total loss: 0.273887
tensor(0.0128, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-8.9306e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.150189
Average KL loss: 0.122650
Average total loss: 0.272838
tensor(0.0127, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-2.1131e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.151589
Average KL loss: 0.122844
Average total loss: 0.274433
tensor(0.0127, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-1.8584e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.149993
Average KL loss: 0.122815
Average total loss: 0.272808
tensor(0.0127, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-1.3489e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.152989
Average KL loss: 0.122734
Average total loss: 0.275723
tensor(0.0127, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-1.0240e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.150544
Average KL loss: 0.122912
Average total loss: 0.273456
tensor(0.0127, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-4.8166e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.148860
Average KL loss: 0.122656
Average total loss: 0.271516
tensor(0.0127, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.5326e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.149147
Average KL loss: 0.122495
Average total loss: 0.271642
tensor(0.0127, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-8.6058e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.149604
Average KL loss: 0.122554
Average total loss: 0.272158
tensor(0.0127, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-1.7282e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.148066
Average KL loss: 0.122515
Average total loss: 0.270581
tensor(0.0127, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-4.9408e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.153415
Average KL loss: 0.122647
Average total loss: 0.276063
tensor(0.0127, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.0796e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.148924
Average KL loss: 0.123022
Average total loss: 0.271946
tensor(0.0127, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-1.1123e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.149381
Average KL loss: 0.123017
Average total loss: 0.272398
tensor(0.0127, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-2.2946e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.148265
Average KL loss: 0.122884
Average total loss: 0.271149
tensor(0.0127, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(4.9309e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.148753
Average KL loss: 0.122921
Average total loss: 0.271675
tensor(0.0127, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-3.8322e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.146378
Average KL loss: 0.122866
Average total loss: 0.269245
tensor(0.0127, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(2.1116e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.147749
Average KL loss: 0.122486
Average total loss: 0.270235
tensor(0.0127, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-7.6538e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.146230
Average KL loss: 0.122612
Average total loss: 0.268842
tensor(0.0127, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(1.9120e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.145037
Average KL loss: 0.122514
Average total loss: 0.267552
tensor(0.0127, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-4.1345e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.148342
Average KL loss: 0.122373
Average total loss: 0.270715
tensor(0.0127, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(1.7000e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.146367
Average KL loss: 0.122626
Average total loss: 0.268993
tensor(0.0127, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-2.1546e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.145249
Average KL loss: 0.122400
Average total loss: 0.267649
tensor(0.0127, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-4.3179e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.146818
Average KL loss: 0.122504
Average total loss: 0.269322
tensor(0.0127, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(1.4155e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.143794
Average KL loss: 0.122663
Average total loss: 0.266457
tensor(0.0126, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(4.6502e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.147483
Average KL loss: 0.122488
Average total loss: 0.269972
tensor(0.0127, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-2.6711e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.144229
Average KL loss: 0.122486
Average total loss: 0.266715
tensor(0.0126, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-2.1345e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.145917
Average KL loss: 0.122512
Average total loss: 0.268430
tensor(0.0126, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.9917e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.146328
Average KL loss: 0.122601
Average total loss: 0.268929
tensor(0.0127, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(1.0490e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.144876
Average KL loss: 0.122610
Average total loss: 0.267486
tensor(0.0126, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-4.9831e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.142863
Average KL loss: 0.122503
Average total loss: 0.265366
tensor(0.0126, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.9387e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.142939
Average KL loss: 0.122308
Average total loss: 0.265246
tensor(0.0126, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.4589e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.144115
Average KL loss: 0.122387
Average total loss: 0.266502
tensor(0.0126, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(4.7151e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.145592
Average KL loss: 0.122452
Average total loss: 0.268044
tensor(0.0126, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-6.1967e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.142437
Average KL loss: 0.122611
Average total loss: 0.265048
tensor(0.0126, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.3015e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.141571
Average KL loss: 0.122275
Average total loss: 0.263846
tensor(0.0126, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(7.3730e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.143948
Average KL loss: 0.122266
Average total loss: 0.266214
tensor(0.0126, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-2.5209e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.143501
Average KL loss: 0.122384
Average total loss: 0.265885
tensor(0.0126, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-2.5041e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.143282
Average KL loss: 0.122233
Average total loss: 0.265515
tensor(0.0126, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(2.2650e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.141077
Average KL loss: 0.122212
Average total loss: 0.263289
tensor(0.0126, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-6.7093e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.142453
Average KL loss: 0.122394
Average total loss: 0.264847
tensor(0.0126, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(1.3005e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.143237
Average KL loss: 0.122332
Average total loss: 0.265569
tensor(0.0126, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-4.9209e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.141348
Average KL loss: 0.122428
Average total loss: 0.263776
tensor(0.0126, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(3.2096e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.142603
Average KL loss: 0.122483
Average total loss: 0.265086
tensor(0.0126, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(2.2408e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.142809
Average KL loss: 0.122402
Average total loss: 0.265211
tensor(0.0126, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(1.0371e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.140950
Average KL loss: 0.122320
Average total loss: 0.263270
tensor(0.0126, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-7.3847e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.141198
Average KL loss: 0.122292
Average total loss: 0.263490
tensor(0.0126, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(9.7954e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.141661
Average KL loss: 0.122493
Average total loss: 0.264154
tensor(0.0126, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-3.1725e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.139792
Average KL loss: 0.122335
Average total loss: 0.262127
tensor(0.0126, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-1.6392e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.140124
Average KL loss: 0.122295
Average total loss: 0.262419
tensor(0.0126, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(3.2429e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.143126
Average KL loss: 0.122207
Average total loss: 0.265333
tensor(0.0126, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-6.6797e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.139697
Average KL loss: 0.122385
Average total loss: 0.262083
tensor(0.0126, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(3.3424e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.140610
Average KL loss: 0.122176
Average total loss: 0.262786
tensor(0.0126, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-8.0050e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.139621
Average KL loss: 0.122092
Average total loss: 0.261713
tensor(0.0126, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(2.3138e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.139170
Average KL loss: 0.122011
Average total loss: 0.261181
tensor(0.0126, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-2.6090e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.140263
Average KL loss: 0.121938
Average total loss: 0.262201
tensor(0.0126, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(1.4373e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.140969
Average KL loss: 0.122113
Average total loss: 0.263082
tensor(0.0126, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-2.5804e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.138808
Average KL loss: 0.122143
Average total loss: 0.260951
tensor(0.0126, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-4.5789e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.141405
Average KL loss: 0.121963
Average total loss: 0.263368
tensor(0.0126, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(1.1141e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.140023
Average KL loss: 0.122175
Average total loss: 0.262197
tensor(0.0126, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-9.0381e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.140182
Average KL loss: 0.122186
Average total loss: 0.262369
tensor(0.0126, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-6.2692e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.140286
Average KL loss: 0.122300
Average total loss: 0.262586
tensor(0.0125, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-4.0422e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.139039
Average KL loss: 0.122051
Average total loss: 0.261090
tensor(0.0126, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-2.3822e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.138773
Average KL loss: 0.121920
Average total loss: 0.260693
tensor(0.0126, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(3.4267e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.140390
Average KL loss: 0.122009
Average total loss: 0.262399
tensor(0.0126, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(9.7748e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.140013
Average KL loss: 0.122015
Average total loss: 0.262028
tensor(0.0126, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(1.0726e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.137997
Average KL loss: 0.122129
Average total loss: 0.260126
tensor(0.0126, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-2.1984e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.139023
Average KL loss: 0.121966
Average total loss: 0.260989
tensor(0.0126, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(2.5854e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.138499
Average KL loss: 0.122066
Average total loss: 0.260565
tensor(0.0126, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(1.7580e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.137723
Average KL loss: 0.121951
Average total loss: 0.259674
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-2.0175e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.137789
Average KL loss: 0.121915
Average total loss: 0.259705
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.9268e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.139452
Average KL loss: 0.121895
Average total loss: 0.261347
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.7127e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.137738
Average KL loss: 0.121858
Average total loss: 0.259596
tensor(0.0126, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.8877e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.139546
Average KL loss: 0.122013
Average total loss: 0.261559
tensor(0.0126, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.6753e-11, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.139659
Average KL loss: 0.122051
Average total loss: 0.261710
tensor(0.0126, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(3.6541e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.138203
Average KL loss: 0.122301
Average total loss: 0.260503
tensor(0.0126, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-5.0093e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.138191
Average KL loss: 0.122117
Average total loss: 0.260309
tensor(0.0126, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-4.2323e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.138036
Average KL loss: 0.122010
Average total loss: 0.260046
tensor(0.0126, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.6256e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.137125
Average KL loss: 0.122062
Average total loss: 0.259188
tensor(0.0126, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-2.1921e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.138897
Average KL loss: 0.121968
Average total loss: 0.260865
tensor(0.0126, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-8.7427e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.136938
Average KL loss: 0.122068
Average total loss: 0.259005
tensor(0.0126, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(5.6124e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.137692
Average KL loss: 0.122012
Average total loss: 0.259704
tensor(0.0126, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-4.0166e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.137876
Average KL loss: 0.122066
Average total loss: 0.259942
tensor(0.0126, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-3.3233e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.138020
Average KL loss: 0.122127
Average total loss: 0.260147
tensor(0.0125, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(6.9820e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.137289
Average KL loss: 0.121977
Average total loss: 0.259265
tensor(0.0125, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(6.6999e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.138521
Average KL loss: 0.122048
Average total loss: 0.260569
tensor(0.0125, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(5.8401e-11, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.135835
Average KL loss: 0.121939
Average total loss: 0.257774
tensor(0.0126, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.1455e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.138858
Average KL loss: 0.121925
Average total loss: 0.260783
tensor(0.0126, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.0015e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.136531
Average KL loss: 0.122002
Average total loss: 0.258533
tensor(0.0125, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-7.2296e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.136106
Average KL loss: 0.121764
Average total loss: 0.257869
tensor(0.0126, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(1.0629e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.136670
Average KL loss: 0.121725
Average total loss: 0.258394
tensor(0.0126, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.7194e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.137943
Average KL loss: 0.121722
Average total loss: 0.259664
tensor(0.0126, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(1.6062e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.137280
Average KL loss: 0.122003
Average total loss: 0.259284
tensor(0.0126, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(1.4343e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.136556
Average KL loss: 0.121871
Average total loss: 0.258426
tensor(0.0126, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(1.8821e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.135657
Average KL loss: 0.121946
Average total loss: 0.257603
tensor(0.0126, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(1.9578e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.137823
Average KL loss: 0.121864
Average total loss: 0.259687
tensor(0.0125, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-8.9964e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.136653
Average KL loss: 0.122004
Average total loss: 0.258657
tensor(0.0125, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(1.3398e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.136595
Average KL loss: 0.121908
Average total loss: 0.258503
tensor(0.0126, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(2.0790e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.135955
Average KL loss: 0.121900
Average total loss: 0.257855
tensor(0.0125, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(2.8209e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.137572
Average KL loss: 0.121944
Average total loss: 0.259516
tensor(0.0126, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-1.4305e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.137223
Average KL loss: 0.122032
Average total loss: 0.259254
tensor(0.0126, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-2.7304e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.137559
Average KL loss: 0.122122
Average total loss: 0.259681
tensor(0.0126, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-7.0139e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.135674
Average KL loss: 0.122036
Average total loss: 0.257710
tensor(0.0126, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-2.3246e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.135317
Average KL loss: 0.121801
Average total loss: 0.257118
tensor(0.0126, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(5.1179e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.135793
Average KL loss: 0.121701
Average total loss: 0.257494
tensor(0.0126, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(5.9674e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.137544
Average KL loss: 0.121901
Average total loss: 0.259444
tensor(0.0126, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.9547e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.136453
Average KL loss: 0.122002
Average total loss: 0.258454
tensor(0.0126, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.2807e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.136474
Average KL loss: 0.121905
Average total loss: 0.258379
tensor(0.0126, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(5.9786e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.135850
Average KL loss: 0.121796
Average total loss: 0.257646
tensor(0.0126, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(3.5080e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.136949
Average KL loss: 0.121676
Average total loss: 0.258625
tensor(0.0126, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(7.3314e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.138532
Average KL loss: 0.121923
Average total loss: 0.260455
 Percentile value: 0.014186191372573376
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =     228 /    1728             ( 13.19%) | total_pruned =    1500 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.bias             | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1551 /   36864             (  4.21%) | total_pruned =   35313 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4434 /   36864             ( 12.03%) | total_pruned =   32430 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3897 /   36864             ( 10.57%) | total_pruned =   32967 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    5417 /   36864             ( 14.69%) | total_pruned =   31447 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   16290 /   73728             ( 22.09%) | total_pruned =   57438 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   30820 /  147456             ( 20.90%) | total_pruned =  116636 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2393 /    8192             ( 29.21%) | total_pruned =    5799 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   29976 /  147456             ( 20.33%) | total_pruned =  117480 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   32110 /  147456             ( 21.78%) | total_pruned =  115346 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   73180 /  294912             ( 24.81%) | total_pruned =  221732 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     205 /     256             ( 80.08%) | total_pruned =      51 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      92 /     256             ( 35.94%) | total_pruned =     164 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  128749 /  589824             ( 21.83%) | total_pruned =  461075 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    9588 /   32768             ( 29.26%) | total_pruned =   23180 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  135810 /  589824             ( 23.03%) | total_pruned =  454014 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  138986 /  589824             ( 23.56%) | total_pruned =  450838 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      61 /     256             ( 23.83%) | total_pruned =     195 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  292029 / 1179648             ( 24.76%) | total_pruned =  887619 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     468 /     512             ( 91.41%) | total_pruned =      44 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      80 /     512             ( 15.62%) | total_pruned =     432 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  550960 / 2359296             ( 23.35%) | total_pruned = 1808336 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     182 /     512             ( 35.55%) | total_pruned =     330 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   27336 /  131072             ( 20.86%) | total_pruned =  103736 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     411 /     512             ( 80.27%) | total_pruned =     101 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     192 /     512             ( 37.50%) | total_pruned =     320 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  526176 / 2359296             ( 22.30%) | total_pruned = 1833120 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  774081 / 2359296             ( 32.81%) | total_pruned = 1585215 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
linear.weight        | nonzeros =    4944 /    5120             ( 96.56%) | total_pruned =     176 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 59/100 Loss: 0.026697 Accuracy: 88.12 100.00 % Best test Accuracy: 88.18%
tensor(0.0126, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-7.6340e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.417343
Average KL loss: 0.108943
Average total loss: 0.526286
tensor(0.0137, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.6990e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.333040
Average KL loss: 0.109658
Average total loss: 0.442699
tensor(0.0134, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.8484e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.295726
Average KL loss: 0.111859
Average total loss: 0.407585
tensor(0.0132, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.4359e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.280507
Average KL loss: 0.113231
Average total loss: 0.393738
tensor(0.0130, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-1.1436e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.270211
Average KL loss: 0.114250
Average total loss: 0.384461
tensor(0.0129, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.5712e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.255425
Average KL loss: 0.115242
Average total loss: 0.370668
tensor(0.0127, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.3625e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.245250
Average KL loss: 0.115842
Average total loss: 0.361092
tensor(0.0127, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-8.2640e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.242178
Average KL loss: 0.116665
Average total loss: 0.358843
tensor(0.0126, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.3301e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.236251
Average KL loss: 0.117806
Average total loss: 0.354056
tensor(0.0126, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-7.8422e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.229279
Average KL loss: 0.118685
Average total loss: 0.347964
tensor(0.0125, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-9.3469e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.225071
Average KL loss: 0.119551
Average total loss: 0.344622
tensor(0.0125, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.1660e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.222068
Average KL loss: 0.120296
Average total loss: 0.342364
tensor(0.0125, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-8.5101e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.214038
Average KL loss: 0.120890
Average total loss: 0.334928
tensor(0.0125, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-8.7848e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.212780
Average KL loss: 0.121615
Average total loss: 0.334395
tensor(0.0124, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-1.3263e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.210182
Average KL loss: 0.122154
Average total loss: 0.332337
tensor(0.0124, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-7.2761e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.204158
Average KL loss: 0.122693
Average total loss: 0.326851
tensor(0.0124, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-5.7764e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.207379
Average KL loss: 0.123279
Average total loss: 0.330658
tensor(0.0124, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-8.1781e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.197925
Average KL loss: 0.123900
Average total loss: 0.321825
tensor(0.0124, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-1.1358e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.196477
Average KL loss: 0.124141
Average total loss: 0.320618
tensor(0.0125, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-3.8448e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.193516
Average KL loss: 0.124705
Average total loss: 0.318221
tensor(0.0124, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-2.1509e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.195048
Average KL loss: 0.124968
Average total loss: 0.320016
tensor(0.0124, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-3.8436e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.188922
Average KL loss: 0.125337
Average total loss: 0.314259
tensor(0.0124, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.2191e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.186665
Average KL loss: 0.125650
Average total loss: 0.312315
tensor(0.0124, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-8.6308e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.187048
Average KL loss: 0.125798
Average total loss: 0.312846
tensor(0.0124, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-2.1697e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.184713
Average KL loss: 0.126208
Average total loss: 0.310921
tensor(0.0124, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-3.3946e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.179631
Average KL loss: 0.126468
Average total loss: 0.306100
tensor(0.0124, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-3.4583e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.179409
Average KL loss: 0.126514
Average total loss: 0.305923
tensor(0.0124, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-7.0938e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.179560
Average KL loss: 0.126706
Average total loss: 0.306267
tensor(0.0124, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-5.2818e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.178057
Average KL loss: 0.127051
Average total loss: 0.305109
tensor(0.0124, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-4.7129e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.175596
Average KL loss: 0.127245
Average total loss: 0.302841
tensor(0.0123, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.6179e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.174140
Average KL loss: 0.127314
Average total loss: 0.301454
tensor(0.0123, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.4050e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.177628
Average KL loss: 0.127536
Average total loss: 0.305164
tensor(0.0123, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(1.7812e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.174805
Average KL loss: 0.127672
Average total loss: 0.302476
tensor(0.0124, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-1.5505e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.173133
Average KL loss: 0.127891
Average total loss: 0.301024
tensor(0.0124, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-1.9678e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.171120
Average KL loss: 0.128131
Average total loss: 0.299251
tensor(0.0123, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(1.6502e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.168714
Average KL loss: 0.128259
Average total loss: 0.296973
tensor(0.0123, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-3.4247e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.168632
Average KL loss: 0.128325
Average total loss: 0.296957
tensor(0.0123, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-3.8629e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.167791
Average KL loss: 0.128391
Average total loss: 0.296182
tensor(0.0123, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.5437e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.167118
Average KL loss: 0.128345
Average total loss: 0.295464
tensor(0.0123, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-2.2539e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.165743
Average KL loss: 0.128497
Average total loss: 0.294240
tensor(0.0123, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-5.3199e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.166443
Average KL loss: 0.128633
Average total loss: 0.295075
tensor(0.0123, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-1.0572e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.164415
Average KL loss: 0.128967
Average total loss: 0.293383
tensor(0.0123, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-4.4996e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.162283
Average KL loss: 0.129169
Average total loss: 0.291451
tensor(0.0123, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-1.0340e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.161974
Average KL loss: 0.129130
Average total loss: 0.291103
tensor(0.0123, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-4.9341e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.161739
Average KL loss: 0.129266
Average total loss: 0.291005
tensor(0.0123, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-1.6550e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.160390
Average KL loss: 0.129414
Average total loss: 0.289805
tensor(0.0123, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-4.0999e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.161017
Average KL loss: 0.129472
Average total loss: 0.290489
tensor(0.0123, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-3.3049e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.160319
Average KL loss: 0.129778
Average total loss: 0.290097
tensor(0.0123, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-9.7562e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.158118
Average KL loss: 0.129838
Average total loss: 0.287957
tensor(0.0123, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(6.7630e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.157864
Average KL loss: 0.129735
Average total loss: 0.287599
tensor(0.0123, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-1.7777e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.160031
Average KL loss: 0.130004
Average total loss: 0.290034
tensor(0.0123, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-8.6105e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.157168
Average KL loss: 0.130063
Average total loss: 0.287231
tensor(0.0123, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-4.6888e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.156811
Average KL loss: 0.130114
Average total loss: 0.286925
tensor(0.0123, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-2.8782e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.153585
Average KL loss: 0.130128
Average total loss: 0.283713
tensor(0.0123, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(1.2682e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.158204
Average KL loss: 0.130162
Average total loss: 0.288367
tensor(0.0123, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-4.6913e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.152069
Average KL loss: 0.130427
Average total loss: 0.282496
tensor(0.0123, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-1.9865e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.153483
Average KL loss: 0.130363
Average total loss: 0.283846
tensor(0.0123, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-2.4103e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.156620
Average KL loss: 0.130384
Average total loss: 0.287004
tensor(0.0123, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-2.9616e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.151345
Average KL loss: 0.130439
Average total loss: 0.281784
tensor(0.0123, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-3.6296e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.153658
Average KL loss: 0.130326
Average total loss: 0.283984
tensor(0.0123, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-7.5807e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.154499
Average KL loss: 0.130739
Average total loss: 0.285238
tensor(0.0123, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(8.1835e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.149590
Average KL loss: 0.130712
Average total loss: 0.280302
tensor(0.0123, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.1166e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.150931
Average KL loss: 0.130685
Average total loss: 0.281615
tensor(0.0123, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.0129e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.153133
Average KL loss: 0.130829
Average total loss: 0.283962
tensor(0.0123, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(5.0349e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.151028
Average KL loss: 0.131003
Average total loss: 0.282031
tensor(0.0123, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(1.7419e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.151146
Average KL loss: 0.131093
Average total loss: 0.282239
tensor(0.0123, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.2659e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.150988
Average KL loss: 0.131242
Average total loss: 0.282230
tensor(0.0123, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(5.1113e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.150034
Average KL loss: 0.131162
Average total loss: 0.281196
tensor(0.0123, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.4245e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.150393
Average KL loss: 0.131251
Average total loss: 0.281643
tensor(0.0123, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(6.8529e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.148036
Average KL loss: 0.131215
Average total loss: 0.279251
tensor(0.0123, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(7.7171e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.147866
Average KL loss: 0.131122
Average total loss: 0.278987
tensor(0.0123, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.0129e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.149216
Average KL loss: 0.131299
Average total loss: 0.280516
tensor(0.0123, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.3568e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.148468
Average KL loss: 0.131321
Average total loss: 0.279789
tensor(0.0123, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(1.7218e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.145232
Average KL loss: 0.131229
Average total loss: 0.276461
tensor(0.0123, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-3.3452e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.147411
Average KL loss: 0.131202
Average total loss: 0.278613
tensor(0.0123, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.7856e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.148226
Average KL loss: 0.131384
Average total loss: 0.279610
tensor(0.0123, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-6.7092e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.148756
Average KL loss: 0.131614
Average total loss: 0.280370
tensor(0.0123, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-3.5484e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.146313
Average KL loss: 0.131534
Average total loss: 0.277847
tensor(0.0123, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(9.0887e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.146861
Average KL loss: 0.131566
Average total loss: 0.278427
tensor(0.0123, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.4650e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.145496
Average KL loss: 0.131566
Average total loss: 0.277062
tensor(0.0123, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-5.9715e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.144488
Average KL loss: 0.131345
Average total loss: 0.275833
tensor(0.0123, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.1663e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.143348
Average KL loss: 0.131434
Average total loss: 0.274782
tensor(0.0123, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(1.6375e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.147883
Average KL loss: 0.131354
Average total loss: 0.279236
tensor(0.0123, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-1.5442e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.145986
Average KL loss: 0.131626
Average total loss: 0.277611
tensor(0.0123, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-1.0860e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.142570
Average KL loss: 0.131723
Average total loss: 0.274292
tensor(0.0123, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(9.6115e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.147854
Average KL loss: 0.131649
Average total loss: 0.279503
tensor(0.0123, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(2.0212e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.144786
Average KL loss: 0.131613
Average total loss: 0.276399
tensor(0.0122, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-8.5881e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.143923
Average KL loss: 0.131653
Average total loss: 0.275576
tensor(0.0123, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-3.3318e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.142255
Average KL loss: 0.131525
Average total loss: 0.273780
tensor(0.0122, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-6.0339e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.142983
Average KL loss: 0.131540
Average total loss: 0.274523
tensor(0.0122, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(6.5277e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.143893
Average KL loss: 0.131695
Average total loss: 0.275588
tensor(0.0122, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-5.0765e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.142506
Average KL loss: 0.131714
Average total loss: 0.274221
tensor(0.0122, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-3.3688e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.143391
Average KL loss: 0.131715
Average total loss: 0.275107
tensor(0.0123, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(8.6306e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.142397
Average KL loss: 0.131754
Average total loss: 0.274151
tensor(0.0122, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-3.6708e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.144210
Average KL loss: 0.131803
Average total loss: 0.276012
tensor(0.0122, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-7.8336e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.142980
Average KL loss: 0.131767
Average total loss: 0.274747
tensor(0.0123, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(3.5320e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.141770
Average KL loss: 0.131876
Average total loss: 0.273646
tensor(0.0123, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-1.9081e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.142940
Average KL loss: 0.131888
Average total loss: 0.274828
tensor(0.0123, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-2.7006e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.140992
Average KL loss: 0.131768
Average total loss: 0.272760
tensor(0.0123, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(1.4092e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.139856
Average KL loss: 0.131682
Average total loss: 0.271538
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.7018e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.142606
Average KL loss: 0.131773
Average total loss: 0.274379
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-2.3208e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.140944
Average KL loss: 0.131834
Average total loss: 0.272778
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.2018e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.141450
Average KL loss: 0.131834
Average total loss: 0.273284
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(1.3024e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.140727
Average KL loss: 0.131834
Average total loss: 0.272561
tensor(0.0122, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(2.6250e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.141096
Average KL loss: 0.131883
Average total loss: 0.272979
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(2.8501e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.140261
Average KL loss: 0.131969
Average total loss: 0.272230
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(6.4708e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.144393
Average KL loss: 0.132146
Average total loss: 0.276539
tensor(0.0123, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(5.9720e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.144407
Average KL loss: 0.132440
Average total loss: 0.276847
tensor(0.0123, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(1.8909e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.139503
Average KL loss: 0.132501
Average total loss: 0.272004
tensor(0.0123, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.7025e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.141225
Average KL loss: 0.132474
Average total loss: 0.273699
tensor(0.0123, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.4246e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.140272
Average KL loss: 0.132458
Average total loss: 0.272731
tensor(0.0123, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(5.3453e-11, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.139182
Average KL loss: 0.132289
Average total loss: 0.271470
tensor(0.0123, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(1.0332e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.140531
Average KL loss: 0.131752
Average total loss: 0.272283
tensor(0.0123, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-2.6380e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.141197
Average KL loss: 0.131308
Average total loss: 0.272505
tensor(0.0123, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-6.6488e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.138986
Average KL loss: 0.130945
Average total loss: 0.269931
tensor(0.0123, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(6.1748e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.139363
Average KL loss: 0.130599
Average total loss: 0.269963
tensor(0.0123, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(1.0596e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.139972
Average KL loss: 0.130279
Average total loss: 0.270251
tensor(0.0123, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-1.5853e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.137872
Average KL loss: 0.129976
Average total loss: 0.267848
tensor(0.0123, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-1.0518e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.138884
Average KL loss: 0.129679
Average total loss: 0.268563
tensor(0.0123, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-2.1102e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.138399
Average KL loss: 0.129409
Average total loss: 0.267808
tensor(0.0123, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-2.5194e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.140017
Average KL loss: 0.129169
Average total loss: 0.269186
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-1.4265e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.143174
Average KL loss: 0.128944
Average total loss: 0.272118
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-7.5818e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.139417
Average KL loss: 0.128735
Average total loss: 0.268152
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-4.0246e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.138593
Average KL loss: 0.128530
Average total loss: 0.267123
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-5.3791e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.138403
Average KL loss: 0.128325
Average total loss: 0.266728
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(4.9770e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.137586
Average KL loss: 0.128148
Average total loss: 0.265734
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(1.0494e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.139032
Average KL loss: 0.127951
Average total loss: 0.266984
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(1.6245e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.138123
Average KL loss: 0.127769
Average total loss: 0.265892
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(3.3722e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.140069
Average KL loss: 0.127605
Average total loss: 0.267674
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-4.0779e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.139067
Average KL loss: 0.127457
Average total loss: 0.266524
tensor(0.0123, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-1.9756e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.139467
Average KL loss: 0.127308
Average total loss: 0.266776
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-3.6800e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.139715
Average KL loss: 0.127159
Average total loss: 0.266875
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(5.6529e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.138187
Average KL loss: 0.127020
Average total loss: 0.265207
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(8.2155e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.137849
Average KL loss: 0.126878
Average total loss: 0.264727
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-2.9159e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.137219
Average KL loss: 0.126751
Average total loss: 0.263970
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(1.2460e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.136743
Average KL loss: 0.126624
Average total loss: 0.263367
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-1.4330e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.140269
Average KL loss: 0.126499
Average total loss: 0.266768
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(3.3973e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.138234
Average KL loss: 0.126360
Average total loss: 0.264594
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-2.8821e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.139523
Average KL loss: 0.126249
Average total loss: 0.265772
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-1.7812e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.136521
Average KL loss: 0.126149
Average total loss: 0.262670
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(1.1601e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.137824
Average KL loss: 0.126034
Average total loss: 0.263858
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(4.4299e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.136513
Average KL loss: 0.125907
Average total loss: 0.262420
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-6.7417e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.136450
Average KL loss: 0.125791
Average total loss: 0.262242
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-3.5992e-11, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.138625
Average KL loss: 0.125667
Average total loss: 0.264291
tensor(0.0123, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-3.8944e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.135069
Average KL loss: 0.125541
Average total loss: 0.260610
tensor(0.0122, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-7.6381e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.139922
Average KL loss: 0.125416
Average total loss: 0.265338
tensor(0.0122, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-7.6397e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.137662
Average KL loss: 0.125323
Average total loss: 0.262986
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(8.9338e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.138372
Average KL loss: 0.125243
Average total loss: 0.263616
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-7.0310e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.141058
Average KL loss: 0.125159
Average total loss: 0.266217
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(1.9389e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.139461
Average KL loss: 0.125068
Average total loss: 0.264529
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.2160e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.137696
Average KL loss: 0.124973
Average total loss: 0.262669
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.4835e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.138315
Average KL loss: 0.124887
Average total loss: 0.263202
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-3.6143e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.140677
Average KL loss: 0.124813
Average total loss: 0.265490
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(2.2551e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.137975
Average KL loss: 0.124731
Average total loss: 0.262705
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-4.5116e-11, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.139728
Average KL loss: 0.124650
Average total loss: 0.264378
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-5.9725e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.138090
Average KL loss: 0.124574
Average total loss: 0.262664
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(1.7331e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.137894
Average KL loss: 0.124531
Average total loss: 0.262425
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.5428e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.135093
Average KL loss: 0.124516
Average total loss: 0.259610
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-3.4192e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.140017
Average KL loss: 0.124503
Average total loss: 0.264519
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(2.0971e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.138363
Average KL loss: 0.124488
Average total loss: 0.262851
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.7776e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.137762
Average KL loss: 0.124475
Average total loss: 0.262236
tensor(0.0123, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(3.2003e-11, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.138095
Average KL loss: 0.124460
Average total loss: 0.262555
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-5.3513e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.135751
Average KL loss: 0.124445
Average total loss: 0.260195
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.7746e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.138553
Average KL loss: 0.124430
Average total loss: 0.262983
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-2.1724e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.136866
Average KL loss: 0.124416
Average total loss: 0.261282
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(1.1730e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.137628
Average KL loss: 0.124401
Average total loss: 0.262030
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.0393e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.139271
Average KL loss: 0.124389
Average total loss: 0.263660
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-8.8631e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.136789
Average KL loss: 0.124376
Average total loss: 0.261166
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-4.9816e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.140231
Average KL loss: 0.124362
Average total loss: 0.264593
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.3284e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.137434
Average KL loss: 0.124356
Average total loss: 0.261790
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.2335e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.138931
Average KL loss: 0.124355
Average total loss: 0.263285
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(1.8841e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.140566
Average KL loss: 0.124353
Average total loss: 0.264919
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-2.8111e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.138580
Average KL loss: 0.124352
Average total loss: 0.262932
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(3.2114e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.139542
Average KL loss: 0.124350
Average total loss: 0.263893
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.1926e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.138979
Average KL loss: 0.124349
Average total loss: 0.263329
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-8.4706e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.137415
Average KL loss: 0.124348
Average total loss: 0.261763
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(3.9457e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.139076
Average KL loss: 0.124347
Average total loss: 0.263422
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.4923e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.138674
Average KL loss: 0.124345
Average total loss: 0.263020
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-3.3643e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.139062
Average KL loss: 0.124344
Average total loss: 0.263406
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.6640e-09, device='cuda:0')
 Percentile value: 0.01690286211669445
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =     108 /    1728             (  6.25%) | total_pruned =    1620 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     407 /   36864             (  1.10%) | total_pruned =   36457 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1947 /   36864             (  5.28%) | total_pruned =   34917 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1301 /   36864             (  3.53%) | total_pruned =   35563 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1715 /   36864             (  4.65%) | total_pruned =   35149 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    9544 /   73728             ( 12.94%) | total_pruned =   64184 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   17394 /  147456             ( 11.80%) | total_pruned =  130062 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1439 /    8192             ( 17.57%) | total_pruned =    6753 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   17544 /  147456             ( 11.90%) | total_pruned =  129912 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   18687 /  147456             ( 12.67%) | total_pruned =  128769 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   44163 /  294912             ( 14.97%) | total_pruned =  250749 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     193 /     256             ( 75.39%) | total_pruned =      63 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   70789 /  589824             ( 12.00%) | total_pruned =  519035 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      84 /     256             ( 32.81%) | total_pruned =     172 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5896 /   32768             ( 17.99%) | total_pruned =   26872 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   66512 /  589824             ( 11.28%) | total_pruned =  523312 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   67736 /  589824             ( 11.48%) | total_pruned =  522088 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      54 /     256             ( 21.09%) | total_pruned =     202 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  159495 / 1179648             ( 13.52%) | total_pruned = 1020153 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     450 /     512             ( 87.89%) | total_pruned =      62 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      65 /     512             ( 12.70%) | total_pruned =     447 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  278664 / 2359296             ( 11.81%) | total_pruned = 2080632 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     463 /     512             ( 90.43%) | total_pruned =      49 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     167 /     512             ( 32.62%) | total_pruned =     345 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   10680 /  131072             (  8.15%) | total_pruned =  120392 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     310 /     512             ( 60.55%) | total_pruned =     202 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     166 /     512             ( 32.42%) | total_pruned =     346 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  198526 / 2359296             (  8.41%) | total_pruned = 2160770 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     369 /     512             ( 72.07%) | total_pruned =     143 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  415024 / 2359296             ( 17.59%) | total_pruned = 1944272 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     480 /     512             ( 93.75%) | total_pruned =      32 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     477 /     512             ( 93.16%) | total_pruned =      35 | shape = torch.Size([512])
linear.weight        | nonzeros =    4742 /    5120             ( 92.62%) | total_pruned =     378 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 51/100 Loss: 0.017856 Accuracy: 87.58 100.00 % Best test Accuracy: 87.77%
tensor(0.0122, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-3.5675e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.332818
Average KL loss: 0.114753
Average total loss: 0.447571
tensor(0.0123, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-1.9938e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.291230
Average KL loss: 0.113060
Average total loss: 0.404290
tensor(0.0121, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.4606e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.269871
Average KL loss: 0.113918
Average total loss: 0.383788
tensor(0.0119, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.6466e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.254571
Average KL loss: 0.114887
Average total loss: 0.369458
tensor(0.0118, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.6474e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.246241
Average KL loss: 0.115516
Average total loss: 0.361757
tensor(0.0117, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-6.8843e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.240253
Average KL loss: 0.116279
Average total loss: 0.356532
tensor(0.0116, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.0541e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.235025
Average KL loss: 0.117038
Average total loss: 0.352062
tensor(0.0116, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-9.8951e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.230276
Average KL loss: 0.118004
Average total loss: 0.348280
tensor(0.0116, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-9.9745e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.224583
Average KL loss: 0.118927
Average total loss: 0.343510
tensor(0.0116, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.0065e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.219332
Average KL loss: 0.120016
Average total loss: 0.339348
tensor(0.0116, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-8.6118e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.215003
Average KL loss: 0.120873
Average total loss: 0.335876
tensor(0.0116, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-9.0122e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.213346
Average KL loss: 0.121743
Average total loss: 0.335090
tensor(0.0116, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-5.7371e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.207201
Average KL loss: 0.122343
Average total loss: 0.329545
tensor(0.0116, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-5.0039e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.203539
Average KL loss: 0.123058
Average total loss: 0.326597
tensor(0.0116, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-9.3772e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.203492
Average KL loss: 0.123617
Average total loss: 0.327109
tensor(0.0116, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-5.8005e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.200717
Average KL loss: 0.124300
Average total loss: 0.325018
tensor(0.0116, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-2.9128e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.192605
Average KL loss: 0.124794
Average total loss: 0.317398
tensor(0.0116, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-8.3597e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.192870
Average KL loss: 0.125250
Average total loss: 0.318119
tensor(0.0116, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-5.9084e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.194267
Average KL loss: 0.125693
Average total loss: 0.319960
tensor(0.0116, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-1.1243e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.195058
Average KL loss: 0.126242
Average total loss: 0.321300
tensor(0.0116, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-4.5598e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.192737
Average KL loss: 0.126824
Average total loss: 0.319562
tensor(0.0116, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-5.8976e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.184579
Average KL loss: 0.127194
Average total loss: 0.311774
tensor(0.0116, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-5.6045e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.189433
Average KL loss: 0.127518
Average total loss: 0.316951
tensor(0.0117, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-5.8916e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.185175
Average KL loss: 0.128040
Average total loss: 0.313215
tensor(0.0117, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-4.4343e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.184221
Average KL loss: 0.128461
Average total loss: 0.312682
tensor(0.0117, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-6.5281e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.176991
Average KL loss: 0.128710
Average total loss: 0.305701
tensor(0.0117, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.1067e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.178869
Average KL loss: 0.128936
Average total loss: 0.307805
tensor(0.0117, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.1790e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.178243
Average KL loss: 0.129384
Average total loss: 0.307627
tensor(0.0117, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-3.8648e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.175293
Average KL loss: 0.129610
Average total loss: 0.304903
tensor(0.0117, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-2.7999e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.176658
Average KL loss: 0.129937
Average total loss: 0.306595
tensor(0.0117, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-5.3491e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.175908
Average KL loss: 0.130209
Average total loss: 0.306117
tensor(0.0117, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-2.5879e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.172050
Average KL loss: 0.130346
Average total loss: 0.302396
tensor(0.0117, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-2.9596e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.173132
Average KL loss: 0.130658
Average total loss: 0.303790
tensor(0.0117, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-5.5707e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.173408
Average KL loss: 0.131060
Average total loss: 0.304468
tensor(0.0117, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-4.0114e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.170505
Average KL loss: 0.131326
Average total loss: 0.301830
tensor(0.0117, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-5.8795e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.171695
Average KL loss: 0.131551
Average total loss: 0.303245
tensor(0.0117, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-2.0455e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.167979
Average KL loss: 0.131720
Average total loss: 0.299699
tensor(0.0117, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-4.8721e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.165700
Average KL loss: 0.131889
Average total loss: 0.297589
tensor(0.0117, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-2.8277e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.168162
Average KL loss: 0.132159
Average total loss: 0.300321
tensor(0.0117, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.0813e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.165362
Average KL loss: 0.132419
Average total loss: 0.297781
tensor(0.0117, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-2.7505e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.168066
Average KL loss: 0.132712
Average total loss: 0.300779
tensor(0.0118, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-6.2183e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.164416
Average KL loss: 0.132963
Average total loss: 0.297379
tensor(0.0117, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-3.3636e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.160119
Average KL loss: 0.132952
Average total loss: 0.293071
tensor(0.0117, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-2.0338e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.167998
Average KL loss: 0.133006
Average total loss: 0.301003
tensor(0.0117, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-5.4848e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.161178
Average KL loss: 0.133268
Average total loss: 0.294445
tensor(0.0118, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-3.8688e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.160989
Average KL loss: 0.133418
Average total loss: 0.294407
tensor(0.0118, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-3.5531e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.159816
Average KL loss: 0.133667
Average total loss: 0.293483
tensor(0.0118, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-9.3778e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.160020
Average KL loss: 0.133728
Average total loss: 0.293748
tensor(0.0118, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.2921e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.161960
Average KL loss: 0.133956
Average total loss: 0.295916
tensor(0.0118, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-7.9237e-11, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.160337
Average KL loss: 0.134176
Average total loss: 0.294513
tensor(0.0118, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-3.9685e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.160094
Average KL loss: 0.134344
Average total loss: 0.294437
tensor(0.0118, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-2.5200e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.158690
Average KL loss: 0.134320
Average total loss: 0.293010
tensor(0.0118, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.4051e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.158336
Average KL loss: 0.134425
Average total loss: 0.292761
tensor(0.0118, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-4.6986e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.158837
Average KL loss: 0.134613
Average total loss: 0.293449
tensor(0.0118, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.8771e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.157754
Average KL loss: 0.134738
Average total loss: 0.292492
tensor(0.0118, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-6.0837e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.157489
Average KL loss: 0.134973
Average total loss: 0.292462
tensor(0.0118, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.0854e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.157123
Average KL loss: 0.135080
Average total loss: 0.292203
tensor(0.0118, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-2.2133e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.155183
Average KL loss: 0.135052
Average total loss: 0.290235
tensor(0.0118, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-7.4602e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.155054
Average KL loss: 0.135199
Average total loss: 0.290253
tensor(0.0118, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-2.7819e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.154955
Average KL loss: 0.135209
Average total loss: 0.290164
tensor(0.0118, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.5262e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.154830
Average KL loss: 0.135279
Average total loss: 0.290109
tensor(0.0118, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-4.0001e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.152984
Average KL loss: 0.135564
Average total loss: 0.288547
tensor(0.0118, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.4470e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.152484
Average KL loss: 0.135544
Average total loss: 0.288028
tensor(0.0118, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-7.3074e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.152747
Average KL loss: 0.135714
Average total loss: 0.288461
tensor(0.0118, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.2631e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.154732
Average KL loss: 0.135772
Average total loss: 0.290504
tensor(0.0118, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.4200e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.152208
Average KL loss: 0.135954
Average total loss: 0.288161
tensor(0.0118, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(1.4508e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.152027
Average KL loss: 0.136107
Average total loss: 0.288135
tensor(0.0118, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-2.2717e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.150143
Average KL loss: 0.136214
Average total loss: 0.286357
tensor(0.0118, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.2468e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.153618
Average KL loss: 0.136332
Average total loss: 0.289950
tensor(0.0118, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-3.3296e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.150429
Average KL loss: 0.136287
Average total loss: 0.286717
tensor(0.0118, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(1.0325e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.151927
Average KL loss: 0.136395
Average total loss: 0.288321
tensor(0.0118, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-2.6155e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.151552
Average KL loss: 0.136528
Average total loss: 0.288080
tensor(0.0118, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-2.7275e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.153625
Average KL loss: 0.136730
Average total loss: 0.290354
tensor(0.0119, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(2.2118e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.151018
Average KL loss: 0.136884
Average total loss: 0.287903
tensor(0.0119, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(9.1690e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.153912
Average KL loss: 0.137075
Average total loss: 0.290987
tensor(0.0119, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-2.3281e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.148803
Average KL loss: 0.137225
Average total loss: 0.286028
tensor(0.0119, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-2.0111e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.151590
Average KL loss: 0.137331
Average total loss: 0.288921
tensor(0.0119, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-3.1025e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.146741
Average KL loss: 0.137447
Average total loss: 0.284187
tensor(0.0119, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-6.9947e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.148750
Average KL loss: 0.137540
Average total loss: 0.286290
tensor(0.0119, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-2.9587e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.149342
Average KL loss: 0.137571
Average total loss: 0.286913
tensor(0.0119, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(9.0910e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.148818
Average KL loss: 0.137599
Average total loss: 0.286417
tensor(0.0119, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(1.6423e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.146124
Average KL loss: 0.137588
Average total loss: 0.283712
tensor(0.0119, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-1.9780e-11, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.149991
Average KL loss: 0.137698
Average total loss: 0.287689
tensor(0.0119, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(1.4057e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.151351
Average KL loss: 0.137980
Average total loss: 0.289331
tensor(0.0119, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-8.7632e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.146575
Average KL loss: 0.138099
Average total loss: 0.284674
tensor(0.0119, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-2.3336e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.145396
Average KL loss: 0.138084
Average total loss: 0.283481
tensor(0.0119, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-6.7953e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.145239
Average KL loss: 0.137929
Average total loss: 0.283168
tensor(0.0119, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-1.4527e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.144196
Average KL loss: 0.137912
Average total loss: 0.282108
tensor(0.0119, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-3.3362e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.148850
Average KL loss: 0.137984
Average total loss: 0.286835
tensor(0.0119, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-5.2165e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.148875
Average KL loss: 0.138317
Average total loss: 0.287192
tensor(0.0119, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-3.3219e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.146682
Average KL loss: 0.138438
Average total loss: 0.285120
tensor(0.0119, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-2.8886e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.145423
Average KL loss: 0.138453
Average total loss: 0.283876
tensor(0.0119, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-7.8055e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.147730
Average KL loss: 0.138424
Average total loss: 0.286154
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.0083e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.148002
Average KL loss: 0.138785
Average total loss: 0.286787
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.4141e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.144126
Average KL loss: 0.138771
Average total loss: 0.282897
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(1.4092e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.145660
Average KL loss: 0.138790
Average total loss: 0.284450
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-5.2829e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.145182
Average KL loss: 0.138846
Average total loss: 0.284028
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(8.8446e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.143885
Average KL loss: 0.138834
Average total loss: 0.282720
tensor(0.0119, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-3.5193e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.144130
Average KL loss: 0.138858
Average total loss: 0.282988
tensor(0.0119, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-9.1329e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.142506
Average KL loss: 0.138721
Average total loss: 0.281228
tensor(0.0119, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(1.5583e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.145328
Average KL loss: 0.138399
Average total loss: 0.283727
tensor(0.0119, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(1.1751e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.145286
Average KL loss: 0.138126
Average total loss: 0.283412
tensor(0.0119, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.8704e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.142550
Average KL loss: 0.137876
Average total loss: 0.280426
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.9293e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.143340
Average KL loss: 0.137647
Average total loss: 0.280987
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-3.9664e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.142916
Average KL loss: 0.137446
Average total loss: 0.280362
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.6625e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.143277
Average KL loss: 0.137243
Average total loss: 0.280520
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(8.2237e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.143066
Average KL loss: 0.137064
Average total loss: 0.280129
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-3.7656e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.142265
Average KL loss: 0.136899
Average total loss: 0.279164
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(1.0694e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.141995
Average KL loss: 0.136728
Average total loss: 0.278722
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(1.5521e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.146381
Average KL loss: 0.136572
Average total loss: 0.282953
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-5.8108e-11, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.144591
Average KL loss: 0.136443
Average total loss: 0.281034
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(1.0572e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.144848
Average KL loss: 0.136303
Average total loss: 0.281151
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.3405e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.144498
Average KL loss: 0.136166
Average total loss: 0.280663
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-9.9736e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.144009
Average KL loss: 0.136039
Average total loss: 0.280048
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-3.5502e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.143386
Average KL loss: 0.135911
Average total loss: 0.279297
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(1.0463e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.141586
Average KL loss: 0.135787
Average total loss: 0.277373
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-3.0605e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.140932
Average KL loss: 0.135663
Average total loss: 0.276595
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-8.0191e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.145021
Average KL loss: 0.135540
Average total loss: 0.280561
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-7.6459e-12, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.143445
Average KL loss: 0.135428
Average total loss: 0.278873
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-3.0371e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.144312
Average KL loss: 0.135322
Average total loss: 0.279634
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.4460e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.144133
Average KL loss: 0.135221
Average total loss: 0.279354
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(1.3650e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.144317
Average KL loss: 0.135112
Average total loss: 0.279429
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.4247e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.143578
Average KL loss: 0.134998
Average total loss: 0.278576
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.0672e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.141415
Average KL loss: 0.134902
Average total loss: 0.276318
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-3.3627e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.141381
Average KL loss: 0.134809
Average total loss: 0.276190
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(8.4727e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.143011
Average KL loss: 0.134716
Average total loss: 0.277727
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.1218e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.142065
Average KL loss: 0.134613
Average total loss: 0.276679
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(1.1576e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.142239
Average KL loss: 0.134505
Average total loss: 0.276744
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.9310e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.143656
Average KL loss: 0.134405
Average total loss: 0.278062
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-5.7721e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.143363
Average KL loss: 0.134327
Average total loss: 0.277691
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-5.8282e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.143710
Average KL loss: 0.134258
Average total loss: 0.277968
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-4.2688e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.141137
Average KL loss: 0.134176
Average total loss: 0.275313
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.1040e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.143664
Average KL loss: 0.134092
Average total loss: 0.277756
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.1644e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.145089
Average KL loss: 0.134003
Average total loss: 0.279093
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.0234e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.142899
Average KL loss: 0.133934
Average total loss: 0.276833
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.8647e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.145002
Average KL loss: 0.133868
Average total loss: 0.278870
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-7.3399e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.142839
Average KL loss: 0.133810
Average total loss: 0.276648
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.7509e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.141120
Average KL loss: 0.133732
Average total loss: 0.274853
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-4.0848e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.141916
Average KL loss: 0.133651
Average total loss: 0.275567
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-4.2475e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.141990
Average KL loss: 0.133586
Average total loss: 0.275576
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.2234e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.144833
Average KL loss: 0.133522
Average total loss: 0.278354
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(5.5618e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.141372
Average KL loss: 0.133472
Average total loss: 0.274844
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-3.1886e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.142749
Average KL loss: 0.133421
Average total loss: 0.276170
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(2.6385e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.142896
Average KL loss: 0.133351
Average total loss: 0.276248
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-7.3773e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.142438
Average KL loss: 0.133289
Average total loss: 0.275727
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(1.2136e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.141914
Average KL loss: 0.133237
Average total loss: 0.275151
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.0352e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.140566
Average KL loss: 0.133175
Average total loss: 0.273741
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.2350e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.142710
Average KL loss: 0.133116
Average total loss: 0.275827
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.6309e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.140890
Average KL loss: 0.133046
Average total loss: 0.273935
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.2996e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.143470
Average KL loss: 0.132983
Average total loss: 0.276453
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-6.3840e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.139440
Average KL loss: 0.132927
Average total loss: 0.272367
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.0597e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.140164
Average KL loss: 0.132867
Average total loss: 0.273031
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-4.1048e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.144259
Average KL loss: 0.132808
Average total loss: 0.277067
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.9954e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.143417
Average KL loss: 0.132751
Average total loss: 0.276167
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.2526e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.141530
Average KL loss: 0.132706
Average total loss: 0.274236
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.9318e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.142017
Average KL loss: 0.132656
Average total loss: 0.274673
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.2089e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.141870
Average KL loss: 0.132601
Average total loss: 0.274472
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.0705e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.140418
Average KL loss: 0.132558
Average total loss: 0.272977
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.8984e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.140151
Average KL loss: 0.132516
Average total loss: 0.272666
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(2.6978e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.141330
Average KL loss: 0.132463
Average total loss: 0.273794
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.6741e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.140524
Average KL loss: 0.132421
Average total loss: 0.272944
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.4145e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.141581
Average KL loss: 0.132382
Average total loss: 0.273963
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-3.4623e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.140683
Average KL loss: 0.132349
Average total loss: 0.273033
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.0813e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.138809
Average KL loss: 0.132341
Average total loss: 0.271150
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-3.4241e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.142008
Average KL loss: 0.132331
Average total loss: 0.274339
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(5.4115e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.144165
Average KL loss: 0.132324
Average total loss: 0.276488
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.5770e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.139076
Average KL loss: 0.132315
Average total loss: 0.271392
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.5896e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.141533
Average KL loss: 0.132306
Average total loss: 0.273839
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-3.2129e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.142820
Average KL loss: 0.132297
Average total loss: 0.275117
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-3.6816e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.140653
Average KL loss: 0.132289
Average total loss: 0.272942
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.1917e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.144899
Average KL loss: 0.132282
Average total loss: 0.277180
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.4027e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.141735
Average KL loss: 0.132273
Average total loss: 0.274008
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.2551e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.142472
Average KL loss: 0.132265
Average total loss: 0.274737
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.2289e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.140966
Average KL loss: 0.132257
Average total loss: 0.273223
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.0184e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.142132
Average KL loss: 0.132249
Average total loss: 0.274381
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.9990e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.141830
Average KL loss: 0.132245
Average total loss: 0.274074
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-3.6382e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.140189
Average KL loss: 0.132244
Average total loss: 0.272433
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.7490e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.144439
Average KL loss: 0.132243
Average total loss: 0.276682
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.7761e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.140121
Average KL loss: 0.132242
Average total loss: 0.272363
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(2.2619e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.141919
Average KL loss: 0.132241
Average total loss: 0.274161
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.3214e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.142555
Average KL loss: 0.132241
Average total loss: 0.274796
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.9386e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.145136
Average KL loss: 0.132240
Average total loss: 0.277376
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.5874e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.139053
Average KL loss: 0.132239
Average total loss: 0.271292
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-9.8597e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.141611
Average KL loss: 0.132238
Average total loss: 0.273849
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.0230e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.140842
Average KL loss: 0.132238
Average total loss: 0.273079
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-4.1464e-09, device='cuda:0')
 Percentile value: 0.0487712025642395
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =      88 /    1728             (  5.09%) | total_pruned =    1640 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     217 /   36864             (  0.59%) | total_pruned =   36647 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1035 /   36864             (  2.81%) | total_pruned =   35829 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     678 /   36864             (  1.84%) | total_pruned =   36186 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     874 /   36864             (  2.37%) | total_pruned =   35990 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    5439 /   73728             (  7.38%) | total_pruned =   68289 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   10244 /  147456             (  6.95%) | total_pruned =  137212 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     878 /    8192             ( 10.72%) | total_pruned =    7314 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   10615 /  147456             (  7.20%) | total_pruned =  136841 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   10642 /  147456             (  7.22%) | total_pruned =  136814 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   27597 /  294912             (  9.36%) | total_pruned =  267315 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     184 /     256             ( 71.88%) | total_pruned =      72 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   39784 /  589824             (  6.75%) | total_pruned =  550040 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      67 /     256             ( 26.17%) | total_pruned =     189 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3482 /   32768             ( 10.63%) | total_pruned =   29286 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   34097 /  589824             (  5.78%) | total_pruned =  555727 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     200 /     256             ( 78.12%) | total_pruned =      56 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   32546 /  589824             (  5.52%) | total_pruned =  557278 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     179 /     256             ( 69.92%) | total_pruned =      77 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   88991 / 1179648             (  7.54%) | total_pruned = 1090657 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     433 /     512             ( 84.57%) | total_pruned =      79 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  119956 / 2359296             (  5.08%) | total_pruned = 2239340 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     418 /     512             ( 81.64%) | total_pruned =      94 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     156 /     512             ( 30.47%) | total_pruned =     356 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3965 /  131072             (  3.03%) | total_pruned =  127107 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     230 /     512             ( 44.92%) | total_pruned =     282 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     152 /     512             ( 29.69%) | total_pruned =     360 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   88838 / 2359296             (  3.77%) | total_pruned = 2270458 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     286 /     512             ( 55.86%) | total_pruned =     226 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  210046 / 2359296             (  8.90%) | total_pruned = 2149250 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     442 /     512             ( 86.33%) | total_pruned =      70 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     429 /     512             ( 83.79%) | total_pruned =      83 | shape = torch.Size([512])
linear.weight        | nonzeros =    4212 /    5120             ( 82.27%) | total_pruned =     908 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 51/100 Loss: 0.019808 Accuracy: 86.74 100.00 % Best test Accuracy: 86.83%
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.8727e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.314633
Average KL loss: 0.123339
Average total loss: 0.437972
tensor(0.0118, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-2.0729e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.282033
Average KL loss: 0.120629
Average total loss: 0.402662
tensor(0.0116, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-1.6368e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.271127
Average KL loss: 0.120696
Average total loss: 0.391823
tensor(0.0114, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.3166e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.259012
Average KL loss: 0.121125
Average total loss: 0.380137
tensor(0.0113, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-1.2765e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.250571
Average KL loss: 0.121601
Average total loss: 0.372172
tensor(0.0112, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-9.8434e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.241153
Average KL loss: 0.122373
Average total loss: 0.363526
tensor(0.0112, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-1.1106e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.235134
Average KL loss: 0.123125
Average total loss: 0.358259
tensor(0.0111, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-1.0319e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.232054
Average KL loss: 0.123699
Average total loss: 0.355753
tensor(0.0111, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-1.2147e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.226830
Average KL loss: 0.124600
Average total loss: 0.351429
tensor(0.0111, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-7.2557e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.223478
Average KL loss: 0.125416
Average total loss: 0.348893
tensor(0.0111, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-9.8648e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.215221
Average KL loss: 0.126213
Average total loss: 0.341434
tensor(0.0111, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-8.9062e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.213527
Average KL loss: 0.126989
Average total loss: 0.340516
tensor(0.0111, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-7.0746e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.214602
Average KL loss: 0.127678
Average total loss: 0.342280
tensor(0.0111, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-6.9422e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.209411
Average KL loss: 0.128236
Average total loss: 0.337648
tensor(0.0111, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-1.4618e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.207102
Average KL loss: 0.128859
Average total loss: 0.335961
tensor(0.0111, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-3.1118e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.201643
Average KL loss: 0.129404
Average total loss: 0.331047
tensor(0.0111, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-2.5871e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.200215
Average KL loss: 0.129847
Average total loss: 0.330062
tensor(0.0111, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-3.8125e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.199408
Average KL loss: 0.130482
Average total loss: 0.329890
tensor(0.0112, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-9.0600e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.193228
Average KL loss: 0.131044
Average total loss: 0.324272
tensor(0.0112, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-8.0729e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.196845
Average KL loss: 0.131463
Average total loss: 0.328308
tensor(0.0112, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-6.3253e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.193433
Average KL loss: 0.132058
Average total loss: 0.325490
tensor(0.0112, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-3.9427e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.188737
Average KL loss: 0.132387
Average total loss: 0.321123
tensor(0.0112, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-2.6591e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.187114
Average KL loss: 0.132779
Average total loss: 0.319893
tensor(0.0112, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-4.8752e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.190573
Average KL loss: 0.133344
Average total loss: 0.323917
tensor(0.0112, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-2.0816e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.182933
Average KL loss: 0.133669
Average total loss: 0.316602
tensor(0.0112, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-3.3105e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.186676
Average KL loss: 0.133967
Average total loss: 0.320642
tensor(0.0112, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-5.2706e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.181167
Average KL loss: 0.134467
Average total loss: 0.315634
tensor(0.0112, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-1.6620e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.181437
Average KL loss: 0.134806
Average total loss: 0.316244
tensor(0.0112, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-4.8525e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.176688
Average KL loss: 0.135127
Average total loss: 0.311815
tensor(0.0112, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-2.7042e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.176305
Average KL loss: 0.135390
Average total loss: 0.311695
tensor(0.0113, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-3.6303e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.177688
Average KL loss: 0.135633
Average total loss: 0.313321
tensor(0.0112, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-1.0696e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.177984
Average KL loss: 0.136020
Average total loss: 0.314004
tensor(0.0113, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-4.5623e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.173574
Average KL loss: 0.136352
Average total loss: 0.309926
tensor(0.0113, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-4.3423e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.173895
Average KL loss: 0.136655
Average total loss: 0.310550
tensor(0.0113, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-1.1789e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.175503
Average KL loss: 0.136941
Average total loss: 0.312444
tensor(0.0113, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-4.1055e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.170234
Average KL loss: 0.137197
Average total loss: 0.307430
tensor(0.0113, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-2.4695e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.167447
Average KL loss: 0.137426
Average total loss: 0.304873
tensor(0.0113, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-4.3983e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.175726
Average KL loss: 0.137666
Average total loss: 0.313392
tensor(0.0113, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-4.1388e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.173994
Average KL loss: 0.138111
Average total loss: 0.312105
tensor(0.0113, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(4.3399e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.164658
Average KL loss: 0.138378
Average total loss: 0.303037
tensor(0.0113, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-3.7509e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.170057
Average KL loss: 0.138634
Average total loss: 0.308691
tensor(0.0113, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.7012e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.166235
Average KL loss: 0.138920
Average total loss: 0.305155
tensor(0.0113, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.6212e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.165687
Average KL loss: 0.139096
Average total loss: 0.304783
tensor(0.0114, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.1017e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.166735
Average KL loss: 0.139346
Average total loss: 0.306081
tensor(0.0114, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-4.8662e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.163099
Average KL loss: 0.139584
Average total loss: 0.302683
tensor(0.0114, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-4.4271e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.164514
Average KL loss: 0.139882
Average total loss: 0.304396
tensor(0.0114, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-3.2920e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.160759
Average KL loss: 0.139959
Average total loss: 0.300718
tensor(0.0114, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.3480e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.163242
Average KL loss: 0.140203
Average total loss: 0.303445
tensor(0.0114, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-4.2935e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.159822
Average KL loss: 0.140364
Average total loss: 0.300186
tensor(0.0114, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-4.3816e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.163878
Average KL loss: 0.140575
Average total loss: 0.304453
tensor(0.0114, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-3.8087e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.159530
Average KL loss: 0.140863
Average total loss: 0.300394
tensor(0.0114, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-2.1955e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.158887
Average KL loss: 0.140977
Average total loss: 0.299864
tensor(0.0114, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-3.8933e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.157110
Average KL loss: 0.141114
Average total loss: 0.298224
tensor(0.0114, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-3.9918e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.159973
Average KL loss: 0.141280
Average total loss: 0.301254
tensor(0.0114, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(5.3953e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.160415
Average KL loss: 0.141516
Average total loss: 0.301931
tensor(0.0114, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-1.1974e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.158371
Average KL loss: 0.141680
Average total loss: 0.300051
tensor(0.0114, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.3743e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.154663
Average KL loss: 0.141809
Average total loss: 0.296471
tensor(0.0114, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-1.5916e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.157031
Average KL loss: 0.141872
Average total loss: 0.298904
tensor(0.0114, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-2.0045e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.159094
Average KL loss: 0.142186
Average total loss: 0.301280
tensor(0.0115, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-2.8483e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.154378
Average KL loss: 0.142395
Average total loss: 0.296772
tensor(0.0115, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-1.9413e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.155425
Average KL loss: 0.142517
Average total loss: 0.297943
tensor(0.0115, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-5.2071e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.152700
Average KL loss: 0.142683
Average total loss: 0.295383
tensor(0.0115, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-2.7363e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.155284
Average KL loss: 0.142742
Average total loss: 0.298027
tensor(0.0115, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-6.0176e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.154767
Average KL loss: 0.142920
Average total loss: 0.297687
tensor(0.0115, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-3.3516e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.157594
Average KL loss: 0.143105
Average total loss: 0.300699
tensor(0.0115, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-3.1329e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.152482
Average KL loss: 0.143188
Average total loss: 0.295670
tensor(0.0115, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-2.0610e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.152243
Average KL loss: 0.143223
Average total loss: 0.295466
tensor(0.0115, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-3.7758e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.151559
Average KL loss: 0.143354
Average total loss: 0.294913
tensor(0.0115, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(3.5622e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.151618
Average KL loss: 0.143427
Average total loss: 0.295046
tensor(0.0115, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-7.3078e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.151969
Average KL loss: 0.143542
Average total loss: 0.295511
tensor(0.0115, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.1914e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.151237
Average KL loss: 0.143792
Average total loss: 0.295029
tensor(0.0115, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-4.2169e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.149243
Average KL loss: 0.143942
Average total loss: 0.293185
tensor(0.0115, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.6870e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.149742
Average KL loss: 0.143982
Average total loss: 0.293724
tensor(0.0115, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.3838e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.149940
Average KL loss: 0.144179
Average total loss: 0.294119
tensor(0.0115, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-7.0258e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.150907
Average KL loss: 0.144278
Average total loss: 0.295185
tensor(0.0115, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(1.2489e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.148250
Average KL loss: 0.144332
Average total loss: 0.292582
tensor(0.0115, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-2.0181e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.150316
Average KL loss: 0.144407
Average total loss: 0.294723
tensor(0.0115, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-8.6207e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.148730
Average KL loss: 0.144593
Average total loss: 0.293323
tensor(0.0116, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.2590e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.148324
Average KL loss: 0.144754
Average total loss: 0.293078
tensor(0.0116, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.4627e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.146835
Average KL loss: 0.144886
Average total loss: 0.291721
tensor(0.0116, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.8203e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.147106
Average KL loss: 0.145009
Average total loss: 0.292115
tensor(0.0116, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.3480e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.146696
Average KL loss: 0.145044
Average total loss: 0.291740
tensor(0.0116, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-2.3395e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.146765
Average KL loss: 0.145180
Average total loss: 0.291945
tensor(0.0116, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.5825e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.146557
Average KL loss: 0.145277
Average total loss: 0.291833
tensor(0.0116, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.5695e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.145838
Average KL loss: 0.145249
Average total loss: 0.291088
tensor(0.0116, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(1.7652e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.144890
Average KL loss: 0.145385
Average total loss: 0.290276
tensor(0.0116, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.9576e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.146706
Average KL loss: 0.145423
Average total loss: 0.292129
tensor(0.0116, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-1.7786e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.144848
Average KL loss: 0.145482
Average total loss: 0.290329
tensor(0.0116, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(4.7616e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.150100
Average KL loss: 0.145716
Average total loss: 0.295816
tensor(0.0116, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(9.8018e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.145504
Average KL loss: 0.145813
Average total loss: 0.291317
tensor(0.0116, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(3.3941e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.148784
Average KL loss: 0.145804
Average total loss: 0.294588
tensor(0.0116, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-2.1790e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.145691
Average KL loss: 0.146033
Average total loss: 0.291724
tensor(0.0116, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-5.0339e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.144555
Average KL loss: 0.146143
Average total loss: 0.290698
tensor(0.0116, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-6.5363e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.147232
Average KL loss: 0.146162
Average total loss: 0.293394
tensor(0.0116, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.0470e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.142412
Average KL loss: 0.146285
Average total loss: 0.288697
tensor(0.0116, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-1.6714e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.143496
Average KL loss: 0.146300
Average total loss: 0.289796
tensor(0.0116, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-2.7104e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.142323
Average KL loss: 0.146282
Average total loss: 0.288606
tensor(0.0116, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-2.4336e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.142379
Average KL loss: 0.146397
Average total loss: 0.288775
tensor(0.0116, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.1714e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.141195
Average KL loss: 0.146417
Average total loss: 0.287611
tensor(0.0116, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.1885e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.141588
Average KL loss: 0.146440
Average total loss: 0.288028
tensor(0.0117, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.7503e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.143286
Average KL loss: 0.146572
Average total loss: 0.289859
tensor(0.0116, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.3625e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.141625
Average KL loss: 0.146626
Average total loss: 0.288251
tensor(0.0116, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-3.4288e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.142320
Average KL loss: 0.146667
Average total loss: 0.288987
tensor(0.0117, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-3.3403e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.140950
Average KL loss: 0.146696
Average total loss: 0.287646
tensor(0.0117, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-1.6907e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.142791
Average KL loss: 0.146705
Average total loss: 0.289496
tensor(0.0117, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-1.1712e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.142546
Average KL loss: 0.146774
Average total loss: 0.289320
tensor(0.0117, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(1.9770e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.141287
Average KL loss: 0.146949
Average total loss: 0.288237
tensor(0.0117, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-3.7658e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.141306
Average KL loss: 0.146902
Average total loss: 0.288208
tensor(0.0117, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(1.6199e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.140447
Average KL loss: 0.146895
Average total loss: 0.287343
tensor(0.0117, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-9.6324e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.141877
Average KL loss: 0.147124
Average total loss: 0.289000
tensor(0.0117, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(3.8604e-11, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.139987
Average KL loss: 0.147172
Average total loss: 0.287159
tensor(0.0117, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-2.7748e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.140682
Average KL loss: 0.147241
Average total loss: 0.287923
tensor(0.0117, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(1.6732e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.140588
Average KL loss: 0.147324
Average total loss: 0.287913
tensor(0.0117, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-8.7180e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.149158
Average KL loss: 0.147422
Average total loss: 0.296580
tensor(0.0117, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.9097e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.143533
Average KL loss: 0.147527
Average total loss: 0.291061
tensor(0.0117, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-1.6700e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.137365
Average KL loss: 0.147629
Average total loss: 0.284995
tensor(0.0117, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(1.7638e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.140725
Average KL loss: 0.147574
Average total loss: 0.288299
tensor(0.0117, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-4.8618e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.140440
Average KL loss: 0.147602
Average total loss: 0.288041
tensor(0.0117, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(4.0094e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.138159
Average KL loss: 0.147694
Average total loss: 0.285853
tensor(0.0117, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(3.0111e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.137362
Average KL loss: 0.147709
Average total loss: 0.285071
tensor(0.0117, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-2.5779e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.140565
Average KL loss: 0.147758
Average total loss: 0.288324
tensor(0.0117, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-1.4544e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.141875
Average KL loss: 0.147834
Average total loss: 0.289709
tensor(0.0117, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-6.8510e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.138042
Average KL loss: 0.147864
Average total loss: 0.285906
tensor(0.0117, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.7653e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.136798
Average KL loss: 0.147906
Average total loss: 0.284704
tensor(0.0117, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-6.8350e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.139246
Average KL loss: 0.148018
Average total loss: 0.287264
tensor(0.0117, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(5.8294e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.138644
Average KL loss: 0.148204
Average total loss: 0.286847
tensor(0.0118, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-7.9828e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.137399
Average KL loss: 0.148120
Average total loss: 0.285519
tensor(0.0118, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(1.6906e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.136447
Average KL loss: 0.148037
Average total loss: 0.284483
tensor(0.0118, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(8.1997e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.137299
Average KL loss: 0.148169
Average total loss: 0.285468
tensor(0.0118, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-1.6348e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.139324
Average KL loss: 0.148247
Average total loss: 0.287571
tensor(0.0118, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-4.8834e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.138580
Average KL loss: 0.148277
Average total loss: 0.286857
tensor(0.0118, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-2.7594e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.138221
Average KL loss: 0.148310
Average total loss: 0.286532
tensor(0.0118, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-2.7823e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.137236
Average KL loss: 0.148402
Average total loss: 0.285638
tensor(0.0118, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-1.0795e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.136918
Average KL loss: 0.148498
Average total loss: 0.285416
tensor(0.0118, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-5.3686e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.138211
Average KL loss: 0.148586
Average total loss: 0.286798
tensor(0.0118, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-3.5126e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.137070
Average KL loss: 0.148624
Average total loss: 0.285694
tensor(0.0118, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-3.7965e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.135056
Average KL loss: 0.148677
Average total loss: 0.283733
tensor(0.0118, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-7.7391e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.137041
Average KL loss: 0.148626
Average total loss: 0.285667
tensor(0.0118, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-3.3603e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.136160
Average KL loss: 0.148721
Average total loss: 0.284881
tensor(0.0118, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(4.6282e-11, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.136399
Average KL loss: 0.148697
Average total loss: 0.285095
tensor(0.0118, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.4100e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.137845
Average KL loss: 0.148796
Average total loss: 0.286641
tensor(0.0118, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.8680e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.135477
Average KL loss: 0.148828
Average total loss: 0.284305
tensor(0.0118, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.4043e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.137204
Average KL loss: 0.148906
Average total loss: 0.286110
tensor(0.0118, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(1.4496e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.136927
Average KL loss: 0.148914
Average total loss: 0.285841
tensor(0.0118, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(7.3272e-11, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.136718
Average KL loss: 0.149051
Average total loss: 0.285770
tensor(0.0118, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(7.9535e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.134883
Average KL loss: 0.148982
Average total loss: 0.283865
tensor(0.0118, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-1.5453e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.133729
Average KL loss: 0.148985
Average total loss: 0.282715
tensor(0.0118, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(1.5192e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.136692
Average KL loss: 0.149007
Average total loss: 0.285699
tensor(0.0118, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(8.8797e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.136647
Average KL loss: 0.149093
Average total loss: 0.285741
tensor(0.0118, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(1.4390e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.133872
Average KL loss: 0.149109
Average total loss: 0.282981
tensor(0.0118, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(1.0805e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.135102
Average KL loss: 0.148985
Average total loss: 0.284087
tensor(0.0118, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(7.2734e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.133669
Average KL loss: 0.148987
Average total loss: 0.282656
tensor(0.0119, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.8239e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.135913
Average KL loss: 0.149073
Average total loss: 0.284987
tensor(0.0118, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.3846e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.135699
Average KL loss: 0.149117
Average total loss: 0.284815
tensor(0.0119, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-9.7108e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.134516
Average KL loss: 0.149234
Average total loss: 0.283750
tensor(0.0119, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-2.0174e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.133849
Average KL loss: 0.149190
Average total loss: 0.283039
tensor(0.0119, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(2.5897e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.134578
Average KL loss: 0.149154
Average total loss: 0.283733
tensor(0.0119, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(1.5367e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.135610
Average KL loss: 0.149260
Average total loss: 0.284870
tensor(0.0119, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-7.8305e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.134461
Average KL loss: 0.149455
Average total loss: 0.283916
tensor(0.0119, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-3.2907e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.135154
Average KL loss: 0.149399
Average total loss: 0.284553
tensor(0.0119, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-2.7444e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.132470
Average KL loss: 0.149466
Average total loss: 0.281937
tensor(0.0119, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-9.6444e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.134583
Average KL loss: 0.149494
Average total loss: 0.284077
tensor(0.0119, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(2.4991e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.134484
Average KL loss: 0.149482
Average total loss: 0.283966
tensor(0.0119, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(3.8520e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.132265
Average KL loss: 0.149543
Average total loss: 0.281809
tensor(0.0119, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-3.9316e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.134000
Average KL loss: 0.149505
Average total loss: 0.283505
tensor(0.0119, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(6.0701e-11, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.134253
Average KL loss: 0.149561
Average total loss: 0.283814
tensor(0.0119, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-2.0191e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.135242
Average KL loss: 0.149658
Average total loss: 0.284899
tensor(0.0119, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.5208e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.134748
Average KL loss: 0.149675
Average total loss: 0.284423
tensor(0.0119, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-5.8035e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.133342
Average KL loss: 0.149773
Average total loss: 0.283114
tensor(0.0119, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.8489e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.134238
Average KL loss: 0.149800
Average total loss: 0.284038
tensor(0.0119, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-2.4967e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.134318
Average KL loss: 0.149884
Average total loss: 0.284202
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.4694e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.133733
Average KL loss: 0.149950
Average total loss: 0.283683
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(1.1820e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.133328
Average KL loss: 0.149908
Average total loss: 0.283236
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.6837e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.135378
Average KL loss: 0.149954
Average total loss: 0.285332
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.6270e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.132055
Average KL loss: 0.149970
Average total loss: 0.282025
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(7.3598e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.131732
Average KL loss: 0.149836
Average total loss: 0.281568
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.3809e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.132004
Average KL loss: 0.149644
Average total loss: 0.281648
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(6.4025e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.133070
Average KL loss: 0.149474
Average total loss: 0.282544
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-2.2205e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.135555
Average KL loss: 0.149327
Average total loss: 0.284882
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-5.0075e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.132322
Average KL loss: 0.149186
Average total loss: 0.281508
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(1.2893e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.134073
Average KL loss: 0.149064
Average total loss: 0.283138
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-2.6493e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.134949
Average KL loss: 0.148942
Average total loss: 0.283892
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.1049e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.134086
Average KL loss: 0.148820
Average total loss: 0.282907
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-3.4567e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.131589
Average KL loss: 0.148721
Average total loss: 0.280310
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(1.1280e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.131110
Average KL loss: 0.148615
Average total loss: 0.279725
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.9723e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.132080
Average KL loss: 0.148507
Average total loss: 0.280587
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-8.2402e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.130824
Average KL loss: 0.148401
Average total loss: 0.279225
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.0882e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.134399
Average KL loss: 0.148297
Average total loss: 0.282696
tensor(0.0119, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(1.0851e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.131439
Average KL loss: 0.148206
Average total loss: 0.279645
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(9.2568e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.136747
Average KL loss: 0.148110
Average total loss: 0.284857
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(1.3658e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.133483
Average KL loss: 0.148025
Average total loss: 0.281508
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(1.1756e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.133479
Average KL loss: 0.147940
Average total loss: 0.281419
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-2.4004e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.133009
Average KL loss: 0.147874
Average total loss: 0.280884
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(1.8018e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.132257
Average KL loss: 0.147806
Average total loss: 0.280063
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(5.0427e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.130535
Average KL loss: 0.147726
Average total loss: 0.278261
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.6253e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.131251
Average KL loss: 0.147634
Average total loss: 0.278886
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.3128e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.131657
Average KL loss: 0.147557
Average total loss: 0.279214
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(2.7291e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.131986
Average KL loss: 0.147476
Average total loss: 0.279462
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.2978e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.131419
Average KL loss: 0.147398
Average total loss: 0.278817
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-4.9691e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.134144
Average KL loss: 0.147326
Average total loss: 0.281470
 Percentile value: 0.12621694803237915
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =      87 /    1728             (  5.03%) | total_pruned =    1641 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     153 /   36864             (  0.42%) | total_pruned =   36711 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     496 /   36864             (  1.35%) | total_pruned =   36368 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     309 /   36864             (  0.84%) | total_pruned =   36555 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     441 /   36864             (  1.20%) | total_pruned =   36423 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2962 /   73728             (  4.02%) | total_pruned =   70766 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5928 /  147456             (  4.02%) | total_pruned =  141528 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     547 /    8192             (  6.68%) | total_pruned =    7645 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    6132 /  147456             (  4.16%) | total_pruned =  141324 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    5957 /  147456             (  4.04%) | total_pruned =  141499 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   17351 /  294912             (  5.88%) | total_pruned =  277561 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     179 /     256             ( 69.92%) | total_pruned =      77 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   23937 /  589824             (  4.06%) | total_pruned =  565887 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     166 /     256             ( 64.84%) | total_pruned =      90 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      58 /     256             ( 22.66%) | total_pruned =     198 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2115 /   32768             (  6.45%) | total_pruned =   30653 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     148 /     256             ( 57.81%) | total_pruned =     108 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      67 /     256             ( 26.17%) | total_pruned =     189 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   17992 /  589824             (  3.05%) | total_pruned =  571832 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   16092 /  589824             (  2.73%) | total_pruned =  573732 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     166 /     256             ( 64.84%) | total_pruned =      90 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   47925 / 1179648             (  4.06%) | total_pruned = 1131723 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     415 /     512             ( 81.05%) | total_pruned =      97 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   54003 / 2359296             (  2.29%) | total_pruned = 2305293 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     359 /     512             ( 70.12%) | total_pruned =     153 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     148 /     512             ( 28.91%) | total_pruned =     364 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1656 /  131072             (  1.26%) | total_pruned =  129416 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     159 /     512             ( 31.05%) | total_pruned =     353 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     145 /     512             ( 28.32%) | total_pruned =     367 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   41770 / 2359296             (  1.77%) | total_pruned = 2317526 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     228 /     512             ( 44.53%) | total_pruned =     284 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   96036 / 2359296             (  4.07%) | total_pruned = 2263260 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     365 /     512             ( 71.29%) | total_pruned =     147 | shape = torch.Size([512])
linear.weight        | nonzeros =    3524 /    5120             ( 68.83%) | total_pruned =    1596 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 60/100 Loss: 0.021917 Accuracy: 86.85 100.00 % Best test Accuracy: 87.13%
tensor(0.0119, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-2.1504e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.316196
Average KL loss: 0.138440
Average total loss: 0.454635
tensor(0.0116, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.4401e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.282487
Average KL loss: 0.134371
Average total loss: 0.416858
tensor(0.0114, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.2813e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.272221
Average KL loss: 0.133259
Average total loss: 0.405480
tensor(0.0112, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-1.3379e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.264384
Average KL loss: 0.132810
Average total loss: 0.397194
tensor(0.0111, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.5099e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.255245
Average KL loss: 0.132553
Average total loss: 0.387798
tensor(0.0110, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.6287e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.251928
Average KL loss: 0.132576
Average total loss: 0.384504
tensor(0.0109, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.2584e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.239219
Average KL loss: 0.132717
Average total loss: 0.371936
tensor(0.0109, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.2337e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.236584
Average KL loss: 0.133040
Average total loss: 0.369623
tensor(0.0108, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-9.6290e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.236089
Average KL loss: 0.133577
Average total loss: 0.369666
tensor(0.0108, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-6.8122e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.226205
Average KL loss: 0.134002
Average total loss: 0.360207
tensor(0.0108, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.1357e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.221542
Average KL loss: 0.134524
Average total loss: 0.356065
tensor(0.0108, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.1885e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.219186
Average KL loss: 0.134946
Average total loss: 0.354132
tensor(0.0108, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-9.8865e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.216092
Average KL loss: 0.135462
Average total loss: 0.351554
tensor(0.0108, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.0254e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.211534
Average KL loss: 0.135876
Average total loss: 0.347410
tensor(0.0108, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-6.6001e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.215591
Average KL loss: 0.136380
Average total loss: 0.351970
tensor(0.0108, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-3.3022e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.205357
Average KL loss: 0.136851
Average total loss: 0.342208
tensor(0.0108, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-7.9754e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.198594
Average KL loss: 0.137212
Average total loss: 0.335805
tensor(0.0108, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-6.7244e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.198749
Average KL loss: 0.137575
Average total loss: 0.336324
tensor(0.0108, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-6.1879e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.197196
Average KL loss: 0.137922
Average total loss: 0.335118
tensor(0.0108, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-4.0398e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.196488
Average KL loss: 0.138368
Average total loss: 0.334856
tensor(0.0108, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-6.4743e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.195056
Average KL loss: 0.138719
Average total loss: 0.333776
tensor(0.0108, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-6.8774e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.193185
Average KL loss: 0.139136
Average total loss: 0.332321
tensor(0.0108, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-5.0220e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.189907
Average KL loss: 0.139433
Average total loss: 0.329340
tensor(0.0108, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.1480e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.186998
Average KL loss: 0.139716
Average total loss: 0.326714
tensor(0.0108, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-2.3287e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.189697
Average KL loss: 0.140131
Average total loss: 0.329828
tensor(0.0108, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-6.6540e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.184629
Average KL loss: 0.140569
Average total loss: 0.325197
tensor(0.0108, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-5.6601e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.184055
Average KL loss: 0.140860
Average total loss: 0.324915
tensor(0.0108, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-8.2106e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.180435
Average KL loss: 0.141166
Average total loss: 0.321601
tensor(0.0108, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-4.5097e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.186691
Average KL loss: 0.141432
Average total loss: 0.328123
tensor(0.0108, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-1.0239e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.177406
Average KL loss: 0.141770
Average total loss: 0.319176
tensor(0.0109, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-2.9385e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.180276
Average KL loss: 0.142020
Average total loss: 0.322296
tensor(0.0109, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-2.5529e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.173566
Average KL loss: 0.142310
Average total loss: 0.315876
tensor(0.0109, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-5.5226e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.170457
Average KL loss: 0.142544
Average total loss: 0.313002
tensor(0.0109, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-2.1684e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.175929
Average KL loss: 0.142849
Average total loss: 0.318778
tensor(0.0109, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-3.9495e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.171115
Average KL loss: 0.143051
Average total loss: 0.314166
tensor(0.0109, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-3.8168e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.169563
Average KL loss: 0.143276
Average total loss: 0.312840
tensor(0.0109, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-6.0424e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.171688
Average KL loss: 0.143547
Average total loss: 0.315234
tensor(0.0109, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.4010e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.166808
Average KL loss: 0.143780
Average total loss: 0.310589
tensor(0.0109, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-4.2386e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.168911
Average KL loss: 0.143937
Average total loss: 0.312848
tensor(0.0109, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-3.9183e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.167551
Average KL loss: 0.144219
Average total loss: 0.311769
tensor(0.0109, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-4.9006e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.167181
Average KL loss: 0.144387
Average total loss: 0.311568
tensor(0.0109, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.0820e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.164682
Average KL loss: 0.144631
Average total loss: 0.309313
tensor(0.0109, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.7636e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.162570
Average KL loss: 0.144898
Average total loss: 0.307468
tensor(0.0109, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-6.8131e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.161351
Average KL loss: 0.145041
Average total loss: 0.306392
tensor(0.0109, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-4.6923e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.160252
Average KL loss: 0.145278
Average total loss: 0.305530
tensor(0.0109, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-7.5946e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.160124
Average KL loss: 0.145471
Average total loss: 0.305596
tensor(0.0110, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-3.5113e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.163007
Average KL loss: 0.145747
Average total loss: 0.308754
tensor(0.0110, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.9929e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.159148
Average KL loss: 0.145939
Average total loss: 0.305086
tensor(0.0110, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-6.8861e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.161900
Average KL loss: 0.146177
Average total loss: 0.308077
tensor(0.0110, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-4.3760e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.157335
Average KL loss: 0.146314
Average total loss: 0.303649
tensor(0.0110, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-2.5716e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.154644
Average KL loss: 0.146480
Average total loss: 0.301124
tensor(0.0110, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-6.8015e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.158921
Average KL loss: 0.146677
Average total loss: 0.305598
tensor(0.0110, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.4352e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.154712
Average KL loss: 0.146848
Average total loss: 0.301560
tensor(0.0110, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-2.1176e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.150987
Average KL loss: 0.147025
Average total loss: 0.298012
tensor(0.0110, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-3.3270e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.152705
Average KL loss: 0.147100
Average total loss: 0.299805
tensor(0.0110, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-2.4016e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.153541
Average KL loss: 0.147217
Average total loss: 0.300758
tensor(0.0110, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-4.0423e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.153288
Average KL loss: 0.147449
Average total loss: 0.300738
tensor(0.0110, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-2.8773e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.151673
Average KL loss: 0.147666
Average total loss: 0.299339
tensor(0.0110, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-2.8089e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.154433
Average KL loss: 0.147858
Average total loss: 0.302292
tensor(0.0110, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-3.3135e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.153152
Average KL loss: 0.148085
Average total loss: 0.301238
tensor(0.0111, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.3426e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.154547
Average KL loss: 0.148337
Average total loss: 0.302884
tensor(0.0111, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-7.7399e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.150810
Average KL loss: 0.148468
Average total loss: 0.299278
tensor(0.0111, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-6.5277e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.149797
Average KL loss: 0.148639
Average total loss: 0.298436
tensor(0.0111, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-3.8977e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.150425
Average KL loss: 0.148820
Average total loss: 0.299245
tensor(0.0111, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-4.4254e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.147117
Average KL loss: 0.149015
Average total loss: 0.296132
tensor(0.0111, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-6.8499e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.147747
Average KL loss: 0.149172
Average total loss: 0.296919
tensor(0.0111, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-2.8177e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.147979
Average KL loss: 0.149328
Average total loss: 0.297307
tensor(0.0111, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-1.3894e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.147986
Average KL loss: 0.149432
Average total loss: 0.297418
tensor(0.0111, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(9.5241e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.145079
Average KL loss: 0.149626
Average total loss: 0.294705
tensor(0.0111, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-9.3063e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.145538
Average KL loss: 0.149668
Average total loss: 0.295206
tensor(0.0111, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.3295e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.144213
Average KL loss: 0.149792
Average total loss: 0.294005
tensor(0.0111, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.9860e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.143254
Average KL loss: 0.149863
Average total loss: 0.293117
tensor(0.0111, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.2583e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.146200
Average KL loss: 0.150035
Average total loss: 0.296235
tensor(0.0111, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.2310e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.141807
Average KL loss: 0.150215
Average total loss: 0.292022
tensor(0.0111, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.5221e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.143672
Average KL loss: 0.150356
Average total loss: 0.294027
tensor(0.0112, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-3.0030e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.145142
Average KL loss: 0.150514
Average total loss: 0.295656
tensor(0.0111, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-2.9974e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.146541
Average KL loss: 0.150584
Average total loss: 0.297124
tensor(0.0112, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-5.9638e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.140898
Average KL loss: 0.150700
Average total loss: 0.291597
tensor(0.0112, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-3.2227e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.140403
Average KL loss: 0.150769
Average total loss: 0.291172
tensor(0.0112, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-2.3885e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.141642
Average KL loss: 0.150830
Average total loss: 0.292472
tensor(0.0112, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-8.7656e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.141581
Average KL loss: 0.150905
Average total loss: 0.292486
tensor(0.0112, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-1.1526e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.144035
Average KL loss: 0.151000
Average total loss: 0.295035
tensor(0.0112, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-3.0155e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.139921
Average KL loss: 0.151186
Average total loss: 0.291107
tensor(0.0112, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-1.0837e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.143179
Average KL loss: 0.151299
Average total loss: 0.294478
tensor(0.0112, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-3.0085e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.141832
Average KL loss: 0.151389
Average total loss: 0.293221
tensor(0.0112, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-2.6564e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.139473
Average KL loss: 0.151575
Average total loss: 0.291048
tensor(0.0112, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-2.2787e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.137942
Average KL loss: 0.151746
Average total loss: 0.289688
tensor(0.0112, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-1.7339e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.141960
Average KL loss: 0.151737
Average total loss: 0.293697
tensor(0.0112, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-1.5155e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.140615
Average KL loss: 0.151867
Average total loss: 0.292482
tensor(0.0112, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-1.7804e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.137355
Average KL loss: 0.151947
Average total loss: 0.289301
tensor(0.0112, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(2.8700e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.135500
Average KL loss: 0.151986
Average total loss: 0.287487
tensor(0.0112, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-5.0944e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.137357
Average KL loss: 0.151960
Average total loss: 0.289317
tensor(0.0112, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.5604e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.137084
Average KL loss: 0.152019
Average total loss: 0.289104
tensor(0.0112, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-4.6282e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.136639
Average KL loss: 0.152128
Average total loss: 0.288767
tensor(0.0112, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-4.7178e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.137158
Average KL loss: 0.152174
Average total loss: 0.289332
tensor(0.0112, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.4106e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.142983
Average KL loss: 0.152340
Average total loss: 0.295323
tensor(0.0113, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-3.6184e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.136093
Average KL loss: 0.152515
Average total loss: 0.288608
tensor(0.0113, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-2.5676e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.135288
Average KL loss: 0.152646
Average total loss: 0.287933
tensor(0.0113, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.7190e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.135971
Average KL loss: 0.152657
Average total loss: 0.288627
tensor(0.0113, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-2.7578e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.136345
Average KL loss: 0.152731
Average total loss: 0.289075
tensor(0.0113, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-2.3391e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.135332
Average KL loss: 0.152862
Average total loss: 0.288194
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.4133e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.136887
Average KL loss: 0.152906
Average total loss: 0.289793
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.9105e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.133685
Average KL loss: 0.152902
Average total loss: 0.286587
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.1185e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.137357
Average KL loss: 0.152807
Average total loss: 0.290165
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-9.1483e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.135549
Average KL loss: 0.152714
Average total loss: 0.288263
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(1.3879e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.133732
Average KL loss: 0.152639
Average total loss: 0.286370
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.2990e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.134865
Average KL loss: 0.152564
Average total loss: 0.287429
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(8.6402e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.135119
Average KL loss: 0.152491
Average total loss: 0.287611
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.8794e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.136413
Average KL loss: 0.152434
Average total loss: 0.288847
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(7.3494e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.134516
Average KL loss: 0.152370
Average total loss: 0.286886
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-5.7491e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.136195
Average KL loss: 0.152320
Average total loss: 0.288515
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.8395e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.134350
Average KL loss: 0.152261
Average total loss: 0.286612
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(1.9349e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.133478
Average KL loss: 0.152202
Average total loss: 0.285680
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(9.6904e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.133492
Average KL loss: 0.152146
Average total loss: 0.285638
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.2217e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.134252
Average KL loss: 0.152087
Average total loss: 0.286339
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(7.3179e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.132539
Average KL loss: 0.152046
Average total loss: 0.284585
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(1.3675e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.133340
Average KL loss: 0.152002
Average total loss: 0.285342
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.6086e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.134577
Average KL loss: 0.151941
Average total loss: 0.286518
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(2.5137e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.131099
Average KL loss: 0.151884
Average total loss: 0.282983
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.6704e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.131664
Average KL loss: 0.151829
Average total loss: 0.283493
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.3692e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.134505
Average KL loss: 0.151779
Average total loss: 0.286283
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-9.0534e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.132495
Average KL loss: 0.151724
Average total loss: 0.284219
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.7894e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.135407
Average KL loss: 0.151681
Average total loss: 0.287088
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.3847e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.134456
Average KL loss: 0.151638
Average total loss: 0.286094
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.5020e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.135120
Average KL loss: 0.151592
Average total loss: 0.286712
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.7248e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.133338
Average KL loss: 0.151561
Average total loss: 0.284899
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-8.7108e-11, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.131714
Average KL loss: 0.151531
Average total loss: 0.283245
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.7996e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.134050
Average KL loss: 0.151505
Average total loss: 0.285555
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.6356e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.132777
Average KL loss: 0.151478
Average total loss: 0.284255
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.2770e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.131566
Average KL loss: 0.151442
Average total loss: 0.283008
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-5.7818e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.132303
Average KL loss: 0.151416
Average total loss: 0.283719
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.0398e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.133914
Average KL loss: 0.151410
Average total loss: 0.285324
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.4671e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.133296
Average KL loss: 0.151405
Average total loss: 0.284701
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-4.2895e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.132753
Average KL loss: 0.151400
Average total loss: 0.284153
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.7097e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.131793
Average KL loss: 0.151395
Average total loss: 0.283188
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.3952e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.133119
Average KL loss: 0.151390
Average total loss: 0.284509
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.5333e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.133420
Average KL loss: 0.151385
Average total loss: 0.284804
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.6286e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.134337
Average KL loss: 0.151381
Average total loss: 0.285718
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.6158e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.132345
Average KL loss: 0.151377
Average total loss: 0.283722
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.9176e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.134711
Average KL loss: 0.151372
Average total loss: 0.286083
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.4094e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.131535
Average KL loss: 0.151367
Average total loss: 0.282902
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.1313e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.130745
Average KL loss: 0.151361
Average total loss: 0.282106
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.1548e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.135262
Average KL loss: 0.151356
Average total loss: 0.286618
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.0489e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.135040
Average KL loss: 0.151351
Average total loss: 0.286391
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-5.6151e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.133157
Average KL loss: 0.151347
Average total loss: 0.284504
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.8427e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.131899
Average KL loss: 0.151343
Average total loss: 0.283241
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.7946e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.132747
Average KL loss: 0.151338
Average total loss: 0.284086
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.0958e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.132711
Average KL loss: 0.151335
Average total loss: 0.284046
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(4.3064e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.133679
Average KL loss: 0.151331
Average total loss: 0.285010
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.3769e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.132145
Average KL loss: 0.151327
Average total loss: 0.283472
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(2.4476e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.133058
Average KL loss: 0.151322
Average total loss: 0.284380
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.5752e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.132751
Average KL loss: 0.151317
Average total loss: 0.284068
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.1765e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.130790
Average KL loss: 0.151312
Average total loss: 0.282103
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(1.6870e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.131305
Average KL loss: 0.151309
Average total loss: 0.282615
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(7.2108e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.137493
Average KL loss: 0.151309
Average total loss: 0.288802
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.9654e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.130297
Average KL loss: 0.151308
Average total loss: 0.281605
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(6.2101e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.135452
Average KL loss: 0.151308
Average total loss: 0.286760
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(1.5021e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.134982
Average KL loss: 0.151307
Average total loss: 0.286289
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.1927e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.132690
Average KL loss: 0.151307
Average total loss: 0.283997
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(1.5079e-11, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.131631
Average KL loss: 0.151306
Average total loss: 0.282937
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.1731e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.133260
Average KL loss: 0.151306
Average total loss: 0.284566
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.5818e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.132690
Average KL loss: 0.151305
Average total loss: 0.283995
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(1.1340e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.133672
Average KL loss: 0.151305
Average total loss: 0.284977
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-7.5286e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.133820
Average KL loss: 0.151304
Average total loss: 0.285124
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.8029e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.133312
Average KL loss: 0.151304
Average total loss: 0.284616
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.1989e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.132424
Average KL loss: 0.151303
Average total loss: 0.283727
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.1212e-09, device='cuda:0')
 Percentile value: 0.3145328164100647
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =      85 /    1728             (  4.92%) | total_pruned =    1643 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     115 /   36864             (  0.31%) | total_pruned =   36749 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     261 /   36864             (  0.71%) | total_pruned =   36603 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     203 /   36864             (  0.55%) | total_pruned =   36661 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     328 /   36864             (  0.89%) | total_pruned =   36536 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1743 /   73728             (  2.36%) | total_pruned =   71985 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3633 /  147456             (  2.46%) | total_pruned =  143823 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     330 /    8192             (  4.03%) | total_pruned =    7862 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3829 /  147456             (  2.60%) | total_pruned =  143627 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3785 /  147456             (  2.57%) | total_pruned =  143671 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   10729 /  294912             (  3.64%) | total_pruned =  284183 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   14489 /  589824             (  2.46%) | total_pruned =  575335 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     151 /     256             ( 58.98%) | total_pruned =     105 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1287 /   32768             (  3.93%) | total_pruned =   31481 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    9909 /  589824             (  1.68%) | total_pruned =  579915 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     179 /     256             ( 69.92%) | total_pruned =      77 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    8550 /  589824             (  1.45%) | total_pruned =  581274 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     152 /     256             ( 59.38%) | total_pruned =     104 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   25450 / 1179648             (  2.16%) | total_pruned = 1154198 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     400 /     512             ( 78.12%) | total_pruned =     112 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      36 /     512             (  7.03%) | total_pruned =     476 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   24967 / 2359296             (  1.06%) | total_pruned = 2334329 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     300 /     512             ( 58.59%) | total_pruned =     212 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     133 /     512             ( 25.98%) | total_pruned =     379 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     625 /  131072             (  0.48%) | total_pruned =  130447 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     129 /     512             ( 25.20%) | total_pruned =     383 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   18851 / 2359296             (  0.80%) | total_pruned = 2340445 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     194 /     512             ( 37.89%) | total_pruned =     318 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   39318 / 2359296             (  1.67%) | total_pruned = 2319978 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     314 /     512             ( 61.33%) | total_pruned =     198 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     297 /     512             ( 58.01%) | total_pruned =     215 | shape = torch.Size([512])
linear.weight        | nonzeros =    2742 /    5120             ( 53.55%) | total_pruned =    2378 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 53/100 Loss: 0.022804 Accuracy: 85.83 100.00 % Best test Accuracy: 86.63%
tensor(0.0113, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.5449e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.320819
Average KL loss: 0.142627
Average total loss: 0.463446
tensor(0.0106, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-1.7242e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.297433
Average KL loss: 0.136945
Average total loss: 0.434379
tensor(0.0103, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-1.3316e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.284646
Average KL loss: 0.134580
Average total loss: 0.419226
tensor(0.0101, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.2524e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.277578
Average KL loss: 0.133117
Average total loss: 0.410695
tensor(0.0100, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.2918e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.264359
Average KL loss: 0.132216
Average total loss: 0.396575
tensor(0.0099, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.1172e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.261552
Average KL loss: 0.131612
Average total loss: 0.393164
tensor(0.0098, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-1.4215e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.261533
Average KL loss: 0.131495
Average total loss: 0.393029
tensor(0.0098, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-1.0557e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.261602
Average KL loss: 0.131673
Average total loss: 0.393275
tensor(0.0097, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-1.0958e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.245583
Average KL loss: 0.132028
Average total loss: 0.377611
tensor(0.0097, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-9.4807e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.237491
Average KL loss: 0.132498
Average total loss: 0.369988
tensor(0.0097, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.3458e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.238803
Average KL loss: 0.132970
Average total loss: 0.371773
tensor(0.0097, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.0165e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.233485
Average KL loss: 0.133352
Average total loss: 0.366837
tensor(0.0097, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.4311e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.237785
Average KL loss: 0.133787
Average total loss: 0.371572
tensor(0.0097, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-8.0616e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.234129
Average KL loss: 0.134207
Average total loss: 0.368335
tensor(0.0097, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-5.3985e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.222150
Average KL loss: 0.134633
Average total loss: 0.356783
tensor(0.0097, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.0467e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.219821
Average KL loss: 0.135034
Average total loss: 0.354855
tensor(0.0097, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-5.4488e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.213822
Average KL loss: 0.135447
Average total loss: 0.349269
tensor(0.0098, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-9.5648e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.211127
Average KL loss: 0.135889
Average total loss: 0.347016
tensor(0.0098, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.1865e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.215806
Average KL loss: 0.136249
Average total loss: 0.352055
tensor(0.0098, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-7.0799e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.207139
Average KL loss: 0.136584
Average total loss: 0.343724
tensor(0.0098, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-8.3588e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.200707
Average KL loss: 0.136919
Average total loss: 0.337625
tensor(0.0098, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-2.9929e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.204186
Average KL loss: 0.137299
Average total loss: 0.341485
tensor(0.0098, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-8.4344e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.205767
Average KL loss: 0.137658
Average total loss: 0.343425
tensor(0.0098, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-7.4053e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.195460
Average KL loss: 0.138026
Average total loss: 0.333486
tensor(0.0098, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-8.2937e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.193691
Average KL loss: 0.138282
Average total loss: 0.331973
tensor(0.0098, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-8.7411e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.193768
Average KL loss: 0.138601
Average total loss: 0.332369
tensor(0.0098, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-6.2172e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.193649
Average KL loss: 0.138993
Average total loss: 0.332642
tensor(0.0098, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-7.8540e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.189562
Average KL loss: 0.139357
Average total loss: 0.328919
tensor(0.0099, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-4.1092e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.191217
Average KL loss: 0.139681
Average total loss: 0.330898
tensor(0.0099, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-7.4933e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.184487
Average KL loss: 0.140034
Average total loss: 0.324520
tensor(0.0099, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-5.9743e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.186736
Average KL loss: 0.140354
Average total loss: 0.327089
tensor(0.0099, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-5.7132e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.187040
Average KL loss: 0.140673
Average total loss: 0.327713
tensor(0.0099, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-4.9304e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.181643
Average KL loss: 0.140916
Average total loss: 0.322558
tensor(0.0099, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-4.7076e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.177648
Average KL loss: 0.141220
Average total loss: 0.318868
tensor(0.0099, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-5.9147e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.177985
Average KL loss: 0.141551
Average total loss: 0.319536
tensor(0.0099, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-8.4877e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.175374
Average KL loss: 0.141838
Average total loss: 0.317212
tensor(0.0099, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-4.1675e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.174272
Average KL loss: 0.142119
Average total loss: 0.316391
tensor(0.0100, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-3.0748e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.176038
Average KL loss: 0.142403
Average total loss: 0.318441
tensor(0.0100, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-4.3694e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.171795
Average KL loss: 0.142703
Average total loss: 0.314498
tensor(0.0100, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.8199e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.171364
Average KL loss: 0.142916
Average total loss: 0.314280
tensor(0.0100, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-3.5118e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.168290
Average KL loss: 0.143196
Average total loss: 0.311486
tensor(0.0100, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-3.9177e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.168988
Average KL loss: 0.143483
Average total loss: 0.312471
tensor(0.0100, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-4.0190e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.168887
Average KL loss: 0.143782
Average total loss: 0.312669
tensor(0.0100, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-5.4460e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.167725
Average KL loss: 0.144050
Average total loss: 0.311775
tensor(0.0100, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-2.3491e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.165974
Average KL loss: 0.144280
Average total loss: 0.310254
tensor(0.0100, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-5.7561e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.164957
Average KL loss: 0.144531
Average total loss: 0.309487
tensor(0.0100, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.5899e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.165218
Average KL loss: 0.144753
Average total loss: 0.309971
tensor(0.0101, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-7.3052e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.165109
Average KL loss: 0.145012
Average total loss: 0.310121
tensor(0.0101, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-2.3495e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.165742
Average KL loss: 0.145262
Average total loss: 0.311004
tensor(0.0101, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.7945e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.164102
Average KL loss: 0.145574
Average total loss: 0.309676
tensor(0.0101, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-1.1710e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.157547
Average KL loss: 0.145844
Average total loss: 0.303392
tensor(0.0101, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-5.2753e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.160170
Average KL loss: 0.146065
Average total loss: 0.306234
tensor(0.0101, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.9688e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.157875
Average KL loss: 0.146283
Average total loss: 0.304158
tensor(0.0101, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-4.4801e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.155089
Average KL loss: 0.146506
Average total loss: 0.301595
tensor(0.0101, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-4.8065e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.156724
Average KL loss: 0.146684
Average total loss: 0.303407
tensor(0.0102, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-4.4215e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.154068
Average KL loss: 0.146926
Average total loss: 0.300994
tensor(0.0102, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-6.3131e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.154692
Average KL loss: 0.147137
Average total loss: 0.301828
tensor(0.0102, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-5.1518e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.149987
Average KL loss: 0.147365
Average total loss: 0.297353
tensor(0.0102, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-3.6615e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.155821
Average KL loss: 0.147637
Average total loss: 0.303458
tensor(0.0102, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-5.3271e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.149737
Average KL loss: 0.147810
Average total loss: 0.297547
tensor(0.0102, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-8.6809e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.154688
Average KL loss: 0.148036
Average total loss: 0.302724
tensor(0.0102, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.8462e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.149153
Average KL loss: 0.148231
Average total loss: 0.297384
tensor(0.0102, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(6.4601e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.147215
Average KL loss: 0.148405
Average total loss: 0.295620
tensor(0.0102, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.1916e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.147834
Average KL loss: 0.148602
Average total loss: 0.296436
tensor(0.0103, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-4.4521e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.147236
Average KL loss: 0.148776
Average total loss: 0.296012
tensor(0.0103, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(9.5203e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.147540
Average KL loss: 0.148915
Average total loss: 0.296456
tensor(0.0103, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-2.6303e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.144043
Average KL loss: 0.149121
Average total loss: 0.293163
tensor(0.0103, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-3.3947e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.144876
Average KL loss: 0.149294
Average total loss: 0.294170
tensor(0.0103, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-5.4197e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.149083
Average KL loss: 0.149401
Average total loss: 0.298484
tensor(0.0103, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(8.6114e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.147647
Average KL loss: 0.149718
Average total loss: 0.297365
tensor(0.0103, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-9.2746e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.143302
Average KL loss: 0.149975
Average total loss: 0.293278
tensor(0.0103, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-3.5136e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.144872
Average KL loss: 0.150131
Average total loss: 0.295002
tensor(0.0103, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-1.4054e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.141891
Average KL loss: 0.150317
Average total loss: 0.292207
tensor(0.0104, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-1.9933e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.148542
Average KL loss: 0.150521
Average total loss: 0.299063
tensor(0.0104, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-2.7151e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.137901
Average KL loss: 0.150711
Average total loss: 0.288612
tensor(0.0104, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-3.8883e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.138870
Average KL loss: 0.150785
Average total loss: 0.289655
tensor(0.0104, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-2.9280e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.141445
Average KL loss: 0.150925
Average total loss: 0.292370
tensor(0.0104, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-3.4427e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.141999
Average KL loss: 0.151067
Average total loss: 0.293066
tensor(0.0104, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-4.0969e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.139462
Average KL loss: 0.151292
Average total loss: 0.290754
tensor(0.0104, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-5.1772e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.139136
Average KL loss: 0.151466
Average total loss: 0.290601
tensor(0.0104, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-2.2229e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.140236
Average KL loss: 0.151603
Average total loss: 0.291839
tensor(0.0104, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-3.4972e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.137237
Average KL loss: 0.151722
Average total loss: 0.288959
tensor(0.0104, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-2.6478e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.135786
Average KL loss: 0.151885
Average total loss: 0.287671
tensor(0.0104, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-9.7778e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.138402
Average KL loss: 0.152051
Average total loss: 0.290453
tensor(0.0105, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.7904e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.134929
Average KL loss: 0.152229
Average total loss: 0.287157
tensor(0.0105, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-3.1799e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.136317
Average KL loss: 0.152341
Average total loss: 0.288657
tensor(0.0105, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-3.1257e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.132941
Average KL loss: 0.152479
Average total loss: 0.285421
tensor(0.0105, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-1.4935e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.136054
Average KL loss: 0.152643
Average total loss: 0.288697
tensor(0.0105, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-2.2986e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.133436
Average KL loss: 0.152816
Average total loss: 0.286252
tensor(0.0105, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-2.9927e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.132600
Average KL loss: 0.152895
Average total loss: 0.285495
tensor(0.0105, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-4.2712e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.132397
Average KL loss: 0.152973
Average total loss: 0.285370
tensor(0.0105, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-2.3717e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.132844
Average KL loss: 0.153153
Average total loss: 0.285997
tensor(0.0105, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.4977e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.134542
Average KL loss: 0.153239
Average total loss: 0.287781
tensor(0.0105, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-2.0456e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.131998
Average KL loss: 0.153367
Average total loss: 0.285365
tensor(0.0105, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.8170e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.130990
Average KL loss: 0.153441
Average total loss: 0.284431
tensor(0.0105, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.6236e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.131851
Average KL loss: 0.153585
Average total loss: 0.285436
tensor(0.0106, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-2.0369e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.134955
Average KL loss: 0.153736
Average total loss: 0.288691
tensor(0.0106, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-1.4534e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.130581
Average KL loss: 0.153845
Average total loss: 0.284426
tensor(0.0106, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-2.1402e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.131431
Average KL loss: 0.154014
Average total loss: 0.285446
tensor(0.0106, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(2.7635e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.129037
Average KL loss: 0.154167
Average total loss: 0.283205
tensor(0.0106, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-3.2602e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.128020
Average KL loss: 0.154269
Average total loss: 0.282289
tensor(0.0106, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-3.7374e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.130860
Average KL loss: 0.154409
Average total loss: 0.285268
tensor(0.0106, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-1.8068e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.126362
Average KL loss: 0.154587
Average total loss: 0.280948
tensor(0.0106, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-2.6733e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.129780
Average KL loss: 0.154698
Average total loss: 0.284478
tensor(0.0106, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.5027e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.129084
Average KL loss: 0.154851
Average total loss: 0.283935
tensor(0.0106, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-1.9780e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.125722
Average KL loss: 0.154983
Average total loss: 0.280704
tensor(0.0106, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-2.1999e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.127628
Average KL loss: 0.155118
Average total loss: 0.282746
tensor(0.0107, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-3.4062e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.127657
Average KL loss: 0.155210
Average total loss: 0.282867
tensor(0.0107, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(8.9320e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.125636
Average KL loss: 0.155241
Average total loss: 0.280877
tensor(0.0107, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-1.6276e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.125890
Average KL loss: 0.155364
Average total loss: 0.281254
tensor(0.0107, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.3972e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.126272
Average KL loss: 0.155445
Average total loss: 0.281717
tensor(0.0107, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-5.3413e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.128340
Average KL loss: 0.155605
Average total loss: 0.283945
tensor(0.0107, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-2.1815e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.122610
Average KL loss: 0.155652
Average total loss: 0.278262
tensor(0.0107, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-1.8136e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.124949
Average KL loss: 0.155773
Average total loss: 0.280722
tensor(0.0107, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-3.0278e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.127734
Average KL loss: 0.155873
Average total loss: 0.283607
tensor(0.0107, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-2.7803e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.123497
Average KL loss: 0.155988
Average total loss: 0.279485
tensor(0.0107, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-5.7783e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.122390
Average KL loss: 0.156061
Average total loss: 0.278451
tensor(0.0107, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-3.0735e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.127699
Average KL loss: 0.156132
Average total loss: 0.283831
tensor(0.0107, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(9.6108e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.125739
Average KL loss: 0.156249
Average total loss: 0.281988
tensor(0.0107, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-4.0851e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.123393
Average KL loss: 0.156336
Average total loss: 0.279729
tensor(0.0107, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-2.7320e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.122884
Average KL loss: 0.156357
Average total loss: 0.279241
tensor(0.0108, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(9.3698e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.122116
Average KL loss: 0.156424
Average total loss: 0.278541
tensor(0.0108, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-3.0854e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.123680
Average KL loss: 0.156564
Average total loss: 0.280243
tensor(0.0108, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.9772e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.123063
Average KL loss: 0.156664
Average total loss: 0.279728
tensor(0.0108, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.2907e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.123915
Average KL loss: 0.156715
Average total loss: 0.280630
tensor(0.0108, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.0170e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.121278
Average KL loss: 0.156685
Average total loss: 0.277963
tensor(0.0108, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-3.3436e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.121239
Average KL loss: 0.156656
Average total loss: 0.277895
tensor(0.0108, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.2181e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.120258
Average KL loss: 0.156631
Average total loss: 0.276889
tensor(0.0108, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-3.2054e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.120504
Average KL loss: 0.156598
Average total loss: 0.277102
tensor(0.0108, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.4620e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.122252
Average KL loss: 0.156568
Average total loss: 0.278820
tensor(0.0108, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.1714e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.117013
Average KL loss: 0.156542
Average total loss: 0.273555
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-5.3460e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.120036
Average KL loss: 0.156516
Average total loss: 0.276552
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-9.1165e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.119283
Average KL loss: 0.156491
Average total loss: 0.275775
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-9.9460e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.120114
Average KL loss: 0.156466
Average total loss: 0.276579
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-9.9480e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.123065
Average KL loss: 0.156451
Average total loss: 0.279517
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.7071e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.119718
Average KL loss: 0.156431
Average total loss: 0.276149
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(1.2310e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.122485
Average KL loss: 0.156408
Average total loss: 0.278894
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.5610e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.122172
Average KL loss: 0.156389
Average total loss: 0.278561
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-3.7872e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.119766
Average KL loss: 0.156367
Average total loss: 0.276133
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.2356e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.120347
Average KL loss: 0.156344
Average total loss: 0.276691
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.0234e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.121091
Average KL loss: 0.156323
Average total loss: 0.277414
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.3144e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.118861
Average KL loss: 0.156309
Average total loss: 0.275170
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(3.4819e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.119581
Average KL loss: 0.156300
Average total loss: 0.275882
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.1254e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.120997
Average KL loss: 0.156297
Average total loss: 0.277294
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-2.9037e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.120881
Average KL loss: 0.156295
Average total loss: 0.277177
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.3990e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.121673
Average KL loss: 0.156293
Average total loss: 0.277966
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-2.3628e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.120100
Average KL loss: 0.156291
Average total loss: 0.276392
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(3.2427e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.120224
Average KL loss: 0.156289
Average total loss: 0.276513
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-3.0153e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.121374
Average KL loss: 0.156286
Average total loss: 0.277660
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(1.0425e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.121739
Average KL loss: 0.156283
Average total loss: 0.278022
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(4.8889e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.122393
Average KL loss: 0.156281
Average total loss: 0.278674
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(7.9633e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.120664
Average KL loss: 0.156279
Average total loss: 0.276943
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(5.5186e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.121010
Average KL loss: 0.156277
Average total loss: 0.277288
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-6.9709e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.119630
Average KL loss: 0.156276
Average total loss: 0.275906
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.9526e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.122232
Average KL loss: 0.156276
Average total loss: 0.278508
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.5844e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.120366
Average KL loss: 0.156276
Average total loss: 0.276642
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-7.9080e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.119601
Average KL loss: 0.156276
Average total loss: 0.275877
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-6.8389e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.120417
Average KL loss: 0.156276
Average total loss: 0.276692
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.1085e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.121996
Average KL loss: 0.156275
Average total loss: 0.278271
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.9732e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.121160
Average KL loss: 0.156275
Average total loss: 0.277435
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-2.3522e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.119710
Average KL loss: 0.156275
Average total loss: 0.275985
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-8.9521e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.120224
Average KL loss: 0.156275
Average total loss: 0.276499
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-3.6003e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.121321
Average KL loss: 0.156275
Average total loss: 0.277595
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.7537e-09, device='cuda:0')
 Percentile value: 0.7653015851974487
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =      83 /    1728             (  4.80%) | total_pruned =    1645 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      83 /   36864             (  0.23%) | total_pruned =   36781 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     140 /   36864             (  0.38%) | total_pruned =   36724 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     145 /   36864             (  0.39%) | total_pruned =   36719 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     229 /   36864             (  0.62%) | total_pruned =   36635 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     982 /   73728             (  1.33%) | total_pruned =   72746 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2332 /  147456             (  1.58%) | total_pruned =  145124 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     204 /    8192             (  2.49%) | total_pruned =    7988 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2472 /  147456             (  1.68%) | total_pruned =  144984 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2489 /  147456             (  1.69%) | total_pruned =  144967 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6624 /  294912             (  2.25%) | total_pruned =  288288 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    8664 /  589824             (  1.47%) | total_pruned =  581160 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     133 /     256             ( 51.95%) | total_pruned =     123 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     758 /   32768             (  2.31%) | total_pruned =   32010 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      50 /     256             ( 19.53%) | total_pruned =     206 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    5488 /  589824             (  0.93%) | total_pruned =  584336 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4603 /  589824             (  0.78%) | total_pruned =  585221 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     128 /     256             ( 50.00%) | total_pruned =     128 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12406 / 1179648             (  1.05%) | total_pruned = 1167242 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     369 /     512             ( 72.07%) | total_pruned =     143 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      31 /     512             (  6.05%) | total_pruned =     481 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   10941 / 2359296             (  0.46%) | total_pruned = 2348355 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     237 /     512             ( 46.29%) | total_pruned =     275 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     203 /  131072             (  0.15%) | total_pruned =  130869 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      51 /     512             (  9.96%) | total_pruned =     461 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    8171 / 2359296             (  0.35%) | total_pruned = 2351125 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     143 /     512             ( 27.93%) | total_pruned =     369 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   15311 / 2359296             (  0.65%) | total_pruned = 2343985 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     261 /     512             ( 50.98%) | total_pruned =     251 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     244 /     512             ( 47.66%) | total_pruned =     268 | shape = torch.Size([512])
linear.weight        | nonzeros =    2093 /    5120             ( 40.88%) | total_pruned =    3027 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 52/100 Loss: 0.045535 Accuracy: 85.40 99.99 % Best test Accuracy: 85.98%
tensor(0.0108, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-6.5653e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.245006
Average KL loss: 0.149848
Average total loss: 0.394854
tensor(0.0101, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-7.4295e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.231189
Average KL loss: 0.145763
Average total loss: 0.376952
tensor(0.0099, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-6.0693e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.227961
Average KL loss: 0.143908
Average total loss: 0.371870
tensor(0.0097, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-6.8238e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.234799
Average KL loss: 0.142585
Average total loss: 0.377384
tensor(0.0096, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-1.8258e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.224767
Average KL loss: 0.141573
Average total loss: 0.366340
tensor(0.0095, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.4131e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.216089
Average KL loss: 0.140909
Average total loss: 0.356998
tensor(0.0095, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-8.1442e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.221575
Average KL loss: 0.140500
Average total loss: 0.362076
tensor(0.0094, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.1211e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.213583
Average KL loss: 0.140486
Average total loss: 0.354069
tensor(0.0094, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-6.8392e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.213822
Average KL loss: 0.140641
Average total loss: 0.354463
tensor(0.0094, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-6.4455e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.201199
Average KL loss: 0.140752
Average total loss: 0.341950
tensor(0.0094, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-7.7472e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.202832
Average KL loss: 0.140966
Average total loss: 0.343798
tensor(0.0094, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-7.2897e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.196041
Average KL loss: 0.141163
Average total loss: 0.337204
tensor(0.0094, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-7.3500e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.200916
Average KL loss: 0.141447
Average total loss: 0.342362
tensor(0.0094, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-6.4764e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.194816
Average KL loss: 0.141726
Average total loss: 0.336541
tensor(0.0094, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-1.0709e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.192496
Average KL loss: 0.141956
Average total loss: 0.334452
tensor(0.0094, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-4.9203e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.187774
Average KL loss: 0.142205
Average total loss: 0.329979
tensor(0.0094, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-7.6584e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.185698
Average KL loss: 0.142466
Average total loss: 0.328165
tensor(0.0094, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-7.0390e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.179800
Average KL loss: 0.142666
Average total loss: 0.322465
tensor(0.0094, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-4.5460e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.180192
Average KL loss: 0.142862
Average total loss: 0.323054
tensor(0.0095, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.3650e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.176813
Average KL loss: 0.143051
Average total loss: 0.319864
tensor(0.0095, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-7.2488e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.179408
Average KL loss: 0.143274
Average total loss: 0.322682
tensor(0.0095, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-8.3321e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.176089
Average KL loss: 0.143506
Average total loss: 0.319595
tensor(0.0095, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-4.8405e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.171365
Average KL loss: 0.143742
Average total loss: 0.315106
tensor(0.0095, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-6.8031e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.171243
Average KL loss: 0.143990
Average total loss: 0.315233
tensor(0.0095, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-8.6086e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.168091
Average KL loss: 0.144180
Average total loss: 0.312271
tensor(0.0095, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-3.6698e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.168063
Average KL loss: 0.144406
Average total loss: 0.312469
tensor(0.0095, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-6.8428e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.167384
Average KL loss: 0.144594
Average total loss: 0.311977
tensor(0.0095, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-6.1483e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.162276
Average KL loss: 0.144805
Average total loss: 0.307081
tensor(0.0095, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-6.8698e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.165767
Average KL loss: 0.145006
Average total loss: 0.310772
tensor(0.0095, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-4.7585e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.166448
Average KL loss: 0.145209
Average total loss: 0.311657
tensor(0.0095, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-4.0397e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.156490
Average KL loss: 0.145483
Average total loss: 0.301974
tensor(0.0096, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-3.9049e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.160525
Average KL loss: 0.145674
Average total loss: 0.306199
tensor(0.0096, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-4.7995e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.153842
Average KL loss: 0.145929
Average total loss: 0.299770
tensor(0.0096, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-4.0517e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.154705
Average KL loss: 0.146119
Average total loss: 0.300823
tensor(0.0096, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-4.2454e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.153810
Average KL loss: 0.146301
Average total loss: 0.300111
tensor(0.0096, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-4.8823e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.153419
Average KL loss: 0.146476
Average total loss: 0.299895
tensor(0.0096, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-2.2502e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.153434
Average KL loss: 0.146671
Average total loss: 0.300105
tensor(0.0096, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-4.6845e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.150486
Average KL loss: 0.146844
Average total loss: 0.297331
tensor(0.0096, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-8.5008e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.151450
Average KL loss: 0.147052
Average total loss: 0.298502
tensor(0.0096, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-2.3503e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.146708
Average KL loss: 0.147238
Average total loss: 0.293946
tensor(0.0096, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-4.3375e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.151544
Average KL loss: 0.147480
Average total loss: 0.299023
tensor(0.0097, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-5.8837e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.157779
Average KL loss: 0.147726
Average total loss: 0.305505
tensor(0.0097, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-3.9511e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.146547
Average KL loss: 0.147935
Average total loss: 0.294483
tensor(0.0097, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-4.6335e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.147011
Average KL loss: 0.148113
Average total loss: 0.295125
tensor(0.0097, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-4.7375e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.142548
Average KL loss: 0.148332
Average total loss: 0.290881
tensor(0.0097, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-2.7175e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.142212
Average KL loss: 0.148531
Average total loss: 0.290743
tensor(0.0097, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-6.0733e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.138395
Average KL loss: 0.148705
Average total loss: 0.287099
tensor(0.0097, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-3.8543e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.143282
Average KL loss: 0.148929
Average total loss: 0.292212
tensor(0.0097, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-3.9655e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.136809
Average KL loss: 0.149082
Average total loss: 0.285890
tensor(0.0097, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-2.4735e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.143592
Average KL loss: 0.149266
Average total loss: 0.292857
tensor(0.0097, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-2.5852e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.138312
Average KL loss: 0.149428
Average total loss: 0.287740
tensor(0.0098, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-2.9283e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.135652
Average KL loss: 0.149588
Average total loss: 0.285240
tensor(0.0098, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-5.6459e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.135588
Average KL loss: 0.149788
Average total loss: 0.285376
tensor(0.0098, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-4.3021e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.136432
Average KL loss: 0.149986
Average total loss: 0.286418
tensor(0.0098, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-3.9544e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.135086
Average KL loss: 0.150132
Average total loss: 0.285218
tensor(0.0098, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-3.9625e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.132599
Average KL loss: 0.150285
Average total loss: 0.282884
tensor(0.0098, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-2.4730e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.136370
Average KL loss: 0.150413
Average total loss: 0.286783
tensor(0.0098, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-4.5335e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.131216
Average KL loss: 0.150532
Average total loss: 0.281748
tensor(0.0098, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-3.7525e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.131379
Average KL loss: 0.150677
Average total loss: 0.282055
tensor(0.0098, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-2.7796e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.134559
Average KL loss: 0.150854
Average total loss: 0.285414
tensor(0.0098, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-3.4088e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.129413
Average KL loss: 0.150948
Average total loss: 0.280361
tensor(0.0099, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-1.8516e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.130877
Average KL loss: 0.151068
Average total loss: 0.281945
tensor(0.0099, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-4.3797e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.130482
Average KL loss: 0.151199
Average total loss: 0.281681
tensor(0.0099, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-2.4191e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.133476
Average KL loss: 0.151372
Average total loss: 0.284849
tensor(0.0099, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-4.7312e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.127399
Average KL loss: 0.151539
Average total loss: 0.278938
tensor(0.0099, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-2.4644e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.126469
Average KL loss: 0.151669
Average total loss: 0.278137
tensor(0.0099, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-3.7209e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.129147
Average KL loss: 0.151806
Average total loss: 0.280953
tensor(0.0099, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-3.5172e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.128690
Average KL loss: 0.151935
Average total loss: 0.280625
tensor(0.0099, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-8.0332e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.121627
Average KL loss: 0.152097
Average total loss: 0.273725
tensor(0.0099, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-2.6304e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.127552
Average KL loss: 0.152209
Average total loss: 0.279762
tensor(0.0099, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-5.1898e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.123844
Average KL loss: 0.152341
Average total loss: 0.276185
tensor(0.0100, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-9.2128e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.123208
Average KL loss: 0.152481
Average total loss: 0.275689
tensor(0.0100, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-1.1430e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.124038
Average KL loss: 0.152581
Average total loss: 0.276619
tensor(0.0100, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.5741e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.120646
Average KL loss: 0.152647
Average total loss: 0.273293
tensor(0.0100, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-2.6491e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.122218
Average KL loss: 0.152759
Average total loss: 0.274977
tensor(0.0100, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.2871e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.122273
Average KL loss: 0.152952
Average total loss: 0.275225
tensor(0.0100, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-2.9022e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.120988
Average KL loss: 0.153039
Average total loss: 0.274027
tensor(0.0100, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-2.4218e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.121540
Average KL loss: 0.153221
Average total loss: 0.274761
tensor(0.0100, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-4.1136e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.120450
Average KL loss: 0.153385
Average total loss: 0.273835
tensor(0.0100, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.9522e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.122127
Average KL loss: 0.153480
Average total loss: 0.275606
tensor(0.0100, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-5.0372e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.118509
Average KL loss: 0.153581
Average total loss: 0.272091
tensor(0.0101, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-1.3972e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.119456
Average KL loss: 0.153634
Average total loss: 0.273091
tensor(0.0101, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-4.6886e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.118947
Average KL loss: 0.153719
Average total loss: 0.272666
tensor(0.0101, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-5.4234e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.119321
Average KL loss: 0.153826
Average total loss: 0.273147
tensor(0.0101, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-2.8933e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.115688
Average KL loss: 0.153930
Average total loss: 0.269618
tensor(0.0101, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-2.2420e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.117535
Average KL loss: 0.153998
Average total loss: 0.271533
tensor(0.0101, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-2.3431e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.116531
Average KL loss: 0.154136
Average total loss: 0.270667
tensor(0.0101, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-1.7014e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.114592
Average KL loss: 0.154260
Average total loss: 0.268852
tensor(0.0101, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-2.5738e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.114246
Average KL loss: 0.154316
Average total loss: 0.268562
tensor(0.0101, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-1.0291e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.116156
Average KL loss: 0.154367
Average total loss: 0.270523
tensor(0.0101, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-1.8854e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.115812
Average KL loss: 0.154454
Average total loss: 0.270266
tensor(0.0101, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(3.1593e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.111440
Average KL loss: 0.154557
Average total loss: 0.265996
tensor(0.0101, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-2.8779e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.114031
Average KL loss: 0.154600
Average total loss: 0.268631
tensor(0.0101, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-1.4801e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.114640
Average KL loss: 0.154690
Average total loss: 0.269330
tensor(0.0102, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-1.2933e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.114286
Average KL loss: 0.154776
Average total loss: 0.269062
tensor(0.0102, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-9.9221e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.114503
Average KL loss: 0.154901
Average total loss: 0.269404
tensor(0.0102, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-1.9405e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.111752
Average KL loss: 0.154976
Average total loss: 0.266728
tensor(0.0102, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-8.9439e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.112757
Average KL loss: 0.155061
Average total loss: 0.267818
tensor(0.0102, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.5108e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.112186
Average KL loss: 0.155168
Average total loss: 0.267354
tensor(0.0102, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-2.3557e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.110338
Average KL loss: 0.155251
Average total loss: 0.265589
tensor(0.0102, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-9.4007e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.110419
Average KL loss: 0.155351
Average total loss: 0.265770
tensor(0.0102, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.5875e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.111839
Average KL loss: 0.155455
Average total loss: 0.267295
tensor(0.0102, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-2.2593e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.113524
Average KL loss: 0.155575
Average total loss: 0.269098
tensor(0.0102, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-3.9570e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.108021
Average KL loss: 0.155675
Average total loss: 0.263696
tensor(0.0102, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-2.2093e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.107921
Average KL loss: 0.155723
Average total loss: 0.263645
tensor(0.0103, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.1564e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.111175
Average KL loss: 0.155793
Average total loss: 0.266968
tensor(0.0103, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-2.0664e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.108043
Average KL loss: 0.155836
Average total loss: 0.263879
tensor(0.0103, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-3.0288e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.110142
Average KL loss: 0.155970
Average total loss: 0.266112
tensor(0.0103, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.9818e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.107889
Average KL loss: 0.156025
Average total loss: 0.263914
tensor(0.0103, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-2.0778e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.109386
Average KL loss: 0.156069
Average total loss: 0.265454
tensor(0.0103, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-3.9946e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.106084
Average KL loss: 0.156158
Average total loss: 0.262242
tensor(0.0103, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-5.8831e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.105973
Average KL loss: 0.156237
Average total loss: 0.262209
tensor(0.0103, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-2.3306e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.105518
Average KL loss: 0.156281
Average total loss: 0.261799
tensor(0.0103, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(3.1916e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.107545
Average KL loss: 0.156321
Average total loss: 0.263866
tensor(0.0103, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-1.2147e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.107488
Average KL loss: 0.156423
Average total loss: 0.263911
tensor(0.0103, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(2.1810e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.105018
Average KL loss: 0.156483
Average total loss: 0.261502
tensor(0.0103, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(4.1900e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.106411
Average KL loss: 0.156521
Average total loss: 0.262932
tensor(0.0103, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-2.1742e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.107850
Average KL loss: 0.156577
Average total loss: 0.264426
tensor(0.0104, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.0569e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.105402
Average KL loss: 0.156663
Average total loss: 0.262064
tensor(0.0104, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-8.5572e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.106432
Average KL loss: 0.156706
Average total loss: 0.263138
tensor(0.0104, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-1.4580e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.103510
Average KL loss: 0.156755
Average total loss: 0.260265
tensor(0.0104, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-1.1225e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.103353
Average KL loss: 0.156803
Average total loss: 0.260156
tensor(0.0104, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-1.2812e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.106632
Average KL loss: 0.156852
Average total loss: 0.263484
tensor(0.0104, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-3.0151e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.104903
Average KL loss: 0.156938
Average total loss: 0.261840
tensor(0.0104, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-2.9253e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.103911
Average KL loss: 0.156993
Average total loss: 0.260903
tensor(0.0104, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-2.5358e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.104986
Average KL loss: 0.157042
Average total loss: 0.262028
tensor(0.0104, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-1.3078e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.104357
Average KL loss: 0.157106
Average total loss: 0.261463
tensor(0.0104, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.5568e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.106037
Average KL loss: 0.157171
Average total loss: 0.263208
tensor(0.0104, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-2.9554e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.102892
Average KL loss: 0.157245
Average total loss: 0.260137
tensor(0.0104, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-1.8245e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.105958
Average KL loss: 0.157299
Average total loss: 0.263257
tensor(0.0104, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-1.4536e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.110027
Average KL loss: 0.157379
Average total loss: 0.267407
tensor(0.0104, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-1.0018e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.102250
Average KL loss: 0.157402
Average total loss: 0.259652
tensor(0.0105, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-6.2301e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.101820
Average KL loss: 0.157467
Average total loss: 0.259287
tensor(0.0105, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-1.8024e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.101575
Average KL loss: 0.157545
Average total loss: 0.259120
tensor(0.0105, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-2.0731e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.101121
Average KL loss: 0.157600
Average total loss: 0.258722
tensor(0.0105, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-2.3897e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.100728
Average KL loss: 0.157645
Average total loss: 0.258373
tensor(0.0105, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-8.1754e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.101352
Average KL loss: 0.157713
Average total loss: 0.259065
tensor(0.0105, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-1.5401e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.100727
Average KL loss: 0.157761
Average total loss: 0.258488
tensor(0.0105, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-6.1081e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.101936
Average KL loss: 0.157801
Average total loss: 0.259737
tensor(0.0105, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-9.7424e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.102284
Average KL loss: 0.157840
Average total loss: 0.260124
tensor(0.0105, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-4.0477e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.100507
Average KL loss: 0.157864
Average total loss: 0.258371
tensor(0.0105, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.3730e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.100864
Average KL loss: 0.157874
Average total loss: 0.258739
tensor(0.0105, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-2.0746e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.103262
Average KL loss: 0.157967
Average total loss: 0.261229
tensor(0.0105, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-2.7465e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.100723
Average KL loss: 0.157975
Average total loss: 0.258698
tensor(0.0105, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-9.7034e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.103055
Average KL loss: 0.157975
Average total loss: 0.261030
tensor(0.0105, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.4180e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.098235
Average KL loss: 0.158044
Average total loss: 0.256279
tensor(0.0106, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-4.2558e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.102282
Average KL loss: 0.158104
Average total loss: 0.260387
tensor(0.0106, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-2.0841e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.099369
Average KL loss: 0.158174
Average total loss: 0.257543
tensor(0.0106, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(1.3952e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.102970
Average KL loss: 0.158240
Average total loss: 0.261210
tensor(0.0106, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-5.1982e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.101445
Average KL loss: 0.158298
Average total loss: 0.259743
tensor(0.0106, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-7.5331e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.099445
Average KL loss: 0.158389
Average total loss: 0.257834
tensor(0.0106, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-1.1256e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.098467
Average KL loss: 0.158440
Average total loss: 0.256907
tensor(0.0106, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-2.5378e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.099256
Average KL loss: 0.158521
Average total loss: 0.257777
tensor(0.0106, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-3.8716e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.104773
Average KL loss: 0.158613
Average total loss: 0.263387
tensor(0.0106, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-4.9508e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.101268
Average KL loss: 0.158695
Average total loss: 0.259963
tensor(0.0106, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-1.8747e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.101709
Average KL loss: 0.158735
Average total loss: 0.260444
tensor(0.0106, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-6.3187e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.099886
Average KL loss: 0.158839
Average total loss: 0.258725
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-5.2025e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.100044
Average KL loss: 0.158868
Average total loss: 0.258912
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-2.3828e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.098694
Average KL loss: 0.158852
Average total loss: 0.257546
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(1.6055e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.096967
Average KL loss: 0.158831
Average total loss: 0.255798
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(4.0661e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.098192
Average KL loss: 0.158813
Average total loss: 0.257005
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-1.1701e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.098704
Average KL loss: 0.158799
Average total loss: 0.257503
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(2.3625e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.097291
Average KL loss: 0.158778
Average total loss: 0.256069
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(8.7290e-11, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.096908
Average KL loss: 0.158761
Average total loss: 0.255669
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-4.6809e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.096366
Average KL loss: 0.158747
Average total loss: 0.255112
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-1.9265e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.098172
Average KL loss: 0.158734
Average total loss: 0.256905
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-1.9008e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.097536
Average KL loss: 0.158726
Average total loss: 0.256262
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(6.2287e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.098119
Average KL loss: 0.158715
Average total loss: 0.256834
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-4.5125e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.097228
Average KL loss: 0.158705
Average total loss: 0.255933
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(1.8264e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.096850
Average KL loss: 0.158694
Average total loss: 0.255544
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-2.2715e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.100634
Average KL loss: 0.158685
Average total loss: 0.259319
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-6.5848e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.103329
Average KL loss: 0.158675
Average total loss: 0.262004
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(2.7543e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.099568
Average KL loss: 0.158666
Average total loss: 0.258234
tensor(0.0106, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-1.5819e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.097078
Average KL loss: 0.158662
Average total loss: 0.255739
tensor(0.0106, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-1.3634e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.096373
Average KL loss: 0.158653
Average total loss: 0.255027
tensor(0.0106, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-3.1176e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.098837
Average KL loss: 0.158646
Average total loss: 0.257483
tensor(0.0106, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-3.0487e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.098669
Average KL loss: 0.158634
Average total loss: 0.257303
tensor(0.0106, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-1.5876e-12, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.098830
Average KL loss: 0.158628
Average total loss: 0.257458
tensor(0.0106, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-2.8251e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.096335
Average KL loss: 0.158618
Average total loss: 0.254953
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-7.0723e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.096456
Average KL loss: 0.158609
Average total loss: 0.255065
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-8.7553e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.099644
Average KL loss: 0.158600
Average total loss: 0.258244
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-1.0816e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.099238
Average KL loss: 0.158595
Average total loss: 0.257833
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-1.5417e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.096797
Average KL loss: 0.158586
Average total loss: 0.255383
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-2.5376e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.100061
Average KL loss: 0.158575
Average total loss: 0.258637
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-2.6755e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.097850
Average KL loss: 0.158567
Average total loss: 0.256417
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-3.3413e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.099168
Average KL loss: 0.158557
Average total loss: 0.257724
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-2.5054e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.099749
Average KL loss: 0.158551
Average total loss: 0.258300
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(1.5325e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.097180
Average KL loss: 0.158542
Average total loss: 0.255721
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-1.3413e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.096176
Average KL loss: 0.158537
Average total loss: 0.254713
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-2.7370e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.098098
Average KL loss: 0.158526
Average total loss: 0.256623
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(1.2733e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.098313
Average KL loss: 0.158520
Average total loss: 0.256832
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(1.5928e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.100354
Average KL loss: 0.158520
Average total loss: 0.258874
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-4.3645e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.096662
Average KL loss: 0.158517
Average total loss: 0.255179
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-4.5520e-11, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.097959
Average KL loss: 0.158515
Average total loss: 0.256474
tensor(0.0107, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-2.1436e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.096284
Average KL loss: 0.158513
Average total loss: 0.254797
tensor(0.0107, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-8.3914e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.096989
Average KL loss: 0.158505
Average total loss: 0.255494
tensor(0.0107, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-9.5672e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.098368
Average KL loss: 0.158503
Average total loss: 0.256871
tensor(0.0107, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(9.9488e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.097787
Average KL loss: 0.158500
Average total loss: 0.256287
tensor(0.0107, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-3.1476e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.098803
Average KL loss: 0.158496
Average total loss: 0.257299
tensor(0.0107, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-1.1235e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.097338
Average KL loss: 0.158491
Average total loss: 0.255829
 Percentile value: 2.08649742603302
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =      83 /    1728             (  4.80%) | total_pruned =    1645 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      62 /   36864             (  0.17%) | total_pruned =   36802 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      92 /   36864             (  0.25%) | total_pruned =   36772 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     108 /   36864             (  0.29%) | total_pruned =   36756 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     185 /   36864             (  0.50%) | total_pruned =   36679 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     654 /   73728             (  0.89%) | total_pruned =   73074 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1452 /  147456             (  0.98%) | total_pruned =  146004 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     136 /    8192             (  1.66%) | total_pruned =    8056 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1577 /  147456             (  1.07%) | total_pruned =  145879 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1577 /  147456             (  1.07%) | total_pruned =  145879 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3947 /  294912             (  1.34%) | total_pruned =  290965 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5383 /  589824             (  0.91%) | total_pruned =  584441 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     453 /   32768             (  1.38%) | total_pruned =   32315 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3251 /  589824             (  0.55%) | total_pruned =  586573 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2685 /  589824             (  0.46%) | total_pruned =  587139 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    6144 / 1179648             (  0.52%) | total_pruned = 1173504 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     347 /     512             ( 67.77%) | total_pruned =     165 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4850 / 2359296             (  0.21%) | total_pruned = 2354446 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     196 /     512             ( 38.28%) | total_pruned =     316 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      88 /  131072             (  0.07%) | total_pruned =  130984 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      98 /     512             ( 19.14%) | total_pruned =     414 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3257 / 2359296             (  0.14%) | total_pruned = 2356039 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    3973 / 2359296             (  0.17%) | total_pruned = 2355323 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     210 /     512             ( 41.02%) | total_pruned =     302 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     176 /     512             ( 34.38%) | total_pruned =     336 | shape = torch.Size([512])
linear.weight        | nonzeros =    1181 /    5120             ( 23.07%) | total_pruned =    3939 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 65/100 Loss: 0.044735 Accuracy: 83.47 99.96 % Best test Accuracy: 84.45%
tensor(0.0107, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-1.0993e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.195272
Average KL loss: 0.151980
Average total loss: 0.347252
tensor(0.0096, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-7.0903e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.195364
Average KL loss: 0.147117
Average total loss: 0.342481
tensor(0.0093, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-9.6359e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.193047
Average KL loss: 0.144691
Average total loss: 0.337739
tensor(0.0091, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-7.6142e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.193210
Average KL loss: 0.142707
Average total loss: 0.335918
tensor(0.0089, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-6.7096e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.196384
Average KL loss: 0.141048
Average total loss: 0.337432
tensor(0.0088, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.2557e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.196035
Average KL loss: 0.139717
Average total loss: 0.335752
tensor(0.0088, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-3.8467e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.189109
Average KL loss: 0.138799
Average total loss: 0.327908
tensor(0.0087, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-1.0705e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.186585
Average KL loss: 0.138333
Average total loss: 0.324917
tensor(0.0087, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-9.4060e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.184101
Average KL loss: 0.138175
Average total loss: 0.322276
tensor(0.0087, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-6.0191e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.179249
Average KL loss: 0.138206
Average total loss: 0.317455
tensor(0.0087, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-1.2384e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.182381
Average KL loss: 0.138263
Average total loss: 0.320643
tensor(0.0087, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-7.5490e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.177453
Average KL loss: 0.138355
Average total loss: 0.315808
tensor(0.0087, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.0168e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.178106
Average KL loss: 0.138476
Average total loss: 0.316583
tensor(0.0087, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.5799e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.168664
Average KL loss: 0.138614
Average total loss: 0.307278
tensor(0.0087, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-3.5558e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.165877
Average KL loss: 0.138759
Average total loss: 0.304636
tensor(0.0087, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-6.8983e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.161710
Average KL loss: 0.138888
Average total loss: 0.300598
tensor(0.0087, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-5.3475e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.165267
Average KL loss: 0.139034
Average total loss: 0.304301
tensor(0.0087, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-4.5114e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.160062
Average KL loss: 0.139183
Average total loss: 0.299245
tensor(0.0087, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-4.7926e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.157360
Average KL loss: 0.139315
Average total loss: 0.296675
tensor(0.0087, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-6.9782e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.162039
Average KL loss: 0.139462
Average total loss: 0.301501
tensor(0.0087, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-7.4910e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.160831
Average KL loss: 0.139646
Average total loss: 0.300477
tensor(0.0088, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-7.4851e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.151976
Average KL loss: 0.139830
Average total loss: 0.291806
tensor(0.0088, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-7.6893e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.156333
Average KL loss: 0.139982
Average total loss: 0.296315
tensor(0.0088, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-6.0129e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.151267
Average KL loss: 0.140145
Average total loss: 0.291412
tensor(0.0088, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-4.7749e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.149652
Average KL loss: 0.140300
Average total loss: 0.289952
tensor(0.0088, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-5.6544e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.146436
Average KL loss: 0.140440
Average total loss: 0.286876
tensor(0.0088, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-6.2645e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.147450
Average KL loss: 0.140576
Average total loss: 0.288025
tensor(0.0088, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-5.3425e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.144836
Average KL loss: 0.140716
Average total loss: 0.285551
tensor(0.0088, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-4.6127e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.154634
Average KL loss: 0.140845
Average total loss: 0.295478
tensor(0.0088, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-5.0885e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.139406
Average KL loss: 0.140988
Average total loss: 0.280394
tensor(0.0089, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-4.4279e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.138261
Average KL loss: 0.141118
Average total loss: 0.279379
tensor(0.0089, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-4.7269e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.135129
Average KL loss: 0.141281
Average total loss: 0.276410
tensor(0.0089, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-3.7192e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.136424
Average KL loss: 0.141368
Average total loss: 0.277792
tensor(0.0089, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-4.3885e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.132234
Average KL loss: 0.141491
Average total loss: 0.273725
tensor(0.0089, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-5.3686e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.136262
Average KL loss: 0.141633
Average total loss: 0.277895
tensor(0.0089, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-3.5073e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.131844
Average KL loss: 0.141772
Average total loss: 0.273616
tensor(0.0089, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-5.4747e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.134650
Average KL loss: 0.141880
Average total loss: 0.276530
tensor(0.0089, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-4.5203e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.129778
Average KL loss: 0.142017
Average total loss: 0.271795
tensor(0.0089, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-9.1531e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.134632
Average KL loss: 0.142132
Average total loss: 0.276763
tensor(0.0090, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-6.6075e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.128115
Average KL loss: 0.142261
Average total loss: 0.270376
tensor(0.0090, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-1.0412e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.140185
Average KL loss: 0.142385
Average total loss: 0.282570
tensor(0.0090, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-4.8747e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.126609
Average KL loss: 0.142497
Average total loss: 0.269106
tensor(0.0090, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-4.4432e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.126026
Average KL loss: 0.142618
Average total loss: 0.268644
tensor(0.0090, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-5.9656e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.128920
Average KL loss: 0.142771
Average total loss: 0.271691
tensor(0.0090, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-4.2592e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.123101
Average KL loss: 0.142920
Average total loss: 0.266021
tensor(0.0090, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-4.4409e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.124549
Average KL loss: 0.143050
Average total loss: 0.267599
tensor(0.0090, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-5.7092e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.122933
Average KL loss: 0.143192
Average total loss: 0.266125
tensor(0.0091, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-4.0133e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.124031
Average KL loss: 0.143317
Average total loss: 0.267348
tensor(0.0091, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.2531e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.118748
Average KL loss: 0.143446
Average total loss: 0.262194
tensor(0.0091, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-2.5577e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.116947
Average KL loss: 0.143574
Average total loss: 0.260521
tensor(0.0091, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-3.2470e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.121766
Average KL loss: 0.143732
Average total loss: 0.265498
tensor(0.0091, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-4.5150e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.116414
Average KL loss: 0.143854
Average total loss: 0.260268
tensor(0.0091, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-5.6628e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.119645
Average KL loss: 0.143965
Average total loss: 0.263610
tensor(0.0091, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-4.9165e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.116252
Average KL loss: 0.144094
Average total loss: 0.260346
tensor(0.0091, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-3.8525e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.113632
Average KL loss: 0.144211
Average total loss: 0.257843
tensor(0.0091, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-8.4265e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.115830
Average KL loss: 0.144302
Average total loss: 0.260132
tensor(0.0092, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-2.1336e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.116606
Average KL loss: 0.144411
Average total loss: 0.261017
tensor(0.0092, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-3.0471e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.117015
Average KL loss: 0.144532
Average total loss: 0.261548
tensor(0.0092, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-3.8782e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.114539
Average KL loss: 0.144642
Average total loss: 0.259181
tensor(0.0092, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-3.3957e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.108782
Average KL loss: 0.144765
Average total loss: 0.253547
tensor(0.0092, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-3.0560e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.112732
Average KL loss: 0.144887
Average total loss: 0.257619
tensor(0.0092, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-5.4364e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.110206
Average KL loss: 0.144986
Average total loss: 0.255193
tensor(0.0092, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-2.6461e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.108228
Average KL loss: 0.145096
Average total loss: 0.253325
tensor(0.0092, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-5.8093e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.109857
Average KL loss: 0.145210
Average total loss: 0.255067
tensor(0.0093, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-3.4649e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.106399
Average KL loss: 0.145328
Average total loss: 0.251727
tensor(0.0093, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-5.3335e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.108259
Average KL loss: 0.145420
Average total loss: 0.253678
tensor(0.0093, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.6596e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.107014
Average KL loss: 0.145508
Average total loss: 0.252522
tensor(0.0093, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-4.1242e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.111493
Average KL loss: 0.145598
Average total loss: 0.257091
tensor(0.0093, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-1.9934e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.106137
Average KL loss: 0.145717
Average total loss: 0.251854
tensor(0.0093, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-3.5037e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.109507
Average KL loss: 0.145798
Average total loss: 0.255306
tensor(0.0093, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(4.1190e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.105265
Average KL loss: 0.145874
Average total loss: 0.251139
tensor(0.0093, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-2.4275e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.109104
Average KL loss: 0.145993
Average total loss: 0.255098
tensor(0.0094, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-3.1537e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.110956
Average KL loss: 0.146091
Average total loss: 0.257047
tensor(0.0094, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-1.4833e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.104414
Average KL loss: 0.146212
Average total loss: 0.250626
tensor(0.0094, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-3.0207e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.100954
Average KL loss: 0.146321
Average total loss: 0.247276
tensor(0.0094, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-2.7795e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.102881
Average KL loss: 0.146409
Average total loss: 0.249290
tensor(0.0094, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-5.2230e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.106103
Average KL loss: 0.146499
Average total loss: 0.252602
tensor(0.0094, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-2.8701e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.102080
Average KL loss: 0.146605
Average total loss: 0.248685
tensor(0.0094, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-5.2406e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.103381
Average KL loss: 0.146716
Average total loss: 0.250097
tensor(0.0094, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-2.4620e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.110332
Average KL loss: 0.146819
Average total loss: 0.257151
tensor(0.0094, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-2.3781e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.100727
Average KL loss: 0.146899
Average total loss: 0.247626
tensor(0.0095, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-2.7867e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.102719
Average KL loss: 0.147011
Average total loss: 0.249730
tensor(0.0095, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-4.1554e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.100462
Average KL loss: 0.147133
Average total loss: 0.247596
tensor(0.0095, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-2.8178e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.098340
Average KL loss: 0.147210
Average total loss: 0.245550
tensor(0.0095, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-2.4356e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.099016
Average KL loss: 0.147294
Average total loss: 0.246309
tensor(0.0095, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-1.3886e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.099223
Average KL loss: 0.147380
Average total loss: 0.246604
tensor(0.0095, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-4.0022e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.121025
Average KL loss: 0.147493
Average total loss: 0.268518
tensor(0.0095, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-2.2381e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.096392
Average KL loss: 0.147555
Average total loss: 0.243948
tensor(0.0095, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-3.5566e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.102235
Average KL loss: 0.147648
Average total loss: 0.249883
tensor(0.0096, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-3.5729e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.096321
Average KL loss: 0.147751
Average total loss: 0.244073
tensor(0.0096, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-1.8262e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.093932
Average KL loss: 0.147835
Average total loss: 0.241768
tensor(0.0096, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-2.5479e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.094086
Average KL loss: 0.147895
Average total loss: 0.241981
tensor(0.0096, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-2.8030e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.098078
Average KL loss: 0.147975
Average total loss: 0.246053
tensor(0.0096, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-2.6436e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.096351
Average KL loss: 0.148094
Average total loss: 0.244445
tensor(0.0096, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-1.4810e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.096094
Average KL loss: 0.148170
Average total loss: 0.244264
tensor(0.0096, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-1.8834e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.093320
Average KL loss: 0.148230
Average total loss: 0.241550
tensor(0.0096, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-3.1175e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.094698
Average KL loss: 0.148308
Average total loss: 0.243005
tensor(0.0096, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-1.9371e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.094668
Average KL loss: 0.148363
Average total loss: 0.243030
tensor(0.0097, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.4983e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.092695
Average KL loss: 0.148404
Average total loss: 0.241100
tensor(0.0097, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-4.5832e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.095730
Average KL loss: 0.148465
Average total loss: 0.244196
tensor(0.0097, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-1.4543e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.094481
Average KL loss: 0.148530
Average total loss: 0.243012
tensor(0.0097, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.9738e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.091855
Average KL loss: 0.148607
Average total loss: 0.240462
tensor(0.0097, device='cuda:0') tensor(0.0408, device='cuda:0') tensor(-2.8888e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.094462
Average KL loss: 0.148686
Average total loss: 0.243149
tensor(0.0097, device='cuda:0') tensor(0.0409, device='cuda:0') tensor(-8.9862e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.089123
Average KL loss: 0.148749
Average total loss: 0.237872
tensor(0.0097, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-8.4364e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.094377
Average KL loss: 0.148812
Average total loss: 0.243189
tensor(0.0097, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(-1.7494e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.106565
Average KL loss: 0.148873
Average total loss: 0.255438
tensor(0.0097, device='cuda:0') tensor(0.0412, device='cuda:0') tensor(-1.1772e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.090400
Average KL loss: 0.148920
Average total loss: 0.239320
tensor(0.0098, device='cuda:0') tensor(0.0413, device='cuda:0') tensor(-6.9048e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.093129
Average KL loss: 0.148990
Average total loss: 0.242118
tensor(0.0098, device='cuda:0') tensor(0.0415, device='cuda:0') tensor(-2.9697e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.090548
Average KL loss: 0.149069
Average total loss: 0.239617
tensor(0.0098, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(-4.4621e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.101272
Average KL loss: 0.149125
Average total loss: 0.250398
tensor(0.0098, device='cuda:0') tensor(0.0417, device='cuda:0') tensor(-1.7458e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.089562
Average KL loss: 0.149165
Average total loss: 0.238727
tensor(0.0098, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-2.5329e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.088556
Average KL loss: 0.149209
Average total loss: 0.237765
tensor(0.0098, device='cuda:0') tensor(0.0419, device='cuda:0') tensor(-3.2352e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.089058
Average KL loss: 0.149252
Average total loss: 0.238310
tensor(0.0098, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(-8.2805e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.087351
Average KL loss: 0.149332
Average total loss: 0.236683
tensor(0.0098, device='cuda:0') tensor(0.0421, device='cuda:0') tensor(-1.4800e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.089918
Average KL loss: 0.149357
Average total loss: 0.239275
tensor(0.0098, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-1.7619e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.087321
Average KL loss: 0.149382
Average total loss: 0.236703
tensor(0.0098, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(-1.6217e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.089572
Average KL loss: 0.149460
Average total loss: 0.239031
tensor(0.0099, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(4.7037e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.084224
Average KL loss: 0.149498
Average total loss: 0.233722
tensor(0.0099, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-1.0334e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.087766
Average KL loss: 0.149540
Average total loss: 0.237306
tensor(0.0099, device='cuda:0') tensor(0.0426, device='cuda:0') tensor(-1.3962e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.087117
Average KL loss: 0.149613
Average total loss: 0.236730
tensor(0.0099, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-1.2287e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.084567
Average KL loss: 0.149677
Average total loss: 0.234244
tensor(0.0099, device='cuda:0') tensor(0.0428, device='cuda:0') tensor(-1.3656e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.088686
Average KL loss: 0.149702
Average total loss: 0.238387
tensor(0.0099, device='cuda:0') tensor(0.0429, device='cuda:0') tensor(-7.1937e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.085800
Average KL loss: 0.149732
Average total loss: 0.235531
tensor(0.0099, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(-1.6191e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.086648
Average KL loss: 0.149786
Average total loss: 0.236433
tensor(0.0099, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-3.4278e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.085280
Average KL loss: 0.149861
Average total loss: 0.235141
tensor(0.0099, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-1.2802e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.085847
Average KL loss: 0.149902
Average total loss: 0.235749
tensor(0.0099, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(-1.7601e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.084697
Average KL loss: 0.149955
Average total loss: 0.234651
tensor(0.0100, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(-2.1659e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.083307
Average KL loss: 0.150007
Average total loss: 0.233314
tensor(0.0100, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-2.1575e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.085325
Average KL loss: 0.150048
Average total loss: 0.235374
tensor(0.0100, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-1.6610e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.084700
Average KL loss: 0.150083
Average total loss: 0.234783
tensor(0.0100, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-1.4026e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.084036
Average KL loss: 0.150137
Average total loss: 0.234173
tensor(0.0100, device='cuda:0') tensor(0.0438, device='cuda:0') tensor(5.4419e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.082836
Average KL loss: 0.150177
Average total loss: 0.233013
tensor(0.0100, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-2.2811e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.084024
Average KL loss: 0.150207
Average total loss: 0.234232
tensor(0.0100, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.6467e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.085054
Average KL loss: 0.150267
Average total loss: 0.235321
tensor(0.0100, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-1.5742e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.082555
Average KL loss: 0.150331
Average total loss: 0.232886
tensor(0.0100, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-1.1821e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.080553
Average KL loss: 0.150354
Average total loss: 0.230907
tensor(0.0100, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-8.3323e-11, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.084268
Average KL loss: 0.150364
Average total loss: 0.234633
tensor(0.0100, device='cuda:0') tensor(0.0444, device='cuda:0') tensor(-2.0091e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.082408
Average KL loss: 0.150426
Average total loss: 0.232834
tensor(0.0101, device='cuda:0') tensor(0.0445, device='cuda:0') tensor(-8.1459e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.082953
Average KL loss: 0.150460
Average total loss: 0.233413
tensor(0.0101, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-8.6617e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.082708
Average KL loss: 0.150505
Average total loss: 0.233213
tensor(0.0101, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.3595e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.080320
Average KL loss: 0.150528
Average total loss: 0.230848
tensor(0.0101, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.0224e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.082768
Average KL loss: 0.150565
Average total loss: 0.233333
tensor(0.0101, device='cuda:0') tensor(0.0448, device='cuda:0') tensor(1.5987e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.079892
Average KL loss: 0.150607
Average total loss: 0.230499
tensor(0.0101, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(-1.0249e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.082606
Average KL loss: 0.150645
Average total loss: 0.233251
tensor(0.0101, device='cuda:0') tensor(0.0450, device='cuda:0') tensor(-1.0275e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.081730
Average KL loss: 0.150680
Average total loss: 0.232410
tensor(0.0101, device='cuda:0') tensor(0.0451, device='cuda:0') tensor(-2.3788e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.081062
Average KL loss: 0.150740
Average total loss: 0.231802
tensor(0.0101, device='cuda:0') tensor(0.0452, device='cuda:0') tensor(-2.2671e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.083655
Average KL loss: 0.150751
Average total loss: 0.234407
tensor(0.0101, device='cuda:0') tensor(0.0453, device='cuda:0') tensor(-1.5526e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.081525
Average KL loss: 0.150779
Average total loss: 0.232303
tensor(0.0101, device='cuda:0') tensor(0.0454, device='cuda:0') tensor(-1.8591e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.080849
Average KL loss: 0.150816
Average total loss: 0.231665
tensor(0.0101, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-2.2897e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.081844
Average KL loss: 0.150853
Average total loss: 0.232697
tensor(0.0102, device='cuda:0') tensor(0.0456, device='cuda:0') tensor(-7.7442e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.079254
Average KL loss: 0.150904
Average total loss: 0.230158
tensor(0.0102, device='cuda:0') tensor(0.0457, device='cuda:0') tensor(-2.7415e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.080668
Average KL loss: 0.150929
Average total loss: 0.231598
tensor(0.0102, device='cuda:0') tensor(0.0458, device='cuda:0') tensor(-2.4120e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.081180
Average KL loss: 0.150964
Average total loss: 0.232144
tensor(0.0102, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(-1.4346e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.081925
Average KL loss: 0.151026
Average total loss: 0.232950
tensor(0.0102, device='cuda:0') tensor(0.0460, device='cuda:0') tensor(-9.8851e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.079520
Average KL loss: 0.151083
Average total loss: 0.230603
tensor(0.0102, device='cuda:0') tensor(0.0461, device='cuda:0') tensor(-1.0762e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.078252
Average KL loss: 0.151105
Average total loss: 0.229357
tensor(0.0102, device='cuda:0') tensor(0.0462, device='cuda:0') tensor(-1.1576e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.081826
Average KL loss: 0.151136
Average total loss: 0.232962
tensor(0.0102, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-1.9259e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.080855
Average KL loss: 0.151191
Average total loss: 0.232046
tensor(0.0102, device='cuda:0') tensor(0.0464, device='cuda:0') tensor(-7.6414e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.080961
Average KL loss: 0.151257
Average total loss: 0.232218
tensor(0.0102, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-3.8890e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.077848
Average KL loss: 0.151293
Average total loss: 0.229140
tensor(0.0102, device='cuda:0') tensor(0.0466, device='cuda:0') tensor(-1.6255e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.079402
Average KL loss: 0.151280
Average total loss: 0.230682
tensor(0.0103, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.4871e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.079394
Average KL loss: 0.151296
Average total loss: 0.230689
tensor(0.0103, device='cuda:0') tensor(0.0468, device='cuda:0') tensor(-9.7264e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.077615
Average KL loss: 0.151347
Average total loss: 0.228962
tensor(0.0103, device='cuda:0') tensor(0.0468, device='cuda:0') tensor(7.2046e-11, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.082517
Average KL loss: 0.151366
Average total loss: 0.233883
tensor(0.0103, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(-7.1281e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.078145
Average KL loss: 0.151423
Average total loss: 0.229567
tensor(0.0103, device='cuda:0') tensor(0.0470, device='cuda:0') tensor(-9.0506e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.078425
Average KL loss: 0.151433
Average total loss: 0.229858
tensor(0.0103, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-2.0217e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.077473
Average KL loss: 0.151434
Average total loss: 0.228907
tensor(0.0103, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-2.0028e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.078166
Average KL loss: 0.151457
Average total loss: 0.229623
tensor(0.0103, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-6.5962e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.076228
Average KL loss: 0.151494
Average total loss: 0.227722
tensor(0.0103, device='cuda:0') tensor(0.0474, device='cuda:0') tensor(-5.7839e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.079437
Average KL loss: 0.151512
Average total loss: 0.230949
tensor(0.0103, device='cuda:0') tensor(0.0475, device='cuda:0') tensor(-2.2477e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.077704
Average KL loss: 0.151557
Average total loss: 0.229261
tensor(0.0103, device='cuda:0') tensor(0.0476, device='cuda:0') tensor(-7.7088e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.077290
Average KL loss: 0.151588
Average total loss: 0.228878
tensor(0.0103, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-8.1017e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.077282
Average KL loss: 0.151623
Average total loss: 0.228905
tensor(0.0104, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-1.5457e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.075752
Average KL loss: 0.151629
Average total loss: 0.227381
tensor(0.0104, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-1.2020e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.078006
Average KL loss: 0.151683
Average total loss: 0.229689
tensor(0.0104, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-9.1276e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.078067
Average KL loss: 0.151750
Average total loss: 0.229817
tensor(0.0104, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(3.1748e-11, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.078476
Average KL loss: 0.151783
Average total loss: 0.230260
tensor(0.0104, device='cuda:0') tensor(0.0481, device='cuda:0') tensor(9.2432e-11, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.076303
Average KL loss: 0.151823
Average total loss: 0.228126
tensor(0.0104, device='cuda:0') tensor(0.0482, device='cuda:0') tensor(-2.6305e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.077197
Average KL loss: 0.151830
Average total loss: 0.229028
tensor(0.0104, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-1.2338e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.076378
Average KL loss: 0.151854
Average total loss: 0.228232
tensor(0.0104, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-7.2305e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.076987
Average KL loss: 0.151880
Average total loss: 0.228866
tensor(0.0104, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-1.5565e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.076816
Average KL loss: 0.151892
Average total loss: 0.228708
tensor(0.0104, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-2.4918e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.076594
Average KL loss: 0.151931
Average total loss: 0.228524
tensor(0.0104, device='cuda:0') tensor(0.0486, device='cuda:0') tensor(-1.0717e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.075891
Average KL loss: 0.151965
Average total loss: 0.227856
tensor(0.0104, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-1.2402e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.076963
Average KL loss: 0.152001
Average total loss: 0.228964
tensor(0.0104, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-1.4863e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.077286
Average KL loss: 0.152031
Average total loss: 0.229317
tensor(0.0104, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-1.5827e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.075825
Average KL loss: 0.152029
Average total loss: 0.227854
tensor(0.0105, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-1.5798e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.075072
Average KL loss: 0.152030
Average total loss: 0.227102
tensor(0.0105, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-1.0870e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.075335
Average KL loss: 0.152027
Average total loss: 0.227361
tensor(0.0105, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-7.2019e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.075328
Average KL loss: 0.152028
Average total loss: 0.227356
tensor(0.0105, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(2.0738e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.076491
Average KL loss: 0.152026
Average total loss: 0.228517
tensor(0.0105, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(3.5715e-12, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.077229
Average KL loss: 0.152023
Average total loss: 0.229252
tensor(0.0105, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(3.6854e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.075420
Average KL loss: 0.152024
Average total loss: 0.227444
tensor(0.0105, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-1.6530e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.076199
Average KL loss: 0.152024
Average total loss: 0.228223
tensor(0.0105, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-2.7731e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.076361
Average KL loss: 0.152026
Average total loss: 0.228387
tensor(0.0105, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-9.9008e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.074458
Average KL loss: 0.152024
Average total loss: 0.226483
tensor(0.0105, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-2.1203e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.078701
Average KL loss: 0.152022
Average total loss: 0.230723
tensor(0.0105, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-6.1561e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.074761
Average KL loss: 0.152022
Average total loss: 0.226783
tensor(0.0105, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-1.6887e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.086335
Average KL loss: 0.152021
Average total loss: 0.238356
tensor(0.0105, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-3.9949e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.075250
Average KL loss: 0.152024
Average total loss: 0.227274
 Percentile value: 4.567876577377319
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =      81 /    1728             (  4.69%) | total_pruned =    1647 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      46 /   36864             (  0.12%) | total_pruned =   36818 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      65 /   36864             (  0.18%) | total_pruned =   36799 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      89 /   36864             (  0.24%) | total_pruned =   36775 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     145 /   36864             (  0.39%) | total_pruned =   36719 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     473 /   73728             (  0.64%) | total_pruned =   73255 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     961 /  147456             (  0.65%) | total_pruned =  146495 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     108 /    8192             (  1.32%) | total_pruned =    8084 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1050 /  147456             (  0.71%) | total_pruned =  146406 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1053 /  147456             (  0.71%) | total_pruned =  146403 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2238 /  294912             (  0.76%) | total_pruned =  292674 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3055 /  589824             (  0.52%) | total_pruned =  586769 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     264 /   32768             (  0.81%) | total_pruned =   32504 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1809 /  589824             (  0.31%) | total_pruned =  588015 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1560 /  589824             (  0.26%) | total_pruned =  588264 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2687 / 1179648             (  0.23%) | total_pruned = 1176961 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     314 /     512             ( 61.33%) | total_pruned =     198 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1878 / 2359296             (  0.08%) | total_pruned = 2357418 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     148 /     512             ( 28.91%) | total_pruned =     364 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      75 /     512             ( 14.65%) | total_pruned =     437 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      31 /  131072             (  0.02%) | total_pruned =  131041 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      74 /     512             ( 14.45%) | total_pruned =     438 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     982 / 2359296             (  0.04%) | total_pruned = 2358314 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      74 /     512             ( 14.45%) | total_pruned =     438 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     823 / 2359296             (  0.03%) | total_pruned = 2358473 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     125 /     512             ( 24.41%) | total_pruned =     387 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      73 /     512             ( 14.26%) | total_pruned =     439 | shape = torch.Size([512])
linear.weight        | nonzeros =     404 /    5120             (  7.89%) | total_pruned =    4716 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.174776 Accuracy: 80.27 98.53 % Best test Accuracy: 82.73%
tensor(0.0105, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-1.9969e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.191806
Average KL loss: 0.145287
Average total loss: 0.337093
tensor(0.0094, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-7.6523e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.208659
Average KL loss: 0.135301
Average total loss: 0.343960
tensor(0.0087, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-3.5581e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.198860
Average KL loss: 0.128442
Average total loss: 0.327301
tensor(0.0082, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-4.3433e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.236513
Average KL loss: 0.123464
Average total loss: 0.359977
tensor(0.0079, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-6.6854e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.219304
Average KL loss: 0.119549
Average total loss: 0.338852
tensor(0.0076, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-7.0658e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.240678
Average KL loss: 0.116238
Average total loss: 0.356916
tensor(0.0074, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-3.6479e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.224063
Average KL loss: 0.113632
Average total loss: 0.337695
tensor(0.0073, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-6.1366e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.213441
Average KL loss: 0.111986
Average total loss: 0.325426
tensor(0.0072, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.9416e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.222787
Average KL loss: 0.111197
Average total loss: 0.333984
tensor(0.0072, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-4.6979e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.217664
Average KL loss: 0.110849
Average total loss: 0.328513
tensor(0.0072, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-1.1824e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.204758
Average KL loss: 0.110651
Average total loss: 0.315409
tensor(0.0071, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-5.2805e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.206778
Average KL loss: 0.110505
Average total loss: 0.317283
tensor(0.0071, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-8.3205e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.212042
Average KL loss: 0.110374
Average total loss: 0.322415
tensor(0.0072, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-6.1950e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.212443
Average KL loss: 0.110255
Average total loss: 0.322699
tensor(0.0072, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-5.7012e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.203530
Average KL loss: 0.110136
Average total loss: 0.313666
tensor(0.0072, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-5.8132e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.198603
Average KL loss: 0.110033
Average total loss: 0.308635
tensor(0.0072, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-4.0286e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.194566
Average KL loss: 0.109935
Average total loss: 0.304502
tensor(0.0072, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-6.6675e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.195201
Average KL loss: 0.109846
Average total loss: 0.305047
tensor(0.0072, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-5.3530e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.196361
Average KL loss: 0.109754
Average total loss: 0.306115
tensor(0.0072, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-4.9436e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.193874
Average KL loss: 0.109668
Average total loss: 0.303542
tensor(0.0072, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-6.0077e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.199054
Average KL loss: 0.109589
Average total loss: 0.308643
tensor(0.0072, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-6.6768e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.199664
Average KL loss: 0.109518
Average total loss: 0.309182
tensor(0.0072, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-4.7585e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.188386
Average KL loss: 0.109443
Average total loss: 0.297830
tensor(0.0072, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-5.6809e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.186871
Average KL loss: 0.109369
Average total loss: 0.296240
tensor(0.0072, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-3.1141e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.191240
Average KL loss: 0.109305
Average total loss: 0.300545
tensor(0.0072, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-1.1340e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.193262
Average KL loss: 0.109241
Average total loss: 0.302503
tensor(0.0072, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-4.4213e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.181446
Average KL loss: 0.109181
Average total loss: 0.290626
tensor(0.0072, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-5.8286e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.177876
Average KL loss: 0.109136
Average total loss: 0.287012
tensor(0.0072, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-3.7668e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.174942
Average KL loss: 0.109078
Average total loss: 0.284020
tensor(0.0072, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-4.5863e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.179467
Average KL loss: 0.109028
Average total loss: 0.288494
tensor(0.0073, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.5419e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.178835
Average KL loss: 0.108984
Average total loss: 0.287819
tensor(0.0073, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-2.6895e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.190397
Average KL loss: 0.108936
Average total loss: 0.299332
tensor(0.0073, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-4.4751e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.181508
Average KL loss: 0.108874
Average total loss: 0.290382
tensor(0.0073, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-3.2073e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.170700
Average KL loss: 0.108822
Average total loss: 0.279521
tensor(0.0073, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-4.1926e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.165321
Average KL loss: 0.108777
Average total loss: 0.274098
tensor(0.0073, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-2.5326e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.175576
Average KL loss: 0.108734
Average total loss: 0.284310
tensor(0.0073, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-3.2413e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.168888
Average KL loss: 0.108695
Average total loss: 0.277583
tensor(0.0073, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-7.9830e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.173630
Average KL loss: 0.108659
Average total loss: 0.282289
tensor(0.0073, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-2.9111e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.167451
Average KL loss: 0.108630
Average total loss: 0.276080
tensor(0.0073, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-4.2812e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.171398
Average KL loss: 0.108590
Average total loss: 0.279988
tensor(0.0073, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-4.3665e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.165856
Average KL loss: 0.108550
Average total loss: 0.274406
tensor(0.0073, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-3.9263e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.163918
Average KL loss: 0.108511
Average total loss: 0.272429
tensor(0.0073, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-3.2740e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.190890
Average KL loss: 0.108472
Average total loss: 0.299362
tensor(0.0074, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-2.1035e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.170148
Average KL loss: 0.108432
Average total loss: 0.278580
tensor(0.0074, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-5.6929e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.168002
Average KL loss: 0.108396
Average total loss: 0.276397
tensor(0.0074, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-3.9802e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.166579
Average KL loss: 0.108364
Average total loss: 0.274943
tensor(0.0074, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-4.1300e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.163309
Average KL loss: 0.108334
Average total loss: 0.271643
tensor(0.0074, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-5.4329e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.164918
Average KL loss: 0.108306
Average total loss: 0.273224
tensor(0.0074, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-4.5234e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.162106
Average KL loss: 0.108289
Average total loss: 0.270395
tensor(0.0074, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-4.3574e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.158928
Average KL loss: 0.108272
Average total loss: 0.267200
tensor(0.0074, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-2.6480e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.165880
Average KL loss: 0.108252
Average total loss: 0.274133
tensor(0.0074, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-4.4165e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.186282
Average KL loss: 0.108230
Average total loss: 0.294513
tensor(0.0074, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-1.6372e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.160882
Average KL loss: 0.108210
Average total loss: 0.269092
tensor(0.0074, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-3.4742e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.178811
Average KL loss: 0.108178
Average total loss: 0.286988
tensor(0.0075, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-3.1598e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.161275
Average KL loss: 0.108144
Average total loss: 0.269419
tensor(0.0075, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-1.3391e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.167087
Average KL loss: 0.108119
Average total loss: 0.275206
tensor(0.0075, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-1.5766e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.157955
Average KL loss: 0.108100
Average total loss: 0.266055
tensor(0.0075, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-1.2147e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.156027
Average KL loss: 0.108073
Average total loss: 0.264101
tensor(0.0075, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-4.6619e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.159792
Average KL loss: 0.108042
Average total loss: 0.267835
tensor(0.0075, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-9.8575e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.160040
Average KL loss: 0.108018
Average total loss: 0.268058
tensor(0.0075, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-2.7912e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.153442
Average KL loss: 0.108003
Average total loss: 0.261445
tensor(0.0075, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-1.0835e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.161503
Average KL loss: 0.107992
Average total loss: 0.269496
tensor(0.0075, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-4.2528e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.159700
Average KL loss: 0.107973
Average total loss: 0.267674
tensor(0.0075, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-1.6866e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.160027
Average KL loss: 0.107958
Average total loss: 0.267985
tensor(0.0075, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-6.0372e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.152433
Average KL loss: 0.107947
Average total loss: 0.260380
tensor(0.0075, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-2.7509e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.157151
Average KL loss: 0.107931
Average total loss: 0.265081
tensor(0.0076, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-2.3201e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.148512
Average KL loss: 0.107912
Average total loss: 0.256425
tensor(0.0076, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-2.9663e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.152698
Average KL loss: 0.107901
Average total loss: 0.260599
tensor(0.0076, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-4.9253e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.156171
Average KL loss: 0.107892
Average total loss: 0.264062
tensor(0.0076, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-1.9684e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.150888
Average KL loss: 0.107869
Average total loss: 0.258757
tensor(0.0076, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(4.7720e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.171334
Average KL loss: 0.107841
Average total loss: 0.279175
tensor(0.0076, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-2.7180e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.151287
Average KL loss: 0.107829
Average total loss: 0.259117
tensor(0.0076, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-3.9485e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.151187
Average KL loss: 0.107812
Average total loss: 0.259000
tensor(0.0076, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-1.7584e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.150010
Average KL loss: 0.107790
Average total loss: 0.257800
tensor(0.0076, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-3.1925e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.149014
Average KL loss: 0.107774
Average total loss: 0.256788
tensor(0.0076, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-2.4884e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.150160
Average KL loss: 0.107762
Average total loss: 0.257922
tensor(0.0076, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-9.0698e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.147862
Average KL loss: 0.107751
Average total loss: 0.255613
tensor(0.0077, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-2.2773e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.147050
Average KL loss: 0.107733
Average total loss: 0.254783
tensor(0.0077, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-1.8535e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.142603
Average KL loss: 0.107719
Average total loss: 0.250323
tensor(0.0077, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-2.3957e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.150857
Average KL loss: 0.107707
Average total loss: 0.258564
tensor(0.0077, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.8102e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.148361
Average KL loss: 0.107694
Average total loss: 0.256055
tensor(0.0077, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-1.6954e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.144843
Average KL loss: 0.107691
Average total loss: 0.252534
tensor(0.0077, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-6.1489e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.144178
Average KL loss: 0.107685
Average total loss: 0.251864
tensor(0.0077, device='cuda:0') tensor(0.0408, device='cuda:0') tensor(-1.6970e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.145777
Average KL loss: 0.107688
Average total loss: 0.253465
tensor(0.0077, device='cuda:0') tensor(0.0409, device='cuda:0') tensor(-2.4233e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.144256
Average KL loss: 0.107673
Average total loss: 0.251928
tensor(0.0077, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-2.3971e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.143808
Average KL loss: 0.107656
Average total loss: 0.251464
tensor(0.0077, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(-1.3536e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.148827
Average KL loss: 0.107644
Average total loss: 0.256471
tensor(0.0077, device='cuda:0') tensor(0.0412, device='cuda:0') tensor(-8.5905e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.144509
Average KL loss: 0.107632
Average total loss: 0.252141
tensor(0.0077, device='cuda:0') tensor(0.0413, device='cuda:0') tensor(-2.3760e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.145282
Average KL loss: 0.107615
Average total loss: 0.252896
tensor(0.0078, device='cuda:0') tensor(0.0414, device='cuda:0') tensor(-9.0689e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.141532
Average KL loss: 0.107605
Average total loss: 0.249137
tensor(0.0078, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(-2.8218e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.146648
Average KL loss: 0.107596
Average total loss: 0.254244
tensor(0.0078, device='cuda:0') tensor(0.0417, device='cuda:0') tensor(-1.1928e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.144540
Average KL loss: 0.107583
Average total loss: 0.252123
tensor(0.0078, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-3.4966e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.161112
Average KL loss: 0.107576
Average total loss: 0.268688
tensor(0.0078, device='cuda:0') tensor(0.0419, device='cuda:0') tensor(-3.0762e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.145687
Average KL loss: 0.107570
Average total loss: 0.253257
tensor(0.0078, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(-2.4532e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.142502
Average KL loss: 0.107566
Average total loss: 0.250068
tensor(0.0078, device='cuda:0') tensor(0.0421, device='cuda:0') tensor(-1.5799e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.138471
Average KL loss: 0.107560
Average total loss: 0.246031
tensor(0.0078, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-1.8575e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.138699
Average KL loss: 0.107556
Average total loss: 0.246254
tensor(0.0078, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(-7.3568e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.140343
Average KL loss: 0.107545
Average total loss: 0.247888
tensor(0.0078, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-2.4346e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.145045
Average KL loss: 0.107526
Average total loss: 0.252571
tensor(0.0078, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-1.8383e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.139898
Average KL loss: 0.107523
Average total loss: 0.247421
tensor(0.0078, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-5.6317e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.134352
Average KL loss: 0.107519
Average total loss: 0.241871
tensor(0.0079, device='cuda:0') tensor(0.0428, device='cuda:0') tensor(-6.2472e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.145890
Average KL loss: 0.107528
Average total loss: 0.253418
tensor(0.0079, device='cuda:0') tensor(0.0429, device='cuda:0') tensor(-4.8583e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.152201
Average KL loss: 0.107534
Average total loss: 0.259735
tensor(0.0079, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(-1.4007e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.136231
Average KL loss: 0.107529
Average total loss: 0.243760
tensor(0.0079, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-1.2402e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.140563
Average KL loss: 0.107521
Average total loss: 0.248084
tensor(0.0079, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-2.0010e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.138772
Average KL loss: 0.107518
Average total loss: 0.246289
tensor(0.0079, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(-2.3658e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.133756
Average KL loss: 0.107510
Average total loss: 0.241265
tensor(0.0079, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(-6.4919e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.138740
Average KL loss: 0.107501
Average total loss: 0.246241
tensor(0.0079, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-2.0181e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.134918
Average KL loss: 0.107504
Average total loss: 0.242421
tensor(0.0079, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-2.1220e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.137322
Average KL loss: 0.107506
Average total loss: 0.244827
tensor(0.0079, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-9.4380e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.135059
Average KL loss: 0.107501
Average total loss: 0.242559
tensor(0.0079, device='cuda:0') tensor(0.0438, device='cuda:0') tensor(-6.2621e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.141317
Average KL loss: 0.107499
Average total loss: 0.248816
tensor(0.0079, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-1.3581e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.139740
Average KL loss: 0.107503
Average total loss: 0.247243
tensor(0.0080, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-2.8807e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.138220
Average KL loss: 0.107497
Average total loss: 0.245717
tensor(0.0080, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-1.5506e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.150492
Average KL loss: 0.107488
Average total loss: 0.257979
tensor(0.0080, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-3.7723e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.141026
Average KL loss: 0.107479
Average total loss: 0.248505
tensor(0.0080, device='cuda:0') tensor(0.0444, device='cuda:0') tensor(-5.4752e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.139594
Average KL loss: 0.107479
Average total loss: 0.247073
tensor(0.0080, device='cuda:0') tensor(0.0445, device='cuda:0') tensor(-1.8841e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.141509
Average KL loss: 0.107480
Average total loss: 0.248989
tensor(0.0080, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-2.0027e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.133104
Average KL loss: 0.107481
Average total loss: 0.240585
tensor(0.0080, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-2.4442e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.137355
Average KL loss: 0.107482
Average total loss: 0.244836
tensor(0.0080, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-1.2242e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.137789
Average KL loss: 0.107482
Average total loss: 0.245271
tensor(0.0080, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-2.0002e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.134370
Average KL loss: 0.107482
Average total loss: 0.241852
tensor(0.0080, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-2.2969e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.134218
Average KL loss: 0.107482
Average total loss: 0.241700
tensor(0.0080, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-2.0594e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.134067
Average KL loss: 0.107482
Average total loss: 0.241549
tensor(0.0080, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-9.7271e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.141171
Average KL loss: 0.107482
Average total loss: 0.248653
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-5.0876e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.137011
Average KL loss: 0.107482
Average total loss: 0.244493
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.4398e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.134517
Average KL loss: 0.107481
Average total loss: 0.241998
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-2.4519e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.136710
Average KL loss: 0.107480
Average total loss: 0.244191
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-5.5551e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.135744
Average KL loss: 0.107480
Average total loss: 0.243224
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.5887e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.135444
Average KL loss: 0.107479
Average total loss: 0.242924
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.2038e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.137202
Average KL loss: 0.107479
Average total loss: 0.244681
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-4.3047e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.135747
Average KL loss: 0.107479
Average total loss: 0.243226
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.6332e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.137057
Average KL loss: 0.107479
Average total loss: 0.244536
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.2984e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.138559
Average KL loss: 0.107479
Average total loss: 0.246038
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.3086e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.136549
Average KL loss: 0.107479
Average total loss: 0.244028
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-5.6646e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.135109
Average KL loss: 0.107479
Average total loss: 0.242588
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-2.8222e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.135802
Average KL loss: 0.107479
Average total loss: 0.243281
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.2809e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.137240
Average KL loss: 0.107479
Average total loss: 0.244719
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-5.0511e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.135539
Average KL loss: 0.107479
Average total loss: 0.243018
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.0779e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.144557
Average KL loss: 0.107479
Average total loss: 0.252035
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.1557e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.134455
Average KL loss: 0.107479
Average total loss: 0.241934
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.2580e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.137200
Average KL loss: 0.107479
Average total loss: 0.244679
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-5.2826e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.141465
Average KL loss: 0.107479
Average total loss: 0.248944
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.2557e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.134093
Average KL loss: 0.107479
Average total loss: 0.241572
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-2.3020e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.136175
Average KL loss: 0.107479
Average total loss: 0.243654
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.0601e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.133225
Average KL loss: 0.107479
Average total loss: 0.240704
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-4.5771e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.133134
Average KL loss: 0.107479
Average total loss: 0.240613
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.7224e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.134941
Average KL loss: 0.107479
Average total loss: 0.242420
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-7.9769e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.136847
Average KL loss: 0.107479
Average total loss: 0.244326
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.5113e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.144352
Average KL loss: 0.107479
Average total loss: 0.251831
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-2.5763e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.133436
Average KL loss: 0.107479
Average total loss: 0.240915
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-2.6457e-09, device='cuda:0')
 Percentile value: 6.00422477722168
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =      58 /    1728             (  3.36%) | total_pruned =    1670 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
bn1.bias             | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      26 /   36864             (  0.07%) | total_pruned =   36838 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      49 /   36864             (  0.13%) | total_pruned =   36815 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      75 /   36864             (  0.20%) | total_pruned =   36789 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     111 /   36864             (  0.30%) | total_pruned =   36753 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     332 /   73728             (  0.45%) | total_pruned =   73396 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     569 /  147456             (  0.39%) | total_pruned =  146887 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      76 /    8192             (  0.93%) | total_pruned =    8116 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     599 /  147456             (  0.41%) | total_pruned =  146857 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     642 /  147456             (  0.44%) | total_pruned =  146814 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1184 /  294912             (  0.40%) | total_pruned =  293728 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1555 /  589824             (  0.26%) | total_pruned =  588269 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     123 /   32768             (  0.38%) | total_pruned =   32645 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     950 /  589824             (  0.16%) | total_pruned =  588874 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     774 /  589824             (  0.13%) | total_pruned =  589050 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     869 / 1179648             (  0.07%) | total_pruned = 1178779 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     233 /     512             ( 45.51%) | total_pruned =     279 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     704 / 2359296             (  0.03%) | total_pruned = 2358592 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      74 /     512             ( 14.45%) | total_pruned =     438 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      15 /  131072             (  0.01%) | total_pruned =  131057 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     324 / 2359296             (  0.01%) | total_pruned = 2358972 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     270 / 2359296             (  0.01%) | total_pruned = 2359026 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
linear.weight        | nonzeros =     128 /    5120             (  2.50%) | total_pruned =    4992 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.669285 Accuracy: 72.68 81.08 % Best test Accuracy: 73.64%
tensor(0.0080, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-2.6649e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.612400
Average KL loss: 0.105254
Average total loss: 0.717654
tensor(0.0073, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.0357e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.617185
Average KL loss: 0.100292
Average total loss: 0.717477
tensor(0.0067, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-4.2773e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.633886
Average KL loss: 0.094049
Average total loss: 0.727935
tensor(0.0061, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-1.0922e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.646337
Average KL loss: 0.085890
Average total loss: 0.732226
tensor(0.0055, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-2.4707e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.656269
Average KL loss: 0.075857
Average total loss: 0.732126
tensor(0.0049, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-2.8618e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.636558
Average KL loss: 0.065571
Average total loss: 0.702128
tensor(0.0044, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.4576e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.650319
Average KL loss: 0.057715
Average total loss: 0.708033
tensor(0.0040, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-7.4605e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.653430
Average KL loss: 0.053646
Average total loss: 0.707076
tensor(0.0038, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-5.1076e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.639444
Average KL loss: 0.052321
Average total loss: 0.691764
tensor(0.0038, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-3.0485e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.642110
Average KL loss: 0.051993
Average total loss: 0.694103
tensor(0.0037, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.1346e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.637013
Average KL loss: 0.051860
Average total loss: 0.688873
tensor(0.0037, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-4.6315e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.645821
Average KL loss: 0.051761
Average total loss: 0.697583
tensor(0.0037, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.9355e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.649250
Average KL loss: 0.051672
Average total loss: 0.700921
tensor(0.0037, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-5.1106e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.624073
Average KL loss: 0.051592
Average total loss: 0.675665
tensor(0.0037, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-1.3593e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.638248
Average KL loss: 0.051519
Average total loss: 0.689767
tensor(0.0037, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-5.2231e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.638457
Average KL loss: 0.051457
Average total loss: 0.689914
tensor(0.0037, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-7.1373e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.631548
Average KL loss: 0.051394
Average total loss: 0.682942
tensor(0.0037, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-1.3796e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.630998
Average KL loss: 0.051333
Average total loss: 0.682331
tensor(0.0037, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-4.4759e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.617812
Average KL loss: 0.051273
Average total loss: 0.669085
tensor(0.0037, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-4.6117e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.637134
Average KL loss: 0.051220
Average total loss: 0.688353
tensor(0.0037, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-2.1746e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.630862
Average KL loss: 0.051174
Average total loss: 0.682036
tensor(0.0037, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-1.7648e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.630380
Average KL loss: 0.051124
Average total loss: 0.681504
tensor(0.0037, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-4.4381e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.637063
Average KL loss: 0.051085
Average total loss: 0.688148
tensor(0.0037, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-3.2927e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.632787
Average KL loss: 0.051043
Average total loss: 0.683831
tensor(0.0037, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-7.5073e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.625703
Average KL loss: 0.050998
Average total loss: 0.676701
tensor(0.0037, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-4.9999e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.631834
Average KL loss: 0.050956
Average total loss: 0.682789
tensor(0.0037, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-4.3776e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.620340
Average KL loss: 0.050918
Average total loss: 0.671258
tensor(0.0037, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-8.6907e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.624124
Average KL loss: 0.050878
Average total loss: 0.675002
tensor(0.0037, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-1.8690e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.622364
Average KL loss: 0.050835
Average total loss: 0.673199
tensor(0.0037, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-2.2381e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.625301
Average KL loss: 0.050794
Average total loss: 0.676095
tensor(0.0037, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-5.8105e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.615152
Average KL loss: 0.050773
Average total loss: 0.665924
tensor(0.0037, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-3.8115e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.619576
Average KL loss: 0.050769
Average total loss: 0.670346
tensor(0.0037, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.0553e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.624894
Average KL loss: 0.050766
Average total loss: 0.675659
tensor(0.0037, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-3.0756e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.622783
Average KL loss: 0.050762
Average total loss: 0.673545
tensor(0.0037, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.9469e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.620659
Average KL loss: 0.050759
Average total loss: 0.671417
tensor(0.0037, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.9766e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.614816
Average KL loss: 0.050756
Average total loss: 0.665572
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.5465e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.625524
Average KL loss: 0.050753
Average total loss: 0.676277
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.4756e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.621383
Average KL loss: 0.050750
Average total loss: 0.672133
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.6144e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.621717
Average KL loss: 0.050747
Average total loss: 0.672464
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-6.3225e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.625263
Average KL loss: 0.050744
Average total loss: 0.676007
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.2477e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.617710
Average KL loss: 0.050741
Average total loss: 0.668451
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-7.3651e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.612569
Average KL loss: 0.050738
Average total loss: 0.663307
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.0519e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.638831
Average KL loss: 0.050735
Average total loss: 0.689566
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.8538e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.624085
Average KL loss: 0.050732
Average total loss: 0.674818
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.9275e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.613607
Average KL loss: 0.050729
Average total loss: 0.664337
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-4.2982e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.619063
Average KL loss: 0.050727
Average total loss: 0.669790
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.3021e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.628755
Average KL loss: 0.050725
Average total loss: 0.679480
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.0133e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.643239
Average KL loss: 0.050722
Average total loss: 0.693962
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-6.6768e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.644119
Average KL loss: 0.050720
Average total loss: 0.694839
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.5498e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.618243
Average KL loss: 0.050717
Average total loss: 0.668960
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.3925e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.632441
Average KL loss: 0.050715
Average total loss: 0.683156
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.9893e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.616694
Average KL loss: 0.050712
Average total loss: 0.667406
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.3538e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.620586
Average KL loss: 0.050709
Average total loss: 0.671296
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.5843e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.616315
Average KL loss: 0.050708
Average total loss: 0.667023
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.5695e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.624337
Average KL loss: 0.050708
Average total loss: 0.675045
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.2242e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.622712
Average KL loss: 0.050708
Average total loss: 0.673420
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-6.4389e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.629424
Average KL loss: 0.050708
Average total loss: 0.680132
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-6.4365e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.617381
Average KL loss: 0.050707
Average total loss: 0.668088
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-5.5668e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.618322
Average KL loss: 0.050707
Average total loss: 0.669030
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.2870e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.617739
Average KL loss: 0.050707
Average total loss: 0.668446
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.6125e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.620272
Average KL loss: 0.050707
Average total loss: 0.670979
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.6324e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.624643
Average KL loss: 0.050706
Average total loss: 0.675349
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-6.0701e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.627407
Average KL loss: 0.050706
Average total loss: 0.678113
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.2699e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.640966
Average KL loss: 0.050706
Average total loss: 0.691672
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-5.0266e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.618443
Average KL loss: 0.050706
Average total loss: 0.669149
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.2703e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.628524
Average KL loss: 0.050706
Average total loss: 0.679229
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-5.9491e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.621666
Average KL loss: 0.050706
Average total loss: 0.672372
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.4010e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.611189
Average KL loss: 0.050706
Average total loss: 0.661895
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.0988e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.612726
Average KL loss: 0.050706
Average total loss: 0.663432
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-7.5483e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.620319
Average KL loss: 0.050706
Average total loss: 0.671025
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.2537e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.626089
Average KL loss: 0.050706
Average total loss: 0.676795
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.7303e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.627133
Average KL loss: 0.050706
Average total loss: 0.677838
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-4.9230e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.617569
Average KL loss: 0.050706
Average total loss: 0.668275
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.9124e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.614128
Average KL loss: 0.050706
Average total loss: 0.664833
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.6671e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.631883
Average KL loss: 0.050706
Average total loss: 0.682589
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.0604e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.625223
Average KL loss: 0.050706
Average total loss: 0.675929
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.6405e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.623696
Average KL loss: 0.050706
Average total loss: 0.674401
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-4.9544e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.622866
Average KL loss: 0.050706
Average total loss: 0.673572
tensor(0.0037, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.0626e-09, device='cuda:0')
 Percentile value: 5.769110202789307
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =      55 /    1728             (  3.18%) | total_pruned =    1673 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
bn1.bias             | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      15 /   36864             (  0.04%) | total_pruned =   36849 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      36 /   36864             (  0.10%) | total_pruned =   36828 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      60 /   36864             (  0.16%) | total_pruned =   36804 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      80 /   36864             (  0.22%) | total_pruned =   36784 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     188 /   73728             (  0.25%) | total_pruned =   73540 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     305 /  147456             (  0.21%) | total_pruned =  147151 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      51 /    8192             (  0.62%) | total_pruned =    8141 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     352 /  147456             (  0.24%) | total_pruned =  147104 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     378 /  147456             (  0.26%) | total_pruned =  147078 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     617 /  294912             (  0.21%) | total_pruned =  294295 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     752 /  589824             (  0.13%) | total_pruned =  589072 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      78 /     256             ( 30.47%) | total_pruned =     178 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      51 /   32768             (  0.16%) | total_pruned =   32717 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     456 /  589824             (  0.08%) | total_pruned =  589368 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     340 /  589824             (  0.06%) | total_pruned =  589484 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     264 / 1179648             (  0.02%) | total_pruned = 1179384 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     194 / 2359296             (  0.01%) | total_pruned = 2359102 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      35 /     512             (  6.84%) | total_pruned =     477 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       6 /  131072             (  0.00%) | total_pruned =  131066 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     147 / 2359296             (  0.01%) | total_pruned = 2359149 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     116 / 2359296             (  0.00%) | total_pruned = 2359180 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
linear.weight        | nonzeros =      76 /    5120             (  1.48%) | total_pruned =    5044 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 0.831050 Accuracy: 68.09 71.48 % Best test Accuracy: 68.40%
