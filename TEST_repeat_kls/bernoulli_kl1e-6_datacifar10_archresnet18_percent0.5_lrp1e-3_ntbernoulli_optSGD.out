Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2564e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302782
Average KL loss: 0.000025
Average total loss: 2.302807
tensor(4.6713e-05, device='cuda:0') tensor(3.9504e-06, device='cuda:0') tensor(-2.3290e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.303063
Average KL loss: 0.000031
Average total loss: 2.303094
tensor(8.0024e-05, device='cuda:0') tensor(8.2500e-06, device='cuda:0') tensor(-2.1282e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.302866
Average KL loss: 0.000037
Average total loss: 2.302903
tensor(0.0001, device='cuda:0') tensor(1.3115e-05, device='cuda:0') tensor(-1.4727e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.302806
Average KL loss: 0.000044
Average total loss: 2.302851
tensor(0.0002, device='cuda:0') tensor(1.8613e-05, device='cuda:0') tensor(-3.6594e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.303020
Average KL loss: 0.000053
Average total loss: 2.303073
tensor(0.0002, device='cuda:0') tensor(2.4828e-05, device='cuda:0') tensor(-3.9616e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.302736
Average KL loss: 0.000061
Average total loss: 2.302797
tensor(0.0002, device='cuda:0') tensor(2.9831e-05, device='cuda:0') tensor(1.4537e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.302354
Average KL loss: 0.000068
Average total loss: 2.302422
tensor(0.0003, device='cuda:0') tensor(3.6534e-05, device='cuda:0') tensor(-1.3342e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.302226
Average KL loss: 0.000080
Average total loss: 2.302306
tensor(0.0003, device='cuda:0') tensor(4.6029e-05, device='cuda:0') tensor(-4.1463e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.302231
Average KL loss: 0.000094
Average total loss: 2.302325
tensor(0.0004, device='cuda:0') tensor(5.6246e-05, device='cuda:0') tensor(-5.4482e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.301798
Average KL loss: 0.000111
Average total loss: 2.301909
tensor(0.0004, device='cuda:0') tensor(7.0107e-05, device='cuda:0') tensor(-3.1837e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.301882
Average KL loss: 0.000130
Average total loss: 2.302012
tensor(0.0005, device='cuda:0') tensor(8.6030e-05, device='cuda:0') tensor(-1.4792e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.301474
Average KL loss: 0.000159
Average total loss: 2.301633
tensor(0.0006, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-1.2243e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.300513
Average KL loss: 0.000194
Average total loss: 2.300707
tensor(0.0008, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-2.2799e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.299997
Average KL loss: 0.000249
Average total loss: 2.300247
tensor(0.0009, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-8.2494e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.299252
Average KL loss: 0.000314
Average total loss: 2.299565
tensor(0.0011, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-8.8204e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.296372
Average KL loss: 0.000419
Average total loss: 2.296790
tensor(0.0014, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-5.2737e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.295230
Average KL loss: 0.000563
Average total loss: 2.295793
tensor(0.0017, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.9521e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.290411
Average KL loss: 0.000769
Average total loss: 2.291180
tensor(0.0021, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-9.0840e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.278108
Average KL loss: 0.001084
Average total loss: 2.279192
tensor(0.0028, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.7990e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.264316
Average KL loss: 0.001581
Average total loss: 2.265897
tensor(0.0037, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-1.7704e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.240437
Average KL loss: 0.002281
Average total loss: 2.242717
tensor(0.0049, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.3316e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.211076
Average KL loss: 0.003257
Average total loss: 2.214332
tensor(0.0063, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.5284e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.161203
Average KL loss: 0.004466
Average total loss: 2.165668
tensor(0.0081, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.8247e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.123493
Average KL loss: 0.005951
Average total loss: 2.129444
tensor(0.0101, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-9.2687e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.064751
Average KL loss: 0.007651
Average total loss: 2.072403
tensor(0.0122, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-8.6358e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.987751
Average KL loss: 0.009567
Average total loss: 1.997318
tensor(0.0146, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.0276e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.928386
Average KL loss: 0.011600
Average total loss: 1.939985
tensor(0.0169, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.0217e-07, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.855002
Average KL loss: 0.013586
Average total loss: 1.868588
tensor(0.0192, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-9.0008e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.783538
Average KL loss: 0.015563
Average total loss: 1.799101
tensor(0.0214, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.0787e-07, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.722905
Average KL loss: 0.017502
Average total loss: 1.740407
tensor(0.0234, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.0098e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.667740
Average KL loss: 0.019230
Average total loss: 1.686971
tensor(0.0252, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.2783e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.600805
Average KL loss: 0.020837
Average total loss: 1.621642
tensor(0.0269, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.1994e-07, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.555914
Average KL loss: 0.022284
Average total loss: 1.578199
tensor(0.0283, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-1.2469e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.522933
Average KL loss: 0.023668
Average total loss: 1.546601
tensor(0.0297, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.1804e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.467543
Average KL loss: 0.025002
Average total loss: 1.492544
tensor(0.0309, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-1.0476e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.418816
Average KL loss: 0.026163
Average total loss: 1.444980
tensor(0.0321, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-1.0980e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.367973
Average KL loss: 0.027253
Average total loss: 1.395226
tensor(0.0331, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.1747e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.334822
Average KL loss: 0.028254
Average total loss: 1.363076
tensor(0.0341, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.1532e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.307060
Average KL loss: 0.029155
Average total loss: 1.336215
tensor(0.0350, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-1.1632e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.267597
Average KL loss: 0.030052
Average total loss: 1.297649
tensor(0.0357, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-1.1045e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.225771
Average KL loss: 0.030872
Average total loss: 1.256643
tensor(0.0365, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-1.2778e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.215007
Average KL loss: 0.031630
Average total loss: 1.246637
tensor(0.0372, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-9.8280e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.160442
Average KL loss: 0.032337
Average total loss: 1.192779
tensor(0.0378, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-9.8589e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.146834
Average KL loss: 0.033043
Average total loss: 1.179876
tensor(0.0384, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.0353e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.120365
Average KL loss: 0.033707
Average total loss: 1.154071
tensor(0.0389, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.1096e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.095364
Average KL loss: 0.034286
Average total loss: 1.129650
tensor(0.0394, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-8.8279e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.068173
Average KL loss: 0.034783
Average total loss: 1.102956
tensor(0.0398, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.0194e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.042214
Average KL loss: 0.035216
Average total loss: 1.077431
tensor(0.0401, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-9.6662e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.039082
Average KL loss: 0.035651
Average total loss: 1.074732
tensor(0.0405, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-9.7880e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.001082
Average KL loss: 0.036047
Average total loss: 1.037129
tensor(0.0408, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-8.9248e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.988911
Average KL loss: 0.036435
Average total loss: 1.025346
tensor(0.0412, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-9.7411e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.976906
Average KL loss: 0.036786
Average total loss: 1.013692
tensor(0.0414, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-8.6533e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.958071
Average KL loss: 0.037092
Average total loss: 0.995163
tensor(0.0416, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-8.3039e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.967403
Average KL loss: 0.037376
Average total loss: 1.004779
tensor(0.0418, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-8.0493e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.924219
Average KL loss: 0.037658
Average total loss: 0.961877
tensor(0.0420, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-8.1065e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.920717
Average KL loss: 0.037919
Average total loss: 0.958637
tensor(0.0423, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-8.2605e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.904248
Average KL loss: 0.038190
Average total loss: 0.942438
tensor(0.0425, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-8.3478e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.896236
Average KL loss: 0.038414
Average total loss: 0.934650
tensor(0.0426, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-7.9102e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.875799
Average KL loss: 0.038620
Average total loss: 0.914418
tensor(0.0428, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-8.4061e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.883353
Average KL loss: 0.038827
Average total loss: 0.922180
tensor(0.0429, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-7.3901e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.838313
Average KL loss: 0.039007
Average total loss: 0.877320
tensor(0.0430, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-6.7896e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.852562
Average KL loss: 0.039151
Average total loss: 0.891713
tensor(0.0431, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-8.4762e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.819463
Average KL loss: 0.039292
Average total loss: 0.858754
tensor(0.0432, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-7.6574e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.808149
Average KL loss: 0.039370
Average total loss: 0.847519
tensor(0.0432, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-6.2166e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.806745
Average KL loss: 0.039470
Average total loss: 0.846216
tensor(0.0433, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-7.5067e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.807368
Average KL loss: 0.039558
Average total loss: 0.846926
tensor(0.0434, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-8.8495e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.779446
Average KL loss: 0.039643
Average total loss: 0.819089
tensor(0.0434, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-6.5174e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.771159
Average KL loss: 0.039698
Average total loss: 0.810857
tensor(0.0435, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-7.1202e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.767299
Average KL loss: 0.039756
Average total loss: 0.807055
tensor(0.0435, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-7.0393e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.760016
Average KL loss: 0.039803
Average total loss: 0.799819
tensor(0.0435, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-7.3812e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.743902
Average KL loss: 0.039870
Average total loss: 0.783773
tensor(0.0436, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-6.2863e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.755871
Average KL loss: 0.039941
Average total loss: 0.795812
tensor(0.0436, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-6.4116e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.736324
Average KL loss: 0.040000
Average total loss: 0.776324
tensor(0.0437, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-6.7745e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.709217
Average KL loss: 0.040033
Average total loss: 0.749250
tensor(0.0437, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-7.2027e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.719273
Average KL loss: 0.040056
Average total loss: 0.759329
tensor(0.0437, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-6.4730e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.710064
Average KL loss: 0.040083
Average total loss: 0.750147
tensor(0.0437, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-7.5495e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.702907
Average KL loss: 0.040117
Average total loss: 0.743024
tensor(0.0438, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-6.0997e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.698668
Average KL loss: 0.040126
Average total loss: 0.738794
tensor(0.0437, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-5.8844e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.680803
Average KL loss: 0.040127
Average total loss: 0.720930
tensor(0.0437, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-4.9719e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.679843
Average KL loss: 0.040134
Average total loss: 0.719977
tensor(0.0438, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-5.6708e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.676070
Average KL loss: 0.040147
Average total loss: 0.716217
tensor(0.0438, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.2756e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.662571
Average KL loss: 0.040155
Average total loss: 0.702726
tensor(0.0438, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.6372e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.661949
Average KL loss: 0.040163
Average total loss: 0.702113
tensor(0.0437, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.5281e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.659755
Average KL loss: 0.040164
Average total loss: 0.699919
tensor(0.0437, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-7.0966e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.640530
Average KL loss: 0.040149
Average total loss: 0.680679
tensor(0.0437, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-6.0415e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.633254
Average KL loss: 0.040131
Average total loss: 0.673385
tensor(0.0437, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.3450e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.638935
Average KL loss: 0.040107
Average total loss: 0.679042
tensor(0.0437, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-6.7831e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.620075
Average KL loss: 0.040082
Average total loss: 0.660157
tensor(0.0437, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-4.7585e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.616078
Average KL loss: 0.040059
Average total loss: 0.656138
tensor(0.0437, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.8711e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.612584
Average KL loss: 0.040054
Average total loss: 0.652638
tensor(0.0437, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.5039e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.626269
Average KL loss: 0.040053
Average total loss: 0.666322
tensor(0.0436, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-6.0856e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.604813
Average KL loss: 0.040045
Average total loss: 0.644859
tensor(0.0436, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.9337e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.593654
Average KL loss: 0.040013
Average total loss: 0.633667
tensor(0.0436, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.1511e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.600248
Average KL loss: 0.039974
Average total loss: 0.640222
tensor(0.0436, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.3753e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.596760
Average KL loss: 0.039952
Average total loss: 0.636712
tensor(0.0436, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-4.7472e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.579844
Average KL loss: 0.039931
Average total loss: 0.619775
tensor(0.0435, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.5323e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.584282
Average KL loss: 0.039907
Average total loss: 0.624189
tensor(0.0435, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-5.1510e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.574378
Average KL loss: 0.039893
Average total loss: 0.614272
tensor(0.0435, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.9546e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.570405
Average KL loss: 0.039872
Average total loss: 0.610278
tensor(0.0435, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.9781e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.568127
Average KL loss: 0.039865
Average total loss: 0.607991
tensor(0.0435, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.5046e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.552676
Average KL loss: 0.039841
Average total loss: 0.592517
tensor(0.0435, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.8675e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.554073
Average KL loss: 0.039813
Average total loss: 0.593886
tensor(0.0434, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-5.1899e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.554345
Average KL loss: 0.039786
Average total loss: 0.594130
tensor(0.0434, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.7863e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.533424
Average KL loss: 0.039764
Average total loss: 0.573188
tensor(0.0434, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.8497e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.530494
Average KL loss: 0.039738
Average total loss: 0.570232
tensor(0.0434, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-5.3240e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.524863
Average KL loss: 0.039712
Average total loss: 0.564575
tensor(0.0434, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.7217e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.530110
Average KL loss: 0.039674
Average total loss: 0.569784
tensor(0.0433, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-6.6022e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.527861
Average KL loss: 0.039640
Average total loss: 0.567500
tensor(0.0433, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.7501e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.519686
Average KL loss: 0.039606
Average total loss: 0.559292
tensor(0.0433, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-6.3199e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.511787
Average KL loss: 0.039570
Average total loss: 0.551357
tensor(0.0432, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-4.5246e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.510813
Average KL loss: 0.039533
Average total loss: 0.550346
tensor(0.0432, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-4.0167e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.503996
Average KL loss: 0.039521
Average total loss: 0.543518
tensor(0.0432, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.4683e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.507610
Average KL loss: 0.039484
Average total loss: 0.547094
tensor(0.0431, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-4.4712e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.497763
Average KL loss: 0.039457
Average total loss: 0.537220
tensor(0.0431, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.6890e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.490582
Average KL loss: 0.039440
Average total loss: 0.530022
tensor(0.0431, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-4.7347e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.494010
Average KL loss: 0.039401
Average total loss: 0.533411
tensor(0.0430, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-4.5619e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.480343
Average KL loss: 0.039372
Average total loss: 0.519715
tensor(0.0430, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.4627e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.487216
Average KL loss: 0.039338
Average total loss: 0.526555
tensor(0.0430, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.5515e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.479553
Average KL loss: 0.039318
Average total loss: 0.518870
tensor(0.0430, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.2668e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.471558
Average KL loss: 0.039290
Average total loss: 0.510848
tensor(0.0429, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-4.0388e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.476503
Average KL loss: 0.039260
Average total loss: 0.515763
tensor(0.0429, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.7103e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.477870
Average KL loss: 0.039250
Average total loss: 0.517120
tensor(0.0429, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.9493e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.472336
Average KL loss: 0.039233
Average total loss: 0.511569
tensor(0.0429, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.6397e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.454699
Average KL loss: 0.039208
Average total loss: 0.493907
tensor(0.0429, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.7932e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.461405
Average KL loss: 0.039195
Average total loss: 0.500600
tensor(0.0429, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.2166e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.447705
Average KL loss: 0.039159
Average total loss: 0.486864
tensor(0.0428, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-5.3089e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.455905
Average KL loss: 0.039131
Average total loss: 0.495036
tensor(0.0428, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.6350e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.451691
Average KL loss: 0.039101
Average total loss: 0.490793
tensor(0.0427, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.1237e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.447439
Average KL loss: 0.039078
Average total loss: 0.486517
tensor(0.0427, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.0227e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.436648
Average KL loss: 0.039045
Average total loss: 0.475694
tensor(0.0427, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.1447e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.446976
Average KL loss: 0.039009
Average total loss: 0.485985
tensor(0.0426, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.6390e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.433038
Average KL loss: 0.038994
Average total loss: 0.472033
tensor(0.0426, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-2.9647e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.439144
Average KL loss: 0.038967
Average total loss: 0.478110
tensor(0.0426, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.6718e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.437528
Average KL loss: 0.038955
Average total loss: 0.476483
tensor(0.0426, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.6122e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.422113
Average KL loss: 0.038949
Average total loss: 0.461062
tensor(0.0426, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.0287e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.420656
Average KL loss: 0.038931
Average total loss: 0.459587
tensor(0.0426, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.1250e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.421540
Average KL loss: 0.038912
Average total loss: 0.460451
tensor(0.0425, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.4275e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.422711
Average KL loss: 0.038894
Average total loss: 0.461605
tensor(0.0425, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.4002e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.413128
Average KL loss: 0.038885
Average total loss: 0.452013
tensor(0.0425, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.3776e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.407098
Average KL loss: 0.038868
Average total loss: 0.445965
tensor(0.0425, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-3.6337e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.410526
Average KL loss: 0.038853
Average total loss: 0.449379
tensor(0.0425, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.5226e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.409529
Average KL loss: 0.038845
Average total loss: 0.448373
tensor(0.0425, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-4.6855e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.403293
Average KL loss: 0.038840
Average total loss: 0.442133
tensor(0.0425, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.0974e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.406270
Average KL loss: 0.038826
Average total loss: 0.445096
tensor(0.0425, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.3860e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.397786
Average KL loss: 0.038816
Average total loss: 0.436602
tensor(0.0424, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-4.3037e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.393650
Average KL loss: 0.038790
Average total loss: 0.432441
tensor(0.0424, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.9703e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.394738
Average KL loss: 0.038765
Average total loss: 0.433503
tensor(0.0423, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-2.5815e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.390428
Average KL loss: 0.038742
Average total loss: 0.429170
tensor(0.0423, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.4965e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.377658
Average KL loss: 0.038722
Average total loss: 0.416380
tensor(0.0423, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.2077e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.382889
Average KL loss: 0.038704
Average total loss: 0.421593
tensor(0.0423, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.7276e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.384547
Average KL loss: 0.038687
Average total loss: 0.423234
tensor(0.0423, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.4671e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.381345
Average KL loss: 0.038679
Average total loss: 0.420024
tensor(0.0423, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-2.6497e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.367658
Average KL loss: 0.038660
Average total loss: 0.406318
tensor(0.0422, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-4.7647e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.379642
Average KL loss: 0.038639
Average total loss: 0.418281
tensor(0.0422, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-2.4887e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.380063
Average KL loss: 0.038624
Average total loss: 0.418686
tensor(0.0422, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-2.7731e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.358509
Average KL loss: 0.038617
Average total loss: 0.397126
tensor(0.0422, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-3.4293e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.360304
Average KL loss: 0.038596
Average total loss: 0.398900
tensor(0.0422, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-3.1534e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.364150
Average KL loss: 0.038582
Average total loss: 0.402731
tensor(0.0421, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-3.6954e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.365927
Average KL loss: 0.038569
Average total loss: 0.404496
tensor(0.0421, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-2.8178e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.366960
Average KL loss: 0.038567
Average total loss: 0.405527
tensor(0.0421, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-2.2698e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.354158
Average KL loss: 0.038563
Average total loss: 0.392721
tensor(0.0421, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-2.9029e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.359436
Average KL loss: 0.038561
Average total loss: 0.397997
tensor(0.0421, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-2.3413e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.359493
Average KL loss: 0.038567
Average total loss: 0.398060
tensor(0.0421, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-2.5581e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.349822
Average KL loss: 0.038560
Average total loss: 0.388383
tensor(0.0421, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-2.7210e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.349758
Average KL loss: 0.038546
Average total loss: 0.388304
tensor(0.0421, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-3.5863e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.353404
Average KL loss: 0.038545
Average total loss: 0.391949
tensor(0.0421, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-3.2425e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.343809
Average KL loss: 0.038543
Average total loss: 0.382352
tensor(0.0420, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-2.4101e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.339771
Average KL loss: 0.038528
Average total loss: 0.378299
tensor(0.0420, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-2.5334e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.337865
Average KL loss: 0.038505
Average total loss: 0.376370
tensor(0.0420, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-2.0292e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.335044
Average KL loss: 0.038498
Average total loss: 0.373542
tensor(0.0420, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-3.0992e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.333704
Average KL loss: 0.038490
Average total loss: 0.372194
tensor(0.0420, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-3.8212e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.338111
Average KL loss: 0.038491
Average total loss: 0.376602
tensor(0.0420, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-2.6922e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.328183
Average KL loss: 0.038488
Average total loss: 0.366671
tensor(0.0419, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-2.9089e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.328973
Average KL loss: 0.038479
Average total loss: 0.367452
tensor(0.0419, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-3.1285e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.327448
Average KL loss: 0.038466
Average total loss: 0.365914
tensor(0.0419, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-3.1217e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.327467
Average KL loss: 0.038466
Average total loss: 0.365933
tensor(0.0419, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-3.0867e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.324792
Average KL loss: 0.038452
Average total loss: 0.363244
tensor(0.0419, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-2.4051e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.324698
Average KL loss: 0.038448
Average total loss: 0.363146
tensor(0.0419, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-2.7644e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.315285
Average KL loss: 0.038446
Average total loss: 0.353731
tensor(0.0418, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-2.9933e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.318289
Average KL loss: 0.038441
Average total loss: 0.356731
tensor(0.0418, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-2.3203e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.319785
Average KL loss: 0.038427
Average total loss: 0.358211
tensor(0.0418, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-2.7832e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.313100
Average KL loss: 0.038418
Average total loss: 0.351518
tensor(0.0418, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-2.1722e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.313803
Average KL loss: 0.038415
Average total loss: 0.352218
tensor(0.0418, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-2.1284e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.310348
Average KL loss: 0.038417
Average total loss: 0.348765
tensor(0.0418, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-3.5717e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.312595
Average KL loss: 0.038417
Average total loss: 0.351013
tensor(0.0418, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-2.3709e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.307004
Average KL loss: 0.038405
Average total loss: 0.345410
tensor(0.0417, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-2.2819e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.306633
Average KL loss: 0.038397
Average total loss: 0.345030
tensor(0.0417, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-2.5897e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.308784
Average KL loss: 0.038395
Average total loss: 0.347178
tensor(0.0417, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-2.3504e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.299247
Average KL loss: 0.038392
Average total loss: 0.337639
tensor(0.0417, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-2.0511e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.296814
Average KL loss: 0.038388
Average total loss: 0.335202
tensor(0.0417, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-2.1319e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.296137
Average KL loss: 0.038378
Average total loss: 0.334516
tensor(0.0417, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-2.1337e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.297356
Average KL loss: 0.038378
Average total loss: 0.335734
tensor(0.0417, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-2.3496e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.290575
Average KL loss: 0.038373
Average total loss: 0.328948
tensor(0.0417, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-2.4175e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.294891
Average KL loss: 0.038377
Average total loss: 0.333268
tensor(0.0417, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-3.1474e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.296172
Average KL loss: 0.038374
Average total loss: 0.334546
tensor(0.0416, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-2.8936e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.293126
Average KL loss: 0.038376
Average total loss: 0.331502
tensor(0.0416, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-2.1814e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.286440
Average KL loss: 0.038372
Average total loss: 0.324812
tensor(0.0416, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-1.9545e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.286726
Average KL loss: 0.038369
Average total loss: 0.325095
tensor(0.0416, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-2.2232e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.287818
Average KL loss: 0.038372
Average total loss: 0.326190
tensor(0.0416, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-2.0735e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.285312
Average KL loss: 0.038373
Average total loss: 0.323685
 Percentile value: 0.05558774992823601
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =     473 /    1728             ( 27.37%) | total_pruned =    1255 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6404 /   36864             ( 17.37%) | total_pruned =   30460 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   16469 /   36864             ( 44.68%) | total_pruned =   20395 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   15704 /   36864             ( 42.60%) | total_pruned =   21160 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   19819 /   36864             ( 53.76%) | total_pruned =   17045 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   42289 /   73728             ( 57.36%) | total_pruned =   31439 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   86141 /  147456             ( 58.42%) | total_pruned =   61315 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5052 /    8192             ( 61.67%) | total_pruned =    3140 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   75030 /  147456             ( 50.88%) | total_pruned =   72426 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   74544 /  147456             ( 50.55%) | total_pruned =   72912 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  163454 /  294912             ( 55.42%) | total_pruned =  131458 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  324842 /  589824             ( 55.07%) | total_pruned =  264982 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19794 /   32768             ( 60.41%) | total_pruned =   12974 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  305773 /  589824             ( 51.84%) | total_pruned =  284051 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  298622 /  589824             ( 50.63%) | total_pruned =  291202 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  603760 / 1179648             ( 51.18%) | total_pruned =  575888 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1122280 / 2359296             ( 47.57%) | total_pruned = 1237016 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     308 /     512             ( 60.16%) | total_pruned =     204 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   64739 /  131072             ( 49.39%) | total_pruned =   66333 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     302 /     512             ( 58.98%) | total_pruned =     210 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1015656 / 2359296             ( 43.05%) | total_pruned = 1343640 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1317277 / 2359296             ( 55.83%) | total_pruned = 1042019 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5003 /    5120             ( 97.71%) | total_pruned =     117 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 50/100 Loss: 0.014377 Accuracy: 90.11 100.00 % Best test Accuracy: 90.25%
tensor(0.0416, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-1.0392e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.541162
Average KL loss: 0.036795
Average total loss: 0.577957
tensor(0.0445, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-7.3847e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.523318
Average KL loss: 0.034574
Average total loss: 0.557891
tensor(0.0470, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-8.5552e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.520406
Average KL loss: 0.033080
Average total loss: 0.553485
tensor(0.0487, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-6.5134e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.494694
Average KL loss: 0.032037
Average total loss: 0.526730
tensor(0.0498, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-7.3029e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.469859
Average KL loss: 0.031290
Average total loss: 0.501149
tensor(0.0507, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-5.7293e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.479513
Average KL loss: 0.030746
Average total loss: 0.510259
tensor(0.0513, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-5.4663e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.442474
Average KL loss: 0.030367
Average total loss: 0.472841
tensor(0.0518, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-7.7521e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.448557
Average KL loss: 0.030096
Average total loss: 0.478654
tensor(0.0521, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-6.0646e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.423310
Average KL loss: 0.029921
Average total loss: 0.453231
tensor(0.0524, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-6.4315e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.423620
Average KL loss: 0.029793
Average total loss: 0.453413
tensor(0.0525, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-5.2284e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.424652
Average KL loss: 0.029718
Average total loss: 0.454369
tensor(0.0526, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-5.6030e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.425629
Average KL loss: 0.029681
Average total loss: 0.455310
tensor(0.0527, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-6.6921e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.400368
Average KL loss: 0.029676
Average total loss: 0.430045
tensor(0.0527, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-3.7324e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.392942
Average KL loss: 0.029691
Average total loss: 0.422633
tensor(0.0528, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-6.3889e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.383221
Average KL loss: 0.029712
Average total loss: 0.412933
tensor(0.0528, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-3.8275e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.392963
Average KL loss: 0.029760
Average total loss: 0.422722
tensor(0.0527, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-4.9832e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.379082
Average KL loss: 0.029817
Average total loss: 0.408898
tensor(0.0527, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-3.8987e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.373448
Average KL loss: 0.029885
Average total loss: 0.403333
tensor(0.0527, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-3.5378e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.358594
Average KL loss: 0.029950
Average total loss: 0.388544
tensor(0.0526, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-4.2981e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.354863
Average KL loss: 0.030014
Average total loss: 0.384877
tensor(0.0526, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-4.6141e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.362108
Average KL loss: 0.030101
Average total loss: 0.392209
tensor(0.0525, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-5.3878e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.350504
Average KL loss: 0.030192
Average total loss: 0.380696
tensor(0.0525, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-4.2446e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.341340
Average KL loss: 0.030278
Average total loss: 0.371618
tensor(0.0524, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-4.7543e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.359651
Average KL loss: 0.030373
Average total loss: 0.390024
tensor(0.0524, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-3.9202e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.342725
Average KL loss: 0.030470
Average total loss: 0.373195
tensor(0.0523, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-5.2721e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.346869
Average KL loss: 0.030559
Average total loss: 0.377427
tensor(0.0523, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.5092e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.343720
Average KL loss: 0.030646
Average total loss: 0.374366
tensor(0.0522, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-4.8159e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.330195
Average KL loss: 0.030725
Average total loss: 0.360919
tensor(0.0521, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-3.4543e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.329260
Average KL loss: 0.030812
Average total loss: 0.360072
tensor(0.0520, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-3.7132e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.330915
Average KL loss: 0.030896
Average total loss: 0.361811
tensor(0.0520, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-3.7413e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.318827
Average KL loss: 0.030989
Average total loss: 0.349816
tensor(0.0519, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-4.5630e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.317882
Average KL loss: 0.031076
Average total loss: 0.348958
tensor(0.0519, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-3.1129e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.316236
Average KL loss: 0.031160
Average total loss: 0.347396
tensor(0.0518, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-2.9545e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.318766
Average KL loss: 0.031239
Average total loss: 0.350006
tensor(0.0518, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-3.2414e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.306156
Average KL loss: 0.031318
Average total loss: 0.337475
tensor(0.0517, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.8583e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.297833
Average KL loss: 0.031391
Average total loss: 0.329224
tensor(0.0516, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.5100e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.308622
Average KL loss: 0.031473
Average total loss: 0.340095
tensor(0.0516, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.8367e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.303940
Average KL loss: 0.031565
Average total loss: 0.335504
tensor(0.0515, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-3.0453e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.298177
Average KL loss: 0.031649
Average total loss: 0.329825
tensor(0.0515, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-3.7314e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.303666
Average KL loss: 0.031728
Average total loss: 0.335394
tensor(0.0514, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.7656e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.287909
Average KL loss: 0.031815
Average total loss: 0.319723
tensor(0.0514, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-3.2329e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.291661
Average KL loss: 0.031896
Average total loss: 0.323557
tensor(0.0514, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-4.7299e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.291502
Average KL loss: 0.031970
Average total loss: 0.323473
tensor(0.0513, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-3.0193e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.277997
Average KL loss: 0.032045
Average total loss: 0.310042
tensor(0.0513, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-3.0780e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.278349
Average KL loss: 0.032117
Average total loss: 0.310466
tensor(0.0512, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-3.6014e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.286181
Average KL loss: 0.032183
Average total loss: 0.318364
tensor(0.0512, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.9726e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.278785
Average KL loss: 0.032247
Average total loss: 0.311032
tensor(0.0511, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-4.6641e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.277295
Average KL loss: 0.032313
Average total loss: 0.309608
tensor(0.0511, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-3.4492e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.273642
Average KL loss: 0.032376
Average total loss: 0.306017
tensor(0.0510, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-2.0393e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.263503
Average KL loss: 0.032439
Average total loss: 0.295942
tensor(0.0509, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-2.8584e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.269849
Average KL loss: 0.032489
Average total loss: 0.302338
tensor(0.0509, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-2.5407e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.264402
Average KL loss: 0.032553
Average total loss: 0.296955
tensor(0.0509, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-2.5147e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.261658
Average KL loss: 0.032618
Average total loss: 0.294277
tensor(0.0508, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-2.4243e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.263351
Average KL loss: 0.032681
Average total loss: 0.296031
tensor(0.0508, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-2.3319e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.260965
Average KL loss: 0.032741
Average total loss: 0.293705
tensor(0.0507, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-2.7643e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.267675
Average KL loss: 0.032796
Average total loss: 0.300471
tensor(0.0507, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-2.8739e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.259173
Average KL loss: 0.032864
Average total loss: 0.292038
tensor(0.0506, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-2.8294e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.252731
Average KL loss: 0.032925
Average total loss: 0.285656
tensor(0.0506, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-3.0292e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.249875
Average KL loss: 0.032978
Average total loss: 0.282853
tensor(0.0505, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-3.5747e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.262646
Average KL loss: 0.033035
Average total loss: 0.295681
tensor(0.0505, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.3281e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.253616
Average KL loss: 0.033103
Average total loss: 0.286719
tensor(0.0505, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.2700e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.246001
Average KL loss: 0.033162
Average total loss: 0.279163
tensor(0.0504, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-2.4841e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.240328
Average KL loss: 0.033210
Average total loss: 0.273538
tensor(0.0504, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-2.3751e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.245927
Average KL loss: 0.033257
Average total loss: 0.279184
tensor(0.0503, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-2.5127e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.239839
Average KL loss: 0.033309
Average total loss: 0.273148
tensor(0.0503, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.9088e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.250360
Average KL loss: 0.033353
Average total loss: 0.283713
tensor(0.0502, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.9721e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.244042
Average KL loss: 0.033416
Average total loss: 0.277458
tensor(0.0502, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.8887e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.233093
Average KL loss: 0.033468
Average total loss: 0.266561
tensor(0.0502, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-2.4583e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.235754
Average KL loss: 0.033517
Average total loss: 0.269272
tensor(0.0501, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-2.0656e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.231616
Average KL loss: 0.033557
Average total loss: 0.265173
tensor(0.0501, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-2.7133e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.231816
Average KL loss: 0.033617
Average total loss: 0.265433
tensor(0.0501, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.8179e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.233007
Average KL loss: 0.033663
Average total loss: 0.266670
tensor(0.0500, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.4138e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.234748
Average KL loss: 0.033718
Average total loss: 0.268466
tensor(0.0500, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.3368e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.224857
Average KL loss: 0.033763
Average total loss: 0.258620
tensor(0.0499, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-2.0267e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.229149
Average KL loss: 0.033796
Average total loss: 0.262946
tensor(0.0499, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-1.8460e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.221024
Average KL loss: 0.033830
Average total loss: 0.254854
tensor(0.0498, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-2.9151e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.222346
Average KL loss: 0.033872
Average total loss: 0.256218
tensor(0.0498, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-4.1469e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.217213
Average KL loss: 0.033915
Average total loss: 0.251128
tensor(0.0498, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-2.5233e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.216029
Average KL loss: 0.033958
Average total loss: 0.249987
tensor(0.0497, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-2.9399e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.223280
Average KL loss: 0.033995
Average total loss: 0.257275
tensor(0.0497, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-1.7797e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.212178
Average KL loss: 0.034030
Average total loss: 0.246208
tensor(0.0497, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-5.2008e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.219275
Average KL loss: 0.034068
Average total loss: 0.253343
tensor(0.0496, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.9124e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.209234
Average KL loss: 0.034108
Average total loss: 0.243342
tensor(0.0496, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-2.8022e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.216713
Average KL loss: 0.034143
Average total loss: 0.250856
tensor(0.0495, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-3.0704e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.209415
Average KL loss: 0.034178
Average total loss: 0.243593
tensor(0.0495, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-2.7034e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.202525
Average KL loss: 0.034205
Average total loss: 0.236730
tensor(0.0494, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-2.9227e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.205551
Average KL loss: 0.034240
Average total loss: 0.239791
tensor(0.0494, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-2.6539e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.210275
Average KL loss: 0.034278
Average total loss: 0.244553
tensor(0.0494, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-2.2928e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.206665
Average KL loss: 0.034319
Average total loss: 0.240984
tensor(0.0493, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.2004e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.212256
Average KL loss: 0.034351
Average total loss: 0.246607
tensor(0.0493, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.6975e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.205144
Average KL loss: 0.034386
Average total loss: 0.239530
tensor(0.0493, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-1.9348e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.200671
Average KL loss: 0.034418
Average total loss: 0.235089
tensor(0.0492, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-2.1444e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.199362
Average KL loss: 0.034458
Average total loss: 0.233820
tensor(0.0492, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-2.0066e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.202543
Average KL loss: 0.034489
Average total loss: 0.237032
tensor(0.0491, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-1.8165e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.199182
Average KL loss: 0.034525
Average total loss: 0.233707
tensor(0.0491, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-2.9369e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.201703
Average KL loss: 0.034568
Average total loss: 0.236271
tensor(0.0491, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-1.8459e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.203841
Average KL loss: 0.034609
Average total loss: 0.238450
tensor(0.0491, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-1.5680e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.191588
Average KL loss: 0.034648
Average total loss: 0.226237
tensor(0.0490, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-1.6890e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.191274
Average KL loss: 0.034678
Average total loss: 0.225952
tensor(0.0490, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-1.7094e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.195378
Average KL loss: 0.034707
Average total loss: 0.230085
tensor(0.0489, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-1.8136e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.189429
Average KL loss: 0.034733
Average total loss: 0.224161
tensor(0.0489, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-1.6536e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.186942
Average KL loss: 0.034758
Average total loss: 0.221701
tensor(0.0489, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.1009e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.194337
Average KL loss: 0.034782
Average total loss: 0.229119
tensor(0.0488, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.8977e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.190714
Average KL loss: 0.034821
Average total loss: 0.225535
tensor(0.0488, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-1.7627e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.193426
Average KL loss: 0.034855
Average total loss: 0.228281
tensor(0.0488, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.9916e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.185632
Average KL loss: 0.034886
Average total loss: 0.220518
tensor(0.0487, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.3384e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.180834
Average KL loss: 0.034907
Average total loss: 0.215742
tensor(0.0487, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.4322e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.181655
Average KL loss: 0.034930
Average total loss: 0.216584
tensor(0.0487, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.8167e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.188481
Average KL loss: 0.034965
Average total loss: 0.223446
tensor(0.0486, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.9005e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.189340
Average KL loss: 0.035005
Average total loss: 0.224345
tensor(0.0486, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-1.3981e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.179413
Average KL loss: 0.035032
Average total loss: 0.214445
tensor(0.0486, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-1.5304e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.178120
Average KL loss: 0.035052
Average total loss: 0.213172
tensor(0.0485, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.4376e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.174601
Average KL loss: 0.035076
Average total loss: 0.209677
tensor(0.0485, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.9672e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.171234
Average KL loss: 0.035103
Average total loss: 0.206338
tensor(0.0485, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.7099e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.182826
Average KL loss: 0.035131
Average total loss: 0.217957
tensor(0.0484, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.3070e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.175596
Average KL loss: 0.035159
Average total loss: 0.210755
tensor(0.0484, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-1.4078e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.180186
Average KL loss: 0.035182
Average total loss: 0.215368
tensor(0.0484, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-1.1547e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.172871
Average KL loss: 0.035206
Average total loss: 0.208077
tensor(0.0483, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-1.8530e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.173583
Average KL loss: 0.035227
Average total loss: 0.208809
tensor(0.0483, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-2.2509e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.172826
Average KL loss: 0.035257
Average total loss: 0.208083
tensor(0.0483, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-1.8665e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.174126
Average KL loss: 0.035288
Average total loss: 0.209414
tensor(0.0482, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-1.4173e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.170892
Average KL loss: 0.035315
Average total loss: 0.206208
tensor(0.0482, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-1.4880e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.173596
Average KL loss: 0.035342
Average total loss: 0.208939
tensor(0.0482, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-1.6777e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.163864
Average KL loss: 0.035365
Average total loss: 0.199229
tensor(0.0481, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-1.4034e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.162693
Average KL loss: 0.035385
Average total loss: 0.198078
tensor(0.0481, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-1.7907e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.165723
Average KL loss: 0.035402
Average total loss: 0.201124
tensor(0.0481, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-1.1360e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.163175
Average KL loss: 0.035423
Average total loss: 0.198598
tensor(0.0480, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-2.1827e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.166262
Average KL loss: 0.035436
Average total loss: 0.201698
tensor(0.0480, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-1.2216e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.166395
Average KL loss: 0.035452
Average total loss: 0.201847
tensor(0.0480, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.8879e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.161070
Average KL loss: 0.035472
Average total loss: 0.196542
tensor(0.0479, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.2098e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.156718
Average KL loss: 0.035487
Average total loss: 0.192205
tensor(0.0479, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.9315e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.157932
Average KL loss: 0.035500
Average total loss: 0.193432
tensor(0.0478, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.6108e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.162502
Average KL loss: 0.035525
Average total loss: 0.198027
tensor(0.0478, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.2579e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.160141
Average KL loss: 0.035555
Average total loss: 0.195696
tensor(0.0478, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.1742e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.159789
Average KL loss: 0.035575
Average total loss: 0.195363
tensor(0.0477, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.5364e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.160617
Average KL loss: 0.035592
Average total loss: 0.196210
tensor(0.0477, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-1.1912e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.157247
Average KL loss: 0.035615
Average total loss: 0.192862
tensor(0.0477, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-1.3028e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.154322
Average KL loss: 0.035638
Average total loss: 0.189960
tensor(0.0477, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.7524e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.156917
Average KL loss: 0.035659
Average total loss: 0.192577
tensor(0.0476, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.2027e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.156023
Average KL loss: 0.035678
Average total loss: 0.191701
tensor(0.0476, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.2998e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.156052
Average KL loss: 0.035694
Average total loss: 0.191746
tensor(0.0476, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-1.4301e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.152890
Average KL loss: 0.035713
Average total loss: 0.188603
tensor(0.0475, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-1.3124e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.155737
Average KL loss: 0.035728
Average total loss: 0.191464
tensor(0.0475, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.2023e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.154352
Average KL loss: 0.035751
Average total loss: 0.190103
tensor(0.0475, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.4141e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.150173
Average KL loss: 0.035769
Average total loss: 0.185942
tensor(0.0474, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-1.8445e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.153365
Average KL loss: 0.035783
Average total loss: 0.189148
tensor(0.0474, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-2.4192e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.149045
Average KL loss: 0.035795
Average total loss: 0.184840
tensor(0.0473, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-1.5564e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.146052
Average KL loss: 0.035800
Average total loss: 0.181852
tensor(0.0473, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-1.6347e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.150438
Average KL loss: 0.035815
Average total loss: 0.186253
tensor(0.0473, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-1.2802e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.145269
Average KL loss: 0.035830
Average total loss: 0.181099
tensor(0.0473, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-1.1707e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.146532
Average KL loss: 0.035843
Average total loss: 0.182375
tensor(0.0472, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-1.3287e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.143783
Average KL loss: 0.035852
Average total loss: 0.179635
tensor(0.0472, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-5.8279e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.142863
Average KL loss: 0.035864
Average total loss: 0.178728
tensor(0.0471, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-1.5404e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.146847
Average KL loss: 0.035880
Average total loss: 0.182727
tensor(0.0471, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-8.4713e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.144745
Average KL loss: 0.035893
Average total loss: 0.180637
tensor(0.0471, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-9.3898e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.142014
Average KL loss: 0.035903
Average total loss: 0.177917
tensor(0.0471, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-1.0111e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.141653
Average KL loss: 0.035907
Average total loss: 0.177560
tensor(0.0470, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-7.6299e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.140175
Average KL loss: 0.035916
Average total loss: 0.176091
tensor(0.0470, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-1.1303e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.140384
Average KL loss: 0.035925
Average total loss: 0.176308
tensor(0.0469, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.1311e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.143060
Average KL loss: 0.035937
Average total loss: 0.178997
tensor(0.0469, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-7.5605e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.136585
Average KL loss: 0.035944
Average total loss: 0.172529
tensor(0.0469, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.4383e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.140006
Average KL loss: 0.035957
Average total loss: 0.175963
tensor(0.0469, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.3980e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.139430
Average KL loss: 0.035981
Average total loss: 0.175411
tensor(0.0468, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.3550e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.136285
Average KL loss: 0.035997
Average total loss: 0.172282
tensor(0.0468, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-7.9912e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.133197
Average KL loss: 0.035998
Average total loss: 0.169195
tensor(0.0468, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.3261e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.136404
Average KL loss: 0.036009
Average total loss: 0.172414
tensor(0.0467, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-7.4025e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.136207
Average KL loss: 0.036022
Average total loss: 0.172229
tensor(0.0467, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.1007e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.133886
Average KL loss: 0.036038
Average total loss: 0.169924
tensor(0.0467, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-8.4120e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.131183
Average KL loss: 0.036047
Average total loss: 0.167230
tensor(0.0466, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.0707e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.136340
Average KL loss: 0.036052
Average total loss: 0.172392
tensor(0.0466, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-8.3322e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.133598
Average KL loss: 0.036061
Average total loss: 0.169659
tensor(0.0466, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-6.2383e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.133110
Average KL loss: 0.036070
Average total loss: 0.169179
tensor(0.0465, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-6.0786e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.129569
Average KL loss: 0.036077
Average total loss: 0.165646
tensor(0.0465, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-7.1101e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.133130
Average KL loss: 0.036091
Average total loss: 0.169220
tensor(0.0465, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-6.7154e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.132474
Average KL loss: 0.036099
Average total loss: 0.168573
tensor(0.0464, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-1.0143e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.129890
Average KL loss: 0.036114
Average total loss: 0.166003
tensor(0.0464, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-2.1915e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.133144
Average KL loss: 0.036125
Average total loss: 0.169269
tensor(0.0464, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-9.7963e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.129213
Average KL loss: 0.036134
Average total loss: 0.165348
tensor(0.0464, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-8.4010e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.130852
Average KL loss: 0.036149
Average total loss: 0.167000
tensor(0.0463, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-6.1777e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.129402
Average KL loss: 0.036153
Average total loss: 0.165555
tensor(0.0463, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-8.6951e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.125561
Average KL loss: 0.036160
Average total loss: 0.161722
tensor(0.0463, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-8.6019e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.130295
Average KL loss: 0.036169
Average total loss: 0.166464
tensor(0.0462, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-1.0787e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.123869
Average KL loss: 0.036184
Average total loss: 0.160053
tensor(0.0462, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-8.0639e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.124930
Average KL loss: 0.036188
Average total loss: 0.161118
tensor(0.0462, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-1.3417e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.121389
Average KL loss: 0.036191
Average total loss: 0.157580
tensor(0.0461, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-8.2637e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.123881
Average KL loss: 0.036186
Average total loss: 0.160067
tensor(0.0461, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.0641e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.124586
Average KL loss: 0.036191
Average total loss: 0.160777
tensor(0.0461, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.0699e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.124826
Average KL loss: 0.036197
Average total loss: 0.161023
tensor(0.0460, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-6.4890e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.122645
Average KL loss: 0.036203
Average total loss: 0.158848
tensor(0.0460, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-6.9127e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.118313
Average KL loss: 0.036202
Average total loss: 0.154515
tensor(0.0459, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-1.2708e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.118663
Average KL loss: 0.036200
Average total loss: 0.154864
tensor(0.0459, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-9.7239e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.119935
Average KL loss: 0.036199
Average total loss: 0.156134
tensor(0.0459, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-4.4483e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.118411
Average KL loss: 0.036201
Average total loss: 0.154612
tensor(0.0458, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-8.8180e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.119261
Average KL loss: 0.036205
Average total loss: 0.155466
tensor(0.0458, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-1.3844e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.117337
Average KL loss: 0.036210
Average total loss: 0.153548
tensor(0.0458, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-8.9915e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.114884
Average KL loss: 0.036206
Average total loss: 0.151090
tensor(0.0457, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-8.2686e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.121454
Average KL loss: 0.036201
Average total loss: 0.157655
tensor(0.0457, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-8.6446e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.119356
Average KL loss: 0.036212
Average total loss: 0.155568
tensor(0.0457, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-7.9598e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.113389
Average KL loss: 0.036217
Average total loss: 0.149606
tensor(0.0456, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-1.0148e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.116094
Average KL loss: 0.036223
Average total loss: 0.152316
 Percentile value: 0.10075737535953522
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =     315 /    1728             ( 18.23%) | total_pruned =    1413 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
bn1.bias             | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2418 /   36864             (  6.56%) | total_pruned =   34446 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    6979 /   36864             ( 18.93%) | total_pruned =   29885 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    7779 /   36864             ( 21.10%) | total_pruned =   29085 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   11517 /   36864             ( 31.24%) | total_pruned =   25347 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   28718 /   73728             ( 38.95%) | total_pruned =   45010 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   56405 /  147456             ( 38.25%) | total_pruned =   91051 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3747 /    8192             ( 45.74%) | total_pruned =    4445 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   39710 /  147456             ( 26.93%) | total_pruned =  107746 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   37615 /  147456             ( 25.51%) | total_pruned =  109841 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  118242 /  294912             ( 40.09%) | total_pruned =  176670 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  223074 /  589824             ( 37.82%) | total_pruned =  366750 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   13749 /   32768             ( 41.96%) | total_pruned =   19019 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  169750 /  589824             ( 28.78%) | total_pruned =  420074 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  146209 /  589824             ( 24.79%) | total_pruned =  443615 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  368078 / 1179648             ( 31.20%) | total_pruned =  811570 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      44 /     512             (  8.59%) | total_pruned =     468 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  548355 / 2359296             ( 23.24%) | total_pruned = 1810941 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     285 /     512             ( 55.66%) | total_pruned =     227 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   25590 /  131072             ( 19.52%) | total_pruned =  105482 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     459 /     512             ( 89.65%) | total_pruned =      53 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     281 /     512             ( 54.88%) | total_pruned =     231 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  368249 / 2359296             ( 15.61%) | total_pruned = 1991047 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  607330 / 2359296             ( 25.74%) | total_pruned = 1751966 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
linear.weight        | nonzeros =    4916 /    5120             ( 96.02%) | total_pruned =     204 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 48/100 Loss: 0.022868 Accuracy: 88.52 100.00 % Best test Accuracy: 88.52%
tensor(0.0456, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-7.8273e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.496068
Average KL loss: 0.035534
Average total loss: 0.531601
tensor(0.0460, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-8.4326e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.488610
Average KL loss: 0.034637
Average total loss: 0.523246
tensor(0.0464, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-5.6735e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.468785
Average KL loss: 0.034019
Average total loss: 0.502804
tensor(0.0465, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-6.5288e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.446190
Average KL loss: 0.033566
Average total loss: 0.479756
tensor(0.0466, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-7.4455e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.436667
Average KL loss: 0.033219
Average total loss: 0.469886
tensor(0.0466, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-6.8308e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.428949
Average KL loss: 0.032955
Average total loss: 0.461903
tensor(0.0466, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-6.6875e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.429073
Average KL loss: 0.032745
Average total loss: 0.461818
tensor(0.0465, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-5.2084e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.394867
Average KL loss: 0.032578
Average total loss: 0.427446
tensor(0.0464, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-4.4607e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.412870
Average KL loss: 0.032447
Average total loss: 0.445317
tensor(0.0463, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-5.2294e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.389878
Average KL loss: 0.032347
Average total loss: 0.422224
tensor(0.0462, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-3.8918e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.376814
Average KL loss: 0.032261
Average total loss: 0.409075
tensor(0.0461, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-5.9141e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.375241
Average KL loss: 0.032194
Average total loss: 0.407435
tensor(0.0460, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-5.1212e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.361296
Average KL loss: 0.032150
Average total loss: 0.393446
tensor(0.0459, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-3.7996e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.350410
Average KL loss: 0.032121
Average total loss: 0.382531
tensor(0.0458, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-6.9938e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.349736
Average KL loss: 0.032098
Average total loss: 0.381833
tensor(0.0457, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-3.7047e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.355435
Average KL loss: 0.032078
Average total loss: 0.387513
tensor(0.0456, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-5.4673e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.356822
Average KL loss: 0.032063
Average total loss: 0.388885
tensor(0.0455, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-3.6357e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.339511
Average KL loss: 0.032063
Average total loss: 0.371575
tensor(0.0454, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-4.4425e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.334500
Average KL loss: 0.032071
Average total loss: 0.366571
tensor(0.0453, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-5.9751e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.341381
Average KL loss: 0.032081
Average total loss: 0.373462
tensor(0.0453, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-5.2210e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.339773
Average KL loss: 0.032095
Average total loss: 0.371867
tensor(0.0452, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-3.7117e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.321991
Average KL loss: 0.032116
Average total loss: 0.354107
tensor(0.0451, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-4.1546e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.313316
Average KL loss: 0.032140
Average total loss: 0.345456
tensor(0.0451, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-3.2093e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.332536
Average KL loss: 0.032167
Average total loss: 0.364702
tensor(0.0450, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-3.6773e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.322898
Average KL loss: 0.032203
Average total loss: 0.355101
tensor(0.0450, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-3.4159e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.306674
Average KL loss: 0.032229
Average total loss: 0.338903
tensor(0.0449, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-2.7100e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.311089
Average KL loss: 0.032260
Average total loss: 0.343349
tensor(0.0449, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-3.6970e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.312514
Average KL loss: 0.032290
Average total loss: 0.344804
tensor(0.0448, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-3.1074e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.302219
Average KL loss: 0.032314
Average total loss: 0.334533
tensor(0.0447, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-3.0515e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.298653
Average KL loss: 0.032347
Average total loss: 0.331000
tensor(0.0447, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-3.9668e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.297234
Average KL loss: 0.032386
Average total loss: 0.329620
tensor(0.0447, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-3.7579e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.302651
Average KL loss: 0.032424
Average total loss: 0.335075
tensor(0.0446, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.8343e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.292117
Average KL loss: 0.032458
Average total loss: 0.324575
tensor(0.0446, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-3.6586e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.285435
Average KL loss: 0.032493
Average total loss: 0.317929
tensor(0.0445, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.7459e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.294947
Average KL loss: 0.032530
Average total loss: 0.327477
tensor(0.0445, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-3.9448e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.296495
Average KL loss: 0.032566
Average total loss: 0.329062
tensor(0.0444, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-4.0351e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.275214
Average KL loss: 0.032603
Average total loss: 0.307816
tensor(0.0444, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-3.1458e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.283743
Average KL loss: 0.032646
Average total loss: 0.316389
tensor(0.0444, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-2.5494e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.286144
Average KL loss: 0.032693
Average total loss: 0.318837
tensor(0.0444, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-3.2919e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.285608
Average KL loss: 0.032737
Average total loss: 0.318345
tensor(0.0443, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-3.8598e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.284984
Average KL loss: 0.032779
Average total loss: 0.317762
tensor(0.0443, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.2746e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.266839
Average KL loss: 0.032821
Average total loss: 0.299660
tensor(0.0443, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.2474e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.279379
Average KL loss: 0.032856
Average total loss: 0.312235
tensor(0.0443, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-3.7099e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.273997
Average KL loss: 0.032898
Average total loss: 0.306895
tensor(0.0442, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-3.5781e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.284023
Average KL loss: 0.032932
Average total loss: 0.316955
tensor(0.0442, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-2.2690e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.262360
Average KL loss: 0.032973
Average total loss: 0.295333
tensor(0.0442, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-3.2598e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.264146
Average KL loss: 0.033007
Average total loss: 0.297153
tensor(0.0441, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-4.1896e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.271023
Average KL loss: 0.033040
Average total loss: 0.304062
tensor(0.0441, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-3.8363e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.263202
Average KL loss: 0.033081
Average total loss: 0.296283
tensor(0.0441, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-2.6465e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.263538
Average KL loss: 0.033120
Average total loss: 0.296658
tensor(0.0440, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-2.4400e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.255522
Average KL loss: 0.033155
Average total loss: 0.288677
tensor(0.0440, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-2.5412e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.257082
Average KL loss: 0.033195
Average total loss: 0.290277
tensor(0.0440, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-2.6392e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.252803
Average KL loss: 0.033236
Average total loss: 0.286039
tensor(0.0440, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.9794e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.254618
Average KL loss: 0.033270
Average total loss: 0.287888
tensor(0.0439, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.6796e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.252042
Average KL loss: 0.033302
Average total loss: 0.285344
tensor(0.0439, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-2.4149e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.252904
Average KL loss: 0.033337
Average total loss: 0.286241
tensor(0.0439, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-2.0757e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.241008
Average KL loss: 0.033377
Average total loss: 0.274385
tensor(0.0439, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-2.7993e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.250434
Average KL loss: 0.033416
Average total loss: 0.283850
tensor(0.0439, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-2.9527e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.246891
Average KL loss: 0.033455
Average total loss: 0.280346
tensor(0.0438, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-2.4448e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.239566
Average KL loss: 0.033489
Average total loss: 0.273054
tensor(0.0438, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-2.1197e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.236402
Average KL loss: 0.033526
Average total loss: 0.269928
tensor(0.0438, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-1.8726e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.244517
Average KL loss: 0.033558
Average total loss: 0.278075
tensor(0.0438, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-2.1015e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.239567
Average KL loss: 0.033594
Average total loss: 0.273161
tensor(0.0437, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-3.0038e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.249101
Average KL loss: 0.033626
Average total loss: 0.282727
tensor(0.0437, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-1.9266e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.235525
Average KL loss: 0.033668
Average total loss: 0.269193
tensor(0.0437, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-2.7269e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.233779
Average KL loss: 0.033706
Average total loss: 0.267485
tensor(0.0437, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-1.5982e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.229798
Average KL loss: 0.033739
Average total loss: 0.263537
tensor(0.0437, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-2.3637e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.230930
Average KL loss: 0.033770
Average total loss: 0.264700
tensor(0.0436, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-2.2966e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.231558
Average KL loss: 0.033804
Average total loss: 0.265361
tensor(0.0436, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-2.3886e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.228418
Average KL loss: 0.033840
Average total loss: 0.262258
tensor(0.0436, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-1.5644e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.228987
Average KL loss: 0.033877
Average total loss: 0.262864
tensor(0.0436, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.7848e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.223753
Average KL loss: 0.033910
Average total loss: 0.257663
tensor(0.0436, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-2.2711e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.222513
Average KL loss: 0.033950
Average total loss: 0.256463
tensor(0.0436, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-2.1279e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.218920
Average KL loss: 0.033983
Average total loss: 0.252903
tensor(0.0435, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-1.7462e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.226143
Average KL loss: 0.034014
Average total loss: 0.260158
tensor(0.0435, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-2.5237e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.217754
Average KL loss: 0.034058
Average total loss: 0.251812
tensor(0.0435, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-2.2083e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.219073
Average KL loss: 0.034091
Average total loss: 0.253164
tensor(0.0435, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-2.2881e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.216657
Average KL loss: 0.034120
Average total loss: 0.250776
tensor(0.0435, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-1.8644e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.213482
Average KL loss: 0.034154
Average total loss: 0.247636
tensor(0.0435, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-1.9780e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.211573
Average KL loss: 0.034185
Average total loss: 0.245758
tensor(0.0434, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-2.1257e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.214309
Average KL loss: 0.034218
Average total loss: 0.248526
tensor(0.0434, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-1.7291e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.216311
Average KL loss: 0.034255
Average total loss: 0.250566
tensor(0.0434, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-2.3069e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.212225
Average KL loss: 0.034288
Average total loss: 0.246513
tensor(0.0434, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-2.0844e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.216622
Average KL loss: 0.034316
Average total loss: 0.250938
tensor(0.0434, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.6867e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.208430
Average KL loss: 0.034354
Average total loss: 0.242784
tensor(0.0433, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-2.1529e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.215710
Average KL loss: 0.034384
Average total loss: 0.250094
tensor(0.0433, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-2.7457e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.212841
Average KL loss: 0.034418
Average total loss: 0.247259
tensor(0.0433, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-2.5661e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.211415
Average KL loss: 0.034454
Average total loss: 0.245869
tensor(0.0433, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-2.8289e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.213409
Average KL loss: 0.034493
Average total loss: 0.247903
tensor(0.0433, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-1.9689e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.202463
Average KL loss: 0.034525
Average total loss: 0.236988
tensor(0.0433, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-1.9891e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.206075
Average KL loss: 0.034553
Average total loss: 0.240628
tensor(0.0432, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-1.5067e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.208013
Average KL loss: 0.034578
Average total loss: 0.242591
tensor(0.0432, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-2.2952e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.200740
Average KL loss: 0.034606
Average total loss: 0.235346
tensor(0.0432, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-2.0894e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.200507
Average KL loss: 0.034635
Average total loss: 0.235143
tensor(0.0432, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.6676e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.196326
Average KL loss: 0.034663
Average total loss: 0.230989
tensor(0.0432, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-2.0526e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.197881
Average KL loss: 0.034696
Average total loss: 0.232576
tensor(0.0432, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.9284e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.196543
Average KL loss: 0.034727
Average total loss: 0.231269
tensor(0.0431, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.6912e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.202881
Average KL loss: 0.034759
Average total loss: 0.237640
tensor(0.0431, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-2.5998e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.193227
Average KL loss: 0.034787
Average total loss: 0.228014
tensor(0.0431, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-2.3636e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.199565
Average KL loss: 0.034817
Average total loss: 0.234382
tensor(0.0431, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-1.6008e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.199725
Average KL loss: 0.034853
Average total loss: 0.234578
tensor(0.0431, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-2.3115e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.189468
Average KL loss: 0.034886
Average total loss: 0.224355
tensor(0.0431, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-2.5126e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.191771
Average KL loss: 0.034915
Average total loss: 0.226686
tensor(0.0431, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.9639e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.189470
Average KL loss: 0.034943
Average total loss: 0.224414
tensor(0.0431, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.6830e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.193891
Average KL loss: 0.034977
Average total loss: 0.228868
tensor(0.0430, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.1007e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.190888
Average KL loss: 0.035007
Average total loss: 0.225894
tensor(0.0430, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-2.0797e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.190438
Average KL loss: 0.035034
Average total loss: 0.225472
tensor(0.0430, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-2.1568e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.191993
Average KL loss: 0.035066
Average total loss: 0.227059
tensor(0.0430, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-1.4128e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.189726
Average KL loss: 0.035093
Average total loss: 0.224818
tensor(0.0430, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-2.0674e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.187546
Average KL loss: 0.035116
Average total loss: 0.222661
tensor(0.0430, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-1.1318e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.185385
Average KL loss: 0.035138
Average total loss: 0.220522
tensor(0.0429, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-1.9186e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.182745
Average KL loss: 0.035168
Average total loss: 0.217913
tensor(0.0429, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-1.7296e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.182105
Average KL loss: 0.035201
Average total loss: 0.217306
tensor(0.0429, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-1.9913e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.182845
Average KL loss: 0.035228
Average total loss: 0.218073
tensor(0.0429, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-2.2798e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.179372
Average KL loss: 0.035259
Average total loss: 0.214631
tensor(0.0429, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-1.2567e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.183936
Average KL loss: 0.035288
Average total loss: 0.219224
tensor(0.0429, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-1.3733e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.179748
Average KL loss: 0.035321
Average total loss: 0.215069
tensor(0.0429, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-1.4924e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.176211
Average KL loss: 0.035351
Average total loss: 0.211562
tensor(0.0429, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-1.5297e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.180549
Average KL loss: 0.035383
Average total loss: 0.215931
tensor(0.0429, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-1.8348e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.182019
Average KL loss: 0.035412
Average total loss: 0.217431
tensor(0.0429, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-2.0511e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.175614
Average KL loss: 0.035440
Average total loss: 0.211054
tensor(0.0428, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-2.0507e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.177473
Average KL loss: 0.035466
Average total loss: 0.212939
tensor(0.0428, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-1.7396e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.177529
Average KL loss: 0.035496
Average total loss: 0.213024
tensor(0.0428, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-1.6535e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.177068
Average KL loss: 0.035529
Average total loss: 0.212597
tensor(0.0428, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-1.3030e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.165908
Average KL loss: 0.035554
Average total loss: 0.201463
tensor(0.0428, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-9.9217e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.175647
Average KL loss: 0.035583
Average total loss: 0.211230
tensor(0.0428, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-1.6595e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.174392
Average KL loss: 0.035613
Average total loss: 0.210006
tensor(0.0428, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-1.2389e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.169155
Average KL loss: 0.035635
Average total loss: 0.204790
tensor(0.0428, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-1.5781e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.170654
Average KL loss: 0.035658
Average total loss: 0.206312
tensor(0.0427, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-1.3167e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.173174
Average KL loss: 0.035685
Average total loss: 0.208859
tensor(0.0427, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-1.7457e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.163851
Average KL loss: 0.035705
Average total loss: 0.199556
tensor(0.0427, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-2.0090e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.172982
Average KL loss: 0.035734
Average total loss: 0.208716
tensor(0.0427, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-1.6571e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.172289
Average KL loss: 0.035767
Average total loss: 0.208056
tensor(0.0427, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-1.6105e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.166960
Average KL loss: 0.035794
Average total loss: 0.202754
tensor(0.0427, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-1.1847e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.166996
Average KL loss: 0.035820
Average total loss: 0.202816
tensor(0.0427, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-1.3592e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.161384
Average KL loss: 0.035842
Average total loss: 0.197226
tensor(0.0427, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-1.5762e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.164604
Average KL loss: 0.035859
Average total loss: 0.200463
tensor(0.0426, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-1.5075e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.163371
Average KL loss: 0.035885
Average total loss: 0.199255
tensor(0.0426, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-1.7850e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.158313
Average KL loss: 0.035910
Average total loss: 0.194223
tensor(0.0426, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-1.5434e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.164881
Average KL loss: 0.035935
Average total loss: 0.200816
tensor(0.0426, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.4788e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.162713
Average KL loss: 0.035963
Average total loss: 0.198676
tensor(0.0426, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.2580e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.163159
Average KL loss: 0.035990
Average total loss: 0.199150
tensor(0.0426, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.7942e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.164650
Average KL loss: 0.036015
Average total loss: 0.200665
tensor(0.0426, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-9.7252e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.158619
Average KL loss: 0.036037
Average total loss: 0.194656
tensor(0.0426, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.1106e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.160108
Average KL loss: 0.036063
Average total loss: 0.196170
tensor(0.0426, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.3826e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.160213
Average KL loss: 0.036091
Average total loss: 0.196304
tensor(0.0425, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.3548e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.156723
Average KL loss: 0.036111
Average total loss: 0.192834
tensor(0.0425, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-2.3513e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.160952
Average KL loss: 0.036138
Average total loss: 0.197090
tensor(0.0425, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.2526e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.157443
Average KL loss: 0.036166
Average total loss: 0.193608
tensor(0.0425, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.3862e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.157350
Average KL loss: 0.036191
Average total loss: 0.193542
tensor(0.0425, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.3771e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.153721
Average KL loss: 0.036216
Average total loss: 0.189937
tensor(0.0425, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.1515e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.152890
Average KL loss: 0.036239
Average total loss: 0.189130
tensor(0.0425, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.2312e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.153697
Average KL loss: 0.036260
Average total loss: 0.189957
tensor(0.0425, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.0318e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.156188
Average KL loss: 0.036281
Average total loss: 0.192468
tensor(0.0425, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.5209e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.154706
Average KL loss: 0.036305
Average total loss: 0.191011
tensor(0.0424, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-9.6871e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.153073
Average KL loss: 0.036326
Average total loss: 0.189399
tensor(0.0424, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-7.8036e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.148049
Average KL loss: 0.036348
Average total loss: 0.184397
tensor(0.0424, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-1.2223e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.152648
Average KL loss: 0.036369
Average total loss: 0.189017
tensor(0.0424, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-1.4514e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.155785
Average KL loss: 0.036396
Average total loss: 0.192181
tensor(0.0424, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.2610e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.147939
Average KL loss: 0.036425
Average total loss: 0.184364
tensor(0.0424, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.2303e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.153583
Average KL loss: 0.036447
Average total loss: 0.190030
tensor(0.0424, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.0585e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.150839
Average KL loss: 0.036476
Average total loss: 0.187315
tensor(0.0424, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.4348e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.149785
Average KL loss: 0.036493
Average total loss: 0.186278
tensor(0.0423, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.1562e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.145073
Average KL loss: 0.036510
Average total loss: 0.181583
tensor(0.0423, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-1.4092e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.148342
Average KL loss: 0.036529
Average total loss: 0.184871
tensor(0.0423, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-1.8794e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.148531
Average KL loss: 0.036553
Average total loss: 0.185083
tensor(0.0423, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-9.5402e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.143300
Average KL loss: 0.036578
Average total loss: 0.179878
tensor(0.0423, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.0700e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.146905
Average KL loss: 0.036598
Average total loss: 0.183502
tensor(0.0423, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.2514e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.145001
Average KL loss: 0.036620
Average total loss: 0.181621
tensor(0.0423, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-1.5024e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.147771
Average KL loss: 0.036645
Average total loss: 0.184416
tensor(0.0423, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-1.3181e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.146323
Average KL loss: 0.036671
Average total loss: 0.182995
tensor(0.0423, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-1.6468e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.146486
Average KL loss: 0.036696
Average total loss: 0.183182
tensor(0.0423, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-8.9920e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.140680
Average KL loss: 0.036720
Average total loss: 0.177401
tensor(0.0422, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-1.1745e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.140795
Average KL loss: 0.036744
Average total loss: 0.177539
tensor(0.0422, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.3397e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.139855
Average KL loss: 0.036765
Average total loss: 0.176620
tensor(0.0422, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.0179e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.141766
Average KL loss: 0.036785
Average total loss: 0.178552
tensor(0.0422, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.4928e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.146002
Average KL loss: 0.036810
Average total loss: 0.182812
tensor(0.0422, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-1.2400e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.139812
Average KL loss: 0.036838
Average total loss: 0.176650
tensor(0.0422, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-1.2394e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.136208
Average KL loss: 0.036857
Average total loss: 0.173065
tensor(0.0422, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.0495e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.138405
Average KL loss: 0.036874
Average total loss: 0.175279
tensor(0.0422, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.1550e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.138518
Average KL loss: 0.036889
Average total loss: 0.175407
tensor(0.0422, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.2541e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.137579
Average KL loss: 0.036908
Average total loss: 0.174487
tensor(0.0421, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-1.2895e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.141590
Average KL loss: 0.036924
Average total loss: 0.178514
tensor(0.0421, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-9.1400e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.139980
Average KL loss: 0.036951
Average total loss: 0.176931
tensor(0.0421, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-9.9227e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.140367
Average KL loss: 0.036980
Average total loss: 0.177347
tensor(0.0421, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-1.4637e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.135861
Average KL loss: 0.036997
Average total loss: 0.172858
tensor(0.0421, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-1.2254e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.135330
Average KL loss: 0.037016
Average total loss: 0.172346
tensor(0.0421, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-1.0454e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.138386
Average KL loss: 0.037039
Average total loss: 0.175425
tensor(0.0421, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-1.1027e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.133070
Average KL loss: 0.037068
Average total loss: 0.170139
tensor(0.0421, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-9.8391e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.136254
Average KL loss: 0.037087
Average total loss: 0.173341
tensor(0.0421, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-1.1040e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.136925
Average KL loss: 0.037109
Average total loss: 0.174034
tensor(0.0421, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-9.3579e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.134991
Average KL loss: 0.037130
Average total loss: 0.172121
tensor(0.0420, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-1.1801e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.134378
Average KL loss: 0.037146
Average total loss: 0.171524
tensor(0.0420, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-1.0216e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.133047
Average KL loss: 0.037165
Average total loss: 0.170212
tensor(0.0420, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-5.0125e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.129743
Average KL loss: 0.037183
Average total loss: 0.166925
tensor(0.0420, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-9.4507e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.132977
Average KL loss: 0.037196
Average total loss: 0.170173
tensor(0.0420, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-1.5375e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.133946
Average KL loss: 0.037213
Average total loss: 0.171159
tensor(0.0420, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-1.2242e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.130256
Average KL loss: 0.037231
Average total loss: 0.167487
tensor(0.0420, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-8.1338e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.129406
Average KL loss: 0.037251
Average total loss: 0.166656
tensor(0.0420, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.3457e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.133490
Average KL loss: 0.037273
Average total loss: 0.170763
 Percentile value: 0.23245274275541306
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =     271 /    1728             ( 15.68%) | total_pruned =    1457 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
bn1.bias             | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1169 /   36864             (  3.17%) | total_pruned =   35695 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2689 /   36864             (  7.29%) | total_pruned =   34175 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2666 /   36864             (  7.23%) | total_pruned =   34198 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4880 /   36864             ( 13.24%) | total_pruned =   31984 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   16745 /   73728             ( 22.71%) | total_pruned =   56983 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   35544 /  147456             ( 24.10%) | total_pruned =  111912 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2363 /    8192             ( 28.85%) | total_pruned =    5829 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   21687 /  147456             ( 14.71%) | total_pruned =  125769 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   19160 /  147456             ( 12.99%) | total_pruned =  128296 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   82339 /  294912             ( 27.92%) | total_pruned =  212573 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  147324 /  589824             ( 24.98%) | total_pruned =  442500 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    9715 /   32768             ( 29.65%) | total_pruned =   23053 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   90023 /  589824             ( 15.26%) | total_pruned =  499801 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   64144 /  589824             ( 10.88%) | total_pruned =  525680 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  216024 / 1179648             ( 18.31%) | total_pruned =  963624 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      34 /     512             (  6.64%) | total_pruned =     478 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  240831 / 2359296             ( 10.21%) | total_pruned = 2118465 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     264 /     512             ( 51.56%) | total_pruned =     248 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9079 /  131072             (  6.93%) | total_pruned =  121993 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     338 /     512             ( 66.02%) | total_pruned =     174 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     263 /     512             ( 51.37%) | total_pruned =     249 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  148784 / 2359296             (  6.31%) | total_pruned = 2210512 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     375 /     512             ( 73.24%) | total_pruned =     137 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  271824 / 2359296             ( 11.52%) | total_pruned = 2087472 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
linear.weight        | nonzeros =    4734 /    5120             ( 92.46%) | total_pruned =     386 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 56/100 Loss: 0.029365 Accuracy: 89.13 100.00 % Best test Accuracy: 89.25%
tensor(0.0420, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-2.3914e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.253654
Average KL loss: 0.036794
Average total loss: 0.290448
tensor(0.0416, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-3.3838e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.247041
Average KL loss: 0.036225
Average total loss: 0.283266
tensor(0.0416, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-2.8756e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.252072
Average KL loss: 0.035831
Average total loss: 0.287903
tensor(0.0416, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-2.8209e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.239001
Average KL loss: 0.035530
Average total loss: 0.274531
tensor(0.0416, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-2.2035e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.234711
Average KL loss: 0.035289
Average total loss: 0.270000
tensor(0.0416, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-2.4427e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.236438
Average KL loss: 0.035094
Average total loss: 0.271531
tensor(0.0415, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.9953e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.229927
Average KL loss: 0.034933
Average total loss: 0.264860
tensor(0.0415, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-3.8336e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.233921
Average KL loss: 0.034805
Average total loss: 0.268725
tensor(0.0414, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-2.2370e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.219609
Average KL loss: 0.034697
Average total loss: 0.254306
tensor(0.0413, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.0161e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.226533
Average KL loss: 0.034603
Average total loss: 0.261136
tensor(0.0412, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.7230e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.220600
Average KL loss: 0.034524
Average total loss: 0.255124
tensor(0.0411, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-2.1409e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.219850
Average KL loss: 0.034458
Average total loss: 0.254308
tensor(0.0411, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-2.8814e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.220047
Average KL loss: 0.034399
Average total loss: 0.254445
tensor(0.0410, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.8195e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.204878
Average KL loss: 0.034346
Average total loss: 0.239224
tensor(0.0409, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.9628e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.217327
Average KL loss: 0.034300
Average total loss: 0.251627
tensor(0.0408, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-2.1493e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.205739
Average KL loss: 0.034263
Average total loss: 0.240002
tensor(0.0407, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.8734e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.207565
Average KL loss: 0.034230
Average total loss: 0.241795
tensor(0.0407, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-2.1703e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.198566
Average KL loss: 0.034206
Average total loss: 0.232772
tensor(0.0406, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-2.1289e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.203655
Average KL loss: 0.034182
Average total loss: 0.237837
tensor(0.0405, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-2.8676e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.205282
Average KL loss: 0.034165
Average total loss: 0.239446
tensor(0.0405, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-2.4347e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.202295
Average KL loss: 0.034152
Average total loss: 0.236446
tensor(0.0404, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-1.9552e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.198300
Average KL loss: 0.034144
Average total loss: 0.232445
tensor(0.0403, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-2.1849e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.198460
Average KL loss: 0.034134
Average total loss: 0.232593
tensor(0.0403, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.9375e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.196067
Average KL loss: 0.034128
Average total loss: 0.230195
tensor(0.0402, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.6750e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.193386
Average KL loss: 0.034127
Average total loss: 0.227513
tensor(0.0402, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.7556e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.190512
Average KL loss: 0.034127
Average total loss: 0.224639
tensor(0.0401, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.6708e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.196644
Average KL loss: 0.034127
Average total loss: 0.230771
tensor(0.0401, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-2.0033e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.192985
Average KL loss: 0.034131
Average total loss: 0.227116
tensor(0.0400, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-2.0086e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.189907
Average KL loss: 0.034133
Average total loss: 0.224040
tensor(0.0400, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-2.3708e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.192191
Average KL loss: 0.034140
Average total loss: 0.226331
tensor(0.0399, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-2.2817e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.186751
Average KL loss: 0.034150
Average total loss: 0.220900
tensor(0.0399, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.8840e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.185082
Average KL loss: 0.034162
Average total loss: 0.219245
tensor(0.0399, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.4428e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.186596
Average KL loss: 0.034172
Average total loss: 0.220768
tensor(0.0398, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.4907e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.188341
Average KL loss: 0.034184
Average total loss: 0.222525
tensor(0.0398, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.7850e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.181269
Average KL loss: 0.034198
Average total loss: 0.215468
tensor(0.0398, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.9036e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.189911
Average KL loss: 0.034210
Average total loss: 0.224122
tensor(0.0397, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.3214e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.179742
Average KL loss: 0.034221
Average total loss: 0.213963
tensor(0.0397, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.4146e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.180232
Average KL loss: 0.034231
Average total loss: 0.214462
tensor(0.0396, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.4881e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.175462
Average KL loss: 0.034243
Average total loss: 0.209705
tensor(0.0396, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-2.3284e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.181805
Average KL loss: 0.034258
Average total loss: 0.216063
tensor(0.0396, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.6524e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.175683
Average KL loss: 0.034271
Average total loss: 0.209954
tensor(0.0395, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.9244e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.179360
Average KL loss: 0.034282
Average total loss: 0.213641
tensor(0.0395, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.6413e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.177781
Average KL loss: 0.034298
Average total loss: 0.212079
tensor(0.0395, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.3094e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.175136
Average KL loss: 0.034317
Average total loss: 0.209453
tensor(0.0395, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.5407e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.168188
Average KL loss: 0.034334
Average total loss: 0.202522
tensor(0.0394, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.4280e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.171659
Average KL loss: 0.034347
Average total loss: 0.206006
tensor(0.0394, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-2.1902e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.171841
Average KL loss: 0.034358
Average total loss: 0.206198
tensor(0.0394, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.2756e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.171919
Average KL loss: 0.034374
Average total loss: 0.206293
tensor(0.0393, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.0472e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.174206
Average KL loss: 0.034395
Average total loss: 0.208601
tensor(0.0393, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.3510e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.171135
Average KL loss: 0.034413
Average total loss: 0.205548
tensor(0.0393, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.3871e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.168261
Average KL loss: 0.034432
Average total loss: 0.202693
tensor(0.0393, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.9419e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.169712
Average KL loss: 0.034449
Average total loss: 0.204161
tensor(0.0392, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-1.7641e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.169747
Average KL loss: 0.034467
Average total loss: 0.204213
tensor(0.0392, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-1.2457e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.166938
Average KL loss: 0.034489
Average total loss: 0.201427
tensor(0.0392, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-1.5848e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.169831
Average KL loss: 0.034511
Average total loss: 0.204342
tensor(0.0392, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.6635e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.162443
Average KL loss: 0.034534
Average total loss: 0.196977
tensor(0.0392, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.2490e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.166322
Average KL loss: 0.034553
Average total loss: 0.200875
tensor(0.0391, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.4387e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.157001
Average KL loss: 0.034570
Average total loss: 0.191571
tensor(0.0391, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.5803e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.159038
Average KL loss: 0.034588
Average total loss: 0.193626
tensor(0.0391, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.9276e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.167733
Average KL loss: 0.034611
Average total loss: 0.202343
tensor(0.0391, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.1970e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.166758
Average KL loss: 0.034635
Average total loss: 0.201393
tensor(0.0390, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-1.0363e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.160991
Average KL loss: 0.034657
Average total loss: 0.195648
tensor(0.0390, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-1.8190e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.159640
Average KL loss: 0.034678
Average total loss: 0.194318
tensor(0.0390, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-1.0982e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.154014
Average KL loss: 0.034696
Average total loss: 0.188710
tensor(0.0390, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.4811e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.157513
Average KL loss: 0.034714
Average total loss: 0.192226
tensor(0.0390, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.0881e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.157205
Average KL loss: 0.034730
Average total loss: 0.191935
tensor(0.0389, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.7871e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.156995
Average KL loss: 0.034750
Average total loss: 0.191745
tensor(0.0389, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-1.6026e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.156200
Average KL loss: 0.034770
Average total loss: 0.190969
tensor(0.0389, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-2.0478e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.152745
Average KL loss: 0.034789
Average total loss: 0.187534
tensor(0.0389, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-1.0958e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.154444
Average KL loss: 0.034810
Average total loss: 0.189254
tensor(0.0389, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-1.1890e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.154427
Average KL loss: 0.034830
Average total loss: 0.189258
tensor(0.0388, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-1.4326e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.153342
Average KL loss: 0.034850
Average total loss: 0.188192
tensor(0.0388, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.3390e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.148824
Average KL loss: 0.034866
Average total loss: 0.183690
tensor(0.0388, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.2153e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.153118
Average KL loss: 0.034884
Average total loss: 0.188003
tensor(0.0388, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.5735e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.154136
Average KL loss: 0.034910
Average total loss: 0.189046
tensor(0.0388, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-1.0462e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.154658
Average KL loss: 0.034932
Average total loss: 0.189590
tensor(0.0388, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-1.1594e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.150754
Average KL loss: 0.034953
Average total loss: 0.185707
tensor(0.0387, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-1.5534e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.149022
Average KL loss: 0.034974
Average total loss: 0.183996
tensor(0.0387, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.5240e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.149984
Average KL loss: 0.034998
Average total loss: 0.184982
tensor(0.0387, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.6527e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.154894
Average KL loss: 0.035017
Average total loss: 0.189911
tensor(0.0387, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.1513e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.144926
Average KL loss: 0.035038
Average total loss: 0.179964
tensor(0.0387, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-1.2136e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.143054
Average KL loss: 0.035058
Average total loss: 0.178112
tensor(0.0386, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-1.7813e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.147670
Average KL loss: 0.035077
Average total loss: 0.182747
tensor(0.0386, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-1.1289e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.148010
Average KL loss: 0.035097
Average total loss: 0.183107
tensor(0.0386, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-1.0990e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.144901
Average KL loss: 0.035120
Average total loss: 0.180021
tensor(0.0386, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-1.3103e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.146793
Average KL loss: 0.035141
Average total loss: 0.181935
tensor(0.0386, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-1.2344e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.143576
Average KL loss: 0.035165
Average total loss: 0.178741
tensor(0.0386, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-9.8701e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.142329
Average KL loss: 0.035184
Average total loss: 0.177513
tensor(0.0386, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-1.4282e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.146934
Average KL loss: 0.035204
Average total loss: 0.182138
tensor(0.0385, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-1.1043e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.141861
Average KL loss: 0.035223
Average total loss: 0.177084
tensor(0.0385, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-1.1285e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.142886
Average KL loss: 0.035244
Average total loss: 0.178130
tensor(0.0385, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-8.2180e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.139057
Average KL loss: 0.035264
Average total loss: 0.174321
tensor(0.0385, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-1.2650e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.144966
Average KL loss: 0.035287
Average total loss: 0.180253
tensor(0.0385, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-1.2609e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.145722
Average KL loss: 0.035310
Average total loss: 0.181032
tensor(0.0385, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-1.2934e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.140776
Average KL loss: 0.035331
Average total loss: 0.176106
tensor(0.0384, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-1.1826e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.143267
Average KL loss: 0.035356
Average total loss: 0.178623
tensor(0.0384, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-1.6611e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.140084
Average KL loss: 0.035376
Average total loss: 0.175461
tensor(0.0384, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.5423e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.135419
Average KL loss: 0.035399
Average total loss: 0.170819
tensor(0.0384, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.2977e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.133618
Average KL loss: 0.035417
Average total loss: 0.169034
tensor(0.0384, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.2886e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.136300
Average KL loss: 0.035432
Average total loss: 0.171732
tensor(0.0384, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-1.0854e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.137455
Average KL loss: 0.035457
Average total loss: 0.172912
tensor(0.0384, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-1.1435e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.136684
Average KL loss: 0.035476
Average total loss: 0.172160
tensor(0.0383, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-6.7536e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.137858
Average KL loss: 0.035495
Average total loss: 0.173353
tensor(0.0383, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-1.2973e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.137004
Average KL loss: 0.035521
Average total loss: 0.172525
tensor(0.0383, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-1.2063e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.137910
Average KL loss: 0.035545
Average total loss: 0.173455
tensor(0.0383, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-1.1514e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.135880
Average KL loss: 0.035568
Average total loss: 0.171448
tensor(0.0383, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-1.3195e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.134106
Average KL loss: 0.035588
Average total loss: 0.169694
tensor(0.0383, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-8.4814e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.131990
Average KL loss: 0.035605
Average total loss: 0.167596
tensor(0.0383, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-1.3245e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.129394
Average KL loss: 0.035621
Average total loss: 0.165015
tensor(0.0383, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-1.0521e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.133199
Average KL loss: 0.035637
Average total loss: 0.168836
tensor(0.0382, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-8.6950e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.131343
Average KL loss: 0.035659
Average total loss: 0.167002
tensor(0.0382, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-9.0726e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.132753
Average KL loss: 0.035680
Average total loss: 0.168433
tensor(0.0382, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-9.0761e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.128941
Average KL loss: 0.035698
Average total loss: 0.164639
tensor(0.0382, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-1.6586e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.130175
Average KL loss: 0.035716
Average total loss: 0.165891
tensor(0.0382, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-1.3212e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.129677
Average KL loss: 0.035731
Average total loss: 0.165408
tensor(0.0382, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-1.1673e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.130901
Average KL loss: 0.035750
Average total loss: 0.166651
tensor(0.0382, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-1.2294e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.128011
Average KL loss: 0.035769
Average total loss: 0.163780
tensor(0.0381, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-7.2467e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.129507
Average KL loss: 0.035788
Average total loss: 0.165295
tensor(0.0381, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-8.1991e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.126555
Average KL loss: 0.035806
Average total loss: 0.162361
tensor(0.0381, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-1.0050e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.124057
Average KL loss: 0.035821
Average total loss: 0.159878
tensor(0.0381, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-6.1653e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.130077
Average KL loss: 0.035836
Average total loss: 0.165912
tensor(0.0381, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-1.2093e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.130774
Average KL loss: 0.035861
Average total loss: 0.166635
tensor(0.0381, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-1.0442e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.127196
Average KL loss: 0.035882
Average total loss: 0.163078
tensor(0.0381, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-1.1388e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.128177
Average KL loss: 0.035907
Average total loss: 0.164083
tensor(0.0381, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-1.0067e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.125795
Average KL loss: 0.035931
Average total loss: 0.161726
tensor(0.0381, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-6.8546e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.126355
Average KL loss: 0.035957
Average total loss: 0.162312
tensor(0.0380, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-8.0258e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.126087
Average KL loss: 0.035979
Average total loss: 0.162066
tensor(0.0380, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-6.0069e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.126567
Average KL loss: 0.036000
Average total loss: 0.162567
tensor(0.0380, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-1.3562e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.126631
Average KL loss: 0.036023
Average total loss: 0.162654
tensor(0.0380, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.5087e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.123189
Average KL loss: 0.036041
Average total loss: 0.159230
tensor(0.0380, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.1373e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.121914
Average KL loss: 0.036056
Average total loss: 0.157970
tensor(0.0380, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-6.6108e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.123223
Average KL loss: 0.036075
Average total loss: 0.159298
tensor(0.0380, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.3155e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.122466
Average KL loss: 0.036096
Average total loss: 0.158562
tensor(0.0380, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.0416e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.123079
Average KL loss: 0.036112
Average total loss: 0.159191
tensor(0.0380, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-9.9025e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.121317
Average KL loss: 0.036130
Average total loss: 0.157446
tensor(0.0379, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.1028e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.118004
Average KL loss: 0.036151
Average total loss: 0.154154
tensor(0.0379, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-8.9601e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.119814
Average KL loss: 0.036165
Average total loss: 0.155979
tensor(0.0379, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-5.1798e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.118387
Average KL loss: 0.036177
Average total loss: 0.154564
tensor(0.0379, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.0429e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.119060
Average KL loss: 0.036193
Average total loss: 0.155253
tensor(0.0379, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-9.3693e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.118362
Average KL loss: 0.036214
Average total loss: 0.154576
tensor(0.0379, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.0673e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.120494
Average KL loss: 0.036231
Average total loss: 0.156725
tensor(0.0379, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-7.3018e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.118951
Average KL loss: 0.036246
Average total loss: 0.155196
tensor(0.0378, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-7.0887e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.117449
Average KL loss: 0.036264
Average total loss: 0.153714
tensor(0.0378, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-7.3944e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.117685
Average KL loss: 0.036284
Average total loss: 0.153969
tensor(0.0378, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-7.9041e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.118671
Average KL loss: 0.036303
Average total loss: 0.154974
tensor(0.0378, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-4.8933e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.121002
Average KL loss: 0.036326
Average total loss: 0.157328
tensor(0.0378, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-5.7533e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.117524
Average KL loss: 0.036345
Average total loss: 0.153870
tensor(0.0378, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-7.3608e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.117161
Average KL loss: 0.036361
Average total loss: 0.153522
tensor(0.0378, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-9.6376e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.118404
Average KL loss: 0.036377
Average total loss: 0.154781
tensor(0.0378, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-7.3458e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.119859
Average KL loss: 0.036396
Average total loss: 0.156255
tensor(0.0378, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-7.6740e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.119575
Average KL loss: 0.036418
Average total loss: 0.155993
tensor(0.0378, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-9.4914e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.115798
Average KL loss: 0.036441
Average total loss: 0.152239
tensor(0.0377, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-9.7116e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.113891
Average KL loss: 0.036460
Average total loss: 0.150351
tensor(0.0377, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-1.0870e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.114831
Average KL loss: 0.036476
Average total loss: 0.151307
tensor(0.0377, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-9.9494e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.117556
Average KL loss: 0.036490
Average total loss: 0.154045
tensor(0.0377, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-9.6568e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.115415
Average KL loss: 0.036509
Average total loss: 0.151924
tensor(0.0377, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-1.9324e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.116343
Average KL loss: 0.036527
Average total loss: 0.152870
tensor(0.0377, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-9.9410e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.115436
Average KL loss: 0.036546
Average total loss: 0.151982
tensor(0.0377, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-8.2766e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.114136
Average KL loss: 0.036563
Average total loss: 0.150699
tensor(0.0377, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-1.3857e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.116609
Average KL loss: 0.036583
Average total loss: 0.153192
tensor(0.0377, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-5.7407e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.112507
Average KL loss: 0.036604
Average total loss: 0.149111
tensor(0.0377, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-7.3331e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.112874
Average KL loss: 0.036622
Average total loss: 0.149496
tensor(0.0376, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-7.5934e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.112793
Average KL loss: 0.036638
Average total loss: 0.149432
tensor(0.0376, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-7.5167e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.111943
Average KL loss: 0.036657
Average total loss: 0.148600
tensor(0.0376, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-7.7952e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.111862
Average KL loss: 0.036673
Average total loss: 0.148534
tensor(0.0376, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-8.0591e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.112194
Average KL loss: 0.036690
Average total loss: 0.148885
tensor(0.0376, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-6.8525e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.110313
Average KL loss: 0.036709
Average total loss: 0.147022
tensor(0.0376, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-6.5640e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.108575
Average KL loss: 0.036724
Average total loss: 0.145299
tensor(0.0376, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-7.7542e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.110582
Average KL loss: 0.036739
Average total loss: 0.147321
tensor(0.0376, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-6.6371e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.111297
Average KL loss: 0.036755
Average total loss: 0.148052
tensor(0.0376, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-7.3659e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.113924
Average KL loss: 0.036776
Average total loss: 0.150700
tensor(0.0376, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-6.2437e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.111139
Average KL loss: 0.036800
Average total loss: 0.147939
tensor(0.0375, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-7.0626e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.110350
Average KL loss: 0.036814
Average total loss: 0.147164
tensor(0.0375, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-9.0244e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.108781
Average KL loss: 0.036831
Average total loss: 0.145612
tensor(0.0375, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-6.2241e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.112499
Average KL loss: 0.036850
Average total loss: 0.149349
tensor(0.0375, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-5.0020e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.107572
Average KL loss: 0.036869
Average total loss: 0.144441
tensor(0.0375, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-7.4867e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.107420
Average KL loss: 0.036886
Average total loss: 0.144306
tensor(0.0375, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-1.1370e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.105815
Average KL loss: 0.036899
Average total loss: 0.142714
tensor(0.0375, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-5.3229e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.105216
Average KL loss: 0.036906
Average total loss: 0.142123
tensor(0.0375, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-6.8448e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.110655
Average KL loss: 0.036923
Average total loss: 0.147578
tensor(0.0375, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-2.6033e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.104941
Average KL loss: 0.036939
Average total loss: 0.141879
tensor(0.0374, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-6.6728e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.108196
Average KL loss: 0.036955
Average total loss: 0.145151
tensor(0.0374, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-4.8028e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.104968
Average KL loss: 0.036971
Average total loss: 0.141940
tensor(0.0374, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-8.0021e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.106835
Average KL loss: 0.036989
Average total loss: 0.143824
tensor(0.0374, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-8.8200e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.104079
Average KL loss: 0.037008
Average total loss: 0.141087
tensor(0.0374, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-6.0644e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.104635
Average KL loss: 0.037025
Average total loss: 0.141661
tensor(0.0374, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-6.3628e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.103985
Average KL loss: 0.037042
Average total loss: 0.141027
tensor(0.0374, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-9.8383e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.107974
Average KL loss: 0.037060
Average total loss: 0.145035
tensor(0.0374, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-4.5650e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.108021
Average KL loss: 0.037080
Average total loss: 0.145101
tensor(0.0374, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-7.4928e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.103882
Average KL loss: 0.037097
Average total loss: 0.140979
tensor(0.0374, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-6.4605e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.104168
Average KL loss: 0.037111
Average total loss: 0.141278
tensor(0.0374, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-6.7995e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.105863
Average KL loss: 0.037129
Average total loss: 0.142993
tensor(0.0374, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-5.2916e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.100563
Average KL loss: 0.037142
Average total loss: 0.137705
tensor(0.0373, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-5.8629e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.103783
Average KL loss: 0.037153
Average total loss: 0.140936
tensor(0.0373, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-1.1595e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.105031
Average KL loss: 0.037166
Average total loss: 0.142197
tensor(0.0373, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-6.0830e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.103965
Average KL loss: 0.037178
Average total loss: 0.141143
tensor(0.0373, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-8.8898e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.103162
Average KL loss: 0.037193
Average total loss: 0.140355
tensor(0.0373, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-5.2545e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.104948
Average KL loss: 0.037211
Average total loss: 0.142159
tensor(0.0373, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-6.1210e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.105125
Average KL loss: 0.037235
Average total loss: 0.142360
tensor(0.0373, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-6.7109e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.102734
Average KL loss: 0.037254
Average total loss: 0.139988
 Percentile value: 0.42313551902770996
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =     213 /    1728             ( 12.33%) | total_pruned =    1515 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.bias             | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     638 /   36864             (  1.73%) | total_pruned =   36226 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1359 /   36864             (  3.69%) | total_pruned =   35505 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1454 /   36864             (  3.94%) | total_pruned =   35410 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2670 /   36864             (  7.24%) | total_pruned =   34194 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8734 /   73728             ( 11.85%) | total_pruned =   64994 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   20442 /  147456             ( 13.86%) | total_pruned =  127014 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1485 /    8192             ( 18.13%) | total_pruned =    6707 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   12812 /  147456             (  8.69%) | total_pruned =  134644 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   11265 /  147456             (  7.64%) | total_pruned =  136191 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   52499 /  294912             ( 17.80%) | total_pruned =  242413 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   85986 /  589824             ( 14.58%) | total_pruned =  503838 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6417 /   32768             ( 19.58%) | total_pruned =   26351 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   44609 /  589824             (  7.56%) | total_pruned =  545215 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     198 /     256             ( 77.34%) | total_pruned =      58 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   31693 /  589824             (  5.37%) | total_pruned =  558131 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     188 /     256             ( 73.44%) | total_pruned =      68 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  110805 / 1179648             (  9.39%) | total_pruned = 1068843 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     463 /     512             ( 90.43%) | total_pruned =      49 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  110076 / 2359296             (  4.67%) | total_pruned = 2249220 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     455 /     512             ( 88.87%) | total_pruned =      57 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     244 /     512             ( 47.66%) | total_pruned =     268 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3397 /  131072             (  2.59%) | total_pruned =  127675 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     241 /     512             ( 47.07%) | total_pruned =     271 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     243 /     512             ( 47.46%) | total_pruned =     269 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   64811 / 2359296             (  2.75%) | total_pruned = 2294485 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     278 /     512             ( 54.30%) | total_pruned =     234 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  118217 / 2359296             (  5.01%) | total_pruned = 2241079 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     454 /     512             ( 88.67%) | total_pruned =      58 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     448 /     512             ( 87.50%) | total_pruned =      64 | shape = torch.Size([512])
linear.weight        | nonzeros =    4310 /    5120             ( 84.18%) | total_pruned =     810 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 40/100 Loss: 0.019217 Accuracy: 88.97 100.00 % Best test Accuracy: 88.97%
tensor(0.0373, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.6692e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.209541
Average KL loss: 0.036854
Average total loss: 0.246394
tensor(0.0364, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-2.2544e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.204724
Average KL loss: 0.036358
Average total loss: 0.241082
tensor(0.0359, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-2.7192e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.200544
Average KL loss: 0.036015
Average total loss: 0.236559
tensor(0.0355, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-2.7370e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.193916
Average KL loss: 0.035753
Average total loss: 0.229669
tensor(0.0352, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-2.7601e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.195246
Average KL loss: 0.035545
Average total loss: 0.230791
tensor(0.0349, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-2.0769e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.198449
Average KL loss: 0.035372
Average total loss: 0.233821
tensor(0.0348, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-1.9216e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.197571
Average KL loss: 0.035226
Average total loss: 0.232797
tensor(0.0346, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-1.5416e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.188861
Average KL loss: 0.035098
Average total loss: 0.223960
tensor(0.0345, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-2.0387e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.185192
Average KL loss: 0.034986
Average total loss: 0.220179
tensor(0.0344, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-2.1546e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.183692
Average KL loss: 0.034890
Average total loss: 0.218582
tensor(0.0342, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.7012e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.196239
Average KL loss: 0.034804
Average total loss: 0.231042
tensor(0.0341, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-2.8543e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.187587
Average KL loss: 0.034730
Average total loss: 0.222316
tensor(0.0341, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.2655e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.169043
Average KL loss: 0.034663
Average total loss: 0.203706
tensor(0.0340, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.1029e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.179769
Average KL loss: 0.034603
Average total loss: 0.214373
tensor(0.0339, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.8062e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.179485
Average KL loss: 0.034554
Average total loss: 0.214039
tensor(0.0338, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-2.3941e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.180040
Average KL loss: 0.034509
Average total loss: 0.214550
tensor(0.0337, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.6556e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.176136
Average KL loss: 0.034469
Average total loss: 0.210605
tensor(0.0337, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.8526e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.171820
Average KL loss: 0.034437
Average total loss: 0.206256
tensor(0.0336, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-2.4995e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.170432
Average KL loss: 0.034408
Average total loss: 0.204839
tensor(0.0335, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.1285e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.175828
Average KL loss: 0.034383
Average total loss: 0.210211
tensor(0.0335, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.9309e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.171660
Average KL loss: 0.034365
Average total loss: 0.206025
tensor(0.0334, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-2.3577e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.176327
Average KL loss: 0.034348
Average total loss: 0.210675
tensor(0.0334, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.7829e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.176209
Average KL loss: 0.034331
Average total loss: 0.210540
tensor(0.0333, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.6064e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.166060
Average KL loss: 0.034316
Average total loss: 0.200376
tensor(0.0333, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.7583e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.162950
Average KL loss: 0.034303
Average total loss: 0.197253
tensor(0.0333, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.9623e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.167840
Average KL loss: 0.034293
Average total loss: 0.202133
tensor(0.0332, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-1.2455e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.165799
Average KL loss: 0.034286
Average total loss: 0.200085
tensor(0.0332, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.2685e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.167304
Average KL loss: 0.034280
Average total loss: 0.201585
tensor(0.0331, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.4549e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.163231
Average KL loss: 0.034273
Average total loss: 0.197504
tensor(0.0331, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.2764e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.165285
Average KL loss: 0.034267
Average total loss: 0.199552
tensor(0.0331, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.9891e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.160988
Average KL loss: 0.034265
Average total loss: 0.195253
tensor(0.0330, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-2.4973e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.157002
Average KL loss: 0.034263
Average total loss: 0.191265
tensor(0.0330, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.5195e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.162976
Average KL loss: 0.034264
Average total loss: 0.197240
tensor(0.0330, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-2.3342e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.160049
Average KL loss: 0.034267
Average total loss: 0.194315
tensor(0.0330, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.5054e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.160464
Average KL loss: 0.034270
Average total loss: 0.194734
tensor(0.0329, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.7664e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.157523
Average KL loss: 0.034276
Average total loss: 0.191799
tensor(0.0329, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.4409e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.155211
Average KL loss: 0.034283
Average total loss: 0.189495
tensor(0.0329, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.8754e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.160661
Average KL loss: 0.034291
Average total loss: 0.194953
tensor(0.0329, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.1286e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.157843
Average KL loss: 0.034299
Average total loss: 0.192143
tensor(0.0328, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.2631e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.154651
Average KL loss: 0.034311
Average total loss: 0.188963
tensor(0.0328, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-9.5652e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.153365
Average KL loss: 0.034321
Average total loss: 0.187687
tensor(0.0328, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.8853e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.158798
Average KL loss: 0.034329
Average total loss: 0.193127
tensor(0.0328, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.3188e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.157940
Average KL loss: 0.034340
Average total loss: 0.192280
tensor(0.0328, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.2554e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.151506
Average KL loss: 0.034349
Average total loss: 0.185855
tensor(0.0328, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.0459e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.147873
Average KL loss: 0.034362
Average total loss: 0.182235
tensor(0.0327, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.2228e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.147115
Average KL loss: 0.034372
Average total loss: 0.181487
tensor(0.0327, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.0258e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.150519
Average KL loss: 0.034383
Average total loss: 0.184902
tensor(0.0327, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.4109e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.151828
Average KL loss: 0.034398
Average total loss: 0.186226
tensor(0.0327, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.0784e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.146221
Average KL loss: 0.034408
Average total loss: 0.180629
tensor(0.0327, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.4974e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.145817
Average KL loss: 0.034416
Average total loss: 0.180234
tensor(0.0327, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.1790e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.142243
Average KL loss: 0.034425
Average total loss: 0.176668
tensor(0.0326, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.3850e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.146070
Average KL loss: 0.034435
Average total loss: 0.180505
tensor(0.0326, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-1.1646e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.147403
Average KL loss: 0.034449
Average total loss: 0.181852
tensor(0.0326, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-1.4255e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.144290
Average KL loss: 0.034465
Average total loss: 0.178754
tensor(0.0326, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-1.9716e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.142143
Average KL loss: 0.034481
Average total loss: 0.176623
tensor(0.0326, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-1.5047e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.145724
Average KL loss: 0.034493
Average total loss: 0.180216
tensor(0.0326, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.3179e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.143430
Average KL loss: 0.034507
Average total loss: 0.177936
tensor(0.0326, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.3130e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.144194
Average KL loss: 0.034520
Average total loss: 0.178714
tensor(0.0326, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.2993e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.142604
Average KL loss: 0.034535
Average total loss: 0.177139
tensor(0.0326, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.2501e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.146662
Average KL loss: 0.034554
Average total loss: 0.181217
tensor(0.0326, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-1.2008e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.137005
Average KL loss: 0.034572
Average total loss: 0.171577
tensor(0.0325, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-1.3282e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.140695
Average KL loss: 0.034586
Average total loss: 0.175280
tensor(0.0325, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-1.1044e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.135934
Average KL loss: 0.034601
Average total loss: 0.170535
tensor(0.0325, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-1.3389e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.143524
Average KL loss: 0.034620
Average total loss: 0.178144
tensor(0.0325, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-1.4931e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.144575
Average KL loss: 0.034639
Average total loss: 0.179214
tensor(0.0325, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-7.9975e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.138337
Average KL loss: 0.034654
Average total loss: 0.172991
tensor(0.0325, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-1.6545e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.135902
Average KL loss: 0.034671
Average total loss: 0.170573
tensor(0.0325, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-1.3435e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.140834
Average KL loss: 0.034687
Average total loss: 0.175521
tensor(0.0325, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-2.3317e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.140936
Average KL loss: 0.034703
Average total loss: 0.175639
tensor(0.0325, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-1.1953e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.137822
Average KL loss: 0.034723
Average total loss: 0.172546
tensor(0.0325, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-1.8050e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.136172
Average KL loss: 0.034736
Average total loss: 0.170908
tensor(0.0325, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-1.5553e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.134698
Average KL loss: 0.034752
Average total loss: 0.169450
tensor(0.0325, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-8.3063e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.133447
Average KL loss: 0.034768
Average total loss: 0.168214
tensor(0.0325, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-1.0862e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.130045
Average KL loss: 0.034788
Average total loss: 0.164833
tensor(0.0324, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-1.2204e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.132756
Average KL loss: 0.034803
Average total loss: 0.167559
tensor(0.0324, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-1.5502e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.131031
Average KL loss: 0.034821
Average total loss: 0.165853
tensor(0.0324, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-7.5755e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.137276
Average KL loss: 0.034838
Average total loss: 0.172114
tensor(0.0324, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-8.8850e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.130429
Average KL loss: 0.034855
Average total loss: 0.165284
tensor(0.0324, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-9.9488e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.131463
Average KL loss: 0.034874
Average total loss: 0.166337
tensor(0.0324, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-9.3064e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.131300
Average KL loss: 0.034892
Average total loss: 0.166193
tensor(0.0324, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-1.0743e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.130515
Average KL loss: 0.034908
Average total loss: 0.165424
tensor(0.0324, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-1.1163e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.130932
Average KL loss: 0.034926
Average total loss: 0.165858
tensor(0.0324, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-1.1452e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.131058
Average KL loss: 0.034943
Average total loss: 0.166002
tensor(0.0324, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-1.0744e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.127390
Average KL loss: 0.034960
Average total loss: 0.162350
tensor(0.0324, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-1.5234e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.127235
Average KL loss: 0.034977
Average total loss: 0.162212
tensor(0.0324, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-1.0487e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.128985
Average KL loss: 0.034997
Average total loss: 0.163982
tensor(0.0324, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-1.0170e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.129693
Average KL loss: 0.035021
Average total loss: 0.164714
tensor(0.0324, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-1.3074e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.127093
Average KL loss: 0.035043
Average total loss: 0.162136
tensor(0.0324, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-1.4368e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.128489
Average KL loss: 0.035061
Average total loss: 0.163550
tensor(0.0324, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-1.5667e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.125796
Average KL loss: 0.035078
Average total loss: 0.160874
tensor(0.0324, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-8.1497e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.123732
Average KL loss: 0.035096
Average total loss: 0.158828
tensor(0.0323, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-1.1522e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.130682
Average KL loss: 0.035118
Average total loss: 0.165800
tensor(0.0323, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-6.8351e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.122707
Average KL loss: 0.035138
Average total loss: 0.157845
tensor(0.0323, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-1.4317e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.124118
Average KL loss: 0.035157
Average total loss: 0.159275
tensor(0.0323, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-1.0138e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.120124
Average KL loss: 0.035172
Average total loss: 0.155296
tensor(0.0323, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-8.6779e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.120531
Average KL loss: 0.035189
Average total loss: 0.155721
tensor(0.0323, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-7.8447e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.123672
Average KL loss: 0.035206
Average total loss: 0.158878
tensor(0.0323, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-8.8245e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.119976
Average KL loss: 0.035224
Average total loss: 0.155200
tensor(0.0323, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-1.1628e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.121045
Average KL loss: 0.035243
Average total loss: 0.156287
tensor(0.0323, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-9.8345e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.121567
Average KL loss: 0.035262
Average total loss: 0.156829
tensor(0.0323, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-1.1553e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.118416
Average KL loss: 0.035280
Average total loss: 0.153695
tensor(0.0323, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-1.1490e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.119644
Average KL loss: 0.035297
Average total loss: 0.154941
tensor(0.0323, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-1.2679e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.122065
Average KL loss: 0.035317
Average total loss: 0.157383
tensor(0.0323, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-7.4887e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.119743
Average KL loss: 0.035335
Average total loss: 0.155078
tensor(0.0323, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-1.5872e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.119335
Average KL loss: 0.035354
Average total loss: 0.154689
tensor(0.0323, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-9.5239e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.117358
Average KL loss: 0.035373
Average total loss: 0.152731
tensor(0.0323, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-4.8109e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.120743
Average KL loss: 0.035393
Average total loss: 0.156136
tensor(0.0323, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-8.8164e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.117388
Average KL loss: 0.035414
Average total loss: 0.152801
tensor(0.0323, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-9.8821e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.119008
Average KL loss: 0.035436
Average total loss: 0.154444
tensor(0.0323, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-8.3568e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.120095
Average KL loss: 0.035457
Average total loss: 0.155551
tensor(0.0323, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-7.3932e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.122658
Average KL loss: 0.035477
Average total loss: 0.158135
tensor(0.0323, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-5.1959e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.115245
Average KL loss: 0.035496
Average total loss: 0.150741
tensor(0.0323, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-1.1202e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.115063
Average KL loss: 0.035512
Average total loss: 0.150576
tensor(0.0323, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-6.9196e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.115990
Average KL loss: 0.035529
Average total loss: 0.151520
tensor(0.0323, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-5.7784e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.116337
Average KL loss: 0.035547
Average total loss: 0.151884
tensor(0.0323, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-8.6017e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.116806
Average KL loss: 0.035566
Average total loss: 0.152372
tensor(0.0323, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-1.0161e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.116287
Average KL loss: 0.035584
Average total loss: 0.151871
tensor(0.0322, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-6.8081e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.115279
Average KL loss: 0.035603
Average total loss: 0.150882
tensor(0.0322, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-7.5737e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.109329
Average KL loss: 0.035621
Average total loss: 0.144950
tensor(0.0322, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-4.7495e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.112503
Average KL loss: 0.035635
Average total loss: 0.148139
tensor(0.0322, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-7.3339e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.113480
Average KL loss: 0.035652
Average total loss: 0.149132
tensor(0.0322, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.6278e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.116239
Average KL loss: 0.035673
Average total loss: 0.151912
tensor(0.0322, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.2079e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.116526
Average KL loss: 0.035693
Average total loss: 0.152218
tensor(0.0322, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-8.7050e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.113857
Average KL loss: 0.035712
Average total loss: 0.149569
tensor(0.0322, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-1.0481e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.111399
Average KL loss: 0.035728
Average total loss: 0.147128
tensor(0.0322, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-1.1461e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.114034
Average KL loss: 0.035743
Average total loss: 0.149777
tensor(0.0322, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-8.6942e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.114132
Average KL loss: 0.035763
Average total loss: 0.149895
tensor(0.0322, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-5.6557e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.109806
Average KL loss: 0.035782
Average total loss: 0.145588
tensor(0.0322, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-7.0349e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.111739
Average KL loss: 0.035799
Average total loss: 0.147538
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.1821e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.111470
Average KL loss: 0.035819
Average total loss: 0.147289
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-7.1052e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.109638
Average KL loss: 0.035830
Average total loss: 0.145468
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-5.3857e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.109224
Average KL loss: 0.035831
Average total loss: 0.145055
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.0204e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.107030
Average KL loss: 0.035833
Average total loss: 0.142862
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-4.7212e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.109337
Average KL loss: 0.035834
Average total loss: 0.145171
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-7.8192e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.111741
Average KL loss: 0.035836
Average total loss: 0.147577
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-7.4919e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.110304
Average KL loss: 0.035838
Average total loss: 0.146142
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-9.7749e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.111215
Average KL loss: 0.035839
Average total loss: 0.147055
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-9.4247e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.109285
Average KL loss: 0.035841
Average total loss: 0.145126
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-9.1589e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.112029
Average KL loss: 0.035842
Average total loss: 0.147871
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-7.2714e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.113163
Average KL loss: 0.035844
Average total loss: 0.149007
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-6.6615e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.109504
Average KL loss: 0.035846
Average total loss: 0.145349
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-6.9851e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.113229
Average KL loss: 0.035847
Average total loss: 0.149076
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-8.1755e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.107235
Average KL loss: 0.035849
Average total loss: 0.143084
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.2157e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.109134
Average KL loss: 0.035850
Average total loss: 0.144985
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-6.9778e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.109579
Average KL loss: 0.035851
Average total loss: 0.145431
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-7.5576e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.110515
Average KL loss: 0.035851
Average total loss: 0.146367
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-8.7958e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.108382
Average KL loss: 0.035852
Average total loss: 0.144233
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-9.3670e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.109047
Average KL loss: 0.035852
Average total loss: 0.144898
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-9.5073e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.111659
Average KL loss: 0.035852
Average total loss: 0.147511
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.0919e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.109067
Average KL loss: 0.035852
Average total loss: 0.144919
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-6.7401e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.110871
Average KL loss: 0.035852
Average total loss: 0.146724
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-7.4491e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.112565
Average KL loss: 0.035852
Average total loss: 0.148417
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-5.9039e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.105893
Average KL loss: 0.035853
Average total loss: 0.141746
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-8.2451e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.109598
Average KL loss: 0.035853
Average total loss: 0.145450
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-7.1783e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.110443
Average KL loss: 0.035853
Average total loss: 0.146296
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-5.3208e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.112500
Average KL loss: 0.035853
Average total loss: 0.148353
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.3860e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.111911
Average KL loss: 0.035853
Average total loss: 0.147764
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-9.0084e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.111204
Average KL loss: 0.035853
Average total loss: 0.147057
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.2471e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.113573
Average KL loss: 0.035853
Average total loss: 0.149426
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-9.0566e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.110161
Average KL loss: 0.035854
Average total loss: 0.146014
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-5.4562e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.110772
Average KL loss: 0.035854
Average total loss: 0.146626
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-7.9873e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.108885
Average KL loss: 0.035854
Average total loss: 0.144739
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-8.1943e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.109845
Average KL loss: 0.035854
Average total loss: 0.145699
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.3988e-08, device='cuda:0')
 Percentile value: 0.7011276483535767
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =     159 /    1728             (  9.20%) | total_pruned =    1569 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     289 /   36864             (  0.78%) | total_pruned =   36575 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     672 /   36864             (  1.82%) | total_pruned =   36192 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     797 /   36864             (  2.16%) | total_pruned =   36067 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1578 /   36864             (  4.28%) | total_pruned =   35286 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    5034 /   73728             (  6.83%) | total_pruned =   68694 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   11962 /  147456             (  8.11%) | total_pruned =  135494 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1062 /    8192             ( 12.96%) | total_pruned =    7130 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    6806 /  147456             (  4.62%) | total_pruned =  140650 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    6441 /  147456             (  4.37%) | total_pruned =  141015 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   29748 /  294912             ( 10.09%) | total_pruned =  265164 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   45580 /  589824             (  7.73%) | total_pruned =  544244 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3996 /   32768             ( 12.19%) | total_pruned =   28772 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     202 /     256             ( 78.91%) | total_pruned =      54 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   22083 /  589824             (  3.74%) | total_pruned =  567741 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     178 /     256             ( 69.53%) | total_pruned =      78 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   17205 /  589824             (  2.92%) | total_pruned =  572619 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   52659 / 1179648             (  4.46%) | total_pruned = 1126989 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     431 /     512             ( 84.18%) | total_pruned =      81 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   50138 / 2359296             (  2.13%) | total_pruned = 2309158 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     420 /     512             ( 82.03%) | total_pruned =      92 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1444 /  131072             (  1.10%) | total_pruned =  129628 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     189 /     512             ( 36.91%) | total_pruned =     323 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     228 /     512             ( 44.53%) | total_pruned =     284 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   31126 / 2359296             (  1.32%) | total_pruned = 2328170 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     215 /     512             ( 41.99%) | total_pruned =     297 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   52505 / 2359296             (  2.23%) | total_pruned = 2306791 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     423 /     512             ( 82.62%) | total_pruned =      89 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     416 /     512             ( 81.25%) | total_pruned =      96 | shape = torch.Size([512])
linear.weight        | nonzeros =    3726 /    5120             ( 72.77%) | total_pruned =    1394 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 58/100 Loss: 0.020124 Accuracy: 88.22 100.00 % Best test Accuracy: 88.22%
tensor(0.0322, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-4.0124e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.249729
Average KL loss: 0.035373
Average total loss: 0.285102
tensor(0.0312, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-2.4667e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.238412
Average KL loss: 0.034630
Average total loss: 0.273043
tensor(0.0303, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-3.1609e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.235906
Average KL loss: 0.034033
Average total loss: 0.269939
tensor(0.0296, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-2.9956e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.226691
Average KL loss: 0.033542
Average total loss: 0.260233
tensor(0.0290, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-3.2207e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.230476
Average KL loss: 0.033129
Average total loss: 0.263605
tensor(0.0284, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-2.3489e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.224691
Average KL loss: 0.032783
Average total loss: 0.257474
tensor(0.0279, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-2.8430e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.225465
Average KL loss: 0.032487
Average total loss: 0.257952
tensor(0.0275, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-3.1955e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.223963
Average KL loss: 0.032228
Average total loss: 0.256191
tensor(0.0272, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-1.7957e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.211078
Average KL loss: 0.032001
Average total loss: 0.243079
tensor(0.0269, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-2.0283e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.219344
Average KL loss: 0.031802
Average total loss: 0.251146
tensor(0.0266, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-2.4084e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.214070
Average KL loss: 0.031626
Average total loss: 0.245696
tensor(0.0264, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-2.3525e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.221216
Average KL loss: 0.031467
Average total loss: 0.252683
tensor(0.0261, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-2.1931e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.212892
Average KL loss: 0.031322
Average total loss: 0.244214
tensor(0.0260, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-2.0952e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.208557
Average KL loss: 0.031191
Average total loss: 0.239748
tensor(0.0258, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-3.0607e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.217178
Average KL loss: 0.031072
Average total loss: 0.248250
tensor(0.0257, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-2.4008e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.213234
Average KL loss: 0.030963
Average total loss: 0.244197
tensor(0.0255, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-2.4908e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.217625
Average KL loss: 0.030865
Average total loss: 0.248490
tensor(0.0254, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.9276e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.201163
Average KL loss: 0.030776
Average total loss: 0.231939
tensor(0.0253, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-2.6977e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.211603
Average KL loss: 0.030694
Average total loss: 0.242296
tensor(0.0252, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.9256e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.200669
Average KL loss: 0.030618
Average total loss: 0.231288
tensor(0.0251, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-2.3392e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.208388
Average KL loss: 0.030548
Average total loss: 0.238936
tensor(0.0250, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-2.3980e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.200072
Average KL loss: 0.030485
Average total loss: 0.230558
tensor(0.0250, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.8054e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.203805
Average KL loss: 0.030427
Average total loss: 0.234232
tensor(0.0249, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-2.3087e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.207334
Average KL loss: 0.030375
Average total loss: 0.237709
tensor(0.0248, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-1.5059e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.195576
Average KL loss: 0.030324
Average total loss: 0.225900
tensor(0.0248, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-2.2214e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.195585
Average KL loss: 0.030276
Average total loss: 0.225861
tensor(0.0247, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.5577e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.200769
Average KL loss: 0.030231
Average total loss: 0.231000
tensor(0.0246, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.7213e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.191558
Average KL loss: 0.030191
Average total loss: 0.221749
tensor(0.0246, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-2.4704e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.191217
Average KL loss: 0.030154
Average total loss: 0.221372
tensor(0.0245, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-2.3609e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.198936
Average KL loss: 0.030121
Average total loss: 0.229058
tensor(0.0245, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-1.9166e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.189998
Average KL loss: 0.030093
Average total loss: 0.220091
tensor(0.0245, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-2.1561e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.190999
Average KL loss: 0.030066
Average total loss: 0.221065
tensor(0.0244, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-2.5742e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.189604
Average KL loss: 0.030040
Average total loss: 0.219644
tensor(0.0244, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.8290e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.189580
Average KL loss: 0.030018
Average total loss: 0.219598
tensor(0.0243, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.4231e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.183790
Average KL loss: 0.029996
Average total loss: 0.213786
tensor(0.0243, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.6738e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.179620
Average KL loss: 0.029977
Average total loss: 0.209597
tensor(0.0243, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.3722e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.181255
Average KL loss: 0.029959
Average total loss: 0.211214
tensor(0.0243, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-2.0507e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.185491
Average KL loss: 0.029942
Average total loss: 0.215433
tensor(0.0242, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.9681e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.179357
Average KL loss: 0.029928
Average total loss: 0.209284
tensor(0.0242, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-2.3159e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.181286
Average KL loss: 0.029914
Average total loss: 0.211200
tensor(0.0242, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.3873e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.185774
Average KL loss: 0.029902
Average total loss: 0.215677
tensor(0.0241, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-2.0215e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.179338
Average KL loss: 0.029892
Average total loss: 0.209230
tensor(0.0241, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.5062e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.183015
Average KL loss: 0.029882
Average total loss: 0.212897
tensor(0.0241, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.8262e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.178813
Average KL loss: 0.029874
Average total loss: 0.208688
tensor(0.0241, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.3991e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.179568
Average KL loss: 0.029867
Average total loss: 0.209436
tensor(0.0241, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.7800e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.184050
Average KL loss: 0.029862
Average total loss: 0.213912
tensor(0.0240, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.5148e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.172726
Average KL loss: 0.029856
Average total loss: 0.202583
tensor(0.0240, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.7343e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.169658
Average KL loss: 0.029852
Average total loss: 0.199510
tensor(0.0240, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.4626e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.176017
Average KL loss: 0.029849
Average total loss: 0.205866
tensor(0.0240, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.2446e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.177842
Average KL loss: 0.029851
Average total loss: 0.207692
tensor(0.0240, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.6701e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.167319
Average KL loss: 0.029849
Average total loss: 0.197169
tensor(0.0240, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.8627e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.171886
Average KL loss: 0.029849
Average total loss: 0.201735
tensor(0.0240, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.9218e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.174131
Average KL loss: 0.029851
Average total loss: 0.203982
tensor(0.0239, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-2.5731e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.168698
Average KL loss: 0.029853
Average total loss: 0.198551
tensor(0.0239, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-2.0611e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.172911
Average KL loss: 0.029855
Average total loss: 0.202766
tensor(0.0239, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.7664e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.171668
Average KL loss: 0.029858
Average total loss: 0.201526
tensor(0.0239, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.4907e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.164719
Average KL loss: 0.029863
Average total loss: 0.194582
tensor(0.0239, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.5495e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.175716
Average KL loss: 0.029867
Average total loss: 0.205582
tensor(0.0239, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.3013e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.169463
Average KL loss: 0.029872
Average total loss: 0.199335
tensor(0.0239, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.6198e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.164210
Average KL loss: 0.029877
Average total loss: 0.194086
tensor(0.0239, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.4523e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.156974
Average KL loss: 0.029882
Average total loss: 0.186857
tensor(0.0239, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.8258e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.163919
Average KL loss: 0.029887
Average total loss: 0.193806
tensor(0.0239, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.8373e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.159663
Average KL loss: 0.029895
Average total loss: 0.189558
tensor(0.0239, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.3574e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.158446
Average KL loss: 0.029901
Average total loss: 0.188347
tensor(0.0238, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.8650e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.165187
Average KL loss: 0.029909
Average total loss: 0.195097
tensor(0.0238, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.8182e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.159585
Average KL loss: 0.029917
Average total loss: 0.189503
tensor(0.0238, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.6205e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.158285
Average KL loss: 0.029924
Average total loss: 0.188209
tensor(0.0238, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.4763e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.159289
Average KL loss: 0.029932
Average total loss: 0.189221
tensor(0.0238, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-2.1145e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.157086
Average KL loss: 0.029940
Average total loss: 0.187025
tensor(0.0238, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.9758e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.160213
Average KL loss: 0.029948
Average total loss: 0.190161
tensor(0.0238, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.5952e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.153360
Average KL loss: 0.029956
Average total loss: 0.183316
tensor(0.0238, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.3189e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.161630
Average KL loss: 0.029964
Average total loss: 0.191594
tensor(0.0238, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.9097e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.157645
Average KL loss: 0.029974
Average total loss: 0.187619
tensor(0.0238, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.4391e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.157654
Average KL loss: 0.029985
Average total loss: 0.187638
tensor(0.0238, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.3785e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.159919
Average KL loss: 0.029995
Average total loss: 0.189914
tensor(0.0238, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-2.0136e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.157744
Average KL loss: 0.030006
Average total loss: 0.187750
tensor(0.0238, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.4447e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.153610
Average KL loss: 0.030016
Average total loss: 0.183626
tensor(0.0238, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.6757e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.153119
Average KL loss: 0.030028
Average total loss: 0.183147
tensor(0.0238, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.6065e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.154138
Average KL loss: 0.030040
Average total loss: 0.184178
tensor(0.0238, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-8.9695e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.153417
Average KL loss: 0.030052
Average total loss: 0.183469
tensor(0.0238, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.0537e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.156529
Average KL loss: 0.030062
Average total loss: 0.186591
tensor(0.0238, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.2735e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.155597
Average KL loss: 0.030077
Average total loss: 0.185674
tensor(0.0238, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.7483e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.155595
Average KL loss: 0.030093
Average total loss: 0.185688
tensor(0.0238, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-1.3968e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.153516
Average KL loss: 0.030106
Average total loss: 0.183622
tensor(0.0238, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-2.0903e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.147665
Average KL loss: 0.030121
Average total loss: 0.177786
tensor(0.0238, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-1.8137e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.152433
Average KL loss: 0.030134
Average total loss: 0.182567
tensor(0.0238, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-1.4562e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.151537
Average KL loss: 0.030148
Average total loss: 0.181685
tensor(0.0238, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.4088e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.148734
Average KL loss: 0.030162
Average total loss: 0.178897
tensor(0.0238, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.4031e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.146220
Average KL loss: 0.030177
Average total loss: 0.176397
tensor(0.0238, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.7741e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.150147
Average KL loss: 0.030192
Average total loss: 0.180339
tensor(0.0238, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.5183e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.152382
Average KL loss: 0.030208
Average total loss: 0.182590
tensor(0.0238, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.4240e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.148192
Average KL loss: 0.030226
Average total loss: 0.178418
tensor(0.0238, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.4776e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.146788
Average KL loss: 0.030245
Average total loss: 0.177033
tensor(0.0238, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.5168e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.145002
Average KL loss: 0.030261
Average total loss: 0.175264
tensor(0.0238, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-1.6545e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.144882
Average KL loss: 0.030278
Average total loss: 0.175160
tensor(0.0238, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-1.4743e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.147055
Average KL loss: 0.030295
Average total loss: 0.177351
tensor(0.0238, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-1.4475e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.138560
Average KL loss: 0.030313
Average total loss: 0.168872
tensor(0.0238, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-1.6466e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.142607
Average KL loss: 0.030329
Average total loss: 0.172935
tensor(0.0238, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.2727e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.143775
Average KL loss: 0.030345
Average total loss: 0.174120
tensor(0.0238, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.3696e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.138179
Average KL loss: 0.030361
Average total loss: 0.168541
tensor(0.0238, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-2.1499e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.144742
Average KL loss: 0.030380
Average total loss: 0.175123
tensor(0.0238, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.4819e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.142483
Average KL loss: 0.030401
Average total loss: 0.172884
tensor(0.0238, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-1.4020e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.137333
Average KL loss: 0.030419
Average total loss: 0.167752
tensor(0.0238, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-1.0500e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.140910
Average KL loss: 0.030438
Average total loss: 0.171348
tensor(0.0238, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-1.3129e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.136735
Average KL loss: 0.030456
Average total loss: 0.167191
tensor(0.0238, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-1.2402e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.137013
Average KL loss: 0.030474
Average total loss: 0.167487
tensor(0.0238, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-1.4275e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.138924
Average KL loss: 0.030493
Average total loss: 0.169417
tensor(0.0238, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-1.3309e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.143308
Average KL loss: 0.030512
Average total loss: 0.173820
tensor(0.0238, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.1606e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.137518
Average KL loss: 0.030529
Average total loss: 0.168047
tensor(0.0238, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-9.3365e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.136170
Average KL loss: 0.030546
Average total loss: 0.166716
tensor(0.0238, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.1886e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.141207
Average KL loss: 0.030564
Average total loss: 0.171771
tensor(0.0238, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.5239e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.132828
Average KL loss: 0.030582
Average total loss: 0.163410
tensor(0.0238, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-1.4612e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.133806
Average KL loss: 0.030599
Average total loss: 0.164405
tensor(0.0238, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-1.0758e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.132615
Average KL loss: 0.030619
Average total loss: 0.163234
tensor(0.0238, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-1.1884e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.142286
Average KL loss: 0.030636
Average total loss: 0.172922
tensor(0.0238, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-8.5112e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.135783
Average KL loss: 0.030656
Average total loss: 0.166439
tensor(0.0238, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.6319e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.132253
Average KL loss: 0.030675
Average total loss: 0.162928
tensor(0.0238, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.3736e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.136416
Average KL loss: 0.030693
Average total loss: 0.167110
tensor(0.0238, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.9328e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.129794
Average KL loss: 0.030711
Average total loss: 0.160505
tensor(0.0238, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-1.0743e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.131346
Average KL loss: 0.030730
Average total loss: 0.162076
tensor(0.0238, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-1.2398e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.133831
Average KL loss: 0.030748
Average total loss: 0.164579
tensor(0.0238, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-1.5221e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.132410
Average KL loss: 0.030767
Average total loss: 0.163177
tensor(0.0238, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-3.2671e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.128135
Average KL loss: 0.030788
Average total loss: 0.158923
tensor(0.0238, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-1.6496e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.131111
Average KL loss: 0.030806
Average total loss: 0.161917
tensor(0.0238, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-1.2613e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.133658
Average KL loss: 0.030826
Average total loss: 0.164483
tensor(0.0239, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-8.4925e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.132263
Average KL loss: 0.030847
Average total loss: 0.163109
tensor(0.0239, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-1.1086e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.127170
Average KL loss: 0.030867
Average total loss: 0.158037
tensor(0.0239, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-1.0010e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.126793
Average KL loss: 0.030884
Average total loss: 0.157677
tensor(0.0239, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-1.2936e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.131033
Average KL loss: 0.030904
Average total loss: 0.161938
tensor(0.0239, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-1.3769e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.130387
Average KL loss: 0.030925
Average total loss: 0.161312
tensor(0.0239, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-1.4108e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.128410
Average KL loss: 0.030944
Average total loss: 0.159354
tensor(0.0239, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-1.2941e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.125772
Average KL loss: 0.030963
Average total loss: 0.156735
tensor(0.0239, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-1.0244e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.124312
Average KL loss: 0.030982
Average total loss: 0.155294
tensor(0.0239, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-1.2675e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.130232
Average KL loss: 0.031000
Average total loss: 0.161232
tensor(0.0239, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-1.7839e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.126352
Average KL loss: 0.031020
Average total loss: 0.157372
tensor(0.0239, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-9.8408e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.125881
Average KL loss: 0.031039
Average total loss: 0.156920
tensor(0.0239, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-1.1708e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.122192
Average KL loss: 0.031058
Average total loss: 0.153250
tensor(0.0239, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-1.2579e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.121819
Average KL loss: 0.031077
Average total loss: 0.152896
tensor(0.0239, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.0873e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.125525
Average KL loss: 0.031096
Average total loss: 0.156621
tensor(0.0239, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.4306e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.123909
Average KL loss: 0.031116
Average total loss: 0.155025
tensor(0.0239, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.5883e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.121015
Average KL loss: 0.031135
Average total loss: 0.152150
tensor(0.0239, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.1605e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.128095
Average KL loss: 0.031154
Average total loss: 0.159250
tensor(0.0239, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-1.7135e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.123639
Average KL loss: 0.031174
Average total loss: 0.154814
tensor(0.0239, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-1.0384e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.122856
Average KL loss: 0.031192
Average total loss: 0.154048
tensor(0.0239, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-1.0539e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.122431
Average KL loss: 0.031210
Average total loss: 0.153641
tensor(0.0239, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-1.1549e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.122527
Average KL loss: 0.031228
Average total loss: 0.153755
tensor(0.0239, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-8.6369e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.121665
Average KL loss: 0.031246
Average total loss: 0.152911
tensor(0.0239, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-1.0306e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.120932
Average KL loss: 0.031266
Average total loss: 0.152199
tensor(0.0239, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-1.4047e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.118343
Average KL loss: 0.031285
Average total loss: 0.149627
tensor(0.0239, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-1.6932e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.121358
Average KL loss: 0.031303
Average total loss: 0.152661
tensor(0.0239, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-1.1499e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.117237
Average KL loss: 0.031321
Average total loss: 0.148558
tensor(0.0239, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-9.1201e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.118058
Average KL loss: 0.031340
Average total loss: 0.149398
tensor(0.0239, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-9.2462e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.120233
Average KL loss: 0.031359
Average total loss: 0.151592
tensor(0.0239, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-8.6654e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.121312
Average KL loss: 0.031378
Average total loss: 0.152690
tensor(0.0239, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-1.1473e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.117394
Average KL loss: 0.031398
Average total loss: 0.148793
tensor(0.0240, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-1.1693e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.121101
Average KL loss: 0.031419
Average total loss: 0.152520
tensor(0.0240, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-1.0268e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.119330
Average KL loss: 0.031439
Average total loss: 0.150770
tensor(0.0240, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-8.2632e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.117802
Average KL loss: 0.031458
Average total loss: 0.149260
tensor(0.0240, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-1.1113e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.117669
Average KL loss: 0.031476
Average total loss: 0.149145
tensor(0.0240, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-8.5500e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.114496
Average KL loss: 0.031495
Average total loss: 0.145991
tensor(0.0240, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-8.9688e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.113980
Average KL loss: 0.031515
Average total loss: 0.145495
tensor(0.0240, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-8.4638e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.119108
Average KL loss: 0.031533
Average total loss: 0.150641
tensor(0.0240, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-7.7758e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.117208
Average KL loss: 0.031552
Average total loss: 0.148760
tensor(0.0240, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-8.6243e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.115793
Average KL loss: 0.031573
Average total loss: 0.147366
tensor(0.0240, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-1.8816e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.121377
Average KL loss: 0.031594
Average total loss: 0.152972
tensor(0.0240, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-9.6242e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.116457
Average KL loss: 0.031615
Average total loss: 0.148072
tensor(0.0240, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-7.9943e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.115988
Average KL loss: 0.031636
Average total loss: 0.147624
tensor(0.0240, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-9.4057e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.112197
Average KL loss: 0.031652
Average total loss: 0.143849
tensor(0.0240, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-8.0964e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.113724
Average KL loss: 0.031668
Average total loss: 0.145392
tensor(0.0240, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-6.3441e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.116588
Average KL loss: 0.031686
Average total loss: 0.148274
tensor(0.0240, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-8.9556e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.117630
Average KL loss: 0.031706
Average total loss: 0.149336
tensor(0.0240, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-1.2866e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.116597
Average KL loss: 0.031726
Average total loss: 0.148323
tensor(0.0240, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-1.5825e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.113660
Average KL loss: 0.031746
Average total loss: 0.145406
tensor(0.0240, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-8.8802e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.111096
Average KL loss: 0.031765
Average total loss: 0.142861
tensor(0.0240, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.2987e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.111432
Average KL loss: 0.031783
Average total loss: 0.143215
tensor(0.0240, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-8.6909e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.109084
Average KL loss: 0.031800
Average total loss: 0.140883
tensor(0.0240, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-1.0383e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.108234
Average KL loss: 0.031817
Average total loss: 0.140051
tensor(0.0240, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-8.6187e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.112610
Average KL loss: 0.031835
Average total loss: 0.144445
tensor(0.0240, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.0244e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.110427
Average KL loss: 0.031855
Average total loss: 0.142282
tensor(0.0240, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-7.3005e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.108418
Average KL loss: 0.031874
Average total loss: 0.140292
tensor(0.0241, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.7571e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.114884
Average KL loss: 0.031890
Average total loss: 0.146774
tensor(0.0241, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-8.4877e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.113692
Average KL loss: 0.031908
Average total loss: 0.145600
tensor(0.0241, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-7.4229e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.104982
Average KL loss: 0.031927
Average total loss: 0.136909
tensor(0.0241, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-8.7983e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.109181
Average KL loss: 0.031944
Average total loss: 0.141125
tensor(0.0241, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.5644e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.108748
Average KL loss: 0.031961
Average total loss: 0.140709
tensor(0.0241, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.1245e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.108802
Average KL loss: 0.031978
Average total loss: 0.140780
tensor(0.0241, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.0031e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.105744
Average KL loss: 0.031995
Average total loss: 0.137739
tensor(0.0241, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-1.2601e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.108278
Average KL loss: 0.032013
Average total loss: 0.140291
tensor(0.0241, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-9.9664e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.109972
Average KL loss: 0.032031
Average total loss: 0.142003
tensor(0.0241, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-8.1457e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.110857
Average KL loss: 0.032049
Average total loss: 0.142906
tensor(0.0241, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.0626e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.104418
Average KL loss: 0.032068
Average total loss: 0.136486
tensor(0.0241, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-9.3094e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.109277
Average KL loss: 0.032085
Average total loss: 0.141363
tensor(0.0241, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-3.8861e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.105404
Average KL loss: 0.032103
Average total loss: 0.137507
tensor(0.0241, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-9.9750e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.105792
Average KL loss: 0.032121
Average total loss: 0.137913
tensor(0.0241, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-1.0953e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.105870
Average KL loss: 0.032138
Average total loss: 0.138008
tensor(0.0241, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-1.1890e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.106869
Average KL loss: 0.032155
Average total loss: 0.139025
tensor(0.0241, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-2.2353e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.107021
Average KL loss: 0.032176
Average total loss: 0.139197
tensor(0.0241, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-1.0830e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.108052
Average KL loss: 0.032193
Average total loss: 0.140245
tensor(0.0241, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-1.0798e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.104916
Average KL loss: 0.032211
Average total loss: 0.137127
tensor(0.0241, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-9.2222e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.105207
Average KL loss: 0.032228
Average total loss: 0.137435
 Percentile value: 1.0878148078918457
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =     140 /    1728             (  8.10%) | total_pruned =    1588 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     164 /   36864             (  0.44%) | total_pruned =   36700 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     376 /   36864             (  1.02%) | total_pruned =   36488 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     588 /   36864             (  1.60%) | total_pruned =   36276 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1073 /   36864             (  2.91%) | total_pruned =   35791 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2917 /   73728             (  3.96%) | total_pruned =   70811 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6751 /  147456             (  4.58%) | total_pruned =  140705 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     703 /    8192             (  8.58%) | total_pruned =    7489 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3746 /  147456             (  2.54%) | total_pruned =  143710 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3654 /  147456             (  2.48%) | total_pruned =  143802 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   16308 /  294912             (  5.53%) | total_pruned =  278604 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   24467 /  589824             (  4.15%) | total_pruned =  565357 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2312 /   32768             (  7.06%) | total_pruned =   30456 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   11893 /  589824             (  2.02%) | total_pruned =  577931 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     157 /     256             ( 61.33%) | total_pruned =      99 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   10050 /  589824             (  1.70%) | total_pruned =  579774 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   27071 / 1179648             (  2.29%) | total_pruned = 1152577 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   23709 / 2359296             (  1.00%) | total_pruned = 2335587 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     337 /     512             ( 65.82%) | total_pruned =     175 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     192 /     512             ( 37.50%) | total_pruned =     320 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     699 /  131072             (  0.53%) | total_pruned =  130373 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     117 /     512             ( 22.85%) | total_pruned =     395 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     188 /     512             ( 36.72%) | total_pruned =     324 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   13952 / 2359296             (  0.59%) | total_pruned = 2345344 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     149 /     512             ( 29.10%) | total_pruned =     363 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   18400 / 2359296             (  0.78%) | total_pruned = 2340896 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     291 /     512             ( 56.84%) | total_pruned =     221 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     268 /     512             ( 52.34%) | total_pruned =     244 | shape = torch.Size([512])
linear.weight        | nonzeros =    2185 /    5120             ( 42.68%) | total_pruned =    2935 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 82/100 Loss: 0.020951 Accuracy: 88.32 100.00 % Best test Accuracy: 88.42%
tensor(0.0241, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-1.9927e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.187139
Average KL loss: 0.031902
Average total loss: 0.219040
tensor(0.0236, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.5062e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.186022
Average KL loss: 0.031364
Average total loss: 0.217386
tensor(0.0232, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-1.8426e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.179719
Average KL loss: 0.030900
Average total loss: 0.210619
tensor(0.0228, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-2.1663e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.183022
Average KL loss: 0.030492
Average total loss: 0.213514
tensor(0.0224, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-2.2646e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.177860
Average KL loss: 0.030133
Average total loss: 0.207993
tensor(0.0220, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-2.0079e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.170275
Average KL loss: 0.029815
Average total loss: 0.200091
tensor(0.0217, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.9773e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.173887
Average KL loss: 0.029535
Average total loss: 0.203421
tensor(0.0214, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-2.1446e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.180548
Average KL loss: 0.029287
Average total loss: 0.209835
tensor(0.0212, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.8442e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.170233
Average KL loss: 0.029069
Average total loss: 0.199302
tensor(0.0209, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.6531e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.168414
Average KL loss: 0.028874
Average total loss: 0.197288
tensor(0.0207, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-1.8724e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.169837
Average KL loss: 0.028698
Average total loss: 0.198535
tensor(0.0205, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.8243e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.173542
Average KL loss: 0.028541
Average total loss: 0.202083
tensor(0.0203, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.6728e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.167827
Average KL loss: 0.028400
Average total loss: 0.196227
tensor(0.0202, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.2799e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.162640
Average KL loss: 0.028272
Average total loss: 0.190912
tensor(0.0200, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.5591e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.167272
Average KL loss: 0.028155
Average total loss: 0.195427
tensor(0.0199, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-1.9542e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.166026
Average KL loss: 0.028047
Average total loss: 0.194073
tensor(0.0198, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-1.7754e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.166377
Average KL loss: 0.027950
Average total loss: 0.194327
tensor(0.0196, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-2.0397e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.171284
Average KL loss: 0.027861
Average total loss: 0.199144
tensor(0.0195, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-1.8108e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.163264
Average KL loss: 0.027780
Average total loss: 0.191044
tensor(0.0194, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-1.7816e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.168076
Average KL loss: 0.027704
Average total loss: 0.195780
tensor(0.0193, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-1.3751e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.158337
Average KL loss: 0.027634
Average total loss: 0.185971
tensor(0.0193, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-1.5126e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.161812
Average KL loss: 0.027567
Average total loss: 0.189379
tensor(0.0192, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-1.6414e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.163391
Average KL loss: 0.027505
Average total loss: 0.190897
tensor(0.0191, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-1.6016e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.160567
Average KL loss: 0.027450
Average total loss: 0.188017
tensor(0.0191, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-1.4497e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.157018
Average KL loss: 0.027396
Average total loss: 0.184413
tensor(0.0190, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-1.4303e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.157109
Average KL loss: 0.027345
Average total loss: 0.184453
tensor(0.0189, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-1.8650e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.158928
Average KL loss: 0.027297
Average total loss: 0.186225
tensor(0.0189, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-1.7987e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.155763
Average KL loss: 0.027253
Average total loss: 0.183017
tensor(0.0188, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-1.4228e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.154648
Average KL loss: 0.027212
Average total loss: 0.181860
tensor(0.0188, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-2.5770e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.157826
Average KL loss: 0.027172
Average total loss: 0.184998
tensor(0.0188, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-1.1114e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.157709
Average KL loss: 0.027134
Average total loss: 0.184844
tensor(0.0187, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-2.0727e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.153059
Average KL loss: 0.027100
Average total loss: 0.180159
tensor(0.0187, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.4733e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.146245
Average KL loss: 0.027067
Average total loss: 0.173312
tensor(0.0187, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.0358e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.149528
Average KL loss: 0.027037
Average total loss: 0.176564
tensor(0.0186, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.0037e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.156751
Average KL loss: 0.027009
Average total loss: 0.183760
tensor(0.0186, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.8262e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.151944
Average KL loss: 0.026984
Average total loss: 0.178928
tensor(0.0186, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-1.8632e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.153740
Average KL loss: 0.026960
Average total loss: 0.180701
tensor(0.0185, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-1.7608e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.150218
Average KL loss: 0.026938
Average total loss: 0.177157
tensor(0.0185, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-1.5303e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.149949
Average KL loss: 0.026919
Average total loss: 0.176868
tensor(0.0185, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-1.4470e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.147795
Average KL loss: 0.026900
Average total loss: 0.174695
tensor(0.0185, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-2.2013e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.152449
Average KL loss: 0.026883
Average total loss: 0.179332
tensor(0.0184, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.4667e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.138678
Average KL loss: 0.026866
Average total loss: 0.165544
tensor(0.0184, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.4412e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.145321
Average KL loss: 0.026850
Average total loss: 0.172171
tensor(0.0184, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.5247e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.147658
Average KL loss: 0.026835
Average total loss: 0.174493
tensor(0.0184, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.3276e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.150272
Average KL loss: 0.026822
Average total loss: 0.177094
tensor(0.0184, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.5714e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.148228
Average KL loss: 0.026810
Average total loss: 0.175038
tensor(0.0183, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.5628e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.144304
Average KL loss: 0.026800
Average total loss: 0.171104
tensor(0.0183, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.6275e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.143324
Average KL loss: 0.026791
Average total loss: 0.170114
tensor(0.0183, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.4011e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.143315
Average KL loss: 0.026781
Average total loss: 0.170096
tensor(0.0183, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.7165e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.137589
Average KL loss: 0.026772
Average total loss: 0.164361
tensor(0.0183, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.5137e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.141167
Average KL loss: 0.026765
Average total loss: 0.167932
tensor(0.0183, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.6451e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.141008
Average KL loss: 0.026758
Average total loss: 0.167765
tensor(0.0183, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.8984e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.137668
Average KL loss: 0.026752
Average total loss: 0.164420
tensor(0.0183, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.1363e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.137824
Average KL loss: 0.026747
Average total loss: 0.164571
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.4219e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.136456
Average KL loss: 0.026743
Average total loss: 0.163199
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.3757e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.139976
Average KL loss: 0.026740
Average total loss: 0.166716
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.4215e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.138308
Average KL loss: 0.026737
Average total loss: 0.165044
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.1840e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.144013
Average KL loss: 0.026734
Average total loss: 0.170747
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-9.8423e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.139277
Average KL loss: 0.026733
Average total loss: 0.166010
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.3989e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.140110
Average KL loss: 0.026732
Average total loss: 0.166842
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.4212e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.134894
Average KL loss: 0.026731
Average total loss: 0.161625
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.2978e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.136461
Average KL loss: 0.026731
Average total loss: 0.163192
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.3245e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.131817
Average KL loss: 0.026731
Average total loss: 0.158547
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.3397e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.137406
Average KL loss: 0.026731
Average total loss: 0.164137
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.0494e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.131796
Average KL loss: 0.026732
Average total loss: 0.158528
tensor(0.0182, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.3233e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.136678
Average KL loss: 0.026733
Average total loss: 0.163411
tensor(0.0181, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.7062e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.141741
Average KL loss: 0.026735
Average total loss: 0.168475
tensor(0.0181, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.5410e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.134189
Average KL loss: 0.026739
Average total loss: 0.160928
tensor(0.0181, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.5604e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.145636
Average KL loss: 0.026743
Average total loss: 0.172378
tensor(0.0181, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.6891e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.134114
Average KL loss: 0.026746
Average total loss: 0.160860
tensor(0.0181, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.2191e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.134969
Average KL loss: 0.026750
Average total loss: 0.161719
tensor(0.0181, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.3042e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.126974
Average KL loss: 0.026755
Average total loss: 0.153729
tensor(0.0181, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.0188e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.129747
Average KL loss: 0.026759
Average total loss: 0.156506
tensor(0.0181, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.2451e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.131116
Average KL loss: 0.026765
Average total loss: 0.157881
tensor(0.0181, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.5009e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.135689
Average KL loss: 0.026770
Average total loss: 0.162459
tensor(0.0181, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.7743e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.135762
Average KL loss: 0.026777
Average total loss: 0.162539
tensor(0.0181, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.1080e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.132402
Average KL loss: 0.026783
Average total loss: 0.159185
tensor(0.0181, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.4631e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.129821
Average KL loss: 0.026789
Average total loss: 0.156610
tensor(0.0181, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.3865e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.125069
Average KL loss: 0.026796
Average total loss: 0.151866
tensor(0.0181, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.2175e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.127985
Average KL loss: 0.026803
Average total loss: 0.154788
tensor(0.0181, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.1748e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.128166
Average KL loss: 0.026810
Average total loss: 0.154976
tensor(0.0181, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.3198e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.126681
Average KL loss: 0.026817
Average total loss: 0.153498
tensor(0.0181, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-9.8543e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.124830
Average KL loss: 0.026826
Average total loss: 0.151656
tensor(0.0181, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.4935e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.132775
Average KL loss: 0.026833
Average total loss: 0.159608
tensor(0.0181, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.2483e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.127636
Average KL loss: 0.026843
Average total loss: 0.154478
tensor(0.0181, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-1.3210e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.134314
Average KL loss: 0.026852
Average total loss: 0.161166
tensor(0.0181, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-1.5525e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.124292
Average KL loss: 0.026861
Average total loss: 0.151153
tensor(0.0181, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-1.1529e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.121531
Average KL loss: 0.026869
Average total loss: 0.148401
tensor(0.0181, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-1.6874e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.133269
Average KL loss: 0.026878
Average total loss: 0.160147
tensor(0.0181, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-8.6972e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.122323
Average KL loss: 0.026888
Average total loss: 0.149212
tensor(0.0181, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-1.3941e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.121720
Average KL loss: 0.026898
Average total loss: 0.148617
tensor(0.0181, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-1.1760e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.131360
Average KL loss: 0.026907
Average total loss: 0.158267
tensor(0.0181, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-1.2369e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.124747
Average KL loss: 0.026918
Average total loss: 0.151665
tensor(0.0181, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-1.4548e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.115938
Average KL loss: 0.026928
Average total loss: 0.142866
tensor(0.0181, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.3817e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.122146
Average KL loss: 0.026938
Average total loss: 0.149084
tensor(0.0181, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.2367e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.125359
Average KL loss: 0.026948
Average total loss: 0.152307
tensor(0.0181, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.2746e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.118595
Average KL loss: 0.026958
Average total loss: 0.145553
tensor(0.0181, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.0785e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.120444
Average KL loss: 0.026969
Average total loss: 0.147413
tensor(0.0181, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.0916e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.120398
Average KL loss: 0.026981
Average total loss: 0.147379
tensor(0.0181, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.2096e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.120633
Average KL loss: 0.026993
Average total loss: 0.147626
tensor(0.0181, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.0289e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.116725
Average KL loss: 0.027006
Average total loss: 0.143731
tensor(0.0181, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-9.6922e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.118082
Average KL loss: 0.027017
Average total loss: 0.145098
tensor(0.0181, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.2349e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.120240
Average KL loss: 0.027029
Average total loss: 0.147268
tensor(0.0181, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-1.2404e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.115531
Average KL loss: 0.027042
Average total loss: 0.142573
tensor(0.0181, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-1.2460e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.117906
Average KL loss: 0.027053
Average total loss: 0.144960
tensor(0.0181, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-6.5665e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.120057
Average KL loss: 0.027067
Average total loss: 0.147124
tensor(0.0181, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-9.9958e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.120580
Average KL loss: 0.027080
Average total loss: 0.147660
tensor(0.0182, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-1.4095e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.115089
Average KL loss: 0.027094
Average total loss: 0.142183
tensor(0.0182, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-9.7712e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.118053
Average KL loss: 0.027109
Average total loss: 0.145162
tensor(0.0182, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-1.4382e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.114065
Average KL loss: 0.027123
Average total loss: 0.141188
tensor(0.0182, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-1.2701e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.118845
Average KL loss: 0.027137
Average total loss: 0.145982
tensor(0.0182, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-1.0923e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.116821
Average KL loss: 0.027151
Average total loss: 0.143972
tensor(0.0182, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-1.4441e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.112599
Average KL loss: 0.027165
Average total loss: 0.139764
tensor(0.0182, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-1.4717e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.111653
Average KL loss: 0.027179
Average total loss: 0.138832
tensor(0.0182, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-1.1675e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.119819
Average KL loss: 0.027193
Average total loss: 0.147012
tensor(0.0182, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-9.5592e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.112728
Average KL loss: 0.027207
Average total loss: 0.139935
tensor(0.0182, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-1.1215e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.115972
Average KL loss: 0.027221
Average total loss: 0.143193
tensor(0.0182, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-1.1840e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.114364
Average KL loss: 0.027236
Average total loss: 0.141600
tensor(0.0182, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-1.2390e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.114855
Average KL loss: 0.027252
Average total loss: 0.142107
tensor(0.0182, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-1.6993e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.113728
Average KL loss: 0.027267
Average total loss: 0.140995
tensor(0.0182, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-8.3078e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.114121
Average KL loss: 0.027282
Average total loss: 0.141403
tensor(0.0182, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-3.4872e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.111984
Average KL loss: 0.027295
Average total loss: 0.139279
tensor(0.0182, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-1.2526e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.108337
Average KL loss: 0.027310
Average total loss: 0.135647
tensor(0.0182, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-7.9327e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.111580
Average KL loss: 0.027325
Average total loss: 0.138905
tensor(0.0182, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-1.0276e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.114826
Average KL loss: 0.027340
Average total loss: 0.142165
tensor(0.0182, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-1.0442e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.111143
Average KL loss: 0.027354
Average total loss: 0.138497
tensor(0.0182, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-9.5028e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.112361
Average KL loss: 0.027369
Average total loss: 0.139730
tensor(0.0182, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-8.8732e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.107153
Average KL loss: 0.027384
Average total loss: 0.134537
tensor(0.0182, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-8.6618e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.107552
Average KL loss: 0.027398
Average total loss: 0.134950
tensor(0.0182, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-9.3320e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.106313
Average KL loss: 0.027411
Average total loss: 0.133724
tensor(0.0182, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-1.1004e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.108239
Average KL loss: 0.027426
Average total loss: 0.135664
tensor(0.0182, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-8.8091e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.107033
Average KL loss: 0.027442
Average total loss: 0.134475
tensor(0.0183, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-1.0964e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.110303
Average KL loss: 0.027457
Average total loss: 0.137760
tensor(0.0183, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-8.7221e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.107432
Average KL loss: 0.027471
Average total loss: 0.134903
tensor(0.0183, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-8.7647e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.106645
Average KL loss: 0.027486
Average total loss: 0.134131
tensor(0.0183, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-1.2484e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.104838
Average KL loss: 0.027501
Average total loss: 0.132339
tensor(0.0183, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-8.6075e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.113014
Average KL loss: 0.027515
Average total loss: 0.140529
tensor(0.0183, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-7.3763e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.106925
Average KL loss: 0.027529
Average total loss: 0.134454
tensor(0.0183, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-1.0275e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.111257
Average KL loss: 0.027543
Average total loss: 0.138800
tensor(0.0183, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-1.1931e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.108052
Average KL loss: 0.027558
Average total loss: 0.135611
tensor(0.0183, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-1.0896e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.115481
Average KL loss: 0.027573
Average total loss: 0.143053
tensor(0.0183, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-1.0372e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.115338
Average KL loss: 0.027587
Average total loss: 0.142926
tensor(0.0183, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-8.1910e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.102035
Average KL loss: 0.027603
Average total loss: 0.129637
tensor(0.0183, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-1.1552e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.107100
Average KL loss: 0.027617
Average total loss: 0.134717
tensor(0.0183, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-1.0354e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.102814
Average KL loss: 0.027631
Average total loss: 0.130445
tensor(0.0183, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-7.7310e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.108964
Average KL loss: 0.027646
Average total loss: 0.136611
tensor(0.0183, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-9.7695e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.104029
Average KL loss: 0.027662
Average total loss: 0.131690
tensor(0.0183, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-8.2235e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.103316
Average KL loss: 0.027677
Average total loss: 0.130993
tensor(0.0183, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-1.0188e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.101865
Average KL loss: 0.027692
Average total loss: 0.129557
tensor(0.0183, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-1.4156e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.104630
Average KL loss: 0.027707
Average total loss: 0.132337
tensor(0.0183, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-8.3240e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.109448
Average KL loss: 0.027722
Average total loss: 0.137170
tensor(0.0183, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-6.9163e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.104698
Average KL loss: 0.027737
Average total loss: 0.132435
tensor(0.0183, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.0803e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.112081
Average KL loss: 0.027753
Average total loss: 0.139834
tensor(0.0183, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.1228e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.100182
Average KL loss: 0.027769
Average total loss: 0.127951
tensor(0.0184, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.2736e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.100843
Average KL loss: 0.027784
Average total loss: 0.128627
tensor(0.0184, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-8.9999e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.105018
Average KL loss: 0.027798
Average total loss: 0.132816
tensor(0.0184, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.0319e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.101047
Average KL loss: 0.027813
Average total loss: 0.128860
tensor(0.0184, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-8.3471e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.099281
Average KL loss: 0.027827
Average total loss: 0.127108
tensor(0.0184, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.1059e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.100660
Average KL loss: 0.027841
Average total loss: 0.128501
tensor(0.0184, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-9.9207e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.099030
Average KL loss: 0.027857
Average total loss: 0.126887
tensor(0.0184, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.0167e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.095076
Average KL loss: 0.027873
Average total loss: 0.122949
tensor(0.0184, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-8.8858e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.100577
Average KL loss: 0.027888
Average total loss: 0.128465
tensor(0.0184, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.0444e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.107636
Average KL loss: 0.027903
Average total loss: 0.135539
tensor(0.0184, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.0829e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.101316
Average KL loss: 0.027918
Average total loss: 0.129234
tensor(0.0184, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.1399e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.096191
Average KL loss: 0.027933
Average total loss: 0.124125
tensor(0.0184, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.0646e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.095693
Average KL loss: 0.027946
Average total loss: 0.123639
tensor(0.0184, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.1810e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.096919
Average KL loss: 0.027960
Average total loss: 0.124879
tensor(0.0184, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-9.2759e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.098036
Average KL loss: 0.027975
Average total loss: 0.126010
tensor(0.0184, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-6.1502e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.101675
Average KL loss: 0.027990
Average total loss: 0.129665
tensor(0.0184, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-5.7241e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.099373
Average KL loss: 0.028005
Average total loss: 0.127379
tensor(0.0184, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-7.8734e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.100359
Average KL loss: 0.028021
Average total loss: 0.128379
tensor(0.0184, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.0386e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.101244
Average KL loss: 0.028035
Average total loss: 0.129280
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-8.0697e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.094896
Average KL loss: 0.028044
Average total loss: 0.122940
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-8.1915e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.102320
Average KL loss: 0.028046
Average total loss: 0.130366
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-8.9452e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.101686
Average KL loss: 0.028048
Average total loss: 0.129734
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.1583e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.097975
Average KL loss: 0.028049
Average total loss: 0.126024
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.1347e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.095924
Average KL loss: 0.028051
Average total loss: 0.123974
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-8.4697e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.095916
Average KL loss: 0.028052
Average total loss: 0.123968
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-7.9690e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.099783
Average KL loss: 0.028054
Average total loss: 0.127836
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.1586e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.101188
Average KL loss: 0.028055
Average total loss: 0.129243
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.1287e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.105403
Average KL loss: 0.028057
Average total loss: 0.133460
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-9.3328e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.099433
Average KL loss: 0.028058
Average total loss: 0.127491
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-9.2704e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.097667
Average KL loss: 0.028060
Average total loss: 0.125726
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-8.7633e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.099288
Average KL loss: 0.028061
Average total loss: 0.127349
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-7.3489e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.092116
Average KL loss: 0.028061
Average total loss: 0.120177
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-6.8199e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.103602
Average KL loss: 0.028061
Average total loss: 0.131663
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-7.2088e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.096412
Average KL loss: 0.028061
Average total loss: 0.124473
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.0073e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.093486
Average KL loss: 0.028061
Average total loss: 0.121547
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-7.4014e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.097526
Average KL loss: 0.028061
Average total loss: 0.125588
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-7.8508e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.097899
Average KL loss: 0.028062
Average total loss: 0.125960
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.0035e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.098023
Average KL loss: 0.028062
Average total loss: 0.126085
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.3757e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.098417
Average KL loss: 0.028062
Average total loss: 0.126479
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.1527e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.099997
Average KL loss: 0.028062
Average total loss: 0.128059
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-7.7502e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.094213
Average KL loss: 0.028062
Average total loss: 0.122275
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-7.0834e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.093585
Average KL loss: 0.028062
Average total loss: 0.121647
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.2403e-08, device='cuda:0')
 Percentile value: 1.5652897357940674
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =     138 /    1728             (  7.99%) | total_pruned =    1590 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     117 /   36864             (  0.32%) | total_pruned =   36747 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     246 /   36864             (  0.67%) | total_pruned =   36618 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     412 /   36864             (  1.12%) | total_pruned =   36452 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     780 /   36864             (  2.12%) | total_pruned =   36084 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1836 /   73728             (  2.49%) | total_pruned =   71892 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3766 /  147456             (  2.55%) | total_pruned =  143690 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     487 /    8192             (  5.94%) | total_pruned =    7705 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2083 /  147456             (  1.41%) | total_pruned =  145373 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2210 /  147456             (  1.50%) | total_pruned =  145246 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8738 /  294912             (  2.96%) | total_pruned =  286174 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   13056 /  589824             (  2.21%) | total_pruned =  576768 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1289 /   32768             (  3.93%) | total_pruned =   31479 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6535 /  589824             (  1.11%) | total_pruned =  583289 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     151 /     256             ( 58.98%) | total_pruned =     105 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    5794 /  589824             (  0.98%) | total_pruned =  584030 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     146 /     256             ( 57.03%) | total_pruned =     110 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   13612 / 1179648             (  1.15%) | total_pruned = 1166036 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     381 /     512             ( 74.41%) | total_pruned =     131 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   10416 / 2359296             (  0.44%) | total_pruned = 2348880 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     242 /     512             ( 47.27%) | total_pruned =     270 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     121 /     512             ( 23.63%) | total_pruned =     391 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     291 /  131072             (  0.22%) | total_pruned =  130781 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      78 /     512             ( 15.23%) | total_pruned =     434 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     119 /     512             ( 23.24%) | total_pruned =     393 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    6466 / 2359296             (  0.27%) | total_pruned = 2352830 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     119 /     512             ( 23.24%) | total_pruned =     393 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    5436 / 2359296             (  0.23%) | total_pruned = 2353860 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     107 /     512             ( 20.90%) | total_pruned =     405 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
linear.weight        | nonzeros =     872 /    5120             ( 17.03%) | total_pruned =    4248 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 60/100 Loss: 0.015618 Accuracy: 86.74 100.00 % Best test Accuracy: 87.13%
tensor(0.0184, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-2.9033e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.241259
Average KL loss: 0.027774
Average total loss: 0.269034
tensor(0.0181, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-2.2065e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.231109
Average KL loss: 0.027268
Average total loss: 0.258378
tensor(0.0178, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-3.3495e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.238557
Average KL loss: 0.026799
Average total loss: 0.265357
tensor(0.0176, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-2.5185e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.236432
Average KL loss: 0.026362
Average total loss: 0.262793
tensor(0.0173, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-2.4627e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.232714
Average KL loss: 0.025954
Average total loss: 0.258668
tensor(0.0171, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-1.6990e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.236143
Average KL loss: 0.025574
Average total loss: 0.261717
tensor(0.0168, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-2.2271e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.243370
Average KL loss: 0.025223
Average total loss: 0.268593
tensor(0.0166, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-2.3373e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.225713
Average KL loss: 0.024898
Average total loss: 0.250611
tensor(0.0164, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-2.2493e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.226026
Average KL loss: 0.024598
Average total loss: 0.250624
tensor(0.0162, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-1.7629e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.230656
Average KL loss: 0.024322
Average total loss: 0.254978
tensor(0.0160, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.8978e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.247165
Average KL loss: 0.024069
Average total loss: 0.271234
tensor(0.0158, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-2.3353e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.229560
Average KL loss: 0.023837
Average total loss: 0.253397
tensor(0.0156, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-2.1330e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.229963
Average KL loss: 0.023626
Average total loss: 0.253589
tensor(0.0154, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-2.6233e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.231171
Average KL loss: 0.023434
Average total loss: 0.254605
tensor(0.0152, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-2.5150e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.217378
Average KL loss: 0.023260
Average total loss: 0.240637
tensor(0.0151, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-2.1194e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.221538
Average KL loss: 0.023101
Average total loss: 0.244639
tensor(0.0149, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-2.5574e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.218816
Average KL loss: 0.022957
Average total loss: 0.241773
tensor(0.0148, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-2.2289e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.220134
Average KL loss: 0.022827
Average total loss: 0.242962
tensor(0.0147, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-1.9452e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.216161
Average KL loss: 0.022710
Average total loss: 0.238871
tensor(0.0145, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-2.5004e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.219024
Average KL loss: 0.022605
Average total loss: 0.241628
tensor(0.0144, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-2.8428e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.219733
Average KL loss: 0.022510
Average total loss: 0.242243
tensor(0.0143, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.7859e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.216024
Average KL loss: 0.022425
Average total loss: 0.238449
tensor(0.0142, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-3.0232e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.212160
Average KL loss: 0.022348
Average total loss: 0.234507
tensor(0.0141, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-3.2343e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.212796
Average KL loss: 0.022278
Average total loss: 0.235074
tensor(0.0140, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-2.2739e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.212103
Average KL loss: 0.022216
Average total loss: 0.234319
tensor(0.0139, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.8620e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.212764
Average KL loss: 0.022160
Average total loss: 0.234924
tensor(0.0139, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-2.3893e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.213701
Average KL loss: 0.022110
Average total loss: 0.235811
tensor(0.0138, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-2.8227e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.215350
Average KL loss: 0.022064
Average total loss: 0.237415
tensor(0.0137, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-2.1094e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.198055
Average KL loss: 0.022023
Average total loss: 0.220078
tensor(0.0137, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.7035e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.206775
Average KL loss: 0.021986
Average total loss: 0.228762
tensor(0.0136, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.5329e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.199886
Average KL loss: 0.021952
Average total loss: 0.221839
tensor(0.0136, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.4430e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.201541
Average KL loss: 0.021922
Average total loss: 0.223463
tensor(0.0135, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.1547e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.207022
Average KL loss: 0.021895
Average total loss: 0.228917
tensor(0.0135, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.2658e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.204939
Average KL loss: 0.021871
Average total loss: 0.226810
tensor(0.0134, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.9466e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.199411
Average KL loss: 0.021849
Average total loss: 0.221260
tensor(0.0134, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.8444e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.199439
Average KL loss: 0.021830
Average total loss: 0.221268
tensor(0.0134, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-3.0312e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.208062
Average KL loss: 0.021812
Average total loss: 0.229874
tensor(0.0133, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.8529e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.200124
Average KL loss: 0.021796
Average total loss: 0.221921
tensor(0.0133, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.1790e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.197394
Average KL loss: 0.021783
Average total loss: 0.219177
tensor(0.0133, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.5168e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.216024
Average KL loss: 0.021771
Average total loss: 0.237794
tensor(0.0133, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.6304e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.196541
Average KL loss: 0.021760
Average total loss: 0.218301
tensor(0.0132, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.4060e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.193738
Average KL loss: 0.021750
Average total loss: 0.215489
tensor(0.0132, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.8456e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.192390
Average KL loss: 0.021742
Average total loss: 0.214132
tensor(0.0132, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-2.7727e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.202257
Average KL loss: 0.021735
Average total loss: 0.223992
tensor(0.0132, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-2.1293e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.196265
Average KL loss: 0.021728
Average total loss: 0.217993
tensor(0.0132, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.6383e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.190379
Average KL loss: 0.021724
Average total loss: 0.212103
tensor(0.0131, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-2.0712e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.190625
Average KL loss: 0.021720
Average total loss: 0.212344
tensor(0.0131, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-2.1640e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.183919
Average KL loss: 0.021716
Average total loss: 0.205635
tensor(0.0131, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-2.0993e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.191256
Average KL loss: 0.021713
Average total loss: 0.212969
tensor(0.0131, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.6342e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.186685
Average KL loss: 0.021710
Average total loss: 0.208395
tensor(0.0131, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.7450e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.181896
Average KL loss: 0.021709
Average total loss: 0.203605
tensor(0.0131, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.5979e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.185874
Average KL loss: 0.021708
Average total loss: 0.207582
tensor(0.0131, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.1075e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.203757
Average KL loss: 0.021707
Average total loss: 0.225465
tensor(0.0131, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.7920e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.178647
Average KL loss: 0.021707
Average total loss: 0.200354
tensor(0.0131, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.5880e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.193206
Average KL loss: 0.021708
Average total loss: 0.214914
tensor(0.0131, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.4947e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.179645
Average KL loss: 0.021710
Average total loss: 0.201354
tensor(0.0131, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.9526e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.194214
Average KL loss: 0.021711
Average total loss: 0.215925
tensor(0.0131, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.9244e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.178444
Average KL loss: 0.021713
Average total loss: 0.200157
tensor(0.0131, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-3.0587e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.186897
Average KL loss: 0.021716
Average total loss: 0.208613
tensor(0.0131, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.3086e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.182245
Average KL loss: 0.021719
Average total loss: 0.203964
tensor(0.0131, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.4194e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.180039
Average KL loss: 0.021722
Average total loss: 0.201761
tensor(0.0130, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.7285e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.186009
Average KL loss: 0.021726
Average total loss: 0.207735
tensor(0.0130, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.5649e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.184007
Average KL loss: 0.021730
Average total loss: 0.205737
tensor(0.0130, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.8528e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.181202
Average KL loss: 0.021735
Average total loss: 0.202937
tensor(0.0130, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.8419e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.178485
Average KL loss: 0.021740
Average total loss: 0.200225
tensor(0.0130, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.4175e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.177557
Average KL loss: 0.021745
Average total loss: 0.199302
tensor(0.0130, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-1.8738e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.193238
Average KL loss: 0.021750
Average total loss: 0.214988
tensor(0.0130, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-2.0336e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.179877
Average KL loss: 0.021756
Average total loss: 0.201633
tensor(0.0130, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-1.6465e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.176707
Average KL loss: 0.021762
Average total loss: 0.198469
tensor(0.0130, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-1.3574e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.172947
Average KL loss: 0.021767
Average total loss: 0.194715
tensor(0.0130, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-1.4141e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.170431
Average KL loss: 0.021773
Average total loss: 0.192204
tensor(0.0130, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-2.3346e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.180929
Average KL loss: 0.021780
Average total loss: 0.202708
tensor(0.0130, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.8970e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.173356
Average KL loss: 0.021786
Average total loss: 0.195141
tensor(0.0130, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-2.1367e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.173405
Average KL loss: 0.021792
Average total loss: 0.195197
tensor(0.0130, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.6677e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.168015
Average KL loss: 0.021799
Average total loss: 0.189814
tensor(0.0130, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.3193e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.174301
Average KL loss: 0.021805
Average total loss: 0.196106
tensor(0.0130, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.9736e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.172425
Average KL loss: 0.021813
Average total loss: 0.194238
tensor(0.0131, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-1.4953e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.177131
Average KL loss: 0.021820
Average total loss: 0.198951
tensor(0.0131, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-1.6985e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.170014
Average KL loss: 0.021828
Average total loss: 0.191842
tensor(0.0131, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-1.6866e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.170464
Average KL loss: 0.021836
Average total loss: 0.192300
tensor(0.0131, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-2.0283e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.172252
Average KL loss: 0.021844
Average total loss: 0.194097
tensor(0.0131, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-2.0363e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.174408
Average KL loss: 0.021853
Average total loss: 0.196260
tensor(0.0131, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.5395e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.169629
Average KL loss: 0.021861
Average total loss: 0.191490
tensor(0.0131, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.8305e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.163553
Average KL loss: 0.021869
Average total loss: 0.185422
tensor(0.0131, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.4955e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.179300
Average KL loss: 0.021877
Average total loss: 0.201177
tensor(0.0131, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-1.6662e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.174433
Average KL loss: 0.021886
Average total loss: 0.196320
tensor(0.0131, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-1.5659e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.171248
Average KL loss: 0.021895
Average total loss: 0.193143
tensor(0.0131, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-1.8542e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.165270
Average KL loss: 0.021904
Average total loss: 0.187174
tensor(0.0131, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-1.9590e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.164102
Average KL loss: 0.021914
Average total loss: 0.186015
tensor(0.0131, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-1.4139e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.161658
Average KL loss: 0.021923
Average total loss: 0.183581
tensor(0.0131, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-1.0935e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.163895
Average KL loss: 0.021933
Average total loss: 0.185827
tensor(0.0131, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-1.6051e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.167710
Average KL loss: 0.021942
Average total loss: 0.189652
tensor(0.0131, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-1.6549e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.161175
Average KL loss: 0.021952
Average total loss: 0.183126
tensor(0.0131, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-1.3781e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.162098
Average KL loss: 0.021961
Average total loss: 0.184059
tensor(0.0131, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-2.0973e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.169887
Average KL loss: 0.021971
Average total loss: 0.191857
tensor(0.0131, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-1.2733e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.168786
Average KL loss: 0.021980
Average total loss: 0.190767
tensor(0.0131, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-1.4550e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.161359
Average KL loss: 0.021990
Average total loss: 0.183349
tensor(0.0131, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-1.8552e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.158947
Average KL loss: 0.021999
Average total loss: 0.180946
tensor(0.0131, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-1.8295e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.157938
Average KL loss: 0.022009
Average total loss: 0.179948
tensor(0.0131, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-1.3948e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.170625
Average KL loss: 0.022020
Average total loss: 0.192645
tensor(0.0131, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-1.8978e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.158864
Average KL loss: 0.022030
Average total loss: 0.180894
tensor(0.0131, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-1.6655e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.160866
Average KL loss: 0.022041
Average total loss: 0.182907
tensor(0.0131, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-1.5377e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.157725
Average KL loss: 0.022051
Average total loss: 0.179776
tensor(0.0131, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-1.1094e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.154550
Average KL loss: 0.022061
Average total loss: 0.176611
tensor(0.0131, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-1.2971e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.159382
Average KL loss: 0.022071
Average total loss: 0.181453
tensor(0.0131, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.1021e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.160635
Average KL loss: 0.022082
Average total loss: 0.182717
tensor(0.0131, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.8773e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.152638
Average KL loss: 0.022092
Average total loss: 0.174731
tensor(0.0132, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.4858e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.152655
Average KL loss: 0.022103
Average total loss: 0.174758
tensor(0.0132, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.5420e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.154985
Average KL loss: 0.022113
Average total loss: 0.177098
tensor(0.0132, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-2.1980e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.149046
Average KL loss: 0.022124
Average total loss: 0.171170
tensor(0.0132, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.1795e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.165446
Average KL loss: 0.022135
Average total loss: 0.187580
tensor(0.0132, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.4019e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.159253
Average KL loss: 0.022145
Average total loss: 0.181399
tensor(0.0132, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.4067e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.150411
Average KL loss: 0.022156
Average total loss: 0.172567
tensor(0.0132, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.2556e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.151837
Average KL loss: 0.022167
Average total loss: 0.174004
tensor(0.0132, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.3831e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.149238
Average KL loss: 0.022178
Average total loss: 0.171416
tensor(0.0132, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.6729e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.153091
Average KL loss: 0.022189
Average total loss: 0.175280
tensor(0.0132, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.5697e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.150135
Average KL loss: 0.022199
Average total loss: 0.172334
tensor(0.0132, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.5101e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.151856
Average KL loss: 0.022210
Average total loss: 0.174065
tensor(0.0132, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.3279e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.150264
Average KL loss: 0.022220
Average total loss: 0.172485
tensor(0.0132, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-1.7486e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.147799
Average KL loss: 0.022231
Average total loss: 0.170030
tensor(0.0132, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-1.4400e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.148319
Average KL loss: 0.022242
Average total loss: 0.170561
tensor(0.0132, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-1.3132e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.147846
Average KL loss: 0.022253
Average total loss: 0.170100
tensor(0.0132, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-1.1978e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.145787
Average KL loss: 0.022264
Average total loss: 0.168051
tensor(0.0132, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-1.1754e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.149047
Average KL loss: 0.022275
Average total loss: 0.171323
tensor(0.0132, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-2.2618e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.150906
Average KL loss: 0.022287
Average total loss: 0.173193
tensor(0.0132, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-1.1364e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.145111
Average KL loss: 0.022298
Average total loss: 0.167409
tensor(0.0132, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-1.2771e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.153685
Average KL loss: 0.022308
Average total loss: 0.175994
tensor(0.0132, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-1.6573e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.149216
Average KL loss: 0.022320
Average total loss: 0.171535
tensor(0.0132, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-1.6336e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.148078
Average KL loss: 0.022331
Average total loss: 0.170409
tensor(0.0133, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-1.1009e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.142312
Average KL loss: 0.022342
Average total loss: 0.164654
tensor(0.0133, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-1.1614e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.146450
Average KL loss: 0.022353
Average total loss: 0.168804
tensor(0.0133, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-1.2559e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.142289
Average KL loss: 0.022365
Average total loss: 0.164654
tensor(0.0133, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-1.5733e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.142559
Average KL loss: 0.022376
Average total loss: 0.164935
tensor(0.0133, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-1.1057e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.152743
Average KL loss: 0.022387
Average total loss: 0.175130
tensor(0.0133, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-1.5147e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.145156
Average KL loss: 0.022398
Average total loss: 0.167554
tensor(0.0133, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-1.2807e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.141995
Average KL loss: 0.022409
Average total loss: 0.164403
tensor(0.0133, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-1.1038e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.135263
Average KL loss: 0.022419
Average total loss: 0.157682
tensor(0.0133, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-1.5163e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.140416
Average KL loss: 0.022430
Average total loss: 0.162846
tensor(0.0133, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.5607e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.139212
Average KL loss: 0.022441
Average total loss: 0.161653
tensor(0.0133, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.1617e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.145481
Average KL loss: 0.022452
Average total loss: 0.167934
tensor(0.0133, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-2.1612e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.140154
Average KL loss: 0.022464
Average total loss: 0.162617
tensor(0.0133, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-1.5876e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.139184
Average KL loss: 0.022475
Average total loss: 0.161659
tensor(0.0133, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-1.1690e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.148313
Average KL loss: 0.022487
Average total loss: 0.170800
tensor(0.0133, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-1.1205e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.134616
Average KL loss: 0.022498
Average total loss: 0.157114
tensor(0.0133, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-8.6162e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.137714
Average KL loss: 0.022509
Average total loss: 0.160223
tensor(0.0133, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-1.2979e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.132281
Average KL loss: 0.022519
Average total loss: 0.154800
tensor(0.0133, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-1.1493e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.135960
Average KL loss: 0.022531
Average total loss: 0.158490
tensor(0.0133, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-1.0077e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.142792
Average KL loss: 0.022542
Average total loss: 0.165334
tensor(0.0133, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-1.4243e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.135033
Average KL loss: 0.022553
Average total loss: 0.157585
tensor(0.0133, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-1.3259e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.138273
Average KL loss: 0.022564
Average total loss: 0.160838
tensor(0.0134, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-1.5045e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.134549
Average KL loss: 0.022576
Average total loss: 0.157125
tensor(0.0134, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-1.1774e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.137207
Average KL loss: 0.022588
Average total loss: 0.159795
tensor(0.0134, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-1.1337e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.137675
Average KL loss: 0.022599
Average total loss: 0.160274
tensor(0.0134, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-1.2936e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.136054
Average KL loss: 0.022610
Average total loss: 0.158664
tensor(0.0134, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-1.3278e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.135860
Average KL loss: 0.022621
Average total loss: 0.158481
tensor(0.0134, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.1929e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.139166
Average KL loss: 0.022632
Average total loss: 0.161798
tensor(0.0134, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.5452e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.140160
Average KL loss: 0.022644
Average total loss: 0.162804
tensor(0.0134, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.1677e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.135776
Average KL loss: 0.022650
Average total loss: 0.158426
tensor(0.0134, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.2349e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.133673
Average KL loss: 0.022651
Average total loss: 0.156324
tensor(0.0134, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.1902e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.138801
Average KL loss: 0.022652
Average total loss: 0.161453
tensor(0.0134, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-9.0294e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.134390
Average KL loss: 0.022653
Average total loss: 0.157043
tensor(0.0134, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.3067e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.131242
Average KL loss: 0.022654
Average total loss: 0.153896
tensor(0.0134, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.0007e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.129559
Average KL loss: 0.022655
Average total loss: 0.152214
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.3408e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.133360
Average KL loss: 0.022657
Average total loss: 0.156017
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-9.6927e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.130850
Average KL loss: 0.022658
Average total loss: 0.153507
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.4696e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.134863
Average KL loss: 0.022659
Average total loss: 0.157522
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-7.6205e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.132842
Average KL loss: 0.022660
Average total loss: 0.155502
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.1076e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.136989
Average KL loss: 0.022661
Average total loss: 0.159650
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.5656e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.127050
Average KL loss: 0.022662
Average total loss: 0.149712
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-9.9941e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.129565
Average KL loss: 0.022663
Average total loss: 0.152228
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.0920e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.138057
Average KL loss: 0.022664
Average total loss: 0.160721
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.2139e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.132213
Average KL loss: 0.022666
Average total loss: 0.154879
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.5820e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.133685
Average KL loss: 0.022667
Average total loss: 0.156352
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-8.6750e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.134584
Average KL loss: 0.022668
Average total loss: 0.157252
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.3758e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.130136
Average KL loss: 0.022669
Average total loss: 0.152805
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.3146e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.129345
Average KL loss: 0.022670
Average total loss: 0.152015
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-9.5720e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.132866
Average KL loss: 0.022671
Average total loss: 0.155537
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.1378e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.139316
Average KL loss: 0.022672
Average total loss: 0.161989
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.1011e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.133682
Average KL loss: 0.022674
Average total loss: 0.156356
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-9.5312e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.131311
Average KL loss: 0.022675
Average total loss: 0.153985
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-8.4626e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.139394
Average KL loss: 0.022676
Average total loss: 0.162069
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-7.6198e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.132679
Average KL loss: 0.022676
Average total loss: 0.155354
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.2949e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.137594
Average KL loss: 0.022676
Average total loss: 0.160270
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.3759e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.139712
Average KL loss: 0.022676
Average total loss: 0.162388
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.0420e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.130937
Average KL loss: 0.022676
Average total loss: 0.153613
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.6625e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.134127
Average KL loss: 0.022676
Average total loss: 0.156803
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.4053e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.146355
Average KL loss: 0.022676
Average total loss: 0.169031
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.4483e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.130368
Average KL loss: 0.022676
Average total loss: 0.153044
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.1239e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.135069
Average KL loss: 0.022676
Average total loss: 0.157745
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.5044e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.128222
Average KL loss: 0.022677
Average total loss: 0.150898
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-9.7057e-09, device='cuda:0')
 Percentile value: 2.1476962566375732
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =     112 /    1728             (  6.48%) | total_pruned =    1616 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      53 /   36864             (  0.14%) | total_pruned =   36811 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     170 /   36864             (  0.46%) | total_pruned =   36694 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     282 /   36864             (  0.76%) | total_pruned =   36582 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     497 /   36864             (  1.35%) | total_pruned =   36367 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1110 /   73728             (  1.51%) | total_pruned =   72618 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1994 /  147456             (  1.35%) | total_pruned =  145462 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     322 /    8192             (  3.93%) | total_pruned =    7870 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1131 /  147456             (  0.77%) | total_pruned =  146325 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1179 /  147456             (  0.80%) | total_pruned =  146277 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    4382 /  294912             (  1.49%) | total_pruned =  290530 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    6171 /  589824             (  1.05%) | total_pruned =  583653 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     673 /   32768             (  2.05%) | total_pruned =   32095 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3367 /  589824             (  0.57%) | total_pruned =  586457 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     139 /     256             ( 54.30%) | total_pruned =     117 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3094 /  589824             (  0.52%) | total_pruned =  586730 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     138 /     256             ( 53.91%) | total_pruned =     118 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    6029 / 1179648             (  0.51%) | total_pruned = 1173619 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     336 /     512             ( 65.62%) | total_pruned =     176 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4313 / 2359296             (  0.18%) | total_pruned = 2354983 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     184 /     512             ( 35.94%) | total_pruned =     328 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     113 /  131072             (  0.09%) | total_pruned =  130959 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      92 /     512             ( 17.97%) | total_pruned =     420 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3124 / 2359296             (  0.13%) | total_pruned = 2356172 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2666 / 2359296             (  0.11%) | total_pruned = 2356630 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      65 /     512             ( 12.70%) | total_pruned =     447 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      59 /     512             ( 11.52%) | total_pruned =     453 | shape = torch.Size([512])
linear.weight        | nonzeros =     557 /    5120             ( 10.88%) | total_pruned =    4563 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 75/100 Loss: 0.032301 Accuracy: 85.00 99.97 % Best test Accuracy: 85.96%
tensor(0.0134, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-2.9078e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.334989
Average KL loss: 0.022487
Average total loss: 0.357477
tensor(0.0132, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-3.0019e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.319965
Average KL loss: 0.022140
Average total loss: 0.342105
tensor(0.0131, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-2.0096e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.330147
Average KL loss: 0.021803
Average total loss: 0.351950
tensor(0.0129, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-3.9718e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.324539
Average KL loss: 0.021474
Average total loss: 0.346013
tensor(0.0128, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-2.9896e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.343784
Average KL loss: 0.021152
Average total loss: 0.364936
tensor(0.0126, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-2.2854e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.327301
Average KL loss: 0.020839
Average total loss: 0.348139
tensor(0.0125, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-2.7490e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.310173
Average KL loss: 0.020534
Average total loss: 0.330707
tensor(0.0123, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-3.1880e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.314987
Average KL loss: 0.020239
Average total loss: 0.335226
tensor(0.0122, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-2.6318e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.326416
Average KL loss: 0.019954
Average total loss: 0.346370
tensor(0.0121, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-3.3606e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.311586
Average KL loss: 0.019679
Average total loss: 0.331265
tensor(0.0119, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-2.3832e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.313606
Average KL loss: 0.019415
Average total loss: 0.333020
tensor(0.0118, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.6595e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.312752
Average KL loss: 0.019162
Average total loss: 0.331914
tensor(0.0117, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-2.2980e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.314802
Average KL loss: 0.018920
Average total loss: 0.333723
tensor(0.0115, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-3.0347e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.302221
Average KL loss: 0.018690
Average total loss: 0.320911
tensor(0.0114, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-3.0159e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.329535
Average KL loss: 0.018472
Average total loss: 0.348007
tensor(0.0113, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-2.6011e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.307024
Average KL loss: 0.018265
Average total loss: 0.325289
tensor(0.0112, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.8328e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.309436
Average KL loss: 0.018070
Average total loss: 0.327506
tensor(0.0111, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-2.4254e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.300989
Average KL loss: 0.017886
Average total loss: 0.318875
tensor(0.0110, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-2.8594e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.312106
Average KL loss: 0.017714
Average total loss: 0.329820
tensor(0.0109, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-2.1447e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.298100
Average KL loss: 0.017554
Average total loss: 0.315653
tensor(0.0108, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.8302e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.293788
Average KL loss: 0.017403
Average total loss: 0.311191
tensor(0.0107, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-2.1054e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.296855
Average KL loss: 0.017263
Average total loss: 0.314118
tensor(0.0106, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-2.9813e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.294059
Average KL loss: 0.017134
Average total loss: 0.311193
tensor(0.0105, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.3442e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.290052
Average KL loss: 0.017013
Average total loss: 0.307066
tensor(0.0104, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.8442e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.296912
Average KL loss: 0.016903
Average total loss: 0.313815
tensor(0.0103, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-2.7904e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.287479
Average KL loss: 0.016802
Average total loss: 0.304281
tensor(0.0102, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-2.7776e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.302604
Average KL loss: 0.016709
Average total loss: 0.319313
tensor(0.0101, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.9538e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.285140
Average KL loss: 0.016624
Average total loss: 0.301764
tensor(0.0101, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.9277e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.303166
Average KL loss: 0.016546
Average total loss: 0.319713
tensor(0.0100, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.6674e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.286824
Average KL loss: 0.016476
Average total loss: 0.303300
tensor(0.0099, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-2.7396e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.292470
Average KL loss: 0.016411
Average total loss: 0.308881
tensor(0.0099, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-2.2851e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.278924
Average KL loss: 0.016353
Average total loss: 0.295277
tensor(0.0098, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-2.3080e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.288114
Average KL loss: 0.016300
Average total loss: 0.304415
tensor(0.0097, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-3.2125e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.292299
Average KL loss: 0.016252
Average total loss: 0.308551
tensor(0.0097, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-3.1880e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.272600
Average KL loss: 0.016210
Average total loss: 0.288809
tensor(0.0096, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.4479e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.289553
Average KL loss: 0.016171
Average total loss: 0.305724
tensor(0.0096, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.4174e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.279670
Average KL loss: 0.016137
Average total loss: 0.295807
tensor(0.0095, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.7938e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.277692
Average KL loss: 0.016106
Average total loss: 0.293799
tensor(0.0095, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.3566e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.275037
Average KL loss: 0.016079
Average total loss: 0.291116
tensor(0.0094, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.6748e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.279613
Average KL loss: 0.016055
Average total loss: 0.295668
tensor(0.0094, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.6884e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.281594
Average KL loss: 0.016034
Average total loss: 0.297627
tensor(0.0094, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.1029e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.283022
Average KL loss: 0.016015
Average total loss: 0.299037
tensor(0.0093, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.7301e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.278458
Average KL loss: 0.015998
Average total loss: 0.294456
tensor(0.0093, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.4017e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.275449
Average KL loss: 0.015984
Average total loss: 0.291433
tensor(0.0093, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.2256e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.286776
Average KL loss: 0.015971
Average total loss: 0.302747
tensor(0.0093, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-3.6678e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.269560
Average KL loss: 0.015959
Average total loss: 0.285519
tensor(0.0092, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.1537e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.282393
Average KL loss: 0.015949
Average total loss: 0.298342
tensor(0.0092, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.9482e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.270414
Average KL loss: 0.015940
Average total loss: 0.286354
tensor(0.0092, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.1479e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.275565
Average KL loss: 0.015933
Average total loss: 0.291498
tensor(0.0092, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.4109e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.269893
Average KL loss: 0.015927
Average total loss: 0.285819
tensor(0.0091, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.7038e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.267673
Average KL loss: 0.015922
Average total loss: 0.283595
tensor(0.0091, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.0099e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.258577
Average KL loss: 0.015917
Average total loss: 0.274494
tensor(0.0091, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.4430e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.271657
Average KL loss: 0.015913
Average total loss: 0.287569
tensor(0.0091, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.6765e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.271777
Average KL loss: 0.015910
Average total loss: 0.287687
tensor(0.0091, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.3518e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.268682
Average KL loss: 0.015907
Average total loss: 0.284589
tensor(0.0091, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.2888e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.261149
Average KL loss: 0.015905
Average total loss: 0.277055
tensor(0.0091, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.3035e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.265768
Average KL loss: 0.015904
Average total loss: 0.281672
tensor(0.0091, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.1244e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.267918
Average KL loss: 0.015903
Average total loss: 0.283821
tensor(0.0091, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.0849e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.260692
Average KL loss: 0.015902
Average total loss: 0.276594
tensor(0.0090, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.2953e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.253253
Average KL loss: 0.015902
Average total loss: 0.269155
tensor(0.0090, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.4710e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.274759
Average KL loss: 0.015902
Average total loss: 0.290662
tensor(0.0090, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.6321e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.262509
Average KL loss: 0.015903
Average total loss: 0.278412
tensor(0.0090, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.6657e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.268457
Average KL loss: 0.015904
Average total loss: 0.284361
tensor(0.0090, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.7033e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.259257
Average KL loss: 0.015905
Average total loss: 0.275162
tensor(0.0090, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-2.2591e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.256507
Average KL loss: 0.015906
Average total loss: 0.272413
tensor(0.0090, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.8836e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.261094
Average KL loss: 0.015908
Average total loss: 0.277002
tensor(0.0090, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.7526e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.264459
Average KL loss: 0.015910
Average total loss: 0.280368
tensor(0.0090, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-1.9314e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.250705
Average KL loss: 0.015912
Average total loss: 0.266616
tensor(0.0090, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-2.1036e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.246306
Average KL loss: 0.015914
Average total loss: 0.262220
tensor(0.0090, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-2.9399e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.248687
Average KL loss: 0.015916
Average total loss: 0.264603
tensor(0.0090, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-5.8127e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.252258
Average KL loss: 0.015918
Average total loss: 0.268177
tensor(0.0090, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-2.0160e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.256321
Average KL loss: 0.015921
Average total loss: 0.272242
tensor(0.0090, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-1.6255e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.260624
Average KL loss: 0.015924
Average total loss: 0.276548
tensor(0.0090, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.5635e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.256313
Average KL loss: 0.015927
Average total loss: 0.272240
tensor(0.0090, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.9863e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.265760
Average KL loss: 0.015931
Average total loss: 0.281691
tensor(0.0090, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.0335e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.244633
Average KL loss: 0.015934
Average total loss: 0.260568
tensor(0.0090, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.5898e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.256966
Average KL loss: 0.015938
Average total loss: 0.272904
tensor(0.0090, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.8789e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.248180
Average KL loss: 0.015942
Average total loss: 0.264122
tensor(0.0090, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.8126e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.239861
Average KL loss: 0.015946
Average total loss: 0.255806
tensor(0.0090, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.6424e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.242211
Average KL loss: 0.015949
Average total loss: 0.258160
tensor(0.0090, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.9101e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.244267
Average KL loss: 0.015953
Average total loss: 0.260221
tensor(0.0090, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.6823e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.239627
Average KL loss: 0.015958
Average total loss: 0.255584
tensor(0.0090, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.0404e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.249068
Average KL loss: 0.015962
Average total loss: 0.265030
tensor(0.0090, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.6891e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.253316
Average KL loss: 0.015966
Average total loss: 0.269282
tensor(0.0090, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-2.8990e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.243325
Average KL loss: 0.015971
Average total loss: 0.259296
tensor(0.0090, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.5572e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.240593
Average KL loss: 0.015975
Average total loss: 0.256568
tensor(0.0090, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.9888e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.234023
Average KL loss: 0.015980
Average total loss: 0.250003
tensor(0.0090, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.7567e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.242162
Average KL loss: 0.015985
Average total loss: 0.258147
tensor(0.0090, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-2.4126e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.232902
Average KL loss: 0.015990
Average total loss: 0.248892
tensor(0.0090, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-2.0056e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.234302
Average KL loss: 0.015995
Average total loss: 0.250297
tensor(0.0090, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.6453e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.244867
Average KL loss: 0.016000
Average total loss: 0.260867
tensor(0.0090, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.8298e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.231511
Average KL loss: 0.016005
Average total loss: 0.247516
tensor(0.0090, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.4461e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.234173
Average KL loss: 0.016010
Average total loss: 0.250184
tensor(0.0091, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.7891e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.237781
Average KL loss: 0.016016
Average total loss: 0.253797
tensor(0.0091, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.1415e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.235104
Average KL loss: 0.016021
Average total loss: 0.251125
tensor(0.0091, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.8003e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.234129
Average KL loss: 0.016027
Average total loss: 0.250155
tensor(0.0091, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.9062e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.225508
Average KL loss: 0.016032
Average total loss: 0.241540
tensor(0.0091, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.6802e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.228367
Average KL loss: 0.016037
Average total loss: 0.244404
tensor(0.0091, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.9012e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.235630
Average KL loss: 0.016043
Average total loss: 0.251672
tensor(0.0091, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.7116e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.231669
Average KL loss: 0.016048
Average total loss: 0.247718
tensor(0.0091, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.7622e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.219344
Average KL loss: 0.016054
Average total loss: 0.235398
tensor(0.0091, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-1.5413e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.230468
Average KL loss: 0.016060
Average total loss: 0.246528
tensor(0.0091, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-2.3349e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.226361
Average KL loss: 0.016066
Average total loss: 0.242427
tensor(0.0091, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-1.9261e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.227722
Average KL loss: 0.016072
Average total loss: 0.243794
tensor(0.0091, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-1.6338e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.236113
Average KL loss: 0.016078
Average total loss: 0.252191
tensor(0.0091, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-1.1234e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.245939
Average KL loss: 0.016084
Average total loss: 0.262023
tensor(0.0091, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-1.7567e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.234357
Average KL loss: 0.016090
Average total loss: 0.250446
tensor(0.0091, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-2.0097e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.225951
Average KL loss: 0.016096
Average total loss: 0.242046
tensor(0.0091, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-1.9232e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.219232
Average KL loss: 0.016102
Average total loss: 0.235334
tensor(0.0091, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-1.2246e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.224259
Average KL loss: 0.016108
Average total loss: 0.240367
tensor(0.0091, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.8890e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.214092
Average KL loss: 0.016114
Average total loss: 0.230206
tensor(0.0091, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.2870e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.223442
Average KL loss: 0.016120
Average total loss: 0.239562
tensor(0.0091, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.5364e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.222719
Average KL loss: 0.016127
Average total loss: 0.238845
tensor(0.0091, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.8292e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.223167
Average KL loss: 0.016133
Average total loss: 0.239300
tensor(0.0091, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-2.0334e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.220835
Average KL loss: 0.016139
Average total loss: 0.236975
tensor(0.0091, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-2.4463e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.219506
Average KL loss: 0.016146
Average total loss: 0.235652
tensor(0.0091, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-1.6762e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.220555
Average KL loss: 0.016152
Average total loss: 0.236707
tensor(0.0091, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-1.7229e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.218537
Average KL loss: 0.016158
Average total loss: 0.234695
tensor(0.0091, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.6366e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.217096
Average KL loss: 0.016165
Average total loss: 0.233260
tensor(0.0091, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.7514e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.230133
Average KL loss: 0.016171
Average total loss: 0.246303
tensor(0.0091, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.9392e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.211894
Average KL loss: 0.016177
Average total loss: 0.228070
tensor(0.0091, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.4291e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.225863
Average KL loss: 0.016183
Average total loss: 0.242046
tensor(0.0091, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-2.3809e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.221505
Average KL loss: 0.016189
Average total loss: 0.237694
tensor(0.0092, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-1.3050e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.214785
Average KL loss: 0.016195
Average total loss: 0.230980
tensor(0.0092, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-2.1870e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.213390
Average KL loss: 0.016202
Average total loss: 0.229591
tensor(0.0092, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-1.6650e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.213073
Average KL loss: 0.016208
Average total loss: 0.229281
tensor(0.0092, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-1.7629e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.224298
Average KL loss: 0.016214
Average total loss: 0.240513
tensor(0.0092, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-1.2560e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.209976
Average KL loss: 0.016221
Average total loss: 0.226197
tensor(0.0092, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-2.0891e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.217127
Average KL loss: 0.016227
Average total loss: 0.233354
tensor(0.0092, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-1.6094e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.208252
Average KL loss: 0.016234
Average total loss: 0.224485
tensor(0.0092, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-2.0236e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.216080
Average KL loss: 0.016240
Average total loss: 0.232320
tensor(0.0092, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.4150e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.213673
Average KL loss: 0.016246
Average total loss: 0.229919
tensor(0.0092, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.6708e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.207617
Average KL loss: 0.016253
Average total loss: 0.223870
tensor(0.0092, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.7122e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.203061
Average KL loss: 0.016260
Average total loss: 0.219320
tensor(0.0092, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.3449e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.214653
Average KL loss: 0.016266
Average total loss: 0.230919
tensor(0.0092, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.4262e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.211546
Average KL loss: 0.016273
Average total loss: 0.227819
tensor(0.0092, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.6990e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.223586
Average KL loss: 0.016279
Average total loss: 0.239865
tensor(0.0092, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.4402e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.209572
Average KL loss: 0.016285
Average total loss: 0.225857
tensor(0.0092, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-1.2939e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.201655
Average KL loss: 0.016292
Average total loss: 0.217947
tensor(0.0092, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-1.6636e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.209993
Average KL loss: 0.016298
Average total loss: 0.226291
tensor(0.0092, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-1.6405e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.207713
Average KL loss: 0.016304
Average total loss: 0.224017
tensor(0.0092, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-1.5460e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.202622
Average KL loss: 0.016311
Average total loss: 0.218932
tensor(0.0092, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-1.6732e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.201188
Average KL loss: 0.016317
Average total loss: 0.217505
tensor(0.0092, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-1.6478e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.204900
Average KL loss: 0.016323
Average total loss: 0.221224
tensor(0.0092, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-1.6717e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.217173
Average KL loss: 0.016330
Average total loss: 0.233503
tensor(0.0092, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-1.9530e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.205185
Average KL loss: 0.016336
Average total loss: 0.221521
tensor(0.0092, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-1.7610e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.210660
Average KL loss: 0.016343
Average total loss: 0.227002
tensor(0.0092, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-1.8816e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.197461
Average KL loss: 0.016349
Average total loss: 0.213811
tensor(0.0092, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-1.7899e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.208451
Average KL loss: 0.016356
Average total loss: 0.224808
tensor(0.0093, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-1.3204e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.200720
Average KL loss: 0.016362
Average total loss: 0.217083
tensor(0.0093, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-1.9053e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.205381
Average KL loss: 0.016369
Average total loss: 0.221750
tensor(0.0093, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-1.6458e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.196979
Average KL loss: 0.016375
Average total loss: 0.213354
tensor(0.0093, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-1.3514e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.202352
Average KL loss: 0.016382
Average total loss: 0.218733
tensor(0.0093, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-2.1373e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.206430
Average KL loss: 0.016388
Average total loss: 0.222818
tensor(0.0093, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-1.1844e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.199444
Average KL loss: 0.016395
Average total loss: 0.215839
tensor(0.0093, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-1.1898e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.195100
Average KL loss: 0.016401
Average total loss: 0.211501
tensor(0.0093, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-1.7504e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.195611
Average KL loss: 0.016408
Average total loss: 0.212018
tensor(0.0093, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-1.3122e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.199228
Average KL loss: 0.016414
Average total loss: 0.215642
tensor(0.0093, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-1.7256e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.197715
Average KL loss: 0.016420
Average total loss: 0.214135
tensor(0.0093, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-2.0438e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.200519
Average KL loss: 0.016427
Average total loss: 0.216946
tensor(0.0093, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-1.2856e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.211234
Average KL loss: 0.016433
Average total loss: 0.227667
tensor(0.0093, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.5670e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.194607
Average KL loss: 0.016439
Average total loss: 0.211047
tensor(0.0093, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.2397e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.196921
Average KL loss: 0.016446
Average total loss: 0.213366
tensor(0.0093, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.6481e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.193744
Average KL loss: 0.016452
Average total loss: 0.210196
tensor(0.0093, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.6839e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.189463
Average KL loss: 0.016459
Average total loss: 0.205922
tensor(0.0093, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-1.2539e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.190396
Average KL loss: 0.016465
Average total loss: 0.206861
tensor(0.0093, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-1.4438e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.190820
Average KL loss: 0.016472
Average total loss: 0.207291
tensor(0.0093, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-1.4317e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.202258
Average KL loss: 0.016478
Average total loss: 0.218736
tensor(0.0093, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-2.7539e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.190142
Average KL loss: 0.016485
Average total loss: 0.206626
tensor(0.0093, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.7879e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.187598
Average KL loss: 0.016491
Average total loss: 0.204089
tensor(0.0093, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.5464e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.195488
Average KL loss: 0.016498
Average total loss: 0.211986
tensor(0.0093, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.3595e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.188727
Average KL loss: 0.016504
Average total loss: 0.205231
tensor(0.0093, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.1457e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.192714
Average KL loss: 0.016511
Average total loss: 0.209225
tensor(0.0093, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.2207e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.184900
Average KL loss: 0.016517
Average total loss: 0.201417
tensor(0.0094, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.1861e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.189676
Average KL loss: 0.016523
Average total loss: 0.206199
tensor(0.0094, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-9.9693e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.186652
Average KL loss: 0.016530
Average total loss: 0.203182
tensor(0.0094, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-1.5985e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.191717
Average KL loss: 0.016536
Average total loss: 0.208253
tensor(0.0094, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-1.5608e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.196051
Average KL loss: 0.016542
Average total loss: 0.212594
tensor(0.0094, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-1.5159e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.194059
Average KL loss: 0.016549
Average total loss: 0.210608
tensor(0.0094, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-1.1289e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.190490
Average KL loss: 0.016556
Average total loss: 0.207046
tensor(0.0094, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.5959e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.190627
Average KL loss: 0.016562
Average total loss: 0.207190
tensor(0.0094, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.2476e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.186193
Average KL loss: 0.016569
Average total loss: 0.202762
tensor(0.0094, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.6809e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.187655
Average KL loss: 0.016575
Average total loss: 0.204231
tensor(0.0094, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.3578e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.187689
Average KL loss: 0.016582
Average total loss: 0.204271
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.2311e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.187828
Average KL loss: 0.016589
Average total loss: 0.204417
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-2.1960e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.197886
Average KL loss: 0.016592
Average total loss: 0.214478
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.1392e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.179392
Average KL loss: 0.016593
Average total loss: 0.195985
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.3908e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.188142
Average KL loss: 0.016594
Average total loss: 0.204736
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.4111e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.182468
Average KL loss: 0.016594
Average total loss: 0.199063
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-4.2952e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.176686
Average KL loss: 0.016595
Average total loss: 0.193281
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.6309e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.188690
Average KL loss: 0.016596
Average total loss: 0.205286
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-2.0275e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.186694
Average KL loss: 0.016596
Average total loss: 0.203290
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.3976e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.178553
Average KL loss: 0.016597
Average total loss: 0.195150
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.2468e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.183815
Average KL loss: 0.016598
Average total loss: 0.200413
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.5924e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.196764
Average KL loss: 0.016598
Average total loss: 0.213362
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.6314e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.188467
Average KL loss: 0.016599
Average total loss: 0.205066
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.0063e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.194608
Average KL loss: 0.016600
Average total loss: 0.211208
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.6204e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.183665
Average KL loss: 0.016600
Average total loss: 0.200266
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-2.1006e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.186994
Average KL loss: 0.016601
Average total loss: 0.203595
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.5442e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.189059
Average KL loss: 0.016602
Average total loss: 0.205661
 Percentile value: 2.8974207639694214
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =     109 /    1728             (  6.31%) | total_pruned =    1619 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      28 /   36864             (  0.08%) | total_pruned =   36836 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      58 /   36864             (  0.16%) | total_pruned =   36806 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     206 /   36864             (  0.56%) | total_pruned =   36658 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     341 /   36864             (  0.93%) | total_pruned =   36523 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     569 /   73728             (  0.77%) | total_pruned =   73159 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1030 /  147456             (  0.70%) | total_pruned =  146426 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     209 /    8192             (  2.55%) | total_pruned =    7983 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     637 /  147456             (  0.43%) | total_pruned =  146819 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     658 /  147456             (  0.45%) | total_pruned =  146798 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2151 /  294912             (  0.73%) | total_pruned =  292761 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2838 /  589824             (  0.48%) | total_pruned =  586986 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     334 /   32768             (  1.02%) | total_pruned =   32434 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     105 /     256             ( 41.02%) | total_pruned =     151 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1685 /  589824             (  0.29%) | total_pruned =  588139 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1587 /  589824             (  0.27%) | total_pruned =  588237 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2412 / 1179648             (  0.20%) | total_pruned = 1177236 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     305 /     512             ( 59.57%) | total_pruned =     207 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1681 / 2359296             (  0.07%) | total_pruned = 2357615 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     131 /     512             ( 25.59%) | total_pruned =     381 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      66 /     512             ( 12.89%) | total_pruned =     446 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      42 /  131072             (  0.03%) | total_pruned =  131030 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1417 / 2359296             (  0.06%) | total_pruned = 2357879 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1466 / 2359296             (  0.06%) | total_pruned = 2357830 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
linear.weight        | nonzeros =     381 /    5120             (  7.44%) | total_pruned =    4739 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.143628 Accuracy: 81.74 96.25 % Best test Accuracy: 83.06%
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.7605e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.448898
Average KL loss: 0.016502
Average total loss: 0.465400
tensor(0.0093, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-2.1556e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.458566
Average KL loss: 0.016313
Average total loss: 0.474879
tensor(0.0092, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-3.0643e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.456208
Average KL loss: 0.016124
Average total loss: 0.472332
tensor(0.0091, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-1.5467e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.462882
Average KL loss: 0.015933
Average total loss: 0.478815
tensor(0.0090, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.9840e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.446384
Average KL loss: 0.015740
Average total loss: 0.462124
tensor(0.0090, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-2.2318e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.456228
Average KL loss: 0.015545
Average total loss: 0.471773
tensor(0.0089, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-1.9283e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.451780
Average KL loss: 0.015350
Average total loss: 0.467129
tensor(0.0088, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-2.1252e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.452400
Average KL loss: 0.015152
Average total loss: 0.467553
tensor(0.0087, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.5547e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.455666
Average KL loss: 0.014955
Average total loss: 0.470621
tensor(0.0086, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.7695e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.449273
Average KL loss: 0.014756
Average total loss: 0.464030
tensor(0.0085, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-3.4576e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.454737
Average KL loss: 0.014558
Average total loss: 0.469295
tensor(0.0084, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-2.3948e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.438253
Average KL loss: 0.014360
Average total loss: 0.452613
tensor(0.0084, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-1.9842e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.445177
Average KL loss: 0.014163
Average total loss: 0.459340
tensor(0.0083, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.5992e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.439804
Average KL loss: 0.013967
Average total loss: 0.453772
tensor(0.0082, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-1.9876e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.444119
Average KL loss: 0.013773
Average total loss: 0.457893
tensor(0.0081, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.2706e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.439988
Average KL loss: 0.013581
Average total loss: 0.453570
tensor(0.0080, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.2882e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.436301
Average KL loss: 0.013392
Average total loss: 0.449693
tensor(0.0079, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.5689e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.432259
Average KL loss: 0.013206
Average total loss: 0.445465
tensor(0.0079, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.7529e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.433965
Average KL loss: 0.013023
Average total loss: 0.446988
tensor(0.0078, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.5365e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.419887
Average KL loss: 0.012844
Average total loss: 0.432731
tensor(0.0077, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.7358e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.445108
Average KL loss: 0.012669
Average total loss: 0.457777
tensor(0.0076, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.8208e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.453697
Average KL loss: 0.012499
Average total loss: 0.466195
tensor(0.0075, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.8736e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.442615
Average KL loss: 0.012333
Average total loss: 0.454948
tensor(0.0075, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-1.7698e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.435146
Average KL loss: 0.012173
Average total loss: 0.447319
tensor(0.0074, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-3.4162e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.433858
Average KL loss: 0.012018
Average total loss: 0.445876
tensor(0.0073, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-1.6115e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.421398
Average KL loss: 0.011869
Average total loss: 0.433267
tensor(0.0072, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-1.7272e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.432605
Average KL loss: 0.011725
Average total loss: 0.444330
tensor(0.0072, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-1.7156e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.428418
Average KL loss: 0.011588
Average total loss: 0.440005
tensor(0.0071, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-2.5274e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.424989
Average KL loss: 0.011456
Average total loss: 0.436446
tensor(0.0070, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-2.0908e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.440410
Average KL loss: 0.011331
Average total loss: 0.451741
tensor(0.0070, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-1.7110e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.426918
Average KL loss: 0.011212
Average total loss: 0.438131
tensor(0.0069, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.6582e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.432256
Average KL loss: 0.011148
Average total loss: 0.443404
tensor(0.0069, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.8194e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.438866
Average KL loss: 0.011137
Average total loss: 0.450003
tensor(0.0069, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.4732e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.445620
Average KL loss: 0.011126
Average total loss: 0.456745
tensor(0.0069, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.7357e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.430386
Average KL loss: 0.011114
Average total loss: 0.441500
tensor(0.0069, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.7403e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.426808
Average KL loss: 0.011103
Average total loss: 0.437911
tensor(0.0069, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.6992e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.444008
Average KL loss: 0.011092
Average total loss: 0.455100
tensor(0.0069, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.8231e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.437445
Average KL loss: 0.011081
Average total loss: 0.448526
tensor(0.0069, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.9434e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.436838
Average KL loss: 0.011069
Average total loss: 0.447908
tensor(0.0068, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.2930e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.457721
Average KL loss: 0.011058
Average total loss: 0.468780
tensor(0.0068, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.7979e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.430465
Average KL loss: 0.011047
Average total loss: 0.441512
tensor(0.0068, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.7176e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.413340
Average KL loss: 0.011036
Average total loss: 0.424376
tensor(0.0068, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-2.3870e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.424190
Average KL loss: 0.011025
Average total loss: 0.435214
tensor(0.0068, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.9225e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.422843
Average KL loss: 0.011013
Average total loss: 0.433857
tensor(0.0068, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-3.4549e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.432402
Average KL loss: 0.011002
Average total loss: 0.443404
tensor(0.0068, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.5747e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.426870
Average KL loss: 0.010991
Average total loss: 0.437862
tensor(0.0068, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-2.0762e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.426984
Average KL loss: 0.010980
Average total loss: 0.437964
tensor(0.0068, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.6266e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.419398
Average KL loss: 0.010969
Average total loss: 0.430367
tensor(0.0068, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.3867e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.425288
Average KL loss: 0.010958
Average total loss: 0.436246
tensor(0.0068, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-2.2927e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.424971
Average KL loss: 0.010947
Average total loss: 0.435918
tensor(0.0068, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-2.4761e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.426481
Average KL loss: 0.010936
Average total loss: 0.437418
tensor(0.0068, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-2.0663e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.427713
Average KL loss: 0.010925
Average total loss: 0.438638
tensor(0.0068, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.3304e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.417168
Average KL loss: 0.010915
Average total loss: 0.428082
tensor(0.0068, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.2943e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.423321
Average KL loss: 0.010908
Average total loss: 0.434229
tensor(0.0068, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-2.6125e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.432760
Average KL loss: 0.010907
Average total loss: 0.443667
tensor(0.0068, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.5288e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.421743
Average KL loss: 0.010906
Average total loss: 0.432650
tensor(0.0068, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-2.8604e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.422539
Average KL loss: 0.010905
Average total loss: 0.433444
tensor(0.0068, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-2.1502e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.430753
Average KL loss: 0.010904
Average total loss: 0.441657
tensor(0.0068, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.2885e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.416637
Average KL loss: 0.010903
Average total loss: 0.427540
tensor(0.0068, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.4302e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.429821
Average KL loss: 0.010902
Average total loss: 0.440722
tensor(0.0068, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.5297e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.439634
Average KL loss: 0.010901
Average total loss: 0.450535
tensor(0.0067, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.4110e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.426902
Average KL loss: 0.010900
Average total loss: 0.437802
tensor(0.0067, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-2.3315e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.424859
Average KL loss: 0.010899
Average total loss: 0.435758
tensor(0.0067, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.9873e-08, device='cuda:0')
 Percentile value: 3.3868649005889893
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =     103 /    1728             (  5.96%) | total_pruned =    1625 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      17 /   36864             (  0.05%) | total_pruned =   36847 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      38 /   36864             (  0.10%) | total_pruned =   36826 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     152 /   36864             (  0.41%) | total_pruned =   36712 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     217 /   36864             (  0.59%) | total_pruned =   36647 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     280 /   73728             (  0.38%) | total_pruned =   73448 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     488 /  147456             (  0.33%) | total_pruned =  146968 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     130 /    8192             (  1.59%) | total_pruned =    8062 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     329 /  147456             (  0.22%) | total_pruned =  147127 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     343 /  147456             (  0.23%) | total_pruned =  147113 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     910 /  294912             (  0.31%) | total_pruned =  294002 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     214 /     256             ( 83.59%) | total_pruned =      42 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1065 /  589824             (  0.18%) | total_pruned =  588759 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     184 /     256             ( 71.88%) | total_pruned =      72 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     153 /   32768             (  0.47%) | total_pruned =   32615 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     654 /  589824             (  0.11%) | total_pruned =  589170 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     693 /  589824             (  0.12%) | total_pruned =  589131 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     819 / 1179648             (  0.07%) | total_pruned = 1178829 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     304 /     512             ( 59.38%) | total_pruned =     208 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     570 / 2359296             (  0.02%) | total_pruned = 2358726 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     131 /     512             ( 25.59%) | total_pruned =     381 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      56 /     512             ( 10.94%) | total_pruned =     456 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      19 /  131072             (  0.01%) | total_pruned =  131053 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     731 / 2359296             (  0.03%) | total_pruned = 2358565 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     930 / 2359296             (  0.04%) | total_pruned = 2358366 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      38 /     512             (  7.42%) | total_pruned =     474 | shape = torch.Size([512])
linear.weight        | nonzeros =     348 /    5120             (  6.80%) | total_pruned =    4772 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.534431 Accuracy: 72.59 78.59 % Best test Accuracy: 72.73%
tensor(0.0067, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.4286e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.852349
Average KL loss: 0.010798
Average total loss: 0.863147
tensor(0.0066, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-2.4689e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.840243
Average KL loss: 0.010607
Average total loss: 0.850850
tensor(0.0065, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-1.3053e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.843648
Average KL loss: 0.010425
Average total loss: 0.854073
tensor(0.0064, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.6801e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.839050
Average KL loss: 0.010250
Average total loss: 0.849300
tensor(0.0063, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.8204e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.837912
Average KL loss: 0.010081
Average total loss: 0.847993
tensor(0.0061, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.3438e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.837533
Average KL loss: 0.009918
Average total loss: 0.847451
tensor(0.0060, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.4155e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.839720
Average KL loss: 0.009760
Average total loss: 0.849480
tensor(0.0059, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-1.3026e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.830606
Average KL loss: 0.009607
Average total loss: 0.840213
tensor(0.0058, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-1.1545e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.830508
Average KL loss: 0.009458
Average total loss: 0.839965
tensor(0.0057, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.3659e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.829833
Average KL loss: 0.009312
Average total loss: 0.839145
tensor(0.0056, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-8.3463e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.837305
Average KL loss: 0.009169
Average total loss: 0.846474
tensor(0.0055, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-1.6090e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.848430
Average KL loss: 0.009028
Average total loss: 0.857458
tensor(0.0055, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-2.6550e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.835507
Average KL loss: 0.008890
Average total loss: 0.844396
tensor(0.0054, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.8725e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.834614
Average KL loss: 0.008753
Average total loss: 0.843367
tensor(0.0053, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-2.0058e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.829753
Average KL loss: 0.008618
Average total loss: 0.838370
tensor(0.0052, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.4955e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.825511
Average KL loss: 0.008484
Average total loss: 0.833994
tensor(0.0051, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-1.9487e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.818284
Average KL loss: 0.008350
Average total loss: 0.826634
tensor(0.0050, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-1.6188e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.836936
Average KL loss: 0.008218
Average total loss: 0.845154
tensor(0.0050, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-9.9042e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.833713
Average KL loss: 0.008087
Average total loss: 0.841800
tensor(0.0049, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-6.6529e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.817106
Average KL loss: 0.007956
Average total loss: 0.825062
tensor(0.0048, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.8582e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.828975
Average KL loss: 0.007826
Average total loss: 0.836802
tensor(0.0047, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-1.3288e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.822613
Average KL loss: 0.007698
Average total loss: 0.830311
tensor(0.0047, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.0109e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.818916
Average KL loss: 0.007570
Average total loss: 0.826486
tensor(0.0046, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.2511e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.815838
Average KL loss: 0.007443
Average total loss: 0.823281
tensor(0.0045, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.7747e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.833142
Average KL loss: 0.007318
Average total loss: 0.840460
tensor(0.0045, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.1914e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.822625
Average KL loss: 0.007194
Average total loss: 0.829819
tensor(0.0044, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.3428e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.810284
Average KL loss: 0.007072
Average total loss: 0.817356
tensor(0.0044, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-8.6134e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.819651
Average KL loss: 0.006951
Average total loss: 0.826602
tensor(0.0043, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.1927e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.811557
Average KL loss: 0.006833
Average total loss: 0.818391
tensor(0.0042, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.9219e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.807058
Average KL loss: 0.006717
Average total loss: 0.813776
tensor(0.0042, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.1116e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.825205
Average KL loss: 0.006604
Average total loss: 0.831809
tensor(0.0041, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.7733e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.822655
Average KL loss: 0.006494
Average total loss: 0.829148
tensor(0.0041, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.9044e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.808881
Average KL loss: 0.006386
Average total loss: 0.815267
tensor(0.0040, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.4388e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.809607
Average KL loss: 0.006282
Average total loss: 0.815889
tensor(0.0040, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-9.1940e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.814677
Average KL loss: 0.006181
Average total loss: 0.820858
tensor(0.0039, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-8.7192e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.810433
Average KL loss: 0.006083
Average total loss: 0.816516
tensor(0.0039, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.8486e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.809101
Average KL loss: 0.005988
Average total loss: 0.815090
tensor(0.0038, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.3909e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.816507
Average KL loss: 0.005898
Average total loss: 0.822405
tensor(0.0038, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.7982e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.806384
Average KL loss: 0.005811
Average total loss: 0.812195
tensor(0.0037, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.3508e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.816739
Average KL loss: 0.005728
Average total loss: 0.822467
tensor(0.0037, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.1435e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.817511
Average KL loss: 0.005648
Average total loss: 0.823159
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.6849e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.800430
Average KL loss: 0.005572
Average total loss: 0.806002
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-8.2484e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.813115
Average KL loss: 0.005500
Average total loss: 0.818615
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.0671e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.807592
Average KL loss: 0.005432
Average total loss: 0.813025
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-8.4602e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.810926
Average KL loss: 0.005368
Average total loss: 0.816294
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-9.3239e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.801011
Average KL loss: 0.005307
Average total loss: 0.806318
tensor(0.0034, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.2982e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.807277
Average KL loss: 0.005249
Average total loss: 0.812526
tensor(0.0034, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-8.4245e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.811142
Average KL loss: 0.005195
Average total loss: 0.816337
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.0969e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.799424
Average KL loss: 0.005144
Average total loss: 0.804568
tensor(0.0033, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.3045e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.813172
Average KL loss: 0.005096
Average total loss: 0.818268
tensor(0.0033, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-7.4372e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.795794
Average KL loss: 0.005051
Average total loss: 0.800845
tensor(0.0033, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.6591e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.793185
Average KL loss: 0.005009
Average total loss: 0.798194
tensor(0.0032, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-8.3688e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.803485
Average KL loss: 0.004970
Average total loss: 0.808455
tensor(0.0032, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.6051e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.800013
Average KL loss: 0.004933
Average total loss: 0.804947
tensor(0.0032, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.6450e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.807496
Average KL loss: 0.004899
Average total loss: 0.812394
tensor(0.0032, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.2383e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.795631
Average KL loss: 0.004867
Average total loss: 0.800498
tensor(0.0031, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.0079e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.799816
Average KL loss: 0.004837
Average total loss: 0.804652
tensor(0.0031, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.3869e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.818361
Average KL loss: 0.004809
Average total loss: 0.823170
tensor(0.0031, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.1693e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.796622
Average KL loss: 0.004783
Average total loss: 0.801405
tensor(0.0031, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.8805e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.801260
Average KL loss: 0.004758
Average total loss: 0.806018
tensor(0.0030, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.0966e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.786452
Average KL loss: 0.004736
Average total loss: 0.791187
tensor(0.0030, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-7.9458e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.793021
Average KL loss: 0.004714
Average total loss: 0.797736
tensor(0.0030, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.7196e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.793510
Average KL loss: 0.004694
Average total loss: 0.798204
tensor(0.0030, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-7.6441e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.793255
Average KL loss: 0.004676
Average total loss: 0.797931
tensor(0.0030, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-8.4546e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.811853
Average KL loss: 0.004658
Average total loss: 0.816511
tensor(0.0029, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.1862e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.796362
Average KL loss: 0.004642
Average total loss: 0.801004
tensor(0.0029, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.1480e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.803207
Average KL loss: 0.004626
Average total loss: 0.807834
tensor(0.0029, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.8633e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.794991
Average KL loss: 0.004612
Average total loss: 0.799603
tensor(0.0029, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.6739e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.806006
Average KL loss: 0.004598
Average total loss: 0.810604
tensor(0.0029, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.7271e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.789793
Average KL loss: 0.004585
Average total loss: 0.794378
tensor(0.0029, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.4416e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.807439
Average KL loss: 0.004573
Average total loss: 0.812012
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.1871e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.799287
Average KL loss: 0.004561
Average total loss: 0.803849
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.1376e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.785713
Average KL loss: 0.004555
Average total loss: 0.790268
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-7.7733e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.790340
Average KL loss: 0.004554
Average total loss: 0.794894
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.3701e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.787682
Average KL loss: 0.004553
Average total loss: 0.792236
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.5284e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.798550
Average KL loss: 0.004552
Average total loss: 0.803103
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.0322e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.808495
Average KL loss: 0.004551
Average total loss: 0.813046
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.4206e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.781853
Average KL loss: 0.004550
Average total loss: 0.786403
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.1859e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.787029
Average KL loss: 0.004549
Average total loss: 0.791578
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.6097e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.788056
Average KL loss: 0.004548
Average total loss: 0.792604
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.9218e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.795754
Average KL loss: 0.004547
Average total loss: 0.800301
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.6625e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.790425
Average KL loss: 0.004546
Average total loss: 0.794971
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.0668e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.793159
Average KL loss: 0.004545
Average total loss: 0.797704
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.0184e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.793329
Average KL loss: 0.004544
Average total loss: 0.797873
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.7521e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.797293
Average KL loss: 0.004543
Average total loss: 0.801836
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.0187e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.784855
Average KL loss: 0.004542
Average total loss: 0.789397
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.5365e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.803657
Average KL loss: 0.004541
Average total loss: 0.808198
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.3674e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.783127
Average KL loss: 0.004540
Average total loss: 0.787667
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.5372e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.782684
Average KL loss: 0.004539
Average total loss: 0.787223
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.2158e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.804110
Average KL loss: 0.004539
Average total loss: 0.808649
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-4.6358e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.788189
Average KL loss: 0.004538
Average total loss: 0.792727
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.0307e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.803117
Average KL loss: 0.004538
Average total loss: 0.807655
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.4524e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.796593
Average KL loss: 0.004538
Average total loss: 0.801131
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.1580e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.813581
Average KL loss: 0.004538
Average total loss: 0.818119
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.5409e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.783898
Average KL loss: 0.004538
Average total loss: 0.788436
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.0691e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.788110
Average KL loss: 0.004538
Average total loss: 0.792648
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-6.1481e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.797189
Average KL loss: 0.004538
Average total loss: 0.801727
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-7.4189e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.806252
Average KL loss: 0.004538
Average total loss: 0.810790
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.2960e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.794455
Average KL loss: 0.004538
Average total loss: 0.798993
tensor(0.0028, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.1414e-08, device='cuda:0')
 Percentile value: 3.785918712615967
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =     101 /    1728             (  5.84%) | total_pruned =    1627 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      11 /   36864             (  0.03%) | total_pruned =   36853 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      23 /   36864             (  0.06%) | total_pruned =   36841 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     125 /   36864             (  0.34%) | total_pruned =   36739 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     165 /   36864             (  0.45%) | total_pruned =   36699 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     151 /   73728             (  0.20%) | total_pruned =   73577 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     249 /  147456             (  0.17%) | total_pruned =  147207 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      83 /    8192             (  1.01%) | total_pruned =    8109 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     185 /  147456             (  0.13%) | total_pruned =  147271 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     167 /  147456             (  0.11%) | total_pruned =  147289 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     384 /  294912             (  0.13%) | total_pruned =  294528 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     429 /  589824             (  0.07%) | total_pruned =  589395 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      67 /   32768             (  0.20%) | total_pruned =   32701 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     303 /  589824             (  0.05%) | total_pruned =  589521 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     301 /  589824             (  0.05%) | total_pruned =  589523 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     332 / 1179648             (  0.03%) | total_pruned = 1179316 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     109 /     512             ( 21.29%) | total_pruned =     403 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     272 / 2359296             (  0.01%) | total_pruned = 2359024 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      60 /     512             ( 11.72%) | total_pruned =     452 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      12 /  131072             (  0.01%) | total_pruned =  131060 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      31 /     512             (  6.05%) | total_pruned =     481 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     372 / 2359296             (  0.02%) | total_pruned = 2358924 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     485 / 2359296             (  0.02%) | total_pruned = 2358811 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      28 /     512             (  5.47%) | total_pruned =     484 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
linear.weight        | nonzeros =     219 /    5120             (  4.28%) | total_pruned =    4901 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 1.032485 Accuracy: 65.81 69.19 % Best test Accuracy: 66.29%
