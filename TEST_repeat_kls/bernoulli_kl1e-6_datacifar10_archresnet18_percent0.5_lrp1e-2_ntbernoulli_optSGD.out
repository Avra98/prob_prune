Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2564e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302463
Average KL loss: 0.000153
Average total loss: 2.302616
tensor(0.0004, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-6.5735e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.299406
Average KL loss: 0.000611
Average total loss: 2.300017
tensor(0.0016, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.0021e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.200370
Average KL loss: 0.004641
Average total loss: 2.205011
tensor(0.0118, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.1994e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.670070
Average KL loss: 0.023702
Average total loss: 1.693772
tensor(0.0316, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-1.3338e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.198806
Average KL loss: 0.042811
Average total loss: 1.241618
tensor(0.0400, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-9.2846e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.918096
Average KL loss: 0.052262
Average total loss: 0.970358
tensor(0.0430, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-7.3585e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.767928
Average KL loss: 0.056155
Average total loss: 0.824083
tensor(0.0437, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-5.9361e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.666415
Average KL loss: 0.057617
Average total loss: 0.724032
tensor(0.0442, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(-3.9304e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.590128
Average KL loss: 0.058249
Average total loss: 0.648376
tensor(0.0439, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(-4.0855e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.539207
Average KL loss: 0.058321
Average total loss: 0.597528
tensor(0.0438, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-3.8875e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.502899
Average KL loss: 0.058499
Average total loss: 0.561398
tensor(0.0440, device='cuda:0') tensor(0.0426, device='cuda:0') tensor(-3.8538e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.476425
Average KL loss: 0.058789
Average total loss: 0.535214
tensor(0.0438, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-2.6024e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.443511
Average KL loss: 0.059090
Average total loss: 0.502601
tensor(0.0439, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(-3.4988e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.403638
Average KL loss: 0.059065
Average total loss: 0.462703
tensor(0.0436, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-4.8885e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.382341
Average KL loss: 0.058956
Average total loss: 0.441297
tensor(0.0435, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-3.9723e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.360595
Average KL loss: 0.058954
Average total loss: 0.419548
tensor(0.0435, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-2.6386e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.343314
Average KL loss: 0.058941
Average total loss: 0.402256
tensor(0.0436, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-3.6583e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.322941
Average KL loss: 0.058946
Average total loss: 0.381887
tensor(0.0434, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-2.5828e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.308029
Average KL loss: 0.058884
Average total loss: 0.366913
tensor(0.0435, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-2.1846e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.295527
Average KL loss: 0.058770
Average total loss: 0.354297
tensor(0.0433, device='cuda:0') tensor(0.0444, device='cuda:0') tensor(-2.4210e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.285315
Average KL loss: 0.058752
Average total loss: 0.344067
tensor(0.0432, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-2.3164e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.269907
Average KL loss: 0.058736
Average total loss: 0.328643
tensor(0.0433, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-2.2347e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.262713
Average KL loss: 0.058776
Average total loss: 0.321488
tensor(0.0432, device='cuda:0') tensor(0.0450, device='cuda:0') tensor(-2.2093e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.249531
Average KL loss: 0.058819
Average total loss: 0.308350
tensor(0.0431, device='cuda:0') tensor(0.0451, device='cuda:0') tensor(-1.9448e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.246671
Average KL loss: 0.058693
Average total loss: 0.305364
tensor(0.0430, device='cuda:0') tensor(0.0453, device='cuda:0') tensor(-1.7855e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.233606
Average KL loss: 0.058726
Average total loss: 0.292331
tensor(0.0431, device='cuda:0') tensor(0.0454, device='cuda:0') tensor(-2.4160e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.225669
Average KL loss: 0.058626
Average total loss: 0.284295
tensor(0.0431, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-1.4594e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.222100
Average KL loss: 0.058612
Average total loss: 0.280712
tensor(0.0430, device='cuda:0') tensor(0.0457, device='cuda:0') tensor(-1.6390e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.206457
Average KL loss: 0.058533
Average total loss: 0.264990
tensor(0.0429, device='cuda:0') tensor(0.0458, device='cuda:0') tensor(-1.8282e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.207514
Average KL loss: 0.058399
Average total loss: 0.265913
tensor(0.0429, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(-1.5284e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.197743
Average KL loss: 0.058346
Average total loss: 0.256089
tensor(0.0429, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(-1.2458e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.189631
Average KL loss: 0.058184
Average total loss: 0.247815
tensor(0.0428, device='cuda:0') tensor(0.0460, device='cuda:0') tensor(-1.2710e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.188567
Average KL loss: 0.058024
Average total loss: 0.246591
tensor(0.0427, device='cuda:0') tensor(0.0461, device='cuda:0') tensor(-1.3607e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.186916
Average KL loss: 0.058043
Average total loss: 0.244960
tensor(0.0428, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-1.1919e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.176938
Average KL loss: 0.057936
Average total loss: 0.234874
tensor(0.0426, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-1.1947e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.175396
Average KL loss: 0.057809
Average total loss: 0.233205
tensor(0.0425, device='cuda:0') tensor(0.0464, device='cuda:0') tensor(-1.3940e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.166262
Average KL loss: 0.057701
Average total loss: 0.223963
tensor(0.0425, device='cuda:0') tensor(0.0464, device='cuda:0') tensor(-1.0140e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.163668
Average KL loss: 0.057552
Average total loss: 0.221220
tensor(0.0424, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-1.3494e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.158160
Average KL loss: 0.057414
Average total loss: 0.215574
tensor(0.0423, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-1.0449e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.159918
Average KL loss: 0.057333
Average total loss: 0.217251
tensor(0.0424, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.1134e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.151684
Average KL loss: 0.057240
Average total loss: 0.208925
tensor(0.0423, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.0156e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.150412
Average KL loss: 0.057140
Average total loss: 0.207552
tensor(0.0423, device='cuda:0') tensor(0.0468, device='cuda:0') tensor(-1.0415e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.144382
Average KL loss: 0.056932
Average total loss: 0.201314
tensor(0.0422, device='cuda:0') tensor(0.0468, device='cuda:0') tensor(-9.4352e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.145260
Average KL loss: 0.056839
Average total loss: 0.202099
tensor(0.0422, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(-1.0064e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.138559
Average KL loss: 0.056670
Average total loss: 0.195230
tensor(0.0420, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(-7.2141e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.136548
Average KL loss: 0.056511
Average total loss: 0.193059
tensor(0.0420, device='cuda:0') tensor(0.0470, device='cuda:0') tensor(-5.0586e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.134908
Average KL loss: 0.056375
Average total loss: 0.191283
tensor(0.0419, device='cuda:0') tensor(0.0470, device='cuda:0') tensor(-1.0078e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.131035
Average KL loss: 0.056308
Average total loss: 0.187342
tensor(0.0419, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-1.0341e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.132416
Average KL loss: 0.056182
Average total loss: 0.188598
tensor(0.0418, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-8.2369e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.123469
Average KL loss: 0.055967
Average total loss: 0.179436
tensor(0.0417, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-8.1367e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.126256
Average KL loss: 0.055733
Average total loss: 0.181989
tensor(0.0416, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-6.6104e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.123105
Average KL loss: 0.055609
Average total loss: 0.178714
tensor(0.0416, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-9.0545e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.122923
Average KL loss: 0.055494
Average total loss: 0.178418
tensor(0.0416, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-5.0820e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.119015
Average KL loss: 0.055431
Average total loss: 0.174446
tensor(0.0415, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-6.5222e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.113656
Average KL loss: 0.055187
Average total loss: 0.168843
tensor(0.0414, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-6.1435e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.114751
Average KL loss: 0.055033
Average total loss: 0.169784
tensor(0.0413, device='cuda:0') tensor(0.0474, device='cuda:0') tensor(-7.6846e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.114431
Average KL loss: 0.054915
Average total loss: 0.169346
tensor(0.0413, device='cuda:0') tensor(0.0474, device='cuda:0') tensor(-7.1733e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.109133
Average KL loss: 0.054767
Average total loss: 0.163900
tensor(0.0412, device='cuda:0') tensor(0.0474, device='cuda:0') tensor(-5.5244e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.108822
Average KL loss: 0.054586
Average total loss: 0.163408
tensor(0.0411, device='cuda:0') tensor(0.0474, device='cuda:0') tensor(-5.7255e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.110244
Average KL loss: 0.054463
Average total loss: 0.164707
tensor(0.0411, device='cuda:0') tensor(0.0476, device='cuda:0') tensor(-6.4656e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.105669
Average KL loss: 0.054382
Average total loss: 0.160052
tensor(0.0410, device='cuda:0') tensor(0.0476, device='cuda:0') tensor(-5.9887e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.105019
Average KL loss: 0.054226
Average total loss: 0.159245
tensor(0.0409, device='cuda:0') tensor(0.0476, device='cuda:0') tensor(-5.7155e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.103089
Average KL loss: 0.054042
Average total loss: 0.157131
tensor(0.0409, device='cuda:0') tensor(0.0476, device='cuda:0') tensor(-3.7582e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.100709
Average KL loss: 0.053872
Average total loss: 0.154580
tensor(0.0408, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-5.3420e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.101200
Average KL loss: 0.053738
Average total loss: 0.154938
tensor(0.0407, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-6.8992e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.098626
Average KL loss: 0.053594
Average total loss: 0.152220
tensor(0.0406, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-4.2193e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.094806
Average KL loss: 0.053272
Average total loss: 0.148078
tensor(0.0405, device='cuda:0') tensor(0.0475, device='cuda:0') tensor(-5.7069e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.097068
Average KL loss: 0.053055
Average total loss: 0.150123
tensor(0.0405, device='cuda:0') tensor(0.0476, device='cuda:0') tensor(-4.6795e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.095572
Average KL loss: 0.052985
Average total loss: 0.148557
tensor(0.0404, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-5.2728e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.094610
Average KL loss: 0.052869
Average total loss: 0.147479
tensor(0.0404, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-5.1344e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.093044
Average KL loss: 0.052731
Average total loss: 0.145775
tensor(0.0404, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-1.2491e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.093461
Average KL loss: 0.052667
Average total loss: 0.146128
tensor(0.0404, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-4.9589e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.093431
Average KL loss: 0.052585
Average total loss: 0.146016
tensor(0.0403, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-3.0697e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.090191
Average KL loss: 0.052492
Average total loss: 0.142683
tensor(0.0402, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-5.0651e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.087502
Average KL loss: 0.052267
Average total loss: 0.139769
tensor(0.0402, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-4.5119e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.087825
Average KL loss: 0.052026
Average total loss: 0.139851
tensor(0.0401, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-3.0044e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.086111
Average KL loss: 0.051893
Average total loss: 0.138004
tensor(0.0400, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-3.1034e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.086930
Average KL loss: 0.051754
Average total loss: 0.138684
tensor(0.0400, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-2.2590e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.085365
Average KL loss: 0.051667
Average total loss: 0.137032
tensor(0.0399, device='cuda:0') tensor(0.0481, device='cuda:0') tensor(-1.5818e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.084077
Average KL loss: 0.051489
Average total loss: 0.135566
tensor(0.0398, device='cuda:0') tensor(0.0481, device='cuda:0') tensor(-1.7623e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.081569
Average KL loss: 0.051296
Average total loss: 0.132865
tensor(0.0396, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-3.2262e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.084707
Average KL loss: 0.051085
Average total loss: 0.135792
tensor(0.0396, device='cuda:0') tensor(0.0481, device='cuda:0') tensor(-3.5781e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.083289
Average KL loss: 0.051055
Average total loss: 0.134344
tensor(0.0396, device='cuda:0') tensor(0.0482, device='cuda:0') tensor(-1.4595e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.080777
Average KL loss: 0.050923
Average total loss: 0.131699
tensor(0.0395, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-1.0238e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.080750
Average KL loss: 0.050795
Average total loss: 0.131545
tensor(0.0395, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-3.2181e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.080611
Average KL loss: 0.050678
Average total loss: 0.131289
tensor(0.0394, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-1.4687e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.077235
Average KL loss: 0.050530
Average total loss: 0.127765
tensor(0.0395, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-4.0151e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.078179
Average KL loss: 0.050329
Average total loss: 0.128507
tensor(0.0394, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-3.0180e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.076833
Average KL loss: 0.050193
Average total loss: 0.127026
tensor(0.0392, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-2.4357e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.076568
Average KL loss: 0.049987
Average total loss: 0.126555
tensor(0.0392, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-2.6968e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.077251
Average KL loss: 0.049951
Average total loss: 0.127202
tensor(0.0392, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-3.2848e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.074834
Average KL loss: 0.049798
Average total loss: 0.124633
tensor(0.0390, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(2.2568e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.075172
Average KL loss: 0.049580
Average total loss: 0.124753
tensor(0.0389, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-2.7160e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.075190
Average KL loss: 0.049527
Average total loss: 0.124717
tensor(0.0389, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-2.7328e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.074192
Average KL loss: 0.049483
Average total loss: 0.123675
tensor(0.0388, device='cuda:0') tensor(0.0486, device='cuda:0') tensor(-1.7073e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.073131
Average KL loss: 0.049390
Average total loss: 0.122521
tensor(0.0388, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-7.4234e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.073201
Average KL loss: 0.049199
Average total loss: 0.122399
tensor(0.0387, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-1.4004e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.072542
Average KL loss: 0.049079
Average total loss: 0.121622
tensor(0.0388, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-3.1389e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.071922
Average KL loss: 0.048999
Average total loss: 0.120922
tensor(0.0387, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-1.3586e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.070266
Average KL loss: 0.048828
Average total loss: 0.119093
tensor(0.0385, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-1.7213e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.070487
Average KL loss: 0.048638
Average total loss: 0.119125
tensor(0.0384, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-1.1924e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.070297
Average KL loss: 0.048544
Average total loss: 0.118842
tensor(0.0384, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-2.8276e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.070032
Average KL loss: 0.048424
Average total loss: 0.118456
tensor(0.0383, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-1.7902e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.070662
Average KL loss: 0.048394
Average total loss: 0.119056
tensor(0.0383, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(-1.5574e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.066208
Average KL loss: 0.048272
Average total loss: 0.114479
tensor(0.0382, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-1.5559e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.067331
Average KL loss: 0.047974
Average total loss: 0.115306
tensor(0.0381, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-3.8778e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.067054
Average KL loss: 0.047807
Average total loss: 0.114861
tensor(0.0381, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-2.3214e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.067968
Average KL loss: 0.047700
Average total loss: 0.115668
tensor(0.0380, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(-6.0224e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.066319
Average KL loss: 0.047663
Average total loss: 0.113982
tensor(0.0379, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(-1.8555e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.067510
Average KL loss: 0.047556
Average total loss: 0.115067
tensor(0.0378, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(-2.9389e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.065230
Average KL loss: 0.047450
Average total loss: 0.112679
tensor(0.0378, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(4.1864e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.066014
Average KL loss: 0.047318
Average total loss: 0.113332
tensor(0.0377, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(-2.2230e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.065593
Average KL loss: 0.047278
Average total loss: 0.112871
tensor(0.0377, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-2.0523e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.065699
Average KL loss: 0.047192
Average total loss: 0.112891
tensor(0.0376, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-1.0192e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.063771
Average KL loss: 0.047086
Average total loss: 0.110856
tensor(0.0376, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-3.2314e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.065178
Average KL loss: 0.047019
Average total loss: 0.112197
tensor(0.0376, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(-1.0234e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.064905
Average KL loss: 0.046973
Average total loss: 0.111878
tensor(0.0376, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(-1.3280e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.063897
Average KL loss: 0.046935
Average total loss: 0.110832
tensor(0.0375, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(-1.4435e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.062662
Average KL loss: 0.046805
Average total loss: 0.109467
tensor(0.0375, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(-2.2568e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.063439
Average KL loss: 0.046687
Average total loss: 0.110126
tensor(0.0374, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(-6.4754e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.063243
Average KL loss: 0.046650
Average total loss: 0.109893
tensor(0.0375, device='cuda:0') tensor(0.0499, device='cuda:0') tensor(-1.0399e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.063382
Average KL loss: 0.046622
Average total loss: 0.110004
tensor(0.0373, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-1.1610e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.061913
Average KL loss: 0.046553
Average total loss: 0.108466
tensor(0.0373, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-1.0614e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.062500
Average KL loss: 0.046436
Average total loss: 0.108936
tensor(0.0372, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(-7.2346e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.061306
Average KL loss: 0.046334
Average total loss: 0.107640
tensor(0.0372, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(-1.1254e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.060513
Average KL loss: 0.046241
Average total loss: 0.106754
tensor(0.0371, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(-7.5302e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.062112
Average KL loss: 0.046071
Average total loss: 0.108183
tensor(0.0371, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(-1.0718e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.060899
Average KL loss: 0.046111
Average total loss: 0.107010
tensor(0.0370, device='cuda:0') tensor(0.0504, device='cuda:0') tensor(4.6073e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.060369
Average KL loss: 0.046027
Average total loss: 0.106396
tensor(0.0369, device='cuda:0') tensor(0.0505, device='cuda:0') tensor(-2.3510e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.059231
Average KL loss: 0.045900
Average total loss: 0.105131
tensor(0.0369, device='cuda:0') tensor(0.0505, device='cuda:0') tensor(-6.0827e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.060208
Average KL loss: 0.045763
Average total loss: 0.105970
tensor(0.0368, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-1.0766e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.059572
Average KL loss: 0.045737
Average total loss: 0.105309
tensor(0.0368, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(-2.4942e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.060270
Average KL loss: 0.045682
Average total loss: 0.105952
tensor(0.0367, device='cuda:0') tensor(0.0508, device='cuda:0') tensor(-1.4602e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.058873
Average KL loss: 0.045594
Average total loss: 0.104467
tensor(0.0367, device='cuda:0') tensor(0.0508, device='cuda:0') tensor(-1.7237e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.059488
Average KL loss: 0.045570
Average total loss: 0.105058
tensor(0.0367, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(-8.6952e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.059002
Average KL loss: 0.045520
Average total loss: 0.104522
tensor(0.0367, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(-8.9145e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.058390
Average KL loss: 0.045463
Average total loss: 0.103853
tensor(0.0366, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(7.9901e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.057402
Average KL loss: 0.045314
Average total loss: 0.102715
tensor(0.0365, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(-4.0189e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.056945
Average KL loss: 0.045132
Average total loss: 0.102077
tensor(0.0363, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(-1.3753e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.057535
Average KL loss: 0.045001
Average total loss: 0.102536
tensor(0.0364, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(-1.5194e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.057644
Average KL loss: 0.044968
Average total loss: 0.102611
tensor(0.0364, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(-5.1637e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.057038
Average KL loss: 0.044860
Average total loss: 0.101898
tensor(0.0362, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(-7.9006e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.057891
Average KL loss: 0.044832
Average total loss: 0.102723
tensor(0.0363, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-1.5511e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.057113
Average KL loss: 0.044850
Average total loss: 0.101963
tensor(0.0362, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-1.9539e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.056297
Average KL loss: 0.044783
Average total loss: 0.101080
tensor(0.0362, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-4.9234e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.056923
Average KL loss: 0.044629
Average total loss: 0.101552
tensor(0.0361, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-6.2526e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.056614
Average KL loss: 0.044639
Average total loss: 0.101253
tensor(0.0362, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-4.6051e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.056804
Average KL loss: 0.044585
Average total loss: 0.101388
tensor(0.0360, device='cuda:0') tensor(0.0519, device='cuda:0') tensor(-3.4117e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.054882
Average KL loss: 0.044585
Average total loss: 0.099468
tensor(0.0360, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(-1.6251e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.056485
Average KL loss: 0.044474
Average total loss: 0.100960
tensor(0.0360, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(-1.1648e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.055008
Average KL loss: 0.044420
Average total loss: 0.099428
tensor(0.0359, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(-1.3209e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.055710
Average KL loss: 0.044405
Average total loss: 0.100115
tensor(0.0359, device='cuda:0') tensor(0.0522, device='cuda:0') tensor(-2.6161e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.055312
Average KL loss: 0.044352
Average total loss: 0.099664
tensor(0.0359, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(4.6828e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.055876
Average KL loss: 0.044329
Average total loss: 0.100206
tensor(0.0359, device='cuda:0') tensor(0.0524, device='cuda:0') tensor(2.8757e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.054459
Average KL loss: 0.044359
Average total loss: 0.098818
tensor(0.0359, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-6.6848e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.054544
Average KL loss: 0.044202
Average total loss: 0.098746
tensor(0.0357, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-5.7166e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.053406
Average KL loss: 0.044026
Average total loss: 0.097432
tensor(0.0357, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-7.0396e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.053536
Average KL loss: 0.043908
Average total loss: 0.097444
tensor(0.0357, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-1.3657e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.054773
Average KL loss: 0.043825
Average total loss: 0.098598
tensor(0.0357, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(2.6760e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.054346
Average KL loss: 0.043882
Average total loss: 0.098229
tensor(0.0357, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(-1.3011e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.053057
Average KL loss: 0.043818
Average total loss: 0.096875
tensor(0.0356, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(-1.1559e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.052822
Average KL loss: 0.043646
Average total loss: 0.096468
tensor(0.0355, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(-7.3485e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.053692
Average KL loss: 0.043577
Average total loss: 0.097269
tensor(0.0355, device='cuda:0') tensor(0.0530, device='cuda:0') tensor(-1.4033e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.053339
Average KL loss: 0.043621
Average total loss: 0.096960
tensor(0.0355, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(-5.3412e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.053806
Average KL loss: 0.043587
Average total loss: 0.097393
tensor(0.0354, device='cuda:0') tensor(0.0532, device='cuda:0') tensor(-1.5102e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.051898
Average KL loss: 0.043469
Average total loss: 0.095367
tensor(0.0353, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(4.3933e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.052488
Average KL loss: 0.043329
Average total loss: 0.095817
tensor(0.0353, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(-4.6072e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.053334
Average KL loss: 0.043379
Average total loss: 0.096713
tensor(0.0354, device='cuda:0') tensor(0.0534, device='cuda:0') tensor(9.6564e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.053719
Average KL loss: 0.043368
Average total loss: 0.097087
tensor(0.0353, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-5.2664e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.052375
Average KL loss: 0.043455
Average total loss: 0.095830
tensor(0.0353, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(-3.7506e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.051962
Average KL loss: 0.043323
Average total loss: 0.095285
tensor(0.0352, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(-6.7599e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.052016
Average KL loss: 0.043223
Average total loss: 0.095239
tensor(0.0352, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(1.4116e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.051703
Average KL loss: 0.043115
Average total loss: 0.094818
tensor(0.0351, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(-7.1601e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.051115
Average KL loss: 0.043008
Average total loss: 0.094123
tensor(0.0351, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(-1.5241e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.051951
Average KL loss: 0.042976
Average total loss: 0.094928
tensor(0.0351, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(-1.2917e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.052705
Average KL loss: 0.043119
Average total loss: 0.095823
tensor(0.0351, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-9.2432e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.050867
Average KL loss: 0.043005
Average total loss: 0.093872
tensor(0.0350, device='cuda:0') tensor(0.0541, device='cuda:0') tensor(8.5774e-11, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.051494
Average KL loss: 0.042880
Average total loss: 0.094373
tensor(0.0350, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-2.5481e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.051474
Average KL loss: 0.042928
Average total loss: 0.094402
tensor(0.0351, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-1.4785e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.052462
Average KL loss: 0.042883
Average total loss: 0.095345
tensor(0.0351, device='cuda:0') tensor(0.0545, device='cuda:0') tensor(-7.4891e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.051124
Average KL loss: 0.042987
Average total loss: 0.094111
tensor(0.0350, device='cuda:0') tensor(0.0546, device='cuda:0') tensor(7.5618e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.051374
Average KL loss: 0.042927
Average total loss: 0.094301
tensor(0.0350, device='cuda:0') tensor(0.0547, device='cuda:0') tensor(5.5126e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.051097
Average KL loss: 0.042866
Average total loss: 0.093963
tensor(0.0350, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(4.2129e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.051079
Average KL loss: 0.042796
Average total loss: 0.093875
tensor(0.0350, device='cuda:0') tensor(0.0549, device='cuda:0') tensor(-4.9511e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.051278
Average KL loss: 0.042818
Average total loss: 0.094096
tensor(0.0350, device='cuda:0') tensor(0.0550, device='cuda:0') tensor(-1.2160e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.051232
Average KL loss: 0.042800
Average total loss: 0.094032
tensor(0.0349, device='cuda:0') tensor(0.0551, device='cuda:0') tensor(-7.7770e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.051264
Average KL loss: 0.042872
Average total loss: 0.094136
tensor(0.0349, device='cuda:0') tensor(0.0553, device='cuda:0') tensor(-7.1244e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.051183
Average KL loss: 0.042823
Average total loss: 0.094006
tensor(0.0349, device='cuda:0') tensor(0.0553, device='cuda:0') tensor(3.1320e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.049767
Average KL loss: 0.042723
Average total loss: 0.092491
tensor(0.0349, device='cuda:0') tensor(0.0552, device='cuda:0') tensor(-4.7026e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.049942
Average KL loss: 0.042471
Average total loss: 0.092413
tensor(0.0349, device='cuda:0') tensor(0.0550, device='cuda:0') tensor(-1.1525e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.048919
Average KL loss: 0.042249
Average total loss: 0.091167
tensor(0.0348, device='cuda:0') tensor(0.0549, device='cuda:0') tensor(-2.5152e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.049738
Average KL loss: 0.042051
Average total loss: 0.091790
tensor(0.0348, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(4.5434e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.048766
Average KL loss: 0.041872
Average total loss: 0.090638
tensor(0.0348, device='cuda:0') tensor(0.0546, device='cuda:0') tensor(-9.0107e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.049278
Average KL loss: 0.041704
Average total loss: 0.090982
tensor(0.0348, device='cuda:0') tensor(0.0545, device='cuda:0') tensor(-3.7934e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.049181
Average KL loss: 0.041545
Average total loss: 0.090726
tensor(0.0348, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-1.1421e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.049356
Average KL loss: 0.041395
Average total loss: 0.090751
tensor(0.0348, device='cuda:0') tensor(0.0543, device='cuda:0') tensor(-2.4836e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.048472
Average KL loss: 0.041254
Average total loss: 0.089725
tensor(0.0348, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-2.0253e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.049442
Average KL loss: 0.041121
Average total loss: 0.090563
tensor(0.0348, device='cuda:0') tensor(0.0541, device='cuda:0') tensor(7.3037e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.049564
Average KL loss: 0.040998
Average total loss: 0.090563
tensor(0.0348, device='cuda:0') tensor(0.0541, device='cuda:0') tensor(-8.0259e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.050028
Average KL loss: 0.040890
Average total loss: 0.090918
 Percentile value: 0.028436485677957535
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =     507 /    1728             ( 29.34%) | total_pruned =    1221 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6844 /   36864             ( 18.57%) | total_pruned =   30020 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   16076 /   36864             ( 43.61%) | total_pruned =   20788 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   16151 /   36864             ( 43.81%) | total_pruned =   20713 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18701 /   36864             ( 50.73%) | total_pruned =   18163 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   41741 /   73728             ( 56.61%) | total_pruned =   31987 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   83253 /  147456             ( 56.46%) | total_pruned =   64203 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5216 /    8192             ( 63.67%) | total_pruned =    2976 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   72478 /  147456             ( 49.15%) | total_pruned =   74978 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   72758 /  147456             ( 49.34%) | total_pruned =   74698 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  163616 /  294912             ( 55.48%) | total_pruned =  131296 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  323025 /  589824             ( 54.77%) | total_pruned =  266799 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     170 /     256             ( 66.41%) | total_pruned =      86 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19169 /   32768             ( 58.50%) | total_pruned =   13599 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     167 /     256             ( 65.23%) | total_pruned =      89 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  308394 /  589824             ( 52.29%) | total_pruned =  281430 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      44 /     256             ( 17.19%) | total_pruned =     212 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  293079 /  589824             ( 49.69%) | total_pruned =  296745 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     174 /     256             ( 67.97%) | total_pruned =      82 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  601239 / 1179648             ( 50.97%) | total_pruned =  578409 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     218 /     512             ( 42.58%) | total_pruned =     294 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1086621 / 2359296             ( 46.06%) | total_pruned = 1272675 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     387 /     512             ( 75.59%) | total_pruned =     125 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   59309 /  131072             ( 45.25%) | total_pruned =   71763 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1004387 / 2359296             ( 42.57%) | total_pruned = 1354909 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1384250 / 2359296             ( 58.67%) | total_pruned =  975046 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5090 /    5120             ( 99.41%) | total_pruned =      30 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 65/100 Loss: 0.019508 Accuracy: 88.97 100.00 % Best test Accuracy: 88.97%
tensor(0.0348, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(-1.0799e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.262461
Average KL loss: 0.035128
Average total loss: 1.297589
tensor(0.0410, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(-1.2711e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.491860
Average KL loss: 0.039073
Average total loss: 0.530932
tensor(0.0437, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-5.6556e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.353551
Average KL loss: 0.041756
Average total loss: 0.395307
tensor(0.0443, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-3.6429e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.304901
Average KL loss: 0.042960
Average total loss: 0.347862
tensor(0.0445, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(-3.0888e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.270505
Average KL loss: 0.043978
Average total loss: 0.314483
tensor(0.0448, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-2.3771e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.250987
Average KL loss: 0.044806
Average total loss: 0.295793
tensor(0.0450, device='cuda:0') tensor(0.0500, device='cuda:0') tensor(-3.1302e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.233039
Average KL loss: 0.045487
Average total loss: 0.278526
tensor(0.0451, device='cuda:0') tensor(0.0504, device='cuda:0') tensor(-2.2092e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.218124
Average KL loss: 0.046105
Average total loss: 0.264229
tensor(0.0453, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(-2.1025e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.211615
Average KL loss: 0.046795
Average total loss: 0.258410
tensor(0.0454, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-1.5945e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.199634
Average KL loss: 0.047317
Average total loss: 0.246951
tensor(0.0456, device='cuda:0') tensor(0.0522, device='cuda:0') tensor(-1.6431e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.189787
Average KL loss: 0.047937
Average total loss: 0.237725
tensor(0.0458, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(-1.3486e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.185013
Average KL loss: 0.048476
Average total loss: 0.233489
tensor(0.0458, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(-1.7066e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.174362
Average KL loss: 0.048883
Average total loss: 0.223245
tensor(0.0459, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(-2.0176e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.170735
Average KL loss: 0.049280
Average total loss: 0.220015
tensor(0.0460, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-1.1362e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.166067
Average KL loss: 0.049690
Average total loss: 0.215756
tensor(0.0461, device='cuda:0') tensor(0.0546, device='cuda:0') tensor(-1.5067e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.164644
Average KL loss: 0.050033
Average total loss: 0.214677
tensor(0.0461, device='cuda:0') tensor(0.0551, device='cuda:0') tensor(-1.4062e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.157692
Average KL loss: 0.050435
Average total loss: 0.208128
tensor(0.0462, device='cuda:0') tensor(0.0555, device='cuda:0') tensor(-9.1480e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.152112
Average KL loss: 0.050738
Average total loss: 0.202850
tensor(0.0462, device='cuda:0') tensor(0.0559, device='cuda:0') tensor(-1.1026e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.146820
Average KL loss: 0.051051
Average total loss: 0.197871
tensor(0.0462, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-1.5545e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.145063
Average KL loss: 0.051344
Average total loss: 0.196407
tensor(0.0463, device='cuda:0') tensor(0.0567, device='cuda:0') tensor(-9.9689e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.141416
Average KL loss: 0.051674
Average total loss: 0.193090
tensor(0.0464, device='cuda:0') tensor(0.0571, device='cuda:0') tensor(-1.2903e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.138108
Average KL loss: 0.051974
Average total loss: 0.190082
tensor(0.0464, device='cuda:0') tensor(0.0575, device='cuda:0') tensor(-1.3592e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.134131
Average KL loss: 0.052180
Average total loss: 0.186311
tensor(0.0464, device='cuda:0') tensor(0.0578, device='cuda:0') tensor(-1.0478e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.134722
Average KL loss: 0.052417
Average total loss: 0.187138
tensor(0.0464, device='cuda:0') tensor(0.0582, device='cuda:0') tensor(-8.7339e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.129473
Average KL loss: 0.052691
Average total loss: 0.182164
tensor(0.0464, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(-9.3244e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.127898
Average KL loss: 0.052930
Average total loss: 0.180828
tensor(0.0465, device='cuda:0') tensor(0.0589, device='cuda:0') tensor(-9.8350e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.122185
Average KL loss: 0.053102
Average total loss: 0.175287
tensor(0.0464, device='cuda:0') tensor(0.0592, device='cuda:0') tensor(-4.9907e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.122959
Average KL loss: 0.053273
Average total loss: 0.176232
tensor(0.0464, device='cuda:0') tensor(0.0595, device='cuda:0') tensor(-5.4538e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.119562
Average KL loss: 0.053467
Average total loss: 0.173029
tensor(0.0464, device='cuda:0') tensor(0.0598, device='cuda:0') tensor(-7.2885e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.118122
Average KL loss: 0.053634
Average total loss: 0.171756
tensor(0.0464, device='cuda:0') tensor(0.0601, device='cuda:0') tensor(-7.8696e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.116530
Average KL loss: 0.053806
Average total loss: 0.170337
tensor(0.0464, device='cuda:0') tensor(0.0604, device='cuda:0') tensor(-7.9970e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.115159
Average KL loss: 0.053992
Average total loss: 0.169152
tensor(0.0464, device='cuda:0') tensor(0.0607, device='cuda:0') tensor(-7.1252e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.113607
Average KL loss: 0.054112
Average total loss: 0.167718
tensor(0.0464, device='cuda:0') tensor(0.0610, device='cuda:0') tensor(-4.0027e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.109610
Average KL loss: 0.054267
Average total loss: 0.163877
tensor(0.0463, device='cuda:0') tensor(0.0613, device='cuda:0') tensor(-5.5573e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.110186
Average KL loss: 0.054362
Average total loss: 0.164548
tensor(0.0463, device='cuda:0') tensor(0.0615, device='cuda:0') tensor(-6.9129e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.109139
Average KL loss: 0.054579
Average total loss: 0.163718
tensor(0.0463, device='cuda:0') tensor(0.0618, device='cuda:0') tensor(-4.0604e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.103795
Average KL loss: 0.054666
Average total loss: 0.158461
tensor(0.0462, device='cuda:0') tensor(0.0621, device='cuda:0') tensor(-5.7362e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.105383
Average KL loss: 0.054762
Average total loss: 0.160145
tensor(0.0462, device='cuda:0') tensor(0.0623, device='cuda:0') tensor(-4.5078e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.103616
Average KL loss: 0.054893
Average total loss: 0.158509
tensor(0.0463, device='cuda:0') tensor(0.0626, device='cuda:0') tensor(-6.3720e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.101722
Average KL loss: 0.055006
Average total loss: 0.156728
tensor(0.0461, device='cuda:0') tensor(0.0628, device='cuda:0') tensor(-5.7086e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.101816
Average KL loss: 0.055078
Average total loss: 0.156894
tensor(0.0461, device='cuda:0') tensor(0.0631, device='cuda:0') tensor(-5.0618e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.100022
Average KL loss: 0.055210
Average total loss: 0.155233
tensor(0.0461, device='cuda:0') tensor(0.0633, device='cuda:0') tensor(-6.4675e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.097820
Average KL loss: 0.055291
Average total loss: 0.153111
tensor(0.0461, device='cuda:0') tensor(0.0636, device='cuda:0') tensor(-7.0388e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.095845
Average KL loss: 0.055335
Average total loss: 0.151181
tensor(0.0460, device='cuda:0') tensor(0.0638, device='cuda:0') tensor(-5.5254e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.095851
Average KL loss: 0.055378
Average total loss: 0.151229
tensor(0.0460, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-4.0537e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.093226
Average KL loss: 0.055475
Average total loss: 0.148701
tensor(0.0459, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-3.7568e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.092626
Average KL loss: 0.055466
Average total loss: 0.148092
tensor(0.0459, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-3.1909e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.095836
Average KL loss: 0.055580
Average total loss: 0.151417
tensor(0.0459, device='cuda:0') tensor(0.0646, device='cuda:0') tensor(-5.3213e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.089677
Average KL loss: 0.055667
Average total loss: 0.145343
tensor(0.0458, device='cuda:0') tensor(0.0648, device='cuda:0') tensor(-3.1868e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.090563
Average KL loss: 0.055697
Average total loss: 0.146260
tensor(0.0458, device='cuda:0') tensor(0.0650, device='cuda:0') tensor(-2.7428e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.088768
Average KL loss: 0.055727
Average total loss: 0.144495
tensor(0.0457, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-3.9655e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.090710
Average KL loss: 0.055816
Average total loss: 0.146525
tensor(0.0457, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-1.6859e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.087291
Average KL loss: 0.055863
Average total loss: 0.143154
tensor(0.0456, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-3.7521e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.087940
Average KL loss: 0.055860
Average total loss: 0.143799
tensor(0.0457, device='cuda:0') tensor(0.0658, device='cuda:0') tensor(-2.8654e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.084691
Average KL loss: 0.055985
Average total loss: 0.140676
tensor(0.0456, device='cuda:0') tensor(0.0660, device='cuda:0') tensor(-3.1452e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.085566
Average KL loss: 0.055970
Average total loss: 0.141536
tensor(0.0455, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-4.2114e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.084609
Average KL loss: 0.056011
Average total loss: 0.140620
tensor(0.0454, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.8076e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.083395
Average KL loss: 0.055990
Average total loss: 0.139385
tensor(0.0454, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.9399e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.082728
Average KL loss: 0.056021
Average total loss: 0.138749
tensor(0.0454, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-3.7887e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.082350
Average KL loss: 0.056050
Average total loss: 0.138399
tensor(0.0453, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-2.0898e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.081511
Average KL loss: 0.056035
Average total loss: 0.137545
tensor(0.0453, device='cuda:0') tensor(0.0670, device='cuda:0') tensor(-3.0369e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.080818
Average KL loss: 0.056061
Average total loss: 0.136879
tensor(0.0452, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(3.5822e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.082239
Average KL loss: 0.056096
Average total loss: 0.138335
tensor(0.0452, device='cuda:0') tensor(0.0674, device='cuda:0') tensor(-4.8242e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.079649
Average KL loss: 0.056124
Average total loss: 0.135772
tensor(0.0451, device='cuda:0') tensor(0.0675, device='cuda:0') tensor(-1.1834e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.080583
Average KL loss: 0.056144
Average total loss: 0.136727
tensor(0.0451, device='cuda:0') tensor(0.0677, device='cuda:0') tensor(-1.7769e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.079228
Average KL loss: 0.056111
Average total loss: 0.135338
tensor(0.0450, device='cuda:0') tensor(0.0679, device='cuda:0') tensor(-2.4919e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.077735
Average KL loss: 0.056156
Average total loss: 0.133891
tensor(0.0450, device='cuda:0') tensor(0.0681, device='cuda:0') tensor(-1.3653e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.077006
Average KL loss: 0.056170
Average total loss: 0.133176
tensor(0.0448, device='cuda:0') tensor(0.0682, device='cuda:0') tensor(-1.4881e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.076587
Average KL loss: 0.056105
Average total loss: 0.132692
tensor(0.0448, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-3.5742e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.077797
Average KL loss: 0.056152
Average total loss: 0.133948
tensor(0.0448, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-6.0301e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.076613
Average KL loss: 0.056146
Average total loss: 0.132759
tensor(0.0448, device='cuda:0') tensor(0.0687, device='cuda:0') tensor(-1.3340e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.075217
Average KL loss: 0.056135
Average total loss: 0.131352
tensor(0.0446, device='cuda:0') tensor(0.0688, device='cuda:0') tensor(-1.5177e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.074470
Average KL loss: 0.056091
Average total loss: 0.130561
tensor(0.0446, device='cuda:0') tensor(0.0689, device='cuda:0') tensor(-2.6625e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.073490
Average KL loss: 0.056072
Average total loss: 0.129561
tensor(0.0445, device='cuda:0') tensor(0.0690, device='cuda:0') tensor(-5.9309e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.074226
Average KL loss: 0.056040
Average total loss: 0.130266
tensor(0.0445, device='cuda:0') tensor(0.0692, device='cuda:0') tensor(-3.9409e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.072858
Average KL loss: 0.056047
Average total loss: 0.128905
tensor(0.0444, device='cuda:0') tensor(0.0693, device='cuda:0') tensor(-1.3510e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.072964
Average KL loss: 0.056037
Average total loss: 0.129001
tensor(0.0443, device='cuda:0') tensor(0.0695, device='cuda:0') tensor(-2.9706e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.071645
Average KL loss: 0.056022
Average total loss: 0.127667
tensor(0.0443, device='cuda:0') tensor(0.0696, device='cuda:0') tensor(-1.0406e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.071934
Average KL loss: 0.056009
Average total loss: 0.127943
tensor(0.0442, device='cuda:0') tensor(0.0697, device='cuda:0') tensor(-2.0871e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.072585
Average KL loss: 0.055976
Average total loss: 0.128561
tensor(0.0442, device='cuda:0') tensor(0.0698, device='cuda:0') tensor(-2.0528e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.072213
Average KL loss: 0.055982
Average total loss: 0.128195
tensor(0.0442, device='cuda:0') tensor(0.0700, device='cuda:0') tensor(-1.4437e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.070724
Average KL loss: 0.055985
Average total loss: 0.126710
tensor(0.0441, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-2.2527e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.071084
Average KL loss: 0.055977
Average total loss: 0.127061
tensor(0.0440, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-1.3708e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.070549
Average KL loss: 0.055992
Average total loss: 0.126541
tensor(0.0440, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-3.6360e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.070073
Average KL loss: 0.056015
Average total loss: 0.126088
tensor(0.0439, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(9.4649e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.069398
Average KL loss: 0.055962
Average total loss: 0.125360
tensor(0.0439, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-1.2769e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.068907
Average KL loss: 0.055964
Average total loss: 0.124871
tensor(0.0439, device='cuda:0') tensor(0.0709, device='cuda:0') tensor(-1.2158e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.070632
Average KL loss: 0.055995
Average total loss: 0.126627
tensor(0.0439, device='cuda:0') tensor(0.0711, device='cuda:0') tensor(-5.0185e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.068034
Average KL loss: 0.056001
Average total loss: 0.124035
tensor(0.0438, device='cuda:0') tensor(0.0712, device='cuda:0') tensor(-3.1882e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.067576
Average KL loss: 0.055958
Average total loss: 0.123534
tensor(0.0437, device='cuda:0') tensor(0.0713, device='cuda:0') tensor(7.0695e-11, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.067375
Average KL loss: 0.055889
Average total loss: 0.123264
tensor(0.0437, device='cuda:0') tensor(0.0714, device='cuda:0') tensor(-1.2279e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.067869
Average KL loss: 0.055868
Average total loss: 0.123737
tensor(0.0436, device='cuda:0') tensor(0.0715, device='cuda:0') tensor(-2.5082e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.067295
Average KL loss: 0.055867
Average total loss: 0.123162
tensor(0.0435, device='cuda:0') tensor(0.0717, device='cuda:0') tensor(-1.4026e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.066893
Average KL loss: 0.055796
Average total loss: 0.122689
tensor(0.0435, device='cuda:0') tensor(0.0717, device='cuda:0') tensor(-4.0524e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.066437
Average KL loss: 0.055801
Average total loss: 0.122238
tensor(0.0434, device='cuda:0') tensor(0.0719, device='cuda:0') tensor(-2.1252e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.065658
Average KL loss: 0.055717
Average total loss: 0.121375
tensor(0.0434, device='cuda:0') tensor(0.0720, device='cuda:0') tensor(-2.0989e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.066064
Average KL loss: 0.055738
Average total loss: 0.121802
tensor(0.0433, device='cuda:0') tensor(0.0722, device='cuda:0') tensor(1.8771e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.065223
Average KL loss: 0.055700
Average total loss: 0.120924
tensor(0.0433, device='cuda:0') tensor(0.0722, device='cuda:0') tensor(-1.2501e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.064807
Average KL loss: 0.055649
Average total loss: 0.120455
tensor(0.0432, device='cuda:0') tensor(0.0724, device='cuda:0') tensor(-7.1243e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.064452
Average KL loss: 0.055601
Average total loss: 0.120053
tensor(0.0431, device='cuda:0') tensor(0.0725, device='cuda:0') tensor(-1.2543e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.067539
Average KL loss: 0.055581
Average total loss: 0.123120
tensor(0.0431, device='cuda:0') tensor(0.0727, device='cuda:0') tensor(-2.2692e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.064494
Average KL loss: 0.055628
Average total loss: 0.120122
tensor(0.0430, device='cuda:0') tensor(0.0727, device='cuda:0') tensor(-1.8162e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.064376
Average KL loss: 0.055575
Average total loss: 0.119950
tensor(0.0430, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(-8.5133e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.064252
Average KL loss: 0.055578
Average total loss: 0.119830
tensor(0.0430, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(-2.7603e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.062728
Average KL loss: 0.055542
Average total loss: 0.118270
tensor(0.0429, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(6.0947e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.063347
Average KL loss: 0.055470
Average total loss: 0.118817
tensor(0.0429, device='cuda:0') tensor(0.0732, device='cuda:0') tensor(-6.1465e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.063946
Average KL loss: 0.055420
Average total loss: 0.119366
tensor(0.0428, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(-6.4883e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.063289
Average KL loss: 0.055440
Average total loss: 0.118728
tensor(0.0428, device='cuda:0') tensor(0.0735, device='cuda:0') tensor(-5.6539e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.063476
Average KL loss: 0.055414
Average total loss: 0.118890
tensor(0.0427, device='cuda:0') tensor(0.0736, device='cuda:0') tensor(-1.9817e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.062850
Average KL loss: 0.055420
Average total loss: 0.118270
tensor(0.0427, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(-1.3613e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.062921
Average KL loss: 0.055387
Average total loss: 0.118307
tensor(0.0427, device='cuda:0') tensor(0.0739, device='cuda:0') tensor(7.1393e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.062485
Average KL loss: 0.055397
Average total loss: 0.117882
tensor(0.0426, device='cuda:0') tensor(0.0740, device='cuda:0') tensor(-1.2336e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.061972
Average KL loss: 0.055335
Average total loss: 0.117306
tensor(0.0426, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(5.7272e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.061075
Average KL loss: 0.055264
Average total loss: 0.116340
tensor(0.0425, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(2.6567e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.061602
Average KL loss: 0.055210
Average total loss: 0.116811
tensor(0.0424, device='cuda:0') tensor(0.0743, device='cuda:0') tensor(-5.5481e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.061662
Average KL loss: 0.055158
Average total loss: 0.116820
tensor(0.0424, device='cuda:0') tensor(0.0744, device='cuda:0') tensor(-1.1182e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.061100
Average KL loss: 0.055145
Average total loss: 0.116245
tensor(0.0424, device='cuda:0') tensor(0.0745, device='cuda:0') tensor(-1.9567e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.061799
Average KL loss: 0.055171
Average total loss: 0.116969
tensor(0.0424, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-3.0464e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.060438
Average KL loss: 0.055176
Average total loss: 0.115614
tensor(0.0423, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(6.3483e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.060411
Average KL loss: 0.055060
Average total loss: 0.115471
tensor(0.0423, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(-1.6201e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.059662
Average KL loss: 0.055063
Average total loss: 0.114725
tensor(0.0422, device='cuda:0') tensor(0.0750, device='cuda:0') tensor(-3.3873e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.060704
Average KL loss: 0.055042
Average total loss: 0.115745
tensor(0.0421, device='cuda:0') tensor(0.0751, device='cuda:0') tensor(-2.3665e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.059894
Average KL loss: 0.055015
Average total loss: 0.114909
tensor(0.0421, device='cuda:0') tensor(0.0752, device='cuda:0') tensor(-5.3191e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.059320
Average KL loss: 0.054952
Average total loss: 0.114273
tensor(0.0421, device='cuda:0') tensor(0.0753, device='cuda:0') tensor(-1.0512e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.059814
Average KL loss: 0.054924
Average total loss: 0.114739
tensor(0.0420, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(3.0804e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.059750
Average KL loss: 0.054902
Average total loss: 0.114652
tensor(0.0420, device='cuda:0') tensor(0.0755, device='cuda:0') tensor(-6.2520e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.058670
Average KL loss: 0.054886
Average total loss: 0.113555
tensor(0.0419, device='cuda:0') tensor(0.0756, device='cuda:0') tensor(-3.6882e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.060157
Average KL loss: 0.054840
Average total loss: 0.114997
tensor(0.0420, device='cuda:0') tensor(0.0758, device='cuda:0') tensor(-9.2486e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.059090
Average KL loss: 0.054860
Average total loss: 0.113950
tensor(0.0419, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(-1.4573e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.059360
Average KL loss: 0.054835
Average total loss: 0.114195
tensor(0.0419, device='cuda:0') tensor(0.0760, device='cuda:0') tensor(-8.0636e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.057805
Average KL loss: 0.054796
Average total loss: 0.112600
tensor(0.0418, device='cuda:0') tensor(0.0761, device='cuda:0') tensor(-1.4814e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.058284
Average KL loss: 0.054685
Average total loss: 0.112970
tensor(0.0418, device='cuda:0') tensor(0.0761, device='cuda:0') tensor(-1.5180e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.058715
Average KL loss: 0.054664
Average total loss: 0.113379
tensor(0.0417, device='cuda:0') tensor(0.0762, device='cuda:0') tensor(7.4344e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.057365
Average KL loss: 0.054605
Average total loss: 0.111970
tensor(0.0417, device='cuda:0') tensor(0.0763, device='cuda:0') tensor(2.2868e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.057889
Average KL loss: 0.054535
Average total loss: 0.112423
tensor(0.0416, device='cuda:0') tensor(0.0764, device='cuda:0') tensor(-1.6809e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.057611
Average KL loss: 0.054520
Average total loss: 0.112131
tensor(0.0416, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-1.2086e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.057901
Average KL loss: 0.054450
Average total loss: 0.112351
tensor(0.0416, device='cuda:0') tensor(0.0766, device='cuda:0') tensor(4.9468e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.057480
Average KL loss: 0.054488
Average total loss: 0.111968
tensor(0.0416, device='cuda:0') tensor(0.0768, device='cuda:0') tensor(4.6519e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.058551
Average KL loss: 0.054510
Average total loss: 0.113061
tensor(0.0415, device='cuda:0') tensor(0.0769, device='cuda:0') tensor(5.5736e-12, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.058047
Average KL loss: 0.054525
Average total loss: 0.112573
tensor(0.0415, device='cuda:0') tensor(0.0771, device='cuda:0') tensor(-1.4554e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.057798
Average KL loss: 0.054518
Average total loss: 0.112316
tensor(0.0415, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-3.2391e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.057906
Average KL loss: 0.054515
Average total loss: 0.112421
tensor(0.0415, device='cuda:0') tensor(0.0773, device='cuda:0') tensor(-8.7294e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.056913
Average KL loss: 0.054484
Average total loss: 0.111397
tensor(0.0414, device='cuda:0') tensor(0.0774, device='cuda:0') tensor(9.9123e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.057414
Average KL loss: 0.054460
Average total loss: 0.111874
tensor(0.0415, device='cuda:0') tensor(0.0776, device='cuda:0') tensor(4.5167e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.056539
Average KL loss: 0.054459
Average total loss: 0.110998
tensor(0.0414, device='cuda:0') tensor(0.0776, device='cuda:0') tensor(1.7688e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.057520
Average KL loss: 0.054443
Average total loss: 0.111963
tensor(0.0413, device='cuda:0') tensor(0.0778, device='cuda:0') tensor(7.9552e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.056900
Average KL loss: 0.054436
Average total loss: 0.111336
tensor(0.0413, device='cuda:0') tensor(0.0778, device='cuda:0') tensor(-6.3952e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.056818
Average KL loss: 0.054402
Average total loss: 0.111220
tensor(0.0413, device='cuda:0') tensor(0.0780, device='cuda:0') tensor(-1.3865e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.056111
Average KL loss: 0.054330
Average total loss: 0.110441
tensor(0.0412, device='cuda:0') tensor(0.0780, device='cuda:0') tensor(-1.2588e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.055928
Average KL loss: 0.054269
Average total loss: 0.110197
tensor(0.0412, device='cuda:0') tensor(0.0781, device='cuda:0') tensor(6.4506e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.057312
Average KL loss: 0.054250
Average total loss: 0.111562
tensor(0.0412, device='cuda:0') tensor(0.0783, device='cuda:0') tensor(-2.4675e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.056762
Average KL loss: 0.054298
Average total loss: 0.111061
tensor(0.0412, device='cuda:0') tensor(0.0784, device='cuda:0') tensor(-4.9830e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.057142
Average KL loss: 0.054315
Average total loss: 0.111457
tensor(0.0412, device='cuda:0') tensor(0.0785, device='cuda:0') tensor(-7.6414e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.056976
Average KL loss: 0.054322
Average total loss: 0.111298
tensor(0.0411, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(-1.5516e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.056329
Average KL loss: 0.054346
Average total loss: 0.110675
tensor(0.0411, device='cuda:0') tensor(0.0788, device='cuda:0') tensor(-4.5610e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.056099
Average KL loss: 0.054290
Average total loss: 0.110390
tensor(0.0411, device='cuda:0') tensor(0.0789, device='cuda:0') tensor(-1.4153e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.056064
Average KL loss: 0.054268
Average total loss: 0.110332
tensor(0.0411, device='cuda:0') tensor(0.0790, device='cuda:0') tensor(-1.6853e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.055506
Average KL loss: 0.054242
Average total loss: 0.109748
tensor(0.0411, device='cuda:0') tensor(0.0791, device='cuda:0') tensor(3.8574e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.055062
Average KL loss: 0.054174
Average total loss: 0.109236
tensor(0.0410, device='cuda:0') tensor(0.0791, device='cuda:0') tensor(-8.6149e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.056146
Average KL loss: 0.054129
Average total loss: 0.110275
tensor(0.0410, device='cuda:0') tensor(0.0792, device='cuda:0') tensor(-5.0498e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.055119
Average KL loss: 0.054109
Average total loss: 0.109228
tensor(0.0409, device='cuda:0') tensor(0.0793, device='cuda:0') tensor(1.5073e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.055374
Average KL loss: 0.054060
Average total loss: 0.109434
tensor(0.0409, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(6.6490e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.058329
Average KL loss: 0.054078
Average total loss: 0.112407
tensor(0.0409, device='cuda:0') tensor(0.0796, device='cuda:0') tensor(4.3118e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.055727
Average KL loss: 0.054206
Average total loss: 0.109933
tensor(0.0410, device='cuda:0') tensor(0.0798, device='cuda:0') tensor(-1.2083e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.055369
Average KL loss: 0.054221
Average total loss: 0.109590
tensor(0.0409, device='cuda:0') tensor(0.0799, device='cuda:0') tensor(-3.7437e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.055194
Average KL loss: 0.054161
Average total loss: 0.109355
tensor(0.0409, device='cuda:0') tensor(0.0800, device='cuda:0') tensor(-1.0485e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.054072
Average KL loss: 0.054099
Average total loss: 0.108170
tensor(0.0408, device='cuda:0') tensor(0.0800, device='cuda:0') tensor(3.1477e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.054882
Average KL loss: 0.054005
Average total loss: 0.108887
tensor(0.0408, device='cuda:0') tensor(0.0801, device='cuda:0') tensor(-5.9159e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.054714
Average KL loss: 0.054038
Average total loss: 0.108752
tensor(0.0408, device='cuda:0') tensor(0.0802, device='cuda:0') tensor(-3.3615e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.055361
Average KL loss: 0.054031
Average total loss: 0.109391
tensor(0.0408, device='cuda:0') tensor(0.0804, device='cuda:0') tensor(-3.1564e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.054636
Average KL loss: 0.054047
Average total loss: 0.108683
tensor(0.0407, device='cuda:0') tensor(0.0805, device='cuda:0') tensor(-1.0191e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.054531
Average KL loss: 0.054012
Average total loss: 0.108544
tensor(0.0407, device='cuda:0') tensor(0.0806, device='cuda:0') tensor(8.9096e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.055079
Average KL loss: 0.053956
Average total loss: 0.109035
tensor(0.0407, device='cuda:0') tensor(0.0807, device='cuda:0') tensor(4.7638e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.054868
Average KL loss: 0.053937
Average total loss: 0.108805
tensor(0.0406, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(-2.3715e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.055172
Average KL loss: 0.053923
Average total loss: 0.109095
tensor(0.0407, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-5.0802e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.054097
Average KL loss: 0.053957
Average total loss: 0.108054
tensor(0.0407, device='cuda:0') tensor(0.0811, device='cuda:0') tensor(-1.7442e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.053963
Average KL loss: 0.053941
Average total loss: 0.107904
tensor(0.0406, device='cuda:0') tensor(0.0811, device='cuda:0') tensor(-6.7143e-11, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.054049
Average KL loss: 0.053869
Average total loss: 0.107919
tensor(0.0406, device='cuda:0') tensor(0.0812, device='cuda:0') tensor(4.0635e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.053852
Average KL loss: 0.053813
Average total loss: 0.107665
tensor(0.0406, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(4.8235e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.053846
Average KL loss: 0.053786
Average total loss: 0.107632
tensor(0.0405, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(-2.0172e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.054096
Average KL loss: 0.053773
Average total loss: 0.107869
tensor(0.0405, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(-1.7520e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.053388
Average KL loss: 0.053754
Average total loss: 0.107142
tensor(0.0405, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(-4.6828e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.053927
Average KL loss: 0.053676
Average total loss: 0.107603
tensor(0.0405, device='cuda:0') tensor(0.0816, device='cuda:0') tensor(-1.6364e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.053142
Average KL loss: 0.053666
Average total loss: 0.106808
tensor(0.0404, device='cuda:0') tensor(0.0817, device='cuda:0') tensor(3.9657e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.053440
Average KL loss: 0.053604
Average total loss: 0.107044
tensor(0.0404, device='cuda:0') tensor(0.0818, device='cuda:0') tensor(-8.0014e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.053803
Average KL loss: 0.053607
Average total loss: 0.107411
tensor(0.0404, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(-3.6761e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.053572
Average KL loss: 0.053623
Average total loss: 0.107195
tensor(0.0404, device='cuda:0') tensor(0.0820, device='cuda:0') tensor(1.2757e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.052893
Average KL loss: 0.053611
Average total loss: 0.106504
tensor(0.0404, device='cuda:0') tensor(0.0821, device='cuda:0') tensor(-1.6891e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.053114
Average KL loss: 0.053560
Average total loss: 0.106674
tensor(0.0403, device='cuda:0') tensor(0.0822, device='cuda:0') tensor(-5.9182e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.053899
Average KL loss: 0.053584
Average total loss: 0.107484
tensor(0.0404, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-4.0697e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.053074
Average KL loss: 0.053577
Average total loss: 0.106651
tensor(0.0403, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-1.2026e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.053321
Average KL loss: 0.053560
Average total loss: 0.106882
tensor(0.0403, device='cuda:0') tensor(0.0825, device='cuda:0') tensor(-7.1419e-11, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.053616
Average KL loss: 0.053514
Average total loss: 0.107130
tensor(0.0403, device='cuda:0') tensor(0.0827, device='cuda:0') tensor(-7.3898e-11, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.052732
Average KL loss: 0.053549
Average total loss: 0.106280
tensor(0.0403, device='cuda:0') tensor(0.0828, device='cuda:0') tensor(3.5650e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.053170
Average KL loss: 0.053521
Average total loss: 0.106690
tensor(0.0403, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(-3.6083e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.052237
Average KL loss: 0.053514
Average total loss: 0.105751
tensor(0.0402, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(-2.7236e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.052993
Average KL loss: 0.053477
Average total loss: 0.106470
tensor(0.0402, device='cuda:0') tensor(0.0830, device='cuda:0') tensor(-5.7794e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.052415
Average KL loss: 0.053423
Average total loss: 0.105838
tensor(0.0402, device='cuda:0') tensor(0.0831, device='cuda:0') tensor(-8.8571e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.052693
Average KL loss: 0.053369
Average total loss: 0.106062
tensor(0.0401, device='cuda:0') tensor(0.0832, device='cuda:0') tensor(8.9688e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.052940
Average KL loss: 0.053393
Average total loss: 0.106333
 Percentile value: 0.03625601530075073
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =     298 /    1728             ( 17.25%) | total_pruned =    1430 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
bn1.bias             | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2166 /   36864             (  5.88%) | total_pruned =   34698 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5497 /   36864             ( 14.91%) | total_pruned =   31367 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3567 /   36864             (  9.68%) | total_pruned =   33297 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4595 /   36864             ( 12.46%) | total_pruned =   32269 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   18735 /   73728             ( 25.41%) | total_pruned =   54993 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   41073 /  147456             ( 27.85%) | total_pruned =  106383 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2664 /    8192             ( 32.52%) | total_pruned =    5528 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   32739 /  147456             ( 22.20%) | total_pruned =  114717 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   34390 /  147456             ( 23.32%) | total_pruned =  113066 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   86715 /  294912             ( 29.40%) | total_pruned =  208197 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  138890 /  589824             ( 23.55%) | total_pruned =  450934 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     200 /     256             ( 78.12%) | total_pruned =      56 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     109 /     256             ( 42.58%) | total_pruned =     147 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    9596 /   32768             ( 29.28%) | total_pruned =   23172 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     101 /     256             ( 39.45%) | total_pruned =     155 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  129346 /  589824             ( 21.93%) | total_pruned =  460478 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  127754 /  589824             ( 21.66%) | total_pruned =  462070 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      92 /     256             ( 35.94%) | total_pruned =     164 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  264192 / 1179648             ( 22.40%) | total_pruned =  915456 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     433 /     512             ( 84.57%) | total_pruned =      79 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     121 /     512             ( 23.63%) | total_pruned =     391 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  534332 / 2359296             ( 22.65%) | total_pruned = 1824964 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     257 /     512             ( 50.20%) | total_pruned =     255 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   24644 /  131072             ( 18.80%) | total_pruned =  106428 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     412 /     512             ( 80.47%) | total_pruned =     100 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     267 /     512             ( 52.15%) | total_pruned =     245 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  487382 / 2359296             ( 20.66%) | total_pruned = 1871914 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     475 /     512             ( 92.77%) | total_pruned =      37 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  835176 / 2359296             ( 35.40%) | total_pruned = 1524120 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
linear.weight        | nonzeros =    4978 /    5120             ( 97.23%) | total_pruned =     142 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 64/100 Loss: 0.024049 Accuracy: 88.50 100.00 % Best test Accuracy: 88.50%
tensor(0.0401, device='cuda:0') tensor(0.0834, device='cuda:0') tensor(-9.1735e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.385183
Average KL loss: 0.048065
Average total loss: 0.433248
tensor(0.0412, device='cuda:0') tensor(0.0724, device='cuda:0') tensor(-4.7240e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.287034
Average KL loss: 0.044516
Average total loss: 0.331550
tensor(0.0403, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-3.2503e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.246344
Average KL loss: 0.043264
Average total loss: 0.289608
tensor(0.0396, device='cuda:0') tensor(0.0658, device='cuda:0') tensor(-3.0597e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.222865
Average KL loss: 0.042616
Average total loss: 0.265481
tensor(0.0390, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-2.7601e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.210423
Average KL loss: 0.042301
Average total loss: 0.252723
tensor(0.0386, device='cuda:0') tensor(0.0630, device='cuda:0') tensor(-2.2647e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.193806
Average KL loss: 0.042223
Average total loss: 0.236028
tensor(0.0384, device='cuda:0') tensor(0.0623, device='cuda:0') tensor(-1.8398e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.180391
Average KL loss: 0.042289
Average total loss: 0.222680
tensor(0.0382, device='cuda:0') tensor(0.0619, device='cuda:0') tensor(-2.1205e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.178747
Average KL loss: 0.042477
Average total loss: 0.221224
tensor(0.0381, device='cuda:0') tensor(0.0616, device='cuda:0') tensor(-2.0192e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.170361
Average KL loss: 0.042715
Average total loss: 0.213075
tensor(0.0379, device='cuda:0') tensor(0.0614, device='cuda:0') tensor(-1.7064e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.160929
Average KL loss: 0.042928
Average total loss: 0.203856
tensor(0.0379, device='cuda:0') tensor(0.0613, device='cuda:0') tensor(-1.8374e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.155948
Average KL loss: 0.043137
Average total loss: 0.199086
tensor(0.0378, device='cuda:0') tensor(0.0613, device='cuda:0') tensor(-1.8573e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.149067
Average KL loss: 0.043353
Average total loss: 0.192420
tensor(0.0379, device='cuda:0') tensor(0.0613, device='cuda:0') tensor(-1.0314e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.146661
Average KL loss: 0.043587
Average total loss: 0.190249
tensor(0.0378, device='cuda:0') tensor(0.0614, device='cuda:0') tensor(-1.4789e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.139207
Average KL loss: 0.043824
Average total loss: 0.183031
tensor(0.0378, device='cuda:0') tensor(0.0615, device='cuda:0') tensor(-1.3055e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.135725
Average KL loss: 0.044027
Average total loss: 0.179752
tensor(0.0378, device='cuda:0') tensor(0.0617, device='cuda:0') tensor(-1.3223e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.127854
Average KL loss: 0.044237
Average total loss: 0.172091
tensor(0.0378, device='cuda:0') tensor(0.0618, device='cuda:0') tensor(-1.2334e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.125333
Average KL loss: 0.044428
Average total loss: 0.169761
tensor(0.0378, device='cuda:0') tensor(0.0619, device='cuda:0') tensor(-1.2360e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.125025
Average KL loss: 0.044605
Average total loss: 0.169630
tensor(0.0378, device='cuda:0') tensor(0.0621, device='cuda:0') tensor(-7.6684e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.120238
Average KL loss: 0.044780
Average total loss: 0.165017
tensor(0.0378, device='cuda:0') tensor(0.0622, device='cuda:0') tensor(-9.8640e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.117956
Average KL loss: 0.044946
Average total loss: 0.162902
tensor(0.0378, device='cuda:0') tensor(0.0624, device='cuda:0') tensor(-1.1614e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.116693
Average KL loss: 0.045127
Average total loss: 0.161821
tensor(0.0377, device='cuda:0') tensor(0.0625, device='cuda:0') tensor(-6.7141e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.110143
Average KL loss: 0.045283
Average total loss: 0.155426
tensor(0.0377, device='cuda:0') tensor(0.0627, device='cuda:0') tensor(-8.7741e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.110096
Average KL loss: 0.045433
Average total loss: 0.155529
tensor(0.0377, device='cuda:0') tensor(0.0629, device='cuda:0') tensor(-5.1740e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.106388
Average KL loss: 0.045569
Average total loss: 0.151957
tensor(0.0377, device='cuda:0') tensor(0.0630, device='cuda:0') tensor(-6.9413e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.104411
Average KL loss: 0.045697
Average total loss: 0.150108
tensor(0.0376, device='cuda:0') tensor(0.0631, device='cuda:0') tensor(-6.9637e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.102776
Average KL loss: 0.045803
Average total loss: 0.148578
tensor(0.0376, device='cuda:0') tensor(0.0633, device='cuda:0') tensor(-6.1266e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.100386
Average KL loss: 0.045934
Average total loss: 0.146320
tensor(0.0376, device='cuda:0') tensor(0.0634, device='cuda:0') tensor(-6.3428e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.098739
Average KL loss: 0.046066
Average total loss: 0.144805
tensor(0.0376, device='cuda:0') tensor(0.0636, device='cuda:0') tensor(-6.0757e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.096592
Average KL loss: 0.046164
Average total loss: 0.142756
tensor(0.0376, device='cuda:0') tensor(0.0637, device='cuda:0') tensor(-5.5947e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.096576
Average KL loss: 0.046288
Average total loss: 0.142863
tensor(0.0375, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-7.0602e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.093309
Average KL loss: 0.046390
Average total loss: 0.139699
tensor(0.0375, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-7.9986e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.090200
Average KL loss: 0.046480
Average total loss: 0.136680
tensor(0.0375, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-3.5255e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.089473
Average KL loss: 0.046553
Average total loss: 0.136025
tensor(0.0374, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-8.8229e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.088897
Average KL loss: 0.046628
Average total loss: 0.135525
tensor(0.0374, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-5.7917e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.086962
Average KL loss: 0.046719
Average total loss: 0.133682
tensor(0.0374, device='cuda:0') tensor(0.0645, device='cuda:0') tensor(-7.6463e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.087145
Average KL loss: 0.046804
Average total loss: 0.133949
tensor(0.0373, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-5.2954e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.084377
Average KL loss: 0.046914
Average total loss: 0.131291
tensor(0.0373, device='cuda:0') tensor(0.0649, device='cuda:0') tensor(-5.8400e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.082812
Average KL loss: 0.046968
Average total loss: 0.129780
tensor(0.0372, device='cuda:0') tensor(0.0650, device='cuda:0') tensor(-5.8453e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.081554
Average KL loss: 0.047037
Average total loss: 0.128591
tensor(0.0372, device='cuda:0') tensor(0.0651, device='cuda:0') tensor(-7.3473e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.082315
Average KL loss: 0.047130
Average total loss: 0.129445
tensor(0.0372, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-7.9097e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.082184
Average KL loss: 0.047181
Average total loss: 0.129365
tensor(0.0372, device='cuda:0') tensor(0.0653, device='cuda:0') tensor(-5.6684e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.078680
Average KL loss: 0.047250
Average total loss: 0.125930
tensor(0.0371, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-4.4018e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.077753
Average KL loss: 0.047302
Average total loss: 0.125055
tensor(0.0371, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-3.2404e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.077155
Average KL loss: 0.047348
Average total loss: 0.124503
tensor(0.0370, device='cuda:0') tensor(0.0657, device='cuda:0') tensor(-3.5959e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.076812
Average KL loss: 0.047387
Average total loss: 0.124199
tensor(0.0370, device='cuda:0') tensor(0.0658, device='cuda:0') tensor(-3.9597e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.075206
Average KL loss: 0.047452
Average total loss: 0.122658
tensor(0.0370, device='cuda:0') tensor(0.0659, device='cuda:0') tensor(-3.0543e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.074589
Average KL loss: 0.047500
Average total loss: 0.122089
tensor(0.0369, device='cuda:0') tensor(0.0660, device='cuda:0') tensor(-4.6215e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.074194
Average KL loss: 0.047536
Average total loss: 0.121731
tensor(0.0369, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-2.5767e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.071279
Average KL loss: 0.047590
Average total loss: 0.118869
tensor(0.0368, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-3.8694e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.072423
Average KL loss: 0.047643
Average total loss: 0.120066
tensor(0.0368, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-2.5670e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.072699
Average KL loss: 0.047716
Average total loss: 0.120416
tensor(0.0368, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-2.7996e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.070842
Average KL loss: 0.047756
Average total loss: 0.118599
tensor(0.0367, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-3.4861e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.068650
Average KL loss: 0.047784
Average total loss: 0.116434
tensor(0.0367, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-2.9346e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.068436
Average KL loss: 0.047805
Average total loss: 0.116241
tensor(0.0367, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-2.7711e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.068119
Average KL loss: 0.047850
Average total loss: 0.115969
tensor(0.0366, device='cuda:0') tensor(0.0670, device='cuda:0') tensor(-3.5334e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.066806
Average KL loss: 0.047898
Average total loss: 0.114704
tensor(0.0366, device='cuda:0') tensor(0.0671, device='cuda:0') tensor(-2.8495e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.067106
Average KL loss: 0.047911
Average total loss: 0.115017
tensor(0.0365, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(-2.8790e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.066269
Average KL loss: 0.047920
Average total loss: 0.114189
tensor(0.0365, device='cuda:0') tensor(0.0673, device='cuda:0') tensor(-3.1579e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.065069
Average KL loss: 0.047952
Average total loss: 0.113021
tensor(0.0364, device='cuda:0') tensor(0.0673, device='cuda:0') tensor(-2.1654e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.063217
Average KL loss: 0.047939
Average total loss: 0.111156
tensor(0.0364, device='cuda:0') tensor(0.0674, device='cuda:0') tensor(-2.7405e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.062791
Average KL loss: 0.047927
Average total loss: 0.110717
tensor(0.0363, device='cuda:0') tensor(0.0675, device='cuda:0') tensor(-2.5960e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.063311
Average KL loss: 0.047918
Average total loss: 0.111229
tensor(0.0363, device='cuda:0') tensor(0.0675, device='cuda:0') tensor(-2.5704e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.062511
Average KL loss: 0.047926
Average total loss: 0.110437
tensor(0.0362, device='cuda:0') tensor(0.0676, device='cuda:0') tensor(-1.0388e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.062432
Average KL loss: 0.047935
Average total loss: 0.110367
tensor(0.0362, device='cuda:0') tensor(0.0677, device='cuda:0') tensor(-2.1809e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.062237
Average KL loss: 0.047945
Average total loss: 0.110182
tensor(0.0361, device='cuda:0') tensor(0.0678, device='cuda:0') tensor(-1.5170e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.060889
Average KL loss: 0.047959
Average total loss: 0.108848
tensor(0.0361, device='cuda:0') tensor(0.0679, device='cuda:0') tensor(-1.6728e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.061795
Average KL loss: 0.047975
Average total loss: 0.109769
tensor(0.0361, device='cuda:0') tensor(0.0680, device='cuda:0') tensor(-2.4777e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.058567
Average KL loss: 0.047990
Average total loss: 0.106557
tensor(0.0360, device='cuda:0') tensor(0.0681, device='cuda:0') tensor(-2.2283e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.057790
Average KL loss: 0.047914
Average total loss: 0.105704
tensor(0.0359, device='cuda:0') tensor(0.0681, device='cuda:0') tensor(-1.1882e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.060132
Average KL loss: 0.047872
Average total loss: 0.108004
tensor(0.0359, device='cuda:0') tensor(0.0682, device='cuda:0') tensor(-8.6086e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.058686
Average KL loss: 0.047907
Average total loss: 0.106592
tensor(0.0358, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-1.2590e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.058849
Average KL loss: 0.047917
Average total loss: 0.106766
tensor(0.0358, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-1.4237e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.056526
Average KL loss: 0.047948
Average total loss: 0.104474
tensor(0.0358, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-1.3261e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.056758
Average KL loss: 0.047912
Average total loss: 0.104670
tensor(0.0357, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-5.9632e-11, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.057918
Average KL loss: 0.047909
Average total loss: 0.105827
tensor(0.0356, device='cuda:0') tensor(0.0686, device='cuda:0') tensor(-1.9187e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.057096
Average KL loss: 0.047916
Average total loss: 0.105011
tensor(0.0356, device='cuda:0') tensor(0.0687, device='cuda:0') tensor(-2.3543e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.057251
Average KL loss: 0.047911
Average total loss: 0.105162
tensor(0.0356, device='cuda:0') tensor(0.0688, device='cuda:0') tensor(-1.4791e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.056118
Average KL loss: 0.047916
Average total loss: 0.104033
tensor(0.0355, device='cuda:0') tensor(0.0689, device='cuda:0') tensor(-1.2019e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.054312
Average KL loss: 0.047896
Average total loss: 0.102208
tensor(0.0355, device='cuda:0') tensor(0.0689, device='cuda:0') tensor(-1.6690e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.054564
Average KL loss: 0.047857
Average total loss: 0.102421
tensor(0.0354, device='cuda:0') tensor(0.0690, device='cuda:0') tensor(-1.3086e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.054127
Average KL loss: 0.047849
Average total loss: 0.101976
tensor(0.0354, device='cuda:0') tensor(0.0691, device='cuda:0') tensor(-2.5478e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.055177
Average KL loss: 0.047846
Average total loss: 0.103023
tensor(0.0354, device='cuda:0') tensor(0.0692, device='cuda:0') tensor(-1.6443e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.054409
Average KL loss: 0.047844
Average total loss: 0.102253
tensor(0.0353, device='cuda:0') tensor(0.0692, device='cuda:0') tensor(-1.0551e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.055354
Average KL loss: 0.047821
Average total loss: 0.103175
tensor(0.0352, device='cuda:0') tensor(0.0693, device='cuda:0') tensor(-1.1371e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.054271
Average KL loss: 0.047835
Average total loss: 0.102107
tensor(0.0352, device='cuda:0') tensor(0.0694, device='cuda:0') tensor(-6.1198e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.053287
Average KL loss: 0.047818
Average total loss: 0.101105
tensor(0.0352, device='cuda:0') tensor(0.0695, device='cuda:0') tensor(-2.2027e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.052502
Average KL loss: 0.047812
Average total loss: 0.100315
tensor(0.0351, device='cuda:0') tensor(0.0696, device='cuda:0') tensor(1.7840e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.053625
Average KL loss: 0.047778
Average total loss: 0.101403
tensor(0.0351, device='cuda:0') tensor(0.0696, device='cuda:0') tensor(-2.1800e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.051700
Average KL loss: 0.047795
Average total loss: 0.099496
tensor(0.0350, device='cuda:0') tensor(0.0697, device='cuda:0') tensor(-1.5221e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.052427
Average KL loss: 0.047768
Average total loss: 0.100195
tensor(0.0350, device='cuda:0') tensor(0.0698, device='cuda:0') tensor(-1.3822e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.052107
Average KL loss: 0.047792
Average total loss: 0.099898
tensor(0.0349, device='cuda:0') tensor(0.0699, device='cuda:0') tensor(-1.2524e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.051262
Average KL loss: 0.047741
Average total loss: 0.099003
tensor(0.0349, device='cuda:0') tensor(0.0700, device='cuda:0') tensor(-1.8200e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.050900
Average KL loss: 0.047731
Average total loss: 0.098631
tensor(0.0348, device='cuda:0') tensor(0.0700, device='cuda:0') tensor(-1.6873e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.050169
Average KL loss: 0.047711
Average total loss: 0.097881
tensor(0.0348, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-1.3950e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.050479
Average KL loss: 0.047675
Average total loss: 0.098155
tensor(0.0347, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-2.1147e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.049952
Average KL loss: 0.047649
Average total loss: 0.097601
tensor(0.0347, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-1.4430e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.051155
Average KL loss: 0.047646
Average total loss: 0.098801
tensor(0.0346, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-7.8320e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.050149
Average KL loss: 0.047646
Average total loss: 0.097795
tensor(0.0346, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-1.0651e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.050373
Average KL loss: 0.047650
Average total loss: 0.098023
tensor(0.0346, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-1.2408e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.048998
Average KL loss: 0.047641
Average total loss: 0.096640
tensor(0.0345, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-1.4149e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.049516
Average KL loss: 0.047605
Average total loss: 0.097122
tensor(0.0345, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(-5.9075e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.049546
Average KL loss: 0.047617
Average total loss: 0.097164
tensor(0.0345, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-3.9823e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.048798
Average KL loss: 0.047600
Average total loss: 0.096398
tensor(0.0344, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(2.5690e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.048266
Average KL loss: 0.047560
Average total loss: 0.095826
tensor(0.0344, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-1.5277e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.049836
Average KL loss: 0.047553
Average total loss: 0.097389
tensor(0.0344, device='cuda:0') tensor(0.0710, device='cuda:0') tensor(-4.2848e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.048302
Average KL loss: 0.047567
Average total loss: 0.095870
tensor(0.0343, device='cuda:0') tensor(0.0710, device='cuda:0') tensor(-9.7299e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.047878
Average KL loss: 0.047539
Average total loss: 0.095417
tensor(0.0343, device='cuda:0') tensor(0.0711, device='cuda:0') tensor(7.1377e-11, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.048153
Average KL loss: 0.047518
Average total loss: 0.095672
tensor(0.0343, device='cuda:0') tensor(0.0712, device='cuda:0') tensor(-5.0980e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.047865
Average KL loss: 0.047509
Average total loss: 0.095374
tensor(0.0342, device='cuda:0') tensor(0.0713, device='cuda:0') tensor(-9.0210e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.047373
Average KL loss: 0.047478
Average total loss: 0.094851
tensor(0.0341, device='cuda:0') tensor(0.0713, device='cuda:0') tensor(-2.1810e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.047985
Average KL loss: 0.047448
Average total loss: 0.095433
tensor(0.0341, device='cuda:0') tensor(0.0714, device='cuda:0') tensor(-8.0673e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.047482
Average KL loss: 0.047433
Average total loss: 0.094915
tensor(0.0341, device='cuda:0') tensor(0.0715, device='cuda:0') tensor(-4.4213e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.046784
Average KL loss: 0.047397
Average total loss: 0.094182
tensor(0.0340, device='cuda:0') tensor(0.0715, device='cuda:0') tensor(-6.8459e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.048103
Average KL loss: 0.047385
Average total loss: 0.095488
tensor(0.0340, device='cuda:0') tensor(0.0716, device='cuda:0') tensor(-1.3109e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.046465
Average KL loss: 0.047382
Average total loss: 0.093847
tensor(0.0340, device='cuda:0') tensor(0.0717, device='cuda:0') tensor(-4.3862e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.047551
Average KL loss: 0.047353
Average total loss: 0.094904
tensor(0.0339, device='cuda:0') tensor(0.0718, device='cuda:0') tensor(-3.8159e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.046803
Average KL loss: 0.047370
Average total loss: 0.094173
tensor(0.0339, device='cuda:0') tensor(0.0719, device='cuda:0') tensor(-7.6184e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.046506
Average KL loss: 0.047324
Average total loss: 0.093831
tensor(0.0339, device='cuda:0') tensor(0.0719, device='cuda:0') tensor(-1.4887e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.046022
Average KL loss: 0.047315
Average total loss: 0.093337
tensor(0.0338, device='cuda:0') tensor(0.0720, device='cuda:0') tensor(-1.2923e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.045593
Average KL loss: 0.047265
Average total loss: 0.092858
tensor(0.0338, device='cuda:0') tensor(0.0720, device='cuda:0') tensor(-4.9854e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.046709
Average KL loss: 0.047237
Average total loss: 0.093946
tensor(0.0337, device='cuda:0') tensor(0.0721, device='cuda:0') tensor(-3.7400e-11, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.045995
Average KL loss: 0.047232
Average total loss: 0.093227
tensor(0.0337, device='cuda:0') tensor(0.0722, device='cuda:0') tensor(-1.4616e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.045553
Average KL loss: 0.047259
Average total loss: 0.092812
tensor(0.0337, device='cuda:0') tensor(0.0723, device='cuda:0') tensor(-9.8694e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.045922
Average KL loss: 0.047229
Average total loss: 0.093151
tensor(0.0337, device='cuda:0') tensor(0.0723, device='cuda:0') tensor(-6.8088e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.045412
Average KL loss: 0.047190
Average total loss: 0.092602
tensor(0.0336, device='cuda:0') tensor(0.0724, device='cuda:0') tensor(-1.6822e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.046056
Average KL loss: 0.047186
Average total loss: 0.093242
tensor(0.0336, device='cuda:0') tensor(0.0725, device='cuda:0') tensor(-1.3374e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.047382
Average KL loss: 0.047234
Average total loss: 0.094616
tensor(0.0336, device='cuda:0') tensor(0.0727, device='cuda:0') tensor(-1.8130e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.044464
Average KL loss: 0.047264
Average total loss: 0.091728
tensor(0.0336, device='cuda:0') tensor(0.0727, device='cuda:0') tensor(-6.2999e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.044757
Average KL loss: 0.047209
Average total loss: 0.091966
tensor(0.0336, device='cuda:0') tensor(0.0728, device='cuda:0') tensor(-9.0329e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.044320
Average KL loss: 0.047174
Average total loss: 0.091494
tensor(0.0335, device='cuda:0') tensor(0.0728, device='cuda:0') tensor(-8.3846e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.045220
Average KL loss: 0.047135
Average total loss: 0.092355
tensor(0.0335, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(-3.2090e-11, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.044558
Average KL loss: 0.047152
Average total loss: 0.091710
tensor(0.0334, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(-2.3910e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.044551
Average KL loss: 0.047116
Average total loss: 0.091667
tensor(0.0334, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(-1.0614e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.044065
Average KL loss: 0.047116
Average total loss: 0.091181
tensor(0.0334, device='cuda:0') tensor(0.0732, device='cuda:0') tensor(-1.0231e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.043931
Average KL loss: 0.047098
Average total loss: 0.091029
tensor(0.0333, device='cuda:0') tensor(0.0732, device='cuda:0') tensor(-4.9919e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.044636
Average KL loss: 0.047066
Average total loss: 0.091703
tensor(0.0333, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(4.5768e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.044379
Average KL loss: 0.047059
Average total loss: 0.091438
tensor(0.0333, device='cuda:0') tensor(0.0734, device='cuda:0') tensor(-7.0372e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.044446
Average KL loss: 0.047067
Average total loss: 0.091514
tensor(0.0333, device='cuda:0') tensor(0.0735, device='cuda:0') tensor(-1.5954e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.044455
Average KL loss: 0.047094
Average total loss: 0.091548
tensor(0.0332, device='cuda:0') tensor(0.0736, device='cuda:0') tensor(-5.9353e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.043026
Average KL loss: 0.047078
Average total loss: 0.090104
tensor(0.0332, device='cuda:0') tensor(0.0736, device='cuda:0') tensor(1.5006e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.043481
Average KL loss: 0.047016
Average total loss: 0.090497
tensor(0.0332, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(5.1229e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.043293
Average KL loss: 0.047006
Average total loss: 0.090298
tensor(0.0332, device='cuda:0') tensor(0.0738, device='cuda:0') tensor(6.9361e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.043069
Average KL loss: 0.046969
Average total loss: 0.090039
tensor(0.0331, device='cuda:0') tensor(0.0738, device='cuda:0') tensor(-5.0526e-11, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.043198
Average KL loss: 0.046925
Average total loss: 0.090123
tensor(0.0331, device='cuda:0') tensor(0.0739, device='cuda:0') tensor(-8.1655e-11, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.042527
Average KL loss: 0.046874
Average total loss: 0.089401
tensor(0.0330, device='cuda:0') tensor(0.0739, device='cuda:0') tensor(-5.8995e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.042990
Average KL loss: 0.046840
Average total loss: 0.089830
tensor(0.0330, device='cuda:0') tensor(0.0740, device='cuda:0') tensor(-9.8375e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.043780
Average KL loss: 0.046849
Average total loss: 0.090629
tensor(0.0330, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(-6.7592e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.043114
Average KL loss: 0.046844
Average total loss: 0.089958
tensor(0.0330, device='cuda:0') tensor(0.0742, device='cuda:0') tensor(-9.8626e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.042893
Average KL loss: 0.046830
Average total loss: 0.089722
tensor(0.0329, device='cuda:0') tensor(0.0743, device='cuda:0') tensor(-3.4034e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.043209
Average KL loss: 0.046817
Average total loss: 0.090026
tensor(0.0329, device='cuda:0') tensor(0.0744, device='cuda:0') tensor(-6.1435e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.043019
Average KL loss: 0.046847
Average total loss: 0.089866
tensor(0.0329, device='cuda:0') tensor(0.0745, device='cuda:0') tensor(-3.9032e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.043046
Average KL loss: 0.046863
Average total loss: 0.089909
tensor(0.0329, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-1.0704e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.042804
Average KL loss: 0.046843
Average total loss: 0.089647
tensor(0.0329, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(7.8410e-11, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.042241
Average KL loss: 0.046824
Average total loss: 0.089065
tensor(0.0328, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-1.0541e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.042693
Average KL loss: 0.046788
Average total loss: 0.089481
tensor(0.0328, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(2.5721e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.041837
Average KL loss: 0.046780
Average total loss: 0.088617
tensor(0.0328, device='cuda:0') tensor(0.0749, device='cuda:0') tensor(-9.7793e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.042159
Average KL loss: 0.046742
Average total loss: 0.088900
tensor(0.0328, device='cuda:0') tensor(0.0749, device='cuda:0') tensor(-9.9554e-11, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.042571
Average KL loss: 0.046737
Average total loss: 0.089308
tensor(0.0328, device='cuda:0') tensor(0.0750, device='cuda:0') tensor(-7.8504e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.042461
Average KL loss: 0.046754
Average total loss: 0.089215
tensor(0.0327, device='cuda:0') tensor(0.0751, device='cuda:0') tensor(2.8859e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.041617
Average KL loss: 0.046726
Average total loss: 0.088343
tensor(0.0327, device='cuda:0') tensor(0.0752, device='cuda:0') tensor(1.2105e-11, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.041074
Average KL loss: 0.046686
Average total loss: 0.087761
tensor(0.0327, device='cuda:0') tensor(0.0752, device='cuda:0') tensor(5.4645e-11, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.041818
Average KL loss: 0.046642
Average total loss: 0.088459
tensor(0.0326, device='cuda:0') tensor(0.0753, device='cuda:0') tensor(-8.3010e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.040991
Average KL loss: 0.046627
Average total loss: 0.087618
tensor(0.0326, device='cuda:0') tensor(0.0753, device='cuda:0') tensor(-1.4859e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.042188
Average KL loss: 0.046593
Average total loss: 0.088781
tensor(0.0326, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(-1.9413e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.041732
Average KL loss: 0.046598
Average total loss: 0.088330
tensor(0.0326, device='cuda:0') tensor(0.0755, device='cuda:0') tensor(5.5235e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.041387
Average KL loss: 0.046564
Average total loss: 0.087950
tensor(0.0325, device='cuda:0') tensor(0.0755, device='cuda:0') tensor(-6.0471e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.042620
Average KL loss: 0.046566
Average total loss: 0.089186
tensor(0.0326, device='cuda:0') tensor(0.0757, device='cuda:0') tensor(-2.9835e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.041161
Average KL loss: 0.046598
Average total loss: 0.087758
tensor(0.0325, device='cuda:0') tensor(0.0757, device='cuda:0') tensor(-3.1125e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.041646
Average KL loss: 0.046604
Average total loss: 0.088250
tensor(0.0325, device='cuda:0') tensor(0.0758, device='cuda:0') tensor(4.9893e-11, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.040889
Average KL loss: 0.046576
Average total loss: 0.087465
tensor(0.0325, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(1.7099e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.041576
Average KL loss: 0.046565
Average total loss: 0.088142
tensor(0.0325, device='cuda:0') tensor(0.0760, device='cuda:0') tensor(-2.6323e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.042276
Average KL loss: 0.046594
Average total loss: 0.088870
tensor(0.0325, device='cuda:0') tensor(0.0761, device='cuda:0') tensor(-3.7046e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.041261
Average KL loss: 0.046638
Average total loss: 0.087899
tensor(0.0325, device='cuda:0') tensor(0.0762, device='cuda:0') tensor(-1.0084e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.041244
Average KL loss: 0.046624
Average total loss: 0.087867
tensor(0.0325, device='cuda:0') tensor(0.0763, device='cuda:0') tensor(-1.0468e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.040442
Average KL loss: 0.046624
Average total loss: 0.087066
tensor(0.0324, device='cuda:0') tensor(0.0764, device='cuda:0') tensor(-8.8591e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.040614
Average KL loss: 0.046561
Average total loss: 0.087174
tensor(0.0324, device='cuda:0') tensor(0.0764, device='cuda:0') tensor(-1.0834e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.040733
Average KL loss: 0.046528
Average total loss: 0.087261
tensor(0.0324, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-5.9627e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.040560
Average KL loss: 0.046515
Average total loss: 0.087075
tensor(0.0324, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-1.9291e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.041210
Average KL loss: 0.046516
Average total loss: 0.087725
tensor(0.0323, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(-5.5707e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.041031
Average KL loss: 0.046521
Average total loss: 0.087552
tensor(0.0324, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(4.0876e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.041474
Average KL loss: 0.046528
Average total loss: 0.088003
tensor(0.0323, device='cuda:0') tensor(0.0768, device='cuda:0') tensor(-1.0748e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.040422
Average KL loss: 0.046509
Average total loss: 0.086930
tensor(0.0323, device='cuda:0') tensor(0.0769, device='cuda:0') tensor(-5.8831e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.040166
Average KL loss: 0.046474
Average total loss: 0.086640
tensor(0.0323, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(-3.8967e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.040267
Average KL loss: 0.046438
Average total loss: 0.086705
tensor(0.0322, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(-1.5614e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.040859
Average KL loss: 0.046425
Average total loss: 0.087283
tensor(0.0322, device='cuda:0') tensor(0.0771, device='cuda:0') tensor(-1.7766e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.040377
Average KL loss: 0.046440
Average total loss: 0.086817
tensor(0.0322, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-7.4906e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.040094
Average KL loss: 0.046418
Average total loss: 0.086512
tensor(0.0322, device='cuda:0') tensor(0.0773, device='cuda:0') tensor(5.3353e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.040127
Average KL loss: 0.046390
Average total loss: 0.086517
tensor(0.0322, device='cuda:0') tensor(0.0773, device='cuda:0') tensor(2.8701e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.040552
Average KL loss: 0.046370
Average total loss: 0.086922
tensor(0.0322, device='cuda:0') tensor(0.0774, device='cuda:0') tensor(3.8395e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.039895
Average KL loss: 0.046369
Average total loss: 0.086265
tensor(0.0322, device='cuda:0') tensor(0.0775, device='cuda:0') tensor(-2.9342e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.040219
Average KL loss: 0.046373
Average total loss: 0.086592
tensor(0.0321, device='cuda:0') tensor(0.0775, device='cuda:0') tensor(3.4034e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.040060
Average KL loss: 0.046337
Average total loss: 0.086396
tensor(0.0321, device='cuda:0') tensor(0.0776, device='cuda:0') tensor(6.7659e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.040506
Average KL loss: 0.046317
Average total loss: 0.086823
tensor(0.0321, device='cuda:0') tensor(0.0777, device='cuda:0') tensor(6.5107e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.039785
Average KL loss: 0.046325
Average total loss: 0.086110
tensor(0.0321, device='cuda:0') tensor(0.0778, device='cuda:0') tensor(-3.6996e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.040535
Average KL loss: 0.046313
Average total loss: 0.086849
tensor(0.0321, device='cuda:0') tensor(0.0779, device='cuda:0') tensor(-1.1082e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.041058
Average KL loss: 0.046348
Average total loss: 0.087407
tensor(0.0321, device='cuda:0') tensor(0.0780, device='cuda:0') tensor(2.9372e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.040194
Average KL loss: 0.046376
Average total loss: 0.086570
tensor(0.0321, device='cuda:0') tensor(0.0781, device='cuda:0') tensor(-1.7229e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.039786
Average KL loss: 0.046330
Average total loss: 0.086116
tensor(0.0321, device='cuda:0') tensor(0.0781, device='cuda:0') tensor(-4.8627e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.040223
Average KL loss: 0.046347
Average total loss: 0.086570
tensor(0.0321, device='cuda:0') tensor(0.0782, device='cuda:0') tensor(3.9112e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.039757
Average KL loss: 0.046336
Average total loss: 0.086093
 Percentile value: 0.05851597711443901
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =     198 /    1728             ( 11.46%) | total_pruned =    1530 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     881 /   36864             (  2.39%) | total_pruned =   35983 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2594 /   36864             (  7.04%) | total_pruned =   34270 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1359 /   36864             (  3.69%) | total_pruned =   35505 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1877 /   36864             (  5.09%) | total_pruned =   34987 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   10447 /   73728             ( 14.17%) | total_pruned =   63281 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   21377 /  147456             ( 14.50%) | total_pruned =  126079 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1641 /    8192             ( 20.03%) | total_pruned =    6551 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   16473 /  147456             ( 11.17%) | total_pruned =  130983 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   17579 /  147456             ( 11.92%) | total_pruned =  129877 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   49933 /  294912             ( 16.93%) | total_pruned =  244979 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     194 /     256             ( 75.78%) | total_pruned =      62 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      98 /     256             ( 38.28%) | total_pruned =     158 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   67279 /  589824             ( 11.41%) | total_pruned =  522545 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      85 /     256             ( 33.20%) | total_pruned =     171 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5433 /   32768             ( 16.58%) | total_pruned =   27335 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      76 /     256             ( 29.69%) | total_pruned =     180 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   58299 /  589824             (  9.88%) | total_pruned =  531525 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   57793 /  589824             (  9.80%) | total_pruned =  532031 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      76 /     256             ( 29.69%) | total_pruned =     180 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  130563 / 1179648             ( 11.07%) | total_pruned = 1049085 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     399 /     512             ( 77.93%) | total_pruned =     113 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  276707 / 2359296             ( 11.73%) | total_pruned = 2082589 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     463 /     512             ( 90.43%) | total_pruned =      49 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     223 /     512             ( 43.55%) | total_pruned =     289 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9871 /  131072             (  7.53%) | total_pruned =  121201 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     320 /     512             ( 62.50%) | total_pruned =     192 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     229 /     512             ( 44.73%) | total_pruned =     283 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  211317 / 2359296             (  8.96%) | total_pruned = 2147979 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     347 /     512             ( 67.77%) | total_pruned =     165 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  445958 / 2359296             ( 18.90%) | total_pruned = 1913338 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     473 /     512             ( 92.38%) | total_pruned =      39 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     467 /     512             ( 91.21%) | total_pruned =      45 | shape = torch.Size([512])
linear.weight        | nonzeros =    4697 /    5120             ( 91.74%) | total_pruned =     423 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 48/100 Loss: 0.022305 Accuracy: 85.59 100.00 % Best test Accuracy: 85.83%
tensor(0.0320, device='cuda:0') tensor(0.0783, device='cuda:0') tensor(-7.4624e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.535945
Average KL loss: 0.042160
Average total loss: 0.578105
tensor(0.0324, device='cuda:0') tensor(0.0690, device='cuda:0') tensor(-4.8923e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.434770
Average KL loss: 0.038774
Average total loss: 0.473544
tensor(0.0316, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-4.7682e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.386087
Average KL loss: 0.037399
Average total loss: 0.423486
tensor(0.0309, device='cuda:0') tensor(0.0629, device='cuda:0') tensor(-3.7251e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.361931
Average KL loss: 0.036683
Average total loss: 0.398614
tensor(0.0304, device='cuda:0') tensor(0.0614, device='cuda:0') tensor(-2.4609e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.338185
Average KL loss: 0.036339
Average total loss: 0.374524
tensor(0.0301, device='cuda:0') tensor(0.0604, device='cuda:0') tensor(-3.5561e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.317151
Average KL loss: 0.036254
Average total loss: 0.353405
tensor(0.0299, device='cuda:0') tensor(0.0598, device='cuda:0') tensor(-2.9744e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.303888
Average KL loss: 0.036314
Average total loss: 0.340202
tensor(0.0298, device='cuda:0') tensor(0.0594, device='cuda:0') tensor(-2.8439e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.290210
Average KL loss: 0.036490
Average total loss: 0.326700
tensor(0.0298, device='cuda:0') tensor(0.0592, device='cuda:0') tensor(-2.8424e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.279195
Average KL loss: 0.036737
Average total loss: 0.315932
tensor(0.0298, device='cuda:0') tensor(0.0591, device='cuda:0') tensor(-2.1499e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.268930
Average KL loss: 0.036966
Average total loss: 0.305897
tensor(0.0298, device='cuda:0') tensor(0.0590, device='cuda:0') tensor(-2.9323e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.263373
Average KL loss: 0.037215
Average total loss: 0.300588
tensor(0.0299, device='cuda:0') tensor(0.0590, device='cuda:0') tensor(-2.7394e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.249724
Average KL loss: 0.037476
Average total loss: 0.287200
tensor(0.0299, device='cuda:0') tensor(0.0591, device='cuda:0') tensor(-2.3492e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.248343
Average KL loss: 0.037726
Average total loss: 0.286068
tensor(0.0300, device='cuda:0') tensor(0.0591, device='cuda:0') tensor(-2.2426e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.240295
Average KL loss: 0.037986
Average total loss: 0.278280
tensor(0.0301, device='cuda:0') tensor(0.0593, device='cuda:0') tensor(-2.5482e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.231670
Average KL loss: 0.038252
Average total loss: 0.269921
tensor(0.0302, device='cuda:0') tensor(0.0594, device='cuda:0') tensor(-1.9109e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.229373
Average KL loss: 0.038504
Average total loss: 0.267877
tensor(0.0302, device='cuda:0') tensor(0.0596, device='cuda:0') tensor(-2.1750e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.218749
Average KL loss: 0.038765
Average total loss: 0.257514
tensor(0.0303, device='cuda:0') tensor(0.0597, device='cuda:0') tensor(-1.8213e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.215206
Average KL loss: 0.039020
Average total loss: 0.254226
tensor(0.0304, device='cuda:0') tensor(0.0600, device='cuda:0') tensor(-2.1188e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.209426
Average KL loss: 0.039279
Average total loss: 0.248705
tensor(0.0305, device='cuda:0') tensor(0.0602, device='cuda:0') tensor(-1.5977e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.203775
Average KL loss: 0.039535
Average total loss: 0.243310
tensor(0.0306, device='cuda:0') tensor(0.0604, device='cuda:0') tensor(-1.6353e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.200171
Average KL loss: 0.039757
Average total loss: 0.239927
tensor(0.0306, device='cuda:0') tensor(0.0606, device='cuda:0') tensor(-1.5776e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.197930
Average KL loss: 0.039997
Average total loss: 0.237927
tensor(0.0307, device='cuda:0') tensor(0.0608, device='cuda:0') tensor(-1.2418e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.187913
Average KL loss: 0.040242
Average total loss: 0.228155
tensor(0.0308, device='cuda:0') tensor(0.0611, device='cuda:0') tensor(-1.5728e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.185571
Average KL loss: 0.040479
Average total loss: 0.226050
tensor(0.0309, device='cuda:0') tensor(0.0613, device='cuda:0') tensor(-1.3384e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.180392
Average KL loss: 0.040726
Average total loss: 0.221118
tensor(0.0310, device='cuda:0') tensor(0.0616, device='cuda:0') tensor(-1.2592e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.175996
Average KL loss: 0.040964
Average total loss: 0.216961
tensor(0.0311, device='cuda:0') tensor(0.0618, device='cuda:0') tensor(-1.6542e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.174522
Average KL loss: 0.041195
Average total loss: 0.215717
tensor(0.0312, device='cuda:0') tensor(0.0621, device='cuda:0') tensor(-1.6441e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.171087
Average KL loss: 0.041421
Average total loss: 0.212507
tensor(0.0312, device='cuda:0') tensor(0.0623, device='cuda:0') tensor(-1.1701e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.169175
Average KL loss: 0.041654
Average total loss: 0.210829
tensor(0.0313, device='cuda:0') tensor(0.0626, device='cuda:0') tensor(-1.3973e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.165337
Average KL loss: 0.041887
Average total loss: 0.207224
tensor(0.0314, device='cuda:0') tensor(0.0629, device='cuda:0') tensor(-1.3110e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.161275
Average KL loss: 0.042099
Average total loss: 0.203374
tensor(0.0315, device='cuda:0') tensor(0.0631, device='cuda:0') tensor(-1.4512e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.158127
Average KL loss: 0.042306
Average total loss: 0.200433
tensor(0.0316, device='cuda:0') tensor(0.0634, device='cuda:0') tensor(-1.2250e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.155105
Average KL loss: 0.042530
Average total loss: 0.197635
tensor(0.0316, device='cuda:0') tensor(0.0637, device='cuda:0') tensor(-1.6558e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.154550
Average KL loss: 0.042735
Average total loss: 0.197285
tensor(0.0317, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-1.2713e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.151774
Average KL loss: 0.042936
Average total loss: 0.194709
tensor(0.0318, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-1.1290e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.151250
Average KL loss: 0.043140
Average total loss: 0.194389
tensor(0.0318, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-8.2437e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.145619
Average KL loss: 0.043339
Average total loss: 0.188958
tensor(0.0319, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-9.7617e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.141512
Average KL loss: 0.043523
Average total loss: 0.185035
tensor(0.0319, device='cuda:0') tensor(0.0649, device='cuda:0') tensor(-1.0706e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.139005
Average KL loss: 0.043718
Average total loss: 0.182723
tensor(0.0320, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-9.9926e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.137427
Average KL loss: 0.043901
Average total loss: 0.181328
tensor(0.0321, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-1.0749e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.136956
Average KL loss: 0.044080
Average total loss: 0.181036
tensor(0.0321, device='cuda:0') tensor(0.0657, device='cuda:0') tensor(-7.5000e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.133848
Average KL loss: 0.044260
Average total loss: 0.178108
tensor(0.0322, device='cuda:0') tensor(0.0659, device='cuda:0') tensor(-9.8969e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.130732
Average KL loss: 0.044456
Average total loss: 0.175188
tensor(0.0323, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.0704e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.130559
Average KL loss: 0.044621
Average total loss: 0.175181
tensor(0.0323, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.1663e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.128446
Average KL loss: 0.044811
Average total loss: 0.173257
tensor(0.0324, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-8.8580e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.124863
Average KL loss: 0.044980
Average total loss: 0.169843
tensor(0.0324, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-9.7723e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.123929
Average KL loss: 0.045146
Average total loss: 0.169075
tensor(0.0325, device='cuda:0') tensor(0.0671, device='cuda:0') tensor(-8.5625e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.123800
Average KL loss: 0.045305
Average total loss: 0.169105
tensor(0.0326, device='cuda:0') tensor(0.0674, device='cuda:0') tensor(-9.2267e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.119586
Average KL loss: 0.045491
Average total loss: 0.165077
tensor(0.0326, device='cuda:0') tensor(0.0676, device='cuda:0') tensor(-9.9287e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.116199
Average KL loss: 0.045650
Average total loss: 0.161849
tensor(0.0327, device='cuda:0') tensor(0.0679, device='cuda:0') tensor(-7.9913e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.114779
Average KL loss: 0.045799
Average total loss: 0.160579
tensor(0.0327, device='cuda:0') tensor(0.0681, device='cuda:0') tensor(-9.1986e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.115656
Average KL loss: 0.045956
Average total loss: 0.161612
tensor(0.0328, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-8.1720e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.113334
Average KL loss: 0.046121
Average total loss: 0.159455
tensor(0.0328, device='cuda:0') tensor(0.0686, device='cuda:0') tensor(-1.0004e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.112707
Average KL loss: 0.046274
Average total loss: 0.158980
tensor(0.0329, device='cuda:0') tensor(0.0689, device='cuda:0') tensor(-1.0834e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.111888
Average KL loss: 0.046446
Average total loss: 0.158334
tensor(0.0329, device='cuda:0') tensor(0.0691, device='cuda:0') tensor(-9.9082e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.107273
Average KL loss: 0.046591
Average total loss: 0.153864
tensor(0.0330, device='cuda:0') tensor(0.0693, device='cuda:0') tensor(-9.2147e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.106653
Average KL loss: 0.046731
Average total loss: 0.153384
tensor(0.0330, device='cuda:0') tensor(0.0696, device='cuda:0') tensor(-8.0389e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.103422
Average KL loss: 0.046880
Average total loss: 0.150302
tensor(0.0330, device='cuda:0') tensor(0.0698, device='cuda:0') tensor(-8.0806e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.103870
Average KL loss: 0.047003
Average total loss: 0.150872
tensor(0.0331, device='cuda:0') tensor(0.0700, device='cuda:0') tensor(-1.2514e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.102089
Average KL loss: 0.047124
Average total loss: 0.149213
tensor(0.0331, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-6.5684e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.100016
Average KL loss: 0.047234
Average total loss: 0.147251
tensor(0.0331, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-5.1925e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.099336
Average KL loss: 0.047359
Average total loss: 0.146696
tensor(0.0332, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(-6.2738e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.098407
Average KL loss: 0.047486
Average total loss: 0.145892
tensor(0.0332, device='cuda:0') tensor(0.0709, device='cuda:0') tensor(-5.4047e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.095734
Average KL loss: 0.047584
Average total loss: 0.143318
tensor(0.0332, device='cuda:0') tensor(0.0711, device='cuda:0') tensor(-7.8129e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.097155
Average KL loss: 0.047693
Average total loss: 0.144849
tensor(0.0333, device='cuda:0') tensor(0.0713, device='cuda:0') tensor(-5.8936e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.095298
Average KL loss: 0.047812
Average total loss: 0.143110
tensor(0.0333, device='cuda:0') tensor(0.0715, device='cuda:0') tensor(-7.5685e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.093287
Average KL loss: 0.047933
Average total loss: 0.141220
tensor(0.0333, device='cuda:0') tensor(0.0717, device='cuda:0') tensor(-5.9225e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.093784
Average KL loss: 0.048054
Average total loss: 0.141838
tensor(0.0334, device='cuda:0') tensor(0.0719, device='cuda:0') tensor(-7.7436e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.090859
Average KL loss: 0.048153
Average total loss: 0.139012
tensor(0.0334, device='cuda:0') tensor(0.0721, device='cuda:0') tensor(-5.5733e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.089841
Average KL loss: 0.048275
Average total loss: 0.138116
tensor(0.0334, device='cuda:0') tensor(0.0723, device='cuda:0') tensor(-5.0926e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.088391
Average KL loss: 0.048374
Average total loss: 0.136765
tensor(0.0335, device='cuda:0') tensor(0.0725, device='cuda:0') tensor(-6.5622e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.089352
Average KL loss: 0.048478
Average total loss: 0.137830
tensor(0.0335, device='cuda:0') tensor(0.0727, device='cuda:0') tensor(-6.4298e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.087072
Average KL loss: 0.048582
Average total loss: 0.135654
tensor(0.0335, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(-7.5095e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.085601
Average KL loss: 0.048675
Average total loss: 0.134276
tensor(0.0335, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(-5.8223e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.087378
Average KL loss: 0.048771
Average total loss: 0.136149
tensor(0.0335, device='cuda:0') tensor(0.0734, device='cuda:0') tensor(-3.8306e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.084481
Average KL loss: 0.048871
Average total loss: 0.133352
tensor(0.0336, device='cuda:0') tensor(0.0736, device='cuda:0') tensor(-5.1719e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.082038
Average KL loss: 0.048953
Average total loss: 0.130991
tensor(0.0336, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(-9.3286e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.083811
Average KL loss: 0.049041
Average total loss: 0.132852
tensor(0.0336, device='cuda:0') tensor(0.0739, device='cuda:0') tensor(-4.6046e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.082062
Average KL loss: 0.049128
Average total loss: 0.131191
tensor(0.0336, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(-4.2414e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.083247
Average KL loss: 0.049232
Average total loss: 0.132480
tensor(0.0337, device='cuda:0') tensor(0.0744, device='cuda:0') tensor(-5.5137e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.079702
Average KL loss: 0.049330
Average total loss: 0.129031
tensor(0.0337, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-5.3962e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.080272
Average KL loss: 0.049427
Average total loss: 0.129700
tensor(0.0337, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(-5.8040e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.079058
Average KL loss: 0.049524
Average total loss: 0.128582
tensor(0.0337, device='cuda:0') tensor(0.0750, device='cuda:0') tensor(-4.9732e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.077706
Average KL loss: 0.049592
Average total loss: 0.127297
tensor(0.0337, device='cuda:0') tensor(0.0751, device='cuda:0') tensor(-3.8888e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.077153
Average KL loss: 0.049666
Average total loss: 0.126819
tensor(0.0338, device='cuda:0') tensor(0.0753, device='cuda:0') tensor(-3.4299e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.075863
Average KL loss: 0.049751
Average total loss: 0.125614
tensor(0.0338, device='cuda:0') tensor(0.0755, device='cuda:0') tensor(-3.5804e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.075471
Average KL loss: 0.049830
Average total loss: 0.125301
tensor(0.0338, device='cuda:0') tensor(0.0757, device='cuda:0') tensor(-2.3595e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.074275
Average KL loss: 0.049908
Average total loss: 0.124183
tensor(0.0338, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(-3.6673e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.076236
Average KL loss: 0.049973
Average total loss: 0.126208
tensor(0.0338, device='cuda:0') tensor(0.0761, device='cuda:0') tensor(-2.4234e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.074579
Average KL loss: 0.050062
Average total loss: 0.124641
tensor(0.0338, device='cuda:0') tensor(0.0763, device='cuda:0') tensor(-4.7549e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.074617
Average KL loss: 0.050137
Average total loss: 0.124754
tensor(0.0339, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-3.7440e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.073313
Average KL loss: 0.050213
Average total loss: 0.123527
tensor(0.0339, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(-3.9647e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.072412
Average KL loss: 0.050279
Average total loss: 0.122691
tensor(0.0339, device='cuda:0') tensor(0.0768, device='cuda:0') tensor(-3.9723e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.071998
Average KL loss: 0.050343
Average total loss: 0.122341
tensor(0.0339, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(-3.2326e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.070585
Average KL loss: 0.050401
Average total loss: 0.120986
tensor(0.0339, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-3.5779e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.070681
Average KL loss: 0.050457
Average total loss: 0.121138
tensor(0.0339, device='cuda:0') tensor(0.0774, device='cuda:0') tensor(-2.5738e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.069557
Average KL loss: 0.050520
Average total loss: 0.120077
tensor(0.0339, device='cuda:0') tensor(0.0775, device='cuda:0') tensor(-3.1089e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.068510
Average KL loss: 0.050570
Average total loss: 0.119080
tensor(0.0339, device='cuda:0') tensor(0.0777, device='cuda:0') tensor(-2.9931e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.067861
Average KL loss: 0.050618
Average total loss: 0.118479
tensor(0.0339, device='cuda:0') tensor(0.0779, device='cuda:0') tensor(-2.4023e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.067227
Average KL loss: 0.050668
Average total loss: 0.117895
tensor(0.0339, device='cuda:0') tensor(0.0780, device='cuda:0') tensor(-2.7205e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.066718
Average KL loss: 0.050710
Average total loss: 0.117429
tensor(0.0339, device='cuda:0') tensor(0.0782, device='cuda:0') tensor(-3.2527e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.067439
Average KL loss: 0.050759
Average total loss: 0.118198
tensor(0.0340, device='cuda:0') tensor(0.0784, device='cuda:0') tensor(-4.2224e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.066134
Average KL loss: 0.050839
Average total loss: 0.116972
tensor(0.0340, device='cuda:0') tensor(0.0785, device='cuda:0') tensor(-3.5707e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.066770
Average KL loss: 0.050878
Average total loss: 0.117647
tensor(0.0339, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(-2.7800e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.063839
Average KL loss: 0.050920
Average total loss: 0.114759
tensor(0.0340, device='cuda:0') tensor(0.0789, device='cuda:0') tensor(-2.5352e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.064262
Average KL loss: 0.050960
Average total loss: 0.115222
tensor(0.0340, device='cuda:0') tensor(0.0790, device='cuda:0') tensor(-2.8054e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.065046
Average KL loss: 0.051004
Average total loss: 0.116050
tensor(0.0340, device='cuda:0') tensor(0.0792, device='cuda:0') tensor(-2.1365e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.064255
Average KL loss: 0.051044
Average total loss: 0.115299
tensor(0.0340, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-3.0905e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.063531
Average KL loss: 0.051090
Average total loss: 0.114622
tensor(0.0340, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-2.5742e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.063009
Average KL loss: 0.051148
Average total loss: 0.114156
tensor(0.0340, device='cuda:0') tensor(0.0797, device='cuda:0') tensor(-2.9128e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.062871
Average KL loss: 0.051204
Average total loss: 0.114075
tensor(0.0340, device='cuda:0') tensor(0.0799, device='cuda:0') tensor(-2.2096e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.063097
Average KL loss: 0.051270
Average total loss: 0.114367
tensor(0.0340, device='cuda:0') tensor(0.0801, device='cuda:0') tensor(-2.2806e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.062184
Average KL loss: 0.051343
Average total loss: 0.113527
tensor(0.0340, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(-2.2905e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.060925
Average KL loss: 0.051370
Average total loss: 0.112295
tensor(0.0340, device='cuda:0') tensor(0.0804, device='cuda:0') tensor(-2.1086e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.060528
Average KL loss: 0.051402
Average total loss: 0.111930
tensor(0.0340, device='cuda:0') tensor(0.0806, device='cuda:0') tensor(-1.9543e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.061263
Average KL loss: 0.051442
Average total loss: 0.112705
tensor(0.0340, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(-3.2922e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.059823
Average KL loss: 0.051476
Average total loss: 0.111299
tensor(0.0340, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-4.2222e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.059904
Average KL loss: 0.051515
Average total loss: 0.111419
tensor(0.0340, device='cuda:0') tensor(0.0811, device='cuda:0') tensor(-1.9997e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.058939
Average KL loss: 0.051538
Average total loss: 0.110477
tensor(0.0340, device='cuda:0') tensor(0.0812, device='cuda:0') tensor(-3.2790e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.059434
Average KL loss: 0.051548
Average total loss: 0.110982
tensor(0.0340, device='cuda:0') tensor(0.0814, device='cuda:0') tensor(-4.0100e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.059484
Average KL loss: 0.051593
Average total loss: 0.111078
tensor(0.0340, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(-1.1193e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.058284
Average KL loss: 0.051624
Average total loss: 0.109907
tensor(0.0340, device='cuda:0') tensor(0.0817, device='cuda:0') tensor(-3.6638e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.057529
Average KL loss: 0.051659
Average total loss: 0.109188
tensor(0.0340, device='cuda:0') tensor(0.0818, device='cuda:0') tensor(-2.6306e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.056191
Average KL loss: 0.051673
Average total loss: 0.107864
tensor(0.0340, device='cuda:0') tensor(0.0820, device='cuda:0') tensor(-2.4756e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.056786
Average KL loss: 0.051698
Average total loss: 0.108483
tensor(0.0340, device='cuda:0') tensor(0.0821, device='cuda:0') tensor(-1.5799e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.055709
Average KL loss: 0.051722
Average total loss: 0.107431
tensor(0.0340, device='cuda:0') tensor(0.0823, device='cuda:0') tensor(-2.1471e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.055705
Average KL loss: 0.051733
Average total loss: 0.107439
tensor(0.0340, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-2.0153e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.056365
Average KL loss: 0.051749
Average total loss: 0.108114
tensor(0.0340, device='cuda:0') tensor(0.0826, device='cuda:0') tensor(-1.2500e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.055397
Average KL loss: 0.051768
Average total loss: 0.107164
tensor(0.0340, device='cuda:0') tensor(0.0827, device='cuda:0') tensor(-1.3945e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.054701
Average KL loss: 0.051782
Average total loss: 0.106483
tensor(0.0339, device='cuda:0') tensor(0.0828, device='cuda:0') tensor(-4.1325e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.054349
Average KL loss: 0.051785
Average total loss: 0.106134
tensor(0.0339, device='cuda:0') tensor(0.0830, device='cuda:0') tensor(-2.8767e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.055246
Average KL loss: 0.051806
Average total loss: 0.107052
tensor(0.0339, device='cuda:0') tensor(0.0831, device='cuda:0') tensor(-1.5147e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.056844
Average KL loss: 0.051823
Average total loss: 0.108667
tensor(0.0339, device='cuda:0') tensor(0.0833, device='cuda:0') tensor(-1.8238e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.055082
Average KL loss: 0.051865
Average total loss: 0.106946
tensor(0.0339, device='cuda:0') tensor(0.0834, device='cuda:0') tensor(-1.4056e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.054039
Average KL loss: 0.051880
Average total loss: 0.105919
tensor(0.0339, device='cuda:0') tensor(0.0836, device='cuda:0') tensor(-8.5357e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.054096
Average KL loss: 0.051894
Average total loss: 0.105990
tensor(0.0339, device='cuda:0') tensor(0.0837, device='cuda:0') tensor(-1.4163e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.053412
Average KL loss: 0.051911
Average total loss: 0.105323
tensor(0.0339, device='cuda:0') tensor(0.0838, device='cuda:0') tensor(-1.3563e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.053856
Average KL loss: 0.051925
Average total loss: 0.105781
tensor(0.0339, device='cuda:0') tensor(0.0840, device='cuda:0') tensor(-1.7764e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.053131
Average KL loss: 0.051945
Average total loss: 0.105076
tensor(0.0339, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(-9.6183e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.053077
Average KL loss: 0.051963
Average total loss: 0.105040
tensor(0.0339, device='cuda:0') tensor(0.0843, device='cuda:0') tensor(-1.7643e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.052254
Average KL loss: 0.051977
Average total loss: 0.104231
tensor(0.0339, device='cuda:0') tensor(0.0844, device='cuda:0') tensor(-1.1459e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.052462
Average KL loss: 0.051983
Average total loss: 0.104445
tensor(0.0339, device='cuda:0') tensor(0.0845, device='cuda:0') tensor(-2.5737e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.051504
Average KL loss: 0.052000
Average total loss: 0.103504
tensor(0.0339, device='cuda:0') tensor(0.0847, device='cuda:0') tensor(-1.4259e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.051727
Average KL loss: 0.052014
Average total loss: 0.103741
tensor(0.0339, device='cuda:0') tensor(0.0848, device='cuda:0') tensor(-1.3218e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.051335
Average KL loss: 0.052033
Average total loss: 0.103368
tensor(0.0339, device='cuda:0') tensor(0.0850, device='cuda:0') tensor(-1.2397e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.051721
Average KL loss: 0.052052
Average total loss: 0.103774
tensor(0.0339, device='cuda:0') tensor(0.0851, device='cuda:0') tensor(-1.0726e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.050229
Average KL loss: 0.052058
Average total loss: 0.102287
tensor(0.0338, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-8.4616e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.050517
Average KL loss: 0.052043
Average total loss: 0.102560
tensor(0.0338, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(-3.6628e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.051357
Average KL loss: 0.052043
Average total loss: 0.103400
tensor(0.0338, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.9687e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.050803
Average KL loss: 0.052062
Average total loss: 0.102865
tensor(0.0338, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-7.0197e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.050669
Average KL loss: 0.052067
Average total loss: 0.102736
tensor(0.0338, device='cuda:0') tensor(0.0858, device='cuda:0') tensor(-1.1907e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.049758
Average KL loss: 0.052074
Average total loss: 0.101832
tensor(0.0338, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-7.5091e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.049503
Average KL loss: 0.052064
Average total loss: 0.101567
tensor(0.0338, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(3.4510e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.049550
Average KL loss: 0.052062
Average total loss: 0.101612
tensor(0.0338, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-1.9756e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.048870
Average KL loss: 0.052063
Average total loss: 0.100933
tensor(0.0338, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-7.7452e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.049850
Average KL loss: 0.052061
Average total loss: 0.101911
tensor(0.0338, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-8.3144e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.049356
Average KL loss: 0.052064
Average total loss: 0.101419
tensor(0.0338, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-1.1819e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.048713
Average KL loss: 0.052083
Average total loss: 0.100795
tensor(0.0338, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(-2.5940e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.049644
Average KL loss: 0.052087
Average total loss: 0.101731
tensor(0.0338, device='cuda:0') tensor(0.0868, device='cuda:0') tensor(-1.0990e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.048865
Average KL loss: 0.052106
Average total loss: 0.100971
tensor(0.0338, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-1.8683e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.048018
Average KL loss: 0.052111
Average total loss: 0.100129
tensor(0.0338, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(-2.1076e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.048380
Average KL loss: 0.052106
Average total loss: 0.100487
tensor(0.0337, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(3.5709e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.047081
Average KL loss: 0.052091
Average total loss: 0.099172
tensor(0.0337, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-1.2465e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.048385
Average KL loss: 0.052077
Average total loss: 0.100462
tensor(0.0337, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.2858e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.047950
Average KL loss: 0.052089
Average total loss: 0.100039
tensor(0.0337, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(-1.4859e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.047193
Average KL loss: 0.052084
Average total loss: 0.099277
tensor(0.0337, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-1.1815e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.047415
Average KL loss: 0.052073
Average total loss: 0.099487
tensor(0.0337, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(-5.4446e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.047468
Average KL loss: 0.052083
Average total loss: 0.099552
tensor(0.0337, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-8.0842e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.047065
Average KL loss: 0.052084
Average total loss: 0.099149
tensor(0.0337, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(-4.6281e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.047707
Average KL loss: 0.052100
Average total loss: 0.099806
tensor(0.0337, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(-6.7246e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.046332
Average KL loss: 0.052092
Average total loss: 0.098424
tensor(0.0337, device='cuda:0') tensor(0.0884, device='cuda:0') tensor(-9.3296e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.045768
Average KL loss: 0.052097
Average total loss: 0.097865
tensor(0.0337, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-1.2808e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.046605
Average KL loss: 0.052088
Average total loss: 0.098693
tensor(0.0337, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(-4.4810e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.046179
Average KL loss: 0.052095
Average total loss: 0.098274
tensor(0.0337, device='cuda:0') tensor(0.0888, device='cuda:0') tensor(-2.0751e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.045980
Average KL loss: 0.052109
Average total loss: 0.098089
tensor(0.0337, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-1.0364e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.046092
Average KL loss: 0.052112
Average total loss: 0.098204
tensor(0.0336, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(-2.0283e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.045443
Average KL loss: 0.052101
Average total loss: 0.097544
tensor(0.0336, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(-1.2848e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.046106
Average KL loss: 0.052093
Average total loss: 0.098199
tensor(0.0336, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-4.5008e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.045043
Average KL loss: 0.052104
Average total loss: 0.097147
tensor(0.0336, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-4.3199e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.046290
Average KL loss: 0.052087
Average total loss: 0.098377
tensor(0.0336, device='cuda:0') tensor(0.0896, device='cuda:0') tensor(-2.6367e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.045560
Average KL loss: 0.052121
Average total loss: 0.097682
tensor(0.0336, device='cuda:0') tensor(0.0898, device='cuda:0') tensor(-4.4519e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.044599
Average KL loss: 0.052107
Average total loss: 0.096706
tensor(0.0336, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(-1.5614e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.045876
Average KL loss: 0.052085
Average total loss: 0.097961
tensor(0.0336, device='cuda:0') tensor(0.0900, device='cuda:0') tensor(-1.1063e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.045865
Average KL loss: 0.052111
Average total loss: 0.097976
tensor(0.0336, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(4.4340e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.045174
Average KL loss: 0.052117
Average total loss: 0.097291
tensor(0.0336, device='cuda:0') tensor(0.0903, device='cuda:0') tensor(-1.8221e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.045657
Average KL loss: 0.052129
Average total loss: 0.097786
tensor(0.0336, device='cuda:0') tensor(0.0904, device='cuda:0') tensor(-1.3708e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.044727
Average KL loss: 0.052145
Average total loss: 0.096871
tensor(0.0336, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(-1.8558e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.044550
Average KL loss: 0.052127
Average total loss: 0.096677
tensor(0.0335, device='cuda:0') tensor(0.0907, device='cuda:0') tensor(-1.1108e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.043949
Average KL loss: 0.052115
Average total loss: 0.096064
tensor(0.0335, device='cuda:0') tensor(0.0908, device='cuda:0') tensor(2.4964e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.043857
Average KL loss: 0.052093
Average total loss: 0.095949
tensor(0.0335, device='cuda:0') tensor(0.0909, device='cuda:0') tensor(-6.5387e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.043948
Average KL loss: 0.052076
Average total loss: 0.096024
tensor(0.0335, device='cuda:0') tensor(0.0910, device='cuda:0') tensor(-9.6220e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.044627
Average KL loss: 0.052074
Average total loss: 0.096701
tensor(0.0335, device='cuda:0') tensor(0.0911, device='cuda:0') tensor(-8.0082e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.044019
Average KL loss: 0.052090
Average total loss: 0.096108
tensor(0.0335, device='cuda:0') tensor(0.0913, device='cuda:0') tensor(-5.5937e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.043409
Average KL loss: 0.052083
Average total loss: 0.095491
tensor(0.0335, device='cuda:0') tensor(0.0914, device='cuda:0') tensor(-1.2551e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.043787
Average KL loss: 0.052078
Average total loss: 0.095865
tensor(0.0335, device='cuda:0') tensor(0.0915, device='cuda:0') tensor(-1.8670e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.043671
Average KL loss: 0.052060
Average total loss: 0.095731
tensor(0.0335, device='cuda:0') tensor(0.0916, device='cuda:0') tensor(-6.3755e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.042420
Average KL loss: 0.052035
Average total loss: 0.094456
tensor(0.0335, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-6.3711e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.042939
Average KL loss: 0.052009
Average total loss: 0.094948
tensor(0.0335, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-1.0481e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.043722
Average KL loss: 0.051998
Average total loss: 0.095720
tensor(0.0335, device='cuda:0') tensor(0.0919, device='cuda:0') tensor(-1.0284e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.043334
Average KL loss: 0.052004
Average total loss: 0.095339
 Percentile value: 0.14050188660621643
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =     162 /    1728             (  9.38%) | total_pruned =    1566 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     472 /   36864             (  1.28%) | total_pruned =   36392 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1276 /   36864             (  3.46%) | total_pruned =   35588 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     676 /   36864             (  1.83%) | total_pruned =   36188 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1111 /   36864             (  3.01%) | total_pruned =   35753 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    6498 /   73728             (  8.81%) | total_pruned =   67230 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   13653 /  147456             (  9.26%) | total_pruned =  133803 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     997 /    8192             ( 12.17%) | total_pruned =    7195 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   10085 /  147456             (  6.84%) | total_pruned =  137371 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   10783 /  147456             (  7.31%) | total_pruned =  136673 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   31742 /  294912             ( 10.76%) | total_pruned =  263170 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     174 /     256             ( 67.97%) | total_pruned =      82 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      74 /     256             ( 28.91%) | total_pruned =     182 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   35104 /  589824             (  5.95%) | total_pruned =  554720 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     129 /     256             ( 50.39%) | total_pruned =     127 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3378 /   32768             ( 10.31%) | total_pruned =   29390 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   27206 /  589824             (  4.61%) | total_pruned =  562618 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   26781 /  589824             (  4.54%) | total_pruned =  563043 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   68109 / 1179648             (  5.77%) | total_pruned = 1111539 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     363 /     512             ( 70.90%) | total_pruned =     149 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  141287 / 2359296             (  5.99%) | total_pruned = 2218009 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     422 /     512             ( 82.42%) | total_pruned =      90 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4097 /  131072             (  3.13%) | total_pruned =  126975 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     235 /     512             ( 45.90%) | total_pruned =     277 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     205 /     512             ( 40.04%) | total_pruned =     307 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   94584 / 2359296             (  4.01%) | total_pruned = 2264712 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     267 /     512             ( 52.15%) | total_pruned =     245 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  211980 / 2359296             (  8.98%) | total_pruned = 2147316 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     449 /     512             ( 87.70%) | total_pruned =      63 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     439 /     512             ( 85.74%) | total_pruned =      73 | shape = torch.Size([512])
linear.weight        | nonzeros =    4347 /    5120             ( 84.90%) | total_pruned =     773 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 52/100 Loss: 0.025268 Accuracy: 85.74 100.00 % Best test Accuracy: 85.89%
tensor(0.0334, device='cuda:0') tensor(0.0921, device='cuda:0') tensor(-3.0986e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.246161
Average KL loss: 0.049471
Average total loss: 0.295633
tensor(0.0340, device='cuda:0') tensor(0.0847, device='cuda:0') tensor(-2.2581e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.218109
Average KL loss: 0.047628
Average total loss: 0.265737
tensor(0.0338, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(-1.8906e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.206823
Average KL loss: 0.046830
Average total loss: 0.253653
tensor(0.0335, device='cuda:0') tensor(0.0802, device='cuda:0') tensor(-1.6662e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.193607
Average KL loss: 0.046365
Average total loss: 0.239972
tensor(0.0332, device='cuda:0') tensor(0.0790, device='cuda:0') tensor(-1.6516e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.187077
Average KL loss: 0.046091
Average total loss: 0.233168
tensor(0.0330, device='cuda:0') tensor(0.0783, device='cuda:0') tensor(-1.9013e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.181148
Average KL loss: 0.045964
Average total loss: 0.227112
tensor(0.0329, device='cuda:0') tensor(0.0777, device='cuda:0') tensor(-1.3801e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.169528
Average KL loss: 0.045931
Average total loss: 0.215460
tensor(0.0328, device='cuda:0') tensor(0.0774, device='cuda:0') tensor(-1.1761e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.166022
Average KL loss: 0.045981
Average total loss: 0.212004
tensor(0.0327, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-1.4543e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.160560
Average KL loss: 0.046053
Average total loss: 0.206614
tensor(0.0327, device='cuda:0') tensor(0.0771, device='cuda:0') tensor(-1.4882e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.156577
Average KL loss: 0.046161
Average total loss: 0.202739
tensor(0.0327, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(-1.0556e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.150613
Average KL loss: 0.046261
Average total loss: 0.196875
tensor(0.0327, device='cuda:0') tensor(0.0769, device='cuda:0') tensor(-1.2961e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.149357
Average KL loss: 0.046360
Average total loss: 0.195717
tensor(0.0327, device='cuda:0') tensor(0.0769, device='cuda:0') tensor(-1.1232e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.145684
Average KL loss: 0.046474
Average total loss: 0.192158
tensor(0.0327, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(-1.0225e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.142240
Average KL loss: 0.046567
Average total loss: 0.188807
tensor(0.0327, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(-1.5252e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.137990
Average KL loss: 0.046669
Average total loss: 0.184659
tensor(0.0327, device='cuda:0') tensor(0.0771, device='cuda:0') tensor(-1.2811e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.137756
Average KL loss: 0.046783
Average total loss: 0.184539
tensor(0.0328, device='cuda:0') tensor(0.0773, device='cuda:0') tensor(-9.2814e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.131069
Average KL loss: 0.046891
Average total loss: 0.177960
tensor(0.0328, device='cuda:0') tensor(0.0774, device='cuda:0') tensor(-8.1046e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.129968
Average KL loss: 0.046986
Average total loss: 0.176955
tensor(0.0328, device='cuda:0') tensor(0.0775, device='cuda:0') tensor(-9.3840e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.127390
Average KL loss: 0.047080
Average total loss: 0.174470
tensor(0.0328, device='cuda:0') tensor(0.0776, device='cuda:0') tensor(-9.0636e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.122981
Average KL loss: 0.047184
Average total loss: 0.170165
tensor(0.0328, device='cuda:0') tensor(0.0777, device='cuda:0') tensor(-8.9919e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.121165
Average KL loss: 0.047277
Average total loss: 0.168442
tensor(0.0328, device='cuda:0') tensor(0.0779, device='cuda:0') tensor(-9.4725e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.119852
Average KL loss: 0.047385
Average total loss: 0.167236
tensor(0.0329, device='cuda:0') tensor(0.0781, device='cuda:0') tensor(-7.3248e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.116475
Average KL loss: 0.047495
Average total loss: 0.163970
tensor(0.0329, device='cuda:0') tensor(0.0782, device='cuda:0') tensor(-1.3271e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.115391
Average KL loss: 0.047598
Average total loss: 0.162988
tensor(0.0329, device='cuda:0') tensor(0.0784, device='cuda:0') tensor(-1.0244e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.113071
Average KL loss: 0.047683
Average total loss: 0.160754
tensor(0.0329, device='cuda:0') tensor(0.0786, device='cuda:0') tensor(-1.0979e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.111659
Average KL loss: 0.047777
Average total loss: 0.159436
tensor(0.0329, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(-9.7735e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.111376
Average KL loss: 0.047870
Average total loss: 0.159246
tensor(0.0330, device='cuda:0') tensor(0.0789, device='cuda:0') tensor(-7.7699e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.109463
Average KL loss: 0.047972
Average total loss: 0.157436
tensor(0.0330, device='cuda:0') tensor(0.0791, device='cuda:0') tensor(-7.5439e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.104458
Average KL loss: 0.048070
Average total loss: 0.152527
tensor(0.0330, device='cuda:0') tensor(0.0792, device='cuda:0') tensor(-8.5046e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.105095
Average KL loss: 0.048154
Average total loss: 0.153249
tensor(0.0330, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-5.0715e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.101003
Average KL loss: 0.048239
Average total loss: 0.149242
tensor(0.0330, device='cuda:0') tensor(0.0796, device='cuda:0') tensor(-6.8853e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.100826
Average KL loss: 0.048319
Average total loss: 0.149146
tensor(0.0330, device='cuda:0') tensor(0.0798, device='cuda:0') tensor(-4.7992e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.099257
Average KL loss: 0.048394
Average total loss: 0.147651
tensor(0.0331, device='cuda:0') tensor(0.0799, device='cuda:0') tensor(-5.4350e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.097460
Average KL loss: 0.048477
Average total loss: 0.145936
tensor(0.0331, device='cuda:0') tensor(0.0801, device='cuda:0') tensor(-5.9231e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.097876
Average KL loss: 0.048559
Average total loss: 0.146435
tensor(0.0331, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(-5.5054e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.095057
Average KL loss: 0.048647
Average total loss: 0.143704
tensor(0.0331, device='cuda:0') tensor(0.0805, device='cuda:0') tensor(-5.5016e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.092380
Average KL loss: 0.048728
Average total loss: 0.141108
tensor(0.0331, device='cuda:0') tensor(0.0807, device='cuda:0') tensor(-5.0171e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.092802
Average KL loss: 0.048782
Average total loss: 0.141584
tensor(0.0331, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(-5.6753e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.092457
Average KL loss: 0.048850
Average total loss: 0.141307
tensor(0.0331, device='cuda:0') tensor(0.0810, device='cuda:0') tensor(-4.1247e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.091023
Average KL loss: 0.048919
Average total loss: 0.139942
tensor(0.0331, device='cuda:0') tensor(0.0812, device='cuda:0') tensor(-4.7901e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.088404
Average KL loss: 0.048987
Average total loss: 0.137392
tensor(0.0332, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(-8.3271e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.088183
Average KL loss: 0.049052
Average total loss: 0.137235
tensor(0.0332, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(-5.9235e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.084781
Average KL loss: 0.049115
Average total loss: 0.133896
tensor(0.0332, device='cuda:0') tensor(0.0817, device='cuda:0') tensor(-5.5546e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.088691
Average KL loss: 0.049173
Average total loss: 0.137864
tensor(0.0332, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(-5.5794e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.083506
Average KL loss: 0.049234
Average total loss: 0.132740
tensor(0.0332, device='cuda:0') tensor(0.0820, device='cuda:0') tensor(-6.2473e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.084918
Average KL loss: 0.049304
Average total loss: 0.134222
tensor(0.0332, device='cuda:0') tensor(0.0822, device='cuda:0') tensor(-5.4774e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.082058
Average KL loss: 0.049361
Average total loss: 0.131418
tensor(0.0332, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-3.5397e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.080077
Average KL loss: 0.049420
Average total loss: 0.129497
tensor(0.0332, device='cuda:0') tensor(0.0826, device='cuda:0') tensor(-3.9613e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.079946
Average KL loss: 0.049466
Average total loss: 0.129413
tensor(0.0332, device='cuda:0') tensor(0.0827, device='cuda:0') tensor(-3.9919e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.081148
Average KL loss: 0.049516
Average total loss: 0.130664
tensor(0.0332, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(-5.3301e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.081817
Average KL loss: 0.049574
Average total loss: 0.131392
tensor(0.0332, device='cuda:0') tensor(0.0830, device='cuda:0') tensor(-4.8001e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.078603
Average KL loss: 0.049647
Average total loss: 0.128250
tensor(0.0332, device='cuda:0') tensor(0.0832, device='cuda:0') tensor(-2.5038e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.077857
Average KL loss: 0.049697
Average total loss: 0.127554
tensor(0.0332, device='cuda:0') tensor(0.0834, device='cuda:0') tensor(-4.1746e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.074475
Average KL loss: 0.049746
Average total loss: 0.124221
tensor(0.0332, device='cuda:0') tensor(0.0835, device='cuda:0') tensor(-3.8088e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.075947
Average KL loss: 0.049790
Average total loss: 0.125737
tensor(0.0332, device='cuda:0') tensor(0.0837, device='cuda:0') tensor(-5.2500e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.074656
Average KL loss: 0.049841
Average total loss: 0.124497
tensor(0.0332, device='cuda:0') tensor(0.0838, device='cuda:0') tensor(-3.3279e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.074033
Average KL loss: 0.049882
Average total loss: 0.123916
tensor(0.0332, device='cuda:0') tensor(0.0840, device='cuda:0') tensor(-4.9847e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.072181
Average KL loss: 0.049923
Average total loss: 0.122104
tensor(0.0332, device='cuda:0') tensor(0.0842, device='cuda:0') tensor(-5.6843e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.072742
Average KL loss: 0.049958
Average total loss: 0.122700
tensor(0.0332, device='cuda:0') tensor(0.0843, device='cuda:0') tensor(-2.0332e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.073513
Average KL loss: 0.050012
Average total loss: 0.123525
tensor(0.0332, device='cuda:0') tensor(0.0845, device='cuda:0') tensor(-4.9914e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.072900
Average KL loss: 0.050061
Average total loss: 0.122961
tensor(0.0332, device='cuda:0') tensor(0.0847, device='cuda:0') tensor(-2.5123e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.069498
Average KL loss: 0.050101
Average total loss: 0.119599
tensor(0.0332, device='cuda:0') tensor(0.0848, device='cuda:0') tensor(-3.0371e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.068829
Average KL loss: 0.050123
Average total loss: 0.118951
tensor(0.0332, device='cuda:0') tensor(0.0850, device='cuda:0') tensor(-4.9066e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.069297
Average KL loss: 0.050165
Average total loss: 0.119462
tensor(0.0332, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(-2.0854e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.068105
Average KL loss: 0.050203
Average total loss: 0.118308
tensor(0.0332, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-3.0722e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.067253
Average KL loss: 0.050226
Average total loss: 0.117479
tensor(0.0332, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-3.3108e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.067959
Average KL loss: 0.050276
Average total loss: 0.118235
tensor(0.0333, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-3.7717e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.066757
Average KL loss: 0.050311
Average total loss: 0.117069
tensor(0.0332, device='cuda:0') tensor(0.0858, device='cuda:0') tensor(-2.9085e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.064680
Average KL loss: 0.050336
Average total loss: 0.115016
tensor(0.0332, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-3.9593e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.065755
Average KL loss: 0.050370
Average total loss: 0.116125
tensor(0.0332, device='cuda:0') tensor(0.0861, device='cuda:0') tensor(-5.3965e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.065349
Average KL loss: 0.050412
Average total loss: 0.115761
tensor(0.0332, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-3.5519e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.062663
Average KL loss: 0.050441
Average total loss: 0.113104
tensor(0.0332, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-2.6673e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.062280
Average KL loss: 0.050472
Average total loss: 0.112753
tensor(0.0332, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-4.4282e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.062566
Average KL loss: 0.050498
Average total loss: 0.113063
tensor(0.0332, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(-3.8948e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.062153
Average KL loss: 0.050512
Average total loss: 0.112665
tensor(0.0332, device='cuda:0') tensor(0.0868, device='cuda:0') tensor(-2.9525e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.060934
Average KL loss: 0.050543
Average total loss: 0.111477
tensor(0.0332, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-2.0748e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.062139
Average KL loss: 0.050572
Average total loss: 0.112711
tensor(0.0332, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(-2.5926e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.061314
Average KL loss: 0.050586
Average total loss: 0.111900
tensor(0.0332, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-1.1857e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.059779
Average KL loss: 0.050605
Average total loss: 0.110384
tensor(0.0332, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-2.5515e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.060644
Average KL loss: 0.050629
Average total loss: 0.111273
tensor(0.0332, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-3.8866e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.060653
Average KL loss: 0.050658
Average total loss: 0.111311
tensor(0.0332, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-9.8694e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.059529
Average KL loss: 0.050679
Average total loss: 0.110207
tensor(0.0332, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-1.0553e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.059420
Average KL loss: 0.050690
Average total loss: 0.110110
tensor(0.0332, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-2.7199e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.058450
Average KL loss: 0.050709
Average total loss: 0.109159
tensor(0.0332, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(-2.0438e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.059219
Average KL loss: 0.050738
Average total loss: 0.109957
tensor(0.0332, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(-2.6773e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.057135
Average KL loss: 0.050755
Average total loss: 0.107890
tensor(0.0332, device='cuda:0') tensor(0.0884, device='cuda:0') tensor(-3.0672e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.056914
Average KL loss: 0.050773
Average total loss: 0.107687
tensor(0.0332, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-1.4790e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.058013
Average KL loss: 0.050794
Average total loss: 0.108807
tensor(0.0331, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(-2.3570e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.056526
Average KL loss: 0.050803
Average total loss: 0.107329
tensor(0.0331, device='cuda:0') tensor(0.0889, device='cuda:0') tensor(-1.3017e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.055206
Average KL loss: 0.050799
Average total loss: 0.106004
tensor(0.0331, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-3.2969e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.056075
Average KL loss: 0.050801
Average total loss: 0.106876
tensor(0.0331, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(-7.8938e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.056286
Average KL loss: 0.050811
Average total loss: 0.107097
tensor(0.0331, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(-1.6979e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.053505
Average KL loss: 0.050814
Average total loss: 0.104319
tensor(0.0331, device='cuda:0') tensor(0.0894, device='cuda:0') tensor(-1.3112e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.055024
Average KL loss: 0.050818
Average total loss: 0.105842
tensor(0.0331, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-2.9253e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.054070
Average KL loss: 0.050837
Average total loss: 0.104908
tensor(0.0331, device='cuda:0') tensor(0.0896, device='cuda:0') tensor(-2.6335e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.053492
Average KL loss: 0.050833
Average total loss: 0.104326
tensor(0.0331, device='cuda:0') tensor(0.0898, device='cuda:0') tensor(-3.7833e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.053687
Average KL loss: 0.050835
Average total loss: 0.104521
tensor(0.0330, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(-1.9980e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.055389
Average KL loss: 0.050846
Average total loss: 0.106235
tensor(0.0330, device='cuda:0') tensor(0.0900, device='cuda:0') tensor(-1.2652e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.051961
Average KL loss: 0.050864
Average total loss: 0.102826
tensor(0.0330, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(-1.5580e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.053296
Average KL loss: 0.050879
Average total loss: 0.104174
tensor(0.0330, device='cuda:0') tensor(0.0904, device='cuda:0') tensor(-1.6532e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.052124
Average KL loss: 0.050895
Average total loss: 0.103019
tensor(0.0330, device='cuda:0') tensor(0.0905, device='cuda:0') tensor(-2.3593e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.052311
Average KL loss: 0.050895
Average total loss: 0.103207
tensor(0.0330, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(-1.8845e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.052513
Average KL loss: 0.050895
Average total loss: 0.103408
tensor(0.0330, device='cuda:0') tensor(0.0908, device='cuda:0') tensor(-1.7160e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.052152
Average KL loss: 0.050908
Average total loss: 0.103060
tensor(0.0330, device='cuda:0') tensor(0.0909, device='cuda:0') tensor(-2.1663e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.050697
Average KL loss: 0.050926
Average total loss: 0.101623
tensor(0.0330, device='cuda:0') tensor(0.0911, device='cuda:0') tensor(-1.6836e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.051709
Average KL loss: 0.050926
Average total loss: 0.102635
tensor(0.0330, device='cuda:0') tensor(0.0912, device='cuda:0') tensor(-1.3469e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.050647
Average KL loss: 0.050936
Average total loss: 0.101583
tensor(0.0330, device='cuda:0') tensor(0.0913, device='cuda:0') tensor(-2.3742e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.049903
Average KL loss: 0.050935
Average total loss: 0.100838
tensor(0.0330, device='cuda:0') tensor(0.0915, device='cuda:0') tensor(-7.6095e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.050825
Average KL loss: 0.050933
Average total loss: 0.101758
tensor(0.0330, device='cuda:0') tensor(0.0916, device='cuda:0') tensor(-7.8251e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.048287
Average KL loss: 0.050936
Average total loss: 0.099223
tensor(0.0329, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.3627e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.049250
Average KL loss: 0.050935
Average total loss: 0.100185
tensor(0.0329, device='cuda:0') tensor(0.0919, device='cuda:0') tensor(-1.8425e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.049511
Average KL loss: 0.050935
Average total loss: 0.100446
tensor(0.0329, device='cuda:0') tensor(0.0920, device='cuda:0') tensor(-1.7151e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.049607
Average KL loss: 0.050953
Average total loss: 0.100560
tensor(0.0329, device='cuda:0') tensor(0.0921, device='cuda:0') tensor(-2.9093e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.048883
Average KL loss: 0.050955
Average total loss: 0.099839
tensor(0.0329, device='cuda:0') tensor(0.0923, device='cuda:0') tensor(-6.1596e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.048205
Average KL loss: 0.050954
Average total loss: 0.099160
tensor(0.0329, device='cuda:0') tensor(0.0924, device='cuda:0') tensor(-5.2542e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.047952
Average KL loss: 0.050937
Average total loss: 0.098888
tensor(0.0329, device='cuda:0') tensor(0.0925, device='cuda:0') tensor(-2.1298e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.047193
Average KL loss: 0.050929
Average total loss: 0.098122
tensor(0.0329, device='cuda:0') tensor(0.0926, device='cuda:0') tensor(-1.3052e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.047849
Average KL loss: 0.050931
Average total loss: 0.098780
tensor(0.0329, device='cuda:0') tensor(0.0928, device='cuda:0') tensor(-2.0282e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.048227
Average KL loss: 0.050937
Average total loss: 0.099164
tensor(0.0329, device='cuda:0') tensor(0.0929, device='cuda:0') tensor(-1.3813e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.048669
Average KL loss: 0.050953
Average total loss: 0.099622
tensor(0.0329, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(-1.7934e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.047976
Average KL loss: 0.050960
Average total loss: 0.098936
tensor(0.0329, device='cuda:0') tensor(0.0932, device='cuda:0') tensor(-1.6342e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.047769
Average KL loss: 0.050969
Average total loss: 0.098739
tensor(0.0329, device='cuda:0') tensor(0.0933, device='cuda:0') tensor(-1.4267e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.045748
Average KL loss: 0.050960
Average total loss: 0.096708
tensor(0.0328, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-1.0906e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.046832
Average KL loss: 0.050927
Average total loss: 0.097759
tensor(0.0328, device='cuda:0') tensor(0.0935, device='cuda:0') tensor(-1.0653e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.046589
Average KL loss: 0.050930
Average total loss: 0.097519
tensor(0.0328, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(-1.4370e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.046944
Average KL loss: 0.050924
Average total loss: 0.097868
tensor(0.0328, device='cuda:0') tensor(0.0938, device='cuda:0') tensor(-6.4278e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.047474
Average KL loss: 0.050937
Average total loss: 0.098411
tensor(0.0328, device='cuda:0') tensor(0.0939, device='cuda:0') tensor(-1.1828e-12, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.045712
Average KL loss: 0.050931
Average total loss: 0.096643
tensor(0.0328, device='cuda:0') tensor(0.0941, device='cuda:0') tensor(-4.1723e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.045791
Average KL loss: 0.050932
Average total loss: 0.096723
tensor(0.0328, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-9.3989e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.045689
Average KL loss: 0.050915
Average total loss: 0.096604
tensor(0.0328, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(-1.0194e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.045353
Average KL loss: 0.050907
Average total loss: 0.096260
tensor(0.0328, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(-1.4357e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.046084
Average KL loss: 0.050913
Average total loss: 0.096997
tensor(0.0327, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(-8.2490e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.044289
Average KL loss: 0.050910
Average total loss: 0.095199
tensor(0.0327, device='cuda:0') tensor(0.0947, device='cuda:0') tensor(-6.7404e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.045679
Average KL loss: 0.050899
Average total loss: 0.096578
tensor(0.0327, device='cuda:0') tensor(0.0948, device='cuda:0') tensor(-1.2731e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.044900
Average KL loss: 0.050891
Average total loss: 0.095790
tensor(0.0327, device='cuda:0') tensor(0.0949, device='cuda:0') tensor(-6.2221e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.044344
Average KL loss: 0.050883
Average total loss: 0.095227
tensor(0.0327, device='cuda:0') tensor(0.0951, device='cuda:0') tensor(-4.4733e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.044282
Average KL loss: 0.050870
Average total loss: 0.095152
tensor(0.0327, device='cuda:0') tensor(0.0952, device='cuda:0') tensor(-8.5874e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.043447
Average KL loss: 0.050856
Average total loss: 0.094304
tensor(0.0327, device='cuda:0') tensor(0.0953, device='cuda:0') tensor(-6.0111e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.045403
Average KL loss: 0.050862
Average total loss: 0.096265
tensor(0.0327, device='cuda:0') tensor(0.0954, device='cuda:0') tensor(-1.0814e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.045421
Average KL loss: 0.050865
Average total loss: 0.096286
tensor(0.0327, device='cuda:0') tensor(0.0956, device='cuda:0') tensor(-2.4032e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.043446
Average KL loss: 0.050867
Average total loss: 0.094313
tensor(0.0327, device='cuda:0') tensor(0.0957, device='cuda:0') tensor(-1.5594e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.044174
Average KL loss: 0.050866
Average total loss: 0.095040
tensor(0.0327, device='cuda:0') tensor(0.0958, device='cuda:0') tensor(-5.8987e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.043146
Average KL loss: 0.050856
Average total loss: 0.094002
tensor(0.0327, device='cuda:0') tensor(0.0959, device='cuda:0') tensor(-2.7867e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.043164
Average KL loss: 0.050832
Average total loss: 0.093996
tensor(0.0326, device='cuda:0') tensor(0.0960, device='cuda:0') tensor(-7.5731e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.043540
Average KL loss: 0.050813
Average total loss: 0.094353
tensor(0.0326, device='cuda:0') tensor(0.0962, device='cuda:0') tensor(-1.1580e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.043182
Average KL loss: 0.050814
Average total loss: 0.093995
tensor(0.0326, device='cuda:0') tensor(0.0963, device='cuda:0') tensor(-2.8893e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.043683
Average KL loss: 0.050808
Average total loss: 0.094491
tensor(0.0326, device='cuda:0') tensor(0.0964, device='cuda:0') tensor(-1.2101e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.042640
Average KL loss: 0.050802
Average total loss: 0.093442
tensor(0.0326, device='cuda:0') tensor(0.0965, device='cuda:0') tensor(-1.1280e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.041680
Average KL loss: 0.050781
Average total loss: 0.092462
tensor(0.0326, device='cuda:0') tensor(0.0966, device='cuda:0') tensor(-1.5119e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.042927
Average KL loss: 0.050755
Average total loss: 0.093682
tensor(0.0326, device='cuda:0') tensor(0.0967, device='cuda:0') tensor(-1.3021e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.042340
Average KL loss: 0.050745
Average total loss: 0.093085
tensor(0.0325, device='cuda:0') tensor(0.0968, device='cuda:0') tensor(-3.5056e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.041807
Average KL loss: 0.050723
Average total loss: 0.092530
tensor(0.0325, device='cuda:0') tensor(0.0969, device='cuda:0') tensor(-8.2868e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.041741
Average KL loss: 0.050704
Average total loss: 0.092445
tensor(0.0325, device='cuda:0') tensor(0.0970, device='cuda:0') tensor(-1.6256e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.041655
Average KL loss: 0.050689
Average total loss: 0.092344
tensor(0.0325, device='cuda:0') tensor(0.0972, device='cuda:0') tensor(-1.3363e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.042184
Average KL loss: 0.050678
Average total loss: 0.092861
tensor(0.0325, device='cuda:0') tensor(0.0973, device='cuda:0') tensor(-2.2435e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.042078
Average KL loss: 0.050686
Average total loss: 0.092764
tensor(0.0325, device='cuda:0') tensor(0.0974, device='cuda:0') tensor(-1.0345e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.041476
Average KL loss: 0.050675
Average total loss: 0.092151
tensor(0.0325, device='cuda:0') tensor(0.0975, device='cuda:0') tensor(-4.2425e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.041082
Average KL loss: 0.050652
Average total loss: 0.091734
tensor(0.0325, device='cuda:0') tensor(0.0976, device='cuda:0') tensor(-1.0509e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.041475
Average KL loss: 0.050649
Average total loss: 0.092124
tensor(0.0325, device='cuda:0') tensor(0.0978, device='cuda:0') tensor(-8.7394e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.041104
Average KL loss: 0.050631
Average total loss: 0.091735
tensor(0.0325, device='cuda:0') tensor(0.0979, device='cuda:0') tensor(-1.0943e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.041067
Average KL loss: 0.050615
Average total loss: 0.091682
tensor(0.0325, device='cuda:0') tensor(0.0980, device='cuda:0') tensor(-7.5067e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.041835
Average KL loss: 0.050604
Average total loss: 0.092438
tensor(0.0324, device='cuda:0') tensor(0.0981, device='cuda:0') tensor(-8.9917e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.041340
Average KL loss: 0.050606
Average total loss: 0.091946
tensor(0.0325, device='cuda:0') tensor(0.0982, device='cuda:0') tensor(-6.2381e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.040938
Average KL loss: 0.050607
Average total loss: 0.091545
tensor(0.0324, device='cuda:0') tensor(0.0984, device='cuda:0') tensor(2.2028e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.040806
Average KL loss: 0.050595
Average total loss: 0.091401
tensor(0.0324, device='cuda:0') tensor(0.0985, device='cuda:0') tensor(-3.6296e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.041341
Average KL loss: 0.050583
Average total loss: 0.091924
tensor(0.0324, device='cuda:0') tensor(0.0986, device='cuda:0') tensor(-6.1668e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.040002
Average KL loss: 0.050570
Average total loss: 0.090572
tensor(0.0324, device='cuda:0') tensor(0.0987, device='cuda:0') tensor(-2.5691e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.039347
Average KL loss: 0.050543
Average total loss: 0.089890
tensor(0.0324, device='cuda:0') tensor(0.0988, device='cuda:0') tensor(-1.1668e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.040757
Average KL loss: 0.050515
Average total loss: 0.091272
tensor(0.0324, device='cuda:0') tensor(0.0989, device='cuda:0') tensor(1.2919e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.040038
Average KL loss: 0.050517
Average total loss: 0.090554
tensor(0.0324, device='cuda:0') tensor(0.0990, device='cuda:0') tensor(-1.6084e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.040199
Average KL loss: 0.050500
Average total loss: 0.090699
tensor(0.0324, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(4.8694e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.041174
Average KL loss: 0.050480
Average total loss: 0.091654
tensor(0.0324, device='cuda:0') tensor(0.0993, device='cuda:0') tensor(-1.0770e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.042546
Average KL loss: 0.050491
Average total loss: 0.093036
tensor(0.0324, device='cuda:0') tensor(0.0994, device='cuda:0') tensor(-6.2179e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.039804
Average KL loss: 0.050513
Average total loss: 0.090317
tensor(0.0324, device='cuda:0') tensor(0.0996, device='cuda:0') tensor(-1.1481e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.040130
Average KL loss: 0.050491
Average total loss: 0.090621
tensor(0.0324, device='cuda:0') tensor(0.0997, device='cuda:0') tensor(-4.1258e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.040269
Average KL loss: 0.050481
Average total loss: 0.090750
tensor(0.0323, device='cuda:0') tensor(0.0998, device='cuda:0') tensor(4.0079e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.039711
Average KL loss: 0.050466
Average total loss: 0.090176
tensor(0.0323, device='cuda:0') tensor(0.0999, device='cuda:0') tensor(-6.6229e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.039962
Average KL loss: 0.050451
Average total loss: 0.090412
tensor(0.0323, device='cuda:0') tensor(0.1000, device='cuda:0') tensor(4.3404e-11, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.039937
Average KL loss: 0.050429
Average total loss: 0.090366
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-6.3166e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.038872
Average KL loss: 0.050414
Average total loss: 0.089286
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-6.6976e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.039719
Average KL loss: 0.050398
Average total loss: 0.090118
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-5.5544e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.039789
Average KL loss: 0.050384
Average total loss: 0.090174
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(3.9163e-11, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.040595
Average KL loss: 0.050371
Average total loss: 0.090966
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-8.0222e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.039004
Average KL loss: 0.050359
Average total loss: 0.089363
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(8.2300e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.039145
Average KL loss: 0.050347
Average total loss: 0.089491
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-2.8514e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.039408
Average KL loss: 0.050335
Average total loss: 0.089743
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-1.7443e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.039341
Average KL loss: 0.050323
Average total loss: 0.089665
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-1.1972e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.039272
Average KL loss: 0.050313
Average total loss: 0.089585
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-7.1207e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.039743
Average KL loss: 0.050300
Average total loss: 0.090043
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-2.0936e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.039735
Average KL loss: 0.050290
Average total loss: 0.090025
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-7.2333e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.039764
Average KL loss: 0.050280
Average total loss: 0.090045
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-2.1295e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.039280
Average KL loss: 0.050275
Average total loss: 0.089555
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-1.0685e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.039319
Average KL loss: 0.050274
Average total loss: 0.089593
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-4.3820e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.039120
Average KL loss: 0.050272
Average total loss: 0.089392
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-1.2793e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.039629
Average KL loss: 0.050271
Average total loss: 0.089900
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-4.6613e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.039413
Average KL loss: 0.050270
Average total loss: 0.089682
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-9.6588e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.040699
Average KL loss: 0.050269
Average total loss: 0.090968
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-1.5778e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.038634
Average KL loss: 0.050267
Average total loss: 0.088901
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-1.0254e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.038877
Average KL loss: 0.050266
Average total loss: 0.089143
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-3.3220e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.040783
Average KL loss: 0.050265
Average total loss: 0.091048
 Percentile value: 0.4665164053440094
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =     147 /    1728             (  8.51%) | total_pruned =    1581 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     300 /   36864             (  0.81%) | total_pruned =   36564 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     531 /   36864             (  1.44%) | total_pruned =   36333 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     328 /   36864             (  0.89%) | total_pruned =   36536 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     655 /   36864             (  1.78%) | total_pruned =   36209 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4211 /   73728             (  5.71%) | total_pruned =   69517 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    9261 /  147456             (  6.28%) | total_pruned =  138195 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     682 /    8192             (  8.33%) | total_pruned =    7510 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    6581 /  147456             (  4.46%) | total_pruned =  140875 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    6855 /  147456             (  4.65%) | total_pruned =  140601 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   20879 /  294912             (  7.08%) | total_pruned =  274033 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     159 /     256             ( 62.11%) | total_pruned =      97 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   23795 /  589824             (  4.03%) | total_pruned =  566029 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2489 /   32768             (  7.60%) | total_pruned =   30279 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   17446 /  589824             (  2.96%) | total_pruned =  572378 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   16203 /  589824             (  2.75%) | total_pruned =  573621 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      58 /     256             ( 22.66%) | total_pruned =     198 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   46438 / 1179648             (  3.94%) | total_pruned = 1133210 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     351 /     512             ( 68.55%) | total_pruned =     161 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   69525 / 2359296             (  2.95%) | total_pruned = 2289771 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     380 /     512             ( 74.22%) | total_pruned =     132 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     185 /     512             ( 36.13%) | total_pruned =     327 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1878 /  131072             (  1.43%) | total_pruned =  129194 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     168 /     512             ( 32.81%) | total_pruned =     344 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     186 /     512             ( 36.33%) | total_pruned =     326 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   34838 / 2359296             (  1.48%) | total_pruned = 2324458 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     208 /     512             ( 40.62%) | total_pruned =     304 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   78703 / 2359296             (  3.34%) | total_pruned = 2280593 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
linear.weight        | nonzeros =    3701 /    5120             ( 72.29%) | total_pruned =    1419 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 44/100 Loss: 0.018469 Accuracy: 84.84 100.00 % Best test Accuracy: 85.17%
tensor(0.0323, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-2.1116e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.230041
Average KL loss: 0.048186
Average total loss: 0.278227
tensor(0.0316, device='cuda:0') tensor(0.0920, device='cuda:0') tensor(-1.6661e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.213069
Average KL loss: 0.046359
Average total loss: 0.259428
tensor(0.0311, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-1.5817e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.199450
Average KL loss: 0.045312
Average total loss: 0.244762
tensor(0.0306, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-1.7576e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.190948
Average KL loss: 0.044523
Average total loss: 0.235471
tensor(0.0301, device='cuda:0') tensor(0.0842, device='cuda:0') tensor(-1.4121e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.186751
Average KL loss: 0.043931
Average total loss: 0.230683
tensor(0.0298, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(-1.2784e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.181089
Average KL loss: 0.043535
Average total loss: 0.224624
tensor(0.0295, device='cuda:0') tensor(0.0821, device='cuda:0') tensor(-1.5402e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.174352
Average KL loss: 0.043314
Average total loss: 0.217666
tensor(0.0293, device='cuda:0') tensor(0.0816, device='cuda:0') tensor(-1.3476e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.173959
Average KL loss: 0.043225
Average total loss: 0.217184
tensor(0.0292, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(-1.2460e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.164227
Average KL loss: 0.043225
Average total loss: 0.207452
tensor(0.0291, device='cuda:0') tensor(0.0811, device='cuda:0') tensor(-1.2345e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.158749
Average KL loss: 0.043248
Average total loss: 0.201997
tensor(0.0291, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-1.0805e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.159696
Average KL loss: 0.043297
Average total loss: 0.202993
tensor(0.0291, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-9.4457e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.153731
Average KL loss: 0.043358
Average total loss: 0.197089
tensor(0.0291, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(-1.3197e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.148884
Average KL loss: 0.043415
Average total loss: 0.192299
tensor(0.0291, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(-9.5371e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.147505
Average KL loss: 0.043485
Average total loss: 0.190989
tensor(0.0291, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(-8.3710e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.145787
Average KL loss: 0.043558
Average total loss: 0.189345
tensor(0.0291, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-1.1573e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.143710
Average KL loss: 0.043630
Average total loss: 0.187340
tensor(0.0291, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-1.1803e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.140602
Average KL loss: 0.043696
Average total loss: 0.184299
tensor(0.0291, device='cuda:0') tensor(0.0810, device='cuda:0') tensor(-9.8495e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.135858
Average KL loss: 0.043764
Average total loss: 0.179622
tensor(0.0291, device='cuda:0') tensor(0.0811, device='cuda:0') tensor(-5.9608e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.134103
Average KL loss: 0.043833
Average total loss: 0.177936
tensor(0.0291, device='cuda:0') tensor(0.0812, device='cuda:0') tensor(-8.7280e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.131202
Average KL loss: 0.043904
Average total loss: 0.175106
tensor(0.0291, device='cuda:0') tensor(0.0814, device='cuda:0') tensor(-8.6191e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.131139
Average KL loss: 0.043978
Average total loss: 0.175118
tensor(0.0292, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(-7.5853e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.128269
Average KL loss: 0.044045
Average total loss: 0.172314
tensor(0.0292, device='cuda:0') tensor(0.0816, device='cuda:0') tensor(-9.1186e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.125633
Average KL loss: 0.044132
Average total loss: 0.169765
tensor(0.0292, device='cuda:0') tensor(0.0818, device='cuda:0') tensor(-9.2991e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.122553
Average KL loss: 0.044210
Average total loss: 0.166763
tensor(0.0292, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(-6.1970e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.121983
Average KL loss: 0.044287
Average total loss: 0.166270
tensor(0.0293, device='cuda:0') tensor(0.0821, device='cuda:0') tensor(-1.3456e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.119433
Average KL loss: 0.044358
Average total loss: 0.163791
tensor(0.0293, device='cuda:0') tensor(0.0823, device='cuda:0') tensor(-7.0092e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.117437
Average KL loss: 0.044430
Average total loss: 0.161867
tensor(0.0293, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-8.9383e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.116697
Average KL loss: 0.044510
Average total loss: 0.161207
tensor(0.0293, device='cuda:0') tensor(0.0826, device='cuda:0') tensor(-6.8748e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.114228
Average KL loss: 0.044590
Average total loss: 0.158818
tensor(0.0293, device='cuda:0') tensor(0.0828, device='cuda:0') tensor(-6.2194e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.114399
Average KL loss: 0.044657
Average total loss: 0.159056
tensor(0.0294, device='cuda:0') tensor(0.0830, device='cuda:0') tensor(-6.0567e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.110433
Average KL loss: 0.044739
Average total loss: 0.155172
tensor(0.0294, device='cuda:0') tensor(0.0831, device='cuda:0') tensor(-7.0615e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.111213
Average KL loss: 0.044813
Average total loss: 0.156026
tensor(0.0294, device='cuda:0') tensor(0.0833, device='cuda:0') tensor(-7.0229e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.108573
Average KL loss: 0.044896
Average total loss: 0.153469
tensor(0.0294, device='cuda:0') tensor(0.0835, device='cuda:0') tensor(-7.2230e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.104693
Average KL loss: 0.044974
Average total loss: 0.149667
tensor(0.0295, device='cuda:0') tensor(0.0837, device='cuda:0') tensor(-7.1519e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.104404
Average KL loss: 0.045035
Average total loss: 0.149438
tensor(0.0295, device='cuda:0') tensor(0.0839, device='cuda:0') tensor(-6.3816e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.100982
Average KL loss: 0.045098
Average total loss: 0.146080
tensor(0.0295, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(-6.1252e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.103110
Average KL loss: 0.045166
Average total loss: 0.148277
tensor(0.0295, device='cuda:0') tensor(0.0843, device='cuda:0') tensor(-4.5216e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.101310
Average KL loss: 0.045235
Average total loss: 0.146545
tensor(0.0296, device='cuda:0') tensor(0.0845, device='cuda:0') tensor(-5.8808e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.101108
Average KL loss: 0.045318
Average total loss: 0.146426
tensor(0.0296, device='cuda:0') tensor(0.0847, device='cuda:0') tensor(-4.8488e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.096826
Average KL loss: 0.045392
Average total loss: 0.142219
tensor(0.0296, device='cuda:0') tensor(0.0849, device='cuda:0') tensor(-6.8256e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.095770
Average KL loss: 0.045461
Average total loss: 0.141231
tensor(0.0296, device='cuda:0') tensor(0.0851, device='cuda:0') tensor(-5.0214e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.096435
Average KL loss: 0.045532
Average total loss: 0.141968
tensor(0.0297, device='cuda:0') tensor(0.0853, device='cuda:0') tensor(-3.9714e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.094496
Average KL loss: 0.045603
Average total loss: 0.140099
tensor(0.0297, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-6.4054e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.093227
Average KL loss: 0.045670
Average total loss: 0.138896
tensor(0.0297, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-4.4137e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.091798
Average KL loss: 0.045733
Average total loss: 0.137530
tensor(0.0297, device='cuda:0') tensor(0.0858, device='cuda:0') tensor(-5.4798e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.091171
Average KL loss: 0.045790
Average total loss: 0.136961
tensor(0.0298, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-6.4362e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.090795
Average KL loss: 0.045862
Average total loss: 0.136657
tensor(0.0298, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-3.9686e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.087290
Average KL loss: 0.045934
Average total loss: 0.133225
tensor(0.0298, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-4.4184e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.087674
Average KL loss: 0.045994
Average total loss: 0.133668
tensor(0.0298, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(-6.0917e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.086919
Average KL loss: 0.046053
Average total loss: 0.132972
tensor(0.0299, device='cuda:0') tensor(0.0868, device='cuda:0') tensor(-4.4377e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.084080
Average KL loss: 0.046112
Average total loss: 0.130192
tensor(0.0299, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-4.4687e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.085910
Average KL loss: 0.046172
Average total loss: 0.132082
tensor(0.0299, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-5.0251e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.081580
Average KL loss: 0.046233
Average total loss: 0.127813
tensor(0.0299, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-4.7519e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.081837
Average KL loss: 0.046287
Average total loss: 0.128124
tensor(0.0299, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(-5.2604e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.079680
Average KL loss: 0.046332
Average total loss: 0.126012
tensor(0.0299, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-3.5023e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.079708
Average KL loss: 0.046381
Average total loss: 0.126088
tensor(0.0300, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(-4.6709e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.082677
Average KL loss: 0.046432
Average total loss: 0.129108
tensor(0.0300, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(-4.6327e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.080321
Average KL loss: 0.046503
Average total loss: 0.126824
tensor(0.0300, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(-3.2046e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.079021
Average KL loss: 0.046559
Average total loss: 0.125579
tensor(0.0300, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-5.2948e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.076485
Average KL loss: 0.046614
Average total loss: 0.123098
tensor(0.0301, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(-4.5653e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.076354
Average KL loss: 0.046659
Average total loss: 0.123014
tensor(0.0301, device='cuda:0') tensor(0.0889, device='cuda:0') tensor(-3.8135e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.075192
Average KL loss: 0.046702
Average total loss: 0.121894
tensor(0.0301, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(-4.3389e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.076185
Average KL loss: 0.046750
Average total loss: 0.122935
tensor(0.0301, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-3.7719e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.074244
Average KL loss: 0.046802
Average total loss: 0.121045
tensor(0.0301, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-4.8324e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.073857
Average KL loss: 0.046840
Average total loss: 0.120697
tensor(0.0301, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(-4.4467e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.072678
Average KL loss: 0.046896
Average total loss: 0.119573
tensor(0.0301, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(-2.8645e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.071971
Average KL loss: 0.046943
Average total loss: 0.118914
tensor(0.0302, device='cuda:0') tensor(0.0901, device='cuda:0') tensor(-4.8691e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.071802
Average KL loss: 0.046994
Average total loss: 0.118796
tensor(0.0302, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(-5.4366e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.071632
Average KL loss: 0.047031
Average total loss: 0.118663
tensor(0.0302, device='cuda:0') tensor(0.0904, device='cuda:0') tensor(-3.1422e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.069822
Average KL loss: 0.047070
Average total loss: 0.116891
tensor(0.0302, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(-3.1446e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.070362
Average KL loss: 0.047118
Average total loss: 0.117480
tensor(0.0302, device='cuda:0') tensor(0.0908, device='cuda:0') tensor(-2.8177e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.069750
Average KL loss: 0.047168
Average total loss: 0.116918
tensor(0.0303, device='cuda:0') tensor(0.0911, device='cuda:0') tensor(-3.9890e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.067116
Average KL loss: 0.047209
Average total loss: 0.114324
tensor(0.0303, device='cuda:0') tensor(0.0912, device='cuda:0') tensor(-3.6623e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.068183
Average KL loss: 0.047250
Average total loss: 0.115433
tensor(0.0303, device='cuda:0') tensor(0.0914, device='cuda:0') tensor(-2.0656e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.067621
Average KL loss: 0.047289
Average total loss: 0.114909
tensor(0.0303, device='cuda:0') tensor(0.0916, device='cuda:0') tensor(-3.9412e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.067276
Average KL loss: 0.047329
Average total loss: 0.114606
tensor(0.0303, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-2.2407e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.066418
Average KL loss: 0.047376
Average total loss: 0.113794
tensor(0.0303, device='cuda:0') tensor(0.0920, device='cuda:0') tensor(-1.8357e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.065765
Average KL loss: 0.047414
Average total loss: 0.113178
tensor(0.0304, device='cuda:0') tensor(0.0922, device='cuda:0') tensor(-2.1649e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.064387
Average KL loss: 0.047446
Average total loss: 0.111833
tensor(0.0304, device='cuda:0') tensor(0.0924, device='cuda:0') tensor(-2.8941e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.062841
Average KL loss: 0.047469
Average total loss: 0.110310
tensor(0.0304, device='cuda:0') tensor(0.0926, device='cuda:0') tensor(-2.4081e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.063670
Average KL loss: 0.047501
Average total loss: 0.111171
tensor(0.0304, device='cuda:0') tensor(0.0928, device='cuda:0') tensor(-2.7772e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.063327
Average KL loss: 0.047544
Average total loss: 0.110870
tensor(0.0304, device='cuda:0') tensor(0.0929, device='cuda:0') tensor(-1.8013e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.062701
Average KL loss: 0.047583
Average total loss: 0.110284
tensor(0.0304, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(-3.4900e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.062751
Average KL loss: 0.047622
Average total loss: 0.110372
tensor(0.0304, device='cuda:0') tensor(0.0933, device='cuda:0') tensor(-2.1305e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.061102
Average KL loss: 0.047659
Average total loss: 0.108761
tensor(0.0304, device='cuda:0') tensor(0.0935, device='cuda:0') tensor(-2.8265e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.061143
Average KL loss: 0.047683
Average total loss: 0.108826
tensor(0.0305, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(-1.6688e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.061196
Average KL loss: 0.047717
Average total loss: 0.108913
tensor(0.0305, device='cuda:0') tensor(0.0939, device='cuda:0') tensor(-2.2017e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.060553
Average KL loss: 0.047754
Average total loss: 0.108307
tensor(0.0305, device='cuda:0') tensor(0.0941, device='cuda:0') tensor(-4.3849e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.061236
Average KL loss: 0.047782
Average total loss: 0.109018
tensor(0.0305, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(-1.5512e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.058725
Average KL loss: 0.047813
Average total loss: 0.106538
tensor(0.0305, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(-2.8201e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.058525
Average KL loss: 0.047838
Average total loss: 0.106364
tensor(0.0305, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(-2.5920e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.057888
Average KL loss: 0.047859
Average total loss: 0.105747
tensor(0.0305, device='cuda:0') tensor(0.0948, device='cuda:0') tensor(-2.7077e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.058725
Average KL loss: 0.047887
Average total loss: 0.106613
tensor(0.0305, device='cuda:0') tensor(0.0950, device='cuda:0') tensor(-1.8394e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.056655
Average KL loss: 0.047914
Average total loss: 0.104569
tensor(0.0306, device='cuda:0') tensor(0.0952, device='cuda:0') tensor(-2.7679e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.058300
Average KL loss: 0.047935
Average total loss: 0.106235
tensor(0.0306, device='cuda:0') tensor(0.0953, device='cuda:0') tensor(-2.8768e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.057051
Average KL loss: 0.047963
Average total loss: 0.105014
tensor(0.0306, device='cuda:0') tensor(0.0955, device='cuda:0') tensor(-2.3800e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.056847
Average KL loss: 0.047982
Average total loss: 0.104829
tensor(0.0306, device='cuda:0') tensor(0.0957, device='cuda:0') tensor(-2.0132e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.056585
Average KL loss: 0.048009
Average total loss: 0.104594
tensor(0.0306, device='cuda:0') tensor(0.0959, device='cuda:0') tensor(-2.7877e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.056121
Average KL loss: 0.048035
Average total loss: 0.104156
tensor(0.0306, device='cuda:0') tensor(0.0961, device='cuda:0') tensor(-1.9790e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.056342
Average KL loss: 0.048061
Average total loss: 0.104403
tensor(0.0306, device='cuda:0') tensor(0.0962, device='cuda:0') tensor(-2.0625e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.059264
Average KL loss: 0.048085
Average total loss: 0.107349
tensor(0.0306, device='cuda:0') tensor(0.0964, device='cuda:0') tensor(-2.4372e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.054980
Average KL loss: 0.048102
Average total loss: 0.103082
tensor(0.0306, device='cuda:0') tensor(0.0966, device='cuda:0') tensor(-2.0207e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.055980
Average KL loss: 0.048121
Average total loss: 0.104101
tensor(0.0306, device='cuda:0') tensor(0.0968, device='cuda:0') tensor(-3.1843e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.053356
Average KL loss: 0.048151
Average total loss: 0.101507
tensor(0.0307, device='cuda:0') tensor(0.0969, device='cuda:0') tensor(-1.9542e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.052826
Average KL loss: 0.048158
Average total loss: 0.100985
tensor(0.0307, device='cuda:0') tensor(0.0971, device='cuda:0') tensor(-2.6424e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.057677
Average KL loss: 0.048169
Average total loss: 0.105846
tensor(0.0307, device='cuda:0') tensor(0.0973, device='cuda:0') tensor(-1.6467e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.053174
Average KL loss: 0.048198
Average total loss: 0.101372
tensor(0.0307, device='cuda:0') tensor(0.0975, device='cuda:0') tensor(-3.0794e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.052976
Average KL loss: 0.048222
Average total loss: 0.101198
tensor(0.0307, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(-1.6395e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.052718
Average KL loss: 0.048240
Average total loss: 0.100958
tensor(0.0307, device='cuda:0') tensor(0.0978, device='cuda:0') tensor(-1.3750e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.052958
Average KL loss: 0.048245
Average total loss: 0.101203
tensor(0.0307, device='cuda:0') tensor(0.0980, device='cuda:0') tensor(-1.5842e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.051361
Average KL loss: 0.048267
Average total loss: 0.099628
tensor(0.0307, device='cuda:0') tensor(0.0981, device='cuda:0') tensor(-1.7659e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.051578
Average KL loss: 0.048276
Average total loss: 0.099855
tensor(0.0307, device='cuda:0') tensor(0.0983, device='cuda:0') tensor(-1.6988e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.050955
Average KL loss: 0.048295
Average total loss: 0.099251
tensor(0.0307, device='cuda:0') tensor(0.0985, device='cuda:0') tensor(-1.0495e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.051092
Average KL loss: 0.048309
Average total loss: 0.099401
tensor(0.0307, device='cuda:0') tensor(0.0987, device='cuda:0') tensor(-8.2795e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.051346
Average KL loss: 0.048328
Average total loss: 0.099674
tensor(0.0307, device='cuda:0') tensor(0.0989, device='cuda:0') tensor(-1.2065e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.050735
Average KL loss: 0.048340
Average total loss: 0.099075
tensor(0.0307, device='cuda:0') tensor(0.0990, device='cuda:0') tensor(-2.0399e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.049993
Average KL loss: 0.048348
Average total loss: 0.098341
tensor(0.0308, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-1.3279e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.049412
Average KL loss: 0.048371
Average total loss: 0.097783
tensor(0.0308, device='cuda:0') tensor(0.0994, device='cuda:0') tensor(-2.0730e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.049255
Average KL loss: 0.048385
Average total loss: 0.097641
tensor(0.0308, device='cuda:0') tensor(0.0996, device='cuda:0') tensor(-1.1928e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.049513
Average KL loss: 0.048400
Average total loss: 0.097913
tensor(0.0308, device='cuda:0') tensor(0.0997, device='cuda:0') tensor(-1.3521e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.049199
Average KL loss: 0.048412
Average total loss: 0.097611
tensor(0.0308, device='cuda:0') tensor(0.0999, device='cuda:0') tensor(-1.3454e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.048664
Average KL loss: 0.048422
Average total loss: 0.097086
tensor(0.0308, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-1.5247e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.048536
Average KL loss: 0.048438
Average total loss: 0.096975
tensor(0.0308, device='cuda:0') tensor(0.1003, device='cuda:0') tensor(-1.7709e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.048806
Average KL loss: 0.048447
Average total loss: 0.097253
tensor(0.0308, device='cuda:0') tensor(0.1004, device='cuda:0') tensor(-1.5645e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.048281
Average KL loss: 0.048452
Average total loss: 0.096733
tensor(0.0308, device='cuda:0') tensor(0.1006, device='cuda:0') tensor(-2.0259e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.048094
Average KL loss: 0.048459
Average total loss: 0.096552
tensor(0.0308, device='cuda:0') tensor(0.1007, device='cuda:0') tensor(-8.2308e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.047731
Average KL loss: 0.048466
Average total loss: 0.096198
tensor(0.0308, device='cuda:0') tensor(0.1009, device='cuda:0') tensor(-1.9754e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.048029
Average KL loss: 0.048477
Average total loss: 0.096506
tensor(0.0308, device='cuda:0') tensor(0.1011, device='cuda:0') tensor(-1.8857e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.047118
Average KL loss: 0.048485
Average total loss: 0.095603
tensor(0.0308, device='cuda:0') tensor(0.1012, device='cuda:0') tensor(-6.0585e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.047124
Average KL loss: 0.048496
Average total loss: 0.095620
tensor(0.0308, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-1.4143e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.047001
Average KL loss: 0.048508
Average total loss: 0.095509
tensor(0.0309, device='cuda:0') tensor(0.1016, device='cuda:0') tensor(-1.3653e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.045813
Average KL loss: 0.048515
Average total loss: 0.094328
tensor(0.0309, device='cuda:0') tensor(0.1017, device='cuda:0') tensor(-2.2449e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.046868
Average KL loss: 0.048515
Average total loss: 0.095383
tensor(0.0309, device='cuda:0') tensor(0.1019, device='cuda:0') tensor(-2.0481e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.045789
Average KL loss: 0.048520
Average total loss: 0.094310
tensor(0.0309, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-1.0503e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.047164
Average KL loss: 0.048527
Average total loss: 0.095691
tensor(0.0309, device='cuda:0') tensor(0.1023, device='cuda:0') tensor(-2.0379e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.046356
Average KL loss: 0.048543
Average total loss: 0.094899
tensor(0.0309, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-1.8660e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.046027
Average KL loss: 0.048559
Average total loss: 0.094586
tensor(0.0309, device='cuda:0') tensor(0.1026, device='cuda:0') tensor(-9.7339e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.045344
Average KL loss: 0.048570
Average total loss: 0.093915
tensor(0.0309, device='cuda:0') tensor(0.1028, device='cuda:0') tensor(-1.5077e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.045360
Average KL loss: 0.048577
Average total loss: 0.093938
tensor(0.0309, device='cuda:0') tensor(0.1029, device='cuda:0') tensor(-8.1809e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.047562
Average KL loss: 0.048584
Average total loss: 0.096147
tensor(0.0309, device='cuda:0') tensor(0.1031, device='cuda:0') tensor(-7.0044e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.044429
Average KL loss: 0.048593
Average total loss: 0.093022
tensor(0.0309, device='cuda:0') tensor(0.1033, device='cuda:0') tensor(-6.2446e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.044991
Average KL loss: 0.048596
Average total loss: 0.093587
tensor(0.0309, device='cuda:0') tensor(0.1035, device='cuda:0') tensor(-2.3661e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.045018
Average KL loss: 0.048604
Average total loss: 0.093622
tensor(0.0309, device='cuda:0') tensor(0.1036, device='cuda:0') tensor(-1.2235e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.044644
Average KL loss: 0.048615
Average total loss: 0.093260
tensor(0.0309, device='cuda:0') tensor(0.1038, device='cuda:0') tensor(-7.8587e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.043825
Average KL loss: 0.048619
Average total loss: 0.092444
tensor(0.0309, device='cuda:0') tensor(0.1040, device='cuda:0') tensor(-3.7137e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.043772
Average KL loss: 0.048622
Average total loss: 0.092395
tensor(0.0309, device='cuda:0') tensor(0.1041, device='cuda:0') tensor(-2.8297e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.043884
Average KL loss: 0.048624
Average total loss: 0.092508
tensor(0.0309, device='cuda:0') tensor(0.1043, device='cuda:0') tensor(-1.3906e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.043941
Average KL loss: 0.048630
Average total loss: 0.092570
tensor(0.0309, device='cuda:0') tensor(0.1045, device='cuda:0') tensor(-1.2869e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.044004
Average KL loss: 0.048632
Average total loss: 0.092636
tensor(0.0310, device='cuda:0') tensor(0.1046, device='cuda:0') tensor(-7.7752e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.043383
Average KL loss: 0.048644
Average total loss: 0.092027
tensor(0.0310, device='cuda:0') tensor(0.1048, device='cuda:0') tensor(-4.5677e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.043632
Average KL loss: 0.048651
Average total loss: 0.092283
tensor(0.0310, device='cuda:0') tensor(0.1050, device='cuda:0') tensor(-8.2944e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.043240
Average KL loss: 0.048655
Average total loss: 0.091895
tensor(0.0310, device='cuda:0') tensor(0.1051, device='cuda:0') tensor(-4.6740e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.042771
Average KL loss: 0.048661
Average total loss: 0.091432
tensor(0.0310, device='cuda:0') tensor(0.1053, device='cuda:0') tensor(-5.5283e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.042076
Average KL loss: 0.048660
Average total loss: 0.090737
tensor(0.0310, device='cuda:0') tensor(0.1055, device='cuda:0') tensor(-7.4786e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.043026
Average KL loss: 0.048657
Average total loss: 0.091683
tensor(0.0310, device='cuda:0') tensor(0.1056, device='cuda:0') tensor(-7.4008e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.041658
Average KL loss: 0.048661
Average total loss: 0.090319
tensor(0.0310, device='cuda:0') tensor(0.1058, device='cuda:0') tensor(-9.5788e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.042492
Average KL loss: 0.048657
Average total loss: 0.091149
tensor(0.0310, device='cuda:0') tensor(0.1059, device='cuda:0') tensor(-1.0991e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.041991
Average KL loss: 0.048662
Average total loss: 0.090653
tensor(0.0310, device='cuda:0') tensor(0.1061, device='cuda:0') tensor(-2.1904e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.041895
Average KL loss: 0.048663
Average total loss: 0.090558
tensor(0.0310, device='cuda:0') tensor(0.1063, device='cuda:0') tensor(-1.2195e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.041194
Average KL loss: 0.048661
Average total loss: 0.089855
tensor(0.0310, device='cuda:0') tensor(0.1064, device='cuda:0') tensor(-8.1398e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.042137
Average KL loss: 0.048653
Average total loss: 0.090790
tensor(0.0310, device='cuda:0') tensor(0.1066, device='cuda:0') tensor(-9.5351e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.041315
Average KL loss: 0.048658
Average total loss: 0.089973
tensor(0.0310, device='cuda:0') tensor(0.1068, device='cuda:0') tensor(-3.9874e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.041290
Average KL loss: 0.048649
Average total loss: 0.089939
tensor(0.0310, device='cuda:0') tensor(0.1069, device='cuda:0') tensor(-6.5201e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.041136
Average KL loss: 0.048651
Average total loss: 0.089787
tensor(0.0311, device='cuda:0') tensor(0.1071, device='cuda:0') tensor(1.3027e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.041011
Average KL loss: 0.048646
Average total loss: 0.089657
tensor(0.0310, device='cuda:0') tensor(0.1072, device='cuda:0') tensor(-8.6545e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.041991
Average KL loss: 0.048643
Average total loss: 0.090634
tensor(0.0311, device='cuda:0') tensor(0.1074, device='cuda:0') tensor(-2.8445e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.040450
Average KL loss: 0.048649
Average total loss: 0.089099
tensor(0.0311, device='cuda:0') tensor(0.1076, device='cuda:0') tensor(-4.7548e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.041496
Average KL loss: 0.048649
Average total loss: 0.090145
tensor(0.0311, device='cuda:0') tensor(0.1078, device='cuda:0') tensor(-3.6406e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.040953
Average KL loss: 0.048660
Average total loss: 0.089614
tensor(0.0311, device='cuda:0') tensor(0.1079, device='cuda:0') tensor(-7.1239e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.040651
Average KL loss: 0.048650
Average total loss: 0.089301
tensor(0.0311, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-6.4486e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.040858
Average KL loss: 0.048658
Average total loss: 0.089517
tensor(0.0311, device='cuda:0') tensor(0.1083, device='cuda:0') tensor(-4.9430e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.040558
Average KL loss: 0.048648
Average total loss: 0.089206
tensor(0.0311, device='cuda:0') tensor(0.1084, device='cuda:0') tensor(-1.0453e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.041544
Average KL loss: 0.048654
Average total loss: 0.090198
tensor(0.0311, device='cuda:0') tensor(0.1086, device='cuda:0') tensor(-7.7432e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.039954
Average KL loss: 0.048667
Average total loss: 0.088621
tensor(0.0311, device='cuda:0') tensor(0.1088, device='cuda:0') tensor(-5.7420e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.039410
Average KL loss: 0.048655
Average total loss: 0.088066
tensor(0.0311, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-1.1400e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.040324
Average KL loss: 0.048652
Average total loss: 0.088976
tensor(0.0311, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(-5.0967e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.039008
Average KL loss: 0.048648
Average total loss: 0.087656
tensor(0.0311, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(-7.6017e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.039852
Average KL loss: 0.048635
Average total loss: 0.088487
tensor(0.0311, device='cuda:0') tensor(0.1094, device='cuda:0') tensor(-1.0717e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.038784
Average KL loss: 0.048629
Average total loss: 0.087414
tensor(0.0311, device='cuda:0') tensor(0.1095, device='cuda:0') tensor(-9.3325e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.040371
Average KL loss: 0.048618
Average total loss: 0.088989
tensor(0.0311, device='cuda:0') tensor(0.1097, device='cuda:0') tensor(-4.2777e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.038992
Average KL loss: 0.048618
Average total loss: 0.087610
tensor(0.0311, device='cuda:0') tensor(0.1098, device='cuda:0') tensor(-4.8475e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.039700
Average KL loss: 0.048618
Average total loss: 0.088318
tensor(0.0311, device='cuda:0') tensor(0.1100, device='cuda:0') tensor(-1.2519e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.039358
Average KL loss: 0.048615
Average total loss: 0.087973
tensor(0.0311, device='cuda:0') tensor(0.1102, device='cuda:0') tensor(-5.0926e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.039036
Average KL loss: 0.048615
Average total loss: 0.087651
tensor(0.0311, device='cuda:0') tensor(0.1103, device='cuda:0') tensor(-2.5408e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.038750
Average KL loss: 0.048607
Average total loss: 0.087357
tensor(0.0311, device='cuda:0') tensor(0.1105, device='cuda:0') tensor(-1.3116e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.038829
Average KL loss: 0.048603
Average total loss: 0.087432
tensor(0.0311, device='cuda:0') tensor(0.1106, device='cuda:0') tensor(-4.6304e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.039157
Average KL loss: 0.048613
Average total loss: 0.087770
tensor(0.0312, device='cuda:0') tensor(0.1108, device='cuda:0') tensor(-9.1301e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.038908
Average KL loss: 0.048615
Average total loss: 0.087522
tensor(0.0312, device='cuda:0') tensor(0.1110, device='cuda:0') tensor(-1.8108e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.038939
Average KL loss: 0.048615
Average total loss: 0.087554
tensor(0.0312, device='cuda:0') tensor(0.1111, device='cuda:0') tensor(-4.8414e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.038166
Average KL loss: 0.048605
Average total loss: 0.086771
tensor(0.0312, device='cuda:0') tensor(0.1113, device='cuda:0') tensor(1.8590e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.038750
Average KL loss: 0.048597
Average total loss: 0.087347
tensor(0.0312, device='cuda:0') tensor(0.1114, device='cuda:0') tensor(-1.7592e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.038152
Average KL loss: 0.048589
Average total loss: 0.086741
tensor(0.0312, device='cuda:0') tensor(0.1116, device='cuda:0') tensor(-8.5333e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.038970
Average KL loss: 0.048587
Average total loss: 0.087557
tensor(0.0312, device='cuda:0') tensor(0.1117, device='cuda:0') tensor(-7.0089e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.038150
Average KL loss: 0.048577
Average total loss: 0.086727
tensor(0.0312, device='cuda:0') tensor(0.1119, device='cuda:0') tensor(-1.3244e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.038803
Average KL loss: 0.048577
Average total loss: 0.087381
tensor(0.0312, device='cuda:0') tensor(0.1120, device='cuda:0') tensor(-3.7925e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.038558
Average KL loss: 0.048577
Average total loss: 0.087135
tensor(0.0312, device='cuda:0') tensor(0.1122, device='cuda:0') tensor(-3.5531e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.037971
Average KL loss: 0.048579
Average total loss: 0.086550
tensor(0.0312, device='cuda:0') tensor(0.1124, device='cuda:0') tensor(-6.7853e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.038162
Average KL loss: 0.048573
Average total loss: 0.086735
tensor(0.0312, device='cuda:0') tensor(0.1125, device='cuda:0') tensor(-6.8439e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.037577
Average KL loss: 0.048564
Average total loss: 0.086141
tensor(0.0312, device='cuda:0') tensor(0.1127, device='cuda:0') tensor(-1.5405e-12, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.038033
Average KL loss: 0.048563
Average total loss: 0.086595
 Percentile value: 1.4599552154541016
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =     147 /    1728             (  8.51%) | total_pruned =    1581 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     204 /   36864             (  0.55%) | total_pruned =   36660 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     270 /   36864             (  0.73%) | total_pruned =   36594 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     196 /   36864             (  0.53%) | total_pruned =   36668 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     423 /   36864             (  1.15%) | total_pruned =   36441 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2687 /   73728             (  3.64%) | total_pruned =   71041 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6312 /  147456             (  4.28%) | total_pruned =  141144 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     400 /    8192             (  4.88%) | total_pruned =    7792 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4489 /  147456             (  3.04%) | total_pruned =  142967 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4534 /  147456             (  3.07%) | total_pruned =  142922 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   13531 /  294912             (  4.59%) | total_pruned =  281381 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     145 /     256             ( 56.64%) | total_pruned =     111 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   15358 /  589824             (  2.60%) | total_pruned =  574466 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1785 /   32768             (  5.45%) | total_pruned =   30983 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     106 /     256             ( 41.41%) | total_pruned =     150 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   10858 /  589824             (  1.84%) | total_pruned =  578966 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    9241 /  589824             (  1.57%) | total_pruned =  580583 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     131 /     256             ( 51.17%) | total_pruned =     125 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      57 /     256             ( 22.27%) | total_pruned =     199 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   28606 / 1179648             (  2.42%) | total_pruned = 1151042 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     343 /     512             ( 66.99%) | total_pruned =     169 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   28804 / 2359296             (  1.22%) | total_pruned = 2330492 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     308 /     512             ( 60.16%) | total_pruned =     204 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     157 /     512             ( 30.66%) | total_pruned =     355 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     804 /  131072             (  0.61%) | total_pruned =  130268 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   12775 / 2359296             (  0.54%) | total_pruned = 2346521 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   26913 / 2359296             (  1.14%) | total_pruned = 2332383 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     343 /     512             ( 66.99%) | total_pruned =     169 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     326 /     512             ( 63.67%) | total_pruned =     186 | shape = torch.Size([512])
linear.weight        | nonzeros =    2941 /    5120             ( 57.44%) | total_pruned =    2179 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 44/100 Loss: 0.028768 Accuracy: 84.81 99.99 % Best test Accuracy: 85.04%
tensor(0.0312, device='cuda:0') tensor(0.1128, device='cuda:0') tensor(-6.6829e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.117445
Average KL loss: 0.047088
Average total loss: 0.164533
tensor(0.0300, device='cuda:0') tensor(0.1046, device='cuda:0') tensor(-6.9111e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.114732
Average KL loss: 0.045931
Average total loss: 0.160663
tensor(0.0295, device='cuda:0') tensor(0.1012, device='cuda:0') tensor(-7.0525e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.110529
Average KL loss: 0.045299
Average total loss: 0.155829
tensor(0.0292, device='cuda:0') tensor(0.0989, device='cuda:0') tensor(-9.7493e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.112853
Average KL loss: 0.044798
Average total loss: 0.157652
tensor(0.0289, device='cuda:0') tensor(0.0973, device='cuda:0') tensor(-9.0793e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.104070
Average KL loss: 0.044380
Average total loss: 0.148450
tensor(0.0286, device='cuda:0') tensor(0.0961, device='cuda:0') tensor(-7.5546e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.103670
Average KL loss: 0.044051
Average total loss: 0.147722
tensor(0.0284, device='cuda:0') tensor(0.0952, device='cuda:0') tensor(-8.2584e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.100515
Average KL loss: 0.043821
Average total loss: 0.144336
tensor(0.0282, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(-6.6333e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.097652
Average KL loss: 0.043685
Average total loss: 0.141337
tensor(0.0281, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-5.2273e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.096607
Average KL loss: 0.043611
Average total loss: 0.140218
tensor(0.0280, device='cuda:0') tensor(0.0940, device='cuda:0') tensor(-3.5769e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.094442
Average KL loss: 0.043579
Average total loss: 0.138022
tensor(0.0280, device='cuda:0') tensor(0.0938, device='cuda:0') tensor(-4.1268e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.091854
Average KL loss: 0.043564
Average total loss: 0.135418
tensor(0.0280, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(-4.6293e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.090681
Average KL loss: 0.043560
Average total loss: 0.134241
tensor(0.0279, device='cuda:0') tensor(0.0936, device='cuda:0') tensor(-5.5976e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.090587
Average KL loss: 0.043569
Average total loss: 0.134155
tensor(0.0279, device='cuda:0') tensor(0.0936, device='cuda:0') tensor(-5.6880e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.087814
Average KL loss: 0.043576
Average total loss: 0.131390
tensor(0.0279, device='cuda:0') tensor(0.0936, device='cuda:0') tensor(-3.8356e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.084163
Average KL loss: 0.043591
Average total loss: 0.127754
tensor(0.0279, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(-5.3629e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.087085
Average KL loss: 0.043606
Average total loss: 0.130691
tensor(0.0279, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(-3.5627e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.082283
Average KL loss: 0.043622
Average total loss: 0.125905
tensor(0.0279, device='cuda:0') tensor(0.0938, device='cuda:0') tensor(-5.0989e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.082227
Average KL loss: 0.043631
Average total loss: 0.125858
tensor(0.0279, device='cuda:0') tensor(0.0938, device='cuda:0') tensor(-5.7948e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.081025
Average KL loss: 0.043644
Average total loss: 0.124669
tensor(0.0279, device='cuda:0') tensor(0.0939, device='cuda:0') tensor(-4.0812e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.080403
Average KL loss: 0.043659
Average total loss: 0.124062
tensor(0.0279, device='cuda:0') tensor(0.0940, device='cuda:0') tensor(-5.7568e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.080706
Average KL loss: 0.043680
Average total loss: 0.124386
tensor(0.0279, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-2.6739e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.077434
Average KL loss: 0.043704
Average total loss: 0.121138
tensor(0.0279, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(-4.2766e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.077053
Average KL loss: 0.043723
Average total loss: 0.120776
tensor(0.0279, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(-4.0236e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.074948
Average KL loss: 0.043744
Average total loss: 0.118692
tensor(0.0279, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(-4.5978e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.074482
Average KL loss: 0.043762
Average total loss: 0.118244
tensor(0.0279, device='cuda:0') tensor(0.0947, device='cuda:0') tensor(-3.7622e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.074290
Average KL loss: 0.043780
Average total loss: 0.118070
tensor(0.0279, device='cuda:0') tensor(0.0948, device='cuda:0') tensor(-2.5210e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.071987
Average KL loss: 0.043798
Average total loss: 0.115785
tensor(0.0279, device='cuda:0') tensor(0.0950, device='cuda:0') tensor(-2.9315e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.072045
Average KL loss: 0.043813
Average total loss: 0.115859
tensor(0.0279, device='cuda:0') tensor(0.0951, device='cuda:0') tensor(-2.9677e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.070908
Average KL loss: 0.043835
Average total loss: 0.114744
tensor(0.0279, device='cuda:0') tensor(0.0953, device='cuda:0') tensor(-3.9604e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.069474
Average KL loss: 0.043845
Average total loss: 0.113319
tensor(0.0279, device='cuda:0') tensor(0.0954, device='cuda:0') tensor(-3.9099e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.068879
Average KL loss: 0.043866
Average total loss: 0.112745
tensor(0.0279, device='cuda:0') tensor(0.0956, device='cuda:0') tensor(-3.6656e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.069590
Average KL loss: 0.043893
Average total loss: 0.113484
tensor(0.0280, device='cuda:0') tensor(0.0957, device='cuda:0') tensor(-2.1557e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.065631
Average KL loss: 0.043914
Average total loss: 0.109545
tensor(0.0280, device='cuda:0') tensor(0.0959, device='cuda:0') tensor(-1.9614e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.068344
Average KL loss: 0.043927
Average total loss: 0.112270
tensor(0.0280, device='cuda:0') tensor(0.0961, device='cuda:0') tensor(-2.7833e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.066173
Average KL loss: 0.043945
Average total loss: 0.110118
tensor(0.0280, device='cuda:0') tensor(0.0962, device='cuda:0') tensor(-3.4946e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.064800
Average KL loss: 0.043967
Average total loss: 0.108767
tensor(0.0280, device='cuda:0') tensor(0.0964, device='cuda:0') tensor(-2.3341e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.066186
Average KL loss: 0.043981
Average total loss: 0.110167
tensor(0.0280, device='cuda:0') tensor(0.0965, device='cuda:0') tensor(-4.1336e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.063347
Average KL loss: 0.044007
Average total loss: 0.107355
tensor(0.0280, device='cuda:0') tensor(0.0967, device='cuda:0') tensor(-4.6736e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.063511
Average KL loss: 0.044029
Average total loss: 0.107539
tensor(0.0280, device='cuda:0') tensor(0.0969, device='cuda:0') tensor(-2.3189e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.062748
Average KL loss: 0.044047
Average total loss: 0.106795
tensor(0.0280, device='cuda:0') tensor(0.0971, device='cuda:0') tensor(-3.2634e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.061078
Average KL loss: 0.044064
Average total loss: 0.105142
tensor(0.0280, device='cuda:0') tensor(0.0972, device='cuda:0') tensor(-2.8635e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.060510
Average KL loss: 0.044073
Average total loss: 0.104583
tensor(0.0280, device='cuda:0') tensor(0.0974, device='cuda:0') tensor(-1.3863e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.061084
Average KL loss: 0.044091
Average total loss: 0.105175
tensor(0.0280, device='cuda:0') tensor(0.0976, device='cuda:0') tensor(-2.8819e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.059587
Average KL loss: 0.044108
Average total loss: 0.103695
tensor(0.0280, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(-3.2061e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.063304
Average KL loss: 0.044125
Average total loss: 0.107429
tensor(0.0281, device='cuda:0') tensor(0.0979, device='cuda:0') tensor(-3.3919e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.059373
Average KL loss: 0.044139
Average total loss: 0.103512
tensor(0.0281, device='cuda:0') tensor(0.0981, device='cuda:0') tensor(-2.8552e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.058840
Average KL loss: 0.044149
Average total loss: 0.102989
tensor(0.0281, device='cuda:0') tensor(0.0982, device='cuda:0') tensor(-2.8562e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.058145
Average KL loss: 0.044160
Average total loss: 0.102306
tensor(0.0281, device='cuda:0') tensor(0.0984, device='cuda:0') tensor(-2.6911e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.056681
Average KL loss: 0.044171
Average total loss: 0.100852
tensor(0.0281, device='cuda:0') tensor(0.0986, device='cuda:0') tensor(-2.8762e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.056953
Average KL loss: 0.044178
Average total loss: 0.101131
tensor(0.0281, device='cuda:0') tensor(0.0987, device='cuda:0') tensor(-1.9956e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.056781
Average KL loss: 0.044196
Average total loss: 0.100977
tensor(0.0281, device='cuda:0') tensor(0.0989, device='cuda:0') tensor(-2.4706e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.054912
Average KL loss: 0.044214
Average total loss: 0.099126
tensor(0.0281, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-2.5587e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.054749
Average KL loss: 0.044223
Average total loss: 0.098972
tensor(0.0281, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-1.7913e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.054489
Average KL loss: 0.044227
Average total loss: 0.098716
tensor(0.0281, device='cuda:0') tensor(0.0994, device='cuda:0') tensor(-2.3691e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.054387
Average KL loss: 0.044237
Average total loss: 0.098623
tensor(0.0281, device='cuda:0') tensor(0.0996, device='cuda:0') tensor(-3.3783e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.053426
Average KL loss: 0.044246
Average total loss: 0.097672
tensor(0.0281, device='cuda:0') tensor(0.0997, device='cuda:0') tensor(-2.2332e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.055046
Average KL loss: 0.044255
Average total loss: 0.099301
tensor(0.0281, device='cuda:0') tensor(0.0999, device='cuda:0') tensor(-2.3583e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.052783
Average KL loss: 0.044266
Average total loss: 0.097049
tensor(0.0281, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-2.2166e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.052760
Average KL loss: 0.044279
Average total loss: 0.097039
tensor(0.0282, device='cuda:0') tensor(0.1003, device='cuda:0') tensor(-1.7409e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.053180
Average KL loss: 0.044297
Average total loss: 0.097477
tensor(0.0282, device='cuda:0') tensor(0.1004, device='cuda:0') tensor(-1.8577e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.051823
Average KL loss: 0.044301
Average total loss: 0.096123
tensor(0.0282, device='cuda:0') tensor(0.1006, device='cuda:0') tensor(-9.3950e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.051043
Average KL loss: 0.044306
Average total loss: 0.095349
tensor(0.0282, device='cuda:0') tensor(0.1008, device='cuda:0') tensor(-4.1265e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.051570
Average KL loss: 0.044309
Average total loss: 0.095879
tensor(0.0282, device='cuda:0') tensor(0.1009, device='cuda:0') tensor(-2.7384e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.050520
Average KL loss: 0.044319
Average total loss: 0.094839
tensor(0.0282, device='cuda:0') tensor(0.1011, device='cuda:0') tensor(-1.8659e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.049865
Average KL loss: 0.044327
Average total loss: 0.094191
tensor(0.0282, device='cuda:0') tensor(0.1013, device='cuda:0') tensor(-1.3741e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.049352
Average KL loss: 0.044330
Average total loss: 0.093682
tensor(0.0282, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-2.2715e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.048904
Average KL loss: 0.044339
Average total loss: 0.093242
tensor(0.0282, device='cuda:0') tensor(0.1016, device='cuda:0') tensor(-1.0537e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.049792
Average KL loss: 0.044345
Average total loss: 0.094137
tensor(0.0282, device='cuda:0') tensor(0.1018, device='cuda:0') tensor(-2.1788e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.048492
Average KL loss: 0.044348
Average total loss: 0.092840
tensor(0.0282, device='cuda:0') tensor(0.1019, device='cuda:0') tensor(-1.3371e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.049743
Average KL loss: 0.044351
Average total loss: 0.094093
tensor(0.0282, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-1.4667e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.047490
Average KL loss: 0.044358
Average total loss: 0.091848
tensor(0.0282, device='cuda:0') tensor(0.1023, device='cuda:0') tensor(-1.7581e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.049070
Average KL loss: 0.044361
Average total loss: 0.093431
tensor(0.0282, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-1.9892e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.047816
Average KL loss: 0.044372
Average total loss: 0.092189
tensor(0.0282, device='cuda:0') tensor(0.1026, device='cuda:0') tensor(-1.5933e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.046797
Average KL loss: 0.044375
Average total loss: 0.091172
tensor(0.0282, device='cuda:0') tensor(0.1028, device='cuda:0') tensor(-9.5969e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.048014
Average KL loss: 0.044382
Average total loss: 0.092395
tensor(0.0283, device='cuda:0') tensor(0.1029, device='cuda:0') tensor(-2.3703e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.046791
Average KL loss: 0.044387
Average total loss: 0.091178
tensor(0.0283, device='cuda:0') tensor(0.1031, device='cuda:0') tensor(-1.1222e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.046294
Average KL loss: 0.044391
Average total loss: 0.090685
tensor(0.0283, device='cuda:0') tensor(0.1033, device='cuda:0') tensor(-1.5235e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.045648
Average KL loss: 0.044392
Average total loss: 0.090040
tensor(0.0283, device='cuda:0') tensor(0.1034, device='cuda:0') tensor(-2.3934e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.045144
Average KL loss: 0.044389
Average total loss: 0.089533
tensor(0.0283, device='cuda:0') tensor(0.1036, device='cuda:0') tensor(-1.3726e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.046718
Average KL loss: 0.044395
Average total loss: 0.091114
tensor(0.0283, device='cuda:0') tensor(0.1038, device='cuda:0') tensor(-1.6733e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.044362
Average KL loss: 0.044397
Average total loss: 0.088759
tensor(0.0283, device='cuda:0') tensor(0.1039, device='cuda:0') tensor(-9.0311e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.045063
Average KL loss: 0.044399
Average total loss: 0.089462
tensor(0.0283, device='cuda:0') tensor(0.1041, device='cuda:0') tensor(-1.1687e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.045365
Average KL loss: 0.044403
Average total loss: 0.089768
tensor(0.0283, device='cuda:0') tensor(0.1043, device='cuda:0') tensor(-8.7173e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.045629
Average KL loss: 0.044408
Average total loss: 0.090037
tensor(0.0283, device='cuda:0') tensor(0.1044, device='cuda:0') tensor(-1.6272e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.044088
Average KL loss: 0.044414
Average total loss: 0.088502
tensor(0.0283, device='cuda:0') tensor(0.1046, device='cuda:0') tensor(-1.2703e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.045457
Average KL loss: 0.044415
Average total loss: 0.089873
tensor(0.0283, device='cuda:0') tensor(0.1048, device='cuda:0') tensor(-1.3458e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.043338
Average KL loss: 0.044421
Average total loss: 0.087759
tensor(0.0283, device='cuda:0') tensor(0.1050, device='cuda:0') tensor(-9.9724e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.043993
Average KL loss: 0.044422
Average total loss: 0.088415
tensor(0.0283, device='cuda:0') tensor(0.1052, device='cuda:0') tensor(-1.0652e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.044018
Average KL loss: 0.044423
Average total loss: 0.088442
tensor(0.0284, device='cuda:0') tensor(0.1053, device='cuda:0') tensor(-1.2341e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.043012
Average KL loss: 0.044427
Average total loss: 0.087439
tensor(0.0284, device='cuda:0') tensor(0.1055, device='cuda:0') tensor(-2.1613e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.042803
Average KL loss: 0.044423
Average total loss: 0.087226
tensor(0.0284, device='cuda:0') tensor(0.1057, device='cuda:0') tensor(-1.3968e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.042809
Average KL loss: 0.044419
Average total loss: 0.087228
tensor(0.0284, device='cuda:0') tensor(0.1058, device='cuda:0') tensor(-7.1362e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.041880
Average KL loss: 0.044417
Average total loss: 0.086298
tensor(0.0284, device='cuda:0') tensor(0.1060, device='cuda:0') tensor(-2.6822e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.042808
Average KL loss: 0.044413
Average total loss: 0.087221
tensor(0.0284, device='cuda:0') tensor(0.1062, device='cuda:0') tensor(-2.4761e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.043145
Average KL loss: 0.044413
Average total loss: 0.087558
tensor(0.0284, device='cuda:0') tensor(0.1063, device='cuda:0') tensor(-9.0860e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.041781
Average KL loss: 0.044416
Average total loss: 0.086197
tensor(0.0284, device='cuda:0') tensor(0.1065, device='cuda:0') tensor(-1.3510e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.041501
Average KL loss: 0.044415
Average total loss: 0.085916
tensor(0.0284, device='cuda:0') tensor(0.1066, device='cuda:0') tensor(-1.0008e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.040730
Average KL loss: 0.044409
Average total loss: 0.085139
tensor(0.0284, device='cuda:0') tensor(0.1068, device='cuda:0') tensor(-1.3245e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.040882
Average KL loss: 0.044403
Average total loss: 0.085285
tensor(0.0284, device='cuda:0') tensor(0.1069, device='cuda:0') tensor(-8.9524e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.041095
Average KL loss: 0.044400
Average total loss: 0.085495
tensor(0.0284, device='cuda:0') tensor(0.1071, device='cuda:0') tensor(-1.0209e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.041256
Average KL loss: 0.044395
Average total loss: 0.085651
tensor(0.0284, device='cuda:0') tensor(0.1072, device='cuda:0') tensor(-5.3069e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.040949
Average KL loss: 0.044388
Average total loss: 0.085337
tensor(0.0284, device='cuda:0') tensor(0.1074, device='cuda:0') tensor(-1.0782e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.040438
Average KL loss: 0.044389
Average total loss: 0.084827
tensor(0.0284, device='cuda:0') tensor(0.1076, device='cuda:0') tensor(-1.3402e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.040672
Average KL loss: 0.044385
Average total loss: 0.085057
tensor(0.0284, device='cuda:0') tensor(0.1077, device='cuda:0') tensor(-9.0986e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.040746
Average KL loss: 0.044386
Average total loss: 0.085132
tensor(0.0284, device='cuda:0') tensor(0.1079, device='cuda:0') tensor(-1.0982e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.040409
Average KL loss: 0.044388
Average total loss: 0.084797
tensor(0.0284, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-7.8216e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.039780
Average KL loss: 0.044382
Average total loss: 0.084163
tensor(0.0284, device='cuda:0') tensor(0.1082, device='cuda:0') tensor(-1.1020e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.039503
Average KL loss: 0.044377
Average total loss: 0.083880
tensor(0.0284, device='cuda:0') tensor(0.1084, device='cuda:0') tensor(-1.2929e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.039400
Average KL loss: 0.044373
Average total loss: 0.083773
tensor(0.0284, device='cuda:0') tensor(0.1085, device='cuda:0') tensor(-6.4988e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.039671
Average KL loss: 0.044364
Average total loss: 0.084035
tensor(0.0284, device='cuda:0') tensor(0.1087, device='cuda:0') tensor(-1.1994e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.039878
Average KL loss: 0.044357
Average total loss: 0.084235
tensor(0.0285, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-1.6842e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.038675
Average KL loss: 0.044356
Average total loss: 0.083030
tensor(0.0285, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-1.0162e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.039074
Average KL loss: 0.044352
Average total loss: 0.083427
tensor(0.0285, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(-5.8084e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.038691
Average KL loss: 0.044350
Average total loss: 0.083040
tensor(0.0285, device='cuda:0') tensor(0.1094, device='cuda:0') tensor(-6.0823e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.039058
Average KL loss: 0.044346
Average total loss: 0.083404
tensor(0.0285, device='cuda:0') tensor(0.1096, device='cuda:0') tensor(-6.6675e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.039353
Average KL loss: 0.044345
Average total loss: 0.083698
tensor(0.0285, device='cuda:0') tensor(0.1097, device='cuda:0') tensor(-5.1762e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.039085
Average KL loss: 0.044343
Average total loss: 0.083429
tensor(0.0285, device='cuda:0') tensor(0.1099, device='cuda:0') tensor(-5.8708e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.038627
Average KL loss: 0.044343
Average total loss: 0.082969
tensor(0.0285, device='cuda:0') tensor(0.1101, device='cuda:0') tensor(-3.2289e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.038981
Average KL loss: 0.044346
Average total loss: 0.083326
tensor(0.0285, device='cuda:0') tensor(0.1103, device='cuda:0') tensor(-1.1726e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.038080
Average KL loss: 0.044345
Average total loss: 0.082425
tensor(0.0285, device='cuda:0') tensor(0.1105, device='cuda:0') tensor(-6.7828e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.038053
Average KL loss: 0.044342
Average total loss: 0.082395
tensor(0.0285, device='cuda:0') tensor(0.1106, device='cuda:0') tensor(-5.5819e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.037210
Average KL loss: 0.044334
Average total loss: 0.081545
tensor(0.0285, device='cuda:0') tensor(0.1108, device='cuda:0') tensor(-1.0944e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.038774
Average KL loss: 0.044327
Average total loss: 0.083101
tensor(0.0285, device='cuda:0') tensor(0.1109, device='cuda:0') tensor(-5.7849e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.037256
Average KL loss: 0.044323
Average total loss: 0.081579
tensor(0.0285, device='cuda:0') tensor(0.1111, device='cuda:0') tensor(-1.5191e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.037648
Average KL loss: 0.044312
Average total loss: 0.081960
tensor(0.0285, device='cuda:0') tensor(0.1112, device='cuda:0') tensor(-7.5969e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.037692
Average KL loss: 0.044303
Average total loss: 0.081995
tensor(0.0285, device='cuda:0') tensor(0.1114, device='cuda:0') tensor(-5.9968e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.037883
Average KL loss: 0.044302
Average total loss: 0.082185
tensor(0.0286, device='cuda:0') tensor(0.1116, device='cuda:0') tensor(-3.0854e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.037059
Average KL loss: 0.044306
Average total loss: 0.081364
tensor(0.0286, device='cuda:0') tensor(0.1117, device='cuda:0') tensor(-8.4781e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.036859
Average KL loss: 0.044290
Average total loss: 0.081149
tensor(0.0286, device='cuda:0') tensor(0.1119, device='cuda:0') tensor(-1.4556e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.037148
Average KL loss: 0.044284
Average total loss: 0.081431
tensor(0.0286, device='cuda:0') tensor(0.1121, device='cuda:0') tensor(-5.2255e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.036037
Average KL loss: 0.044274
Average total loss: 0.080312
tensor(0.0286, device='cuda:0') tensor(0.1122, device='cuda:0') tensor(-1.9470e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.036112
Average KL loss: 0.044264
Average total loss: 0.080376
tensor(0.0286, device='cuda:0') tensor(0.1124, device='cuda:0') tensor(-4.5160e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.036585
Average KL loss: 0.044262
Average total loss: 0.080847
tensor(0.0286, device='cuda:0') tensor(0.1125, device='cuda:0') tensor(-3.1896e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.036334
Average KL loss: 0.044259
Average total loss: 0.080593
tensor(0.0286, device='cuda:0') tensor(0.1127, device='cuda:0') tensor(-1.8728e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.035913
Average KL loss: 0.044248
Average total loss: 0.080161
tensor(0.0286, device='cuda:0') tensor(0.1129, device='cuda:0') tensor(-4.5178e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.036177
Average KL loss: 0.044240
Average total loss: 0.080417
tensor(0.0286, device='cuda:0') tensor(0.1130, device='cuda:0') tensor(-1.5290e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.036150
Average KL loss: 0.044231
Average total loss: 0.080380
tensor(0.0286, device='cuda:0') tensor(0.1132, device='cuda:0') tensor(-9.6453e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.035807
Average KL loss: 0.044227
Average total loss: 0.080034
tensor(0.0286, device='cuda:0') tensor(0.1134, device='cuda:0') tensor(-1.0017e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.035906
Average KL loss: 0.044222
Average total loss: 0.080128
tensor(0.0286, device='cuda:0') tensor(0.1135, device='cuda:0') tensor(-3.6404e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.035115
Average KL loss: 0.044214
Average total loss: 0.079329
tensor(0.0286, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-7.8973e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.035741
Average KL loss: 0.044208
Average total loss: 0.079949
tensor(0.0286, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-5.5907e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.036721
Average KL loss: 0.044202
Average total loss: 0.080922
tensor(0.0286, device='cuda:0') tensor(0.1140, device='cuda:0') tensor(-7.1165e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.035448
Average KL loss: 0.044197
Average total loss: 0.079645
tensor(0.0286, device='cuda:0') tensor(0.1142, device='cuda:0') tensor(-8.8196e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.035986
Average KL loss: 0.044191
Average total loss: 0.080177
tensor(0.0286, device='cuda:0') tensor(0.1143, device='cuda:0') tensor(-8.8770e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.035006
Average KL loss: 0.044187
Average total loss: 0.079193
tensor(0.0287, device='cuda:0') tensor(0.1145, device='cuda:0') tensor(-3.9482e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.035588
Average KL loss: 0.044179
Average total loss: 0.079767
tensor(0.0287, device='cuda:0') tensor(0.1147, device='cuda:0') tensor(4.3773e-12, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.035808
Average KL loss: 0.044178
Average total loss: 0.079986
tensor(0.0287, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-1.6908e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.035170
Average KL loss: 0.044176
Average total loss: 0.079346
tensor(0.0287, device='cuda:0') tensor(0.1150, device='cuda:0') tensor(-2.1208e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.035334
Average KL loss: 0.044174
Average total loss: 0.079508
tensor(0.0287, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-7.5067e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.035129
Average KL loss: 0.044172
Average total loss: 0.079302
tensor(0.0287, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-8.8047e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.035083
Average KL loss: 0.044163
Average total loss: 0.079247
tensor(0.0287, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-6.6982e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.035765
Average KL loss: 0.044159
Average total loss: 0.079924
tensor(0.0287, device='cuda:0') tensor(0.1157, device='cuda:0') tensor(-5.7191e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.034868
Average KL loss: 0.044160
Average total loss: 0.079029
tensor(0.0287, device='cuda:0') tensor(0.1159, device='cuda:0') tensor(-5.2439e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.034843
Average KL loss: 0.044156
Average total loss: 0.078999
tensor(0.0287, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(-5.2124e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.034764
Average KL loss: 0.044154
Average total loss: 0.078917
tensor(0.0287, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(-6.1360e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.034371
Average KL loss: 0.044148
Average total loss: 0.078519
tensor(0.0287, device='cuda:0') tensor(0.1164, device='cuda:0') tensor(-7.3993e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.033854
Average KL loss: 0.044140
Average total loss: 0.077993
tensor(0.0287, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-2.8682e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.034716
Average KL loss: 0.044129
Average total loss: 0.078845
tensor(0.0287, device='cuda:0') tensor(0.1167, device='cuda:0') tensor(-6.1933e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.034432
Average KL loss: 0.044122
Average total loss: 0.078554
tensor(0.0288, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-3.6799e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.035318
Average KL loss: 0.044117
Average total loss: 0.079435
tensor(0.0288, device='cuda:0') tensor(0.1171, device='cuda:0') tensor(-1.5589e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.034226
Average KL loss: 0.044108
Average total loss: 0.078334
tensor(0.0288, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-5.4903e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.034139
Average KL loss: 0.044099
Average total loss: 0.078238
tensor(0.0288, device='cuda:0') tensor(0.1174, device='cuda:0') tensor(-1.0171e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.033483
Average KL loss: 0.044088
Average total loss: 0.077571
tensor(0.0288, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-8.0003e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.034102
Average KL loss: 0.044081
Average total loss: 0.078183
tensor(0.0288, device='cuda:0') tensor(0.1177, device='cuda:0') tensor(-5.6468e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.034438
Average KL loss: 0.044074
Average total loss: 0.078512
tensor(0.0288, device='cuda:0') tensor(0.1179, device='cuda:0') tensor(-4.0421e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.034368
Average KL loss: 0.044068
Average total loss: 0.078436
tensor(0.0288, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-3.6612e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.033840
Average KL loss: 0.044064
Average total loss: 0.077904
tensor(0.0288, device='cuda:0') tensor(0.1182, device='cuda:0') tensor(-1.8809e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.033571
Average KL loss: 0.044053
Average total loss: 0.077624
tensor(0.0288, device='cuda:0') tensor(0.1184, device='cuda:0') tensor(-3.8355e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.033552
Average KL loss: 0.044042
Average total loss: 0.077594
tensor(0.0288, device='cuda:0') tensor(0.1185, device='cuda:0') tensor(-7.0840e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.036115
Average KL loss: 0.044041
Average total loss: 0.080156
tensor(0.0288, device='cuda:0') tensor(0.1187, device='cuda:0') tensor(-5.1436e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.032998
Average KL loss: 0.044037
Average total loss: 0.077035
tensor(0.0288, device='cuda:0') tensor(0.1189, device='cuda:0') tensor(-2.2157e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.033575
Average KL loss: 0.044025
Average total loss: 0.077600
tensor(0.0288, device='cuda:0') tensor(0.1190, device='cuda:0') tensor(-6.4386e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.036402
Average KL loss: 0.044023
Average total loss: 0.080425
tensor(0.0288, device='cuda:0') tensor(0.1192, device='cuda:0') tensor(-1.4144e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.033427
Average KL loss: 0.044015
Average total loss: 0.077441
tensor(0.0288, device='cuda:0') tensor(0.1194, device='cuda:0') tensor(-1.1066e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.034063
Average KL loss: 0.044009
Average total loss: 0.078072
tensor(0.0289, device='cuda:0') tensor(0.1195, device='cuda:0') tensor(-1.8363e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.033496
Average KL loss: 0.044006
Average total loss: 0.077503
tensor(0.0289, device='cuda:0') tensor(0.1197, device='cuda:0') tensor(-3.9540e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.033337
Average KL loss: 0.043999
Average total loss: 0.077336
tensor(0.0289, device='cuda:0') tensor(0.1199, device='cuda:0') tensor(-3.3510e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.033103
Average KL loss: 0.043999
Average total loss: 0.077103
tensor(0.0289, device='cuda:0') tensor(0.1200, device='cuda:0') tensor(-2.5412e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.033332
Average KL loss: 0.043996
Average total loss: 0.077328
tensor(0.0289, device='cuda:0') tensor(0.1202, device='cuda:0') tensor(-1.3634e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.033227
Average KL loss: 0.043991
Average total loss: 0.077218
tensor(0.0289, device='cuda:0') tensor(0.1204, device='cuda:0') tensor(-2.8873e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.033254
Average KL loss: 0.043986
Average total loss: 0.077240
tensor(0.0289, device='cuda:0') tensor(0.1205, device='cuda:0') tensor(-3.9918e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.033061
Average KL loss: 0.043979
Average total loss: 0.077040
tensor(0.0289, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-4.1901e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.032712
Average KL loss: 0.043976
Average total loss: 0.076688
tensor(0.0289, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-1.1875e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.032757
Average KL loss: 0.043972
Average total loss: 0.076729
tensor(0.0289, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-1.1757e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.032939
Average KL loss: 0.043970
Average total loss: 0.076909
tensor(0.0289, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-7.8527e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.033289
Average KL loss: 0.043967
Average total loss: 0.077256
tensor(0.0289, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-1.7233e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.032785
Average KL loss: 0.043965
Average total loss: 0.076750
tensor(0.0289, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-5.4076e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.032515
Average KL loss: 0.043962
Average total loss: 0.076477
tensor(0.0289, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-3.5232e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.033334
Average KL loss: 0.043960
Average total loss: 0.077293
tensor(0.0289, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(1.5767e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.033293
Average KL loss: 0.043957
Average total loss: 0.077250
tensor(0.0289, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-1.8377e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.033056
Average KL loss: 0.043954
Average total loss: 0.077011
tensor(0.0289, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-8.0404e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.032293
Average KL loss: 0.043952
Average total loss: 0.076245
tensor(0.0289, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(9.1464e-12, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.032542
Average KL loss: 0.043949
Average total loss: 0.076490
tensor(0.0289, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-1.0359e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.032718
Average KL loss: 0.043945
Average total loss: 0.076663
tensor(0.0289, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-4.5578e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.033072
Average KL loss: 0.043942
Average total loss: 0.077014
tensor(0.0289, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-8.0119e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.033514
Average KL loss: 0.043940
Average total loss: 0.077454
tensor(0.0289, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-1.9496e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.034046
Average KL loss: 0.043938
Average total loss: 0.077984
tensor(0.0289, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-2.7860e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.032651
Average KL loss: 0.043936
Average total loss: 0.076586
tensor(0.0289, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.6219e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.032747
Average KL loss: 0.043933
Average total loss: 0.076680
tensor(0.0289, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.2198e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.032405
Average KL loss: 0.043930
Average total loss: 0.076335
 Percentile value: 3.291735887527466
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =     145 /    1728             (  8.39%) | total_pruned =    1583 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     133 /   36864             (  0.36%) | total_pruned =   36731 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     118 /   36864             (  0.32%) | total_pruned =   36746 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     148 /   36864             (  0.40%) | total_pruned =   36716 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     343 /   36864             (  0.93%) | total_pruned =   36521 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1778 /   73728             (  2.41%) | total_pruned =   71950 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3987 /  147456             (  2.70%) | total_pruned =  143469 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     268 /    8192             (  3.27%) | total_pruned =    7924 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2998 /  147456             (  2.03%) | total_pruned =  144458 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2977 /  147456             (  2.02%) | total_pruned =  144479 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8333 /  294912             (  2.83%) | total_pruned =  286579 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    9682 /  589824             (  1.64%) | total_pruned =  580142 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     110 /     256             ( 42.97%) | total_pruned =     146 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      44 /     256             ( 17.19%) | total_pruned =     212 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1097 /   32768             (  3.35%) | total_pruned =   31671 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      99 /     256             ( 38.67%) | total_pruned =     157 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6071 /  589824             (  1.03%) | total_pruned =  583753 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    5050 /  589824             (  0.86%) | total_pruned =  584774 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     119 /     256             ( 46.48%) | total_pruned =     137 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   14861 / 1179648             (  1.26%) | total_pruned = 1164787 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     335 /     512             ( 65.43%) | total_pruned =     177 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   12039 / 2359296             (  0.51%) | total_pruned = 2347257 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     264 /     512             ( 51.56%) | total_pruned =     248 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     137 /     512             ( 26.76%) | total_pruned =     375 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     318 /  131072             (  0.24%) | total_pruned =  130754 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      69 /     512             ( 13.48%) | total_pruned =     443 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     140 /     512             ( 27.34%) | total_pruned =     372 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    5181 / 2359296             (  0.22%) | total_pruned = 2354115 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     127 /     512             ( 24.80%) | total_pruned =     385 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    7071 / 2359296             (  0.30%) | total_pruned = 2352225 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     270 /     512             ( 52.73%) | total_pruned =     242 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     225 /     512             ( 43.95%) | total_pruned =     287 | shape = torch.Size([512])
linear.weight        | nonzeros =    1805 /    5120             ( 35.25%) | total_pruned =    3315 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 50/100 Loss: 0.052689 Accuracy: 83.61 99.98 % Best test Accuracy: 84.43%
tensor(0.0289, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-3.1327e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.066564
Average KL loss: 0.042400
Average total loss: 0.108964
tensor(0.0268, device='cuda:0') tensor(0.1114, device='cuda:0') tensor(-4.3765e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.066366
Average KL loss: 0.040965
Average total loss: 0.107331
tensor(0.0259, device='cuda:0') tensor(0.1072, device='cuda:0') tensor(-4.3237e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.065575
Average KL loss: 0.040304
Average total loss: 0.105879
tensor(0.0254, device='cuda:0') tensor(0.1044, device='cuda:0') tensor(-2.8024e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.064195
Average KL loss: 0.039813
Average total loss: 0.104008
tensor(0.0251, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-3.0437e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.063094
Average KL loss: 0.039374
Average total loss: 0.102468
tensor(0.0248, device='cuda:0') tensor(0.1009, device='cuda:0') tensor(-2.5984e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.062485
Average KL loss: 0.038994
Average total loss: 0.101478
tensor(0.0245, device='cuda:0') tensor(0.0999, device='cuda:0') tensor(-2.9121e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.062191
Average KL loss: 0.038691
Average total loss: 0.100881
tensor(0.0244, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.0518e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.061375
Average KL loss: 0.038472
Average total loss: 0.099847
tensor(0.0242, device='cuda:0') tensor(0.0986, device='cuda:0') tensor(-2.4966e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.061043
Average KL loss: 0.038320
Average total loss: 0.099363
tensor(0.0241, device='cuda:0') tensor(0.0982, device='cuda:0') tensor(-3.0986e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.057453
Average KL loss: 0.038213
Average total loss: 0.095666
tensor(0.0240, device='cuda:0') tensor(0.0980, device='cuda:0') tensor(-3.2675e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.058961
Average KL loss: 0.038128
Average total loss: 0.097089
tensor(0.0240, device='cuda:0') tensor(0.0978, device='cuda:0') tensor(-3.1108e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.058238
Average KL loss: 0.038060
Average total loss: 0.096297
tensor(0.0240, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(-2.4858e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.057150
Average KL loss: 0.038002
Average total loss: 0.095152
tensor(0.0239, device='cuda:0') tensor(0.0976, device='cuda:0') tensor(-2.5908e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.055456
Average KL loss: 0.037952
Average total loss: 0.093408
tensor(0.0239, device='cuda:0') tensor(0.0976, device='cuda:0') tensor(-2.5342e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.057036
Average KL loss: 0.037908
Average total loss: 0.094945
tensor(0.0239, device='cuda:0') tensor(0.0976, device='cuda:0') tensor(-2.2281e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.055944
Average KL loss: 0.037872
Average total loss: 0.093816
tensor(0.0239, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(-2.6167e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.054752
Average KL loss: 0.037839
Average total loss: 0.092591
tensor(0.0239, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(-3.1117e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.053419
Average KL loss: 0.037808
Average total loss: 0.091227
tensor(0.0239, device='cuda:0') tensor(0.0978, device='cuda:0') tensor(-2.5119e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.053517
Average KL loss: 0.037778
Average total loss: 0.091295
tensor(0.0238, device='cuda:0') tensor(0.0979, device='cuda:0') tensor(-4.4514e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.053776
Average KL loss: 0.037748
Average total loss: 0.091525
tensor(0.0238, device='cuda:0') tensor(0.0980, device='cuda:0') tensor(-2.3611e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.051802
Average KL loss: 0.037719
Average total loss: 0.089521
tensor(0.0238, device='cuda:0') tensor(0.0981, device='cuda:0') tensor(-2.7237e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.052019
Average KL loss: 0.037692
Average total loss: 0.089711
tensor(0.0238, device='cuda:0') tensor(0.0982, device='cuda:0') tensor(-1.1592e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.053727
Average KL loss: 0.037667
Average total loss: 0.091394
tensor(0.0238, device='cuda:0') tensor(0.0983, device='cuda:0') tensor(-1.8221e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.049170
Average KL loss: 0.037644
Average total loss: 0.086814
tensor(0.0238, device='cuda:0') tensor(0.0984, device='cuda:0') tensor(-1.8624e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.049436
Average KL loss: 0.037621
Average total loss: 0.087058
tensor(0.0238, device='cuda:0') tensor(0.0986, device='cuda:0') tensor(-2.5352e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.049907
Average KL loss: 0.037599
Average total loss: 0.087506
tensor(0.0238, device='cuda:0') tensor(0.0987, device='cuda:0') tensor(-2.0697e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.049130
Average KL loss: 0.037577
Average total loss: 0.086707
tensor(0.0238, device='cuda:0') tensor(0.0989, device='cuda:0') tensor(-1.6973e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.049868
Average KL loss: 0.037558
Average total loss: 0.087426
tensor(0.0238, device='cuda:0') tensor(0.0990, device='cuda:0') tensor(-1.7025e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.048793
Average KL loss: 0.037537
Average total loss: 0.086331
tensor(0.0238, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-1.4122e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.047396
Average KL loss: 0.037520
Average total loss: 0.084915
tensor(0.0238, device='cuda:0') tensor(0.0993, device='cuda:0') tensor(-2.2928e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.046550
Average KL loss: 0.037499
Average total loss: 0.084050
tensor(0.0238, device='cuda:0') tensor(0.0995, device='cuda:0') tensor(-1.5983e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.046641
Average KL loss: 0.037481
Average total loss: 0.084122
tensor(0.0238, device='cuda:0') tensor(0.0997, device='cuda:0') tensor(-1.7816e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.045114
Average KL loss: 0.037464
Average total loss: 0.082578
tensor(0.0238, device='cuda:0') tensor(0.0999, device='cuda:0') tensor(-1.5168e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.046668
Average KL loss: 0.037446
Average total loss: 0.084115
tensor(0.0238, device='cuda:0') tensor(0.1000, device='cuda:0') tensor(-1.2218e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.046604
Average KL loss: 0.037429
Average total loss: 0.084033
tensor(0.0239, device='cuda:0') tensor(0.1002, device='cuda:0') tensor(-1.8905e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.046521
Average KL loss: 0.037415
Average total loss: 0.083936
tensor(0.0239, device='cuda:0') tensor(0.1004, device='cuda:0') tensor(-1.2467e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.045648
Average KL loss: 0.037400
Average total loss: 0.083048
tensor(0.0239, device='cuda:0') tensor(0.1006, device='cuda:0') tensor(-2.0782e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.045587
Average KL loss: 0.037384
Average total loss: 0.082971
tensor(0.0239, device='cuda:0') tensor(0.1008, device='cuda:0') tensor(-1.6406e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.044277
Average KL loss: 0.037370
Average total loss: 0.081647
tensor(0.0239, device='cuda:0') tensor(0.1009, device='cuda:0') tensor(-1.4827e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.044214
Average KL loss: 0.037354
Average total loss: 0.081568
tensor(0.0239, device='cuda:0') tensor(0.1011, device='cuda:0') tensor(-1.1685e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.043952
Average KL loss: 0.037339
Average total loss: 0.081292
tensor(0.0239, device='cuda:0') tensor(0.1013, device='cuda:0') tensor(-1.5270e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.046103
Average KL loss: 0.037321
Average total loss: 0.083424
tensor(0.0239, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-1.9361e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.044947
Average KL loss: 0.037304
Average total loss: 0.082251
tensor(0.0239, device='cuda:0') tensor(0.1016, device='cuda:0') tensor(-1.3304e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.042304
Average KL loss: 0.037291
Average total loss: 0.079595
tensor(0.0239, device='cuda:0') tensor(0.1018, device='cuda:0') tensor(-2.2688e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.042550
Average KL loss: 0.037276
Average total loss: 0.079825
tensor(0.0239, device='cuda:0') tensor(0.1020, device='cuda:0') tensor(-1.7428e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.041900
Average KL loss: 0.037259
Average total loss: 0.079159
tensor(0.0239, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(-1.8543e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.042058
Average KL loss: 0.037242
Average total loss: 0.079300
tensor(0.0239, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-7.8164e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.042124
Average KL loss: 0.037226
Average total loss: 0.079350
tensor(0.0239, device='cuda:0') tensor(0.1025, device='cuda:0') tensor(-1.4249e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.041735
Average KL loss: 0.037208
Average total loss: 0.078944
tensor(0.0239, device='cuda:0') tensor(0.1027, device='cuda:0') tensor(-1.3345e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.041615
Average KL loss: 0.037192
Average total loss: 0.078807
tensor(0.0239, device='cuda:0') tensor(0.1029, device='cuda:0') tensor(-9.8314e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.043080
Average KL loss: 0.037182
Average total loss: 0.080262
tensor(0.0240, device='cuda:0') tensor(0.1031, device='cuda:0') tensor(-1.2398e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.041632
Average KL loss: 0.037170
Average total loss: 0.078803
tensor(0.0240, device='cuda:0') tensor(0.1033, device='cuda:0') tensor(-6.7224e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.043093
Average KL loss: 0.037156
Average total loss: 0.080249
tensor(0.0240, device='cuda:0') tensor(0.1035, device='cuda:0') tensor(-1.4988e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.041659
Average KL loss: 0.037143
Average total loss: 0.078802
tensor(0.0240, device='cuda:0') tensor(0.1037, device='cuda:0') tensor(-1.0437e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.040095
Average KL loss: 0.037128
Average total loss: 0.077223
tensor(0.0240, device='cuda:0') tensor(0.1039, device='cuda:0') tensor(-1.2507e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.041133
Average KL loss: 0.037113
Average total loss: 0.078247
tensor(0.0240, device='cuda:0') tensor(0.1041, device='cuda:0') tensor(-1.5659e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.040034
Average KL loss: 0.037098
Average total loss: 0.077132
tensor(0.0240, device='cuda:0') tensor(0.1043, device='cuda:0') tensor(-1.4642e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.040273
Average KL loss: 0.037079
Average total loss: 0.077352
tensor(0.0240, device='cuda:0') tensor(0.1044, device='cuda:0') tensor(-1.4515e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.039088
Average KL loss: 0.037066
Average total loss: 0.076153
tensor(0.0240, device='cuda:0') tensor(0.1046, device='cuda:0') tensor(-1.3328e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.038816
Average KL loss: 0.037053
Average total loss: 0.075869
tensor(0.0240, device='cuda:0') tensor(0.1048, device='cuda:0') tensor(-6.5764e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.038366
Average KL loss: 0.037035
Average total loss: 0.075402
tensor(0.0240, device='cuda:0') tensor(0.1050, device='cuda:0') tensor(-1.3497e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.038603
Average KL loss: 0.037019
Average total loss: 0.075621
tensor(0.0240, device='cuda:0') tensor(0.1052, device='cuda:0') tensor(-4.4656e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.039679
Average KL loss: 0.037002
Average total loss: 0.076681
tensor(0.0240, device='cuda:0') tensor(0.1054, device='cuda:0') tensor(-8.5488e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.039549
Average KL loss: 0.036988
Average total loss: 0.076537
tensor(0.0240, device='cuda:0') tensor(0.1055, device='cuda:0') tensor(-9.4110e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.038469
Average KL loss: 0.036972
Average total loss: 0.075442
tensor(0.0240, device='cuda:0') tensor(0.1057, device='cuda:0') tensor(-1.3348e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.039695
Average KL loss: 0.036960
Average total loss: 0.076655
tensor(0.0241, device='cuda:0') tensor(0.1059, device='cuda:0') tensor(-1.8225e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.037844
Average KL loss: 0.036948
Average total loss: 0.074791
tensor(0.0241, device='cuda:0') tensor(0.1061, device='cuda:0') tensor(-1.8749e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.038222
Average KL loss: 0.036935
Average total loss: 0.075156
tensor(0.0241, device='cuda:0') tensor(0.1063, device='cuda:0') tensor(-1.0347e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.037766
Average KL loss: 0.036924
Average total loss: 0.074690
tensor(0.0241, device='cuda:0') tensor(0.1065, device='cuda:0') tensor(-1.1048e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.038557
Average KL loss: 0.036909
Average total loss: 0.075467
tensor(0.0241, device='cuda:0') tensor(0.1067, device='cuda:0') tensor(-1.0935e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.037783
Average KL loss: 0.036898
Average total loss: 0.074681
tensor(0.0241, device='cuda:0') tensor(0.1069, device='cuda:0') tensor(-1.8766e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.040273
Average KL loss: 0.036885
Average total loss: 0.077158
tensor(0.0241, device='cuda:0') tensor(0.1071, device='cuda:0') tensor(-8.8472e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.037054
Average KL loss: 0.036872
Average total loss: 0.073925
tensor(0.0241, device='cuda:0') tensor(0.1073, device='cuda:0') tensor(-1.1913e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.036896
Average KL loss: 0.036856
Average total loss: 0.073752
tensor(0.0241, device='cuda:0') tensor(0.1075, device='cuda:0') tensor(-6.3982e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.037286
Average KL loss: 0.036842
Average total loss: 0.074128
tensor(0.0241, device='cuda:0') tensor(0.1077, device='cuda:0') tensor(-4.7074e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.037943
Average KL loss: 0.036832
Average total loss: 0.074775
tensor(0.0241, device='cuda:0') tensor(0.1079, device='cuda:0') tensor(-1.2802e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.037633
Average KL loss: 0.036822
Average total loss: 0.074456
tensor(0.0242, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-9.2475e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.037701
Average KL loss: 0.036813
Average total loss: 0.074514
tensor(0.0242, device='cuda:0') tensor(0.1083, device='cuda:0') tensor(-8.9413e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.036339
Average KL loss: 0.036800
Average total loss: 0.073139
tensor(0.0242, device='cuda:0') tensor(0.1085, device='cuda:0') tensor(-7.0813e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.036325
Average KL loss: 0.036787
Average total loss: 0.073113
tensor(0.0242, device='cuda:0') tensor(0.1087, device='cuda:0') tensor(-8.3235e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.036309
Average KL loss: 0.036776
Average total loss: 0.073084
tensor(0.0242, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-4.8243e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.034874
Average KL loss: 0.036760
Average total loss: 0.071634
tensor(0.0242, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(-9.8933e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.035786
Average KL loss: 0.036742
Average total loss: 0.072528
tensor(0.0242, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(-1.2118e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.037451
Average KL loss: 0.036728
Average total loss: 0.074179
tensor(0.0242, device='cuda:0') tensor(0.1094, device='cuda:0') tensor(-4.3296e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.035869
Average KL loss: 0.036720
Average total loss: 0.072589
tensor(0.0242, device='cuda:0') tensor(0.1096, device='cuda:0') tensor(-4.3900e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.036263
Average KL loss: 0.036707
Average total loss: 0.072970
tensor(0.0242, device='cuda:0') tensor(0.1098, device='cuda:0') tensor(-6.2366e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.035814
Average KL loss: 0.036695
Average total loss: 0.072509
tensor(0.0242, device='cuda:0') tensor(0.1100, device='cuda:0') tensor(-1.1686e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.035603
Average KL loss: 0.036685
Average total loss: 0.072288
tensor(0.0243, device='cuda:0') tensor(0.1102, device='cuda:0') tensor(-9.0081e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.035009
Average KL loss: 0.036672
Average total loss: 0.071680
tensor(0.0243, device='cuda:0') tensor(0.1104, device='cuda:0') tensor(-9.2180e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.035271
Average KL loss: 0.036659
Average total loss: 0.071930
tensor(0.0243, device='cuda:0') tensor(0.1106, device='cuda:0') tensor(-7.2763e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.034427
Average KL loss: 0.036647
Average total loss: 0.071074
tensor(0.0243, device='cuda:0') tensor(0.1108, device='cuda:0') tensor(-1.5165e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.034656
Average KL loss: 0.036633
Average total loss: 0.071289
tensor(0.0243, device='cuda:0') tensor(0.1109, device='cuda:0') tensor(-4.4968e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.034856
Average KL loss: 0.036618
Average total loss: 0.071473
tensor(0.0243, device='cuda:0') tensor(0.1111, device='cuda:0') tensor(-6.9154e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.035058
Average KL loss: 0.036606
Average total loss: 0.071665
tensor(0.0243, device='cuda:0') tensor(0.1113, device='cuda:0') tensor(-2.3019e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.035163
Average KL loss: 0.036593
Average total loss: 0.071757
tensor(0.0243, device='cuda:0') tensor(0.1115, device='cuda:0') tensor(-1.3603e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.034403
Average KL loss: 0.036581
Average total loss: 0.070984
tensor(0.0243, device='cuda:0') tensor(0.1117, device='cuda:0') tensor(-4.8506e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.034485
Average KL loss: 0.036568
Average total loss: 0.071053
tensor(0.0243, device='cuda:0') tensor(0.1119, device='cuda:0') tensor(-7.2761e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.033819
Average KL loss: 0.036558
Average total loss: 0.070377
tensor(0.0243, device='cuda:0') tensor(0.1121, device='cuda:0') tensor(-2.4047e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.034671
Average KL loss: 0.036546
Average total loss: 0.071217
tensor(0.0243, device='cuda:0') tensor(0.1122, device='cuda:0') tensor(-6.6341e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.033784
Average KL loss: 0.036536
Average total loss: 0.070320
tensor(0.0244, device='cuda:0') tensor(0.1124, device='cuda:0') tensor(-4.5538e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.033812
Average KL loss: 0.036523
Average total loss: 0.070335
tensor(0.0244, device='cuda:0') tensor(0.1126, device='cuda:0') tensor(-7.6606e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.034253
Average KL loss: 0.036510
Average total loss: 0.070763
tensor(0.0244, device='cuda:0') tensor(0.1128, device='cuda:0') tensor(-4.7412e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.034769
Average KL loss: 0.036501
Average total loss: 0.071270
tensor(0.0244, device='cuda:0') tensor(0.1130, device='cuda:0') tensor(-7.3303e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.034433
Average KL loss: 0.036491
Average total loss: 0.070924
tensor(0.0244, device='cuda:0') tensor(0.1132, device='cuda:0') tensor(-7.1590e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.033728
Average KL loss: 0.036478
Average total loss: 0.070206
tensor(0.0244, device='cuda:0') tensor(0.1134, device='cuda:0') tensor(-3.3357e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.033398
Average KL loss: 0.036466
Average total loss: 0.069865
tensor(0.0244, device='cuda:0') tensor(0.1136, device='cuda:0') tensor(-7.3518e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.034087
Average KL loss: 0.036456
Average total loss: 0.070543
tensor(0.0244, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-9.0675e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.033335
Average KL loss: 0.036443
Average total loss: 0.069778
tensor(0.0244, device='cuda:0') tensor(0.1140, device='cuda:0') tensor(-3.4386e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.033041
Average KL loss: 0.036431
Average total loss: 0.069471
tensor(0.0244, device='cuda:0') tensor(0.1141, device='cuda:0') tensor(-8.6515e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.033717
Average KL loss: 0.036422
Average total loss: 0.070139
tensor(0.0245, device='cuda:0') tensor(0.1143, device='cuda:0') tensor(-6.8446e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.033156
Average KL loss: 0.036409
Average total loss: 0.069566
tensor(0.0245, device='cuda:0') tensor(0.1145, device='cuda:0') tensor(-3.6010e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.032990
Average KL loss: 0.036399
Average total loss: 0.069389
tensor(0.0245, device='cuda:0') tensor(0.1147, device='cuda:0') tensor(-7.5503e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.033652
Average KL loss: 0.036390
Average total loss: 0.070042
tensor(0.0245, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-7.3649e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.033587
Average KL loss: 0.036382
Average total loss: 0.069968
tensor(0.0245, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-7.2257e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.034423
Average KL loss: 0.036372
Average total loss: 0.070795
tensor(0.0245, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-5.1077e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.032625
Average KL loss: 0.036361
Average total loss: 0.068986
tensor(0.0245, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-1.8592e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.034545
Average KL loss: 0.036352
Average total loss: 0.070898
tensor(0.0245, device='cuda:0') tensor(0.1157, device='cuda:0') tensor(-6.5246e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.032204
Average KL loss: 0.036346
Average total loss: 0.068550
tensor(0.0245, device='cuda:0') tensor(0.1159, device='cuda:0') tensor(-4.1805e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.032500
Average KL loss: 0.036334
Average total loss: 0.068834
tensor(0.0246, device='cuda:0') tensor(0.1161, device='cuda:0') tensor(-2.8424e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.032399
Average KL loss: 0.036324
Average total loss: 0.068723
tensor(0.0246, device='cuda:0') tensor(0.1163, device='cuda:0') tensor(-4.7510e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.036552
Average KL loss: 0.036309
Average total loss: 0.072861
tensor(0.0246, device='cuda:0') tensor(0.1165, device='cuda:0') tensor(-8.0605e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.032882
Average KL loss: 0.036305
Average total loss: 0.069188
tensor(0.0246, device='cuda:0') tensor(0.1167, device='cuda:0') tensor(-3.0728e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.032363
Average KL loss: 0.036293
Average total loss: 0.068656
tensor(0.0246, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-8.9965e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.033231
Average KL loss: 0.036280
Average total loss: 0.069511
tensor(0.0246, device='cuda:0') tensor(0.1171, device='cuda:0') tensor(-4.7280e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.032263
Average KL loss: 0.036270
Average total loss: 0.068534
tensor(0.0246, device='cuda:0') tensor(0.1173, device='cuda:0') tensor(-4.6911e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.032377
Average KL loss: 0.036261
Average total loss: 0.068638
tensor(0.0246, device='cuda:0') tensor(0.1175, device='cuda:0') tensor(-2.9490e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.032301
Average KL loss: 0.036250
Average total loss: 0.068551
tensor(0.0246, device='cuda:0') tensor(0.1177, device='cuda:0') tensor(-3.7128e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.032485
Average KL loss: 0.036243
Average total loss: 0.068728
tensor(0.0246, device='cuda:0') tensor(0.1179, device='cuda:0') tensor(-4.5300e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.031912
Average KL loss: 0.036231
Average total loss: 0.068142
tensor(0.0247, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-3.5252e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.032136
Average KL loss: 0.036219
Average total loss: 0.068355
tensor(0.0247, device='cuda:0') tensor(0.1182, device='cuda:0') tensor(-3.0232e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.031822
Average KL loss: 0.036207
Average total loss: 0.068029
tensor(0.0247, device='cuda:0') tensor(0.1184, device='cuda:0') tensor(-3.5718e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.031445
Average KL loss: 0.036198
Average total loss: 0.067643
tensor(0.0247, device='cuda:0') tensor(0.1186, device='cuda:0') tensor(4.3434e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.031389
Average KL loss: 0.036188
Average total loss: 0.067577
tensor(0.0247, device='cuda:0') tensor(0.1188, device='cuda:0') tensor(-4.3985e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.031824
Average KL loss: 0.036179
Average total loss: 0.068003
tensor(0.0247, device='cuda:0') tensor(0.1190, device='cuda:0') tensor(-2.1323e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.031251
Average KL loss: 0.036171
Average total loss: 0.067422
tensor(0.0247, device='cuda:0') tensor(0.1192, device='cuda:0') tensor(-8.0146e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.031596
Average KL loss: 0.036162
Average total loss: 0.067758
tensor(0.0247, device='cuda:0') tensor(0.1194, device='cuda:0') tensor(-3.3713e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.031921
Average KL loss: 0.036155
Average total loss: 0.068076
tensor(0.0247, device='cuda:0') tensor(0.1196, device='cuda:0') tensor(-6.2132e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.031686
Average KL loss: 0.036148
Average total loss: 0.067834
tensor(0.0247, device='cuda:0') tensor(0.1198, device='cuda:0') tensor(-2.8863e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.032013
Average KL loss: 0.036139
Average total loss: 0.068151
tensor(0.0248, device='cuda:0') tensor(0.1200, device='cuda:0') tensor(-4.3282e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.033208
Average KL loss: 0.036132
Average total loss: 0.069340
tensor(0.0248, device='cuda:0') tensor(0.1202, device='cuda:0') tensor(-2.0511e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.031702
Average KL loss: 0.036127
Average total loss: 0.067829
tensor(0.0248, device='cuda:0') tensor(0.1203, device='cuda:0') tensor(-3.1891e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.031136
Average KL loss: 0.036115
Average total loss: 0.067251
tensor(0.0248, device='cuda:0') tensor(0.1205, device='cuda:0') tensor(-2.2404e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.031374
Average KL loss: 0.036104
Average total loss: 0.067478
tensor(0.0248, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-5.1464e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.031413
Average KL loss: 0.036096
Average total loss: 0.067509
tensor(0.0248, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-1.8392e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.030918
Average KL loss: 0.036085
Average total loss: 0.067003
tensor(0.0248, device='cuda:0') tensor(0.1211, device='cuda:0') tensor(-4.5294e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.031883
Average KL loss: 0.036076
Average total loss: 0.067959
tensor(0.0248, device='cuda:0') tensor(0.1213, device='cuda:0') tensor(-4.4558e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.030887
Average KL loss: 0.036068
Average total loss: 0.066955
tensor(0.0248, device='cuda:0') tensor(0.1215, device='cuda:0') tensor(-3.3295e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.031104
Average KL loss: 0.036059
Average total loss: 0.067163
tensor(0.0249, device='cuda:0') tensor(0.1216, device='cuda:0') tensor(-8.3711e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.031056
Average KL loss: 0.036051
Average total loss: 0.067108
tensor(0.0249, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-2.9526e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.031610
Average KL loss: 0.036043
Average total loss: 0.067653
tensor(0.0249, device='cuda:0') tensor(0.1220, device='cuda:0') tensor(-1.5040e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.031230
Average KL loss: 0.036038
Average total loss: 0.067269
tensor(0.0249, device='cuda:0') tensor(0.1222, device='cuda:0') tensor(-2.6493e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.032084
Average KL loss: 0.036032
Average total loss: 0.068116
tensor(0.0249, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-4.4675e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.031254
Average KL loss: 0.036024
Average total loss: 0.067278
tensor(0.0249, device='cuda:0') tensor(0.1226, device='cuda:0') tensor(-4.6338e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.030962
Average KL loss: 0.036017
Average total loss: 0.066979
tensor(0.0249, device='cuda:0') tensor(0.1228, device='cuda:0') tensor(-2.8872e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.030532
Average KL loss: 0.036009
Average total loss: 0.066540
tensor(0.0249, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(-2.2233e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.031094
Average KL loss: 0.035999
Average total loss: 0.067094
tensor(0.0249, device='cuda:0') tensor(0.1231, device='cuda:0') tensor(-5.1975e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.032984
Average KL loss: 0.035990
Average total loss: 0.068974
tensor(0.0250, device='cuda:0') tensor(0.1233, device='cuda:0') tensor(-2.9882e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.031504
Average KL loss: 0.035984
Average total loss: 0.067488
tensor(0.0250, device='cuda:0') tensor(0.1236, device='cuda:0') tensor(-2.7946e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.030668
Average KL loss: 0.035979
Average total loss: 0.066647
tensor(0.0250, device='cuda:0') tensor(0.1237, device='cuda:0') tensor(-1.4618e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.030624
Average KL loss: 0.035972
Average total loss: 0.066596
tensor(0.0250, device='cuda:0') tensor(0.1239, device='cuda:0') tensor(-3.5117e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.030861
Average KL loss: 0.035964
Average total loss: 0.066824
tensor(0.0250, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-1.0579e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.031155
Average KL loss: 0.035958
Average total loss: 0.067113
tensor(0.0250, device='cuda:0') tensor(0.1243, device='cuda:0') tensor(-1.8522e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.029935
Average KL loss: 0.035949
Average total loss: 0.065885
tensor(0.0250, device='cuda:0') tensor(0.1245, device='cuda:0') tensor(-2.7398e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.030673
Average KL loss: 0.035940
Average total loss: 0.066612
tensor(0.0250, device='cuda:0') tensor(0.1246, device='cuda:0') tensor(-5.1961e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.030411
Average KL loss: 0.035929
Average total loss: 0.066340
tensor(0.0250, device='cuda:0') tensor(0.1248, device='cuda:0') tensor(-2.9839e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.029684
Average KL loss: 0.035919
Average total loss: 0.065603
tensor(0.0250, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-4.0127e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.030454
Average KL loss: 0.035907
Average total loss: 0.066362
tensor(0.0251, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-2.3807e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.030502
Average KL loss: 0.035901
Average total loss: 0.066403
tensor(0.0251, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-2.2228e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.031627
Average KL loss: 0.035893
Average total loss: 0.067519
tensor(0.0251, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-3.7359e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.030929
Average KL loss: 0.035890
Average total loss: 0.066818
tensor(0.0251, device='cuda:0') tensor(0.1257, device='cuda:0') tensor(-2.1445e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.030113
Average KL loss: 0.035882
Average total loss: 0.065995
tensor(0.0251, device='cuda:0') tensor(0.1259, device='cuda:0') tensor(-1.6682e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.030363
Average KL loss: 0.035873
Average total loss: 0.066236
tensor(0.0251, device='cuda:0') tensor(0.1260, device='cuda:0') tensor(-3.7017e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.030527
Average KL loss: 0.035867
Average total loss: 0.066394
tensor(0.0251, device='cuda:0') tensor(0.1262, device='cuda:0') tensor(-1.6171e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.030658
Average KL loss: 0.035860
Average total loss: 0.066518
tensor(0.0251, device='cuda:0') tensor(0.1264, device='cuda:0') tensor(-3.2829e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.029938
Average KL loss: 0.035852
Average total loss: 0.065790
tensor(0.0251, device='cuda:0') tensor(0.1266, device='cuda:0') tensor(-5.8440e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.030008
Average KL loss: 0.035846
Average total loss: 0.065854
tensor(0.0252, device='cuda:0') tensor(0.1268, device='cuda:0') tensor(-1.7066e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.030338
Average KL loss: 0.035839
Average total loss: 0.066177
tensor(0.0252, device='cuda:0') tensor(0.1269, device='cuda:0') tensor(-4.4240e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.029906
Average KL loss: 0.035836
Average total loss: 0.065742
tensor(0.0252, device='cuda:0') tensor(0.1270, device='cuda:0') tensor(-3.0960e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.030766
Average KL loss: 0.035835
Average total loss: 0.066601
tensor(0.0252, device='cuda:0') tensor(0.1270, device='cuda:0') tensor(-1.8403e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.030411
Average KL loss: 0.035835
Average total loss: 0.066246
tensor(0.0252, device='cuda:0') tensor(0.1270, device='cuda:0') tensor(-1.2287e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.030112
Average KL loss: 0.035834
Average total loss: 0.065946
tensor(0.0252, device='cuda:0') tensor(0.1270, device='cuda:0') tensor(-1.5530e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.030170
Average KL loss: 0.035833
Average total loss: 0.066002
tensor(0.0252, device='cuda:0') tensor(0.1270, device='cuda:0') tensor(-2.4888e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.029958
Average KL loss: 0.035831
Average total loss: 0.065789
tensor(0.0252, device='cuda:0') tensor(0.1270, device='cuda:0') tensor(-2.5255e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.030145
Average KL loss: 0.035829
Average total loss: 0.065975
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-8.4248e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.030046
Average KL loss: 0.035828
Average total loss: 0.065875
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-4.2963e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.030281
Average KL loss: 0.035827
Average total loss: 0.066109
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-1.5796e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.029904
Average KL loss: 0.035826
Average total loss: 0.065731
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-2.4490e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.030371
Average KL loss: 0.035825
Average total loss: 0.066196
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-3.0582e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.030046
Average KL loss: 0.035825
Average total loss: 0.065871
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-2.7817e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.030646
Average KL loss: 0.035825
Average total loss: 0.066471
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-4.2486e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.030254
Average KL loss: 0.035825
Average total loss: 0.066078
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-3.2500e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.030148
Average KL loss: 0.035824
Average total loss: 0.065973
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-4.0113e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.031273
Average KL loss: 0.035824
Average total loss: 0.067098
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-1.9332e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.029879
Average KL loss: 0.035824
Average total loss: 0.065704
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-2.5533e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.029831
Average KL loss: 0.035824
Average total loss: 0.065655
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-2.0922e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.030411
Average KL loss: 0.035824
Average total loss: 0.066235
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-1.8956e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.029960
Average KL loss: 0.035824
Average total loss: 0.065784
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(3.2393e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.030400
Average KL loss: 0.035824
Average total loss: 0.066224
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-5.6055e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.031028
Average KL loss: 0.035824
Average total loss: 0.066852
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-3.2677e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.030072
Average KL loss: 0.035824
Average total loss: 0.065896
 Percentile value: 5.207948684692383
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =     128 /    1728             (  7.41%) | total_pruned =    1600 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      81 /   36864             (  0.22%) | total_pruned =   36783 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      65 /   36864             (  0.18%) | total_pruned =   36799 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     104 /   36864             (  0.28%) | total_pruned =   36760 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     239 /   36864             (  0.65%) | total_pruned =   36625 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1083 /   73728             (  1.47%) | total_pruned =   72645 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2373 /  147456             (  1.61%) | total_pruned =  145083 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     183 /    8192             (  2.23%) | total_pruned =    8009 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1958 /  147456             (  1.33%) | total_pruned =  145498 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1737 /  147456             (  1.18%) | total_pruned =  145719 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    4306 /  294912             (  1.46%) | total_pruned =  290606 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     132 /     256             ( 51.56%) | total_pruned =     124 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5282 /  589824             (  0.90%) | total_pruned =  584542 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     106 /     256             ( 41.41%) | total_pruned =     150 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     636 /   32768             (  1.94%) | total_pruned =   32132 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3107 /  589824             (  0.53%) | total_pruned =  586717 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2532 /  589824             (  0.43%) | total_pruned =  587292 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     109 /     256             ( 42.58%) | total_pruned =     147 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    6363 / 1179648             (  0.54%) | total_pruned = 1173285 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     328 /     512             ( 64.06%) | total_pruned =     184 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    5008 / 2359296             (  0.21%) | total_pruned = 2354288 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     213 /     512             ( 41.60%) | total_pruned =     299 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     118 /     512             ( 23.05%) | total_pruned =     394 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     132 /  131072             (  0.10%) | total_pruned =  130940 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     122 /     512             ( 23.83%) | total_pruned =     390 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2397 / 2359296             (  0.10%) | total_pruned = 2356899 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      91 /     512             ( 17.77%) | total_pruned =     421 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2496 / 2359296             (  0.11%) | total_pruned = 2356800 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     172 /     512             ( 33.59%) | total_pruned =     340 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     135 /     512             ( 26.37%) | total_pruned =     377 | shape = torch.Size([512])
linear.weight        | nonzeros =     999 /    5120             ( 19.51%) | total_pruned =    4121 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 75/100 Loss: 0.060605 Accuracy: 82.35 99.95 % Best test Accuracy: 83.65%
tensor(0.0252, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-1.1194e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.045216
Average KL loss: 0.034611
Average total loss: 0.079827
tensor(0.0233, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-2.6502e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.046158
Average KL loss: 0.032470
Average total loss: 0.078628
tensor(0.0220, device='cuda:0') tensor(0.1082, device='cuda:0') tensor(-8.7561e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.046541
Average KL loss: 0.030596
Average total loss: 0.077137
tensor(0.0209, device='cuda:0') tensor(0.1032, device='cuda:0') tensor(-1.5676e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.046123
Average KL loss: 0.029008
Average total loss: 0.075131
tensor(0.0200, device='cuda:0') tensor(0.0998, device='cuda:0') tensor(-1.8283e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.048354
Average KL loss: 0.027848
Average total loss: 0.076202
tensor(0.0194, device='cuda:0') tensor(0.0975, device='cuda:0') tensor(-8.6375e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.045821
Average KL loss: 0.027132
Average total loss: 0.072953
tensor(0.0189, device='cuda:0') tensor(0.0960, device='cuda:0') tensor(-1.0887e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.047857
Average KL loss: 0.026716
Average total loss: 0.074573
tensor(0.0186, device='cuda:0') tensor(0.0951, device='cuda:0') tensor(-7.3372e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.047505
Average KL loss: 0.026459
Average total loss: 0.073964
tensor(0.0184, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(-1.1476e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.047647
Average KL loss: 0.026292
Average total loss: 0.073939
tensor(0.0183, device='cuda:0') tensor(0.0941, device='cuda:0') tensor(-8.3952e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.047217
Average KL loss: 0.026179
Average total loss: 0.073395
tensor(0.0182, device='cuda:0') tensor(0.0938, device='cuda:0') tensor(-7.2237e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.048067
Average KL loss: 0.026097
Average total loss: 0.074163
tensor(0.0181, device='cuda:0') tensor(0.0936, device='cuda:0') tensor(-1.1030e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.046623
Average KL loss: 0.026035
Average total loss: 0.072657
tensor(0.0181, device='cuda:0') tensor(0.0935, device='cuda:0') tensor(-3.3087e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.046941
Average KL loss: 0.025983
Average total loss: 0.072924
tensor(0.0181, device='cuda:0') tensor(0.0935, device='cuda:0') tensor(-1.5435e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.046259
Average KL loss: 0.025942
Average total loss: 0.072201
tensor(0.0181, device='cuda:0') tensor(0.0935, device='cuda:0') tensor(-8.5494e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.046332
Average KL loss: 0.025906
Average total loss: 0.072239
tensor(0.0181, device='cuda:0') tensor(0.0936, device='cuda:0') tensor(-1.5027e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.045903
Average KL loss: 0.025876
Average total loss: 0.071779
tensor(0.0181, device='cuda:0') tensor(0.0936, device='cuda:0') tensor(-1.1926e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.045190
Average KL loss: 0.025847
Average total loss: 0.071037
tensor(0.0181, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(-1.2088e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.044784
Average KL loss: 0.025818
Average total loss: 0.070602
tensor(0.0181, device='cuda:0') tensor(0.0938, device='cuda:0') tensor(-1.9736e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.046210
Average KL loss: 0.025791
Average total loss: 0.072002
tensor(0.0181, device='cuda:0') tensor(0.0939, device='cuda:0') tensor(-1.5726e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.047163
Average KL loss: 0.025766
Average total loss: 0.072929
tensor(0.0181, device='cuda:0') tensor(0.0940, device='cuda:0') tensor(-1.0206e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.047297
Average KL loss: 0.025745
Average total loss: 0.073042
tensor(0.0181, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-1.3797e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.045082
Average KL loss: 0.025724
Average total loss: 0.070806
tensor(0.0181, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(-7.9690e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.045451
Average KL loss: 0.025704
Average total loss: 0.071155
tensor(0.0181, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(-7.1607e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.044717
Average KL loss: 0.025684
Average total loss: 0.070401
tensor(0.0181, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(-8.8918e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.045429
Average KL loss: 0.025664
Average total loss: 0.071094
tensor(0.0181, device='cuda:0') tensor(0.0948, device='cuda:0') tensor(-2.0792e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.043213
Average KL loss: 0.025646
Average total loss: 0.068858
tensor(0.0181, device='cuda:0') tensor(0.0950, device='cuda:0') tensor(-1.1162e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.047776
Average KL loss: 0.025628
Average total loss: 0.073404
tensor(0.0181, device='cuda:0') tensor(0.0951, device='cuda:0') tensor(-8.3179e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.043858
Average KL loss: 0.025609
Average total loss: 0.069467
tensor(0.0181, device='cuda:0') tensor(0.0953, device='cuda:0') tensor(-1.4500e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.043621
Average KL loss: 0.025591
Average total loss: 0.069212
tensor(0.0181, device='cuda:0') tensor(0.0955, device='cuda:0') tensor(-9.9334e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.045363
Average KL loss: 0.025574
Average total loss: 0.070938
tensor(0.0181, device='cuda:0') tensor(0.0957, device='cuda:0') tensor(-1.2619e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.045216
Average KL loss: 0.025559
Average total loss: 0.070775
tensor(0.0181, device='cuda:0') tensor(0.0959, device='cuda:0') tensor(-7.5642e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.042140
Average KL loss: 0.025543
Average total loss: 0.067682
tensor(0.0181, device='cuda:0') tensor(0.0960, device='cuda:0') tensor(-1.3972e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.043237
Average KL loss: 0.025527
Average total loss: 0.068764
tensor(0.0182, device='cuda:0') tensor(0.0962, device='cuda:0') tensor(-7.3898e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.045222
Average KL loss: 0.025512
Average total loss: 0.070734
tensor(0.0182, device='cuda:0') tensor(0.0964, device='cuda:0') tensor(-7.2487e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.043585
Average KL loss: 0.025496
Average total loss: 0.069081
tensor(0.0182, device='cuda:0') tensor(0.0966, device='cuda:0') tensor(-1.0649e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.045658
Average KL loss: 0.025481
Average total loss: 0.071138
tensor(0.0182, device='cuda:0') tensor(0.0968, device='cuda:0') tensor(-5.9588e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.044934
Average KL loss: 0.025466
Average total loss: 0.070400
tensor(0.0182, device='cuda:0') tensor(0.0970, device='cuda:0') tensor(-5.0290e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.043694
Average KL loss: 0.025453
Average total loss: 0.069147
tensor(0.0182, device='cuda:0') tensor(0.0972, device='cuda:0') tensor(-1.3526e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.045963
Average KL loss: 0.025439
Average total loss: 0.071402
tensor(0.0182, device='cuda:0') tensor(0.0974, device='cuda:0') tensor(-6.6110e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.044442
Average KL loss: 0.025427
Average total loss: 0.069869
tensor(0.0182, device='cuda:0') tensor(0.0975, device='cuda:0') tensor(-1.2869e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.044152
Average KL loss: 0.025414
Average total loss: 0.069566
tensor(0.0182, device='cuda:0') tensor(0.0978, device='cuda:0') tensor(-8.3815e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.040937
Average KL loss: 0.025401
Average total loss: 0.066338
tensor(0.0182, device='cuda:0') tensor(0.0979, device='cuda:0') tensor(-8.0821e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.042388
Average KL loss: 0.025388
Average total loss: 0.067776
tensor(0.0183, device='cuda:0') tensor(0.0981, device='cuda:0') tensor(-5.4591e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.050646
Average KL loss: 0.025375
Average total loss: 0.076021
tensor(0.0183, device='cuda:0') tensor(0.0983, device='cuda:0') tensor(-8.6562e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.041507
Average KL loss: 0.025363
Average total loss: 0.066870
tensor(0.0183, device='cuda:0') tensor(0.0985, device='cuda:0') tensor(-6.4059e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.041405
Average KL loss: 0.025352
Average total loss: 0.066757
tensor(0.0183, device='cuda:0') tensor(0.0987, device='cuda:0') tensor(-1.8155e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.041176
Average KL loss: 0.025341
Average total loss: 0.066517
tensor(0.0183, device='cuda:0') tensor(0.0989, device='cuda:0') tensor(-4.0623e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.041919
Average KL loss: 0.025327
Average total loss: 0.067246
tensor(0.0183, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-5.9066e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.042298
Average KL loss: 0.025314
Average total loss: 0.067612
tensor(0.0183, device='cuda:0') tensor(0.0993, device='cuda:0') tensor(-7.4349e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.040126
Average KL loss: 0.025303
Average total loss: 0.065429
tensor(0.0183, device='cuda:0') tensor(0.0994, device='cuda:0') tensor(-5.1704e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.041989
Average KL loss: 0.025291
Average total loss: 0.067281
tensor(0.0183, device='cuda:0') tensor(0.0996, device='cuda:0') tensor(-5.4582e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.041107
Average KL loss: 0.025280
Average total loss: 0.066388
tensor(0.0183, device='cuda:0') tensor(0.0998, device='cuda:0') tensor(-4.9622e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.039070
Average KL loss: 0.025270
Average total loss: 0.064340
tensor(0.0184, device='cuda:0') tensor(0.1000, device='cuda:0') tensor(-6.2408e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.040168
Average KL loss: 0.025258
Average total loss: 0.065426
tensor(0.0184, device='cuda:0') tensor(0.1002, device='cuda:0') tensor(-4.9913e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.040559
Average KL loss: 0.025248
Average total loss: 0.065806
tensor(0.0184, device='cuda:0') tensor(0.1003, device='cuda:0') tensor(-9.2874e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.040433
Average KL loss: 0.025237
Average total loss: 0.065671
tensor(0.0184, device='cuda:0') tensor(0.1005, device='cuda:0') tensor(-5.0741e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.039864
Average KL loss: 0.025226
Average total loss: 0.065090
tensor(0.0184, device='cuda:0') tensor(0.1007, device='cuda:0') tensor(-9.7758e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.048060
Average KL loss: 0.025217
Average total loss: 0.073277
tensor(0.0184, device='cuda:0') tensor(0.1009, device='cuda:0') tensor(-6.8069e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.039646
Average KL loss: 0.025207
Average total loss: 0.064852
tensor(0.0184, device='cuda:0') tensor(0.1011, device='cuda:0') tensor(-4.4352e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.041331
Average KL loss: 0.025197
Average total loss: 0.066529
tensor(0.0184, device='cuda:0') tensor(0.1013, device='cuda:0') tensor(-6.0733e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.039876
Average KL loss: 0.025189
Average total loss: 0.065065
tensor(0.0184, device='cuda:0') tensor(0.1015, device='cuda:0') tensor(-6.8352e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.039804
Average KL loss: 0.025179
Average total loss: 0.064983
tensor(0.0185, device='cuda:0') tensor(0.1017, device='cuda:0') tensor(-5.2610e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.041352
Average KL loss: 0.025169
Average total loss: 0.066521
tensor(0.0185, device='cuda:0') tensor(0.1019, device='cuda:0') tensor(-6.6434e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.039179
Average KL loss: 0.025159
Average total loss: 0.064338
tensor(0.0185, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-2.7050e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.041612
Average KL loss: 0.025154
Average total loss: 0.066765
tensor(0.0185, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-1.2352e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.040966
Average KL loss: 0.025153
Average total loss: 0.066119
tensor(0.0185, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-1.3634e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.039835
Average KL loss: 0.025152
Average total loss: 0.064987
tensor(0.0185, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-4.6355e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.040691
Average KL loss: 0.025151
Average total loss: 0.065842
tensor(0.0185, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-4.9908e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.038491
Average KL loss: 0.025150
Average total loss: 0.063641
tensor(0.0185, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(-1.0038e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.039665
Average KL loss: 0.025149
Average total loss: 0.064814
tensor(0.0185, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(-9.3433e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.040173
Average KL loss: 0.025149
Average total loss: 0.065322
tensor(0.0185, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(-3.9966e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.039042
Average KL loss: 0.025148
Average total loss: 0.064190
tensor(0.0185, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(-1.4971e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.040967
Average KL loss: 0.025147
Average total loss: 0.066114
tensor(0.0185, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(-4.0705e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.039861
Average KL loss: 0.025146
Average total loss: 0.065007
tensor(0.0185, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(-4.0560e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.041143
Average KL loss: 0.025145
Average total loss: 0.066289
tensor(0.0185, device='cuda:0') tensor(0.1023, device='cuda:0') tensor(-2.5551e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.039315
Average KL loss: 0.025145
Average total loss: 0.064459
tensor(0.0185, device='cuda:0') tensor(0.1023, device='cuda:0') tensor(-3.4073e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.040029
Average KL loss: 0.025144
Average total loss: 0.065173
tensor(0.0185, device='cuda:0') tensor(0.1023, device='cuda:0') tensor(-1.6212e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.039853
Average KL loss: 0.025143
Average total loss: 0.064996
tensor(0.0185, device='cuda:0') tensor(0.1023, device='cuda:0') tensor(-5.3038e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.039784
Average KL loss: 0.025142
Average total loss: 0.064927
tensor(0.0185, device='cuda:0') tensor(0.1023, device='cuda:0') tensor(-1.0919e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.039770
Average KL loss: 0.025142
Average total loss: 0.064912
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-9.2076e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.039297
Average KL loss: 0.025141
Average total loss: 0.064438
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-4.7558e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.039224
Average KL loss: 0.025141
Average total loss: 0.064365
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-4.2927e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.039005
Average KL loss: 0.025141
Average total loss: 0.064147
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-7.5101e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.040223
Average KL loss: 0.025141
Average total loss: 0.065365
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-5.3965e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.039155
Average KL loss: 0.025141
Average total loss: 0.064296
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-5.1063e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.040262
Average KL loss: 0.025141
Average total loss: 0.065403
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-7.9488e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.038219
Average KL loss: 0.025141
Average total loss: 0.063360
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-1.5075e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.039651
Average KL loss: 0.025141
Average total loss: 0.064792
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-5.1414e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.038290
Average KL loss: 0.025141
Average total loss: 0.063431
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-3.3006e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.039346
Average KL loss: 0.025141
Average total loss: 0.064487
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-1.2944e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.039419
Average KL loss: 0.025141
Average total loss: 0.064560
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-4.7532e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.040321
Average KL loss: 0.025141
Average total loss: 0.065461
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-3.2666e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.039035
Average KL loss: 0.025140
Average total loss: 0.064175
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-6.7488e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.039523
Average KL loss: 0.025140
Average total loss: 0.064663
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-5.3078e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.040078
Average KL loss: 0.025140
Average total loss: 0.065218
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-1.3202e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.040827
Average KL loss: 0.025140
Average total loss: 0.065967
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-4.3855e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.038136
Average KL loss: 0.025140
Average total loss: 0.063276
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-5.5008e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.041611
Average KL loss: 0.025140
Average total loss: 0.066751
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-6.3367e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.039616
Average KL loss: 0.025140
Average total loss: 0.064756
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-3.8127e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.039428
Average KL loss: 0.025140
Average total loss: 0.064568
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-3.3372e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.038619
Average KL loss: 0.025140
Average total loss: 0.063759
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-1.6741e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.039577
Average KL loss: 0.025140
Average total loss: 0.064716
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-5.6131e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.039376
Average KL loss: 0.025140
Average total loss: 0.064515
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-8.0037e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.039404
Average KL loss: 0.025140
Average total loss: 0.064543
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-8.6553e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.039197
Average KL loss: 0.025140
Average total loss: 0.064337
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-1.8263e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.039906
Average KL loss: 0.025140
Average total loss: 0.065045
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-8.1203e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.040305
Average KL loss: 0.025140
Average total loss: 0.065444
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-7.3765e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.040385
Average KL loss: 0.025139
Average total loss: 0.065524
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-3.8595e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.040654
Average KL loss: 0.025139
Average total loss: 0.065793
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-4.1840e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.040121
Average KL loss: 0.025139
Average total loss: 0.065261
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-3.0385e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.040089
Average KL loss: 0.025139
Average total loss: 0.065229
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-3.0644e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.040368
Average KL loss: 0.025139
Average total loss: 0.065507
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-9.5223e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.040678
Average KL loss: 0.025139
Average total loss: 0.065817
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-9.8572e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.039399
Average KL loss: 0.025139
Average total loss: 0.064539
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-5.6474e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.038997
Average KL loss: 0.025139
Average total loss: 0.064136
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-1.2257e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.039875
Average KL loss: 0.025139
Average total loss: 0.065014
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-3.9229e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.039435
Average KL loss: 0.025139
Average total loss: 0.064574
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-3.8956e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.040307
Average KL loss: 0.025139
Average total loss: 0.065446
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-5.4067e-10, device='cuda:0')
 Percentile value: 5.978144407272339
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =     123 /    1728             (  7.12%) | total_pruned =    1605 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      49 /   36864             (  0.13%) | total_pruned =   36815 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      34 /   36864             (  0.09%) | total_pruned =   36830 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      74 /   36864             (  0.20%) | total_pruned =   36790 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     190 /   36864             (  0.52%) | total_pruned =   36674 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     674 /   73728             (  0.91%) | total_pruned =   73054 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1393 /  147456             (  0.94%) | total_pruned =  146063 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     124 /    8192             (  1.51%) | total_pruned =    8068 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1136 /  147456             (  0.77%) | total_pruned =  146320 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     947 /  147456             (  0.64%) | total_pruned =  146509 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2064 /  294912             (  0.70%) | total_pruned =  292848 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     129 /     256             ( 50.39%) | total_pruned =     127 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2561 /  589824             (  0.43%) | total_pruned =  587263 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     101 /     256             ( 39.45%) | total_pruned =     155 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     365 /   32768             (  1.11%) | total_pruned =   32403 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1447 /  589824             (  0.25%) | total_pruned =  588377 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1185 /  589824             (  0.20%) | total_pruned =  588639 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2375 / 1179648             (  0.20%) | total_pruned = 1177273 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     308 /     512             ( 60.16%) | total_pruned =     204 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1963 / 2359296             (  0.08%) | total_pruned = 2357333 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      40 /  131072             (  0.03%) | total_pruned =  131032 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     104 /     512             ( 20.31%) | total_pruned =     408 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1164 / 2359296             (  0.05%) | total_pruned = 2358132 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      66 /     512             ( 12.89%) | total_pruned =     446 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1278 / 2359296             (  0.05%) | total_pruned = 2358018 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     115 /     512             ( 22.46%) | total_pruned =     397 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      82 /     512             ( 16.02%) | total_pruned =     430 | shape = torch.Size([512])
linear.weight        | nonzeros =     585 /    5120             ( 11.43%) | total_pruned =    4535 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.331958 Accuracy: 78.27 90.54 % Best test Accuracy: 79.38%
tensor(0.0185, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-2.2449e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.341176
Average KL loss: 0.024759
Average total loss: 0.365935
tensor(0.0174, device='cuda:0') tensor(0.0921, device='cuda:0') tensor(-2.1107e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.345235
Average KL loss: 0.023857
Average total loss: 0.369092
tensor(0.0162, device='cuda:0') tensor(0.0830, device='cuda:0') tensor(-3.7005e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.351381
Average KL loss: 0.022640
Average total loss: 0.374021
tensor(0.0150, device='cuda:0') tensor(0.0745, device='cuda:0') tensor(-2.5237e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.345076
Average KL loss: 0.020951
Average total loss: 0.366027
tensor(0.0137, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-2.3339e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.345859
Average KL loss: 0.018719
Average total loss: 0.364578
tensor(0.0124, device='cuda:0') tensor(0.0602, device='cuda:0') tensor(-1.2319e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.346663
Average KL loss: 0.016171
Average total loss: 0.362833
tensor(0.0111, device='cuda:0') tensor(0.0553, device='cuda:0') tensor(-2.3767e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.348845
Average KL loss: 0.013921
Average total loss: 0.362765
tensor(0.0100, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(-2.2765e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.348448
Average KL loss: 0.012446
Average total loss: 0.360894
tensor(0.0093, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(-7.9334e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.349909
Average KL loss: 0.011650
Average total loss: 0.361559
tensor(0.0088, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(-2.3610e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.347678
Average KL loss: 0.011241
Average total loss: 0.358919
tensor(0.0085, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-4.1189e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.347967
Average KL loss: 0.011023
Average total loss: 0.358990
tensor(0.0084, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-1.5215e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.346513
Average KL loss: 0.010895
Average total loss: 0.357408
tensor(0.0083, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-1.9010e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.342444
Average KL loss: 0.010813
Average total loss: 0.353256
tensor(0.0083, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-1.4887e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.350223
Average KL loss: 0.010755
Average total loss: 0.360977
tensor(0.0082, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-1.3843e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.352525
Average KL loss: 0.010713
Average total loss: 0.363238
tensor(0.0082, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-2.0213e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.348981
Average KL loss: 0.010681
Average total loss: 0.359661
tensor(0.0082, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-3.4658e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.346071
Average KL loss: 0.010656
Average total loss: 0.356728
tensor(0.0082, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-2.9231e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.347181
Average KL loss: 0.010636
Average total loss: 0.357817
tensor(0.0082, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-2.7896e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.340850
Average KL loss: 0.010619
Average total loss: 0.351469
tensor(0.0082, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-3.0073e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.345001
Average KL loss: 0.010606
Average total loss: 0.355608
tensor(0.0082, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-5.0504e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.345337
Average KL loss: 0.010595
Average total loss: 0.355932
tensor(0.0082, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-1.4265e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.348379
Average KL loss: 0.010585
Average total loss: 0.358964
tensor(0.0082, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-1.0609e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.346370
Average KL loss: 0.010576
Average total loss: 0.356946
tensor(0.0082, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-1.0961e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.341085
Average KL loss: 0.010569
Average total loss: 0.351654
tensor(0.0082, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-1.6085e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.346309
Average KL loss: 0.010563
Average total loss: 0.356872
tensor(0.0082, device='cuda:0') tensor(0.0481, device='cuda:0') tensor(-1.5646e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.346204
Average KL loss: 0.010558
Average total loss: 0.356762
tensor(0.0082, device='cuda:0') tensor(0.0482, device='cuda:0') tensor(-7.2890e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.347343
Average KL loss: 0.010552
Average total loss: 0.357895
tensor(0.0082, device='cuda:0') tensor(0.0482, device='cuda:0') tensor(-3.2496e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.340529
Average KL loss: 0.010547
Average total loss: 0.351076
tensor(0.0082, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-6.7566e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.349598
Average KL loss: 0.010543
Average total loss: 0.360141
tensor(0.0082, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-1.8470e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.338378
Average KL loss: 0.010538
Average total loss: 0.348916
tensor(0.0082, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-6.1081e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.340145
Average KL loss: 0.010534
Average total loss: 0.350679
tensor(0.0082, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-2.5999e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.344585
Average KL loss: 0.010530
Average total loss: 0.355115
tensor(0.0082, device='cuda:0') tensor(0.0486, device='cuda:0') tensor(-1.3281e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.344111
Average KL loss: 0.010526
Average total loss: 0.354637
tensor(0.0082, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-8.5411e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.342200
Average KL loss: 0.010523
Average total loss: 0.352723
tensor(0.0082, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-1.6232e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.340734
Average KL loss: 0.010519
Average total loss: 0.351254
tensor(0.0082, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-8.2849e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.341239
Average KL loss: 0.010516
Average total loss: 0.351755
tensor(0.0082, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-2.1633e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.348936
Average KL loss: 0.010511
Average total loss: 0.359447
tensor(0.0082, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-1.9325e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.338747
Average KL loss: 0.010506
Average total loss: 0.349253
tensor(0.0082, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(-2.0487e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.342042
Average KL loss: 0.010502
Average total loss: 0.352544
tensor(0.0082, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(-2.6155e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.341171
Average KL loss: 0.010498
Average total loss: 0.351669
tensor(0.0082, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(-9.0015e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.342900
Average KL loss: 0.010494
Average total loss: 0.353393
tensor(0.0082, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(-1.1105e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.335232
Average KL loss: 0.010491
Average total loss: 0.345723
tensor(0.0082, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(-2.4986e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.336824
Average KL loss: 0.010491
Average total loss: 0.347315
tensor(0.0082, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(-1.8738e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.345939
Average KL loss: 0.010491
Average total loss: 0.356430
tensor(0.0082, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(-1.1755e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.338514
Average KL loss: 0.010491
Average total loss: 0.349004
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-2.9790e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.351643
Average KL loss: 0.010490
Average total loss: 0.362133
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-1.0187e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.341852
Average KL loss: 0.010490
Average total loss: 0.352342
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-2.3585e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.338401
Average KL loss: 0.010490
Average total loss: 0.348891
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-1.4561e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.338995
Average KL loss: 0.010489
Average total loss: 0.349485
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-1.0741e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.334435
Average KL loss: 0.010489
Average total loss: 0.344924
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-1.4740e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.336047
Average KL loss: 0.010489
Average total loss: 0.346536
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-2.3128e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.340261
Average KL loss: 0.010489
Average total loss: 0.350750
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-8.5963e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.339291
Average KL loss: 0.010488
Average total loss: 0.349779
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-1.2875e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.336637
Average KL loss: 0.010488
Average total loss: 0.347125
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-1.0221e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.336243
Average KL loss: 0.010488
Average total loss: 0.346731
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-1.7276e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.341084
Average KL loss: 0.010488
Average total loss: 0.351572
tensor(0.0082, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-4.1253e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.336207
Average KL loss: 0.010488
Average total loss: 0.346694
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-9.1144e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.341018
Average KL loss: 0.010488
Average total loss: 0.351505
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-6.9046e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.335674
Average KL loss: 0.010487
Average total loss: 0.346162
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.0833e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.343397
Average KL loss: 0.010487
Average total loss: 0.353884
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.4256e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.337985
Average KL loss: 0.010487
Average total loss: 0.348472
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-8.5084e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.339130
Average KL loss: 0.010487
Average total loss: 0.349617
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(1.0906e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.338553
Average KL loss: 0.010487
Average total loss: 0.349040
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-8.2399e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.342733
Average KL loss: 0.010487
Average total loss: 0.353220
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.2752e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.333294
Average KL loss: 0.010487
Average total loss: 0.343781
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-2.0451e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.334096
Average KL loss: 0.010487
Average total loss: 0.344583
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.8620e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.336199
Average KL loss: 0.010487
Average total loss: 0.346686
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-2.5393e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.338256
Average KL loss: 0.010487
Average total loss: 0.348743
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-9.5410e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.341849
Average KL loss: 0.010487
Average total loss: 0.352336
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.0009e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.350112
Average KL loss: 0.010487
Average total loss: 0.360599
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.7093e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.341365
Average KL loss: 0.010487
Average total loss: 0.351852
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-3.3167e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.340466
Average KL loss: 0.010487
Average total loss: 0.350952
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-6.2905e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.336764
Average KL loss: 0.010487
Average total loss: 0.347251
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-5.4219e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.338710
Average KL loss: 0.010487
Average total loss: 0.349197
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.6819e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.339575
Average KL loss: 0.010487
Average total loss: 0.350061
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.5108e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.337059
Average KL loss: 0.010487
Average total loss: 0.347545
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.2432e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.336322
Average KL loss: 0.010487
Average total loss: 0.346809
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.2621e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.338180
Average KL loss: 0.010487
Average total loss: 0.348667
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-3.5484e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.343156
Average KL loss: 0.010487
Average total loss: 0.353643
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.5819e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.338055
Average KL loss: 0.010487
Average total loss: 0.348542
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-8.9413e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.341065
Average KL loss: 0.010487
Average total loss: 0.351551
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-2.3673e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.338454
Average KL loss: 0.010487
Average total loss: 0.348940
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.6629e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.334120
Average KL loss: 0.010487
Average total loss: 0.344607
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-6.9102e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.342558
Average KL loss: 0.010487
Average total loss: 0.353045
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.0631e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.335786
Average KL loss: 0.010487
Average total loss: 0.346272
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-3.2667e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.338091
Average KL loss: 0.010487
Average total loss: 0.348577
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-6.1433e-10, device='cuda:0')
 Percentile value: 6.175161361694336
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =      96 /    1728             (  5.56%) | total_pruned =    1632 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      23 /   36864             (  0.06%) | total_pruned =   36841 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      17 /   36864             (  0.05%) | total_pruned =   36847 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      52 /   36864             (  0.14%) | total_pruned =   36812 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     132 /   36864             (  0.36%) | total_pruned =   36732 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     444 /   73728             (  0.60%) | total_pruned =   73284 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     820 /  147456             (  0.56%) | total_pruned =  146636 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      79 /    8192             (  0.96%) | total_pruned =    8113 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     696 /  147456             (  0.47%) | total_pruned =  146760 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     558 /  147456             (  0.38%) | total_pruned =  146898 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1202 /  294912             (  0.41%) | total_pruned =  293710 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1458 /  589824             (  0.25%) | total_pruned =  588366 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      89 /     256             ( 34.77%) | total_pruned =     167 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     175 /   32768             (  0.53%) | total_pruned =   32593 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     768 /  589824             (  0.13%) | total_pruned =  589056 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     575 /  589824             (  0.10%) | total_pruned =  589249 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      67 /     256             ( 26.17%) | total_pruned =     189 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     880 / 1179648             (  0.07%) | total_pruned = 1178768 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     594 / 2359296             (  0.03%) | total_pruned = 2358702 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      88 /     512             ( 17.19%) | total_pruned =     424 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       7 /  131072             (  0.01%) | total_pruned =  131065 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     441 / 2359296             (  0.02%) | total_pruned = 2358855 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     366 / 2359296             (  0.02%) | total_pruned = 2358930 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      28 /     512             (  5.47%) | total_pruned =     484 | shape = torch.Size([512])
linear.weight        | nonzeros =     227 /    5120             (  4.43%) | total_pruned =    4893 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.567393 Accuracy: 75.09 83.80 % Best test Accuracy: 76.21%
tensor(0.0082, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-6.9537e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.524203
Average KL loss: 0.010416
Average total loss: 0.534619
tensor(0.0079, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-2.0957e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.522068
Average KL loss: 0.010251
Average total loss: 0.532319
tensor(0.0075, device='cuda:0') tensor(0.0421, device='cuda:0') tensor(-2.3530e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.522020
Average KL loss: 0.010021
Average total loss: 0.532041
tensor(0.0072, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-6.3524e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.523622
Average KL loss: 0.009671
Average total loss: 0.533293
tensor(0.0068, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-2.2610e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.531347
Average KL loss: 0.009133
Average total loss: 0.540480
tensor(0.0063, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-1.1814e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.525578
Average KL loss: 0.008373
Average total loss: 0.533951
tensor(0.0059, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(3.3512e-11, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.522286
Average KL loss: 0.007518
Average total loss: 0.529803
tensor(0.0055, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-6.8115e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.525498
Average KL loss: 0.006844
Average total loss: 0.532342
tensor(0.0052, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.4496e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.533878
Average KL loss: 0.006472
Average total loss: 0.540350
tensor(0.0050, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-9.0463e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.526814
Average KL loss: 0.006299
Average total loss: 0.533113
tensor(0.0049, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-9.5630e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.525805
Average KL loss: 0.006219
Average total loss: 0.532024
tensor(0.0049, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-1.7928e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.525371
Average KL loss: 0.006180
Average total loss: 0.531551
tensor(0.0048, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-1.8162e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.520294
Average KL loss: 0.006158
Average total loss: 0.526453
tensor(0.0048, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-2.4093e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.530357
Average KL loss: 0.006146
Average total loss: 0.536503
tensor(0.0048, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-2.6050e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.524944
Average KL loss: 0.006138
Average total loss: 0.531081
tensor(0.0048, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-1.4490e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.523583
Average KL loss: 0.006131
Average total loss: 0.529714
tensor(0.0048, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-7.9065e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.525354
Average KL loss: 0.006126
Average total loss: 0.531480
tensor(0.0048, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-1.6028e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.528449
Average KL loss: 0.006123
Average total loss: 0.534572
tensor(0.0048, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-6.5988e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.521594
Average KL loss: 0.006120
Average total loss: 0.527714
tensor(0.0048, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-1.3957e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.521922
Average KL loss: 0.006118
Average total loss: 0.528039
tensor(0.0048, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-4.5840e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.521464
Average KL loss: 0.006116
Average total loss: 0.527580
tensor(0.0048, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-1.7292e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.524484
Average KL loss: 0.006115
Average total loss: 0.530599
tensor(0.0048, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-1.1563e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.523070
Average KL loss: 0.006114
Average total loss: 0.529184
tensor(0.0048, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-2.2617e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.528450
Average KL loss: 0.006114
Average total loss: 0.534564
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.3340e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.525447
Average KL loss: 0.006113
Average total loss: 0.531560
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.5661e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.523192
Average KL loss: 0.006113
Average total loss: 0.529305
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-2.0733e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.524746
Average KL loss: 0.006113
Average total loss: 0.530859
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-8.5146e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.521110
Average KL loss: 0.006113
Average total loss: 0.527223
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-2.2295e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.522895
Average KL loss: 0.006113
Average total loss: 0.529008
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.4882e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.521986
Average KL loss: 0.006113
Average total loss: 0.528099
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-8.6777e-11, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.522046
Average KL loss: 0.006113
Average total loss: 0.528159
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-6.4380e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.521316
Average KL loss: 0.006113
Average total loss: 0.527429
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-2.6056e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.523224
Average KL loss: 0.006113
Average total loss: 0.529337
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-7.2769e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.519793
Average KL loss: 0.006113
Average total loss: 0.525906
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.1021e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.524999
Average KL loss: 0.006113
Average total loss: 0.531112
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-5.2395e-11, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.521124
Average KL loss: 0.006113
Average total loss: 0.527237
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-3.4281e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.518699
Average KL loss: 0.006113
Average total loss: 0.524811
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.0967e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.519699
Average KL loss: 0.006113
Average total loss: 0.525811
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-3.0209e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.517681
Average KL loss: 0.006113
Average total loss: 0.523793
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.6223e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.525446
Average KL loss: 0.006113
Average total loss: 0.531559
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.1477e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.518257
Average KL loss: 0.006113
Average total loss: 0.524370
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.8459e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.534004
Average KL loss: 0.006113
Average total loss: 0.540117
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-7.6093e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.522093
Average KL loss: 0.006113
Average total loss: 0.528206
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.6964e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.524321
Average KL loss: 0.006112
Average total loss: 0.530434
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.9301e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.527348
Average KL loss: 0.006112
Average total loss: 0.533460
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-8.4689e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.518616
Average KL loss: 0.006112
Average total loss: 0.524728
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-6.8610e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.526689
Average KL loss: 0.006112
Average total loss: 0.532801
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-8.9377e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.522738
Average KL loss: 0.006112
Average total loss: 0.528850
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-6.7619e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.536397
Average KL loss: 0.006112
Average total loss: 0.542509
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.0369e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.537864
Average KL loss: 0.006112
Average total loss: 0.543976
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.4338e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.518639
Average KL loss: 0.006112
Average total loss: 0.524751
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-3.7388e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.519732
Average KL loss: 0.006112
Average total loss: 0.525845
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-5.5930e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.520727
Average KL loss: 0.006112
Average total loss: 0.526839
tensor(0.0049, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-6.8845e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.530400
Average KL loss: 0.006112
Average total loss: 0.536512
tensor(0.0049, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(8.6489e-11, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.521830
Average KL loss: 0.006112
Average total loss: 0.527942
tensor(0.0049, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.7925e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.520815
Average KL loss: 0.006112
Average total loss: 0.526927
tensor(0.0049, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.3143e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.523565
Average KL loss: 0.006112
Average total loss: 0.529677
tensor(0.0049, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.4640e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.520782
Average KL loss: 0.006112
Average total loss: 0.526894
tensor(0.0049, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.6353e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.519827
Average KL loss: 0.006112
Average total loss: 0.525939
tensor(0.0049, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-3.0695e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.528031
Average KL loss: 0.006112
Average total loss: 0.534143
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.8428e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.525146
Average KL loss: 0.006112
Average total loss: 0.531258
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-3.1789e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.525637
Average KL loss: 0.006112
Average total loss: 0.531749
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.8209e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.521743
Average KL loss: 0.006112
Average total loss: 0.527855
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(1.4990e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.520949
Average KL loss: 0.006112
Average total loss: 0.527061
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.0084e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.518065
Average KL loss: 0.006112
Average total loss: 0.524177
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.3381e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.522845
Average KL loss: 0.006112
Average total loss: 0.528957
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.8689e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.519199
Average KL loss: 0.006112
Average total loss: 0.525311
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.6016e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.519406
Average KL loss: 0.006112
Average total loss: 0.525518
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.0852e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.518811
Average KL loss: 0.006112
Average total loss: 0.524924
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-4.1065e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.523419
Average KL loss: 0.006112
Average total loss: 0.529532
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.0349e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.520748
Average KL loss: 0.006112
Average total loss: 0.526861
tensor(0.0049, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-9.9122e-10, device='cuda:0')
 Percentile value: 6.3052215576171875
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =      89 /    1728             (  5.15%) | total_pruned =    1639 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      17 /   36864             (  0.05%) | total_pruned =   36847 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      12 /   36864             (  0.03%) | total_pruned =   36852 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      45 /   36864             (  0.12%) | total_pruned =   36819 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      97 /   36864             (  0.26%) | total_pruned =   36767 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     283 /   73728             (  0.38%) | total_pruned =   73445 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     426 /  147456             (  0.29%) | total_pruned =  147030 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      53 /    8192             (  0.65%) | total_pruned =    8139 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     394 /  147456             (  0.27%) | total_pruned =  147062 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     295 /  147456             (  0.20%) | total_pruned =  147161 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     558 /  294912             (  0.19%) | total_pruned =  294354 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     683 /  589824             (  0.12%) | total_pruned =  589141 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      83 /   32768             (  0.25%) | total_pruned =   32685 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     336 /  589824             (  0.06%) | total_pruned =  589488 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     254 /  589824             (  0.04%) | total_pruned =  589570 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     286 / 1179648             (  0.02%) | total_pruned = 1179362 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      92 /     512             ( 17.97%) | total_pruned =     420 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     197 / 2359296             (  0.01%) | total_pruned = 2359099 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       1 /  131072             (  0.00%) | total_pruned =  131071 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      28 /     512             (  5.47%) | total_pruned =     484 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     169 / 2359296             (  0.01%) | total_pruned = 2359127 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      34 /     512             (  6.64%) | total_pruned =     478 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     143 / 2359296             (  0.01%) | total_pruned = 2359153 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
linear.weight        | nonzeros =     114 /    5120             (  2.23%) | total_pruned =    5006 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 0.804327 Accuracy: 68.26 72.03 % Best test Accuracy: 68.38%
