Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/8]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2560e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302421
Average KL loss: 0.000030
Average total loss: 2.302451
tensor(0.0007, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-8.2324e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.297203
Average KL loss: 0.000167
Average total loss: 2.297370
tensor(0.0035, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.8850e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.143323
Average KL loss: 0.001181
Average total loss: 2.144504
tensor(0.0213, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-8.3641e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.579244
Average KL loss: 0.004773
Average total loss: 1.584018
tensor(0.0506, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-1.3324e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.156164
Average KL loss: 0.008383
Average total loss: 1.164547
tensor(0.0693, device='cuda:0') tensor(0.0680, device='cuda:0') tensor(-9.3565e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.896000
Average KL loss: 0.010911
Average total loss: 0.906911
tensor(0.0809, device='cuda:0') tensor(0.0820, device='cuda:0') tensor(-7.6923e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.755201
Average KL loss: 0.012547
Average total loss: 0.767747
tensor(0.0882, device='cuda:0') tensor(0.0909, device='cuda:0') tensor(-6.2198e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.654762
Average KL loss: 0.013609
Average total loss: 0.668371
tensor(0.0935, device='cuda:0') tensor(0.0973, device='cuda:0') tensor(-4.2866e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.579746
Average KL loss: 0.014363
Average total loss: 0.594109
tensor(0.0972, device='cuda:0') tensor(0.1018, device='cuda:0') tensor(-4.6336e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.529098
Average KL loss: 0.014904
Average total loss: 0.544002
tensor(0.1002, device='cuda:0') tensor(0.1055, device='cuda:0') tensor(-4.1520e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.492237
Average KL loss: 0.015383
Average total loss: 0.507620
tensor(0.1030, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-4.3237e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.463605
Average KL loss: 0.015832
Average total loss: 0.479437
tensor(0.1050, device='cuda:0') tensor(0.1125, device='cuda:0') tensor(-3.0381e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.430374
Average KL loss: 0.016240
Average total loss: 0.446614
tensor(0.1071, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-3.9063e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.390284
Average KL loss: 0.016581
Average total loss: 0.406864
tensor(0.1086, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-5.2340e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.368797
Average KL loss: 0.016881
Average total loss: 0.385678
tensor(0.1101, device='cuda:0') tensor(0.1205, device='cuda:0') tensor(-4.0495e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.345256
Average KL loss: 0.017177
Average total loss: 0.362433
tensor(0.1113, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(-2.9872e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.326996
Average KL loss: 0.017462
Average total loss: 0.344458
tensor(0.1128, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-4.1281e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.305700
Average KL loss: 0.017740
Average total loss: 0.323440
tensor(0.1138, device='cuda:0') tensor(0.1277, device='cuda:0') tensor(-2.8233e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.290583
Average KL loss: 0.018007
Average total loss: 0.308591
tensor(0.1150, device='cuda:0') tensor(0.1301, device='cuda:0') tensor(-2.5681e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.275988
Average KL loss: 0.018263
Average total loss: 0.294252
tensor(0.1160, device='cuda:0') tensor(0.1322, device='cuda:0') tensor(-2.7757e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.264859
Average KL loss: 0.018515
Average total loss: 0.283375
tensor(0.1168, device='cuda:0') tensor(0.1345, device='cuda:0') tensor(-2.5192e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.248978
Average KL loss: 0.018768
Average total loss: 0.267746
tensor(0.1178, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(-2.3692e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.240694
Average KL loss: 0.019014
Average total loss: 0.259708
tensor(0.1185, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-2.4852e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.227421
Average KL loss: 0.019258
Average total loss: 0.246679
tensor(0.1192, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(-2.3178e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.222810
Average KL loss: 0.019469
Average total loss: 0.242280
tensor(0.1198, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-2.1148e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.209409
Average KL loss: 0.019698
Average total loss: 0.229107
tensor(0.1206, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(-2.5552e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.202060
Average KL loss: 0.019898
Average total loss: 0.221958
tensor(0.1211, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(-1.8906e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.196103
Average KL loss: 0.020101
Average total loss: 0.216205
tensor(0.1216, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(-1.7847e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.182052
Average KL loss: 0.020287
Average total loss: 0.202339
tensor(0.1220, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(-1.9692e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.181550
Average KL loss: 0.020457
Average total loss: 0.202008
tensor(0.1225, device='cuda:0') tensor(0.1528, device='cuda:0') tensor(-1.7478e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.171331
Average KL loss: 0.020629
Average total loss: 0.191960
tensor(0.1230, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(-1.5077e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.162731
Average KL loss: 0.020784
Average total loss: 0.183515
tensor(0.1233, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(-1.4295e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.161432
Average KL loss: 0.020925
Average total loss: 0.182357
tensor(0.1236, device='cuda:0') tensor(0.1576, device='cuda:0') tensor(-1.5592e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.158957
Average KL loss: 0.021090
Average total loss: 0.180046
tensor(0.1240, device='cuda:0') tensor(0.1594, device='cuda:0') tensor(-1.7454e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.148707
Average KL loss: 0.021236
Average total loss: 0.169943
tensor(0.1242, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-1.5034e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.147180
Average KL loss: 0.021360
Average total loss: 0.168540
tensor(0.1243, device='cuda:0') tensor(0.1623, device='cuda:0') tensor(-1.6173e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.137722
Average KL loss: 0.021486
Average total loss: 0.159208
tensor(0.1246, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(-1.2932e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.134117
Average KL loss: 0.021598
Average total loss: 0.155715
tensor(0.1247, device='cuda:0') tensor(0.1649, device='cuda:0') tensor(-1.5123e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.129823
Average KL loss: 0.021698
Average total loss: 0.151521
tensor(0.1248, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-1.2915e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.129326
Average KL loss: 0.021806
Average total loss: 0.151133
tensor(0.1251, device='cuda:0') tensor(0.1675, device='cuda:0') tensor(-1.2426e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.121782
Average KL loss: 0.021907
Average total loss: 0.143689
tensor(0.1251, device='cuda:0') tensor(0.1686, device='cuda:0') tensor(-1.1998e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.120048
Average KL loss: 0.022003
Average total loss: 0.142051
tensor(0.1253, device='cuda:0') tensor(0.1699, device='cuda:0') tensor(-1.1957e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.114585
Average KL loss: 0.022083
Average total loss: 0.136668
tensor(0.1253, device='cuda:0') tensor(0.1708, device='cuda:0') tensor(-1.1209e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.113822
Average KL loss: 0.022174
Average total loss: 0.135996
tensor(0.1255, device='cuda:0') tensor(0.1720, device='cuda:0') tensor(-1.1891e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.108297
Average KL loss: 0.022250
Average total loss: 0.130547
tensor(0.1254, device='cuda:0') tensor(0.1730, device='cuda:0') tensor(-1.0203e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.105496
Average KL loss: 0.022307
Average total loss: 0.127803
tensor(0.1254, device='cuda:0') tensor(0.1740, device='cuda:0') tensor(-8.0844e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.103948
Average KL loss: 0.022371
Average total loss: 0.126319
tensor(0.1254, device='cuda:0') tensor(0.1750, device='cuda:0') tensor(-1.0046e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.099396
Average KL loss: 0.022439
Average total loss: 0.121834
tensor(0.1254, device='cuda:0') tensor(0.1758, device='cuda:0') tensor(-1.0772e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.101471
Average KL loss: 0.022499
Average total loss: 0.123970
tensor(0.1255, device='cuda:0') tensor(0.1768, device='cuda:0') tensor(-1.1110e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.093330
Average KL loss: 0.022548
Average total loss: 0.115877
tensor(0.1253, device='cuda:0') tensor(0.1775, device='cuda:0') tensor(-9.8423e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.095483
Average KL loss: 0.022575
Average total loss: 0.118058
tensor(0.1252, device='cuda:0') tensor(0.1782, device='cuda:0') tensor(-7.7177e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.091381
Average KL loss: 0.022627
Average total loss: 0.114007
tensor(0.1253, device='cuda:0') tensor(0.1791, device='cuda:0') tensor(-9.2378e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.090271
Average KL loss: 0.022669
Average total loss: 0.112940
tensor(0.1251, device='cuda:0') tensor(0.1799, device='cuda:0') tensor(-7.0178e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.087598
Average KL loss: 0.022710
Average total loss: 0.110308
tensor(0.1251, device='cuda:0') tensor(0.1806, device='cuda:0') tensor(-6.4814e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.083174
Average KL loss: 0.022731
Average total loss: 0.105906
tensor(0.1249, device='cuda:0') tensor(0.1811, device='cuda:0') tensor(-7.2284e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.083076
Average KL loss: 0.022752
Average total loss: 0.105828
tensor(0.1249, device='cuda:0') tensor(0.1818, device='cuda:0') tensor(-1.0395e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.081693
Average KL loss: 0.022780
Average total loss: 0.104473
tensor(0.1247, device='cuda:0') tensor(0.1824, device='cuda:0') tensor(-8.2467e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.078493
Average KL loss: 0.022798
Average total loss: 0.101291
tensor(0.1246, device='cuda:0') tensor(0.1830, device='cuda:0') tensor(-5.8192e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.076347
Average KL loss: 0.022814
Average total loss: 0.099161
tensor(0.1245, device='cuda:0') tensor(0.1835, device='cuda:0') tensor(-6.0368e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.077642
Average KL loss: 0.022823
Average total loss: 0.100464
tensor(0.1243, device='cuda:0') tensor(0.1841, device='cuda:0') tensor(-6.6384e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.074115
Average KL loss: 0.022846
Average total loss: 0.096961
tensor(0.1242, device='cuda:0') tensor(0.1846, device='cuda:0') tensor(-6.5722e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.073233
Average KL loss: 0.022854
Average total loss: 0.096087
tensor(0.1240, device='cuda:0') tensor(0.1851, device='cuda:0') tensor(-6.3970e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.070640
Average KL loss: 0.022854
Average total loss: 0.093494
tensor(0.1238, device='cuda:0') tensor(0.1854, device='cuda:0') tensor(-5.0423e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.068869
Average KL loss: 0.022848
Average total loss: 0.091717
tensor(0.1236, device='cuda:0') tensor(0.1859, device='cuda:0') tensor(-6.2936e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.068955
Average KL loss: 0.022850
Average total loss: 0.091805
tensor(0.1235, device='cuda:0') tensor(0.1863, device='cuda:0') tensor(-7.6254e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.066335
Average KL loss: 0.022848
Average total loss: 0.089183
tensor(0.1232, device='cuda:0') tensor(0.1866, device='cuda:0') tensor(-5.3634e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.063863
Average KL loss: 0.022814
Average total loss: 0.086677
tensor(0.1230, device='cuda:0') tensor(0.1866, device='cuda:0') tensor(-5.8858e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.064912
Average KL loss: 0.022788
Average total loss: 0.087700
tensor(0.1228, device='cuda:0') tensor(0.1870, device='cuda:0') tensor(-5.7582e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.063550
Average KL loss: 0.022785
Average total loss: 0.086334
tensor(0.1226, device='cuda:0') tensor(0.1873, device='cuda:0') tensor(-6.0389e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.062659
Average KL loss: 0.022778
Average total loss: 0.085436
tensor(0.1224, device='cuda:0') tensor(0.1877, device='cuda:0') tensor(-4.8723e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.061156
Average KL loss: 0.022763
Average total loss: 0.083919
tensor(0.1223, device='cuda:0') tensor(0.1880, device='cuda:0') tensor(-3.1509e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.061508
Average KL loss: 0.022760
Average total loss: 0.084268
tensor(0.1222, device='cuda:0') tensor(0.1884, device='cuda:0') tensor(-5.4749e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.061494
Average KL loss: 0.022763
Average total loss: 0.084257
tensor(0.1220, device='cuda:0') tensor(0.1887, device='cuda:0') tensor(-4.4355e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.058548
Average KL loss: 0.022759
Average total loss: 0.081307
tensor(0.1218, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-5.5459e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.056393
Average KL loss: 0.022735
Average total loss: 0.079128
tensor(0.1216, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-5.3413e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.056403
Average KL loss: 0.022697
Average total loss: 0.079100
tensor(0.1214, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(-3.6442e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.054392
Average KL loss: 0.022673
Average total loss: 0.077065
tensor(0.1211, device='cuda:0') tensor(0.1894, device='cuda:0') tensor(-4.5074e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.055205
Average KL loss: 0.022638
Average total loss: 0.077843
tensor(0.1209, device='cuda:0') tensor(0.1896, device='cuda:0') tensor(-3.4333e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.054357
Average KL loss: 0.022622
Average total loss: 0.076979
tensor(0.1207, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-2.8994e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.052594
Average KL loss: 0.022593
Average total loss: 0.075186
tensor(0.1205, device='cuda:0') tensor(0.1899, device='cuda:0') tensor(-3.6429e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.050563
Average KL loss: 0.022552
Average total loss: 0.073115
tensor(0.1202, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-5.0549e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.052915
Average KL loss: 0.022506
Average total loss: 0.075420
tensor(0.1199, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(-3.9820e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.051566
Average KL loss: 0.022482
Average total loss: 0.074049
tensor(0.1197, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-3.1951e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.049338
Average KL loss: 0.022449
Average total loss: 0.071788
tensor(0.1195, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-1.9735e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.049604
Average KL loss: 0.022412
Average total loss: 0.072016
tensor(0.1193, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-3.7549e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.049272
Average KL loss: 0.022380
Average total loss: 0.071653
tensor(0.1191, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-2.8531e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.046556
Average KL loss: 0.022341
Average total loss: 0.068897
tensor(0.1189, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-3.8220e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.047070
Average KL loss: 0.022293
Average total loss: 0.069362
tensor(0.1187, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-3.1298e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.046384
Average KL loss: 0.022254
Average total loss: 0.068637
tensor(0.1184, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-2.9169e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.045461
Average KL loss: 0.022206
Average total loss: 0.067667
tensor(0.1181, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-3.6373e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.046633
Average KL loss: 0.022176
Average total loss: 0.068809
tensor(0.1180, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-3.6865e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.044850
Average KL loss: 0.022142
Average total loss: 0.066991
tensor(0.1177, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-1.8121e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.044776
Average KL loss: 0.022086
Average total loss: 0.066862
tensor(0.1174, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-3.1587e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.044511
Average KL loss: 0.022056
Average total loss: 0.066567
tensor(0.1171, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-2.6744e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.043611
Average KL loss: 0.022025
Average total loss: 0.065636
tensor(0.1169, device='cuda:0') tensor(0.1906, device='cuda:0') tensor(-2.3424e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.042050
Average KL loss: 0.021981
Average total loss: 0.064031
tensor(0.1167, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-1.8830e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.042743
Average KL loss: 0.021917
Average total loss: 0.064660
tensor(0.1164, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-2.1468e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.041863
Average KL loss: 0.021875
Average total loss: 0.063737
tensor(0.1162, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-3.7653e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.041563
Average KL loss: 0.021834
Average total loss: 0.063397
tensor(0.1160, device='cuda:0') tensor(0.1903, device='cuda:0') tensor(-1.9447e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.040785
Average KL loss: 0.021782
Average total loss: 0.062567
tensor(0.1156, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-1.9293e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.040299
Average KL loss: 0.021723
Average total loss: 0.062022
tensor(0.1154, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(-1.8969e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.040081
Average KL loss: 0.021677
Average total loss: 0.061758
tensor(0.1152, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(-3.6100e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.040266
Average KL loss: 0.021633
Average total loss: 0.061899
tensor(0.1149, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(-1.8022e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.039340
Average KL loss: 0.021601
Average total loss: 0.060941
tensor(0.1148, device='cuda:0') tensor(0.1901, device='cuda:0') tensor(-1.5315e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.037463
Average KL loss: 0.021542
Average total loss: 0.059005
tensor(0.1145, device='cuda:0') tensor(0.1898, device='cuda:0') tensor(-2.0150e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.038153
Average KL loss: 0.021469
Average total loss: 0.059622
tensor(0.1142, device='cuda:0') tensor(0.1896, device='cuda:0') tensor(-2.1646e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.037825
Average KL loss: 0.021410
Average total loss: 0.059234
tensor(0.1139, device='cuda:0') tensor(0.1894, device='cuda:0') tensor(-3.1083e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.037690
Average KL loss: 0.021353
Average total loss: 0.059043
tensor(0.1136, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(-9.8956e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.036979
Average KL loss: 0.021308
Average total loss: 0.058287
tensor(0.1134, device='cuda:0') tensor(0.1892, device='cuda:0') tensor(-1.6127e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.037300
Average KL loss: 0.021250
Average total loss: 0.058550
tensor(0.1131, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-2.7978e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.036292
Average KL loss: 0.021196
Average total loss: 0.057489
tensor(0.1128, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-1.1382e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.036027
Average KL loss: 0.021143
Average total loss: 0.057170
tensor(0.1126, device='cuda:0') tensor(0.1888, device='cuda:0') tensor(-2.3930e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.035866
Average KL loss: 0.021097
Average total loss: 0.056963
tensor(0.1124, device='cuda:0') tensor(0.1888, device='cuda:0') tensor(-1.8818e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.035462
Average KL loss: 0.021044
Average total loss: 0.056506
tensor(0.1121, device='cuda:0') tensor(0.1886, device='cuda:0') tensor(-1.1580e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.034803
Average KL loss: 0.020977
Average total loss: 0.055780
tensor(0.1118, device='cuda:0') tensor(0.1884, device='cuda:0') tensor(-9.1823e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.035292
Average KL loss: 0.020927
Average total loss: 0.056219
tensor(0.1116, device='cuda:0') tensor(0.1884, device='cuda:0') tensor(-1.8799e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.034874
Average KL loss: 0.020888
Average total loss: 0.055762
tensor(0.1114, device='cuda:0') tensor(0.1883, device='cuda:0') tensor(-1.7716e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.034520
Average KL loss: 0.020850
Average total loss: 0.055371
tensor(0.1112, device='cuda:0') tensor(0.1883, device='cuda:0') tensor(-1.7095e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.033540
Average KL loss: 0.020798
Average total loss: 0.054338
tensor(0.1110, device='cuda:0') tensor(0.1881, device='cuda:0') tensor(-1.6787e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.033798
Average KL loss: 0.020735
Average total loss: 0.054533
tensor(0.1108, device='cuda:0') tensor(0.1879, device='cuda:0') tensor(-1.5712e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.034271
Average KL loss: 0.020694
Average total loss: 0.054965
tensor(0.1106, device='cuda:0') tensor(0.1880, device='cuda:0') tensor(-2.2779e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.034005
Average KL loss: 0.020667
Average total loss: 0.054672
tensor(0.1105, device='cuda:0') tensor(0.1881, device='cuda:0') tensor(-2.2004e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.033066
Average KL loss: 0.020630
Average total loss: 0.053696
tensor(0.1102, device='cuda:0') tensor(0.1880, device='cuda:0') tensor(-1.2198e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.032588
Average KL loss: 0.020577
Average total loss: 0.053165
tensor(0.1100, device='cuda:0') tensor(0.1878, device='cuda:0') tensor(-8.5414e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.032569
Average KL loss: 0.020514
Average total loss: 0.053083
tensor(0.1097, device='cuda:0') tensor(0.1876, device='cuda:0') tensor(-2.0806e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.032179
Average KL loss: 0.020470
Average total loss: 0.052649
tensor(0.1095, device='cuda:0') tensor(0.1876, device='cuda:0') tensor(-1.1018e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.032881
Average KL loss: 0.020418
Average total loss: 0.053298
tensor(0.1092, device='cuda:0') tensor(0.1875, device='cuda:0') tensor(-1.1100e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.031991
Average KL loss: 0.020386
Average total loss: 0.052376
tensor(0.1090, device='cuda:0') tensor(0.1875, device='cuda:0') tensor(-4.9060e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.031572
Average KL loss: 0.020335
Average total loss: 0.051906
tensor(0.1088, device='cuda:0') tensor(0.1874, device='cuda:0') tensor(-1.2307e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.030571
Average KL loss: 0.020276
Average total loss: 0.050847
tensor(0.1085, device='cuda:0') tensor(0.1871, device='cuda:0') tensor(-9.1474e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.031110
Average KL loss: 0.020205
Average total loss: 0.051315
tensor(0.1081, device='cuda:0') tensor(0.1869, device='cuda:0') tensor(-1.4495e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.031097
Average KL loss: 0.020158
Average total loss: 0.051254
tensor(0.1080, device='cuda:0') tensor(0.1869, device='cuda:0') tensor(-1.6189e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.031276
Average KL loss: 0.020123
Average total loss: 0.051400
tensor(0.1078, device='cuda:0') tensor(0.1869, device='cuda:0') tensor(-1.8843e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.030551
Average KL loss: 0.020077
Average total loss: 0.050628
tensor(0.1076, device='cuda:0') tensor(0.1867, device='cuda:0') tensor(-1.2001e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.030673
Average KL loss: 0.020035
Average total loss: 0.050708
tensor(0.1075, device='cuda:0') tensor(0.1867, device='cuda:0') tensor(-1.1732e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.029877
Average KL loss: 0.019993
Average total loss: 0.049870
tensor(0.1073, device='cuda:0') tensor(0.1866, device='cuda:0') tensor(-1.2232e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.029532
Average KL loss: 0.019937
Average total loss: 0.049468
tensor(0.1070, device='cuda:0') tensor(0.1863, device='cuda:0') tensor(-3.7792e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.028946
Average KL loss: 0.019867
Average total loss: 0.048812
tensor(0.1067, device='cuda:0') tensor(0.1861, device='cuda:0') tensor(-3.9736e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.028959
Average KL loss: 0.019787
Average total loss: 0.048746
tensor(0.1062, device='cuda:0') tensor(0.1857, device='cuda:0') tensor(-8.7594e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.029551
Average KL loss: 0.019733
Average total loss: 0.049284
tensor(0.1062, device='cuda:0') tensor(0.1856, device='cuda:0') tensor(-1.3002e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.029050
Average KL loss: 0.019684
Average total loss: 0.048734
tensor(0.1060, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-3.4717e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.028690
Average KL loss: 0.019630
Average total loss: 0.048321
tensor(0.1057, device='cuda:0') tensor(0.1853, device='cuda:0') tensor(-4.3373e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.028658
Average KL loss: 0.019575
Average total loss: 0.048233
tensor(0.1055, device='cuda:0') tensor(0.1852, device='cuda:0') tensor(-7.7295e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.028389
Average KL loss: 0.019520
Average total loss: 0.047909
tensor(0.1052, device='cuda:0') tensor(0.1850, device='cuda:0') tensor(-1.6197e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.028143
Average KL loss: 0.019467
Average total loss: 0.047610
tensor(0.1050, device='cuda:0') tensor(0.1848, device='cuda:0') tensor(-7.4393e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.027935
Average KL loss: 0.019403
Average total loss: 0.047338
tensor(0.1047, device='cuda:0') tensor(0.1845, device='cuda:0') tensor(-4.7208e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.028350
Average KL loss: 0.019354
Average total loss: 0.047704
tensor(0.1046, device='cuda:0') tensor(0.1845, device='cuda:0') tensor(-8.6300e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.027834
Average KL loss: 0.019310
Average total loss: 0.047144
tensor(0.1043, device='cuda:0') tensor(0.1844, device='cuda:0') tensor(-2.7646e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.027331
Average KL loss: 0.019269
Average total loss: 0.046599
tensor(0.1041, device='cuda:0') tensor(0.1843, device='cuda:0') tensor(-1.2251e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.028165
Average KL loss: 0.019220
Average total loss: 0.047385
tensor(0.1039, device='cuda:0') tensor(0.1843, device='cuda:0') tensor(-1.2916e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.026825
Average KL loss: 0.019179
Average total loss: 0.046003
tensor(0.1036, device='cuda:0') tensor(0.1840, device='cuda:0') tensor(-1.1266e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.026900
Average KL loss: 0.019111
Average total loss: 0.046011
tensor(0.1034, device='cuda:0') tensor(0.1838, device='cuda:0') tensor(-7.0656e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.026916
Average KL loss: 0.019049
Average total loss: 0.045965
tensor(0.1032, device='cuda:0') tensor(0.1836, device='cuda:0') tensor(-4.5057e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.027432
Average KL loss: 0.019003
Average total loss: 0.046434
tensor(0.1030, device='cuda:0') tensor(0.1836, device='cuda:0') tensor(-6.8034e-11, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.026399
Average KL loss: 0.018980
Average total loss: 0.045379
tensor(0.1028, device='cuda:0') tensor(0.1836, device='cuda:0') tensor(-4.1535e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.026124
Average KL loss: 0.018915
Average total loss: 0.045039
tensor(0.1025, device='cuda:0') tensor(0.1832, device='cuda:0') tensor(-7.9280e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.026281
Average KL loss: 0.018837
Average total loss: 0.045118
tensor(0.1022, device='cuda:0') tensor(0.1830, device='cuda:0') tensor(-1.0104e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.026194
Average KL loss: 0.018792
Average total loss: 0.044986
tensor(0.1021, device='cuda:0') tensor(0.1829, device='cuda:0') tensor(-7.4756e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.026505
Average KL loss: 0.018749
Average total loss: 0.045254
tensor(0.1019, device='cuda:0') tensor(0.1829, device='cuda:0') tensor(-1.2986e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.026558
Average KL loss: 0.018713
Average total loss: 0.045271
tensor(0.1017, device='cuda:0') tensor(0.1828, device='cuda:0') tensor(-1.1207e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.025588
Average KL loss: 0.018681
Average total loss: 0.044269
tensor(0.1015, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-8.7652e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.025443
Average KL loss: 0.018613
Average total loss: 0.044056
tensor(0.1012, device='cuda:0') tensor(0.1824, device='cuda:0') tensor(-7.0274e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.025809
Average KL loss: 0.018555
Average total loss: 0.044365
tensor(0.1011, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(-3.7933e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.025646
Average KL loss: 0.018520
Average total loss: 0.044166
tensor(0.1009, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(-5.6098e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.025541
Average KL loss: 0.018476
Average total loss: 0.044017
tensor(0.1007, device='cuda:0') tensor(0.1822, device='cuda:0') tensor(-1.3772e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.024951
Average KL loss: 0.018429
Average total loss: 0.043380
tensor(0.1004, device='cuda:0') tensor(0.1820, device='cuda:0') tensor(-1.7520e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.024827
Average KL loss: 0.018364
Average total loss: 0.043192
tensor(0.1002, device='cuda:0') tensor(0.1818, device='cuda:0') tensor(-6.3302e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.025348
Average KL loss: 0.018328
Average total loss: 0.043676
tensor(0.1000, device='cuda:0') tensor(0.1818, device='cuda:0') tensor(-4.2952e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.025413
Average KL loss: 0.018282
Average total loss: 0.043695
tensor(0.0999, device='cuda:0') tensor(0.1817, device='cuda:0') tensor(-8.7848e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.024820
Average KL loss: 0.018251
Average total loss: 0.043071
tensor(0.0997, device='cuda:0') tensor(0.1817, device='cuda:0') tensor(-9.1965e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.024599
Average KL loss: 0.018215
Average total loss: 0.042814
tensor(0.0995, device='cuda:0') tensor(0.1816, device='cuda:0') tensor(-4.5763e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.024520
Average KL loss: 0.018157
Average total loss: 0.042677
tensor(0.0993, device='cuda:0') tensor(0.1814, device='cuda:0') tensor(-4.6790e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.024191
Average KL loss: 0.018100
Average total loss: 0.042291
tensor(0.0990, device='cuda:0') tensor(0.1812, device='cuda:0') tensor(-4.3954e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.024047
Average KL loss: 0.018036
Average total loss: 0.042083
tensor(0.0987, device='cuda:0') tensor(0.1810, device='cuda:0') tensor(-3.7877e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.024203
Average KL loss: 0.017990
Average total loss: 0.042194
tensor(0.0986, device='cuda:0') tensor(0.1809, device='cuda:0') tensor(-1.1093e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.024712
Average KL loss: 0.017969
Average total loss: 0.042681
tensor(0.0984, device='cuda:0') tensor(0.1811, device='cuda:0') tensor(-5.7131e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.023821
Average KL loss: 0.017931
Average total loss: 0.041751
tensor(0.0982, device='cuda:0') tensor(0.1809, device='cuda:0') tensor(-2.1758e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.023825
Average KL loss: 0.017877
Average total loss: 0.041702
tensor(0.0980, device='cuda:0') tensor(0.1808, device='cuda:0') tensor(-7.5088e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.024046
Average KL loss: 0.017838
Average total loss: 0.041885
tensor(0.0978, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-1.0225e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.024340
Average KL loss: 0.017796
Average total loss: 0.042137
tensor(0.0977, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-7.3838e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.023531
Average KL loss: 0.017776
Average total loss: 0.041306
tensor(0.0975, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-1.7010e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.023659
Average KL loss: 0.017733
Average total loss: 0.041392
tensor(0.0973, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-3.5741e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.023289
Average KL loss: 0.017688
Average total loss: 0.040977
tensor(0.0971, device='cuda:0') tensor(0.1804, device='cuda:0') tensor(-2.8486e-11, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.023798
Average KL loss: 0.017639
Average total loss: 0.041437
tensor(0.0969, device='cuda:0') tensor(0.1805, device='cuda:0') tensor(-4.2761e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.023493
Average KL loss: 0.017626
Average total loss: 0.041118
tensor(0.0969, device='cuda:0') tensor(0.1805, device='cuda:0') tensor(-8.8671e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.023747
Average KL loss: 0.017597
Average total loss: 0.041344
tensor(0.0967, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-4.5159e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.023785
Average KL loss: 0.017591
Average total loss: 0.041376
tensor(0.0966, device='cuda:0') tensor(0.1810, device='cuda:0') tensor(-3.3847e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.023320
Average KL loss: 0.017568
Average total loss: 0.040888
tensor(0.0964, device='cuda:0') tensor(0.1810, device='cuda:0') tensor(-1.7788e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.023072
Average KL loss: 0.017536
Average total loss: 0.040609
tensor(0.0962, device='cuda:0') tensor(0.1808, device='cuda:0') tensor(-3.6788e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.023291
Average KL loss: 0.017490
Average total loss: 0.040782
tensor(0.0961, device='cuda:0') tensor(0.1810, device='cuda:0') tensor(-5.7587e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.022616
Average KL loss: 0.017472
Average total loss: 0.040088
tensor(0.0958, device='cuda:0') tensor(0.1809, device='cuda:0') tensor(-4.6509e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.022799
Average KL loss: 0.017414
Average total loss: 0.040213
tensor(0.0957, device='cuda:0') tensor(0.1807, device='cuda:0') tensor(-1.4559e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.022520
Average KL loss: 0.017371
Average total loss: 0.039891
tensor(0.0954, device='cuda:0') tensor(0.1806, device='cuda:0') tensor(-3.5797e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.022502
Average KL loss: 0.017330
Average total loss: 0.039832
tensor(0.0952, device='cuda:0') tensor(0.1805, device='cuda:0') tensor(-4.9815e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.022464
Average KL loss: 0.017286
Average total loss: 0.039750
tensor(0.0950, device='cuda:0') tensor(0.1804, device='cuda:0') tensor(-3.2137e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.022671
Average KL loss: 0.017241
Average total loss: 0.039912
tensor(0.0949, device='cuda:0') tensor(0.1803, device='cuda:0') tensor(-2.2255e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.022264
Average KL loss: 0.017203
Average total loss: 0.039467
tensor(0.0947, device='cuda:0') tensor(0.1802, device='cuda:0') tensor(-1.9757e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.022528
Average KL loss: 0.017164
Average total loss: 0.039691
tensor(0.0945, device='cuda:0') tensor(0.1802, device='cuda:0') tensor(-2.4814e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.022474
Average KL loss: 0.017135
Average total loss: 0.039608
tensor(0.0945, device='cuda:0') tensor(0.1802, device='cuda:0') tensor(-5.8333e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.022398
Average KL loss: 0.017116
Average total loss: 0.039514
 Percentile value: 0.43311736583709715
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/8]: ---
conv1.weight         | nonzeros =     499 /    1728             ( 28.88%) | total_pruned =    1229 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5806 /   36864             ( 15.75%) | total_pruned =   31058 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   12926 /   36864             ( 35.06%) | total_pruned =   23938 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   12731 /   36864             ( 34.54%) | total_pruned =   24133 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   15109 /   36864             ( 40.99%) | total_pruned =   21755 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   36644 /   73728             ( 49.70%) | total_pruned =   37084 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   72908 /  147456             ( 49.44%) | total_pruned =   74548 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4861 /    8192             ( 59.34%) | total_pruned =    3331 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   53695 /  147456             ( 36.41%) | total_pruned =   93761 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   51239 /  147456             ( 34.75%) | total_pruned =   96217 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  148556 /  294912             ( 50.37%) | total_pruned =  146356 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     156 /     256             ( 60.94%) | total_pruned =     100 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  286894 /  589824             ( 48.64%) | total_pruned =  302930 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   17417 /   32768             ( 53.15%) | total_pruned =   15351 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  247706 /  589824             ( 42.00%) | total_pruned =  342118 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      61 /     256             ( 23.83%) | total_pruned =     195 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  205125 /  589824             ( 34.78%) | total_pruned =  384699 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  462229 / 1179648             ( 39.18%) | total_pruned =  717419 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     301 /     512             ( 58.79%) | total_pruned =     211 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  545638 / 2359296             ( 23.13%) | total_pruned = 1813658 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     419 /     512             ( 81.84%) | total_pruned =      93 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   32163 /  131072             ( 24.54%) | total_pruned =   98909 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  444357 / 2359296             ( 18.83%) | total_pruned = 1914939 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      59 /     512             ( 11.52%) | total_pruned =     453 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  684414 / 2359296             ( 29.01%) | total_pruned = 1674882 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5088 /    5120             ( 99.38%) | total_pruned =      32 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 70/100 Loss: 0.016989 Accuracy: 89.00 100.00 % Best test Accuracy: 89.16%
tensor(0.0944, device='cuda:0') tensor(0.1804, device='cuda:0') tensor(-6.3851e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.243316
Average KL loss: 0.015058
Average total loss: 0.258374
tensor(0.0952, device='cuda:0') tensor(0.1449, device='cuda:0') tensor(-4.1777e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.185086
Average KL loss: 0.012530
Average total loss: 0.197616
tensor(0.0953, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-2.4865e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.157780
Average KL loss: 0.011320
Average total loss: 0.169100
tensor(0.0946, device='cuda:0') tensor(0.1192, device='cuda:0') tensor(-2.0959e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.139642
Average KL loss: 0.010724
Average total loss: 0.150366
tensor(0.0938, device='cuda:0') tensor(0.1147, device='cuda:0') tensor(-1.4267e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.131475
Average KL loss: 0.010452
Average total loss: 0.141926
tensor(0.0931, device='cuda:0') tensor(0.1126, device='cuda:0') tensor(-2.0401e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.127147
Average KL loss: 0.010362
Average total loss: 0.137509
tensor(0.0925, device='cuda:0') tensor(0.1118, device='cuda:0') tensor(-1.4433e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.112777
Average KL loss: 0.010366
Average total loss: 0.123143
tensor(0.0922, device='cuda:0') tensor(0.1118, device='cuda:0') tensor(-1.5027e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.105890
Average KL loss: 0.010421
Average total loss: 0.116311
tensor(0.0920, device='cuda:0') tensor(0.1122, device='cuda:0') tensor(-1.5779e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.102753
Average KL loss: 0.010508
Average total loss: 0.113262
tensor(0.0919, device='cuda:0') tensor(0.1129, device='cuda:0') tensor(-1.1642e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.096864
Average KL loss: 0.010617
Average total loss: 0.107481
tensor(0.0920, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-1.2117e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.093628
Average KL loss: 0.010724
Average total loss: 0.104352
tensor(0.0920, device='cuda:0') tensor(0.1146, device='cuda:0') tensor(-1.2266e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.087536
Average KL loss: 0.010833
Average total loss: 0.098368
tensor(0.0921, device='cuda:0') tensor(0.1156, device='cuda:0') tensor(-1.2049e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.085566
Average KL loss: 0.010946
Average total loss: 0.096512
tensor(0.0922, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-1.4715e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.080173
Average KL loss: 0.011054
Average total loss: 0.091227
tensor(0.0924, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-1.1498e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.076579
Average KL loss: 0.011163
Average total loss: 0.087741
tensor(0.0925, device='cuda:0') tensor(0.1187, device='cuda:0') tensor(-1.3588e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.075019
Average KL loss: 0.011268
Average total loss: 0.086286
tensor(0.0926, device='cuda:0') tensor(0.1197, device='cuda:0') tensor(-8.1833e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.070119
Average KL loss: 0.011362
Average total loss: 0.081481
tensor(0.0927, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-1.1011e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.068120
Average KL loss: 0.011454
Average total loss: 0.079574
tensor(0.0928, device='cuda:0') tensor(0.1216, device='cuda:0') tensor(-1.0436e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.067457
Average KL loss: 0.011540
Average total loss: 0.078997
tensor(0.0929, device='cuda:0') tensor(0.1226, device='cuda:0') tensor(-7.0281e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.065380
Average KL loss: 0.011628
Average total loss: 0.077008
tensor(0.0930, device='cuda:0') tensor(0.1236, device='cuda:0') tensor(-6.4480e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.066682
Average KL loss: 0.011723
Average total loss: 0.078405
tensor(0.0931, device='cuda:0') tensor(0.1247, device='cuda:0') tensor(-6.8029e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.060968
Average KL loss: 0.011805
Average total loss: 0.072773
tensor(0.0932, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-9.4036e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.058995
Average KL loss: 0.011878
Average total loss: 0.070873
tensor(0.0932, device='cuda:0') tensor(0.1264, device='cuda:0') tensor(-7.2657e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.057846
Average KL loss: 0.011946
Average total loss: 0.069792
tensor(0.0932, device='cuda:0') tensor(0.1273, device='cuda:0') tensor(-5.3022e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.057709
Average KL loss: 0.012016
Average total loss: 0.069725
tensor(0.0933, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-6.7741e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.054585
Average KL loss: 0.012085
Average total loss: 0.066670
tensor(0.0933, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-5.9176e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.054911
Average KL loss: 0.012149
Average total loss: 0.067060
tensor(0.0933, device='cuda:0') tensor(0.1299, device='cuda:0') tensor(-6.5115e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.053757
Average KL loss: 0.012217
Average total loss: 0.065974
tensor(0.0934, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-4.2894e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.050631
Average KL loss: 0.012279
Average total loss: 0.062911
tensor(0.0934, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-5.8109e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.051668
Average KL loss: 0.012339
Average total loss: 0.064007
tensor(0.0934, device='cuda:0') tensor(0.1324, device='cuda:0') tensor(-6.0184e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.049093
Average KL loss: 0.012398
Average total loss: 0.061491
tensor(0.0934, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(-6.3646e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.047881
Average KL loss: 0.012450
Average total loss: 0.060332
tensor(0.0933, device='cuda:0') tensor(0.1340, device='cuda:0') tensor(-5.1722e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.045830
Average KL loss: 0.012494
Average total loss: 0.058324
tensor(0.0933, device='cuda:0') tensor(0.1347, device='cuda:0') tensor(-5.5579e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.048094
Average KL loss: 0.012541
Average total loss: 0.060635
tensor(0.0933, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-5.1457e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.043268
Average KL loss: 0.012591
Average total loss: 0.055859
tensor(0.0932, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-4.5694e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.043698
Average KL loss: 0.012631
Average total loss: 0.056329
tensor(0.0932, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-2.4503e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.042717
Average KL loss: 0.012673
Average total loss: 0.055389
tensor(0.0932, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-4.8307e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.042213
Average KL loss: 0.012710
Average total loss: 0.054922
tensor(0.0931, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(-3.9439e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.041344
Average KL loss: 0.012746
Average total loss: 0.054090
tensor(0.0930, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(-3.4598e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.039695
Average KL loss: 0.012777
Average total loss: 0.052472
tensor(0.0930, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-4.2905e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.039410
Average KL loss: 0.012805
Average total loss: 0.052215
tensor(0.0929, device='cuda:0') tensor(0.1399, device='cuda:0') tensor(-3.1871e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.039138
Average KL loss: 0.012838
Average total loss: 0.051977
tensor(0.0928, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(-3.1354e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.037181
Average KL loss: 0.012865
Average total loss: 0.050046
tensor(0.0927, device='cuda:0') tensor(0.1410, device='cuda:0') tensor(-4.4806e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.037523
Average KL loss: 0.012892
Average total loss: 0.050415
tensor(0.0927, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(-2.5641e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.038897
Average KL loss: 0.012918
Average total loss: 0.051815
tensor(0.0926, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-2.8761e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.037706
Average KL loss: 0.012947
Average total loss: 0.050653
tensor(0.0925, device='cuda:0') tensor(0.1427, device='cuda:0') tensor(-2.9996e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.034756
Average KL loss: 0.012975
Average total loss: 0.047731
tensor(0.0924, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(-4.2686e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.034602
Average KL loss: 0.012993
Average total loss: 0.047596
tensor(0.0923, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(-2.5777e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.033024
Average KL loss: 0.013009
Average total loss: 0.046033
tensor(0.0921, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(-2.4512e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.033808
Average KL loss: 0.013025
Average total loss: 0.046832
tensor(0.0920, device='cuda:0') tensor(0.1445, device='cuda:0') tensor(-2.9681e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.033508
Average KL loss: 0.013044
Average total loss: 0.046552
tensor(0.0920, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-2.3844e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.033195
Average KL loss: 0.013064
Average total loss: 0.046259
tensor(0.0919, device='cuda:0') tensor(0.1455, device='cuda:0') tensor(-2.2481e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.032330
Average KL loss: 0.013083
Average total loss: 0.045413
tensor(0.0917, device='cuda:0') tensor(0.1460, device='cuda:0') tensor(-2.0658e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.031797
Average KL loss: 0.013099
Average total loss: 0.044896
tensor(0.0916, device='cuda:0') tensor(0.1464, device='cuda:0') tensor(-2.6480e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.031737
Average KL loss: 0.013114
Average total loss: 0.044852
tensor(0.0915, device='cuda:0') tensor(0.1468, device='cuda:0') tensor(-1.9392e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.031395
Average KL loss: 0.013128
Average total loss: 0.044524
tensor(0.0914, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(-2.4767e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.031578
Average KL loss: 0.013144
Average total loss: 0.044723
tensor(0.0913, device='cuda:0') tensor(0.1477, device='cuda:0') tensor(-1.9370e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.030299
Average KL loss: 0.013157
Average total loss: 0.043456
tensor(0.0911, device='cuda:0') tensor(0.1481, device='cuda:0') tensor(-1.9579e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.030059
Average KL loss: 0.013169
Average total loss: 0.043228
tensor(0.0910, device='cuda:0') tensor(0.1485, device='cuda:0') tensor(-2.7242e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.030024
Average KL loss: 0.013182
Average total loss: 0.043205
tensor(0.0909, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(-3.3506e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.030386
Average KL loss: 0.013196
Average total loss: 0.043582
tensor(0.0908, device='cuda:0') tensor(0.1494, device='cuda:0') tensor(-1.5562e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.029217
Average KL loss: 0.013211
Average total loss: 0.042428
tensor(0.0907, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-1.9964e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.028428
Average KL loss: 0.013221
Average total loss: 0.041649
tensor(0.0906, device='cuda:0') tensor(0.1502, device='cuda:0') tensor(-2.5934e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.027821
Average KL loss: 0.013229
Average total loss: 0.041050
tensor(0.0904, device='cuda:0') tensor(0.1506, device='cuda:0') tensor(-1.6637e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.028339
Average KL loss: 0.013238
Average total loss: 0.041577
tensor(0.0903, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(-1.4051e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.029083
Average KL loss: 0.013246
Average total loss: 0.042329
tensor(0.0902, device='cuda:0') tensor(0.1514, device='cuda:0') tensor(-1.9449e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.027758
Average KL loss: 0.013262
Average total loss: 0.041020
tensor(0.0901, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(-2.0067e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.027372
Average KL loss: 0.013272
Average total loss: 0.040644
tensor(0.0900, device='cuda:0') tensor(0.1522, device='cuda:0') tensor(-2.0081e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.026551
Average KL loss: 0.013277
Average total loss: 0.039829
tensor(0.0899, device='cuda:0') tensor(0.1525, device='cuda:0') tensor(-1.1789e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.026457
Average KL loss: 0.013280
Average total loss: 0.039737
tensor(0.0897, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(-1.1428e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.026016
Average KL loss: 0.013279
Average total loss: 0.039295
tensor(0.0896, device='cuda:0') tensor(0.1531, device='cuda:0') tensor(-1.5533e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.027500
Average KL loss: 0.013281
Average total loss: 0.040781
tensor(0.0894, device='cuda:0') tensor(0.1535, device='cuda:0') tensor(-2.5850e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.026284
Average KL loss: 0.013293
Average total loss: 0.039577
tensor(0.0893, device='cuda:0') tensor(0.1539, device='cuda:0') tensor(-1.0810e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.025137
Average KL loss: 0.013299
Average total loss: 0.038436
tensor(0.0892, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(-3.9127e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.024690
Average KL loss: 0.013297
Average total loss: 0.037987
tensor(0.0890, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(-1.9375e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.024679
Average KL loss: 0.013292
Average total loss: 0.037971
tensor(0.0889, device='cuda:0') tensor(0.1547, device='cuda:0') tensor(-1.0562e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.024546
Average KL loss: 0.013292
Average total loss: 0.037838
tensor(0.0887, device='cuda:0') tensor(0.1550, device='cuda:0') tensor(-1.3435e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.024548
Average KL loss: 0.013293
Average total loss: 0.037841
tensor(0.0886, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-1.1536e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.023574
Average KL loss: 0.013291
Average total loss: 0.036865
tensor(0.0884, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(-1.1930e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.023030
Average KL loss: 0.013282
Average total loss: 0.036311
tensor(0.0883, device='cuda:0') tensor(0.1557, device='cuda:0') tensor(-1.6279e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.023645
Average KL loss: 0.013272
Average total loss: 0.036917
tensor(0.0881, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(-2.3899e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.023318
Average KL loss: 0.013270
Average total loss: 0.036588
tensor(0.0880, device='cuda:0') tensor(0.1562, device='cuda:0') tensor(-1.0769e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.023477
Average KL loss: 0.013267
Average total loss: 0.036744
tensor(0.0878, device='cuda:0') tensor(0.1565, device='cuda:0') tensor(-1.5455e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.023345
Average KL loss: 0.013269
Average total loss: 0.036614
tensor(0.0877, device='cuda:0') tensor(0.1568, device='cuda:0') tensor(-1.7037e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.023250
Average KL loss: 0.013269
Average total loss: 0.036519
tensor(0.0875, device='cuda:0') tensor(0.1571, device='cuda:0') tensor(-1.0892e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.022340
Average KL loss: 0.013264
Average total loss: 0.035604
tensor(0.0873, device='cuda:0') tensor(0.1573, device='cuda:0') tensor(-9.1693e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.023161
Average KL loss: 0.013260
Average total loss: 0.036421
tensor(0.0872, device='cuda:0') tensor(0.1576, device='cuda:0') tensor(-8.1152e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.022817
Average KL loss: 0.013261
Average total loss: 0.036078
tensor(0.0871, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(-5.4109e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.023098
Average KL loss: 0.013258
Average total loss: 0.036356
tensor(0.0869, device='cuda:0') tensor(0.1582, device='cuda:0') tensor(-2.3269e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.022222
Average KL loss: 0.013262
Average total loss: 0.035483
tensor(0.0868, device='cuda:0') tensor(0.1585, device='cuda:0') tensor(-6.8845e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.022645
Average KL loss: 0.013259
Average total loss: 0.035904
tensor(0.0867, device='cuda:0') tensor(0.1588, device='cuda:0') tensor(-8.3898e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.021598
Average KL loss: 0.013258
Average total loss: 0.034855
tensor(0.0865, device='cuda:0') tensor(0.1590, device='cuda:0') tensor(-2.9795e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.021452
Average KL loss: 0.013251
Average total loss: 0.034703
tensor(0.0864, device='cuda:0') tensor(0.1592, device='cuda:0') tensor(-7.3040e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.021035
Average KL loss: 0.013242
Average total loss: 0.034277
tensor(0.0862, device='cuda:0') tensor(0.1594, device='cuda:0') tensor(-6.7425e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.021110
Average KL loss: 0.013232
Average total loss: 0.034342
tensor(0.0860, device='cuda:0') tensor(0.1596, device='cuda:0') tensor(-5.6742e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.021427
Average KL loss: 0.013229
Average total loss: 0.034656
tensor(0.0859, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-1.6027e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.021621
Average KL loss: 0.013230
Average total loss: 0.034851
tensor(0.0858, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(-1.0300e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.020977
Average KL loss: 0.013225
Average total loss: 0.034202
tensor(0.0856, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(-2.8008e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.020439
Average KL loss: 0.013218
Average total loss: 0.033657
tensor(0.0854, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(-7.8312e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.020564
Average KL loss: 0.013207
Average total loss: 0.033771
tensor(0.0853, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(-9.0741e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.020865
Average KL loss: 0.013202
Average total loss: 0.034067
tensor(0.0852, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(-1.2746e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.019967
Average KL loss: 0.013198
Average total loss: 0.033165
tensor(0.0850, device='cuda:0') tensor(0.1612, device='cuda:0') tensor(-5.5268e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.020005
Average KL loss: 0.013186
Average total loss: 0.033191
tensor(0.0848, device='cuda:0') tensor(0.1614, device='cuda:0') tensor(-4.8691e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.022018
Average KL loss: 0.013177
Average total loss: 0.035195
tensor(0.0847, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-4.5846e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.019942
Average KL loss: 0.013185
Average total loss: 0.033128
tensor(0.0846, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-8.5573e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.019774
Average KL loss: 0.013182
Average total loss: 0.032957
tensor(0.0844, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(-8.1190e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.019264
Average KL loss: 0.013172
Average total loss: 0.032436
tensor(0.0842, device='cuda:0') tensor(0.1624, device='cuda:0') tensor(-9.8828e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.019595
Average KL loss: 0.013156
Average total loss: 0.032751
tensor(0.0841, device='cuda:0') tensor(0.1625, device='cuda:0') tensor(-3.6960e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.019816
Average KL loss: 0.013147
Average total loss: 0.032963
tensor(0.0839, device='cuda:0') tensor(0.1627, device='cuda:0') tensor(-5.7080e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.018675
Average KL loss: 0.013138
Average total loss: 0.031812
tensor(0.0838, device='cuda:0') tensor(0.1628, device='cuda:0') tensor(-5.2815e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.019164
Average KL loss: 0.013120
Average total loss: 0.032284
tensor(0.0836, device='cuda:0') tensor(0.1630, device='cuda:0') tensor(-1.1609e-11, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.018943
Average KL loss: 0.013108
Average total loss: 0.032052
tensor(0.0834, device='cuda:0') tensor(0.1631, device='cuda:0') tensor(-4.4218e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.018931
Average KL loss: 0.013097
Average total loss: 0.032027
tensor(0.0833, device='cuda:0') tensor(0.1633, device='cuda:0') tensor(-7.1043e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.019043
Average KL loss: 0.013088
Average total loss: 0.032131
tensor(0.0831, device='cuda:0') tensor(0.1635, device='cuda:0') tensor(-6.4286e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.018723
Average KL loss: 0.013078
Average total loss: 0.031801
tensor(0.0830, device='cuda:0') tensor(0.1637, device='cuda:0') tensor(-4.5797e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.018804
Average KL loss: 0.013070
Average total loss: 0.031874
tensor(0.0828, device='cuda:0') tensor(0.1639, device='cuda:0') tensor(-1.3225e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.018915
Average KL loss: 0.013067
Average total loss: 0.031981
tensor(0.0827, device='cuda:0') tensor(0.1641, device='cuda:0') tensor(-4.3174e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.018348
Average KL loss: 0.013057
Average total loss: 0.031405
tensor(0.0825, device='cuda:0') tensor(0.1643, device='cuda:0') tensor(-2.1765e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.018597
Average KL loss: 0.013044
Average total loss: 0.031641
tensor(0.0824, device='cuda:0') tensor(0.1645, device='cuda:0') tensor(-1.7852e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.017998
Average KL loss: 0.013034
Average total loss: 0.031031
tensor(0.0822, device='cuda:0') tensor(0.1646, device='cuda:0') tensor(5.3454e-11, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.018133
Average KL loss: 0.013018
Average total loss: 0.031151
tensor(0.0820, device='cuda:0') tensor(0.1647, device='cuda:0') tensor(-5.3150e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.018538
Average KL loss: 0.013007
Average total loss: 0.031545
tensor(0.0819, device='cuda:0') tensor(0.1649, device='cuda:0') tensor(-1.1214e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.018068
Average KL loss: 0.013000
Average total loss: 0.031068
tensor(0.0817, device='cuda:0') tensor(0.1651, device='cuda:0') tensor(-4.4192e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.017552
Average KL loss: 0.012987
Average total loss: 0.030540
tensor(0.0816, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-3.1975e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.018079
Average KL loss: 0.012972
Average total loss: 0.031051
tensor(0.0814, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(-6.1858e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.017560
Average KL loss: 0.012961
Average total loss: 0.030522
tensor(0.0813, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(-4.2882e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.017825
Average KL loss: 0.012947
Average total loss: 0.030772
tensor(0.0811, device='cuda:0') tensor(0.1657, device='cuda:0') tensor(-2.0386e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.018039
Average KL loss: 0.012942
Average total loss: 0.030981
tensor(0.0810, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(-7.7825e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.019407
Average KL loss: 0.012938
Average total loss: 0.032345
tensor(0.0808, device='cuda:0') tensor(0.1663, device='cuda:0') tensor(2.6368e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.017258
Average KL loss: 0.012947
Average total loss: 0.030205
tensor(0.0807, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(3.6525e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.017218
Average KL loss: 0.012929
Average total loss: 0.030147
tensor(0.0805, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-9.1578e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.016897
Average KL loss: 0.012914
Average total loss: 0.029811
tensor(0.0804, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-3.1107e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.017606
Average KL loss: 0.012896
Average total loss: 0.030502
tensor(0.0802, device='cuda:0') tensor(0.1668, device='cuda:0') tensor(-3.8263e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.017336
Average KL loss: 0.012891
Average total loss: 0.030227
tensor(0.0801, device='cuda:0') tensor(0.1670, device='cuda:0') tensor(-8.7293e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.016900
Average KL loss: 0.012876
Average total loss: 0.029776
tensor(0.0799, device='cuda:0') tensor(0.1671, device='cuda:0') tensor(-1.1148e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.017180
Average KL loss: 0.012862
Average total loss: 0.030042
tensor(0.0798, device='cuda:0') tensor(0.1673, device='cuda:0') tensor(-4.9633e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.016685
Average KL loss: 0.012848
Average total loss: 0.029532
tensor(0.0796, device='cuda:0') tensor(0.1674, device='cuda:0') tensor(3.4655e-12, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.016629
Average KL loss: 0.012832
Average total loss: 0.029461
tensor(0.0794, device='cuda:0') tensor(0.1675, device='cuda:0') tensor(-3.1208e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.016722
Average KL loss: 0.012814
Average total loss: 0.029536
tensor(0.0793, device='cuda:0') tensor(0.1676, device='cuda:0') tensor(1.8267e-11, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.016746
Average KL loss: 0.012799
Average total loss: 0.029544
tensor(0.0791, device='cuda:0') tensor(0.1677, device='cuda:0') tensor(-2.5052e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.016982
Average KL loss: 0.012785
Average total loss: 0.029767
tensor(0.0790, device='cuda:0') tensor(0.1679, device='cuda:0') tensor(-8.8799e-11, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.016436
Average KL loss: 0.012783
Average total loss: 0.029219
tensor(0.0789, device='cuda:0') tensor(0.1681, device='cuda:0') tensor(-2.3077e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.016537
Average KL loss: 0.012768
Average total loss: 0.029306
tensor(0.0787, device='cuda:0') tensor(0.1682, device='cuda:0') tensor(-3.7526e-11, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.016220
Average KL loss: 0.012753
Average total loss: 0.028973
tensor(0.0786, device='cuda:0') tensor(0.1683, device='cuda:0') tensor(-5.0081e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.016297
Average KL loss: 0.012733
Average total loss: 0.029030
tensor(0.0784, device='cuda:0') tensor(0.1683, device='cuda:0') tensor(-2.7618e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.015966
Average KL loss: 0.012714
Average total loss: 0.028680
tensor(0.0782, device='cuda:0') tensor(0.1684, device='cuda:0') tensor(-1.9104e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.016208
Average KL loss: 0.012697
Average total loss: 0.028906
tensor(0.0781, device='cuda:0') tensor(0.1685, device='cuda:0') tensor(-3.6052e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.016211
Average KL loss: 0.012689
Average total loss: 0.028900
tensor(0.0780, device='cuda:0') tensor(0.1687, device='cuda:0') tensor(-4.2327e-11, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.016143
Average KL loss: 0.012673
Average total loss: 0.028816
tensor(0.0778, device='cuda:0') tensor(0.1688, device='cuda:0') tensor(-1.0564e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.016182
Average KL loss: 0.012665
Average total loss: 0.028847
tensor(0.0777, device='cuda:0') tensor(0.1690, device='cuda:0') tensor(-1.9775e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.016095
Average KL loss: 0.012658
Average total loss: 0.028753
tensor(0.0775, device='cuda:0') tensor(0.1692, device='cuda:0') tensor(-7.4429e-11, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.016062
Average KL loss: 0.012643
Average total loss: 0.028704
tensor(0.0774, device='cuda:0') tensor(0.1693, device='cuda:0') tensor(8.8610e-12, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.016074
Average KL loss: 0.012633
Average total loss: 0.028707
tensor(0.0773, device='cuda:0') tensor(0.1695, device='cuda:0') tensor(-1.0703e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.015927
Average KL loss: 0.012625
Average total loss: 0.028552
tensor(0.0771, device='cuda:0') tensor(0.1697, device='cuda:0') tensor(-2.2966e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.015933
Average KL loss: 0.012616
Average total loss: 0.028549
tensor(0.0770, device='cuda:0') tensor(0.1698, device='cuda:0') tensor(-5.5194e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.015656
Average KL loss: 0.012602
Average total loss: 0.028258
tensor(0.0769, device='cuda:0') tensor(0.1699, device='cuda:0') tensor(-6.7161e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.015669
Average KL loss: 0.012588
Average total loss: 0.028256
tensor(0.0767, device='cuda:0') tensor(0.1701, device='cuda:0') tensor(-5.5170e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.015843
Average KL loss: 0.012577
Average total loss: 0.028420
tensor(0.0766, device='cuda:0') tensor(0.1702, device='cuda:0') tensor(-2.3125e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.015658
Average KL loss: 0.012571
Average total loss: 0.028229
tensor(0.0764, device='cuda:0') tensor(0.1704, device='cuda:0') tensor(1.1754e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.015742
Average KL loss: 0.012561
Average total loss: 0.028303
tensor(0.0763, device='cuda:0') tensor(0.1706, device='cuda:0') tensor(-3.4615e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.015163
Average KL loss: 0.012544
Average total loss: 0.027707
tensor(0.0762, device='cuda:0') tensor(0.1706, device='cuda:0') tensor(-4.5455e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.015279
Average KL loss: 0.012519
Average total loss: 0.027799
tensor(0.0760, device='cuda:0') tensor(0.1706, device='cuda:0') tensor(-4.8871e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.015438
Average KL loss: 0.012507
Average total loss: 0.027945
tensor(0.0759, device='cuda:0') tensor(0.1708, device='cuda:0') tensor(-5.8325e-11, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.015106
Average KL loss: 0.012491
Average total loss: 0.027598
tensor(0.0757, device='cuda:0') tensor(0.1708, device='cuda:0') tensor(-1.0099e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.015522
Average KL loss: 0.012474
Average total loss: 0.027996
tensor(0.0756, device='cuda:0') tensor(0.1709, device='cuda:0') tensor(1.7263e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.015237
Average KL loss: 0.012461
Average total loss: 0.027698
tensor(0.0754, device='cuda:0') tensor(0.1710, device='cuda:0') tensor(-2.8177e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.015110
Average KL loss: 0.012449
Average total loss: 0.027559
tensor(0.0753, device='cuda:0') tensor(0.1711, device='cuda:0') tensor(-4.8979e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.015211
Average KL loss: 0.012432
Average total loss: 0.027643
tensor(0.0752, device='cuda:0') tensor(0.1712, device='cuda:0') tensor(2.0663e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.015142
Average KL loss: 0.012424
Average total loss: 0.027566
tensor(0.0751, device='cuda:0') tensor(0.1714, device='cuda:0') tensor(-3.9721e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.015287
Average KL loss: 0.012415
Average total loss: 0.027701
tensor(0.0750, device='cuda:0') tensor(0.1716, device='cuda:0') tensor(-3.9411e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.014883
Average KL loss: 0.012401
Average total loss: 0.027284
tensor(0.0748, device='cuda:0') tensor(0.1717, device='cuda:0') tensor(-1.5762e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.014856
Average KL loss: 0.012388
Average total loss: 0.027243
tensor(0.0747, device='cuda:0') tensor(0.1718, device='cuda:0') tensor(-3.9489e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.015150
Average KL loss: 0.012374
Average total loss: 0.027524
tensor(0.0745, device='cuda:0') tensor(0.1720, device='cuda:0') tensor(-2.1106e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.015048
Average KL loss: 0.012370
Average total loss: 0.027418
tensor(0.0744, device='cuda:0') tensor(0.1722, device='cuda:0') tensor(-6.7836e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.014711
Average KL loss: 0.012360
Average total loss: 0.027071
tensor(0.0743, device='cuda:0') tensor(0.1723, device='cuda:0') tensor(-1.4736e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.015151
Average KL loss: 0.012346
Average total loss: 0.027497
tensor(0.0742, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-2.5698e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.014780
Average KL loss: 0.012336
Average total loss: 0.027116
tensor(0.0741, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(9.2049e-11, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.014572
Average KL loss: 0.012321
Average total loss: 0.026893
tensor(0.0739, device='cuda:0') tensor(0.1727, device='cuda:0') tensor(-8.8579e-11, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.014663
Average KL loss: 0.012301
Average total loss: 0.026964
tensor(0.0738, device='cuda:0') tensor(0.1727, device='cuda:0') tensor(-5.3288e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.014865
Average KL loss: 0.012289
Average total loss: 0.027153
tensor(0.0737, device='cuda:0') tensor(0.1729, device='cuda:0') tensor(-1.4498e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.014631
Average KL loss: 0.012284
Average total loss: 0.026915
tensor(0.0736, device='cuda:0') tensor(0.1731, device='cuda:0') tensor(1.1664e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.015036
Average KL loss: 0.012275
Average total loss: 0.027311
tensor(0.0735, device='cuda:0') tensor(0.1732, device='cuda:0') tensor(2.1832e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.014799
Average KL loss: 0.012268
Average total loss: 0.027067
tensor(0.0733, device='cuda:0') tensor(0.1734, device='cuda:0') tensor(-1.8327e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.014595
Average KL loss: 0.012259
Average total loss: 0.026854
tensor(0.0732, device='cuda:0') tensor(0.1736, device='cuda:0') tensor(1.1747e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.014683
Average KL loss: 0.012247
Average total loss: 0.026929
tensor(0.0731, device='cuda:0') tensor(0.1737, device='cuda:0') tensor(-5.1796e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.014881
Average KL loss: 0.012245
Average total loss: 0.027126
tensor(0.0731, device='cuda:0') tensor(0.1740, device='cuda:0') tensor(1.2481e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.014466
Average KL loss: 0.012238
Average total loss: 0.026704
tensor(0.0729, device='cuda:0') tensor(0.1741, device='cuda:0') tensor(4.7957e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.014328
Average KL loss: 0.012222
Average total loss: 0.026550
tensor(0.0728, device='cuda:0') tensor(0.1741, device='cuda:0') tensor(-1.7990e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.014618
Average KL loss: 0.012207
Average total loss: 0.026825
tensor(0.0727, device='cuda:0') tensor(0.1743, device='cuda:0') tensor(2.1985e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.014395
Average KL loss: 0.012200
Average total loss: 0.026595
tensor(0.0726, device='cuda:0') tensor(0.1744, device='cuda:0') tensor(-6.6758e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.014423
Average KL loss: 0.012185
Average total loss: 0.026609
tensor(0.0725, device='cuda:0') tensor(0.1745, device='cuda:0') tensor(-1.0607e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.014448
Average KL loss: 0.012178
Average total loss: 0.026626
tensor(0.0724, device='cuda:0') tensor(0.1747, device='cuda:0') tensor(-4.5290e-11, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.014386
Average KL loss: 0.012167
Average total loss: 0.026553
tensor(0.0722, device='cuda:0') tensor(0.1748, device='cuda:0') tensor(-2.1632e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.014380
Average KL loss: 0.012160
Average total loss: 0.026540
tensor(0.0721, device='cuda:0') tensor(0.1750, device='cuda:0') tensor(1.0061e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.014314
Average KL loss: 0.012152
Average total loss: 0.026465
tensor(0.0720, device='cuda:0') tensor(0.1751, device='cuda:0') tensor(-3.5237e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.014163
Average KL loss: 0.012137
Average total loss: 0.026300
tensor(0.0719, device='cuda:0') tensor(0.1752, device='cuda:0') tensor(-1.3434e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.014132
Average KL loss: 0.012122
Average total loss: 0.026255
tensor(0.0718, device='cuda:0') tensor(0.1753, device='cuda:0') tensor(3.5744e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.014312
Average KL loss: 0.012112
Average total loss: 0.026424
tensor(0.0717, device='cuda:0') tensor(0.1754, device='cuda:0') tensor(1.7229e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.014056
Average KL loss: 0.012099
Average total loss: 0.026155
tensor(0.0716, device='cuda:0') tensor(0.1755, device='cuda:0') tensor(-1.0523e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.014280
Average KL loss: 0.012088
Average total loss: 0.026367
 Percentile value: 1.0159371137619018
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/8]: ---
conv1.weight         | nonzeros =     263 /    1728             ( 15.22%) | total_pruned =    1465 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1116 /   36864             (  3.03%) | total_pruned =   35748 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    3043 /   36864             (  8.25%) | total_pruned =   33821 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3650 /   36864             (  9.90%) | total_pruned =   33214 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4372 /   36864             ( 11.86%) | total_pruned =   32492 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   16023 /   73728             ( 21.73%) | total_pruned =   57705 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   29960 /  147456             ( 20.32%) | total_pruned =  117496 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2420 /    8192             ( 29.54%) | total_pruned =    5772 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   16659 /  147456             ( 11.30%) | total_pruned =  130797 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   15357 /  147456             ( 10.41%) | total_pruned =  132099 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   73546 /  294912             ( 24.94%) | total_pruned =  221366 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  110036 /  589824             ( 18.66%) | total_pruned =  479788 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    8123 /   32768             ( 24.79%) | total_pruned =   24645 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     183 /     256             ( 71.48%) | total_pruned =      73 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   78897 /  589824             ( 13.38%) | total_pruned =  510927 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   63604 /  589824             ( 10.78%) | total_pruned =  526220 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     138 /     256             ( 53.91%) | total_pruned =     118 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  167555 / 1179648             ( 14.20%) | total_pruned = 1012093 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     423 /     512             ( 82.62%) | total_pruned =      89 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     208 /     512             ( 40.62%) | total_pruned =     304 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  165299 / 2359296             (  7.01%) | total_pruned = 2193997 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     469 /     512             ( 91.60%) | total_pruned =      43 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    5903 /  131072             (  4.50%) | total_pruned =  125169 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     320 /     512             ( 62.50%) | total_pruned =     192 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   81788 / 2359296             (  3.47%) | total_pruned = 2277508 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     353 /     512             ( 68.95%) | total_pruned =     159 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      35 /     512             (  6.84%) | total_pruned =     477 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  147897 / 2359296             (  6.27%) | total_pruned = 2211399 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     469 /     512             ( 91.60%) | total_pruned =      43 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     464 /     512             ( 90.62%) | total_pruned =      48 | shape = torch.Size([512])
linear.weight        | nonzeros =    4569 /    5120             ( 89.24%) | total_pruned =     551 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 47/100 Loss: 0.015853 Accuracy: 86.30 100.00 % Best test Accuracy: 86.37%
tensor(0.0715, device='cuda:0') tensor(0.1756, device='cuda:0') tensor(-3.7738e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.249564
Average KL loss: 0.011419
Average total loss: 0.260983
tensor(0.0711, device='cuda:0') tensor(0.1614, device='cuda:0') tensor(-2.6733e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.215578
Average KL loss: 0.010575
Average total loss: 0.226153
tensor(0.0708, device='cuda:0') tensor(0.1540, device='cuda:0') tensor(-2.9805e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.194255
Average KL loss: 0.010087
Average total loss: 0.204342
tensor(0.0702, device='cuda:0') tensor(0.1494, device='cuda:0') tensor(-2.2226e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.181825
Average KL loss: 0.009791
Average total loss: 0.191616
tensor(0.0695, device='cuda:0') tensor(0.1465, device='cuda:0') tensor(-2.1377e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.171706
Average KL loss: 0.009609
Average total loss: 0.181314
tensor(0.0688, device='cuda:0') tensor(0.1447, device='cuda:0') tensor(-2.8877e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.161843
Average KL loss: 0.009504
Average total loss: 0.171346
tensor(0.0683, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(-2.0089e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.152492
Average KL loss: 0.009451
Average total loss: 0.161943
tensor(0.0679, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-1.3914e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.144800
Average KL loss: 0.009435
Average total loss: 0.154235
tensor(0.0676, device='cuda:0') tensor(0.1429, device='cuda:0') tensor(-1.8945e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.142793
Average KL loss: 0.009439
Average total loss: 0.152232
tensor(0.0674, device='cuda:0') tensor(0.1429, device='cuda:0') tensor(-1.3866e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.133284
Average KL loss: 0.009459
Average total loss: 0.142743
tensor(0.0673, device='cuda:0') tensor(0.1430, device='cuda:0') tensor(-1.5272e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.131419
Average KL loss: 0.009487
Average total loss: 0.140906
tensor(0.0673, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-1.7836e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.120369
Average KL loss: 0.009523
Average total loss: 0.129893
tensor(0.0673, device='cuda:0') tensor(0.1436, device='cuda:0') tensor(-1.7283e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.118938
Average KL loss: 0.009561
Average total loss: 0.128498
tensor(0.0674, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(-1.4106e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.114672
Average KL loss: 0.009599
Average total loss: 0.124272
tensor(0.0674, device='cuda:0') tensor(0.1443, device='cuda:0') tensor(-1.5259e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.108451
Average KL loss: 0.009639
Average total loss: 0.118090
tensor(0.0675, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(-1.4040e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.113623
Average KL loss: 0.009683
Average total loss: 0.123306
tensor(0.0676, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(-1.0357e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.103600
Average KL loss: 0.009724
Average total loss: 0.113324
tensor(0.0677, device='cuda:0') tensor(0.1457, device='cuda:0') tensor(-1.0499e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.101486
Average KL loss: 0.009767
Average total loss: 0.111253
tensor(0.0678, device='cuda:0') tensor(0.1463, device='cuda:0') tensor(-1.3147e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.098878
Average KL loss: 0.009811
Average total loss: 0.108689
tensor(0.0679, device='cuda:0') tensor(0.1468, device='cuda:0') tensor(-1.1590e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.096507
Average KL loss: 0.009854
Average total loss: 0.106361
tensor(0.0681, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(-1.4419e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.093126
Average KL loss: 0.009896
Average total loss: 0.103022
tensor(0.0682, device='cuda:0') tensor(0.1478, device='cuda:0') tensor(-1.0648e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.091257
Average KL loss: 0.009939
Average total loss: 0.101196
tensor(0.0683, device='cuda:0') tensor(0.1484, device='cuda:0') tensor(-9.5937e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.091552
Average KL loss: 0.009981
Average total loss: 0.101533
tensor(0.0684, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(-1.0051e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.091117
Average KL loss: 0.010024
Average total loss: 0.101141
tensor(0.0685, device='cuda:0') tensor(0.1495, device='cuda:0') tensor(-1.3156e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.086629
Average KL loss: 0.010066
Average total loss: 0.096695
tensor(0.0686, device='cuda:0') tensor(0.1501, device='cuda:0') tensor(-9.0248e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.080878
Average KL loss: 0.010108
Average total loss: 0.090986
tensor(0.0688, device='cuda:0') tensor(0.1506, device='cuda:0') tensor(-8.5440e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.080806
Average KL loss: 0.010148
Average total loss: 0.090954
tensor(0.0689, device='cuda:0') tensor(0.1512, device='cuda:0') tensor(-8.6872e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.082148
Average KL loss: 0.010190
Average total loss: 0.092337
tensor(0.0690, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(-1.0538e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.076136
Average KL loss: 0.010229
Average total loss: 0.086365
tensor(0.0691, device='cuda:0') tensor(0.1523, device='cuda:0') tensor(-8.9175e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.076675
Average KL loss: 0.010264
Average total loss: 0.086939
tensor(0.0692, device='cuda:0') tensor(0.1528, device='cuda:0') tensor(-9.2855e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.075037
Average KL loss: 0.010300
Average total loss: 0.085337
tensor(0.0693, device='cuda:0') tensor(0.1534, device='cuda:0') tensor(-6.3612e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.074070
Average KL loss: 0.010337
Average total loss: 0.084407
tensor(0.0694, device='cuda:0') tensor(0.1539, device='cuda:0') tensor(-9.2888e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.071125
Average KL loss: 0.010375
Average total loss: 0.081500
tensor(0.0695, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(-7.6829e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.069542
Average KL loss: 0.010413
Average total loss: 0.079955
tensor(0.0696, device='cuda:0') tensor(0.1551, device='cuda:0') tensor(-9.2288e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.070667
Average KL loss: 0.010449
Average total loss: 0.081116
tensor(0.0697, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(-6.1185e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.066676
Average KL loss: 0.010483
Average total loss: 0.077159
tensor(0.0698, device='cuda:0') tensor(0.1562, device='cuda:0') tensor(-6.9187e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.065018
Average KL loss: 0.010517
Average total loss: 0.075535
tensor(0.0699, device='cuda:0') tensor(0.1567, device='cuda:0') tensor(-4.9137e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.064604
Average KL loss: 0.010551
Average total loss: 0.075156
tensor(0.0700, device='cuda:0') tensor(0.1572, device='cuda:0') tensor(-6.0422e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.064635
Average KL loss: 0.010583
Average total loss: 0.075218
tensor(0.0701, device='cuda:0') tensor(0.1577, device='cuda:0') tensor(-6.3792e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.062884
Average KL loss: 0.010613
Average total loss: 0.073497
tensor(0.0701, device='cuda:0') tensor(0.1582, device='cuda:0') tensor(-1.0346e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.059908
Average KL loss: 0.010645
Average total loss: 0.070553
tensor(0.0702, device='cuda:0') tensor(0.1588, device='cuda:0') tensor(-6.8943e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.060303
Average KL loss: 0.010677
Average total loss: 0.070980
tensor(0.0703, device='cuda:0') tensor(0.1593, device='cuda:0') tensor(-7.4345e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.057909
Average KL loss: 0.010707
Average total loss: 0.068616
tensor(0.0704, device='cuda:0') tensor(0.1598, device='cuda:0') tensor(-6.6388e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.058129
Average KL loss: 0.010735
Average total loss: 0.068864
tensor(0.0705, device='cuda:0') tensor(0.1603, device='cuda:0') tensor(-5.4521e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.057216
Average KL loss: 0.010765
Average total loss: 0.067981
tensor(0.0705, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-5.0063e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.056202
Average KL loss: 0.010796
Average total loss: 0.066998
tensor(0.0706, device='cuda:0') tensor(0.1613, device='cuda:0') tensor(-7.3436e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.055228
Average KL loss: 0.010823
Average total loss: 0.066051
tensor(0.0707, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(-6.1451e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.054433
Average KL loss: 0.010851
Average total loss: 0.065284
tensor(0.0708, device='cuda:0') tensor(0.1623, device='cuda:0') tensor(-4.4553e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.053898
Average KL loss: 0.010878
Average total loss: 0.064777
tensor(0.0708, device='cuda:0') tensor(0.1628, device='cuda:0') tensor(-4.5810e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.051075
Average KL loss: 0.010905
Average total loss: 0.061980
tensor(0.0709, device='cuda:0') tensor(0.1632, device='cuda:0') tensor(-8.0530e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.051239
Average KL loss: 0.010932
Average total loss: 0.062171
tensor(0.0710, device='cuda:0') tensor(0.1637, device='cuda:0') tensor(-4.8671e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.051971
Average KL loss: 0.010957
Average total loss: 0.062928
tensor(0.0710, device='cuda:0') tensor(0.1642, device='cuda:0') tensor(-6.1280e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.049270
Average KL loss: 0.010982
Average total loss: 0.060252
tensor(0.0711, device='cuda:0') tensor(0.1647, device='cuda:0') tensor(-3.4947e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.048206
Average KL loss: 0.011006
Average total loss: 0.059212
tensor(0.0711, device='cuda:0') tensor(0.1651, device='cuda:0') tensor(-4.5270e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.047997
Average KL loss: 0.011031
Average total loss: 0.059028
tensor(0.0712, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(-4.4372e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.047756
Average KL loss: 0.011056
Average total loss: 0.058813
tensor(0.0712, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-3.5102e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.046815
Average KL loss: 0.011080
Average total loss: 0.057895
tensor(0.0713, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-5.6588e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.046075
Average KL loss: 0.011104
Average total loss: 0.057180
tensor(0.0713, device='cuda:0') tensor(0.1670, device='cuda:0') tensor(-4.0272e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.045573
Average KL loss: 0.011127
Average total loss: 0.056701
tensor(0.0714, device='cuda:0') tensor(0.1675, device='cuda:0') tensor(-3.7287e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.045050
Average KL loss: 0.011150
Average total loss: 0.056199
tensor(0.0714, device='cuda:0') tensor(0.1679, device='cuda:0') tensor(-5.7590e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.043174
Average KL loss: 0.011171
Average total loss: 0.054346
tensor(0.0715, device='cuda:0') tensor(0.1684, device='cuda:0') tensor(-3.8569e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.044489
Average KL loss: 0.011193
Average total loss: 0.055682
tensor(0.0715, device='cuda:0') tensor(0.1688, device='cuda:0') tensor(-4.5746e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.042555
Average KL loss: 0.011216
Average total loss: 0.053772
tensor(0.0716, device='cuda:0') tensor(0.1693, device='cuda:0') tensor(-3.8071e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.041789
Average KL loss: 0.011236
Average total loss: 0.053025
tensor(0.0716, device='cuda:0') tensor(0.1697, device='cuda:0') tensor(-2.9733e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.042314
Average KL loss: 0.011256
Average total loss: 0.053569
tensor(0.0716, device='cuda:0') tensor(0.1701, device='cuda:0') tensor(-4.7148e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.042452
Average KL loss: 0.011278
Average total loss: 0.053730
tensor(0.0717, device='cuda:0') tensor(0.1706, device='cuda:0') tensor(-4.6154e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.040081
Average KL loss: 0.011299
Average total loss: 0.051380
tensor(0.0717, device='cuda:0') tensor(0.1710, device='cuda:0') tensor(-3.1845e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.039636
Average KL loss: 0.011319
Average total loss: 0.050955
tensor(0.0718, device='cuda:0') tensor(0.1714, device='cuda:0') tensor(-4.1968e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.042558
Average KL loss: 0.011340
Average total loss: 0.053898
tensor(0.0718, device='cuda:0') tensor(0.1719, device='cuda:0') tensor(-5.4392e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.039008
Average KL loss: 0.011362
Average total loss: 0.050370
tensor(0.0719, device='cuda:0') tensor(0.1723, device='cuda:0') tensor(-3.2194e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.038495
Average KL loss: 0.011380
Average total loss: 0.049875
tensor(0.0719, device='cuda:0') tensor(0.1727, device='cuda:0') tensor(-3.7048e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.039152
Average KL loss: 0.011399
Average total loss: 0.050551
tensor(0.0719, device='cuda:0') tensor(0.1732, device='cuda:0') tensor(-3.1353e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.038001
Average KL loss: 0.011417
Average total loss: 0.049418
tensor(0.0720, device='cuda:0') tensor(0.1736, device='cuda:0') tensor(-2.4404e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.038355
Average KL loss: 0.011436
Average total loss: 0.049791
tensor(0.0720, device='cuda:0') tensor(0.1740, device='cuda:0') tensor(-2.6868e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.037473
Average KL loss: 0.011456
Average total loss: 0.048929
tensor(0.0720, device='cuda:0') tensor(0.1745, device='cuda:0') tensor(-3.3527e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.036546
Average KL loss: 0.011475
Average total loss: 0.048021
tensor(0.0721, device='cuda:0') tensor(0.1749, device='cuda:0') tensor(-3.8337e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.036222
Average KL loss: 0.011492
Average total loss: 0.047715
tensor(0.0721, device='cuda:0') tensor(0.1753, device='cuda:0') tensor(-2.7388e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.036436
Average KL loss: 0.011509
Average total loss: 0.047945
tensor(0.0721, device='cuda:0') tensor(0.1757, device='cuda:0') tensor(-2.7804e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.036012
Average KL loss: 0.011527
Average total loss: 0.047540
tensor(0.0722, device='cuda:0') tensor(0.1761, device='cuda:0') tensor(-3.0042e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.035154
Average KL loss: 0.011546
Average total loss: 0.046700
tensor(0.0722, device='cuda:0') tensor(0.1765, device='cuda:0') tensor(-2.1885e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.034960
Average KL loss: 0.011563
Average total loss: 0.046523
tensor(0.0722, device='cuda:0') tensor(0.1769, device='cuda:0') tensor(-2.5929e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.034150
Average KL loss: 0.011579
Average total loss: 0.045729
tensor(0.0722, device='cuda:0') tensor(0.1773, device='cuda:0') tensor(-3.3725e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.033709
Average KL loss: 0.011593
Average total loss: 0.045302
tensor(0.0722, device='cuda:0') tensor(0.1777, device='cuda:0') tensor(-2.5342e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.032653
Average KL loss: 0.011610
Average total loss: 0.044263
tensor(0.0723, device='cuda:0') tensor(0.1781, device='cuda:0') tensor(-2.1686e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.033700
Average KL loss: 0.011625
Average total loss: 0.045325
tensor(0.0723, device='cuda:0') tensor(0.1785, device='cuda:0') tensor(-2.9991e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.034942
Average KL loss: 0.011643
Average total loss: 0.046585
tensor(0.0723, device='cuda:0') tensor(0.1789, device='cuda:0') tensor(-2.4536e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.031920
Average KL loss: 0.011658
Average total loss: 0.043578
tensor(0.0723, device='cuda:0') tensor(0.1793, device='cuda:0') tensor(-2.0524e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.032229
Average KL loss: 0.011671
Average total loss: 0.043901
tensor(0.0724, device='cuda:0') tensor(0.1797, device='cuda:0') tensor(-2.7964e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.032596
Average KL loss: 0.011689
Average total loss: 0.044285
tensor(0.0724, device='cuda:0') tensor(0.1801, device='cuda:0') tensor(-2.8030e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.031540
Average KL loss: 0.011706
Average total loss: 0.043246
tensor(0.0724, device='cuda:0') tensor(0.1805, device='cuda:0') tensor(-2.0222e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.031129
Average KL loss: 0.011719
Average total loss: 0.042849
tensor(0.0724, device='cuda:0') tensor(0.1809, device='cuda:0') tensor(-2.0910e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.030006
Average KL loss: 0.011731
Average total loss: 0.041737
tensor(0.0724, device='cuda:0') tensor(0.1812, device='cuda:0') tensor(-2.0284e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.030046
Average KL loss: 0.011741
Average total loss: 0.041788
tensor(0.0724, device='cuda:0') tensor(0.1816, device='cuda:0') tensor(-1.9054e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.029817
Average KL loss: 0.011752
Average total loss: 0.041569
tensor(0.0724, device='cuda:0') tensor(0.1819, device='cuda:0') tensor(-2.2619e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.029798
Average KL loss: 0.011764
Average total loss: 0.041562
tensor(0.0724, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(-2.0325e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.029052
Average KL loss: 0.011776
Average total loss: 0.040829
tensor(0.0724, device='cuda:0') tensor(0.1826, device='cuda:0') tensor(-3.3475e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.029073
Average KL loss: 0.011787
Average total loss: 0.040861
tensor(0.0725, device='cuda:0') tensor(0.1830, device='cuda:0') tensor(-1.2830e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.028878
Average KL loss: 0.011799
Average total loss: 0.040677
tensor(0.0725, device='cuda:0') tensor(0.1833, device='cuda:0') tensor(-1.4637e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.028889
Average KL loss: 0.011810
Average total loss: 0.040699
tensor(0.0725, device='cuda:0') tensor(0.1837, device='cuda:0') tensor(-1.7758e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.029150
Average KL loss: 0.011822
Average total loss: 0.040972
tensor(0.0725, device='cuda:0') tensor(0.1841, device='cuda:0') tensor(-9.9431e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.028389
Average KL loss: 0.011835
Average total loss: 0.040224
tensor(0.0725, device='cuda:0') tensor(0.1844, device='cuda:0') tensor(-1.7970e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.028520
Average KL loss: 0.011847
Average total loss: 0.040367
tensor(0.0725, device='cuda:0') tensor(0.1848, device='cuda:0') tensor(-2.2288e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.028126
Average KL loss: 0.011860
Average total loss: 0.039986
tensor(0.0725, device='cuda:0') tensor(0.1852, device='cuda:0') tensor(-1.4861e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.027422
Average KL loss: 0.011871
Average total loss: 0.039293
tensor(0.0725, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-1.3868e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.028092
Average KL loss: 0.011882
Average total loss: 0.039974
tensor(0.0725, device='cuda:0') tensor(0.1859, device='cuda:0') tensor(-2.1371e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.027107
Average KL loss: 0.011892
Average total loss: 0.038999
tensor(0.0725, device='cuda:0') tensor(0.1862, device='cuda:0') tensor(-3.0090e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.026909
Average KL loss: 0.011901
Average total loss: 0.038810
tensor(0.0725, device='cuda:0') tensor(0.1865, device='cuda:0') tensor(-1.8164e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.026668
Average KL loss: 0.011911
Average total loss: 0.038579
tensor(0.0725, device='cuda:0') tensor(0.1869, device='cuda:0') tensor(-1.7069e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.026404
Average KL loss: 0.011921
Average total loss: 0.038325
tensor(0.0725, device='cuda:0') tensor(0.1872, device='cuda:0') tensor(-2.0432e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.025719
Average KL loss: 0.011930
Average total loss: 0.037649
tensor(0.0725, device='cuda:0') tensor(0.1875, device='cuda:0') tensor(-2.2502e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.025919
Average KL loss: 0.011939
Average total loss: 0.037858
tensor(0.0725, device='cuda:0') tensor(0.1879, device='cuda:0') tensor(-1.7601e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.025628
Average KL loss: 0.011948
Average total loss: 0.037577
tensor(0.0725, device='cuda:0') tensor(0.1882, device='cuda:0') tensor(-1.2566e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.025983
Average KL loss: 0.011957
Average total loss: 0.037940
tensor(0.0725, device='cuda:0') tensor(0.1885, device='cuda:0') tensor(-7.2441e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.024799
Average KL loss: 0.011963
Average total loss: 0.036762
tensor(0.0724, device='cuda:0') tensor(0.1888, device='cuda:0') tensor(-1.9593e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.025066
Average KL loss: 0.011970
Average total loss: 0.037036
tensor(0.0724, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-1.6987e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.024962
Average KL loss: 0.011978
Average total loss: 0.036940
tensor(0.0724, device='cuda:0') tensor(0.1894, device='cuda:0') tensor(-1.3947e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.024774
Average KL loss: 0.011986
Average total loss: 0.036760
tensor(0.0724, device='cuda:0') tensor(0.1897, device='cuda:0') tensor(-1.9077e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.024517
Average KL loss: 0.011992
Average total loss: 0.036509
tensor(0.0724, device='cuda:0') tensor(0.1900, device='cuda:0') tensor(-1.5786e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.024316
Average KL loss: 0.012000
Average total loss: 0.036316
tensor(0.0724, device='cuda:0') tensor(0.1904, device='cuda:0') tensor(-1.3389e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.024360
Average KL loss: 0.012009
Average total loss: 0.036369
tensor(0.0724, device='cuda:0') tensor(0.1907, device='cuda:0') tensor(-2.5874e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.023858
Average KL loss: 0.012017
Average total loss: 0.035875
tensor(0.0724, device='cuda:0') tensor(0.1910, device='cuda:0') tensor(-1.8591e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.023483
Average KL loss: 0.012023
Average total loss: 0.035506
tensor(0.0724, device='cuda:0') tensor(0.1913, device='cuda:0') tensor(-1.0592e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.023788
Average KL loss: 0.012029
Average total loss: 0.035817
tensor(0.0724, device='cuda:0') tensor(0.1916, device='cuda:0') tensor(-1.2186e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.024111
Average KL loss: 0.012037
Average total loss: 0.036148
tensor(0.0724, device='cuda:0') tensor(0.1920, device='cuda:0') tensor(-2.1996e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.023165
Average KL loss: 0.012046
Average total loss: 0.035210
tensor(0.0723, device='cuda:0') tensor(0.1923, device='cuda:0') tensor(-7.5290e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.023170
Average KL loss: 0.012051
Average total loss: 0.035221
tensor(0.0723, device='cuda:0') tensor(0.1926, device='cuda:0') tensor(-1.2618e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.022953
Average KL loss: 0.012058
Average total loss: 0.035011
tensor(0.0723, device='cuda:0') tensor(0.1929, device='cuda:0') tensor(-2.1575e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.022356
Average KL loss: 0.012061
Average total loss: 0.034417
tensor(0.0723, device='cuda:0') tensor(0.1931, device='cuda:0') tensor(-9.6730e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.022618
Average KL loss: 0.012067
Average total loss: 0.034684
tensor(0.0723, device='cuda:0') tensor(0.1934, device='cuda:0') tensor(-9.6293e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.022392
Average KL loss: 0.012072
Average total loss: 0.034464
tensor(0.0723, device='cuda:0') tensor(0.1937, device='cuda:0') tensor(-6.8387e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.022135
Average KL loss: 0.012076
Average total loss: 0.034211
tensor(0.0722, device='cuda:0') tensor(0.1940, device='cuda:0') tensor(-1.8106e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.022430
Average KL loss: 0.012081
Average total loss: 0.034511
tensor(0.0722, device='cuda:0') tensor(0.1943, device='cuda:0') tensor(-1.0173e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.022375
Average KL loss: 0.012086
Average total loss: 0.034462
tensor(0.0722, device='cuda:0') tensor(0.1946, device='cuda:0') tensor(-1.5629e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.021735
Average KL loss: 0.012091
Average total loss: 0.033826
tensor(0.0722, device='cuda:0') tensor(0.1949, device='cuda:0') tensor(-1.4551e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.021530
Average KL loss: 0.012094
Average total loss: 0.033625
tensor(0.0722, device='cuda:0') tensor(0.1951, device='cuda:0') tensor(-1.4178e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.021402
Average KL loss: 0.012097
Average total loss: 0.033500
tensor(0.0721, device='cuda:0') tensor(0.1954, device='cuda:0') tensor(-1.2976e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.022199
Average KL loss: 0.012103
Average total loss: 0.034303
tensor(0.0721, device='cuda:0') tensor(0.1957, device='cuda:0') tensor(-6.4654e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.021510
Average KL loss: 0.012112
Average total loss: 0.033622
tensor(0.0721, device='cuda:0') tensor(0.1960, device='cuda:0') tensor(-8.2629e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.021344
Average KL loss: 0.012116
Average total loss: 0.033459
tensor(0.0721, device='cuda:0') tensor(0.1963, device='cuda:0') tensor(-6.5361e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.020827
Average KL loss: 0.012119
Average total loss: 0.032945
tensor(0.0721, device='cuda:0') tensor(0.1965, device='cuda:0') tensor(-1.2518e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.020968
Average KL loss: 0.012121
Average total loss: 0.033088
tensor(0.0720, device='cuda:0') tensor(0.1968, device='cuda:0') tensor(-7.4317e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.020680
Average KL loss: 0.012124
Average total loss: 0.032803
tensor(0.0720, device='cuda:0') tensor(0.1971, device='cuda:0') tensor(-1.1177e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.020869
Average KL loss: 0.012127
Average total loss: 0.032996
tensor(0.0720, device='cuda:0') tensor(0.1973, device='cuda:0') tensor(-8.9450e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.020590
Average KL loss: 0.012132
Average total loss: 0.032722
tensor(0.0720, device='cuda:0') tensor(0.1976, device='cuda:0') tensor(-6.1096e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.020447
Average KL loss: 0.012134
Average total loss: 0.032580
tensor(0.0720, device='cuda:0') tensor(0.1979, device='cuda:0') tensor(-8.4740e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.020044
Average KL loss: 0.012137
Average total loss: 0.032180
tensor(0.0719, device='cuda:0') tensor(0.1982, device='cuda:0') tensor(-8.3624e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.019769
Average KL loss: 0.012138
Average total loss: 0.031908
tensor(0.0719, device='cuda:0') tensor(0.1984, device='cuda:0') tensor(-5.0373e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.020310
Average KL loss: 0.012139
Average total loss: 0.032450
tensor(0.0719, device='cuda:0') tensor(0.1987, device='cuda:0') tensor(-1.0781e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.019602
Average KL loss: 0.012141
Average total loss: 0.031743
tensor(0.0718, device='cuda:0') tensor(0.1989, device='cuda:0') tensor(-1.0932e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.019823
Average KL loss: 0.012142
Average total loss: 0.031964
tensor(0.0718, device='cuda:0') tensor(0.1991, device='cuda:0') tensor(-8.1579e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.019562
Average KL loss: 0.012143
Average total loss: 0.031705
tensor(0.0718, device='cuda:0') tensor(0.1993, device='cuda:0') tensor(-1.3650e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.019789
Average KL loss: 0.012147
Average total loss: 0.031936
tensor(0.0717, device='cuda:0') tensor(0.1996, device='cuda:0') tensor(-7.4552e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.019871
Average KL loss: 0.012150
Average total loss: 0.032021
tensor(0.0717, device='cuda:0') tensor(0.1999, device='cuda:0') tensor(-2.3277e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.019690
Average KL loss: 0.012154
Average total loss: 0.031845
tensor(0.0717, device='cuda:0') tensor(0.2002, device='cuda:0') tensor(-8.0057e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.019858
Average KL loss: 0.012157
Average total loss: 0.032014
tensor(0.0717, device='cuda:0') tensor(0.2005, device='cuda:0') tensor(-5.4703e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.018828
Average KL loss: 0.012162
Average total loss: 0.030990
tensor(0.0716, device='cuda:0') tensor(0.2008, device='cuda:0') tensor(-1.0929e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.019143
Average KL loss: 0.012162
Average total loss: 0.031305
tensor(0.0716, device='cuda:0') tensor(0.2010, device='cuda:0') tensor(-5.7138e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.018913
Average KL loss: 0.012165
Average total loss: 0.031079
tensor(0.0716, device='cuda:0') tensor(0.2013, device='cuda:0') tensor(-8.0802e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.019475
Average KL loss: 0.012167
Average total loss: 0.031642
tensor(0.0716, device='cuda:0') tensor(0.2016, device='cuda:0') tensor(-9.9847e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.019250
Average KL loss: 0.012171
Average total loss: 0.031421
tensor(0.0716, device='cuda:0') tensor(0.2019, device='cuda:0') tensor(-4.6325e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.018479
Average KL loss: 0.012171
Average total loss: 0.030651
tensor(0.0715, device='cuda:0') tensor(0.2021, device='cuda:0') tensor(-5.3534e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.019971
Average KL loss: 0.012173
Average total loss: 0.032144
tensor(0.0715, device='cuda:0') tensor(0.2024, device='cuda:0') tensor(-4.5723e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.018159
Average KL loss: 0.012174
Average total loss: 0.030333
tensor(0.0715, device='cuda:0') tensor(0.2026, device='cuda:0') tensor(-4.4380e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.018582
Average KL loss: 0.012174
Average total loss: 0.030756
tensor(0.0714, device='cuda:0') tensor(0.2029, device='cuda:0') tensor(-7.8866e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.018460
Average KL loss: 0.012177
Average total loss: 0.030638
tensor(0.0714, device='cuda:0') tensor(0.2031, device='cuda:0') tensor(-4.4850e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.018282
Average KL loss: 0.012179
Average total loss: 0.030460
tensor(0.0714, device='cuda:0') tensor(0.2034, device='cuda:0') tensor(-6.2091e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.018092
Average KL loss: 0.012177
Average total loss: 0.030270
tensor(0.0713, device='cuda:0') tensor(0.2036, device='cuda:0') tensor(-6.2977e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.018117
Average KL loss: 0.012178
Average total loss: 0.030295
tensor(0.0713, device='cuda:0') tensor(0.2039, device='cuda:0') tensor(-5.1706e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.017991
Average KL loss: 0.012177
Average total loss: 0.030168
tensor(0.0713, device='cuda:0') tensor(0.2041, device='cuda:0') tensor(-3.4549e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.017535
Average KL loss: 0.012176
Average total loss: 0.029711
tensor(0.0712, device='cuda:0') tensor(0.2043, device='cuda:0') tensor(-7.5400e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.017688
Average KL loss: 0.012173
Average total loss: 0.029861
tensor(0.0712, device='cuda:0') tensor(0.2045, device='cuda:0') tensor(-4.4262e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.017582
Average KL loss: 0.012170
Average total loss: 0.029752
tensor(0.0711, device='cuda:0') tensor(0.2047, device='cuda:0') tensor(-8.9698e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.017481
Average KL loss: 0.012167
Average total loss: 0.029649
tensor(0.0711, device='cuda:0') tensor(0.2049, device='cuda:0') tensor(-8.6719e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.017822
Average KL loss: 0.012167
Average total loss: 0.029989
tensor(0.0711, device='cuda:0') tensor(0.2052, device='cuda:0') tensor(-4.8672e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.017432
Average KL loss: 0.012167
Average total loss: 0.029598
tensor(0.0711, device='cuda:0') tensor(0.2054, device='cuda:0') tensor(-1.7634e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.017334
Average KL loss: 0.012166
Average total loss: 0.029499
tensor(0.0710, device='cuda:0') tensor(0.2056, device='cuda:0') tensor(-6.1277e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.017875
Average KL loss: 0.012166
Average total loss: 0.030041
tensor(0.0710, device='cuda:0') tensor(0.2059, device='cuda:0') tensor(-8.5906e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.017338
Average KL loss: 0.012169
Average total loss: 0.029507
tensor(0.0710, device='cuda:0') tensor(0.2062, device='cuda:0') tensor(-7.1869e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.017370
Average KL loss: 0.012168
Average total loss: 0.029538
tensor(0.0709, device='cuda:0') tensor(0.2064, device='cuda:0') tensor(-9.1295e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.017058
Average KL loss: 0.012165
Average total loss: 0.029223
tensor(0.0709, device='cuda:0') tensor(0.2066, device='cuda:0') tensor(-4.4647e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.017212
Average KL loss: 0.012165
Average total loss: 0.029377
tensor(0.0709, device='cuda:0') tensor(0.2069, device='cuda:0') tensor(-3.6885e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.017086
Average KL loss: 0.012167
Average total loss: 0.029253
tensor(0.0708, device='cuda:0') tensor(0.2071, device='cuda:0') tensor(-5.5427e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.016828
Average KL loss: 0.012164
Average total loss: 0.028993
tensor(0.0708, device='cuda:0') tensor(0.2073, device='cuda:0') tensor(-7.4197e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.017101
Average KL loss: 0.012164
Average total loss: 0.029265
tensor(0.0708, device='cuda:0') tensor(0.2076, device='cuda:0') tensor(-2.0620e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.016525
Average KL loss: 0.012163
Average total loss: 0.028688
tensor(0.0707, device='cuda:0') tensor(0.2078, device='cuda:0') tensor(-3.7643e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.016590
Average KL loss: 0.012160
Average total loss: 0.028750
tensor(0.0707, device='cuda:0') tensor(0.2080, device='cuda:0') tensor(-2.2419e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.016778
Average KL loss: 0.012159
Average total loss: 0.028937
tensor(0.0706, device='cuda:0') tensor(0.2082, device='cuda:0') tensor(-5.7923e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.016798
Average KL loss: 0.012157
Average total loss: 0.028955
tensor(0.0706, device='cuda:0') tensor(0.2085, device='cuda:0') tensor(-6.9332e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.016516
Average KL loss: 0.012156
Average total loss: 0.028672
tensor(0.0706, device='cuda:0') tensor(0.2087, device='cuda:0') tensor(-2.1538e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.016605
Average KL loss: 0.012155
Average total loss: 0.028760
tensor(0.0705, device='cuda:0') tensor(0.2090, device='cuda:0') tensor(-3.6522e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.016243
Average KL loss: 0.012153
Average total loss: 0.028396
tensor(0.0705, device='cuda:0') tensor(0.2092, device='cuda:0') tensor(-9.0187e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.016348
Average KL loss: 0.012151
Average total loss: 0.028499
tensor(0.0705, device='cuda:0') tensor(0.2094, device='cuda:0') tensor(-5.3452e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.016192
Average KL loss: 0.012149
Average total loss: 0.028341
tensor(0.0704, device='cuda:0') tensor(0.2096, device='cuda:0') tensor(-2.9539e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.016101
Average KL loss: 0.012145
Average total loss: 0.028245
tensor(0.0704, device='cuda:0') tensor(0.2098, device='cuda:0') tensor(-7.0825e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.016343
Average KL loss: 0.012142
Average total loss: 0.028485
tensor(0.0703, device='cuda:0') tensor(0.2100, device='cuda:0') tensor(-2.8566e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.016032
Average KL loss: 0.012142
Average total loss: 0.028173
tensor(0.0703, device='cuda:0') tensor(0.2103, device='cuda:0') tensor(-2.9309e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.015917
Average KL loss: 0.012139
Average total loss: 0.028056
tensor(0.0703, device='cuda:0') tensor(0.2105, device='cuda:0') tensor(-5.7592e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.015982
Average KL loss: 0.012135
Average total loss: 0.028117
tensor(0.0702, device='cuda:0') tensor(0.2106, device='cuda:0') tensor(-3.4792e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.016187
Average KL loss: 0.012129
Average total loss: 0.028316
tensor(0.0702, device='cuda:0') tensor(0.2108, device='cuda:0') tensor(-4.9101e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.015810
Average KL loss: 0.012128
Average total loss: 0.027939
 Percentile value: 2.711476182937622
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/8]: ---
conv1.weight         | nonzeros =     210 /    1728             ( 12.15%) | total_pruned =    1518 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     415 /   36864             (  1.13%) | total_pruned =   36449 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     734 /   36864             (  1.99%) | total_pruned =   36130 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     813 /   36864             (  2.21%) | total_pruned =   36051 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     982 /   36864             (  2.66%) | total_pruned =   35882 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4049 /   73728             (  5.49%) | total_pruned =   69679 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   11309 /  147456             (  7.67%) | total_pruned =  136147 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1017 /    8192             ( 12.41%) | total_pruned =    7175 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    6677 /  147456             (  4.53%) | total_pruned =  140779 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    6073 /  147456             (  4.12%) | total_pruned =  141383 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   31204 /  294912             ( 10.58%) | total_pruned =  263708 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   42666 /  589824             (  7.23%) | total_pruned =  547158 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     161 /     256             ( 62.89%) | total_pruned =      95 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      99 /     256             ( 38.67%) | total_pruned =     157 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3780 /   32768             ( 11.54%) | total_pruned =   28988 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   23966 /  589824             (  4.06%) | total_pruned =  565858 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   18206 /  589824             (  3.09%) | total_pruned =  571618 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     115 /     256             ( 44.92%) | total_pruned =     141 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   52695 / 1179648             (  4.47%) | total_pruned = 1126953 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     372 /     512             ( 72.66%) | total_pruned =     140 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     163 /     512             ( 31.84%) | total_pruned =     349 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   39819 / 2359296             (  1.69%) | total_pruned = 2319477 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     413 /     512             ( 80.66%) | total_pruned =      99 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     341 /     512             ( 66.60%) | total_pruned =     171 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1038 /  131072             (  0.79%) | total_pruned =  130034 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     154 /     512             ( 30.08%) | total_pruned =     358 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     339 /     512             ( 66.21%) | total_pruned =     173 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   19404 / 2359296             (  0.82%) | total_pruned = 2339892 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     194 /     512             ( 37.89%) | total_pruned =     318 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   28119 / 2359296             (  1.19%) | total_pruned = 2331177 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     437 /     512             ( 85.35%) | total_pruned =      75 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     420 /     512             ( 82.03%) | total_pruned =      92 | shape = torch.Size([512])
linear.weight        | nonzeros =    3700 /    5120             ( 72.27%) | total_pruned =    1420 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 51/100 Loss: 0.025645 Accuracy: 85.14 100.00 % Best test Accuracy: 85.31%
tensor(0.0701, device='cuda:0') tensor(0.2111, device='cuda:0') tensor(-9.1674e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.093188
Average KL loss: 0.011502
Average total loss: 0.104690
tensor(0.0655, device='cuda:0') tensor(0.1963, device='cuda:0') tensor(-8.4463e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.090058
Average KL loss: 0.010636
Average total loss: 0.100694
tensor(0.0624, device='cuda:0') tensor(0.1880, device='cuda:0') tensor(-1.2447e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.082679
Average KL loss: 0.010094
Average total loss: 0.092773
tensor(0.0601, device='cuda:0') tensor(0.1824, device='cuda:0') tensor(-6.2430e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.082821
Average KL loss: 0.009720
Average total loss: 0.092541
tensor(0.0584, device='cuda:0') tensor(0.1783, device='cuda:0') tensor(-1.1054e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.078128
Average KL loss: 0.009446
Average total loss: 0.087574
tensor(0.0570, device='cuda:0') tensor(0.1753, device='cuda:0') tensor(-1.0342e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.075094
Average KL loss: 0.009241
Average total loss: 0.084335
tensor(0.0560, device='cuda:0') tensor(0.1731, device='cuda:0') tensor(-8.3884e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.074967
Average KL loss: 0.009091
Average total loss: 0.084057
tensor(0.0551, device='cuda:0') tensor(0.1716, device='cuda:0') tensor(-1.0740e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.069452
Average KL loss: 0.008983
Average total loss: 0.078436
tensor(0.0545, device='cuda:0') tensor(0.1706, device='cuda:0') tensor(-8.2455e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.068311
Average KL loss: 0.008909
Average total loss: 0.077220
tensor(0.0540, device='cuda:0') tensor(0.1699, device='cuda:0') tensor(-6.6250e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.066279
Average KL loss: 0.008858
Average total loss: 0.075138
tensor(0.0537, device='cuda:0') tensor(0.1694, device='cuda:0') tensor(-8.0605e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.065009
Average KL loss: 0.008824
Average total loss: 0.073833
tensor(0.0534, device='cuda:0') tensor(0.1691, device='cuda:0') tensor(-6.4194e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.062865
Average KL loss: 0.008802
Average total loss: 0.071667
tensor(0.0532, device='cuda:0') tensor(0.1689, device='cuda:0') tensor(-7.7203e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.063246
Average KL loss: 0.008788
Average total loss: 0.072034
tensor(0.0531, device='cuda:0') tensor(0.1689, device='cuda:0') tensor(-8.0451e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.060954
Average KL loss: 0.008778
Average total loss: 0.069733
tensor(0.0530, device='cuda:0') tensor(0.1688, device='cuda:0') tensor(-6.4564e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.060962
Average KL loss: 0.008772
Average total loss: 0.069734
tensor(0.0529, device='cuda:0') tensor(0.1689, device='cuda:0') tensor(-6.2296e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.058233
Average KL loss: 0.008768
Average total loss: 0.067001
tensor(0.0528, device='cuda:0') tensor(0.1689, device='cuda:0') tensor(-6.3249e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.057038
Average KL loss: 0.008766
Average total loss: 0.065803
tensor(0.0528, device='cuda:0') tensor(0.1690, device='cuda:0') tensor(-5.5783e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.057130
Average KL loss: 0.008764
Average total loss: 0.065895
tensor(0.0528, device='cuda:0') tensor(0.1691, device='cuda:0') tensor(-5.6156e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.055229
Average KL loss: 0.008765
Average total loss: 0.063993
tensor(0.0528, device='cuda:0') tensor(0.1692, device='cuda:0') tensor(-5.0726e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.052570
Average KL loss: 0.008766
Average total loss: 0.061335
tensor(0.0528, device='cuda:0') tensor(0.1694, device='cuda:0') tensor(-5.2470e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.053298
Average KL loss: 0.008767
Average total loss: 0.062065
tensor(0.0528, device='cuda:0') tensor(0.1695, device='cuda:0') tensor(-4.9275e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.052112
Average KL loss: 0.008769
Average total loss: 0.060881
tensor(0.0528, device='cuda:0') tensor(0.1697, device='cuda:0') tensor(-5.1486e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.051024
Average KL loss: 0.008770
Average total loss: 0.059794
tensor(0.0528, device='cuda:0') tensor(0.1699, device='cuda:0') tensor(-5.1823e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.050463
Average KL loss: 0.008773
Average total loss: 0.059235
tensor(0.0528, device='cuda:0') tensor(0.1701, device='cuda:0') tensor(-3.4793e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.048133
Average KL loss: 0.008776
Average total loss: 0.056909
tensor(0.0528, device='cuda:0') tensor(0.1703, device='cuda:0') tensor(-5.0040e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.048244
Average KL loss: 0.008778
Average total loss: 0.057022
tensor(0.0528, device='cuda:0') tensor(0.1705, device='cuda:0') tensor(-5.1576e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.046659
Average KL loss: 0.008780
Average total loss: 0.055439
tensor(0.0528, device='cuda:0') tensor(0.1707, device='cuda:0') tensor(-4.8766e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.046341
Average KL loss: 0.008784
Average total loss: 0.055125
tensor(0.0528, device='cuda:0') tensor(0.1709, device='cuda:0') tensor(-5.0595e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.045134
Average KL loss: 0.008787
Average total loss: 0.053921
tensor(0.0528, device='cuda:0') tensor(0.1711, device='cuda:0') tensor(-3.8740e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.045338
Average KL loss: 0.008789
Average total loss: 0.054127
tensor(0.0528, device='cuda:0') tensor(0.1713, device='cuda:0') tensor(-4.3921e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.043871
Average KL loss: 0.008792
Average total loss: 0.052663
tensor(0.0529, device='cuda:0') tensor(0.1716, device='cuda:0') tensor(-3.6677e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.042876
Average KL loss: 0.008795
Average total loss: 0.051671
tensor(0.0529, device='cuda:0') tensor(0.1718, device='cuda:0') tensor(-3.2103e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.044436
Average KL loss: 0.008799
Average total loss: 0.053235
tensor(0.0529, device='cuda:0') tensor(0.1721, device='cuda:0') tensor(-5.2472e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.042747
Average KL loss: 0.008803
Average total loss: 0.051550
tensor(0.0529, device='cuda:0') tensor(0.1723, device='cuda:0') tensor(-3.5845e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.042425
Average KL loss: 0.008806
Average total loss: 0.051230
tensor(0.0529, device='cuda:0') tensor(0.1725, device='cuda:0') tensor(-3.6627e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.041124
Average KL loss: 0.008809
Average total loss: 0.049934
tensor(0.0529, device='cuda:0') tensor(0.1728, device='cuda:0') tensor(-3.7529e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.039698
Average KL loss: 0.008812
Average total loss: 0.048510
tensor(0.0530, device='cuda:0') tensor(0.1730, device='cuda:0') tensor(-3.7907e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.049791
Average KL loss: 0.008815
Average total loss: 0.058606
tensor(0.0530, device='cuda:0') tensor(0.1732, device='cuda:0') tensor(-2.5454e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.038941
Average KL loss: 0.008817
Average total loss: 0.047759
tensor(0.0530, device='cuda:0') tensor(0.1735, device='cuda:0') tensor(-2.7180e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.039266
Average KL loss: 0.008821
Average total loss: 0.048087
tensor(0.0530, device='cuda:0') tensor(0.1737, device='cuda:0') tensor(-3.1370e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.039283
Average KL loss: 0.008825
Average total loss: 0.048108
tensor(0.0530, device='cuda:0') tensor(0.1740, device='cuda:0') tensor(-2.9645e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.038402
Average KL loss: 0.008828
Average total loss: 0.047229
tensor(0.0530, device='cuda:0') tensor(0.1742, device='cuda:0') tensor(-2.9246e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.037487
Average KL loss: 0.008831
Average total loss: 0.046318
tensor(0.0531, device='cuda:0') tensor(0.1745, device='cuda:0') tensor(-4.4222e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.038006
Average KL loss: 0.008833
Average total loss: 0.046840
tensor(0.0531, device='cuda:0') tensor(0.1747, device='cuda:0') tensor(-3.6673e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.036803
Average KL loss: 0.008836
Average total loss: 0.045639
tensor(0.0531, device='cuda:0') tensor(0.1750, device='cuda:0') tensor(-2.3728e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.035342
Average KL loss: 0.008839
Average total loss: 0.044181
tensor(0.0531, device='cuda:0') tensor(0.1752, device='cuda:0') tensor(-2.4466e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.035241
Average KL loss: 0.008841
Average total loss: 0.044082
tensor(0.0531, device='cuda:0') tensor(0.1755, device='cuda:0') tensor(-3.1198e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.036640
Average KL loss: 0.008844
Average total loss: 0.045484
tensor(0.0531, device='cuda:0') tensor(0.1757, device='cuda:0') tensor(-2.4568e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.035431
Average KL loss: 0.008846
Average total loss: 0.044277
tensor(0.0532, device='cuda:0') tensor(0.1760, device='cuda:0') tensor(-2.4152e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.034351
Average KL loss: 0.008848
Average total loss: 0.043200
tensor(0.0532, device='cuda:0') tensor(0.1762, device='cuda:0') tensor(-2.3133e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.034665
Average KL loss: 0.008850
Average total loss: 0.043515
tensor(0.0532, device='cuda:0') tensor(0.1765, device='cuda:0') tensor(-2.4252e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.033376
Average KL loss: 0.008852
Average total loss: 0.042228
tensor(0.0532, device='cuda:0') tensor(0.1767, device='cuda:0') tensor(-3.1756e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.034385
Average KL loss: 0.008855
Average total loss: 0.043239
tensor(0.0532, device='cuda:0') tensor(0.1770, device='cuda:0') tensor(-2.4668e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.033355
Average KL loss: 0.008857
Average total loss: 0.042212
tensor(0.0532, device='cuda:0') tensor(0.1773, device='cuda:0') tensor(-3.1436e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.033441
Average KL loss: 0.008860
Average total loss: 0.042301
tensor(0.0533, device='cuda:0') tensor(0.1776, device='cuda:0') tensor(-2.0180e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.034535
Average KL loss: 0.008862
Average total loss: 0.043397
tensor(0.0533, device='cuda:0') tensor(0.1778, device='cuda:0') tensor(-2.6949e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.031670
Average KL loss: 0.008864
Average total loss: 0.040534
tensor(0.0533, device='cuda:0') tensor(0.1781, device='cuda:0') tensor(-3.3223e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.032002
Average KL loss: 0.008866
Average total loss: 0.040868
tensor(0.0533, device='cuda:0') tensor(0.1784, device='cuda:0') tensor(-1.9806e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.030985
Average KL loss: 0.008868
Average total loss: 0.039854
tensor(0.0533, device='cuda:0') tensor(0.1786, device='cuda:0') tensor(-2.1290e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.032189
Average KL loss: 0.008870
Average total loss: 0.041060
tensor(0.0533, device='cuda:0') tensor(0.1789, device='cuda:0') tensor(-2.2107e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.031571
Average KL loss: 0.008873
Average total loss: 0.040443
tensor(0.0533, device='cuda:0') tensor(0.1792, device='cuda:0') tensor(-1.9758e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.033304
Average KL loss: 0.008875
Average total loss: 0.042179
tensor(0.0534, device='cuda:0') tensor(0.1795, device='cuda:0') tensor(-1.7429e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.030905
Average KL loss: 0.008877
Average total loss: 0.039782
tensor(0.0534, device='cuda:0') tensor(0.1797, device='cuda:0') tensor(-2.6619e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.030305
Average KL loss: 0.008879
Average total loss: 0.039184
tensor(0.0534, device='cuda:0') tensor(0.1800, device='cuda:0') tensor(-1.6842e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.029673
Average KL loss: 0.008881
Average total loss: 0.038553
tensor(0.0534, device='cuda:0') tensor(0.1803, device='cuda:0') tensor(-2.0451e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.029975
Average KL loss: 0.008882
Average total loss: 0.038858
tensor(0.0534, device='cuda:0') tensor(0.1805, device='cuda:0') tensor(-1.3554e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.029922
Average KL loss: 0.008884
Average total loss: 0.038806
tensor(0.0534, device='cuda:0') tensor(0.1808, device='cuda:0') tensor(-2.1474e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.029360
Average KL loss: 0.008886
Average total loss: 0.038246
tensor(0.0535, device='cuda:0') tensor(0.1811, device='cuda:0') tensor(-2.2743e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.029117
Average KL loss: 0.008888
Average total loss: 0.038005
tensor(0.0535, device='cuda:0') tensor(0.1814, device='cuda:0') tensor(-1.3561e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.028537
Average KL loss: 0.008890
Average total loss: 0.037426
tensor(0.0535, device='cuda:0') tensor(0.1817, device='cuda:0') tensor(-2.1602e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.028717
Average KL loss: 0.008891
Average total loss: 0.037608
tensor(0.0535, device='cuda:0') tensor(0.1819, device='cuda:0') tensor(-2.4752e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.028511
Average KL loss: 0.008893
Average total loss: 0.037404
tensor(0.0535, device='cuda:0') tensor(0.1822, device='cuda:0') tensor(-1.9210e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.028020
Average KL loss: 0.008895
Average total loss: 0.036915
tensor(0.0535, device='cuda:0') tensor(0.1825, device='cuda:0') tensor(-2.1629e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.028531
Average KL loss: 0.008897
Average total loss: 0.037428
tensor(0.0535, device='cuda:0') tensor(0.1828, device='cuda:0') tensor(-1.5274e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.027202
Average KL loss: 0.008899
Average total loss: 0.036100
tensor(0.0536, device='cuda:0') tensor(0.1831, device='cuda:0') tensor(-1.6439e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.027592
Average KL loss: 0.008899
Average total loss: 0.036491
tensor(0.0536, device='cuda:0') tensor(0.1834, device='cuda:0') tensor(-1.6564e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.026803
Average KL loss: 0.008900
Average total loss: 0.035703
tensor(0.0536, device='cuda:0') tensor(0.1836, device='cuda:0') tensor(-1.4633e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.027383
Average KL loss: 0.008901
Average total loss: 0.036285
tensor(0.0536, device='cuda:0') tensor(0.1839, device='cuda:0') tensor(-1.2031e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.027287
Average KL loss: 0.008903
Average total loss: 0.036190
tensor(0.0536, device='cuda:0') tensor(0.1842, device='cuda:0') tensor(-1.0098e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.026174
Average KL loss: 0.008904
Average total loss: 0.035077
tensor(0.0536, device='cuda:0') tensor(0.1845, device='cuda:0') tensor(-1.5070e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.026093
Average KL loss: 0.008905
Average total loss: 0.034998
tensor(0.0536, device='cuda:0') tensor(0.1848, device='cuda:0') tensor(-1.5400e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.026435
Average KL loss: 0.008906
Average total loss: 0.035341
tensor(0.0537, device='cuda:0') tensor(0.1851, device='cuda:0') tensor(-1.7190e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.026449
Average KL loss: 0.008908
Average total loss: 0.035357
tensor(0.0537, device='cuda:0') tensor(0.1854, device='cuda:0') tensor(-1.4605e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.025887
Average KL loss: 0.008909
Average total loss: 0.034796
tensor(0.0537, device='cuda:0') tensor(0.1856, device='cuda:0') tensor(-1.0742e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.025213
Average KL loss: 0.008910
Average total loss: 0.034123
tensor(0.0537, device='cuda:0') tensor(0.1859, device='cuda:0') tensor(-1.3398e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.025219
Average KL loss: 0.008912
Average total loss: 0.034131
tensor(0.0537, device='cuda:0') tensor(0.1862, device='cuda:0') tensor(-1.4218e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.025419
Average KL loss: 0.008913
Average total loss: 0.034333
tensor(0.0537, device='cuda:0') tensor(0.1865, device='cuda:0') tensor(-1.0439e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.024847
Average KL loss: 0.008914
Average total loss: 0.033762
tensor(0.0537, device='cuda:0') tensor(0.1868, device='cuda:0') tensor(-9.4927e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.024770
Average KL loss: 0.008915
Average total loss: 0.033686
tensor(0.0537, device='cuda:0') tensor(0.1871, device='cuda:0') tensor(-7.7314e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.024467
Average KL loss: 0.008916
Average total loss: 0.033382
tensor(0.0538, device='cuda:0') tensor(0.1873, device='cuda:0') tensor(-1.2983e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.024073
Average KL loss: 0.008917
Average total loss: 0.032989
tensor(0.0538, device='cuda:0') tensor(0.1876, device='cuda:0') tensor(-1.1189e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.023880
Average KL loss: 0.008917
Average total loss: 0.032797
tensor(0.0538, device='cuda:0') tensor(0.1879, device='cuda:0') tensor(-1.0333e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.024110
Average KL loss: 0.008918
Average total loss: 0.033028
tensor(0.0538, device='cuda:0') tensor(0.1882, device='cuda:0') tensor(-1.0512e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.023626
Average KL loss: 0.008919
Average total loss: 0.032544
tensor(0.0538, device='cuda:0') tensor(0.1885, device='cuda:0') tensor(-8.6430e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.023963
Average KL loss: 0.008919
Average total loss: 0.032882
tensor(0.0538, device='cuda:0') tensor(0.1888, device='cuda:0') tensor(-1.6727e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.024243
Average KL loss: 0.008920
Average total loss: 0.033163
tensor(0.0538, device='cuda:0') tensor(0.1891, device='cuda:0') tensor(-1.5336e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.023495
Average KL loss: 0.008921
Average total loss: 0.032416
tensor(0.0538, device='cuda:0') tensor(0.1894, device='cuda:0') tensor(-9.4775e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.022823
Average KL loss: 0.008921
Average total loss: 0.031744
tensor(0.0539, device='cuda:0') tensor(0.1896, device='cuda:0') tensor(-1.4134e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.023166
Average KL loss: 0.008921
Average total loss: 0.032088
tensor(0.0539, device='cuda:0') tensor(0.1899, device='cuda:0') tensor(-1.0942e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.023226
Average KL loss: 0.008922
Average total loss: 0.032147
tensor(0.0539, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-1.2749e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.023172
Average KL loss: 0.008923
Average total loss: 0.032095
tensor(0.0539, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-6.4018e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.022942
Average KL loss: 0.008923
Average total loss: 0.031865
tensor(0.0539, device='cuda:0') tensor(0.1908, device='cuda:0') tensor(-1.0589e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.023099
Average KL loss: 0.008924
Average total loss: 0.032023
tensor(0.0539, device='cuda:0') tensor(0.1911, device='cuda:0') tensor(-1.0051e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.022435
Average KL loss: 0.008925
Average total loss: 0.031359
tensor(0.0539, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-4.9849e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.022110
Average KL loss: 0.008925
Average total loss: 0.031034
tensor(0.0539, device='cuda:0') tensor(0.1916, device='cuda:0') tensor(-1.2061e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.022122
Average KL loss: 0.008924
Average total loss: 0.031046
tensor(0.0539, device='cuda:0') tensor(0.1919, device='cuda:0') tensor(-1.3271e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.023084
Average KL loss: 0.008925
Average total loss: 0.032009
tensor(0.0540, device='cuda:0') tensor(0.1922, device='cuda:0') tensor(-1.2384e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.022384
Average KL loss: 0.008926
Average total loss: 0.031310
tensor(0.0540, device='cuda:0') tensor(0.1925, device='cuda:0') tensor(-7.4899e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.021944
Average KL loss: 0.008926
Average total loss: 0.030870
tensor(0.0540, device='cuda:0') tensor(0.1928, device='cuda:0') tensor(-1.1700e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.022153
Average KL loss: 0.008927
Average total loss: 0.031080
tensor(0.0540, device='cuda:0') tensor(0.1931, device='cuda:0') tensor(-1.0087e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.021714
Average KL loss: 0.008927
Average total loss: 0.030640
tensor(0.0540, device='cuda:0') tensor(0.1934, device='cuda:0') tensor(-1.2457e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.021828
Average KL loss: 0.008927
Average total loss: 0.030756
tensor(0.0540, device='cuda:0') tensor(0.1938, device='cuda:0') tensor(-1.0176e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.021449
Average KL loss: 0.008928
Average total loss: 0.030377
tensor(0.0540, device='cuda:0') tensor(0.1941, device='cuda:0') tensor(-1.0583e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.022090
Average KL loss: 0.008928
Average total loss: 0.031018
tensor(0.0540, device='cuda:0') tensor(0.1944, device='cuda:0') tensor(-1.0188e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.021057
Average KL loss: 0.008929
Average total loss: 0.029986
tensor(0.0540, device='cuda:0') tensor(0.1947, device='cuda:0') tensor(-5.4554e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.020650
Average KL loss: 0.008929
Average total loss: 0.029579
tensor(0.0541, device='cuda:0') tensor(0.1949, device='cuda:0') tensor(-1.1624e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.021280
Average KL loss: 0.008928
Average total loss: 0.030208
tensor(0.0541, device='cuda:0') tensor(0.1952, device='cuda:0') tensor(-1.2182e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.020631
Average KL loss: 0.008929
Average total loss: 0.029559
tensor(0.0541, device='cuda:0') tensor(0.1955, device='cuda:0') tensor(-5.9586e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.020488
Average KL loss: 0.008929
Average total loss: 0.029417
tensor(0.0541, device='cuda:0') tensor(0.1958, device='cuda:0') tensor(-5.5492e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.020776
Average KL loss: 0.008929
Average total loss: 0.029705
tensor(0.0541, device='cuda:0') tensor(0.1961, device='cuda:0') tensor(-7.6462e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.020146
Average KL loss: 0.008929
Average total loss: 0.029074
tensor(0.0541, device='cuda:0') tensor(0.1964, device='cuda:0') tensor(-7.6916e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.020303
Average KL loss: 0.008928
Average total loss: 0.029231
tensor(0.0541, device='cuda:0') tensor(0.1968, device='cuda:0') tensor(-1.1035e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.020245
Average KL loss: 0.008928
Average total loss: 0.029173
tensor(0.0541, device='cuda:0') tensor(0.1970, device='cuda:0') tensor(-8.9135e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.020157
Average KL loss: 0.008928
Average total loss: 0.029085
tensor(0.0541, device='cuda:0') tensor(0.1973, device='cuda:0') tensor(-7.3896e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.020252
Average KL loss: 0.008927
Average total loss: 0.029179
tensor(0.0541, device='cuda:0') tensor(0.1976, device='cuda:0') tensor(-7.1770e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.020014
Average KL loss: 0.008927
Average total loss: 0.028941
tensor(0.0541, device='cuda:0') tensor(0.1979, device='cuda:0') tensor(-7.4383e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.019803
Average KL loss: 0.008927
Average total loss: 0.028730
tensor(0.0542, device='cuda:0') tensor(0.1982, device='cuda:0') tensor(-9.5244e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.019730
Average KL loss: 0.008927
Average total loss: 0.028657
tensor(0.0542, device='cuda:0') tensor(0.1985, device='cuda:0') tensor(-6.5972e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.019745
Average KL loss: 0.008927
Average total loss: 0.028672
tensor(0.0542, device='cuda:0') tensor(0.1988, device='cuda:0') tensor(-7.7144e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.019144
Average KL loss: 0.008926
Average total loss: 0.028070
tensor(0.0542, device='cuda:0') tensor(0.1991, device='cuda:0') tensor(-7.7041e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.019755
Average KL loss: 0.008925
Average total loss: 0.028680
tensor(0.0542, device='cuda:0') tensor(0.1994, device='cuda:0') tensor(-5.3816e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.019389
Average KL loss: 0.008925
Average total loss: 0.028313
tensor(0.0542, device='cuda:0') tensor(0.1997, device='cuda:0') tensor(-8.8318e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.019386
Average KL loss: 0.008924
Average total loss: 0.028311
tensor(0.0542, device='cuda:0') tensor(0.2000, device='cuda:0') tensor(-5.1019e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.019137
Average KL loss: 0.008924
Average total loss: 0.028061
tensor(0.0542, device='cuda:0') tensor(0.2003, device='cuda:0') tensor(-5.4610e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.019367
Average KL loss: 0.008923
Average total loss: 0.028290
tensor(0.0542, device='cuda:0') tensor(0.2006, device='cuda:0') tensor(-8.7559e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.019355
Average KL loss: 0.008922
Average total loss: 0.028277
tensor(0.0542, device='cuda:0') tensor(0.2010, device='cuda:0') tensor(-1.0361e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.019299
Average KL loss: 0.008922
Average total loss: 0.028220
tensor(0.0542, device='cuda:0') tensor(0.2013, device='cuda:0') tensor(-7.6642e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.019168
Average KL loss: 0.008922
Average total loss: 0.028090
tensor(0.0542, device='cuda:0') tensor(0.2016, device='cuda:0') tensor(-8.1061e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.018939
Average KL loss: 0.008922
Average total loss: 0.027861
tensor(0.0542, device='cuda:0') tensor(0.2019, device='cuda:0') tensor(-8.6973e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.018964
Average KL loss: 0.008921
Average total loss: 0.027886
tensor(0.0543, device='cuda:0') tensor(0.2023, device='cuda:0') tensor(-7.7558e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.018619
Average KL loss: 0.008921
Average total loss: 0.027539
tensor(0.0543, device='cuda:0') tensor(0.2026, device='cuda:0') tensor(-4.4803e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.018272
Average KL loss: 0.008921
Average total loss: 0.027193
tensor(0.0543, device='cuda:0') tensor(0.2029, device='cuda:0') tensor(-3.2810e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.018317
Average KL loss: 0.008920
Average total loss: 0.027237
tensor(0.0543, device='cuda:0') tensor(0.2031, device='cuda:0') tensor(-5.2215e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.018340
Average KL loss: 0.008918
Average total loss: 0.027258
tensor(0.0543, device='cuda:0') tensor(0.2034, device='cuda:0') tensor(-4.8430e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.018276
Average KL loss: 0.008917
Average total loss: 0.027193
tensor(0.0543, device='cuda:0') tensor(0.2037, device='cuda:0') tensor(-5.6850e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.018696
Average KL loss: 0.008917
Average total loss: 0.027612
tensor(0.0543, device='cuda:0') tensor(0.2041, device='cuda:0') tensor(-4.2910e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.018749
Average KL loss: 0.008917
Average total loss: 0.027666
tensor(0.0543, device='cuda:0') tensor(0.2044, device='cuda:0') tensor(-7.7018e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.018170
Average KL loss: 0.008917
Average total loss: 0.027087
tensor(0.0543, device='cuda:0') tensor(0.2047, device='cuda:0') tensor(-3.9822e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.017971
Average KL loss: 0.008916
Average total loss: 0.026886
tensor(0.0543, device='cuda:0') tensor(0.2050, device='cuda:0') tensor(-5.4598e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.018171
Average KL loss: 0.008914
Average total loss: 0.027085
tensor(0.0543, device='cuda:0') tensor(0.2053, device='cuda:0') tensor(-8.1509e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.017833
Average KL loss: 0.008914
Average total loss: 0.026747
tensor(0.0543, device='cuda:0') tensor(0.2056, device='cuda:0') tensor(-6.4678e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.017975
Average KL loss: 0.008913
Average total loss: 0.026888
tensor(0.0543, device='cuda:0') tensor(0.2059, device='cuda:0') tensor(-6.4833e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.017673
Average KL loss: 0.008913
Average total loss: 0.026585
tensor(0.0543, device='cuda:0') tensor(0.2062, device='cuda:0') tensor(-2.8307e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.017898
Average KL loss: 0.008911
Average total loss: 0.026809
tensor(0.0544, device='cuda:0') tensor(0.2066, device='cuda:0') tensor(-4.5094e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.017655
Average KL loss: 0.008910
Average total loss: 0.026566
tensor(0.0544, device='cuda:0') tensor(0.2069, device='cuda:0') tensor(-4.7443e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.017811
Average KL loss: 0.008909
Average total loss: 0.026720
tensor(0.0544, device='cuda:0') tensor(0.2072, device='cuda:0') tensor(-4.6254e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.017393
Average KL loss: 0.008908
Average total loss: 0.026301
tensor(0.0544, device='cuda:0') tensor(0.2075, device='cuda:0') tensor(-3.9051e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.017766
Average KL loss: 0.008907
Average total loss: 0.026674
tensor(0.0544, device='cuda:0') tensor(0.2078, device='cuda:0') tensor(-3.6416e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.017339
Average KL loss: 0.008907
Average total loss: 0.026246
tensor(0.0544, device='cuda:0') tensor(0.2082, device='cuda:0') tensor(-3.5037e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.017373
Average KL loss: 0.008906
Average total loss: 0.026279
tensor(0.0544, device='cuda:0') tensor(0.2085, device='cuda:0') tensor(-4.0086e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.017467
Average KL loss: 0.008905
Average total loss: 0.026372
tensor(0.0544, device='cuda:0') tensor(0.2088, device='cuda:0') tensor(-4.6957e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.017231
Average KL loss: 0.008905
Average total loss: 0.026136
tensor(0.0544, device='cuda:0') tensor(0.2091, device='cuda:0') tensor(-3.3115e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.016827
Average KL loss: 0.008904
Average total loss: 0.025731
tensor(0.0544, device='cuda:0') tensor(0.2094, device='cuda:0') tensor(-2.6800e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.017165
Average KL loss: 0.008902
Average total loss: 0.026067
tensor(0.0544, device='cuda:0') tensor(0.2097, device='cuda:0') tensor(-3.4801e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.017071
Average KL loss: 0.008901
Average total loss: 0.025972
tensor(0.0544, device='cuda:0') tensor(0.2100, device='cuda:0') tensor(-4.1317e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.017111
Average KL loss: 0.008900
Average total loss: 0.026011
tensor(0.0544, device='cuda:0') tensor(0.2104, device='cuda:0') tensor(-4.0771e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.016869
Average KL loss: 0.008899
Average total loss: 0.025768
tensor(0.0544, device='cuda:0') tensor(0.2107, device='cuda:0') tensor(-4.1673e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.016890
Average KL loss: 0.008898
Average total loss: 0.025788
tensor(0.0544, device='cuda:0') tensor(0.2110, device='cuda:0') tensor(-3.5245e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.016659
Average KL loss: 0.008896
Average total loss: 0.025556
tensor(0.0544, device='cuda:0') tensor(0.2113, device='cuda:0') tensor(-3.6886e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.016451
Average KL loss: 0.008894
Average total loss: 0.025346
tensor(0.0544, device='cuda:0') tensor(0.2116, device='cuda:0') tensor(-3.0033e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.017092
Average KL loss: 0.008893
Average total loss: 0.025985
tensor(0.0545, device='cuda:0') tensor(0.2119, device='cuda:0') tensor(-1.1678e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.016394
Average KL loss: 0.008892
Average total loss: 0.025286
tensor(0.0545, device='cuda:0') tensor(0.2122, device='cuda:0') tensor(-3.1773e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.016755
Average KL loss: 0.008891
Average total loss: 0.025645
tensor(0.0545, device='cuda:0') tensor(0.2125, device='cuda:0') tensor(-1.8140e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.016690
Average KL loss: 0.008889
Average total loss: 0.025579
tensor(0.0545, device='cuda:0') tensor(0.2129, device='cuda:0') tensor(-1.7583e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.016259
Average KL loss: 0.008888
Average total loss: 0.025147
tensor(0.0545, device='cuda:0') tensor(0.2131, device='cuda:0') tensor(-3.3058e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.016444
Average KL loss: 0.008887
Average total loss: 0.025331
tensor(0.0545, device='cuda:0') tensor(0.2135, device='cuda:0') tensor(-2.7328e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.016402
Average KL loss: 0.008886
Average total loss: 0.025288
tensor(0.0545, device='cuda:0') tensor(0.2138, device='cuda:0') tensor(-3.1034e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.016285
Average KL loss: 0.008884
Average total loss: 0.025169
tensor(0.0545, device='cuda:0') tensor(0.2141, device='cuda:0') tensor(-5.4052e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.016442
Average KL loss: 0.008884
Average total loss: 0.025326
tensor(0.0545, device='cuda:0') tensor(0.2144, device='cuda:0') tensor(-3.5339e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.015972
Average KL loss: 0.008883
Average total loss: 0.024854
tensor(0.0545, device='cuda:0') tensor(0.2148, device='cuda:0') tensor(-2.9426e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.016319
Average KL loss: 0.008881
Average total loss: 0.025200
tensor(0.0545, device='cuda:0') tensor(0.2151, device='cuda:0') tensor(-2.8773e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.016167
Average KL loss: 0.008880
Average total loss: 0.025047
tensor(0.0545, device='cuda:0') tensor(0.2154, device='cuda:0') tensor(-2.3687e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.016337
Average KL loss: 0.008879
Average total loss: 0.025217
tensor(0.0545, device='cuda:0') tensor(0.2157, device='cuda:0') tensor(-6.3514e-11, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.016114
Average KL loss: 0.008878
Average total loss: 0.024991
tensor(0.0545, device='cuda:0') tensor(0.2160, device='cuda:0') tensor(-2.3497e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.015681
Average KL loss: 0.008876
Average total loss: 0.024557
tensor(0.0545, device='cuda:0') tensor(0.2163, device='cuda:0') tensor(-4.8774e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.015999
Average KL loss: 0.008874
Average total loss: 0.024873
tensor(0.0545, device='cuda:0') tensor(0.2166, device='cuda:0') tensor(-3.0431e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.015766
Average KL loss: 0.008873
Average total loss: 0.024638
tensor(0.0545, device='cuda:0') tensor(0.2170, device='cuda:0') tensor(-3.0064e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.015788
Average KL loss: 0.008871
Average total loss: 0.024659
tensor(0.0545, device='cuda:0') tensor(0.2173, device='cuda:0') tensor(-2.0541e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.015864
Average KL loss: 0.008869
Average total loss: 0.024734
tensor(0.0545, device='cuda:0') tensor(0.2176, device='cuda:0') tensor(-2.9994e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.015926
Average KL loss: 0.008868
Average total loss: 0.024794
tensor(0.0545, device='cuda:0') tensor(0.2179, device='cuda:0') tensor(-3.2342e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.016245
Average KL loss: 0.008867
Average total loss: 0.025112
tensor(0.0545, device='cuda:0') tensor(0.2182, device='cuda:0') tensor(-2.3741e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.015436
Average KL loss: 0.008867
Average total loss: 0.024302
tensor(0.0545, device='cuda:0') tensor(0.2186, device='cuda:0') tensor(-2.4955e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.015434
Average KL loss: 0.008865
Average total loss: 0.024298
tensor(0.0545, device='cuda:0') tensor(0.2189, device='cuda:0') tensor(-3.7565e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.015939
Average KL loss: 0.008863
Average total loss: 0.024802
tensor(0.0545, device='cuda:0') tensor(0.2192, device='cuda:0') tensor(-2.5406e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.015673
Average KL loss: 0.008862
Average total loss: 0.024535
tensor(0.0546, device='cuda:0') tensor(0.2195, device='cuda:0') tensor(-3.4887e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.015445
Average KL loss: 0.008861
Average total loss: 0.024306
tensor(0.0546, device='cuda:0') tensor(0.2198, device='cuda:0') tensor(-2.6853e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.015705
Average KL loss: 0.008859
Average total loss: 0.024565
tensor(0.0546, device='cuda:0') tensor(0.2202, device='cuda:0') tensor(-3.0185e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.015716
Average KL loss: 0.008859
Average total loss: 0.024574
tensor(0.0546, device='cuda:0') tensor(0.2205, device='cuda:0') tensor(-2.1762e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.015511
Average KL loss: 0.008857
Average total loss: 0.024368
tensor(0.0546, device='cuda:0') tensor(0.2208, device='cuda:0') tensor(-2.9981e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.015378
Average KL loss: 0.008856
Average total loss: 0.024234
 Percentile value: 4.7629820823669435
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/8]: ---
conv1.weight         | nonzeros =     177 /    1728             ( 10.24%) | total_pruned =    1551 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
bn1.bias             | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     188 /   36864             (  0.51%) | total_pruned =   36676 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     212 /   36864             (  0.58%) | total_pruned =   36652 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     263 /   36864             (  0.71%) | total_pruned =   36601 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     361 /   36864             (  0.98%) | total_pruned =   36503 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1566 /   73728             (  2.12%) | total_pruned =   72162 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3763 /  147456             (  2.55%) | total_pruned =  143693 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     565 /    8192             (  6.90%) | total_pruned =    7627 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2646 /  147456             (  1.79%) | total_pruned =  144810 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2624 /  147456             (  1.78%) | total_pruned =  144832 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   10029 /  294912             (  3.40%) | total_pruned =  284883 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      74 /     256             ( 28.91%) | total_pruned =     182 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   12564 /  589824             (  2.13%) | total_pruned =  577260 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1512 /   32768             (  4.61%) | total_pruned =   31256 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6340 /  589824             (  1.07%) | total_pruned =  583484 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     161 /     256             ( 62.89%) | total_pruned =      95 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    5031 /  589824             (  0.85%) | total_pruned =  584793 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      98 /     256             ( 38.28%) | total_pruned =     158 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12623 / 1179648             (  1.07%) | total_pruned = 1167025 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     318 /     512             ( 62.11%) | total_pruned =     194 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    9763 / 2359296             (  0.41%) | total_pruned = 2349533 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     302 /     512             ( 58.98%) | total_pruned =     210 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     277 /     512             ( 54.10%) | total_pruned =     235 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     248 /  131072             (  0.19%) | total_pruned =  130824 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     277 /     512             ( 54.10%) | total_pruned =     235 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    6377 / 2359296             (  0.27%) | total_pruned = 2352919 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     126 /     512             ( 24.61%) | total_pruned =     386 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    7734 / 2359296             (  0.33%) | total_pruned = 2351562 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     367 /     512             ( 71.68%) | total_pruned =     145 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     270 /     512             ( 52.73%) | total_pruned =     242 | shape = torch.Size([512])
linear.weight        | nonzeros =    2097 /    5120             ( 40.96%) | total_pruned =    3023 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 67/100 Loss: 0.038839 Accuracy: 83.46 99.99 % Best test Accuracy: 84.74%
tensor(0.0546, device='cuda:0') tensor(0.2211, device='cuda:0') tensor(-1.2891e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.037574
Average KL loss: 0.008515
Average total loss: 0.046090
tensor(0.0512, device='cuda:0') tensor(0.2060, device='cuda:0') tensor(-2.5901e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.038326
Average KL loss: 0.007871
Average total loss: 0.046197
tensor(0.0483, device='cuda:0') tensor(0.1948, device='cuda:0') tensor(-1.5320e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.036575
Average KL loss: 0.007270
Average total loss: 0.043845
tensor(0.0455, device='cuda:0') tensor(0.1857, device='cuda:0') tensor(-1.5702e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.036099
Average KL loss: 0.006714
Average total loss: 0.042813
tensor(0.0429, device='cuda:0') tensor(0.1783, device='cuda:0') tensor(-1.4001e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.035174
Average KL loss: 0.006224
Average total loss: 0.041399
tensor(0.0406, device='cuda:0') tensor(0.1726, device='cuda:0') tensor(-1.6557e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.035918
Average KL loss: 0.005825
Average total loss: 0.041742
tensor(0.0386, device='cuda:0') tensor(0.1685, device='cuda:0') tensor(-2.2579e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.034621
Average KL loss: 0.005527
Average total loss: 0.040148
tensor(0.0370, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(-1.7297e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.035025
Average KL loss: 0.005323
Average total loss: 0.040348
tensor(0.0358, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(-1.8530e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.034624
Average KL loss: 0.005188
Average total loss: 0.039812
tensor(0.0348, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(-1.5928e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.033811
Average KL loss: 0.005097
Average total loss: 0.038908
tensor(0.0341, device='cuda:0') tensor(0.1612, device='cuda:0') tensor(-1.3025e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.033776
Average KL loss: 0.005033
Average total loss: 0.038809
tensor(0.0336, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(-1.4760e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.033069
Average KL loss: 0.004985
Average total loss: 0.038054
tensor(0.0333, device='cuda:0') tensor(0.1598, device='cuda:0') tensor(-1.9603e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.033606
Average KL loss: 0.004948
Average total loss: 0.038554
tensor(0.0330, device='cuda:0') tensor(0.1594, device='cuda:0') tensor(-1.5289e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.032758
Average KL loss: 0.004919
Average total loss: 0.037677
tensor(0.0328, device='cuda:0') tensor(0.1591, device='cuda:0') tensor(-1.9698e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.034208
Average KL loss: 0.004896
Average total loss: 0.039104
tensor(0.0326, device='cuda:0') tensor(0.1588, device='cuda:0') tensor(-2.2018e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.033054
Average KL loss: 0.004876
Average total loss: 0.037929
tensor(0.0325, device='cuda:0') tensor(0.1586, device='cuda:0') tensor(-1.3213e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.032432
Average KL loss: 0.004859
Average total loss: 0.037292
tensor(0.0324, device='cuda:0') tensor(0.1585, device='cuda:0') tensor(-9.7881e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.031276
Average KL loss: 0.004845
Average total loss: 0.036120
tensor(0.0323, device='cuda:0') tensor(0.1584, device='cuda:0') tensor(-1.4032e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.033389
Average KL loss: 0.004832
Average total loss: 0.038221
tensor(0.0323, device='cuda:0') tensor(0.1583, device='cuda:0') tensor(-9.7204e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.031183
Average KL loss: 0.004822
Average total loss: 0.036004
tensor(0.0322, device='cuda:0') tensor(0.1583, device='cuda:0') tensor(-1.3141e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.030854
Average KL loss: 0.004812
Average total loss: 0.035665
tensor(0.0322, device='cuda:0') tensor(0.1583, device='cuda:0') tensor(-1.2105e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.030220
Average KL loss: 0.004803
Average total loss: 0.035022
tensor(0.0321, device='cuda:0') tensor(0.1583, device='cuda:0') tensor(-1.3389e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.031062
Average KL loss: 0.004795
Average total loss: 0.035857
tensor(0.0321, device='cuda:0') tensor(0.1584, device='cuda:0') tensor(-1.2234e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.031023
Average KL loss: 0.004788
Average total loss: 0.035811
tensor(0.0321, device='cuda:0') tensor(0.1585, device='cuda:0') tensor(-1.5306e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.029706
Average KL loss: 0.004782
Average total loss: 0.034488
tensor(0.0321, device='cuda:0') tensor(0.1585, device='cuda:0') tensor(-1.1036e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.031269
Average KL loss: 0.004776
Average total loss: 0.036045
tensor(0.0321, device='cuda:0') tensor(0.1586, device='cuda:0') tensor(-9.1712e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.029690
Average KL loss: 0.004771
Average total loss: 0.034460
tensor(0.0321, device='cuda:0') tensor(0.1588, device='cuda:0') tensor(-1.0656e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.028944
Average KL loss: 0.004765
Average total loss: 0.033709
tensor(0.0321, device='cuda:0') tensor(0.1589, device='cuda:0') tensor(-1.3554e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.029873
Average KL loss: 0.004760
Average total loss: 0.034633
tensor(0.0320, device='cuda:0') tensor(0.1590, device='cuda:0') tensor(-1.1689e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.028710
Average KL loss: 0.004755
Average total loss: 0.033466
tensor(0.0320, device='cuda:0') tensor(0.1591, device='cuda:0') tensor(-1.1320e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.028531
Average KL loss: 0.004751
Average total loss: 0.033282
tensor(0.0320, device='cuda:0') tensor(0.1593, device='cuda:0') tensor(-8.9419e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.028219
Average KL loss: 0.004747
Average total loss: 0.032966
tensor(0.0320, device='cuda:0') tensor(0.1594, device='cuda:0') tensor(-1.2919e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.028838
Average KL loss: 0.004743
Average total loss: 0.033580
tensor(0.0320, device='cuda:0') tensor(0.1596, device='cuda:0') tensor(-1.2473e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.028624
Average KL loss: 0.004739
Average total loss: 0.033363
tensor(0.0320, device='cuda:0') tensor(0.1597, device='cuda:0') tensor(-6.9377e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.029452
Average KL loss: 0.004735
Average total loss: 0.034188
tensor(0.0320, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-1.1436e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.028166
Average KL loss: 0.004732
Average total loss: 0.032898
tensor(0.0320, device='cuda:0') tensor(0.1601, device='cuda:0') tensor(-1.0913e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.027995
Average KL loss: 0.004729
Average total loss: 0.032724
tensor(0.0320, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-1.1355e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.028191
Average KL loss: 0.004726
Average total loss: 0.032917
tensor(0.0320, device='cuda:0') tensor(0.1604, device='cuda:0') tensor(-1.5905e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.027700
Average KL loss: 0.004723
Average total loss: 0.032423
tensor(0.0320, device='cuda:0') tensor(0.1606, device='cuda:0') tensor(-9.3822e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.027689
Average KL loss: 0.004720
Average total loss: 0.032409
tensor(0.0321, device='cuda:0') tensor(0.1608, device='cuda:0') tensor(-9.0139e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.027422
Average KL loss: 0.004717
Average total loss: 0.032139
tensor(0.0321, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(-6.8576e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.027000
Average KL loss: 0.004714
Average total loss: 0.031715
tensor(0.0321, device='cuda:0') tensor(0.1612, device='cuda:0') tensor(-1.0075e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.027030
Average KL loss: 0.004712
Average total loss: 0.031742
tensor(0.0321, device='cuda:0') tensor(0.1614, device='cuda:0') tensor(-7.6382e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.027040
Average KL loss: 0.004709
Average total loss: 0.031750
tensor(0.0321, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(-1.0291e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.027629
Average KL loss: 0.004707
Average total loss: 0.032336
tensor(0.0321, device='cuda:0') tensor(0.1618, device='cuda:0') tensor(-8.0439e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.026770
Average KL loss: 0.004704
Average total loss: 0.031474
tensor(0.0321, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-6.0963e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.026497
Average KL loss: 0.004701
Average total loss: 0.031198
tensor(0.0321, device='cuda:0') tensor(0.1622, device='cuda:0') tensor(-8.8956e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.026740
Average KL loss: 0.004699
Average total loss: 0.031439
tensor(0.0321, device='cuda:0') tensor(0.1624, device='cuda:0') tensor(-1.1968e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.026834
Average KL loss: 0.004696
Average total loss: 0.031530
tensor(0.0321, device='cuda:0') tensor(0.1627, device='cuda:0') tensor(-7.3201e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.026852
Average KL loss: 0.004694
Average total loss: 0.031546
tensor(0.0321, device='cuda:0') tensor(0.1629, device='cuda:0') tensor(-9.1614e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.026530
Average KL loss: 0.004692
Average total loss: 0.031222
tensor(0.0321, device='cuda:0') tensor(0.1631, device='cuda:0') tensor(-8.9646e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.026563
Average KL loss: 0.004690
Average total loss: 0.031252
tensor(0.0322, device='cuda:0') tensor(0.1633, device='cuda:0') tensor(-6.5931e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.026228
Average KL loss: 0.004688
Average total loss: 0.030916
tensor(0.0322, device='cuda:0') tensor(0.1636, device='cuda:0') tensor(-4.9028e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.025289
Average KL loss: 0.004686
Average total loss: 0.029975
tensor(0.0322, device='cuda:0') tensor(0.1638, device='cuda:0') tensor(-7.6114e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.025981
Average KL loss: 0.004684
Average total loss: 0.030665
tensor(0.0322, device='cuda:0') tensor(0.1641, device='cuda:0') tensor(-7.8105e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.025653
Average KL loss: 0.004683
Average total loss: 0.030336
tensor(0.0322, device='cuda:0') tensor(0.1643, device='cuda:0') tensor(-9.3452e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.025878
Average KL loss: 0.004681
Average total loss: 0.030559
tensor(0.0322, device='cuda:0') tensor(0.1645, device='cuda:0') tensor(-4.3871e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.026088
Average KL loss: 0.004679
Average total loss: 0.030767
tensor(0.0322, device='cuda:0') tensor(0.1648, device='cuda:0') tensor(-4.1915e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.025574
Average KL loss: 0.004677
Average total loss: 0.030250
tensor(0.0323, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-6.0399e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.025145
Average KL loss: 0.004675
Average total loss: 0.029820
tensor(0.0323, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-6.4341e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.025080
Average KL loss: 0.004673
Average total loss: 0.029753
tensor(0.0323, device='cuda:0') tensor(0.1655, device='cuda:0') tensor(-4.5918e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.025426
Average KL loss: 0.004671
Average total loss: 0.030097
tensor(0.0323, device='cuda:0') tensor(0.1657, device='cuda:0') tensor(-4.3368e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.025097
Average KL loss: 0.004669
Average total loss: 0.029766
tensor(0.0323, device='cuda:0') tensor(0.1659, device='cuda:0') tensor(-3.9267e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.025608
Average KL loss: 0.004668
Average total loss: 0.030275
tensor(0.0323, device='cuda:0') tensor(0.1662, device='cuda:0') tensor(-6.9739e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.024868
Average KL loss: 0.004666
Average total loss: 0.029534
tensor(0.0323, device='cuda:0') tensor(0.1664, device='cuda:0') tensor(-5.2008e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.025011
Average KL loss: 0.004665
Average total loss: 0.029676
tensor(0.0323, device='cuda:0') tensor(0.1667, device='cuda:0') tensor(-9.0120e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.025133
Average KL loss: 0.004663
Average total loss: 0.029796
tensor(0.0324, device='cuda:0') tensor(0.1669, device='cuda:0') tensor(-4.5250e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.024629
Average KL loss: 0.004661
Average total loss: 0.029290
tensor(0.0324, device='cuda:0') tensor(0.1672, device='cuda:0') tensor(-7.2047e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.024627
Average KL loss: 0.004660
Average total loss: 0.029286
tensor(0.0324, device='cuda:0') tensor(0.1674, device='cuda:0') tensor(-5.4549e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.024497
Average KL loss: 0.004658
Average total loss: 0.029156
tensor(0.0324, device='cuda:0') tensor(0.1677, device='cuda:0') tensor(-7.0908e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.024675
Average KL loss: 0.004657
Average total loss: 0.029331
tensor(0.0324, device='cuda:0') tensor(0.1679, device='cuda:0') tensor(-4.7624e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.024363
Average KL loss: 0.004655
Average total loss: 0.029018
tensor(0.0324, device='cuda:0') tensor(0.1682, device='cuda:0') tensor(-5.2108e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.024591
Average KL loss: 0.004653
Average total loss: 0.029245
tensor(0.0324, device='cuda:0') tensor(0.1684, device='cuda:0') tensor(-2.7151e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.024915
Average KL loss: 0.004652
Average total loss: 0.029567
tensor(0.0325, device='cuda:0') tensor(0.1687, device='cuda:0') tensor(-4.5513e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.024569
Average KL loss: 0.004651
Average total loss: 0.029219
tensor(0.0325, device='cuda:0') tensor(0.1689, device='cuda:0') tensor(-7.5201e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.024249
Average KL loss: 0.004649
Average total loss: 0.028898
tensor(0.0325, device='cuda:0') tensor(0.1692, device='cuda:0') tensor(-5.2976e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.024848
Average KL loss: 0.004648
Average total loss: 0.029496
tensor(0.0325, device='cuda:0') tensor(0.1695, device='cuda:0') tensor(-5.9680e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.023843
Average KL loss: 0.004646
Average total loss: 0.028489
tensor(0.0325, device='cuda:0') tensor(0.1697, device='cuda:0') tensor(-4.6235e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.024205
Average KL loss: 0.004644
Average total loss: 0.028850
tensor(0.0325, device='cuda:0') tensor(0.1700, device='cuda:0') tensor(-8.0331e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.024017
Average KL loss: 0.004643
Average total loss: 0.028660
tensor(0.0326, device='cuda:0') tensor(0.1703, device='cuda:0') tensor(-4.3769e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.024575
Average KL loss: 0.004642
Average total loss: 0.029217
tensor(0.0326, device='cuda:0') tensor(0.1705, device='cuda:0') tensor(-3.5243e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.023719
Average KL loss: 0.004640
Average total loss: 0.028359
tensor(0.0326, device='cuda:0') tensor(0.1708, device='cuda:0') tensor(-3.7828e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.023915
Average KL loss: 0.004639
Average total loss: 0.028554
tensor(0.0326, device='cuda:0') tensor(0.1710, device='cuda:0') tensor(-2.8360e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.023383
Average KL loss: 0.004637
Average total loss: 0.028020
tensor(0.0326, device='cuda:0') tensor(0.1713, device='cuda:0') tensor(-8.4268e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.023979
Average KL loss: 0.004636
Average total loss: 0.028615
tensor(0.0326, device='cuda:0') tensor(0.1716, device='cuda:0') tensor(-5.0572e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.023721
Average KL loss: 0.004634
Average total loss: 0.028355
tensor(0.0327, device='cuda:0') tensor(0.1718, device='cuda:0') tensor(-3.8351e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.024152
Average KL loss: 0.004633
Average total loss: 0.028785
tensor(0.0327, device='cuda:0') tensor(0.1721, device='cuda:0') tensor(-2.7928e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.023959
Average KL loss: 0.004632
Average total loss: 0.028591
tensor(0.0327, device='cuda:0') tensor(0.1724, device='cuda:0') tensor(-3.9897e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.024246
Average KL loss: 0.004630
Average total loss: 0.028876
tensor(0.0327, device='cuda:0') tensor(0.1727, device='cuda:0') tensor(-5.4016e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.023467
Average KL loss: 0.004629
Average total loss: 0.028096
tensor(0.0327, device='cuda:0') tensor(0.1729, device='cuda:0') tensor(-7.0292e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.025019
Average KL loss: 0.004628
Average total loss: 0.029647
tensor(0.0327, device='cuda:0') tensor(0.1732, device='cuda:0') tensor(-1.8393e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.022862
Average KL loss: 0.004626
Average total loss: 0.027488
tensor(0.0328, device='cuda:0') tensor(0.1735, device='cuda:0') tensor(-4.3177e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.023315
Average KL loss: 0.004625
Average total loss: 0.027940
tensor(0.0328, device='cuda:0') tensor(0.1738, device='cuda:0') tensor(-3.4563e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.023491
Average KL loss: 0.004624
Average total loss: 0.028114
tensor(0.0328, device='cuda:0') tensor(0.1740, device='cuda:0') tensor(-2.8653e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.023436
Average KL loss: 0.004622
Average total loss: 0.028059
tensor(0.0328, device='cuda:0') tensor(0.1743, device='cuda:0') tensor(-4.5192e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.023257
Average KL loss: 0.004621
Average total loss: 0.027878
tensor(0.0328, device='cuda:0') tensor(0.1746, device='cuda:0') tensor(-3.0842e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.023313
Average KL loss: 0.004620
Average total loss: 0.027933
tensor(0.0329, device='cuda:0') tensor(0.1749, device='cuda:0') tensor(-2.8058e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.023212
Average KL loss: 0.004618
Average total loss: 0.027831
tensor(0.0329, device='cuda:0') tensor(0.1752, device='cuda:0') tensor(-3.7788e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.023339
Average KL loss: 0.004617
Average total loss: 0.027956
tensor(0.0329, device='cuda:0') tensor(0.1754, device='cuda:0') tensor(-2.3317e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.022949
Average KL loss: 0.004616
Average total loss: 0.027565
tensor(0.0329, device='cuda:0') tensor(0.1757, device='cuda:0') tensor(-4.2247e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.022924
Average KL loss: 0.004614
Average total loss: 0.027538
tensor(0.0329, device='cuda:0') tensor(0.1760, device='cuda:0') tensor(-1.9015e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.022991
Average KL loss: 0.004613
Average total loss: 0.027604
tensor(0.0329, device='cuda:0') tensor(0.1763, device='cuda:0') tensor(-3.6839e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.022806
Average KL loss: 0.004612
Average total loss: 0.027417
tensor(0.0330, device='cuda:0') tensor(0.1765, device='cuda:0') tensor(-3.6238e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.022674
Average KL loss: 0.004611
Average total loss: 0.027285
tensor(0.0330, device='cuda:0') tensor(0.1768, device='cuda:0') tensor(-4.3105e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.023114
Average KL loss: 0.004609
Average total loss: 0.027723
tensor(0.0330, device='cuda:0') tensor(0.1771, device='cuda:0') tensor(-1.6477e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.023067
Average KL loss: 0.004608
Average total loss: 0.027676
tensor(0.0330, device='cuda:0') tensor(0.1774, device='cuda:0') tensor(-4.6362e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.022812
Average KL loss: 0.004607
Average total loss: 0.027419
tensor(0.0330, device='cuda:0') tensor(0.1777, device='cuda:0') tensor(-3.1486e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.022708
Average KL loss: 0.004606
Average total loss: 0.027314
tensor(0.0330, device='cuda:0') tensor(0.1780, device='cuda:0') tensor(-1.2928e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.023206
Average KL loss: 0.004605
Average total loss: 0.027810
tensor(0.0331, device='cuda:0') tensor(0.1783, device='cuda:0') tensor(-3.6132e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.022358
Average KL loss: 0.004604
Average total loss: 0.026961
tensor(0.0331, device='cuda:0') tensor(0.1786, device='cuda:0') tensor(-3.5212e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.022138
Average KL loss: 0.004603
Average total loss: 0.026741
tensor(0.0331, device='cuda:0') tensor(0.1789, device='cuda:0') tensor(-3.7273e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.022187
Average KL loss: 0.004601
Average total loss: 0.026788
tensor(0.0331, device='cuda:0') tensor(0.1791, device='cuda:0') tensor(-2.8345e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.022542
Average KL loss: 0.004600
Average total loss: 0.027142
tensor(0.0331, device='cuda:0') tensor(0.1794, device='cuda:0') tensor(-3.9932e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.022106
Average KL loss: 0.004599
Average total loss: 0.026705
tensor(0.0332, device='cuda:0') tensor(0.1797, device='cuda:0') tensor(-2.5435e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.022562
Average KL loss: 0.004598
Average total loss: 0.027160
tensor(0.0332, device='cuda:0') tensor(0.1800, device='cuda:0') tensor(-3.6824e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.022664
Average KL loss: 0.004597
Average total loss: 0.027261
tensor(0.0332, device='cuda:0') tensor(0.1803, device='cuda:0') tensor(-2.8593e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.022194
Average KL loss: 0.004596
Average total loss: 0.026790
tensor(0.0332, device='cuda:0') tensor(0.1806, device='cuda:0') tensor(-3.3258e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.022319
Average KL loss: 0.004595
Average total loss: 0.026914
tensor(0.0332, device='cuda:0') tensor(0.1809, device='cuda:0') tensor(-2.4859e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.022222
Average KL loss: 0.004594
Average total loss: 0.026816
tensor(0.0333, device='cuda:0') tensor(0.1812, device='cuda:0') tensor(-2.7833e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.021955
Average KL loss: 0.004593
Average total loss: 0.026548
tensor(0.0333, device='cuda:0') tensor(0.1814, device='cuda:0') tensor(-3.0690e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.022021
Average KL loss: 0.004592
Average total loss: 0.026613
tensor(0.0333, device='cuda:0') tensor(0.1817, device='cuda:0') tensor(-3.9115e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.022485
Average KL loss: 0.004591
Average total loss: 0.027076
tensor(0.0333, device='cuda:0') tensor(0.1820, device='cuda:0') tensor(-4.4777e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.022087
Average KL loss: 0.004590
Average total loss: 0.026677
tensor(0.0333, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(-3.7508e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.022199
Average KL loss: 0.004589
Average total loss: 0.026788
tensor(0.0333, device='cuda:0') tensor(0.1826, device='cuda:0') tensor(-4.1721e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.022251
Average KL loss: 0.004588
Average total loss: 0.026839
tensor(0.0334, device='cuda:0') tensor(0.1829, device='cuda:0') tensor(-2.6301e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.021875
Average KL loss: 0.004587
Average total loss: 0.026461
tensor(0.0334, device='cuda:0') tensor(0.1832, device='cuda:0') tensor(-3.3195e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.021893
Average KL loss: 0.004586
Average total loss: 0.026479
tensor(0.0334, device='cuda:0') tensor(0.1835, device='cuda:0') tensor(-2.0190e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.021650
Average KL loss: 0.004585
Average total loss: 0.026235
tensor(0.0334, device='cuda:0') tensor(0.1838, device='cuda:0') tensor(-3.2494e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.022034
Average KL loss: 0.004584
Average total loss: 0.026618
tensor(0.0334, device='cuda:0') tensor(0.1841, device='cuda:0') tensor(-2.5321e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.021835
Average KL loss: 0.004583
Average total loss: 0.026418
tensor(0.0335, device='cuda:0') tensor(0.1843, device='cuda:0') tensor(-3.7388e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.021557
Average KL loss: 0.004582
Average total loss: 0.026139
tensor(0.0335, device='cuda:0') tensor(0.1846, device='cuda:0') tensor(-1.9399e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.021565
Average KL loss: 0.004581
Average total loss: 0.026146
tensor(0.0335, device='cuda:0') tensor(0.1849, device='cuda:0') tensor(-3.3675e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.021786
Average KL loss: 0.004580
Average total loss: 0.026366
tensor(0.0335, device='cuda:0') tensor(0.1852, device='cuda:0') tensor(-2.8096e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.021482
Average KL loss: 0.004579
Average total loss: 0.026061
tensor(0.0335, device='cuda:0') tensor(0.1855, device='cuda:0') tensor(-2.6642e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.021806
Average KL loss: 0.004578
Average total loss: 0.026384
tensor(0.0336, device='cuda:0') tensor(0.1858, device='cuda:0') tensor(-2.4544e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.021698
Average KL loss: 0.004577
Average total loss: 0.026276
tensor(0.0336, device='cuda:0') tensor(0.1861, device='cuda:0') tensor(-1.2268e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.021651
Average KL loss: 0.004576
Average total loss: 0.026227
tensor(0.0336, device='cuda:0') tensor(0.1864, device='cuda:0') tensor(-1.7556e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.023764
Average KL loss: 0.004576
Average total loss: 0.028340
tensor(0.0336, device='cuda:0') tensor(0.1867, device='cuda:0') tensor(-2.1591e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.021842
Average KL loss: 0.004575
Average total loss: 0.026417
tensor(0.0336, device='cuda:0') tensor(0.1870, device='cuda:0') tensor(-5.0865e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.021620
Average KL loss: 0.004574
Average total loss: 0.026194
tensor(0.0336, device='cuda:0') tensor(0.1873, device='cuda:0') tensor(-3.0069e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.021781
Average KL loss: 0.004573
Average total loss: 0.026354
tensor(0.0337, device='cuda:0') tensor(0.1876, device='cuda:0') tensor(-2.3613e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.021367
Average KL loss: 0.004572
Average total loss: 0.025939
tensor(0.0337, device='cuda:0') tensor(0.1879, device='cuda:0') tensor(-2.3272e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.021663
Average KL loss: 0.004571
Average total loss: 0.026234
tensor(0.0337, device='cuda:0') tensor(0.1882, device='cuda:0') tensor(-4.3098e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.021581
Average KL loss: 0.004570
Average total loss: 0.026151
tensor(0.0337, device='cuda:0') tensor(0.1885, device='cuda:0') tensor(-3.1980e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.021555
Average KL loss: 0.004569
Average total loss: 0.026125
tensor(0.0337, device='cuda:0') tensor(0.1887, device='cuda:0') tensor(-3.1044e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.021644
Average KL loss: 0.004569
Average total loss: 0.026213
tensor(0.0338, device='cuda:0') tensor(0.1890, device='cuda:0') tensor(-2.3244e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.021377
Average KL loss: 0.004568
Average total loss: 0.025945
tensor(0.0338, device='cuda:0') tensor(0.1893, device='cuda:0') tensor(-2.8712e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.021244
Average KL loss: 0.004567
Average total loss: 0.025811
tensor(0.0338, device='cuda:0') tensor(0.1896, device='cuda:0') tensor(-2.8216e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.021159
Average KL loss: 0.004566
Average total loss: 0.025725
tensor(0.0338, device='cuda:0') tensor(0.1899, device='cuda:0') tensor(-1.5411e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.021121
Average KL loss: 0.004565
Average total loss: 0.025686
tensor(0.0338, device='cuda:0') tensor(0.1902, device='cuda:0') tensor(-4.8549e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.021427
Average KL loss: 0.004564
Average total loss: 0.025992
tensor(0.0339, device='cuda:0') tensor(0.1905, device='cuda:0') tensor(-6.5041e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.020969
Average KL loss: 0.004564
Average total loss: 0.025532
tensor(0.0339, device='cuda:0') tensor(0.1908, device='cuda:0') tensor(-1.6201e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.021350
Average KL loss: 0.004563
Average total loss: 0.025913
tensor(0.0339, device='cuda:0') tensor(0.1911, device='cuda:0') tensor(-1.9529e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.020960
Average KL loss: 0.004562
Average total loss: 0.025522
tensor(0.0339, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-9.5513e-11, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.020991
Average KL loss: 0.004561
Average total loss: 0.025553
tensor(0.0339, device='cuda:0') tensor(0.1917, device='cuda:0') tensor(-2.2519e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.021131
Average KL loss: 0.004561
Average total loss: 0.025691
tensor(0.0339, device='cuda:0') tensor(0.1919, device='cuda:0') tensor(-2.2163e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.020961
Average KL loss: 0.004560
Average total loss: 0.025521
tensor(0.0340, device='cuda:0') tensor(0.1922, device='cuda:0') tensor(-1.2400e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.021488
Average KL loss: 0.004559
Average total loss: 0.026048
tensor(0.0340, device='cuda:0') tensor(0.1925, device='cuda:0') tensor(-1.1331e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.020852
Average KL loss: 0.004559
Average total loss: 0.025411
tensor(0.0340, device='cuda:0') tensor(0.1928, device='cuda:0') tensor(-1.7290e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.020774
Average KL loss: 0.004558
Average total loss: 0.025332
tensor(0.0340, device='cuda:0') tensor(0.1931, device='cuda:0') tensor(-1.6143e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.021223
Average KL loss: 0.004557
Average total loss: 0.025780
tensor(0.0340, device='cuda:0') tensor(0.1934, device='cuda:0') tensor(-2.0459e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.021113
Average KL loss: 0.004557
Average total loss: 0.025670
tensor(0.0341, device='cuda:0') tensor(0.1937, device='cuda:0') tensor(-2.5873e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.020905
Average KL loss: 0.004556
Average total loss: 0.025461
tensor(0.0341, device='cuda:0') tensor(0.1940, device='cuda:0') tensor(-1.8983e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.021663
Average KL loss: 0.004555
Average total loss: 0.026218
tensor(0.0341, device='cuda:0') tensor(0.1943, device='cuda:0') tensor(-1.5413e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.020869
Average KL loss: 0.004554
Average total loss: 0.025423
tensor(0.0341, device='cuda:0') tensor(0.1946, device='cuda:0') tensor(-2.7943e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.021289
Average KL loss: 0.004554
Average total loss: 0.025843
tensor(0.0341, device='cuda:0') tensor(0.1949, device='cuda:0') tensor(-1.1527e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.020734
Average KL loss: 0.004553
Average total loss: 0.025288
tensor(0.0342, device='cuda:0') tensor(0.1952, device='cuda:0') tensor(-1.5538e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.020352
Average KL loss: 0.004552
Average total loss: 0.024905
tensor(0.0342, device='cuda:0') tensor(0.1955, device='cuda:0') tensor(-7.8913e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.020540
Average KL loss: 0.004552
Average total loss: 0.025092
tensor(0.0342, device='cuda:0') tensor(0.1958, device='cuda:0') tensor(-1.3606e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.020799
Average KL loss: 0.004551
Average total loss: 0.025349
tensor(0.0342, device='cuda:0') tensor(0.1961, device='cuda:0') tensor(-9.8693e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.020826
Average KL loss: 0.004550
Average total loss: 0.025377
tensor(0.0342, device='cuda:0') tensor(0.1963, device='cuda:0') tensor(-2.2817e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.021161
Average KL loss: 0.004550
Average total loss: 0.025710
tensor(0.0342, device='cuda:0') tensor(0.1966, device='cuda:0') tensor(-1.5162e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.020748
Average KL loss: 0.004549
Average total loss: 0.025297
tensor(0.0343, device='cuda:0') tensor(0.1970, device='cuda:0') tensor(-4.2248e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.020641
Average KL loss: 0.004548
Average total loss: 0.025189
tensor(0.0343, device='cuda:0') tensor(0.1972, device='cuda:0') tensor(-8.7663e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.020613
Average KL loss: 0.004548
Average total loss: 0.025161
tensor(0.0343, device='cuda:0') tensor(0.1975, device='cuda:0') tensor(-2.2168e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.020700
Average KL loss: 0.004547
Average total loss: 0.025247
tensor(0.0343, device='cuda:0') tensor(0.1979, device='cuda:0') tensor(-1.4652e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.022815
Average KL loss: 0.004547
Average total loss: 0.027362
tensor(0.0343, device='cuda:0') tensor(0.1981, device='cuda:0') tensor(-4.0628e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.021136
Average KL loss: 0.004546
Average total loss: 0.025682
tensor(0.0344, device='cuda:0') tensor(0.1984, device='cuda:0') tensor(-2.0661e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.020819
Average KL loss: 0.004545
Average total loss: 0.025364
tensor(0.0344, device='cuda:0') tensor(0.1987, device='cuda:0') tensor(-2.7112e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.020521
Average KL loss: 0.004545
Average total loss: 0.025066
tensor(0.0344, device='cuda:0') tensor(0.1987, device='cuda:0') tensor(-1.9999e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.021550
Average KL loss: 0.004545
Average total loss: 0.026095
tensor(0.0344, device='cuda:0') tensor(0.1988, device='cuda:0') tensor(-1.5697e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.020664
Average KL loss: 0.004545
Average total loss: 0.025209
tensor(0.0344, device='cuda:0') tensor(0.1988, device='cuda:0') tensor(-1.2106e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.020636
Average KL loss: 0.004545
Average total loss: 0.025181
tensor(0.0344, device='cuda:0') tensor(0.1988, device='cuda:0') tensor(-1.5932e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.020501
Average KL loss: 0.004545
Average total loss: 0.025046
tensor(0.0344, device='cuda:0') tensor(0.1988, device='cuda:0') tensor(-1.8017e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.020469
Average KL loss: 0.004545
Average total loss: 0.025014
tensor(0.0344, device='cuda:0') tensor(0.1989, device='cuda:0') tensor(-6.9841e-11, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.020693
Average KL loss: 0.004545
Average total loss: 0.025238
tensor(0.0344, device='cuda:0') tensor(0.1989, device='cuda:0') tensor(-1.0729e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.020282
Average KL loss: 0.004545
Average total loss: 0.024827
tensor(0.0344, device='cuda:0') tensor(0.1989, device='cuda:0') tensor(-2.5560e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.020684
Average KL loss: 0.004545
Average total loss: 0.025228
tensor(0.0344, device='cuda:0') tensor(0.1990, device='cuda:0') tensor(-2.0008e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.020526
Average KL loss: 0.004545
Average total loss: 0.025071
tensor(0.0344, device='cuda:0') tensor(0.1990, device='cuda:0') tensor(-3.4929e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.021023
Average KL loss: 0.004545
Average total loss: 0.025568
tensor(0.0344, device='cuda:0') tensor(0.1990, device='cuda:0') tensor(-2.9078e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.020735
Average KL loss: 0.004545
Average total loss: 0.025279
tensor(0.0344, device='cuda:0') tensor(0.1990, device='cuda:0') tensor(-2.7774e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.020451
Average KL loss: 0.004545
Average total loss: 0.024995
tensor(0.0344, device='cuda:0') tensor(0.1991, device='cuda:0') tensor(-2.3275e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.020735
Average KL loss: 0.004544
Average total loss: 0.025280
tensor(0.0344, device='cuda:0') tensor(0.1991, device='cuda:0') tensor(-1.2902e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.020501
Average KL loss: 0.004544
Average total loss: 0.025045
tensor(0.0344, device='cuda:0') tensor(0.1991, device='cuda:0') tensor(-7.0240e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.020955
Average KL loss: 0.004544
Average total loss: 0.025499
tensor(0.0344, device='cuda:0') tensor(0.1992, device='cuda:0') tensor(-2.5061e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.020589
Average KL loss: 0.004544
Average total loss: 0.025133
tensor(0.0344, device='cuda:0') tensor(0.1992, device='cuda:0') tensor(-2.2344e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.020894
Average KL loss: 0.004544
Average total loss: 0.025439
tensor(0.0344, device='cuda:0') tensor(0.1992, device='cuda:0') tensor(-3.7427e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.020449
Average KL loss: 0.004544
Average total loss: 0.024993
tensor(0.0344, device='cuda:0') tensor(0.1992, device='cuda:0') tensor(-5.4193e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.020742
Average KL loss: 0.004544
Average total loss: 0.025286
tensor(0.0344, device='cuda:0') tensor(0.1992, device='cuda:0') tensor(-1.0526e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.021079
Average KL loss: 0.004544
Average total loss: 0.025623
 Percentile value: 6.970155334472656
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/8]: ---
conv1.weight         | nonzeros =     163 /    1728             (  9.43%) | total_pruned =    1565 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      86 /   36864             (  0.23%) | total_pruned =   36778 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      59 /   36864             (  0.16%) | total_pruned =   36805 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     130 /   36864             (  0.35%) | total_pruned =   36734 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     182 /   36864             (  0.49%) | total_pruned =   36682 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     634 /   73728             (  0.86%) | total_pruned =   73094 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1268 /  147456             (  0.86%) | total_pruned =  146188 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     266 /    8192             (  3.25%) | total_pruned =    7926 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1082 /  147456             (  0.73%) | total_pruned =  146374 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1022 /  147456             (  0.69%) | total_pruned =  146434 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2610 /  294912             (  0.89%) | total_pruned =  292302 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      62 /     256             ( 24.22%) | total_pruned =     194 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3157 /  589824             (  0.54%) | total_pruned =  586667 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     128 /     256             ( 50.00%) | total_pruned =     128 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      69 /     256             ( 26.95%) | total_pruned =     187 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     453 /   32768             (  1.38%) | total_pruned =   32315 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     105 /     256             ( 41.02%) | total_pruned =     151 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      61 /     256             ( 23.83%) | total_pruned =     195 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1653 /  589824             (  0.28%) | total_pruned =  588171 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     136 /     256             ( 53.12%) | total_pruned =     120 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1355 /  589824             (  0.23%) | total_pruned =  588469 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      66 /     256             ( 25.78%) | total_pruned =     190 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2322 / 1179648             (  0.20%) | total_pruned = 1177326 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     276 /     512             ( 53.91%) | total_pruned =     236 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      76 /     512             ( 14.84%) | total_pruned =     436 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2180 / 2359296             (  0.09%) | total_pruned = 2357116 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     170 /     512             ( 33.20%) | total_pruned =     342 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      92 /  131072             (  0.07%) | total_pruned =  130980 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     172 /     512             ( 33.59%) | total_pruned =     340 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1864 / 2359296             (  0.08%) | total_pruned = 2357432 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      97 /     512             ( 18.95%) | total_pruned =     415 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2676 / 2359296             (  0.11%) | total_pruned = 2356620 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     281 /     512             ( 54.88%) | total_pruned =     231 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     113 /     512             ( 22.07%) | total_pruned =     399 | shape = torch.Size([512])
linear.weight        | nonzeros =    1026 /    5120             ( 20.04%) | total_pruned =    4094 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 99/100 Loss: 0.315185 Accuracy: 79.10 93.18 % Best test Accuracy: 80.99%
tensor(0.0344, device='cuda:0') tensor(0.1992, device='cuda:0') tensor(-2.2115e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.260176
Average KL loss: 0.004506
Average total loss: 0.264682
tensor(0.0337, device='cuda:0') tensor(0.1931, device='cuda:0') tensor(-7.0940e-11, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.257627
Average KL loss: 0.004427
Average total loss: 0.262054
tensor(0.0329, device='cuda:0') tensor(0.1872, device='cuda:0') tensor(-5.0201e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.259467
Average KL loss: 0.004341
Average total loss: 0.263808
tensor(0.0321, device='cuda:0') tensor(0.1812, device='cuda:0') tensor(-8.2781e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.258784
Average KL loss: 0.004245
Average total loss: 0.263029
tensor(0.0312, device='cuda:0') tensor(0.1752, device='cuda:0') tensor(-1.1410e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.256859
Average KL loss: 0.004139
Average total loss: 0.260998
tensor(0.0303, device='cuda:0') tensor(0.1692, device='cuda:0') tensor(-9.6802e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.258222
Average KL loss: 0.004019
Average total loss: 0.262241
tensor(0.0293, device='cuda:0') tensor(0.1631, device='cuda:0') tensor(-5.0263e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.258722
Average KL loss: 0.003887
Average total loss: 0.262609
tensor(0.0283, device='cuda:0') tensor(0.1571, device='cuda:0') tensor(-2.4450e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.257879
Average KL loss: 0.003744
Average total loss: 0.261623
tensor(0.0273, device='cuda:0') tensor(0.1512, device='cuda:0') tensor(-7.5365e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.255891
Average KL loss: 0.003590
Average total loss: 0.259482
tensor(0.0262, device='cuda:0') tensor(0.1454, device='cuda:0') tensor(-1.2622e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.258818
Average KL loss: 0.003430
Average total loss: 0.262247
tensor(0.0252, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(-5.8606e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.256927
Average KL loss: 0.003264
Average total loss: 0.260191
tensor(0.0241, device='cuda:0') tensor(0.1345, device='cuda:0') tensor(-3.6540e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.259206
Average KL loss: 0.003096
Average total loss: 0.262302
tensor(0.0230, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-5.0692e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.260087
Average KL loss: 0.002929
Average total loss: 0.263016
tensor(0.0220, device='cuda:0') tensor(0.1248, device='cuda:0') tensor(-2.1212e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.257374
Average KL loss: 0.002765
Average total loss: 0.260139
tensor(0.0209, device='cuda:0') tensor(0.1205, device='cuda:0') tensor(-3.4157e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.259863
Average KL loss: 0.002606
Average total loss: 0.262469
tensor(0.0200, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-9.1545e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.258964
Average KL loss: 0.002456
Average total loss: 0.261421
tensor(0.0191, device='cuda:0') tensor(0.1131, device='cuda:0') tensor(-1.1470e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.255883
Average KL loss: 0.002316
Average total loss: 0.258199
tensor(0.0183, device='cuda:0') tensor(0.1100, device='cuda:0') tensor(-8.0117e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.257231
Average KL loss: 0.002187
Average total loss: 0.259419
tensor(0.0176, device='cuda:0') tensor(0.1074, device='cuda:0') tensor(-1.7733e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.259295
Average KL loss: 0.002071
Average total loss: 0.261365
tensor(0.0169, device='cuda:0') tensor(0.1052, device='cuda:0') tensor(-2.3949e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.255111
Average KL loss: 0.001969
Average total loss: 0.257080
tensor(0.0163, device='cuda:0') tensor(0.1034, device='cuda:0') tensor(-1.5520e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.255885
Average KL loss: 0.001884
Average total loss: 0.257769
tensor(0.0159, device='cuda:0') tensor(0.1020, device='cuda:0') tensor(-5.7379e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.260015
Average KL loss: 0.001818
Average total loss: 0.261833
tensor(0.0155, device='cuda:0') tensor(0.1008, device='cuda:0') tensor(-4.2219e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.257002
Average KL loss: 0.001771
Average total loss: 0.258773
tensor(0.0152, device='cuda:0') tensor(0.0999, device='cuda:0') tensor(-6.9094e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.257533
Average KL loss: 0.001736
Average total loss: 0.259269
tensor(0.0149, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-1.2174e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.255069
Average KL loss: 0.001709
Average total loss: 0.256777
tensor(0.0147, device='cuda:0') tensor(0.0983, device='cuda:0') tensor(-8.9968e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.256684
Average KL loss: 0.001685
Average total loss: 0.258369
tensor(0.0146, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(-8.2451e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.255671
Average KL loss: 0.001664
Average total loss: 0.257335
tensor(0.0144, device='cuda:0') tensor(0.0971, device='cuda:0') tensor(-3.9966e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.255910
Average KL loss: 0.001645
Average total loss: 0.257554
tensor(0.0143, device='cuda:0') tensor(0.0965, device='cuda:0') tensor(-6.4884e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.256893
Average KL loss: 0.001627
Average total loss: 0.258520
tensor(0.0142, device='cuda:0') tensor(0.0960, device='cuda:0') tensor(-5.5775e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.257439
Average KL loss: 0.001611
Average total loss: 0.259049
tensor(0.0141, device='cuda:0') tensor(0.0955, device='cuda:0') tensor(-6.4570e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.255925
Average KL loss: 0.001596
Average total loss: 0.257521
tensor(0.0140, device='cuda:0') tensor(0.0951, device='cuda:0') tensor(-4.0143e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.254132
Average KL loss: 0.001582
Average total loss: 0.255714
tensor(0.0139, device='cuda:0') tensor(0.0947, device='cuda:0') tensor(-4.2411e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.254050
Average KL loss: 0.001569
Average total loss: 0.255619
tensor(0.0138, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(-8.3554e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.256008
Average KL loss: 0.001557
Average total loss: 0.257565
tensor(0.0137, device='cuda:0') tensor(0.0940, device='cuda:0') tensor(-5.6993e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.255455
Average KL loss: 0.001546
Average total loss: 0.257001
tensor(0.0136, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(-5.2819e-11, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.254346
Average KL loss: 0.001535
Average total loss: 0.255882
tensor(0.0136, device='cuda:0') tensor(0.0934, device='cuda:0') tensor(-1.1035e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.255521
Average KL loss: 0.001526
Average total loss: 0.257047
tensor(0.0135, device='cuda:0') tensor(0.0931, device='cuda:0') tensor(-1.2901e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.255316
Average KL loss: 0.001517
Average total loss: 0.256834
tensor(0.0135, device='cuda:0') tensor(0.0929, device='cuda:0') tensor(-6.2192e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.254142
Average KL loss: 0.001510
Average total loss: 0.255652
tensor(0.0134, device='cuda:0') tensor(0.0927, device='cuda:0') tensor(-1.3484e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.254617
Average KL loss: 0.001502
Average total loss: 0.256119
tensor(0.0134, device='cuda:0') tensor(0.0925, device='cuda:0') tensor(-4.5507e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.255052
Average KL loss: 0.001496
Average total loss: 0.256548
tensor(0.0133, device='cuda:0') tensor(0.0923, device='cuda:0') tensor(-7.6061e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.256380
Average KL loss: 0.001489
Average total loss: 0.257870
tensor(0.0133, device='cuda:0') tensor(0.0921, device='cuda:0') tensor(-1.2937e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.254916
Average KL loss: 0.001484
Average total loss: 0.256400
tensor(0.0132, device='cuda:0') tensor(0.0920, device='cuda:0') tensor(-2.9104e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.256927
Average KL loss: 0.001479
Average total loss: 0.258406
tensor(0.0132, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-7.1788e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.254243
Average KL loss: 0.001476
Average total loss: 0.255719
tensor(0.0132, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-4.1080e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.255337
Average KL loss: 0.001476
Average total loss: 0.256812
tensor(0.0132, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-1.0149e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.255570
Average KL loss: 0.001475
Average total loss: 0.257046
tensor(0.0132, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-3.1977e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.254303
Average KL loss: 0.001475
Average total loss: 0.255778
tensor(0.0132, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-1.8447e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.254274
Average KL loss: 0.001475
Average total loss: 0.255749
tensor(0.0132, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-1.6639e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.255259
Average KL loss: 0.001474
Average total loss: 0.256733
tensor(0.0132, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-4.6267e-11, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.254907
Average KL loss: 0.001474
Average total loss: 0.256381
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.6000e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.254612
Average KL loss: 0.001474
Average total loss: 0.256086
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-4.5826e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.256260
Average KL loss: 0.001473
Average total loss: 0.257733
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.5113e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.254393
Average KL loss: 0.001473
Average total loss: 0.255865
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.9150e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.255807
Average KL loss: 0.001472
Average total loss: 0.257280
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-5.8542e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.255450
Average KL loss: 0.001472
Average total loss: 0.256922
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-3.4898e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.252422
Average KL loss: 0.001472
Average total loss: 0.253895
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-9.4018e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.254542
Average KL loss: 0.001472
Average total loss: 0.256015
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-5.6847e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.253173
Average KL loss: 0.001472
Average total loss: 0.254645
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-6.7710e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.254706
Average KL loss: 0.001472
Average total loss: 0.256178
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-5.5438e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.255114
Average KL loss: 0.001472
Average total loss: 0.256586
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-7.4062e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.253176
Average KL loss: 0.001472
Average total loss: 0.254648
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.1585e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.258798
Average KL loss: 0.001472
Average total loss: 0.260270
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(1.4862e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.253966
Average KL loss: 0.001472
Average total loss: 0.255438
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-9.5318e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.255673
Average KL loss: 0.001472
Average total loss: 0.257145
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-2.4409e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.256856
Average KL loss: 0.001472
Average total loss: 0.258328
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-4.4127e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.254307
Average KL loss: 0.001472
Average total loss: 0.255779
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-4.2319e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.255097
Average KL loss: 0.001472
Average total loss: 0.256569
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-5.3980e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.254366
Average KL loss: 0.001472
Average total loss: 0.255838
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-7.1685e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.258307
Average KL loss: 0.001472
Average total loss: 0.259779
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.4802e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.253860
Average KL loss: 0.001472
Average total loss: 0.255332
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-9.4606e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.252554
Average KL loss: 0.001472
Average total loss: 0.254026
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-4.2974e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.253228
Average KL loss: 0.001472
Average total loss: 0.254699
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-5.9431e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.253991
Average KL loss: 0.001472
Average total loss: 0.255463
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-4.8227e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.253857
Average KL loss: 0.001472
Average total loss: 0.255328
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-4.7209e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.254279
Average KL loss: 0.001472
Average total loss: 0.255751
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.2211e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.255964
Average KL loss: 0.001472
Average total loss: 0.257435
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.0685e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.255644
Average KL loss: 0.001472
Average total loss: 0.257116
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.7628e-09, device='cuda:0')
 Percentile value: 8.172023677825928
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/8]: ---
conv1.weight         | nonzeros =     138 /    1728             (  7.99%) | total_pruned =    1590 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      38 /   36864             (  0.10%) | total_pruned =   36826 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      34 /   36864             (  0.09%) | total_pruned =   36830 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      73 /   36864             (  0.20%) | total_pruned =   36791 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     100 /   36864             (  0.27%) | total_pruned =   36764 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     230 /   73728             (  0.31%) | total_pruned =   73498 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     302 /  147456             (  0.20%) | total_pruned =  147154 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     118 /    8192             (  1.44%) | total_pruned =    8074 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     335 /  147456             (  0.23%) | total_pruned =  147121 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     314 /  147456             (  0.21%) | total_pruned =  147142 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     406 /  294912             (  0.14%) | total_pruned =  294506 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     400 /  589824             (  0.07%) | total_pruned =  589424 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      85 /   32768             (  0.26%) | total_pruned =   32683 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     260 /  589824             (  0.04%) | total_pruned =  589564 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     128 /     256             ( 50.00%) | total_pruned =     128 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     244 /  589824             (  0.04%) | total_pruned =  589580 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     103 /     256             ( 40.23%) | total_pruned =     153 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     247 / 1179648             (  0.02%) | total_pruned = 1179401 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     248 /     512             ( 48.44%) | total_pruned =     264 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     337 / 2359296             (  0.01%) | total_pruned = 2358959 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     161 /     512             ( 31.45%) | total_pruned =     351 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     121 /     512             ( 23.63%) | total_pruned =     391 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      43 /  131072             (  0.03%) | total_pruned =  131029 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     121 /     512             ( 23.63%) | total_pruned =     391 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     417 / 2359296             (  0.02%) | total_pruned = 2358879 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      87 /     512             ( 16.99%) | total_pruned =     425 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     955 / 2359296             (  0.04%) | total_pruned = 2358341 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     236 /     512             ( 46.09%) | total_pruned =     276 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      67 /     512             ( 13.09%) | total_pruned =     445 | shape = torch.Size([512])
linear.weight        | nonzeros =     734 /    5120             ( 14.34%) | total_pruned =    4386 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 99/100 Loss: 0.766359 Accuracy: 66.18 68.84 % Best test Accuracy: 66.38%
tensor(0.0132, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.8041e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.882067
Average KL loss: 0.001470
Average total loss: 0.883537
tensor(0.0131, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(1.9236e-11, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.879120
Average KL loss: 0.001466
Average total loss: 0.880586
tensor(0.0130, device='cuda:0') tensor(0.0896, device='cuda:0') tensor(-1.6733e-11, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.884022
Average KL loss: 0.001461
Average total loss: 0.885483
tensor(0.0129, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(3.0521e-11, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.883017
Average KL loss: 0.001457
Average total loss: 0.884473
tensor(0.0128, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-8.6956e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.880262
Average KL loss: 0.001452
Average total loss: 0.881713
tensor(0.0127, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-1.9766e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.883912
Average KL loss: 0.001446
Average total loss: 0.885358
tensor(0.0126, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(-8.3499e-11, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.881499
Average KL loss: 0.001440
Average total loss: 0.882939
tensor(0.0124, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(-2.0326e-11, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.881834
Average KL loss: 0.001434
Average total loss: 0.883267
tensor(0.0123, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(-6.9305e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.882000
Average KL loss: 0.001427
Average total loss: 0.883426
tensor(0.0122, device='cuda:0') tensor(0.0816, device='cuda:0') tensor(-7.6588e-11, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.882109
Average KL loss: 0.001419
Average total loss: 0.883528
tensor(0.0121, device='cuda:0') tensor(0.0804, device='cuda:0') tensor(-2.2740e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.880085
Average KL loss: 0.001410
Average total loss: 0.881495
tensor(0.0119, device='cuda:0') tensor(0.0790, device='cuda:0') tensor(-1.3286e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.882002
Average KL loss: 0.001400
Average total loss: 0.883401
tensor(0.0118, device='cuda:0') tensor(0.0777, device='cuda:0') tensor(-9.2023e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.883830
Average KL loss: 0.001388
Average total loss: 0.885218
tensor(0.0116, device='cuda:0') tensor(0.0763, device='cuda:0') tensor(-3.0257e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.882720
Average KL loss: 0.001381
Average total loss: 0.884101
tensor(0.0116, device='cuda:0') tensor(0.0761, device='cuda:0') tensor(-6.0343e-11, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.883651
Average KL loss: 0.001380
Average total loss: 0.885031
tensor(0.0116, device='cuda:0') tensor(0.0760, device='cuda:0') tensor(-1.2501e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.882060
Average KL loss: 0.001379
Average total loss: 0.883439
tensor(0.0116, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(-6.0357e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.885471
Average KL loss: 0.001378
Average total loss: 0.886849
tensor(0.0115, device='cuda:0') tensor(0.0757, device='cuda:0') tensor(-1.4949e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.880102
Average KL loss: 0.001376
Average total loss: 0.881479
tensor(0.0115, device='cuda:0') tensor(0.0756, device='cuda:0') tensor(8.2149e-12, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.882447
Average KL loss: 0.001375
Average total loss: 0.883822
tensor(0.0115, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(9.6102e-11, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.889013
Average KL loss: 0.001374
Average total loss: 0.890387
tensor(0.0115, device='cuda:0') tensor(0.0753, device='cuda:0') tensor(6.5470e-11, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.880548
Average KL loss: 0.001373
Average total loss: 0.881921
tensor(0.0115, device='cuda:0') tensor(0.0752, device='cuda:0') tensor(-3.5108e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.887247
Average KL loss: 0.001371
Average total loss: 0.888619
tensor(0.0115, device='cuda:0') tensor(0.0750, device='cuda:0') tensor(-8.5008e-11, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.881825
Average KL loss: 0.001370
Average total loss: 0.883195
tensor(0.0114, device='cuda:0') tensor(0.0749, device='cuda:0') tensor(8.4564e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.882602
Average KL loss: 0.001369
Average total loss: 0.883971
tensor(0.0114, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(9.2997e-11, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.881248
Average KL loss: 0.001368
Average total loss: 0.882617
tensor(0.0114, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-3.2306e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.882438
Average KL loss: 0.001368
Average total loss: 0.883806
tensor(0.0114, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-8.6114e-11, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.885720
Average KL loss: 0.001368
Average total loss: 0.887088
tensor(0.0114, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(1.3266e-11, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.885901
Average KL loss: 0.001368
Average total loss: 0.887269
tensor(0.0114, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-5.3239e-12, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.880943
Average KL loss: 0.001368
Average total loss: 0.882311
tensor(0.0114, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-1.1053e-11, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.881317
Average KL loss: 0.001368
Average total loss: 0.882684
tensor(0.0114, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-6.1338e-12, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.881046
Average KL loss: 0.001367
Average total loss: 0.882414
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-1.7327e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.880752
Average KL loss: 0.001367
Average total loss: 0.882119
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(1.2993e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.881500
Average KL loss: 0.001367
Average total loss: 0.882867
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(2.1607e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.882533
Average KL loss: 0.001367
Average total loss: 0.883900
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-2.0049e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.881853
Average KL loss: 0.001367
Average total loss: 0.883220
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(2.5620e-11, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.882657
Average KL loss: 0.001367
Average total loss: 0.884023
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-1.0395e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.882135
Average KL loss: 0.001367
Average total loss: 0.883502
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-4.2367e-11, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.880979
Average KL loss: 0.001367
Average total loss: 0.882346
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-8.5015e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.881060
Average KL loss: 0.001367
Average total loss: 0.882427
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-1.3475e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.886893
Average KL loss: 0.001367
Average total loss: 0.888260
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-2.0349e-11, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.881516
Average KL loss: 0.001367
Average total loss: 0.882883
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-2.5934e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.883254
Average KL loss: 0.001367
Average total loss: 0.884621
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-6.2094e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.884744
Average KL loss: 0.001367
Average total loss: 0.886111
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-1.1215e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.883535
Average KL loss: 0.001367
Average total loss: 0.884902
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-1.3602e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.880674
Average KL loss: 0.001367
Average total loss: 0.882041
tensor(0.0114, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-1.5491e-09, device='cuda:0')
 Percentile value: 9.094441604614257
Non-zero model percentage: 0.02187183126807213%, Non-zero mask percentage: 0.02187183126807213%

--- Pruning Level [7/8]: ---
conv1.weight         | nonzeros =      69 /    1728             (  3.99%) | total_pruned =    1659 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       8 /   36864             (  0.02%) | total_pruned =   36856 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       2 /   36864             (  0.01%) | total_pruned =   36862 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      10 /   36864             (  0.03%) | total_pruned =   36854 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      18 /   36864             (  0.05%) | total_pruned =   36846 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      17 /   73728             (  0.02%) | total_pruned =   73711 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       5 /  147456             (  0.00%) | total_pruned =  147451 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      18 /    8192             (  0.22%) | total_pruned =    8174 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =      15 /  147456             (  0.01%) | total_pruned =  147441 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       4 /  147456             (  0.00%) | total_pruned =  147452 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       1 /  294912             (  0.00%) | total_pruned =  294911 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       2 /  589824             (  0.00%) | total_pruned =  589822 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     105 /     256             ( 41.02%) | total_pruned =     151 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       1 /   32768             (  0.00%) | total_pruned =   32767 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       1 /  589824             (  0.00%) | total_pruned =  589823 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       5 / 1179648             (  0.00%) | total_pruned = 1179643 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     139 /     512             ( 27.15%) | total_pruned =     373 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =      37 / 2359296             (  0.00%) | total_pruned = 2359259 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     104 /     512             ( 20.31%) | total_pruned =     408 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       9 /  131072             (  0.01%) | total_pruned =  131063 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      18 / 2359296             (  0.00%) | total_pruned = 2359278 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      78 /     512             ( 15.23%) | total_pruned =     434 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     193 / 2359296             (  0.01%) | total_pruned = 2359103 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     199 /     512             ( 38.87%) | total_pruned =     313 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      36 /     512             (  7.03%) | total_pruned =     476 | shape = torch.Size([512])
linear.weight        | nonzeros =     512 /    5120             ( 10.00%) | total_pruned =    4608 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 2445, pruned : 11176317, total: 11178762, Compression rate :    4572.09x  ( 99.98% pruned)
Train Epoch: 56/100 Loss: 2.302584 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
