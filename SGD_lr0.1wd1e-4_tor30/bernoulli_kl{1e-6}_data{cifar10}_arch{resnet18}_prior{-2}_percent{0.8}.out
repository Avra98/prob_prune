Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/8]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 99/100 Loss: 0.000593 Accuracy: 86.36% Best Accuracy: 86.36%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(4.5698e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.255603
Average KL loss: 511731.650256
Average total loss: 0.767335
tensor(-0.2711, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(3.7624e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.238123
Average KL loss: 386980.601023
Average total loss: 0.625104
tensor(-0.4602, device='cuda:0') tensor(0.0734, device='cuda:0') tensor(3.0247e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.215351
Average KL loss: 311926.008951
Average total loss: 0.527277
tensor(-0.6117, device='cuda:0') tensor(0.1315, device='cuda:0') tensor(2.5962e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.198806
Average KL loss: 262413.613491
Average total loss: 0.461220
tensor(-0.7363, device='cuda:0') tensor(0.1853, device='cuda:0') tensor(2.2265e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.184192
Average KL loss: 227475.610934
Average total loss: 0.411668
tensor(-0.8408, device='cuda:0') tensor(0.2302, device='cuda:0') tensor(1.9147e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.172810
Average KL loss: 201358.977621
Average total loss: 0.374169
tensor(-0.9297, device='cuda:0') tensor(0.2662, device='cuda:0') tensor(1.7095e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.163239
Average KL loss: 181036.985614
Average total loss: 0.344276
tensor(-1.0063, device='cuda:0') tensor(0.2942, device='cuda:0') tensor(1.5038e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.155147
Average KL loss: 164663.576726
Average total loss: 0.319811
tensor(-1.0730, device='cuda:0') tensor(0.3151, device='cuda:0') tensor(1.3089e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.147330
Average KL loss: 151173.207801
Average total loss: 0.298503
tensor(-1.1315, device='cuda:0') tensor(0.3306, device='cuda:0') tensor(1.2836e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.141911
Average KL loss: 139842.340473
Average total loss: 0.281754
tensor(-1.1831, device='cuda:0') tensor(0.3416, device='cuda:0') tensor(1.1260e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.137720
Average KL loss: 130162.280371
Average total loss: 0.267883
tensor(-1.2291, device='cuda:0') tensor(0.3487, device='cuda:0') tensor(1.1237e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.132778
Average KL loss: 121771.564418
Average total loss: 0.254549
tensor(-1.2702, device='cuda:0') tensor(0.3533, device='cuda:0') tensor(1.0735e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.128711
Average KL loss: 114449.739610
Average total loss: 0.243161
tensor(-1.3073, device='cuda:0') tensor(0.3554, device='cuda:0') tensor(9.8363e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.125282
Average KL loss: 107949.099425
Average total loss: 0.233231
tensor(-1.3408, device='cuda:0') tensor(0.3557, device='cuda:0') tensor(8.5733e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.123389
Average KL loss: 102153.880914
Average total loss: 0.225543
tensor(-1.3714, device='cuda:0') tensor(0.3546, device='cuda:0') tensor(8.2940e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.118687
Average KL loss: 96970.301151
Average total loss: 0.215657
tensor(-1.3992, device='cuda:0') tensor(0.3526, device='cuda:0') tensor(8.4604e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.117122
Average KL loss: 92324.368766
Average total loss: 0.209447
tensor(-1.4247, device='cuda:0') tensor(0.3499, device='cuda:0') tensor(7.4695e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.114585
Average KL loss: 88092.783887
Average total loss: 0.202678
tensor(-1.4482, device='cuda:0') tensor(0.3466, device='cuda:0') tensor(7.3892e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.111016
Average KL loss: 84222.848625
Average total loss: 0.195239
tensor(-1.4699, device='cuda:0') tensor(0.3427, device='cuda:0') tensor(6.1466e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.110940
Average KL loss: 80726.689098
Average total loss: 0.191666
tensor(-1.4901, device='cuda:0') tensor(0.3390, device='cuda:0') tensor(7.4421e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.106709
Average KL loss: 77521.667679
Average total loss: 0.184230
tensor(-1.5088, device='cuda:0') tensor(0.3347, device='cuda:0') tensor(6.2615e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.105976
Average KL loss: 74547.040761
Average total loss: 0.180523
tensor(-1.5263, device='cuda:0') tensor(0.3304, device='cuda:0') tensor(6.7818e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.104077
Average KL loss: 71821.625799
Average total loss: 0.175898
tensor(-1.5426, device='cuda:0') tensor(0.3262, device='cuda:0') tensor(5.7445e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.104587
Average KL loss: 69307.769022
Average total loss: 0.173894
tensor(-1.5579, device='cuda:0') tensor(0.3221, device='cuda:0') tensor(6.1282e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.103208
Average KL loss: 66974.862692
Average total loss: 0.170183
tensor(-1.5723, device='cuda:0') tensor(0.3177, device='cuda:0') tensor(5.0907e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.101732
Average KL loss: 64798.263027
Average total loss: 0.166530
tensor(-1.5859, device='cuda:0') tensor(0.3136, device='cuda:0') tensor(5.0680e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.100006
Average KL loss: 62765.333440
Average total loss: 0.162771
tensor(-1.5987, device='cuda:0') tensor(0.3093, device='cuda:0') tensor(4.8167e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.098936
Average KL loss: 60861.264306
Average total loss: 0.159797
tensor(-1.6108, device='cuda:0') tensor(0.3052, device='cuda:0') tensor(4.9241e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.098784
Average KL loss: 59097.338555
Average total loss: 0.157881
tensor(-1.6222, device='cuda:0') tensor(0.3012, device='cuda:0') tensor(4.7597e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.099276
Average KL loss: 57438.680627
Average total loss: 0.156715
tensor(-1.6331, device='cuda:0') tensor(0.2974, device='cuda:0') tensor(4.3714e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.097905
Average KL loss: 55902.031570
Average total loss: 0.153807
tensor(-1.6433, device='cuda:0') tensor(0.2938, device='cuda:0') tensor(3.9031e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.097103
Average KL loss: 54477.414562
Average total loss: 0.151581
tensor(-1.6531, device='cuda:0') tensor(0.2904, device='cuda:0') tensor(4.1341e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.095311
Average KL loss: 53119.562500
Average total loss: 0.148430
tensor(-1.6624, device='cuda:0') tensor(0.2869, device='cuda:0') tensor(3.8086e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.094723
Average KL loss: 51821.475543
Average total loss: 0.146545
tensor(-1.6713, device='cuda:0') tensor(0.2834, device='cuda:0') tensor(3.6293e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.093572
Average KL loss: 50615.177430
Average total loss: 0.144187
tensor(-1.6797, device='cuda:0') tensor(0.2802, device='cuda:0') tensor(3.8158e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.093239
Average KL loss: 49472.756234
Average total loss: 0.142711
tensor(-1.6877, device='cuda:0') tensor(0.2771, device='cuda:0') tensor(3.4610e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.092768
Average KL loss: 48387.385710
Average total loss: 0.141156
tensor(-1.6955, device='cuda:0') tensor(0.2741, device='cuda:0') tensor(3.2569e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.091849
Average KL loss: 47365.665521
Average total loss: 0.139215
tensor(-1.7028, device='cuda:0') tensor(0.2711, device='cuda:0') tensor(2.9009e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.091665
Average KL loss: 46392.446052
Average total loss: 0.138057
tensor(-1.7099, device='cuda:0') tensor(0.2683, device='cuda:0') tensor(3.3648e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.089543
Average KL loss: 45485.271260
Average total loss: 0.135029
tensor(-1.7167, device='cuda:0') tensor(0.2657, device='cuda:0') tensor(3.0795e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.092426
Average KL loss: 44620.574409
Average total loss: 0.137047
tensor(-1.7231, device='cuda:0') tensor(0.2632, device='cuda:0') tensor(2.9082e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.089288
Average KL loss: 43818.090233
Average total loss: 0.133106
tensor(-1.7293, device='cuda:0') tensor(0.2608, device='cuda:0') tensor(3.2253e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.088661
Average KL loss: 43019.760310
Average total loss: 0.131680
tensor(-1.7353, device='cuda:0') tensor(0.2581, device='cuda:0') tensor(2.9533e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.088726
Average KL loss: 42256.080643
Average total loss: 0.130983
tensor(-1.7411, device='cuda:0') tensor(0.2559, device='cuda:0') tensor(2.9282e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.088579
Average KL loss: 41551.797954
Average total loss: 0.130131
tensor(-1.7466, device='cuda:0') tensor(0.2536, device='cuda:0') tensor(2.4983e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.088612
Average KL loss: 40875.107657
Average total loss: 0.129487
tensor(-1.7519, device='cuda:0') tensor(0.2515, device='cuda:0') tensor(2.6516e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.088143
Average KL loss: 40220.955083
Average total loss: 0.128364
tensor(-1.7571, device='cuda:0') tensor(0.2493, device='cuda:0') tensor(2.4432e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.088185
Average KL loss: 39620.750000
Average total loss: 0.127806
tensor(-1.7620, device='cuda:0') tensor(0.2476, device='cuda:0') tensor(2.1373e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.085649
Average KL loss: 39049.728021
Average total loss: 0.124699
tensor(-1.7667, device='cuda:0') tensor(0.2458, device='cuda:0') tensor(2.1444e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.087601
Average KL loss: 38499.257673
Average total loss: 0.126100
tensor(-1.7713, device='cuda:0') tensor(0.2441, device='cuda:0') tensor(2.2905e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.086018
Average KL loss: 37975.913763
Average total loss: 0.123994
tensor(-1.7757, device='cuda:0') tensor(0.2424, device='cuda:0') tensor(1.9265e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.085557
Average KL loss: 37460.665601
Average total loss: 0.123018
tensor(-1.7799, device='cuda:0') tensor(0.2406, device='cuda:0') tensor(1.9145e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.087137
Average KL loss: 36975.290761
Average total loss: 0.124113
tensor(-1.7841, device='cuda:0') tensor(0.2393, device='cuda:0') tensor(1.9881e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.085342
Average KL loss: 36536.741368
Average total loss: 0.121879
tensor(-1.7880, device='cuda:0') tensor(0.2378, device='cuda:0') tensor(2.0256e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.085679
Average KL loss: 36096.450767
Average total loss: 0.121775
tensor(-1.7919, device='cuda:0') tensor(0.2363, device='cuda:0') tensor(2.0518e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.083154
Average KL loss: 35661.169277
Average total loss: 0.118815
tensor(-1.7956, device='cuda:0') tensor(0.2348, device='cuda:0') tensor(2.5694e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.084556
Average KL loss: 35234.760470
Average total loss: 0.119790
tensor(-1.7992, device='cuda:0') tensor(0.2334, device='cuda:0') tensor(1.7723e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.083857
Average KL loss: 34833.326966
Average total loss: 0.118690
tensor(-1.8026, device='cuda:0') tensor(0.2320, device='cuda:0') tensor(2.0910e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.084992
Average KL loss: 34460.115489
Average total loss: 0.119452
tensor(-1.8059, device='cuda:0') tensor(0.2309, device='cuda:0') tensor(1.5506e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.084569
Average KL loss: 34115.598386
Average total loss: 0.118685
tensor(-1.8092, device='cuda:0') tensor(0.2298, device='cuda:0') tensor(1.8397e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.082773
Average KL loss: 33751.861253
Average total loss: 0.116525
tensor(-1.8124, device='cuda:0') tensor(0.2284, device='cuda:0') tensor(1.5310e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.083908
Average KL loss: 33399.697331
Average total loss: 0.117308
tensor(-1.8154, device='cuda:0') tensor(0.2274, device='cuda:0') tensor(1.4470e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.083101
Average KL loss: 33083.193974
Average total loss: 0.116184
tensor(-1.8184, device='cuda:0') tensor(0.2264, device='cuda:0') tensor(1.7397e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.083404
Average KL loss: 32782.569733
Average total loss: 0.116187
tensor(-1.8213, device='cuda:0') tensor(0.2255, device='cuda:0') tensor(1.7937e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.082762
Average KL loss: 32479.921555
Average total loss: 0.115242
tensor(-1.8241, device='cuda:0') tensor(0.2244, device='cuda:0') tensor(1.2581e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.083655
Average KL loss: 32211.081002
Average total loss: 0.115866
tensor(-1.8268, device='cuda:0') tensor(0.2240, device='cuda:0') tensor(1.6723e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.081583
Average KL loss: 31958.300112
Average total loss: 0.113541
tensor(-1.8295, device='cuda:0') tensor(0.2231, device='cuda:0') tensor(1.3751e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.082215
Average KL loss: 31683.686141
Average total loss: 0.113899
tensor(-1.8321, device='cuda:0') tensor(0.2221, device='cuda:0') tensor(1.5089e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.082644
Average KL loss: 31433.966033
Average total loss: 0.114078
tensor(-1.8346, device='cuda:0') tensor(0.2215, device='cuda:0') tensor(1.6419e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.081756
Average KL loss: 31200.779771
Average total loss: 0.112956
tensor(-1.8370, device='cuda:0') tensor(0.2209, device='cuda:0') tensor(1.6992e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.081888
Average KL loss: 30960.484255
Average total loss: 0.112849
tensor(-1.8394, device='cuda:0') tensor(0.2201, device='cuda:0') tensor(1.4770e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.080735
Average KL loss: 30712.336477
Average total loss: 0.111447
tensor(-1.8417, device='cuda:0') tensor(0.2193, device='cuda:0') tensor(1.6428e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.081343
Average KL loss: 30485.812100
Average total loss: 0.111829
tensor(-1.8439, device='cuda:0') tensor(0.2186, device='cuda:0') tensor(1.5577e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.080836
Average KL loss: 30266.991328
Average total loss: 0.111103
tensor(-1.8461, device='cuda:0') tensor(0.2179, device='cuda:0') tensor(1.1649e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.081047
Average KL loss: 30064.625719
Average total loss: 0.111111
tensor(-1.8482, device='cuda:0') tensor(0.2174, device='cuda:0') tensor(1.4551e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.081505
Average KL loss: 29882.813859
Average total loss: 0.111388
tensor(-1.8503, device='cuda:0') tensor(0.2172, device='cuda:0') tensor(8.7212e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.080538
Average KL loss: 29697.018702
Average total loss: 0.110235
tensor(-1.8523, device='cuda:0') tensor(0.2166, device='cuda:0') tensor(1.2998e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.080695
Average KL loss: 29519.261389
Average total loss: 0.110214
tensor(-1.8542, device='cuda:0') tensor(0.2163, device='cuda:0') tensor(1.4409e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.080271
Average KL loss: 29340.305067
Average total loss: 0.109611
tensor(-1.8561, device='cuda:0') tensor(0.2156, device='cuda:0') tensor(1.4067e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.080876
Average KL loss: 29150.222347
Average total loss: 0.110026
tensor(-1.8580, device='cuda:0') tensor(0.2150, device='cuda:0') tensor(1.3120e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.080595
Average KL loss: 28979.487652
Average total loss: 0.109575
tensor(-1.8598, device='cuda:0') tensor(0.2148, device='cuda:0') tensor(1.1079e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.079837
Average KL loss: 28840.174473
Average total loss: 0.108677
tensor(-1.8615, device='cuda:0') tensor(0.2145, device='cuda:0') tensor(1.3262e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.080150
Average KL loss: 28696.344309
Average total loss: 0.108847
tensor(-1.8632, device='cuda:0') tensor(0.2143, device='cuda:0') tensor(1.0193e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.079364
Average KL loss: 28563.241688
Average total loss: 0.107928
tensor(-1.8649, device='cuda:0') tensor(0.2140, device='cuda:0') tensor(5.3165e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.079264
Average KL loss: 28425.534647
Average total loss: 0.107689
tensor(-1.8665, device='cuda:0') tensor(0.2138, device='cuda:0') tensor(1.1724e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.079684
Average KL loss: 28289.189858
Average total loss: 0.107973
tensor(-1.8681, device='cuda:0') tensor(0.2136, device='cuda:0') tensor(1.0447e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.079204
Average KL loss: 28154.328724
Average total loss: 0.107359
tensor(-1.8696, device='cuda:0') tensor(0.2132, device='cuda:0') tensor(9.6698e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.078925
Average KL loss: 28008.560022
Average total loss: 0.106934
tensor(-1.8711, device='cuda:0') tensor(0.2128, device='cuda:0') tensor(9.8015e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.080122
Average KL loss: 27857.302470
Average total loss: 0.107980
tensor(-1.8725, device='cuda:0') tensor(0.2124, device='cuda:0') tensor(3.7502e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.079239
Average KL loss: 27748.146859
Average total loss: 0.106987
tensor(-1.8739, device='cuda:0') tensor(0.2123, device='cuda:0') tensor(1.1850e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.079592
Average KL loss: 27632.073410
Average total loss: 0.107224
tensor(-1.8753, device='cuda:0') tensor(0.2123, device='cuda:0') tensor(9.8229e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.078656
Average KL loss: 27546.815937
Average total loss: 0.106203
tensor(-1.8767, device='cuda:0') tensor(0.2124, device='cuda:0') tensor(1.1865e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.078582
Average KL loss: 27436.575368
Average total loss: 0.106018
tensor(-1.8780, device='cuda:0') tensor(0.2121, device='cuda:0') tensor(1.1619e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.078086
Average KL loss: 27316.388507
Average total loss: 0.105403
tensor(-1.8793, device='cuda:0') tensor(0.2118, device='cuda:0') tensor(8.3459e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.079498
Average KL loss: 27200.220948
Average total loss: 0.106698
tensor(-1.8807, device='cuda:0') tensor(0.2117, device='cuda:0') tensor(4.1764e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.078821
Average KL loss: 27107.016224
Average total loss: 0.105928
tensor(-1.8819, device='cuda:0') tensor(0.2117, device='cuda:0') tensor(8.8696e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.078357
Average KL loss: 27013.622003
Average total loss: 0.105371
tensor(-1.8831, device='cuda:0') tensor(0.2115, device='cuda:0') tensor(8.0620e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.078629
Average KL loss: 26907.754835
Average total loss: 0.105536
tensor(-1.8843, device='cuda:0') tensor(0.2114, device='cuda:0') tensor(9.5967e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.077436
Average KL loss: 26811.855459
Average total loss: 0.104248
tensor(-1.8854, device='cuda:0') tensor(0.2113, device='cuda:0') tensor(7.2519e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.078921
Average KL loss: 26727.656290
Average total loss: 0.105649
 Percentile value: -1.7698729276657104
Non-zero model percentage: 20.000003814697266%, Non-zero mask percentage: 20.000003814697266%

--- Pruning Level [1/8]: ---
conv1.weight         | nonzeros =    1617 /    1728             ( 93.58%) | total_pruned =     111 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   27525 /   36864             ( 74.67%) | total_pruned =    9339 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   27051 /   36864             ( 73.38%) | total_pruned =    9813 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   26059 /   36864             ( 70.69%) | total_pruned =   10805 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   24183 /   36864             ( 65.60%) | total_pruned =   12681 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   46741 /   73728             ( 63.40%) | total_pruned =   26987 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   77976 /  147456             ( 52.88%) | total_pruned =   69480 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    6806 /    8192             ( 83.08%) | total_pruned =    1386 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   70857 /  147456             ( 48.05%) | total_pruned =   76599 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   69643 /  147456             ( 47.23%) | total_pruned =   77813 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  133352 /  294912             ( 45.22%) | total_pruned =  161560 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     180 /     256             ( 70.31%) | total_pruned =      76 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  210189 /  589824             ( 35.64%) | total_pruned =  379635 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   23779 /   32768             ( 72.57%) | total_pruned =    8989 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  187074 /  589824             ( 31.72%) | total_pruned =  402750 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  176092 /  589824             ( 29.86%) | total_pruned =  413732 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     167 /     256             ( 65.23%) | total_pruned =      89 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  283658 / 1179648             ( 24.05%) | total_pruned =  895990 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     387 /     512             ( 75.59%) | total_pruned =     125 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  303597 / 2359296             ( 12.87%) | total_pruned = 2055699 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      75 /     512             ( 14.65%) | total_pruned =     437 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   66354 /  131072             ( 50.62%) | total_pruned =   64718 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      76 /     512             ( 14.84%) | total_pruned =     436 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  249906 / 2359296             ( 10.59%) | total_pruned = 2109390 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     463 /     512             ( 90.43%) | total_pruned =      49 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     416 /     512             ( 81.25%) | total_pruned =      96 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  210835 / 2359296             (  8.94%) | total_pruned = 2148461 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    4716 /    5120             ( 92.11%) | total_pruned =     404 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       8 /      10             ( 80.00%) | total_pruned =       2 | shape = torch.Size([10])
alive: 2235753, pruned : 8943009, total: 11178762, Compression rate :       5.00x  ( 80.00% pruned)
Train Epoch: 99/100 Loss: 0.002354 Accuracy: 87.07% Best Accuracy: 87.07%
tensor(-1.8865, device='cuda:0') tensor(0.2113, device='cuda:0') tensor(-1.2673e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.163495
Average KL loss: 24634.725863
Average total loss: 0.188130
tensor(-1.8704, device='cuda:0') tensor(0.1764, device='cuda:0') tensor(-1.4759e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.145795
Average KL loss: 23965.479020
Average total loss: 0.169760
tensor(-1.8652, device='cuda:0') tensor(0.1752, device='cuda:0') tensor(-9.9048e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.136624
Average KL loss: 24167.099544
Average total loss: 0.160791
tensor(-1.8657, device='cuda:0') tensor(0.1782, device='cuda:0') tensor(-7.1064e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.130805
Average KL loss: 24497.999760
Average total loss: 0.155303
tensor(-1.8669, device='cuda:0') tensor(0.1817, device='cuda:0') tensor(-5.3134e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.123259
Average KL loss: 24826.235334
Average total loss: 0.148085
tensor(-1.8682, device='cuda:0') tensor(0.1850, device='cuda:0') tensor(-6.7177e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.120341
Average KL loss: 25113.062700
Average total loss: 0.145454
tensor(-1.8695, device='cuda:0') tensor(0.1879, device='cuda:0') tensor(3.2656e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.118790
Average KL loss: 25384.260590
Average total loss: 0.144174
tensor(-1.8706, device='cuda:0') tensor(0.1908, device='cuda:0') tensor(1.2613e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.115216
Average KL loss: 25639.551471
Average total loss: 0.140855
tensor(-1.8718, device='cuda:0') tensor(0.1933, device='cuda:0') tensor(-9.5042e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.113338
Average KL loss: 25862.356018
Average total loss: 0.139200
tensor(-1.8730, device='cuda:0') tensor(0.1957, device='cuda:0') tensor(-1.1265e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.111328
Average KL loss: 26075.282409
Average total loss: 0.137403
tensor(-1.8741, device='cuda:0') tensor(0.1979, device='cuda:0') tensor(-1.5190e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.110000
Average KL loss: 26258.083760
Average total loss: 0.136259
tensor(-1.8752, device='cuda:0') tensor(0.1999, device='cuda:0') tensor(-1.4532e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.108210
Average KL loss: 26426.912444
Average total loss: 0.134636
tensor(-1.8763, device='cuda:0') tensor(0.2019, device='cuda:0') tensor(1.5675e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.107096
Average KL loss: 26583.813099
Average total loss: 0.133680
tensor(-1.8773, device='cuda:0') tensor(0.2037, device='cuda:0') tensor(-4.4377e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.105538
Average KL loss: 26717.804987
Average total loss: 0.132255
tensor(-1.8784, device='cuda:0') tensor(0.2052, device='cuda:0') tensor(3.3538e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.104298
Average KL loss: 26808.893782
Average total loss: 0.131107
tensor(-1.8795, device='cuda:0') tensor(0.2065, device='cuda:0') tensor(2.7353e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.103411
Average KL loss: 26899.465713
Average total loss: 0.130311
tensor(-1.8805, device='cuda:0') tensor(0.2080, device='cuda:0') tensor(1.2714e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.104301
Average KL loss: 27025.824129
Average total loss: 0.131326
tensor(-1.8814, device='cuda:0') tensor(0.2096, device='cuda:0') tensor(3.9083e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.102313
Average KL loss: 27121.521739
Average total loss: 0.129435
tensor(-1.8823, device='cuda:0') tensor(0.2108, device='cuda:0') tensor(3.2294e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.102000
Average KL loss: 27187.229739
Average total loss: 0.129187
tensor(-1.8832, device='cuda:0') tensor(0.2121, device='cuda:0') tensor(4.2719e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.101788
Average KL loss: 27252.374041
Average total loss: 0.129040
tensor(-1.8842, device='cuda:0') tensor(0.2133, device='cuda:0') tensor(-2.4010e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.100829
Average KL loss: 27318.584119
Average total loss: 0.128148
tensor(-1.8851, device='cuda:0') tensor(0.2144, device='cuda:0') tensor(3.8209e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.101027
Average KL loss: 27366.958800
Average total loss: 0.128394
tensor(-1.8859, device='cuda:0') tensor(0.2154, device='cuda:0') tensor(1.3704e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.099470
Average KL loss: 27404.905850
Average total loss: 0.126875
tensor(-1.8868, device='cuda:0') tensor(0.2164, device='cuda:0') tensor(2.5473e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.100173
Average KL loss: 27440.255355
Average total loss: 0.127613
tensor(-1.8876, device='cuda:0') tensor(0.2174, device='cuda:0') tensor(3.0070e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.099493
Average KL loss: 27480.385390
Average total loss: 0.126974
tensor(-1.8884, device='cuda:0') tensor(0.2184, device='cuda:0') tensor(3.3387e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.099267
Average KL loss: 27525.390425
Average total loss: 0.126793
tensor(-1.8892, device='cuda:0') tensor(0.2194, device='cuda:0') tensor(3.4981e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.097806
Average KL loss: 27538.125440
Average total loss: 0.125344
tensor(-1.8900, device='cuda:0') tensor(0.2201, device='cuda:0') tensor(4.3685e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.098222
Average KL loss: 27546.803629
Average total loss: 0.125768
tensor(-1.8907, device='cuda:0') tensor(0.2210, device='cuda:0') tensor(5.1570e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.096760
Average KL loss: 27560.973386
Average total loss: 0.124321
tensor(-1.8915, device='cuda:0') tensor(0.2217, device='cuda:0') tensor(2.2447e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.097417
Average KL loss: 27561.735654
Average total loss: 0.124979
tensor(-1.8922, device='cuda:0') tensor(0.2225, device='cuda:0') tensor(4.3957e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.096038
Average KL loss: 27552.441576
Average total loss: 0.123591
tensor(-1.8929, device='cuda:0') tensor(0.2231, device='cuda:0') tensor(1.9236e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.096558
Average KL loss: 27559.192176
Average total loss: 0.124117
tensor(-1.8936, device='cuda:0') tensor(0.2239, device='cuda:0') tensor(3.4947e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.096867
Average KL loss: 27568.549512
Average total loss: 0.124436
tensor(-1.8942, device='cuda:0') tensor(0.2246, device='cuda:0') tensor(2.8143e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.096077
Average KL loss: 27575.357457
Average total loss: 0.123653
tensor(-1.8949, device='cuda:0') tensor(0.2254, device='cuda:0') tensor(3.7032e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.096948
Average KL loss: 27596.301391
Average total loss: 0.124544
tensor(-1.8954, device='cuda:0') tensor(0.2264, device='cuda:0') tensor(1.5748e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.096042
Average KL loss: 27639.108256
Average total loss: 0.123681
tensor(-1.8960, device='cuda:0') tensor(0.2273, device='cuda:0') tensor(3.5451e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.095161
Average KL loss: 27644.718111
Average total loss: 0.122806
tensor(-1.8966, device='cuda:0') tensor(0.2280, device='cuda:0') tensor(1.4477e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.095197
Average KL loss: 27644.304668
Average total loss: 0.122841
tensor(-1.8972, device='cuda:0') tensor(0.2286, device='cuda:0') tensor(4.2631e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.094982
Average KL loss: 27646.896619
Average total loss: 0.122629
tensor(-1.8978, device='cuda:0') tensor(0.2294, device='cuda:0') tensor(2.5358e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.094238
Average KL loss: 27650.972027
Average total loss: 0.121888
tensor(-1.8984, device='cuda:0') tensor(0.2300, device='cuda:0') tensor(5.8491e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.094251
Average KL loss: 27629.389266
Average total loss: 0.121880
tensor(-1.8989, device='cuda:0') tensor(0.2305, device='cuda:0') tensor(2.5821e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.093954
Average KL loss: 27625.971667
Average total loss: 0.121580
tensor(-1.8995, device='cuda:0') tensor(0.2312, device='cuda:0') tensor(6.3585e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.093801
Average KL loss: 27613.095828
Average total loss: 0.121414
tensor(-1.9000, device='cuda:0') tensor(0.2317, device='cuda:0') tensor(4.4932e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.094162
Average KL loss: 27610.235534
Average total loss: 0.121772
tensor(-1.9005, device='cuda:0') tensor(0.2325, device='cuda:0') tensor(3.9320e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.094889
Average KL loss: 27627.115849
Average total loss: 0.122516
tensor(-1.9010, device='cuda:0') tensor(0.2334, device='cuda:0') tensor(1.2771e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.094050
Average KL loss: 27644.596707
Average total loss: 0.121695
tensor(-1.9015, device='cuda:0') tensor(0.2341, device='cuda:0') tensor(2.3773e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.093812
Average KL loss: 27651.813899
Average total loss: 0.121464
tensor(-1.9019, device='cuda:0') tensor(0.2349, device='cuda:0') tensor(3.5707e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.093712
Average KL loss: 27665.388387
Average total loss: 0.121378
tensor(-1.9024, device='cuda:0') tensor(0.2356, device='cuda:0') tensor(4.6136e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.093755
Average KL loss: 27674.046435
Average total loss: 0.121429
tensor(-1.9028, device='cuda:0') tensor(0.2363, device='cuda:0') tensor(-1.8250e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.094159
Average KL loss: 27680.439938
Average total loss: 0.121840
tensor(-1.9033, device='cuda:0') tensor(0.2371, device='cuda:0') tensor(8.0098e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.093426
Average KL loss: 27687.866288
Average total loss: 0.121114
tensor(-1.9037, device='cuda:0') tensor(0.2377, device='cuda:0') tensor(1.2229e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.093713
Average KL loss: 27682.574688
Average total loss: 0.121395
tensor(-1.9041, device='cuda:0') tensor(0.2384, device='cuda:0') tensor(2.3066e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.093453
Average KL loss: 27688.889027
Average total loss: 0.121141
tensor(-1.9046, device='cuda:0') tensor(0.2390, device='cuda:0') tensor(2.1944e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.092825
Average KL loss: 27689.979020
Average total loss: 0.120515
tensor(-1.9050, device='cuda:0') tensor(0.2397, device='cuda:0') tensor(1.1704e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.092385
Average KL loss: 27695.185382
Average total loss: 0.120080
tensor(-1.9054, device='cuda:0') tensor(0.2404, device='cuda:0') tensor(2.1621e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.092783
Average KL loss: 27698.460598
Average total loss: 0.120481
tensor(-1.9058, device='cuda:0') tensor(0.2411, device='cuda:0') tensor(-4.8571e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.092409
Average KL loss: 27708.087836
Average total loss: 0.120118
tensor(-1.9061, device='cuda:0') tensor(0.2418, device='cuda:0') tensor(2.3517e-11, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.092459
Average KL loss: 27709.240249
Average total loss: 0.120168
tensor(-1.9065, device='cuda:0') tensor(0.2425, device='cuda:0') tensor(4.7035e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.091042
Average KL loss: 27706.831242
Average total loss: 0.118748
tensor(-1.9069, device='cuda:0') tensor(0.2430, device='cuda:0') tensor(3.6250e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.092846
Average KL loss: 27705.566456
Average total loss: 0.120552
tensor(-1.9073, device='cuda:0') tensor(0.2438, device='cuda:0') tensor(3.8161e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.093601
Average KL loss: 27718.549233
Average total loss: 0.121320
tensor(-1.9076, device='cuda:0') tensor(0.2445, device='cuda:0') tensor(1.1246e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.091910
Average KL loss: 27719.651574
Average total loss: 0.119630
tensor(-1.9079, device='cuda:0') tensor(0.2452, device='cuda:0') tensor(3.8797e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.091439
Average KL loss: 27729.496124
Average total loss: 0.119169
tensor(-1.9083, device='cuda:0') tensor(0.2459, device='cuda:0') tensor(4.0638e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.092157
Average KL loss: 27730.217831
Average total loss: 0.119887
tensor(-1.9086, device='cuda:0') tensor(0.2465, device='cuda:0') tensor(1.5942e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.092593
Average KL loss: 27745.443215
Average total loss: 0.120339
tensor(-1.9089, device='cuda:0') tensor(0.2472, device='cuda:0') tensor(2.5161e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.091673
Average KL loss: 27740.999680
Average total loss: 0.119414
tensor(-1.9093, device='cuda:0') tensor(0.2478, device='cuda:0') tensor(2.5941e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.092170
Average KL loss: 27740.341672
Average total loss: 0.119910
tensor(-1.9096, device='cuda:0') tensor(0.2485, device='cuda:0') tensor(2.7936e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.092493
Average KL loss: 27744.795876
Average total loss: 0.120238
tensor(-1.9099, device='cuda:0') tensor(0.2492, device='cuda:0') tensor(1.7275e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.092043
Average KL loss: 27734.382593
Average total loss: 0.119778
tensor(-1.9103, device='cuda:0') tensor(0.2497, device='cuda:0') tensor(2.9362e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.091978
Average KL loss: 27737.840074
Average total loss: 0.119715
tensor(-1.9106, device='cuda:0') tensor(0.2504, device='cuda:0') tensor(7.4874e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.090948
Average KL loss: 27734.280211
Average total loss: 0.118683
tensor(-1.9108, device='cuda:0') tensor(0.2510, device='cuda:0') tensor(2.1995e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.090546
Average KL loss: 27736.806985
Average total loss: 0.118283
tensor(-1.9111, device='cuda:0') tensor(0.2517, device='cuda:0') tensor(3.8290e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.091037
Average KL loss: 27743.328924
Average total loss: 0.118780
tensor(-1.9114, device='cuda:0') tensor(0.2523, device='cuda:0') tensor(3.3316e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.091940
Average KL loss: 27742.102462
Average total loss: 0.119682
tensor(-1.9117, device='cuda:0') tensor(0.2530, device='cuda:0') tensor(1.8211e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.090740
Average KL loss: 27754.486733
Average total loss: 0.118494
tensor(-1.9119, device='cuda:0') tensor(0.2537, device='cuda:0') tensor(2.4451e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.090667
Average KL loss: 27768.072970
Average total loss: 0.118435
tensor(-1.9122, device='cuda:0') tensor(0.2544, device='cuda:0') tensor(2.2310e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.091829
Average KL loss: 27777.739250
Average total loss: 0.119607
tensor(-1.9124, device='cuda:0') tensor(0.2551, device='cuda:0') tensor(6.6133e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.091864
Average KL loss: 27787.287124
Average total loss: 0.119651
tensor(-1.9127, device='cuda:0') tensor(0.2558, device='cuda:0') tensor(1.4580e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.090617
Average KL loss: 27781.628756
Average total loss: 0.118399
tensor(-1.9130, device='cuda:0') tensor(0.2564, device='cuda:0') tensor(1.3019e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.091766
Average KL loss: 27793.374121
Average total loss: 0.119559
tensor(-1.9132, device='cuda:0') tensor(0.2572, device='cuda:0') tensor(3.7211e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.090921
Average KL loss: 27803.429348
Average total loss: 0.118725
tensor(-1.9134, device='cuda:0') tensor(0.2577, device='cuda:0') tensor(2.7353e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.090201
Average KL loss: 27790.469230
Average total loss: 0.117992
tensor(-1.9137, device='cuda:0') tensor(0.2582, device='cuda:0') tensor(3.8074e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.090163
Average KL loss: 27758.467551
Average total loss: 0.117921
tensor(-1.9139, device='cuda:0') tensor(0.2586, device='cuda:0') tensor(2.5434e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.091492
Average KL loss: 27773.961597
Average total loss: 0.119266
tensor(-1.9141, device='cuda:0') tensor(0.2595, device='cuda:0') tensor(1.4663e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.091256
Average KL loss: 27789.166121
Average total loss: 0.119045
tensor(-1.9144, device='cuda:0') tensor(0.2601, device='cuda:0') tensor(-1.7767e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.090640
Average KL loss: 27778.325048
Average total loss: 0.118418
tensor(-1.9146, device='cuda:0') tensor(0.2606, device='cuda:0') tensor(4.5313e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.089236
Average KL loss: 27767.328045
Average total loss: 0.117003
tensor(-1.9148, device='cuda:0') tensor(0.2611, device='cuda:0') tensor(2.6042e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.091269
Average KL loss: 27768.160726
Average total loss: 0.119038
tensor(-1.9150, device='cuda:0') tensor(0.2619, device='cuda:0') tensor(1.8300e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.089996
Average KL loss: 27795.738211
Average total loss: 0.117792
tensor(-1.9152, device='cuda:0') tensor(0.2627, device='cuda:0') tensor(-1.7679e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.090924
Average KL loss: 27810.271100
Average total loss: 0.118734
tensor(-1.9154, device='cuda:0') tensor(0.2634, device='cuda:0') tensor(2.0514e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.090438
Average KL loss: 27818.452206
Average total loss: 0.118257
tensor(-1.9156, device='cuda:0') tensor(0.2640, device='cuda:0') tensor(1.5905e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.090617
Average KL loss: 27822.383951
Average total loss: 0.118439
tensor(-1.9158, device='cuda:0') tensor(0.2647, device='cuda:0') tensor(9.1045e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.089531
Average KL loss: 27818.581282
Average total loss: 0.117349
tensor(-1.9160, device='cuda:0') tensor(0.2651, device='cuda:0') tensor(5.1419e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.090409
Average KL loss: 27801.953245
Average total loss: 0.118211
tensor(-1.9162, device='cuda:0') tensor(0.2657, device='cuda:0') tensor(3.8279e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.090396
Average KL loss: 27816.141904
Average total loss: 0.118212
tensor(-1.9164, device='cuda:0') tensor(0.2664, device='cuda:0') tensor(8.0618e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.089577
Average KL loss: 27828.482896
Average total loss: 0.117405
tensor(-1.9166, device='cuda:0') tensor(0.2671, device='cuda:0') tensor(1.3329e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.088950
Average KL loss: 27837.940857
Average total loss: 0.116788
tensor(-1.9167, device='cuda:0') tensor(0.2678, device='cuda:0') tensor(-5.2264e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.089249
Average KL loss: 27818.296755
Average total loss: 0.117067
tensor(-1.9170, device='cuda:0') tensor(0.2680, device='cuda:0') tensor(3.6858e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.090011
Average KL loss: 27793.865249
Average total loss: 0.117805
tensor(-1.9172, device='cuda:0') tensor(0.2685, device='cuda:0') tensor(1.2981e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.090230
Average KL loss: 27787.938299
Average total loss: 0.118018
 Percentile value: -1.0945727348327636
Non-zero model percentage: 4.000004291534424%, Non-zero mask percentage: 4.000004291534424%

--- Pruning Level [2/8]: ---
conv1.weight         | nonzeros =    1341 /    1728             ( 77.60%) | total_pruned =     387 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    8881 /   36864             ( 24.09%) | total_pruned =   27983 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    9206 /   36864             ( 24.97%) | total_pruned =   27658 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    8227 /   36864             ( 22.32%) | total_pruned =   28637 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    7260 /   36864             ( 19.69%) | total_pruned =   29604 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13841 /   73728             ( 18.77%) | total_pruned =   59887 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   21007 /  147456             ( 14.25%) | total_pruned =  126449 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4008 /    8192             ( 48.93%) | total_pruned =    4184 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   14088 /  147456             (  9.55%) | total_pruned =  133368 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   15110 /  147456             ( 10.25%) | total_pruned =  132346 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   33554 /  294912             ( 11.38%) | total_pruned =  261358 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      73 /     256             ( 28.52%) | total_pruned =     183 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   45300 /  589824             (  7.68%) | total_pruned =  544524 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   10283 /   32768             ( 31.38%) | total_pruned =   22485 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     111 /     256             ( 43.36%) | total_pruned =     145 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   34044 /  589824             (  5.77%) | total_pruned =  555780 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   31596 /  589824             (  5.36%) | total_pruned =  558228 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   40138 / 1179648             (  3.40%) | total_pruned = 1139510 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      76 /     512             ( 14.84%) | total_pruned =     436 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   38827 / 2359296             (  1.65%) | total_pruned = 2320469 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   14665 /  131072             ( 11.19%) | total_pruned =  116407 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   32585 / 2359296             (  1.38%) | total_pruned = 2326711 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     448 /     512             ( 87.50%) | total_pruned =      64 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   52733 / 2359296             (  2.24%) | total_pruned = 2306563 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    4290 /    5120             ( 83.79%) | total_pruned =     830 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 447151, pruned : 10731611, total: 11178762, Compression rate :      25.00x  ( 96.00% pruned)
Train Epoch: 85/100 Loss: 0.001419 Accuracy: 87.22% Best Accuracy: 87.25%
tensor(-1.9174, device='cuda:0') tensor(0.2691, device='cuda:0') tensor(2.4758e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.300356
Average KL loss: 24537.105579
Average total loss: 0.324893
tensor(-1.9302, device='cuda:0') tensor(0.2185, device='cuda:0') tensor(1.7534e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.300076
Average KL loss: 21008.571891
Average total loss: 0.321085
tensor(-1.9343, device='cuda:0') tensor(0.1973, device='cuda:0') tensor(1.8006e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.296525
Average KL loss: 19145.314658
Average total loss: 0.315671
tensor(-1.9367, device='cuda:0') tensor(0.1848, device='cuda:0') tensor(1.2849e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.296704
Average KL loss: 17859.094869
Average total loss: 0.314563
tensor(-1.9390, device='cuda:0') tensor(0.1761, device='cuda:0') tensor(1.1799e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.294403
Average KL loss: 16860.642303
Average total loss: 0.311264
tensor(-1.9411, device='cuda:0') tensor(0.1693, device='cuda:0') tensor(1.1757e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.295413
Average KL loss: 16052.228660
Average total loss: 0.311465
tensor(-1.9431, device='cuda:0') tensor(0.1637, device='cuda:0') tensor(9.9673e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.294080
Average KL loss: 15372.836037
Average total loss: 0.309453
tensor(-1.9449, device='cuda:0') tensor(0.1588, device='cuda:0') tensor(1.0277e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.293856
Average KL loss: 14774.966892
Average total loss: 0.308631
tensor(-1.9466, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(1.0304e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.293303
Average KL loss: 14235.493107
Average total loss: 0.307539
tensor(-1.9481, device='cuda:0') tensor(0.1503, device='cuda:0') tensor(1.0758e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.292896
Average KL loss: 13747.992967
Average total loss: 0.306644
tensor(-1.9495, device='cuda:0') tensor(0.1466, device='cuda:0') tensor(9.7446e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.292984
Average KL loss: 13301.739130
Average total loss: 0.306286
tensor(-1.9508, device='cuda:0') tensor(0.1430, device='cuda:0') tensor(8.9743e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.291995
Average KL loss: 12886.529512
Average total loss: 0.304882
tensor(-1.9520, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(9.4111e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.291597
Average KL loss: 12502.473266
Average total loss: 0.304100
tensor(-1.9531, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(8.6763e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.292262
Average KL loss: 12140.575987
Average total loss: 0.304403
tensor(-1.9542, device='cuda:0') tensor(0.1337, device='cuda:0') tensor(8.7628e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.291318
Average KL loss: 11802.072251
Average total loss: 0.303121
tensor(-1.9552, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(8.2200e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.291845
Average KL loss: 11478.973426
Average total loss: 0.303324
tensor(-1.9562, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(7.1347e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.290747
Average KL loss: 11172.596288
Average total loss: 0.301920
tensor(-1.9571, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(7.3910e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.290953
Average KL loss: 10879.869805
Average total loss: 0.301833
tensor(-1.9580, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(6.6113e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.290761
Average KL loss: 10597.220508
Average total loss: 0.301358
tensor(-1.9589, device='cuda:0') tensor(0.1205, device='cuda:0') tensor(6.7636e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.290033
Average KL loss: 10329.000619
Average total loss: 0.300362
tensor(-1.9597, device='cuda:0') tensor(0.1181, device='cuda:0') tensor(8.1700e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.290527
Average KL loss: 10071.092112
Average total loss: 0.300598
tensor(-1.9606, device='cuda:0') tensor(0.1158, device='cuda:0') tensor(6.3740e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.290164
Average KL loss: 9825.085238
Average total loss: 0.299989
tensor(-1.9614, device='cuda:0') tensor(0.1135, device='cuda:0') tensor(6.9855e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.289925
Average KL loss: 9586.865409
Average total loss: 0.299511
tensor(-1.9621, device='cuda:0') tensor(0.1113, device='cuda:0') tensor(6.1214e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.289716
Average KL loss: 9359.144561
Average total loss: 0.299076
tensor(-1.9628, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(5.9035e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.289801
Average KL loss: 9136.350504
Average total loss: 0.298937
tensor(-1.9636, device='cuda:0') tensor(0.1070, device='cuda:0') tensor(6.2976e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.289655
Average KL loss: 8920.442016
Average total loss: 0.298575
tensor(-1.9643, device='cuda:0') tensor(0.1049, device='cuda:0') tensor(7.5560e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.289435
Average KL loss: 8712.889066
Average total loss: 0.298148
tensor(-1.9650, device='cuda:0') tensor(0.1029, device='cuda:0') tensor(5.4428e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.289363
Average KL loss: 8516.057145
Average total loss: 0.297879
tensor(-1.9656, device='cuda:0') tensor(0.1010, device='cuda:0') tensor(6.3842e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.288926
Average KL loss: 8325.669677
Average total loss: 0.297252
tensor(-1.9663, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(5.2898e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.289130
Average KL loss: 8140.439908
Average total loss: 0.297270
tensor(-1.9669, device='cuda:0') tensor(0.0972, device='cuda:0') tensor(5.7010e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.289097
Average KL loss: 7961.818404
Average total loss: 0.297059
tensor(-1.9675, device='cuda:0') tensor(0.0954, device='cuda:0') tensor(4.9957e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.289179
Average KL loss: 7789.912624
Average total loss: 0.296969
tensor(-1.9681, device='cuda:0') tensor(0.0936, device='cuda:0') tensor(5.3527e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.288955
Average KL loss: 7620.014296
Average total loss: 0.296575
tensor(-1.9687, device='cuda:0') tensor(0.0919, device='cuda:0') tensor(4.7375e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.289017
Average KL loss: 7461.765076
Average total loss: 0.296479
tensor(-1.9693, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(4.7459e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.288928
Average KL loss: 7308.920726
Average total loss: 0.296237
tensor(-1.9698, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(5.7043e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.288710
Average KL loss: 7160.629895
Average total loss: 0.295871
tensor(-1.9704, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(4.4676e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.288851
Average KL loss: 7021.101413
Average total loss: 0.295872
tensor(-1.9709, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(4.0177e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.288690
Average KL loss: 6886.205243
Average total loss: 0.295576
tensor(-1.9714, device='cuda:0') tensor(0.0842, device='cuda:0') tensor(3.9949e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.288604
Average KL loss: 6760.203265
Average total loss: 0.295365
tensor(-1.9719, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(4.0935e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.288315
Average KL loss: 6637.629855
Average total loss: 0.294953
tensor(-1.9724, device='cuda:0') tensor(0.0816, device='cuda:0') tensor(3.6798e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.288464
Average KL loss: 6524.419857
Average total loss: 0.294989
tensor(-1.9729, device='cuda:0') tensor(0.0804, device='cuda:0') tensor(3.2924e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.288379
Average KL loss: 6410.662794
Average total loss: 0.294790
tensor(-1.9733, device='cuda:0') tensor(0.0792, device='cuda:0') tensor(3.6388e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.288126
Average KL loss: 6308.437330
Average total loss: 0.294434
tensor(-1.9737, device='cuda:0') tensor(0.0781, device='cuda:0') tensor(3.7248e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.287916
Average KL loss: 6214.442006
Average total loss: 0.294130
tensor(-1.9742, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(3.4647e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.287884
Average KL loss: 6124.450488
Average total loss: 0.294009
tensor(-1.9746, device='cuda:0') tensor(0.0762, device='cuda:0') tensor(2.9999e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.287685
Average KL loss: 6043.828754
Average total loss: 0.293729
tensor(-1.9749, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(3.0557e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.287609
Average KL loss: 5968.270780
Average total loss: 0.293577
tensor(-1.9753, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(3.1543e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.287263
Average KL loss: 5904.426730
Average total loss: 0.293168
tensor(-1.9757, device='cuda:0') tensor(0.0739, device='cuda:0') tensor(3.3847e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.287065
Average KL loss: 5849.949908
Average total loss: 0.292915
tensor(-1.9760, device='cuda:0') tensor(0.0734, device='cuda:0') tensor(2.7037e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.286978
Average KL loss: 5806.862732
Average total loss: 0.292785
tensor(-1.9763, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(1.7904e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.286598
Average KL loss: 5775.192445
Average total loss: 0.292374
tensor(-1.9766, device='cuda:0') tensor(0.0726, device='cuda:0') tensor(1.8051e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.286153
Average KL loss: 5758.115129
Average total loss: 0.291911
tensor(-1.9768, device='cuda:0') tensor(0.0724, device='cuda:0') tensor(2.1965e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.285983
Average KL loss: 5750.043468
Average total loss: 0.291733
tensor(-1.9771, device='cuda:0') tensor(0.0724, device='cuda:0') tensor(2.2213e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.285098
Average KL loss: 5764.278962
Average total loss: 0.290862
tensor(-1.9773, device='cuda:0') tensor(0.0726, device='cuda:0') tensor(1.8636e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.285343
Average KL loss: 5783.911435
Average total loss: 0.291127
tensor(-1.9775, device='cuda:0') tensor(0.0728, device='cuda:0') tensor(2.1789e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.284652
Average KL loss: 5817.715663
Average total loss: 0.290469
tensor(-1.9777, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(3.1610e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.284526
Average KL loss: 5851.150296
Average total loss: 0.290377
tensor(-1.9779, device='cuda:0') tensor(0.0735, device='cuda:0') tensor(-3.1260e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.283333
Average KL loss: 5904.161565
Average total loss: 0.289238
tensor(-1.9780, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(1.8197e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.282991
Average KL loss: 5967.260390
Average total loss: 0.288959
tensor(-1.9781, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(-2.5913e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.282887
Average KL loss: 6033.681676
Average total loss: 0.288921
tensor(-1.9783, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(-2.5606e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.281339
Average KL loss: 6099.825088
Average total loss: 0.287438
tensor(-1.9784, device='cuda:0') tensor(0.0763, device='cuda:0') tensor(-6.8956e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.281848
Average KL loss: 6182.629656
Average total loss: 0.288030
tensor(-1.9785, device='cuda:0') tensor(0.0769, device='cuda:0') tensor(-8.6065e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.280415
Average KL loss: 6249.632013
Average total loss: 0.286664
tensor(-1.9786, device='cuda:0') tensor(0.0777, device='cuda:0') tensor(-7.6923e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.279367
Average KL loss: 6328.209759
Average total loss: 0.285695
tensor(-1.9787, device='cuda:0') tensor(0.0786, device='cuda:0') tensor(-2.2575e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.279735
Average KL loss: 6402.318654
Average total loss: 0.286137
tensor(-1.9788, device='cuda:0') tensor(0.0793, device='cuda:0') tensor(2.7667e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.280002
Average KL loss: 6457.860874
Average total loss: 0.286460
tensor(-1.9790, device='cuda:0') tensor(0.0800, device='cuda:0') tensor(1.5376e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.278950
Average KL loss: 6514.785186
Average total loss: 0.285464
tensor(-1.9791, device='cuda:0') tensor(0.0807, device='cuda:0') tensor(4.1437e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.278458
Average KL loss: 6576.504695
Average total loss: 0.285035
tensor(-1.9792, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(7.2492e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.279014
Average KL loss: 6633.307275
Average total loss: 0.285647
tensor(-1.9793, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(1.6279e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.278408
Average KL loss: 6658.869635
Average total loss: 0.285067
tensor(-1.9795, device='cuda:0') tensor(0.0823, device='cuda:0') tensor(2.1415e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.276174
Average KL loss: 6710.582771
Average total loss: 0.282884
tensor(-1.9795, device='cuda:0') tensor(0.0830, device='cuda:0') tensor(2.5750e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.278614
Average KL loss: 6755.002288
Average total loss: 0.285369
tensor(-1.9796, device='cuda:0') tensor(0.0834, device='cuda:0') tensor(-1.8368e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.276026
Average KL loss: 6794.940517
Average total loss: 0.282821
tensor(-1.9797, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(3.5207e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.277142
Average KL loss: 6839.429498
Average total loss: 0.283982
tensor(-1.9798, device='cuda:0') tensor(0.0845, device='cuda:0') tensor(7.8060e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.276827
Average KL loss: 6878.240459
Average total loss: 0.283705
tensor(-1.9799, device='cuda:0') tensor(0.0849, device='cuda:0') tensor(-2.2881e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.277173
Average KL loss: 6888.898827
Average total loss: 0.284062
tensor(-1.9801, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(2.0536e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.278039
Average KL loss: 6911.871823
Average total loss: 0.284951
tensor(-1.9802, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-2.1316e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.275739
Average KL loss: 6931.955792
Average total loss: 0.282671
tensor(-1.9803, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-1.7555e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.274981
Average KL loss: 6966.859865
Average total loss: 0.281948
tensor(-1.9804, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(8.4757e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.277223
Average KL loss: 6993.961777
Average total loss: 0.284217
tensor(-1.9805, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(1.4538e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.275973
Average KL loss: 7004.907079
Average total loss: 0.282978
tensor(-1.9806, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(3.3316e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.275518
Average KL loss: 7033.836817
Average total loss: 0.282552
tensor(-1.9807, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-4.0221e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.275772
Average KL loss: 7056.704544
Average total loss: 0.282829
tensor(-1.9808, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(-3.3926e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.274833
Average KL loss: 7092.262528
Average total loss: 0.281925
tensor(-1.9808, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(1.0281e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.273252
Average KL loss: 7110.932025
Average total loss: 0.280363
tensor(-1.9809, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-7.7429e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.275119
Average KL loss: 7137.737572
Average total loss: 0.282257
tensor(-1.9810, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-1.3397e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.274185
Average KL loss: 7160.077685
Average total loss: 0.281345
tensor(-1.9810, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-6.9785e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.273865
Average KL loss: 7171.693724
Average total loss: 0.281037
tensor(-1.9811, device='cuda:0') tensor(0.0896, device='cuda:0') tensor(2.8741e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.273380
Average KL loss: 7199.995874
Average total loss: 0.280580
tensor(-1.9812, device='cuda:0') tensor(0.0900, device='cuda:0') tensor(3.4921e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.275095
Average KL loss: 7224.566706
Average total loss: 0.282319
tensor(-1.9813, device='cuda:0') tensor(0.0903, device='cuda:0') tensor(1.0109e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.275394
Average KL loss: 7235.084509
Average total loss: 0.282629
tensor(-1.9814, device='cuda:0') tensor(0.0905, device='cuda:0') tensor(-5.0847e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.274765
Average KL loss: 7237.704354
Average total loss: 0.282002
tensor(-1.9815, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(4.0093e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.273254
Average KL loss: 7240.566806
Average total loss: 0.280494
tensor(-1.9815, device='cuda:0') tensor(0.0908, device='cuda:0') tensor(4.4793e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.274556
Average KL loss: 7256.460818
Average total loss: 0.281812
tensor(-1.9816, device='cuda:0') tensor(0.0911, device='cuda:0') tensor(-3.3680e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.273649
Average KL loss: 7276.289532
Average total loss: 0.280925
tensor(-1.9817, device='cuda:0') tensor(0.0914, device='cuda:0') tensor(8.8154e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.275005
Average KL loss: 7284.980439
Average total loss: 0.282290
tensor(-1.9818, device='cuda:0') tensor(0.0915, device='cuda:0') tensor(-5.4018e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.273018
Average KL loss: 7290.629506
Average total loss: 0.280309
tensor(-1.9818, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-4.6242e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.274024
Average KL loss: 7305.822331
Average total loss: 0.281330
tensor(-1.9819, device='cuda:0') tensor(0.0921, device='cuda:0') tensor(-3.5777e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.274447
Average KL loss: 7324.883102
Average total loss: 0.281772
tensor(-1.9819, device='cuda:0') tensor(0.0923, device='cuda:0') tensor(2.5254e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.272731
Average KL loss: 7330.389896
Average total loss: 0.280061
 Percentile value: -1.1720612049102783
Non-zero model percentage: 0.8000080585479736%, Non-zero mask percentage: 0.8000080585479736%

--- Pruning Level [3/8]: ---
conv1.weight         | nonzeros =     658 /    1728             ( 38.08%) | total_pruned =    1070 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2553 /   36864             (  6.93%) | total_pruned =   34311 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2536 /   36864             (  6.88%) | total_pruned =   34328 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1755 /   36864             (  4.76%) | total_pruned =   35109 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1667 /   36864             (  4.52%) | total_pruned =   35197 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3816 /   73728             (  5.18%) | total_pruned =   69912 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4350 /  147456             (  2.95%) | total_pruned =  143106 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1312 /    8192             ( 16.02%) | total_pruned =    6880 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1859 /  147456             (  1.26%) | total_pruned =  145597 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1986 /  147456             (  1.35%) | total_pruned =  145470 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6388 /  294912             (  2.17%) | total_pruned =  288524 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    8046 /  589824             (  1.36%) | total_pruned =  581778 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2751 /   32768             (  8.40%) | total_pruned =   30017 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      58 /     256             ( 22.66%) | total_pruned =     198 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4793 /  589824             (  0.81%) | total_pruned =  585031 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    5056 /  589824             (  0.86%) | total_pruned =  584768 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      32 /     256             ( 12.50%) | total_pruned =     224 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    8011 / 1179648             (  0.68%) | total_pruned = 1171637 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     407 /     512             ( 79.49%) | total_pruned =     105 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    6350 / 2359296             (  0.27%) | total_pruned = 2352946 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     415 /     512             ( 81.05%) | total_pruned =      97 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    5009 /  131072             (  3.82%) | total_pruned =  126063 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     462 /     512             ( 90.23%) | total_pruned =      50 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    5912 / 2359296             (  0.25%) | total_pruned = 2353384 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     237 /     512             ( 46.29%) | total_pruned =     275 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    6967 / 2359296             (  0.30%) | total_pruned = 2352329 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
linear.weight        | nonzeros =    2681 /    5120             ( 52.36%) | total_pruned =    2439 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 89431, pruned : 11089331, total: 11178762, Compression rate :     125.00x  ( 99.20% pruned)
Train Epoch: 99/100 Loss: 0.224053 Accuracy: 78.99% Best Accuracy: 79.58%
tensor(-1.9820, device='cuda:0') tensor(0.0925, device='cuda:0') tensor(5.0188e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.342775
Average KL loss: 7071.642713
Average total loss: 0.349847
tensor(-1.9824, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(1.7646e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.339460
Average KL loss: 6853.138497
Average total loss: 0.346313
tensor(-1.9821, device='cuda:0') tensor(0.0838, device='cuda:0') tensor(6.1278e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.332718
Average KL loss: 6750.700188
Average total loss: 0.339468
tensor(-1.9817, device='cuda:0') tensor(0.0822, device='cuda:0') tensor(-3.8361e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.328356
Average KL loss: 6679.313509
Average total loss: 0.335035
tensor(-1.9815, device='cuda:0') tensor(0.0810, device='cuda:0') tensor(3.1204e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.324881
Average KL loss: 6621.704494
Average total loss: 0.331503
tensor(-1.9814, device='cuda:0') tensor(0.0802, device='cuda:0') tensor(1.7275e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.319439
Average KL loss: 6575.001039
Average total loss: 0.326014
tensor(-1.9814, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(6.4612e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.321497
Average KL loss: 6536.739830
Average total loss: 0.328033
tensor(-1.9814, device='cuda:0') tensor(0.0790, device='cuda:0') tensor(2.1920e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.318273
Average KL loss: 6505.460348
Average total loss: 0.324778
tensor(-1.9814, device='cuda:0') tensor(0.0785, device='cuda:0') tensor(2.1474e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.314844
Average KL loss: 6479.197830
Average total loss: 0.321324
tensor(-1.9815, device='cuda:0') tensor(0.0782, device='cuda:0') tensor(1.6232e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.310748
Average KL loss: 6456.449768
Average total loss: 0.317205
tensor(-1.9815, device='cuda:0') tensor(0.0778, device='cuda:0') tensor(6.3165e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.315744
Average KL loss: 6435.148677
Average total loss: 0.322179
tensor(-1.9816, device='cuda:0') tensor(0.0775, device='cuda:0') tensor(2.0885e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.306146
Average KL loss: 6415.496413
Average total loss: 0.312561
tensor(-1.9817, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-9.6623e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.306068
Average KL loss: 6397.451746
Average total loss: 0.312465
tensor(-1.9818, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(2.7683e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.304232
Average KL loss: 6380.851902
Average total loss: 0.310612
tensor(-1.9818, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(1.0189e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.303237
Average KL loss: 6366.382862
Average total loss: 0.309604
tensor(-1.9819, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-3.8314e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.300007
Average KL loss: 6352.177410
Average total loss: 0.306360
tensor(-1.9820, device='cuda:0') tensor(0.0763, device='cuda:0') tensor(7.9539e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.302133
Average KL loss: 6339.475783
Average total loss: 0.308472
tensor(-1.9820, device='cuda:0') tensor(0.0760, device='cuda:0') tensor(2.4530e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.296497
Average KL loss: 6327.984765
Average total loss: 0.302825
tensor(-1.9821, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(1.1014e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.295730
Average KL loss: 6317.756734
Average total loss: 0.302048
tensor(-1.9821, device='cuda:0') tensor(0.0757, device='cuda:0') tensor(6.6825e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.299080
Average KL loss: 6307.111323
Average total loss: 0.305387
tensor(-1.9822, device='cuda:0') tensor(0.0755, device='cuda:0') tensor(3.3824e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.295228
Average KL loss: 6294.935392
Average total loss: 0.301523
tensor(-1.9822, device='cuda:0') tensor(0.0753, device='cuda:0') tensor(7.4083e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.290645
Average KL loss: 6284.123961
Average total loss: 0.296929
tensor(-1.9823, device='cuda:0') tensor(0.0752, device='cuda:0') tensor(1.9443e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.292279
Average KL loss: 6274.412984
Average total loss: 0.298553
tensor(-1.9824, device='cuda:0') tensor(0.0750, device='cuda:0') tensor(-2.6821e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.289663
Average KL loss: 6264.611143
Average total loss: 0.295928
tensor(-1.9824, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(4.7337e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.288719
Average KL loss: 6255.416900
Average total loss: 0.294974
tensor(-1.9825, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-3.5016e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.291270
Average KL loss: 6246.621264
Average total loss: 0.297517
tensor(-1.9825, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(1.5665e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.287883
Average KL loss: 6238.916420
Average total loss: 0.294122
tensor(-1.9826, device='cuda:0') tensor(0.0744, device='cuda:0') tensor(-1.3489e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.288031
Average KL loss: 6230.838635
Average total loss: 0.294262
tensor(-1.9826, device='cuda:0') tensor(0.0743, device='cuda:0') tensor(9.0729e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.287292
Average KL loss: 6222.290401
Average total loss: 0.293515
tensor(-1.9827, device='cuda:0') tensor(0.0742, device='cuda:0') tensor(-1.8400e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.283117
Average KL loss: 6214.509351
Average total loss: 0.289332
tensor(-1.9827, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(-1.8411e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.283722
Average KL loss: 6207.695752
Average total loss: 0.289929
tensor(-1.9827, device='cuda:0') tensor(0.0740, device='cuda:0') tensor(1.3114e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.283017
Average KL loss: 6200.020360
Average total loss: 0.289217
tensor(-1.9828, device='cuda:0') tensor(0.0738, device='cuda:0') tensor(3.1769e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.282869
Average KL loss: 6192.588675
Average total loss: 0.289061
tensor(-1.9828, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(-1.5277e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.280789
Average KL loss: 6186.112002
Average total loss: 0.286975
tensor(-1.9829, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(3.4572e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.281601
Average KL loss: 6179.995564
Average total loss: 0.287781
tensor(-1.9829, device='cuda:0') tensor(0.0736, device='cuda:0') tensor(2.7655e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.277960
Average KL loss: 6173.956472
Average total loss: 0.284134
tensor(-1.9830, device='cuda:0') tensor(0.0735, device='cuda:0') tensor(4.6386e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.277723
Average KL loss: 6167.838455
Average total loss: 0.283891
tensor(-1.9830, device='cuda:0') tensor(0.0734, device='cuda:0') tensor(2.1087e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.278621
Average KL loss: 6162.131574
Average total loss: 0.284783
tensor(-1.9830, device='cuda:0') tensor(0.0734, device='cuda:0') tensor(9.6712e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.280278
Average KL loss: 6156.216582
Average total loss: 0.286434
tensor(-1.9831, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(-2.1505e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.278061
Average KL loss: 6151.534896
Average total loss: 0.284212
tensor(-1.9831, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(-1.4509e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.277930
Average KL loss: 6146.043628
Average total loss: 0.284076
tensor(-1.9831, device='cuda:0') tensor(0.0732, device='cuda:0') tensor(6.6704e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.275703
Average KL loss: 6139.315008
Average total loss: 0.281842
tensor(-1.9832, device='cuda:0') tensor(0.0732, device='cuda:0') tensor(-1.7581e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.280253
Average KL loss: 6133.198350
Average total loss: 0.286386
tensor(-1.9832, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(5.7884e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.272902
Average KL loss: 6126.660586
Average total loss: 0.279029
tensor(-1.9833, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(1.8405e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.272789
Average KL loss: 6123.092132
Average total loss: 0.278912
tensor(-1.9833, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(1.1147e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.273889
Average KL loss: 6118.340313
Average total loss: 0.280008
tensor(-1.9833, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(-1.6859e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.271731
Average KL loss: 6113.076157
Average total loss: 0.277844
tensor(-1.9834, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(2.4720e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.272320
Average KL loss: 6109.828195
Average total loss: 0.278430
tensor(-1.9834, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(-4.8068e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.274731
Average KL loss: 6104.980009
Average total loss: 0.280836
tensor(-1.9834, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(-3.8337e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.271346
Average KL loss: 6100.297365
Average total loss: 0.277446
tensor(-1.9835, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(4.4742e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.270430
Average KL loss: 6096.549283
Average total loss: 0.276527
tensor(-1.9835, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(1.3528e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.269640
Average KL loss: 6092.598855
Average total loss: 0.275732
tensor(-1.9835, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(4.4803e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.272388
Average KL loss: 6088.790801
Average total loss: 0.278477
tensor(-1.9836, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(-2.1256e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.269860
Average KL loss: 6086.480029
Average total loss: 0.275947
tensor(-1.9836, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(-3.1963e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.266156
Average KL loss: 6084.882373
Average total loss: 0.272241
tensor(-1.9836, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(3.3501e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.268950
Average KL loss: 6082.044717
Average total loss: 0.275032
tensor(-1.9836, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(-2.5628e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.266748
Average KL loss: 6079.382773
Average total loss: 0.272828
tensor(-1.9837, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(5.9117e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.265774
Average KL loss: 6078.099624
Average total loss: 0.271852
tensor(-1.9837, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(9.8858e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.268201
Average KL loss: 6076.657639
Average total loss: 0.274278
tensor(-1.9837, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(2.1121e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.265565
Average KL loss: 6076.573649
Average total loss: 0.271641
tensor(-1.9837, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(5.1308e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.264460
Average KL loss: 6074.907609
Average total loss: 0.270535
tensor(-1.9838, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(7.9494e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.265717
Average KL loss: 6072.214214
Average total loss: 0.271789
tensor(-1.9838, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(1.6191e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.264838
Average KL loss: 6070.437930
Average total loss: 0.270908
tensor(-1.9838, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(-1.0359e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.263796
Average KL loss: 6069.196691
Average total loss: 0.269865
tensor(-1.9838, device='cuda:0') tensor(0.0732, device='cuda:0') tensor(-3.8003e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.265243
Average KL loss: 6069.745135
Average total loss: 0.271313
tensor(-1.9839, device='cuda:0') tensor(0.0732, device='cuda:0') tensor(-5.9943e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.263862
Average KL loss: 6070.172914
Average total loss: 0.269933
tensor(-1.9839, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(-3.9337e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.261659
Average KL loss: 6069.678439
Average total loss: 0.267729
tensor(-1.9839, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(-1.7719e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.260978
Average KL loss: 6069.640815
Average total loss: 0.267048
tensor(-1.9839, device='cuda:0') tensor(0.0734, device='cuda:0') tensor(-1.5713e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.262740
Average KL loss: 6068.956831
Average total loss: 0.268809
tensor(-1.9840, device='cuda:0') tensor(0.0734, device='cuda:0') tensor(1.2246e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.262678
Average KL loss: 6068.201537
Average total loss: 0.268746
tensor(-1.9840, device='cuda:0') tensor(0.0734, device='cuda:0') tensor(-4.8366e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.262744
Average KL loss: 6068.003377
Average total loss: 0.268812
tensor(-1.9840, device='cuda:0') tensor(0.0735, device='cuda:0') tensor(-2.1205e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.261436
Average KL loss: 6068.290062
Average total loss: 0.267504
tensor(-1.9840, device='cuda:0') tensor(0.0736, device='cuda:0') tensor(3.9156e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.262722
Average KL loss: 6068.123831
Average total loss: 0.268790
tensor(-1.9841, device='cuda:0') tensor(0.0736, device='cuda:0') tensor(-2.8192e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.261904
Average KL loss: 6069.407549
Average total loss: 0.267974
tensor(-1.9841, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(3.1802e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.262031
Average KL loss: 6069.872223
Average total loss: 0.268101
tensor(-1.9841, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(-4.3076e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.258245
Average KL loss: 6070.089824
Average total loss: 0.264315
tensor(-1.9841, device='cuda:0') tensor(0.0738, device='cuda:0') tensor(-6.4302e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.258938
Average KL loss: 6070.586677
Average total loss: 0.265009
tensor(-1.9841, device='cuda:0') tensor(0.0738, device='cuda:0') tensor(-1.6872e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.261275
Average KL loss: 6070.215583
Average total loss: 0.267345
tensor(-1.9842, device='cuda:0') tensor(0.0739, device='cuda:0') tensor(-6.8368e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.256642
Average KL loss: 6070.846447
Average total loss: 0.262713
tensor(-1.9842, device='cuda:0') tensor(0.0739, device='cuda:0') tensor(1.2786e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.260127
Average KL loss: 6072.150825
Average total loss: 0.266199
tensor(-1.9842, device='cuda:0') tensor(0.0740, device='cuda:0') tensor(2.2489e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.256918
Average KL loss: 6073.852911
Average total loss: 0.262992
tensor(-1.9842, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(1.2618e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.259246
Average KL loss: 6075.575637
Average total loss: 0.265322
tensor(-1.9843, device='cuda:0') tensor(0.0742, device='cuda:0') tensor(1.5047e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.258910
Average KL loss: 6075.818994
Average total loss: 0.264986
tensor(-1.9843, device='cuda:0') tensor(0.0742, device='cuda:0') tensor(-3.1416e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.257388
Average KL loss: 6076.653063
Average total loss: 0.263465
tensor(-1.9843, device='cuda:0') tensor(0.0743, device='cuda:0') tensor(-1.4583e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.256679
Average KL loss: 6078.166570
Average total loss: 0.262757
tensor(-1.9843, device='cuda:0') tensor(0.0744, device='cuda:0') tensor(5.0595e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.258200
Average KL loss: 6078.936931
Average total loss: 0.264279
tensor(-1.9843, device='cuda:0') tensor(0.0744, device='cuda:0') tensor(-1.9838e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.255940
Average KL loss: 6080.090573
Average total loss: 0.262020
tensor(-1.9844, device='cuda:0') tensor(0.0745, device='cuda:0') tensor(-3.3164e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.256114
Average KL loss: 6082.190427
Average total loss: 0.262196
tensor(-1.9844, device='cuda:0') tensor(0.0746, device='cuda:0') tensor(-2.1963e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.258188
Average KL loss: 6084.207671
Average total loss: 0.264272
tensor(-1.9844, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(1.3830e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.254367
Average KL loss: 6085.357896
Average total loss: 0.260452
tensor(-1.9844, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(2.1811e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.256743
Average KL loss: 6086.681186
Average total loss: 0.262829
tensor(-1.9844, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(-1.4237e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.255260
Average KL loss: 6086.849734
Average total loss: 0.261347
tensor(-1.9845, device='cuda:0') tensor(0.0749, device='cuda:0') tensor(-3.9652e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.254544
Average KL loss: 6088.248022
Average total loss: 0.260632
tensor(-1.9845, device='cuda:0') tensor(0.0750, device='cuda:0') tensor(6.6282e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.253693
Average KL loss: 6089.631684
Average total loss: 0.259782
tensor(-1.9845, device='cuda:0') tensor(0.0751, device='cuda:0') tensor(-3.2595e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.255833
Average KL loss: 6089.949548
Average total loss: 0.261922
tensor(-1.9845, device='cuda:0') tensor(0.0752, device='cuda:0') tensor(-2.6676e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.254049
Average KL loss: 6091.516364
Average total loss: 0.260141
tensor(-1.9845, device='cuda:0') tensor(0.0752, device='cuda:0') tensor(-1.6209e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.253123
Average KL loss: 6093.749860
Average total loss: 0.259217
tensor(-1.9846, device='cuda:0') tensor(0.0753, device='cuda:0') tensor(-3.9842e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.254058
Average KL loss: 6096.142623
Average total loss: 0.260155
tensor(-1.9846, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(6.8965e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.253312
Average KL loss: 6099.766754
Average total loss: 0.259411
tensor(-1.9846, device='cuda:0') tensor(0.0756, device='cuda:0') tensor(-9.8652e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.254979
Average KL loss: 6103.464514
Average total loss: 0.261082
 Percentile value: 1.3249176740646362
Non-zero model percentage: 0.1600087732076645%, Non-zero mask percentage: 0.1600087732076645%

--- Pruning Level [4/8]: ---
conv1.weight         | nonzeros =     414 /    1728             ( 23.96%) | total_pruned =    1314 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
bn1.bias             | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     684 /   36864             (  1.86%) | total_pruned =   36180 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     704 /   36864             (  1.91%) | total_pruned =   36160 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     330 /   36864             (  0.90%) | total_pruned =   36534 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     244 /   36864             (  0.66%) | total_pruned =   36620 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     993 /   73728             (  1.35%) | total_pruned =   72735 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1023 /  147456             (  0.69%) | total_pruned =  146433 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     519 /    8192             (  6.34%) | total_pruned =    7673 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     251 /  147456             (  0.17%) | total_pruned =  147205 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     207 /  147456             (  0.14%) | total_pruned =  147249 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1148 /  294912             (  0.39%) | total_pruned =  293764 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1184 /  589824             (  0.20%) | total_pruned =  588640 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     633 /   32768             (  1.93%) | total_pruned =   32135 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     189 /     256             ( 73.83%) | total_pruned =      67 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     452 /  589824             (  0.08%) | total_pruned =  589372 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     180 /     256             ( 70.31%) | total_pruned =      76 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     442 /  589824             (  0.07%) | total_pruned =  589382 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     924 / 1179648             (  0.08%) | total_pruned = 1178724 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     319 /     512             ( 62.30%) | total_pruned =     193 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     916 / 2359296             (  0.04%) | total_pruned = 2358380 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     290 /     512             ( 56.64%) | total_pruned =     222 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1024 /  131072             (  0.78%) | total_pruned =  130048 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     336 /     512             ( 65.62%) | total_pruned =     176 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1013 / 2359296             (  0.04%) | total_pruned = 2358283 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     138 /     512             ( 26.95%) | total_pruned =     374 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     237 / 2359296             (  0.01%) | total_pruned = 2359059 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     118 /     512             ( 23.05%) | total_pruned =     394 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     291 /     512             ( 56.84%) | total_pruned =     221 | shape = torch.Size([512])
linear.weight        | nonzeros =    1221 /    5120             ( 23.85%) | total_pruned =    3899 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 17887, pruned : 11160875, total: 11178762, Compression rate :     624.97x  ( 99.84% pruned)
Train Epoch: 99/100 Loss: 0.569407 Accuracy: 71.85% Best Accuracy: 73.01%
tensor(-1.9846, device='cuda:0') tensor(0.0757, device='cuda:0') tensor(6.6263e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.373318
Average KL loss: 5600.052300
Average total loss: 0.378918
tensor(-1.9864, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-1.0412e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.369156
Average KL loss: 4800.294297
Average total loss: 0.373957
tensor(-1.9877, device='cuda:0') tensor(0.0635, device='cuda:0') tensor(-3.6287e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.366386
Average KL loss: 4266.911560
Average total loss: 0.370653
tensor(-1.9887, device='cuda:0') tensor(0.0602, device='cuda:0') tensor(2.4600e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.366012
Average KL loss: 3922.292669
Average total loss: 0.369934
tensor(-1.9895, device='cuda:0') tensor(0.0580, device='cuda:0') tensor(2.9349e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.361683
Average KL loss: 3700.193524
Average total loss: 0.365383
tensor(-1.9901, device='cuda:0') tensor(0.0564, device='cuda:0') tensor(-5.0110e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.370379
Average KL loss: 3554.707286
Average total loss: 0.373934
tensor(-1.9906, device='cuda:0') tensor(0.0553, device='cuda:0') tensor(3.8395e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.358491
Average KL loss: 3456.650436
Average total loss: 0.361948
tensor(-1.9910, device='cuda:0') tensor(0.0545, device='cuda:0') tensor(2.7047e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.362688
Average KL loss: 3388.781834
Average total loss: 0.366077
tensor(-1.9913, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(-1.1633e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.362385
Average KL loss: 3341.353126
Average total loss: 0.365726
tensor(-1.9916, device='cuda:0') tensor(0.0534, device='cuda:0') tensor(9.8550e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.361058
Average KL loss: 3307.409877
Average total loss: 0.364366
tensor(-1.9918, device='cuda:0') tensor(0.0530, device='cuda:0') tensor(2.8094e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.364504
Average KL loss: 3281.982986
Average total loss: 0.367786
tensor(-1.9919, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(5.5309e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.356511
Average KL loss: 3261.467576
Average total loss: 0.359773
tensor(-1.9920, device='cuda:0') tensor(0.0524, device='cuda:0') tensor(1.7785e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.357260
Average KL loss: 3245.287719
Average total loss: 0.360505
tensor(-1.9921, device='cuda:0') tensor(0.0522, device='cuda:0') tensor(1.1750e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.359151
Average KL loss: 3231.474874
Average total loss: 0.362382
tensor(-1.9922, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(5.9365e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.355701
Average KL loss: 3218.707386
Average total loss: 0.358920
tensor(-1.9923, device='cuda:0') tensor(0.0519, device='cuda:0') tensor(1.1681e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.357946
Average KL loss: 3206.986538
Average total loss: 0.361153
tensor(-1.9923, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(1.3685e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.351773
Average KL loss: 3195.838890
Average total loss: 0.354969
tensor(-1.9924, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(4.0797e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.348485
Average KL loss: 3185.983151
Average total loss: 0.351671
tensor(-1.9924, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(1.2042e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.354642
Average KL loss: 3177.700438
Average total loss: 0.357820
tensor(-1.9925, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(1.1168e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.351589
Average KL loss: 3169.706382
Average total loss: 0.354759
tensor(-1.9925, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(5.8704e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.353393
Average KL loss: 3161.755095
Average total loss: 0.356555
tensor(-1.9925, device='cuda:0') tensor(0.0512, device='cuda:0') tensor(4.1926e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.355634
Average KL loss: 3154.041260
Average total loss: 0.358788
tensor(-1.9925, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(-9.0707e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.351176
Average KL loss: 3145.642034
Average total loss: 0.354322
tensor(-1.9925, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(1.3734e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.353233
Average KL loss: 3138.202201
Average total loss: 0.356371
tensor(-1.9926, device='cuda:0') tensor(0.0509, device='cuda:0') tensor(6.9644e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.345944
Average KL loss: 3131.287934
Average total loss: 0.349075
tensor(-1.9926, device='cuda:0') tensor(0.0508, device='cuda:0') tensor(4.6141e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.349331
Average KL loss: 3124.664053
Average total loss: 0.352456
tensor(-1.9926, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(7.1079e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.347610
Average KL loss: 3117.778807
Average total loss: 0.350727
tensor(-1.9926, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(-1.1693e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.348069
Average KL loss: 3110.349859
Average total loss: 0.351179
tensor(-1.9926, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(9.8304e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.345212
Average KL loss: 3103.097137
Average total loss: 0.348315
tensor(-1.9926, device='cuda:0') tensor(0.0505, device='cuda:0') tensor(6.4924e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.344191
Average KL loss: 3096.261239
Average total loss: 0.347287
tensor(-1.9926, device='cuda:0') tensor(0.0505, device='cuda:0') tensor(5.8092e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.339308
Average KL loss: 3089.848396
Average total loss: 0.342398
tensor(-1.9927, device='cuda:0') tensor(0.0504, device='cuda:0') tensor(-3.1442e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.339979
Average KL loss: 3082.904432
Average total loss: 0.343062
tensor(-1.9927, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(2.9301e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.346644
Average KL loss: 3077.412434
Average total loss: 0.349722
tensor(-1.9927, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(1.0288e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.341957
Average KL loss: 3071.181601
Average total loss: 0.345028
tensor(-1.9927, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(-3.8913e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.345673
Average KL loss: 3064.195867
Average total loss: 0.348737
tensor(-1.9927, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(3.5924e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.342628
Average KL loss: 3057.531350
Average total loss: 0.345686
tensor(-1.9927, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(4.4898e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.343165
Average KL loss: 3051.602007
Average total loss: 0.346216
tensor(-1.9927, device='cuda:0') tensor(0.0500, device='cuda:0') tensor(1.0326e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.338622
Average KL loss: 3045.443379
Average total loss: 0.341668
tensor(-1.9927, device='cuda:0') tensor(0.0499, device='cuda:0') tensor(5.6833e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.336303
Average KL loss: 3039.038333
Average total loss: 0.339342
tensor(-1.9927, device='cuda:0') tensor(0.0499, device='cuda:0') tensor(3.0881e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.337686
Average KL loss: 3032.895660
Average total loss: 0.340719
tensor(-1.9928, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(-7.6796e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.337996
Average KL loss: 3027.430187
Average total loss: 0.341023
tensor(-1.9928, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(1.2106e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.340397
Average KL loss: 3022.459938
Average total loss: 0.343419
tensor(-1.9928, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(2.3795e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.344832
Average KL loss: 3016.573415
Average total loss: 0.347849
tensor(-1.9928, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(5.9822e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.343691
Average KL loss: 3010.826472
Average total loss: 0.346701
tensor(-1.9928, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(-2.8751e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.332308
Average KL loss: 3004.811166
Average total loss: 0.335313
tensor(-1.9928, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(1.5601e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.335891
Average KL loss: 2998.878152
Average total loss: 0.338890
tensor(-1.9928, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(2.9972e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.329861
Average KL loss: 2993.290391
Average total loss: 0.332854
tensor(-1.9928, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(2.1472e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.331723
Average KL loss: 2987.707596
Average total loss: 0.334711
tensor(-1.9928, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(7.4314e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.336102
Average KL loss: 2981.711887
Average total loss: 0.339083
tensor(-1.9928, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-5.0523e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.335796
Average KL loss: 2975.919118
Average total loss: 0.338772
tensor(-1.9928, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(5.6721e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.335548
Average KL loss: 2970.140420
Average total loss: 0.338518
tensor(-1.9929, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(1.2116e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.336450
Average KL loss: 2964.473790
Average total loss: 0.339415
tensor(-1.9929, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(-4.8452e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.332981
Average KL loss: 2958.913528
Average total loss: 0.335940
tensor(-1.9929, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(3.3434e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.328634
Average KL loss: 2953.805881
Average total loss: 0.331588
tensor(-1.9929, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(-1.7542e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.337032
Average KL loss: 2948.701841
Average total loss: 0.339980
tensor(-1.9929, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(3.2735e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.338376
Average KL loss: 2943.989125
Average total loss: 0.341320
tensor(-1.9929, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(3.6961e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.331790
Average KL loss: 2938.773048
Average total loss: 0.334729
tensor(-1.9929, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(3.8408e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.327882
Average KL loss: 2933.075622
Average total loss: 0.330815
tensor(-1.9929, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(7.6770e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.327956
Average KL loss: 2927.828894
Average total loss: 0.330884
tensor(-1.9929, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(6.3079e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.326464
Average KL loss: 2922.485299
Average total loss: 0.329386
tensor(-1.9929, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(2.7303e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.329547
Average KL loss: 2917.406924
Average total loss: 0.332465
tensor(-1.9929, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(3.2036e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.332914
Average KL loss: 2912.045446
Average total loss: 0.335826
tensor(-1.9929, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(3.0599e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.329590
Average KL loss: 2906.725563
Average total loss: 0.332497
tensor(-1.9929, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(1.6253e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.330832
Average KL loss: 2901.228830
Average total loss: 0.333733
tensor(-1.9930, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-1.6995e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.325391
Average KL loss: 2896.641135
Average total loss: 0.328287
tensor(-1.9930, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(1.0358e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.326481
Average KL loss: 2891.928484
Average total loss: 0.329373
tensor(-1.9930, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(6.2462e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.328178
Average KL loss: 2887.062450
Average total loss: 0.331065
tensor(-1.9930, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(2.5276e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.325196
Average KL loss: 2881.881474
Average total loss: 0.328078
tensor(-1.9930, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(7.3675e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.321998
Average KL loss: 2877.127188
Average total loss: 0.324875
tensor(-1.9930, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(4.4426e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.328230
Average KL loss: 2872.038663
Average total loss: 0.331102
tensor(-1.9930, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(1.1016e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.324578
Average KL loss: 2866.978760
Average total loss: 0.327445
tensor(-1.9930, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(4.9248e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.328466
Average KL loss: 2862.078979
Average total loss: 0.331328
tensor(-1.9930, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(7.0749e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.322917
Average KL loss: 2857.458005
Average total loss: 0.325775
tensor(-1.9930, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-4.3679e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.323039
Average KL loss: 2853.350299
Average total loss: 0.325892
tensor(-1.9930, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(7.9381e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.320406
Average KL loss: 2848.876349
Average total loss: 0.323255
tensor(-1.9930, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(1.8870e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.327503
Average KL loss: 2844.461582
Average total loss: 0.330348
tensor(-1.9930, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(7.4650e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.331104
Average KL loss: 2840.136404
Average total loss: 0.333944
tensor(-1.9930, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-5.7595e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.328372
Average KL loss: 2836.109575
Average total loss: 0.331208
tensor(-1.9930, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(7.1219e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.329815
Average KL loss: 2832.359525
Average total loss: 0.332647
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(2.8234e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.324896
Average KL loss: 2827.741383
Average total loss: 0.327724
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(3.7221e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.326220
Average KL loss: 2823.064678
Average total loss: 0.329043
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(4.2561e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.320346
Average KL loss: 2818.745065
Average total loss: 0.323165
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(3.4124e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.321197
Average KL loss: 2814.446337
Average total loss: 0.324011
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-7.3595e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.318557
Average KL loss: 2810.642733
Average total loss: 0.321368
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(4.4087e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.317928
Average KL loss: 2806.305087
Average total loss: 0.320734
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-4.4271e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.323192
Average KL loss: 2801.718875
Average total loss: 0.325993
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(5.2644e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.321616
Average KL loss: 2797.534976
Average total loss: 0.324414
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(1.1411e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.317729
Average KL loss: 2793.513427
Average total loss: 0.320522
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(1.8797e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.318104
Average KL loss: 2789.507618
Average total loss: 0.320894
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(5.6484e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.321864
Average KL loss: 2785.758227
Average total loss: 0.324650
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(5.3475e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.321534
Average KL loss: 2782.010365
Average total loss: 0.324316
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(2.0236e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.322588
Average KL loss: 2778.218705
Average total loss: 0.325366
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(3.4222e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.322619
Average KL loss: 2774.318574
Average total loss: 0.325393
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(1.0985e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.320535
Average KL loss: 2770.628711
Average total loss: 0.323305
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(5.9586e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.320181
Average KL loss: 2766.812685
Average total loss: 0.322948
tensor(-1.9931, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(8.8449e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.317338
Average KL loss: 2763.028593
Average total loss: 0.320101
tensor(-1.9931, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(4.8215e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.318762
Average KL loss: 2759.446162
Average total loss: 0.321521
tensor(-1.9932, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(3.4738e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.317633
Average KL loss: 2755.526220
Average total loss: 0.320389
tensor(-1.9932, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(8.8220e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.316963
Average KL loss: 2751.976602
Average total loss: 0.319715
tensor(-1.9932, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(2.7778e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.315639
Average KL loss: 2748.587991
Average total loss: 0.318387
 Percentile value: 4.467262077331543
Non-zero model percentage: 0.0320071205496788%, Non-zero mask percentage: 0.0320071205496788%

--- Pruning Level [5/8]: ---
conv1.weight         | nonzeros =     228 /    1728             ( 13.19%) | total_pruned =    1500 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
bn1.bias             | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     152 /   36864             (  0.41%) | total_pruned =   36712 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      99 /   36864             (  0.27%) | total_pruned =   36765 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      42 /   36864             (  0.11%) | total_pruned =   36822 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      18 /   36864             (  0.05%) | total_pruned =   36846 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     151 /   73728             (  0.20%) | total_pruned =   73577 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     139 /  147456             (  0.09%) | total_pruned =  147317 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     147 /    8192             (  1.79%) | total_pruned =    8045 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =      19 /  147456             (  0.01%) | total_pruned =  147437 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       9 /  147456             (  0.01%) | total_pruned =  147447 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =      95 /  294912             (  0.03%) | total_pruned =  294817 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =      73 /  589824             (  0.01%) | total_pruned =  589751 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     102 /   32768             (  0.31%) | total_pruned =   32666 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =      25 /  589824             (  0.00%) | total_pruned =  589799 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =      17 /  589824             (  0.00%) | total_pruned =  589807 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      92 /     256             ( 35.94%) | total_pruned =     164 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =      39 / 1179648             (  0.00%) | total_pruned = 1179609 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     146 /     512             ( 28.52%) | total_pruned =     366 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =      43 / 2359296             (  0.00%) | total_pruned = 2359253 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     134 /     512             ( 26.17%) | total_pruned =     378 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      99 /  131072             (  0.08%) | total_pruned =  130973 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     157 /     512             ( 30.66%) | total_pruned =     355 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      28 / 2359296             (  0.00%) | total_pruned = 2359268 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      28 /     512             (  5.47%) | total_pruned =     484 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =       1 / 2359296             (  0.00%) | total_pruned = 2359295 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
linear.weight        | nonzeros =     441 /    5120             (  8.61%) | total_pruned =    4679 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 3578, pruned : 11175184, total: 11178762, Compression rate :    3124.30x  ( 99.97% pruned)
Train Epoch: 99/100 Loss: 1.514541 Accuracy: 43.54% Best Accuracy: 47.70%
tensor(-1.9932, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(9.4171e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.363530
Average KL loss: 2629.840423
Average total loss: 0.366160
tensor(-1.9937, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(-7.9896e-11, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.366628
Average KL loss: 2373.608566
Average total loss: 0.369002
tensor(-1.9942, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(2.6820e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.366924
Average KL loss: 2087.236885
Average total loss: 0.369011
tensor(-1.9947, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-2.7200e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.370372
Average KL loss: 1777.121281
Average total loss: 0.372149
tensor(-1.9952, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(3.7692e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.364240
Average KL loss: 1467.481663
Average total loss: 0.365708
tensor(-1.9957, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(3.6467e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.369523
Average KL loss: 1197.311591
Average total loss: 0.370720
tensor(-1.9962, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(6.4892e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.357759
Average KL loss: 997.422978
Average total loss: 0.358757
tensor(-1.9965, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(7.1652e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.360022
Average KL loss: 867.454165
Average total loss: 0.360890
tensor(-1.9968, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(5.8414e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.359522
Average KL loss: 786.397600
Average total loss: 0.360308
tensor(-1.9970, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(4.5647e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.371593
Average KL loss: 734.156477
Average total loss: 0.372328
tensor(-1.9972, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(1.8600e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.372416
Average KL loss: 698.831398
Average total loss: 0.373114
tensor(-1.9973, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-2.5048e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.370254
Average KL loss: 674.397053
Average total loss: 0.370929
tensor(-1.9974, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(9.1890e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.365091
Average KL loss: 656.805503
Average total loss: 0.365747
tensor(-1.9975, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(4.8843e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.366379
Average KL loss: 642.605398
Average total loss: 0.367022
tensor(-1.9976, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(2.0292e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.366859
Average KL loss: 630.344052
Average total loss: 0.367489
tensor(-1.9977, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-2.3231e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.357246
Average KL loss: 620.424225
Average total loss: 0.357867
tensor(-1.9977, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(9.0930e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.365169
Average KL loss: 612.959884
Average total loss: 0.365782
tensor(-1.9978, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(1.1278e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.360455
Average KL loss: 606.643817
Average total loss: 0.361061
tensor(-1.9978, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-4.0263e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.366603
Average KL loss: 601.287714
Average total loss: 0.367204
tensor(-1.9979, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(5.2893e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.354646
Average KL loss: 596.568514
Average total loss: 0.355243
tensor(-1.9979, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(1.4784e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.364408
Average KL loss: 592.210574
Average total loss: 0.365001
tensor(-1.9979, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-1.5303e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.361920
Average KL loss: 588.328435
Average total loss: 0.362508
tensor(-1.9979, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(6.9799e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.361564
Average KL loss: 585.132440
Average total loss: 0.362149
tensor(-1.9980, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(6.8766e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.364845
Average KL loss: 581.646416
Average total loss: 0.365427
tensor(-1.9980, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(1.6570e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.357380
Average KL loss: 577.789326
Average total loss: 0.357958
tensor(-1.9980, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(1.5439e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.371938
Average KL loss: 574.318294
Average total loss: 0.372513
tensor(-1.9980, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(4.4142e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.363366
Average KL loss: 570.428656
Average total loss: 0.363937
tensor(-1.9980, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(4.3762e-11, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.359854
Average KL loss: 566.667045
Average total loss: 0.360420
tensor(-1.9980, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(2.2916e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.358584
Average KL loss: 563.713538
Average total loss: 0.359147
tensor(-1.9981, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(3.7759e-11, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.361530
Average KL loss: 560.744990
Average total loss: 0.362091
tensor(-1.9981, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(2.1197e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.358749
Average KL loss: 557.704238
Average total loss: 0.359306
tensor(-1.9981, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(2.2308e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.364587
Average KL loss: 555.127159
Average total loss: 0.365142
tensor(-1.9981, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(6.3512e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.358479
Average KL loss: 552.252962
Average total loss: 0.359032
tensor(-1.9981, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(7.9070e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.369060
Average KL loss: 548.746764
Average total loss: 0.369609
tensor(-1.9981, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(4.3972e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.364325
Average KL loss: 545.609777
Average total loss: 0.364871
tensor(-1.9981, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(9.8404e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.370191
Average KL loss: 542.636430
Average total loss: 0.370734
tensor(-1.9981, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(3.6392e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.365186
Average KL loss: 540.266221
Average total loss: 0.365726
tensor(-1.9981, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-9.0138e-11, device='cuda:0')
