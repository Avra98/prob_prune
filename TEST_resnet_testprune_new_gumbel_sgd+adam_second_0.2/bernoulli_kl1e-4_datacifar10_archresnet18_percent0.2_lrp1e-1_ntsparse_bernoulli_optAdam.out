Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.4786e-05, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.905239
Average KL loss: 189.331430
Average total loss: 191.236664
tensor(-3.3396, device='cuda:0') tensor(0.2401, device='cuda:0') tensor(3.6076e-06, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.906319
Average KL loss: 28.880134
Average total loss: 30.786452
tensor(-4.2937, device='cuda:0') tensor(0.2904, device='cuda:0') tensor(1.5993e-06, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.875756
Average KL loss: 15.407740
Average total loss: 17.283495
tensor(-4.8153, device='cuda:0') tensor(0.3157, device='cuda:0') tensor(9.7388e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.834596
Average KL loss: 10.406014
Average total loss: 12.240610
tensor(-5.1971, device='cuda:0') tensor(0.3381, device='cuda:0') tensor(7.1412e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.796720
Average KL loss: 7.758653
Average total loss: 9.555373
tensor(-5.5010, device='cuda:0') tensor(0.3556, device='cuda:0') tensor(5.1645e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.767840
Average KL loss: 6.135651
Average total loss: 7.903491
tensor(-5.7541, device='cuda:0') tensor(0.3707, device='cuda:0') tensor(4.1795e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.734271
Average KL loss: 5.053933
Average total loss: 6.788204
tensor(-5.9716, device='cuda:0') tensor(0.3841, device='cuda:0') tensor(3.5295e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.703514
Average KL loss: 4.283913
Average total loss: 5.987427
tensor(-6.1625, device='cuda:0') tensor(0.3949, device='cuda:0') tensor(3.0917e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.663220
Average KL loss: 3.704771
Average total loss: 5.367990
tensor(-6.3330, device='cuda:0') tensor(0.4028, device='cuda:0') tensor(2.5516e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.636119
Average KL loss: 3.253947
Average total loss: 4.890066
tensor(-6.4872, device='cuda:0') tensor(0.4088, device='cuda:0') tensor(2.2096e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.599933
Average KL loss: 2.895501
Average total loss: 4.495434
tensor(-6.6280, device='cuda:0') tensor(0.4138, device='cuda:0') tensor(1.8756e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.580764
Average KL loss: 2.602141
Average total loss: 4.182904
tensor(-6.7578, device='cuda:0') tensor(0.4181, device='cuda:0') tensor(1.7559e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.556254
Average KL loss: 2.361804
Average total loss: 3.918057
tensor(-6.8782, device='cuda:0') tensor(0.4216, device='cuda:0') tensor(1.5672e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.520404
Average KL loss: 2.157747
Average total loss: 3.678151
tensor(-6.9907, device='cuda:0') tensor(0.4237, device='cuda:0') tensor(1.4767e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.512979
Average KL loss: 1.981513
Average total loss: 3.494492
tensor(-7.0962, device='cuda:0') tensor(0.4257, device='cuda:0') tensor(1.3272e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.480897
Average KL loss: 1.831991
Average total loss: 3.312887
tensor(-7.1957, device='cuda:0') tensor(0.4275, device='cuda:0') tensor(1.2362e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.462960
Average KL loss: 1.703001
Average total loss: 3.165961
tensor(-7.2898, device='cuda:0') tensor(0.4293, device='cuda:0') tensor(1.0072e-07, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.438812
Average KL loss: 1.592720
Average total loss: 3.031531
tensor(-7.3793, device='cuda:0') tensor(0.4311, device='cuda:0') tensor(9.8864e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.414288
Average KL loss: 1.497437
Average total loss: 2.911725
tensor(-7.4645, device='cuda:0') tensor(0.4326, device='cuda:0') tensor(8.8620e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.391189
Average KL loss: 1.411750
Average total loss: 2.802938
tensor(-7.5460, device='cuda:0') tensor(0.4339, device='cuda:0') tensor(8.2914e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.369097
Average KL loss: 1.334004
Average total loss: 2.703100
tensor(-7.6240, device='cuda:0') tensor(0.4349, device='cuda:0') tensor(7.7982e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.360217
Average KL loss: 1.265794
Average total loss: 2.626011
tensor(-7.6989, device='cuda:0') tensor(0.4361, device='cuda:0') tensor(7.1318e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.345131
Average KL loss: 1.204095
Average total loss: 2.549226
tensor(-7.7710, device='cuda:0') tensor(0.4372, device='cuda:0') tensor(7.1008e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.323609
Average KL loss: 1.148666
Average total loss: 2.472275
tensor(-7.8405, device='cuda:0') tensor(0.4380, device='cuda:0') tensor(6.0047e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.309541
Average KL loss: 1.098052
Average total loss: 2.407594
tensor(-7.9076, device='cuda:0') tensor(0.4389, device='cuda:0') tensor(5.8231e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.299030
Average KL loss: 1.052464
Average total loss: 2.351493
tensor(-7.9726, device='cuda:0') tensor(0.4400, device='cuda:0') tensor(5.3360e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.292202
Average KL loss: 1.010510
Average total loss: 2.302712
tensor(-8.0355, device='cuda:0') tensor(0.4409, device='cuda:0') tensor(4.9848e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.278181
Average KL loss: 0.971740
Average total loss: 2.249921
tensor(-8.0966, device='cuda:0') tensor(0.4419, device='cuda:0') tensor(4.8038e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.267267
Average KL loss: 0.936404
Average total loss: 2.203671
tensor(-8.1559, device='cuda:0') tensor(0.4428, device='cuda:0') tensor(4.4107e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.260538
Average KL loss: 0.903762
Average total loss: 2.164300
tensor(-8.2136, device='cuda:0') tensor(0.4440, device='cuda:0') tensor(4.3807e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.247968
Average KL loss: 0.875323
Average total loss: 2.123291
tensor(-8.2698, device='cuda:0') tensor(0.4451, device='cuda:0') tensor(4.0583e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.241842
Average KL loss: 0.848154
Average total loss: 2.089996
tensor(-8.3246, device='cuda:0') tensor(0.4462, device='cuda:0') tensor(3.9273e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.235607
Average KL loss: 0.823300
Average total loss: 2.058907
tensor(-8.3781, device='cuda:0') tensor(0.4473, device='cuda:0') tensor(3.6287e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.226160
Average KL loss: 0.801431
Average total loss: 2.027591
tensor(-8.4304, device='cuda:0') tensor(0.4486, device='cuda:0') tensor(3.3821e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.218069
Average KL loss: 0.780755
Average total loss: 1.998824
tensor(-8.4814, device='cuda:0') tensor(0.4498, device='cuda:0') tensor(3.1824e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.210077
Average KL loss: 0.761179
Average total loss: 1.971256
tensor(-8.5314, device='cuda:0') tensor(0.4510, device='cuda:0') tensor(3.1082e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.205840
Average KL loss: 0.742803
Average total loss: 1.948642
tensor(-8.5803, device='cuda:0') tensor(0.4523, device='cuda:0') tensor(2.9352e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.202312
Average KL loss: 0.726348
Average total loss: 1.928660
tensor(-8.6283, device='cuda:0') tensor(0.4536, device='cuda:0') tensor(2.7026e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.190494
Average KL loss: 0.711228
Average total loss: 1.901721
tensor(-8.6753, device='cuda:0') tensor(0.4550, device='cuda:0') tensor(2.7217e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.187695
Average KL loss: 0.697303
Average total loss: 1.884998
tensor(-8.7215, device='cuda:0') tensor(0.4562, device='cuda:0') tensor(2.5512e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.176686
Average KL loss: 0.683506
Average total loss: 1.860192
tensor(-8.7668, device='cuda:0') tensor(0.4575, device='cuda:0') tensor(2.5107e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.175481
Average KL loss: 0.670325
Average total loss: 1.845806
tensor(-8.8114, device='cuda:0') tensor(0.4587, device='cuda:0') tensor(2.4139e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.169041
Average KL loss: 0.657579
Average total loss: 1.826620
tensor(-8.8552, device='cuda:0') tensor(0.4599, device='cuda:0') tensor(2.5251e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.166719
Average KL loss: 0.645707
Average total loss: 1.812425
tensor(-8.8983, device='cuda:0') tensor(0.4612, device='cuda:0') tensor(2.0481e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.162909
Average KL loss: 0.634179
Average total loss: 1.797089
tensor(-8.9408, device='cuda:0') tensor(0.4624, device='cuda:0') tensor(2.1502e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.157473
Average KL loss: 0.623746
Average total loss: 1.781220
tensor(-8.9826, device='cuda:0') tensor(0.4637, device='cuda:0') tensor(2.2530e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.151998
Average KL loss: 0.614027
Average total loss: 1.766024
tensor(-9.0237, device='cuda:0') tensor(0.4650, device='cuda:0') tensor(2.0659e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.147020
Average KL loss: 0.605092
Average total loss: 1.752113
tensor(-9.0643, device='cuda:0') tensor(0.4663, device='cuda:0') tensor(1.9019e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.143225
Average KL loss: 0.596415
Average total loss: 1.739641
tensor(-9.1043, device='cuda:0') tensor(0.4676, device='cuda:0') tensor(2.0317e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.139519
Average KL loss: 0.588072
Average total loss: 1.727591
tensor(-9.1438, device='cuda:0') tensor(0.4689, device='cuda:0') tensor(1.7467e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.139539
Average KL loss: 0.580142
Average total loss: 1.719681
tensor(-9.1828, device='cuda:0') tensor(0.4702, device='cuda:0') tensor(1.4488e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.131051
Average KL loss: 0.573383
Average total loss: 1.704434
tensor(-9.2213, device='cuda:0') tensor(0.4714, device='cuda:0') tensor(1.8155e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.128553
Average KL loss: 0.567020
Average total loss: 1.695574
tensor(-9.2593, device='cuda:0') tensor(0.4727, device='cuda:0') tensor(1.5739e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.121612
Average KL loss: 0.561255
Average total loss: 1.682867
tensor(-9.2969, device='cuda:0') tensor(0.4739, device='cuda:0') tensor(1.4513e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.120550
Average KL loss: 0.555186
Average total loss: 1.675736
tensor(-9.3340, device='cuda:0') tensor(0.4752, device='cuda:0') tensor(1.4488e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.116764
Average KL loss: 0.548780
Average total loss: 1.665544
tensor(-9.3707, device='cuda:0') tensor(0.4764, device='cuda:0') tensor(1.3049e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.116112
Average KL loss: 0.543171
Average total loss: 1.659283
tensor(-9.4070, device='cuda:0') tensor(0.4777, device='cuda:0') tensor(1.1638e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.112064
Average KL loss: 0.537787
Average total loss: 1.649851
tensor(-9.4429, device='cuda:0') tensor(0.4789, device='cuda:0') tensor(1.4058e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.108308
Average KL loss: 0.532371
Average total loss: 1.640680
tensor(-9.4785, device='cuda:0') tensor(0.4801, device='cuda:0') tensor(1.3717e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.106107
Average KL loss: 0.527647
Average total loss: 1.633754
tensor(-9.5137, device='cuda:0') tensor(0.4814, device='cuda:0') tensor(1.2600e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.103122
Average KL loss: 0.523105
Average total loss: 1.626227
tensor(-9.5485, device='cuda:0') tensor(0.4824, device='cuda:0') tensor(1.2294e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.100168
Average KL loss: 0.518438
Average total loss: 1.618606
tensor(-9.5831, device='cuda:0') tensor(0.4834, device='cuda:0') tensor(1.1236e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.099282
Average KL loss: 0.513640
Average total loss: 1.612922
tensor(-9.6173, device='cuda:0') tensor(0.4846, device='cuda:0') tensor(1.0525e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.094907
Average KL loss: 0.509408
Average total loss: 1.604315
tensor(-9.6512, device='cuda:0') tensor(0.4857, device='cuda:0') tensor(1.0138e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.094286
Average KL loss: 0.505380
Average total loss: 1.599666
tensor(-9.6848, device='cuda:0') tensor(0.4869, device='cuda:0') tensor(9.0908e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.092716
Average KL loss: 0.501988
Average total loss: 1.594704
tensor(-9.7181, device='cuda:0') tensor(0.4882, device='cuda:0') tensor(1.1811e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.090381
Average KL loss: 0.498232
Average total loss: 1.588613
tensor(-9.7512, device='cuda:0') tensor(0.4893, device='cuda:0') tensor(1.0695e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.087773
Average KL loss: 0.494525
Average total loss: 1.582298
tensor(-9.7840, device='cuda:0') tensor(0.4905, device='cuda:0') tensor(8.5783e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.087616
Average KL loss: 0.491198
Average total loss: 1.578815
tensor(-9.8165, device='cuda:0') tensor(0.4917, device='cuda:0') tensor(9.4086e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.086917
Average KL loss: 0.488088
Average total loss: 1.575005
tensor(-9.8488, device='cuda:0') tensor(0.4929, device='cuda:0') tensor(9.2713e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.082743
Average KL loss: 0.485300
Average total loss: 1.568044
tensor(-9.8808, device='cuda:0') tensor(0.4941, device='cuda:0') tensor(9.0796e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.082419
Average KL loss: 0.482125
Average total loss: 1.564545
tensor(-9.9126, device='cuda:0') tensor(0.4952, device='cuda:0') tensor(8.7036e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.078949
Average KL loss: 0.479280
Average total loss: 1.558229
tensor(-9.9442, device='cuda:0') tensor(0.4963, device='cuda:0') tensor(7.1669e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.081620
Average KL loss: 0.476589
Average total loss: 1.558209
tensor(-9.9755, device='cuda:0') tensor(0.4976, device='cuda:0') tensor(6.9326e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.076239
Average KL loss: 0.473918
Average total loss: 1.550157
tensor(-10.0067, device='cuda:0') tensor(0.4986, device='cuda:0') tensor(8.3913e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.076299
Average KL loss: 0.471227
Average total loss: 1.547526
tensor(-10.0377, device='cuda:0') tensor(0.4996, device='cuda:0') tensor(7.7261e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.075245
Average KL loss: 0.468588
Average total loss: 1.543833
tensor(-10.0685, device='cuda:0') tensor(0.5006, device='cuda:0') tensor(6.9791e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.076281
Average KL loss: 0.466361
Average total loss: 1.542642
tensor(-10.0990, device='cuda:0') tensor(0.5018, device='cuda:0') tensor(7.6386e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.071039
Average KL loss: 0.464538
Average total loss: 1.535577
tensor(-10.1294, device='cuda:0') tensor(0.5029, device='cuda:0') tensor(6.8800e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.070867
Average KL loss: 0.462638
Average total loss: 1.533505
tensor(-10.1596, device='cuda:0') tensor(0.5040, device='cuda:0') tensor(4.9692e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.070120
Average KL loss: 0.460455
Average total loss: 1.530575
tensor(-10.1896, device='cuda:0') tensor(0.5050, device='cuda:0') tensor(6.1108e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.068878
Average KL loss: 0.458357
Average total loss: 1.527235
tensor(-10.2195, device='cuda:0') tensor(0.5061, device='cuda:0') tensor(5.0128e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.067324
Average KL loss: 0.456818
Average total loss: 1.524142
tensor(-10.2492, device='cuda:0') tensor(0.5073, device='cuda:0') tensor(6.3282e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.068275
Average KL loss: 0.455022
Average total loss: 1.523297
tensor(-10.2787, device='cuda:0') tensor(0.5083, device='cuda:0') tensor(5.8110e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.065490
Average KL loss: 0.452920
Average total loss: 1.518410
tensor(-10.3081, device='cuda:0') tensor(0.5093, device='cuda:0') tensor(5.0168e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.064127
Average KL loss: 0.451487
Average total loss: 1.515614
tensor(-10.3374, device='cuda:0') tensor(0.5104, device='cuda:0') tensor(6.0328e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.063623
Average KL loss: 0.450057
Average total loss: 1.513679
tensor(-10.3664, device='cuda:0') tensor(0.5114, device='cuda:0') tensor(4.6406e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.063823
Average KL loss: 0.448125
Average total loss: 1.511948
tensor(-10.3954, device='cuda:0') tensor(0.5123, device='cuda:0') tensor(4.5926e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.063043
Average KL loss: 0.446522
Average total loss: 1.509566
tensor(-10.4242, device='cuda:0') tensor(0.5134, device='cuda:0') tensor(5.6199e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.063632
Average KL loss: 0.445125
Average total loss: 1.508757
tensor(-10.4529, device='cuda:0') tensor(0.5144, device='cuda:0') tensor(5.3193e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.062288
Average KL loss: 0.443691
Average total loss: 1.505979
tensor(-10.4814, device='cuda:0') tensor(0.5154, device='cuda:0') tensor(4.2641e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.060590
Average KL loss: 0.442162
Average total loss: 1.502752
tensor(-10.5099, device='cuda:0') tensor(0.5163, device='cuda:0') tensor(5.0645e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.060876
Average KL loss: 0.440570
Average total loss: 1.501446
tensor(-10.5382, device='cuda:0') tensor(0.5172, device='cuda:0') tensor(4.2420e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.060219
Average KL loss: 0.439301
Average total loss: 1.499521
tensor(-10.5663, device='cuda:0') tensor(0.5181, device='cuda:0') tensor(4.2629e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.061352
Average KL loss: 0.437854
Average total loss: 1.499206
tensor(-10.5944, device='cuda:0') tensor(0.5190, device='cuda:0') tensor(4.3432e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.057720
Average KL loss: 0.436682
Average total loss: 1.494402
tensor(-10.6223, device='cuda:0') tensor(0.5201, device='cuda:0') tensor(4.2599e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.056891
Average KL loss: 0.435627
Average total loss: 1.492518
tensor(-10.6502, device='cuda:0') tensor(0.5211, device='cuda:0') tensor(3.5742e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.057933
Average KL loss: 0.434622
Average total loss: 1.492555
tensor(-10.6779, device='cuda:0') tensor(0.5221, device='cuda:0') tensor(4.2761e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.055967
Average KL loss: 0.433501
Average total loss: 1.489468
tensor(-10.7055, device='cuda:0') tensor(0.5230, device='cuda:0') tensor(3.5409e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.055582
Average KL loss: 0.432171
Average total loss: 1.487753
tensor(-10.7330, device='cuda:0') tensor(0.5239, device='cuda:0') tensor(3.0769e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.055270
Average KL loss: 0.431170
Average total loss: 1.486440
tensor(-10.7605, device='cuda:0') tensor(0.5249, device='cuda:0') tensor(3.7011e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.052141
Average KL loss: 0.430314
Average total loss: 1.482455
tensor(-10.7878, device='cuda:0') tensor(0.5258, device='cuda:0') tensor(3.6547e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.053500
Average KL loss: 0.429254
Average total loss: 1.482754
tensor(-10.8150, device='cuda:0') tensor(0.5266, device='cuda:0') tensor(3.5376e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.053806
Average KL loss: 0.428051
Average total loss: 1.481856
tensor(-10.8421, device='cuda:0') tensor(0.5276, device='cuda:0') tensor(3.3751e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.051190
Average KL loss: 0.427300
Average total loss: 1.478490
tensor(-10.8692, device='cuda:0') tensor(0.5286, device='cuda:0') tensor(2.5132e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.050930
Average KL loss: 0.426718
Average total loss: 1.477648
tensor(-10.8961, device='cuda:0') tensor(0.5295, device='cuda:0') tensor(3.1659e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.050129
Average KL loss: 0.426029
Average total loss: 1.476158
tensor(-10.9230, device='cuda:0') tensor(0.5305, device='cuda:0') tensor(3.0828e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.050647
Average KL loss: 0.425554
Average total loss: 1.476201
tensor(-10.9498, device='cuda:0') tensor(0.5314, device='cuda:0') tensor(1.8653e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.047567
Average KL loss: 0.425029
Average total loss: 1.472596
tensor(-10.9765, device='cuda:0') tensor(0.5322, device='cuda:0') tensor(5.8119e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.048377
Average KL loss: 0.424530
Average total loss: 1.472907
tensor(-11.0031, device='cuda:0') tensor(0.5331, device='cuda:0') tensor(2.5868e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.046549
Average KL loss: 0.423997
Average total loss: 1.470546
tensor(-11.0296, device='cuda:0') tensor(0.5339, device='cuda:0') tensor(2.5954e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.045846
Average KL loss: 0.423038
Average total loss: 1.468884
tensor(-11.0561, device='cuda:0') tensor(0.5346, device='cuda:0') tensor(2.6205e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.046526
Average KL loss: 0.422013
Average total loss: 1.468539
tensor(-11.0825, device='cuda:0') tensor(0.5353, device='cuda:0') tensor(2.9620e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.044416
Average KL loss: 0.421204
Average total loss: 1.465619
tensor(-11.1088, device='cuda:0') tensor(0.5361, device='cuda:0') tensor(1.9853e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.044308
Average KL loss: 0.420564
Average total loss: 1.464872
tensor(-11.1350, device='cuda:0') tensor(0.5369, device='cuda:0') tensor(2.4632e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.044869
Average KL loss: 0.419553
Average total loss: 1.464422
tensor(-11.1612, device='cuda:0') tensor(0.5377, device='cuda:0') tensor(2.0789e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.042668
Average KL loss: 0.419134
Average total loss: 1.461802
tensor(-11.1873, device='cuda:0') tensor(0.5386, device='cuda:0') tensor(2.2892e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.041838
Average KL loss: 0.418775
Average total loss: 1.460613
tensor(-11.2133, device='cuda:0') tensor(0.5394, device='cuda:0') tensor(1.8025e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.041407
Average KL loss: 0.418409
Average total loss: 1.459816
tensor(-11.2392, device='cuda:0') tensor(0.5403, device='cuda:0') tensor(1.9205e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.040035
Average KL loss: 0.417980
Average total loss: 1.458015
tensor(-11.2651, device='cuda:0') tensor(0.5410, device='cuda:0') tensor(1.7916e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.039853
Average KL loss: 0.417312
Average total loss: 1.457166
tensor(-11.2909, device='cuda:0') tensor(0.5419, device='cuda:0') tensor(1.9275e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.040144
Average KL loss: 0.416776
Average total loss: 1.456920
tensor(-11.3167, device='cuda:0') tensor(0.5427, device='cuda:0') tensor(2.6036e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.040800
Average KL loss: 0.415999
Average total loss: 1.456799
tensor(-11.3424, device='cuda:0') tensor(0.5434, device='cuda:0') tensor(1.9593e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.038888
Average KL loss: 0.415349
Average total loss: 1.454237
tensor(-11.3680, device='cuda:0') tensor(0.5441, device='cuda:0') tensor(1.3772e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.038790
Average KL loss: 0.414895
Average total loss: 1.453685
tensor(-11.3936, device='cuda:0') tensor(0.5448, device='cuda:0') tensor(2.6596e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.039956
Average KL loss: 0.414109
Average total loss: 1.454065
tensor(-11.4191, device='cuda:0') tensor(0.5455, device='cuda:0') tensor(1.8209e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.038347
Average KL loss: 0.413385
Average total loss: 1.451732
tensor(-11.4445, device='cuda:0') tensor(0.5462, device='cuda:0') tensor(2.0521e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.036704
Average KL loss: 0.413092
Average total loss: 1.449795
tensor(-11.4699, device='cuda:0') tensor(0.5469, device='cuda:0') tensor(2.2865e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.036345
Average KL loss: 0.412652
Average total loss: 1.448997
tensor(-11.4952, device='cuda:0') tensor(0.5476, device='cuda:0') tensor(1.9592e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.036420
Average KL loss: 0.412246
Average total loss: 1.448666
tensor(-11.5205, device='cuda:0') tensor(0.5482, device='cuda:0') tensor(1.5419e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.034974
Average KL loss: 0.412027
Average total loss: 1.447000
tensor(-11.5457, device='cuda:0') tensor(0.5488, device='cuda:0') tensor(1.4373e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.034925
Average KL loss: 0.411853
Average total loss: 1.446778
tensor(-11.5709, device='cuda:0') tensor(0.5495, device='cuda:0') tensor(1.6886e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.034272
Average KL loss: 0.411284
Average total loss: 1.445556
tensor(-11.5960, device='cuda:0') tensor(0.5500, device='cuda:0') tensor(2.1093e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.034978
Average KL loss: 0.410631
Average total loss: 1.445609
tensor(-11.6210, device='cuda:0') tensor(0.5506, device='cuda:0') tensor(2.1073e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.034580
Average KL loss: 0.409917
Average total loss: 1.444497
tensor(-11.6460, device='cuda:0') tensor(0.5512, device='cuda:0') tensor(1.4734e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.035459
Average KL loss: 0.409489
Average total loss: 1.444947
tensor(-11.6710, device='cuda:0') tensor(0.5519, device='cuda:0') tensor(1.0616e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.035419
Average KL loss: 0.409047
Average total loss: 1.444466
tensor(-11.6958, device='cuda:0') tensor(0.5526, device='cuda:0') tensor(1.4686e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.033370
Average KL loss: 0.408752
Average total loss: 1.442122
tensor(-11.7207, device='cuda:0') tensor(0.5533, device='cuda:0') tensor(1.6681e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.032545
Average KL loss: 0.408616
Average total loss: 1.441160
tensor(-11.7454, device='cuda:0') tensor(0.5541, device='cuda:0') tensor(4.0670e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.033754
Average KL loss: 0.408339
Average total loss: 1.442093
tensor(-11.7702, device='cuda:0') tensor(0.5546, device='cuda:0') tensor(4.9982e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.033229
Average KL loss: 0.407702
Average total loss: 1.440931
tensor(-11.7948, device='cuda:0') tensor(0.5552, device='cuda:0') tensor(1.1489e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.033212
Average KL loss: 0.407034
Average total loss: 1.440246
tensor(-11.8195, device='cuda:0') tensor(0.5558, device='cuda:0') tensor(1.0543e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.032621
Average KL loss: 0.406371
Average total loss: 1.438991
tensor(-11.8440, device='cuda:0') tensor(0.5564, device='cuda:0') tensor(8.1067e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.033187
Average KL loss: 0.405940
Average total loss: 1.439128
tensor(-11.8686, device='cuda:0') tensor(0.5568, device='cuda:0') tensor(1.3986e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.033065
Average KL loss: 0.405515
Average total loss: 1.438581
tensor(-11.8930, device='cuda:0') tensor(0.5573, device='cuda:0') tensor(1.1513e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.032888
Average KL loss: 0.405101
Average total loss: 1.437989
tensor(-11.9175, device='cuda:0') tensor(0.5578, device='cuda:0') tensor(1.6574e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.032007
Average KL loss: 0.404528
Average total loss: 1.436535
tensor(-11.9418, device='cuda:0') tensor(0.5583, device='cuda:0') tensor(8.2446e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.033074
Average KL loss: 0.404073
Average total loss: 1.437147
tensor(-11.9662, device='cuda:0') tensor(0.5589, device='cuda:0') tensor(1.8221e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.031765
Average KL loss: 0.403960
Average total loss: 1.435725
tensor(-11.9904, device='cuda:0') tensor(0.5593, device='cuda:0') tensor(9.2553e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.031738
Average KL loss: 0.403734
Average total loss: 1.435472
tensor(-12.0147, device='cuda:0') tensor(0.5597, device='cuda:0') tensor(1.5093e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.030265
Average KL loss: 0.403442
Average total loss: 1.433707
tensor(-12.0388, device='cuda:0') tensor(0.5600, device='cuda:0') tensor(1.3466e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.030325
Average KL loss: 0.403076
Average total loss: 1.433401
tensor(-12.0630, device='cuda:0') tensor(0.5603, device='cuda:0') tensor(1.4704e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.030306
Average KL loss: 0.402628
Average total loss: 1.432933
tensor(-12.0871, device='cuda:0') tensor(0.5607, device='cuda:0') tensor(1.3707e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.030536
Average KL loss: 0.402482
Average total loss: 1.433018
tensor(-12.1111, device='cuda:0') tensor(0.5611, device='cuda:0') tensor(7.3354e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.028938
Average KL loss: 0.402429
Average total loss: 1.431366
tensor(-12.1351, device='cuda:0') tensor(0.5616, device='cuda:0') tensor(7.7466e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.028100
Average KL loss: 0.402249
Average total loss: 1.430350
tensor(-12.1590, device='cuda:0') tensor(0.5619, device='cuda:0') tensor(9.7508e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.028564
Average KL loss: 0.401964
Average total loss: 1.430528
tensor(-12.1829, device='cuda:0') tensor(0.5623, device='cuda:0') tensor(-3.3007e-11, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.028211
Average KL loss: 0.401980
Average total loss: 1.430190
tensor(-12.2067, device='cuda:0') tensor(0.5627, device='cuda:0') tensor(9.8812e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.028621
Average KL loss: 0.401896
Average total loss: 1.430517
tensor(-12.2305, device='cuda:0') tensor(0.5631, device='cuda:0') tensor(3.2133e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.027582
Average KL loss: 0.401895
Average total loss: 1.429477
tensor(-12.2542, device='cuda:0') tensor(0.5635, device='cuda:0') tensor(1.1552e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.026939
Average KL loss: 0.401784
Average total loss: 1.428723
tensor(-12.2779, device='cuda:0') tensor(0.5639, device='cuda:0') tensor(1.3678e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.027327
Average KL loss: 0.401408
Average total loss: 1.428735
tensor(-12.3015, device='cuda:0') tensor(0.5642, device='cuda:0') tensor(7.4183e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.025836
Average KL loss: 0.401097
Average total loss: 1.426933
tensor(-12.3251, device='cuda:0') tensor(0.5645, device='cuda:0') tensor(9.9611e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.027662
Average KL loss: 0.401140
Average total loss: 1.428802
tensor(-12.3486, device='cuda:0') tensor(0.5648, device='cuda:0') tensor(3.6563e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.026355
Average KL loss: 0.401131
Average total loss: 1.427487
tensor(-12.3721, device='cuda:0') tensor(0.5651, device='cuda:0') tensor(9.6991e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.026456
Average KL loss: 0.400664
Average total loss: 1.427120
tensor(-12.3956, device='cuda:0') tensor(0.5652, device='cuda:0') tensor(1.0987e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.026492
Average KL loss: 0.400596
Average total loss: 1.427088
tensor(-12.4189, device='cuda:0') tensor(0.5655, device='cuda:0') tensor(-1.3096e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.024842
Average KL loss: 0.400529
Average total loss: 1.425371
tensor(-12.4423, device='cuda:0') tensor(0.5656, device='cuda:0') tensor(5.0535e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.024540
Average KL loss: 0.400201
Average total loss: 1.424742
tensor(-12.4655, device='cuda:0') tensor(0.5658, device='cuda:0') tensor(1.1435e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.026659
Average KL loss: 0.399867
Average total loss: 1.426526
tensor(-12.4888, device='cuda:0') tensor(0.5658, device='cuda:0') tensor(8.1391e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.024433
Average KL loss: 0.399589
Average total loss: 1.424022
tensor(-12.5120, device='cuda:0') tensor(0.5659, device='cuda:0') tensor(3.4614e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 1.025087
Average KL loss: 0.399240
Average total loss: 1.424327
tensor(-12.5351, device='cuda:0') tensor(0.5659, device='cuda:0') tensor(9.1280e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.024620
Average KL loss: 0.399029
Average total loss: 1.423649
tensor(-12.5582, device='cuda:0') tensor(0.5660, device='cuda:0') tensor(7.7137e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.024932
Average KL loss: 0.398581
Average total loss: 1.423514
tensor(-12.5812, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(1.0737e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 1.025728
Average KL loss: 0.398274
Average total loss: 1.424003
tensor(-12.6041, device='cuda:0') tensor(0.5660, device='cuda:0') tensor(6.6978e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 1.024904
Average KL loss: 0.397777
Average total loss: 1.422681
tensor(-12.6270, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(5.8585e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 1.026234
Average KL loss: 0.397377
Average total loss: 1.423611
tensor(-12.6499, device='cuda:0') tensor(0.5662, device='cuda:0') tensor(5.3168e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 1.026014
Average KL loss: 0.397348
Average total loss: 1.423362
tensor(-12.6727, device='cuda:0') tensor(0.5663, device='cuda:0') tensor(7.2697e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 1.026585
Average KL loss: 0.397235
Average total loss: 1.423819
tensor(-12.6954, device='cuda:0') tensor(0.5663, device='cuda:0') tensor(4.4797e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 1.024805
Average KL loss: 0.396999
Average total loss: 1.421804
tensor(-12.7181, device='cuda:0') tensor(0.5663, device='cuda:0') tensor(7.1507e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 1.024530
Average KL loss: 0.396966
Average total loss: 1.421496
tensor(-12.7408, device='cuda:0') tensor(0.5662, device='cuda:0') tensor(7.2094e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 1.025707
Average KL loss: 0.396757
Average total loss: 1.422464
tensor(-12.7633, device='cuda:0') tensor(0.5662, device='cuda:0') tensor(7.5941e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 1.026520
Average KL loss: 0.396555
Average total loss: 1.423075
tensor(-12.7859, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(3.5469e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 1.024413
Average KL loss: 0.396350
Average total loss: 1.420763
tensor(-12.8083, device='cuda:0') tensor(0.5661, device='cuda:0') tensor(2.5803e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 1.024887
Average KL loss: 0.396262
Average total loss: 1.421149
tensor(-12.8307, device='cuda:0') tensor(0.5659, device='cuda:0') tensor(1.3641e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 1.025437
Average KL loss: 0.396286
Average total loss: 1.421723
tensor(-12.8531, device='cuda:0') tensor(0.5658, device='cuda:0') tensor(3.1525e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 1.024418
Average KL loss: 0.396236
Average total loss: 1.420653
tensor(-12.8753, device='cuda:0') tensor(0.5657, device='cuda:0') tensor(3.9494e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 1.025135
Average KL loss: 0.395995
Average total loss: 1.421130
tensor(-12.8976, device='cuda:0') tensor(0.5655, device='cuda:0') tensor(3.1674e-11, device='cuda:0')
Epoch 189
Average batch original loss after noise: 1.024948
Average KL loss: 0.395710
Average total loss: 1.420658
tensor(-12.9197, device='cuda:0') tensor(0.5653, device='cuda:0') tensor(7.8570e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 1.024555
Average KL loss: 0.395733
Average total loss: 1.420287
tensor(-12.9418, device='cuda:0') tensor(0.5652, device='cuda:0') tensor(4.1121e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 1.023229
Average KL loss: 0.395465
Average total loss: 1.418694
tensor(-12.9639, device='cuda:0') tensor(0.5650, device='cuda:0') tensor(5.1370e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 1.023501
Average KL loss: 0.395384
Average total loss: 1.418885
tensor(-12.9858, device='cuda:0') tensor(0.5648, device='cuda:0') tensor(-1.6232e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 1.024440
Average KL loss: 0.395432
Average total loss: 1.419871
tensor(-13.0078, device='cuda:0') tensor(0.5646, device='cuda:0') tensor(4.2628e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 1.022791
Average KL loss: 0.395329
Average total loss: 1.418120
tensor(-13.0296, device='cuda:0') tensor(0.5643, device='cuda:0') tensor(4.8285e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 1.023692
Average KL loss: 0.395203
Average total loss: 1.418895
tensor(-13.0514, device='cuda:0') tensor(0.5639, device='cuda:0') tensor(4.8902e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 1.023369
Average KL loss: 0.395155
Average total loss: 1.418524
tensor(-13.0731, device='cuda:0') tensor(0.5636, device='cuda:0') tensor(1.8995e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 1.022258
Average KL loss: 0.394885
Average total loss: 1.417144
tensor(-13.0948, device='cuda:0') tensor(0.5635, device='cuda:0') tensor(7.6229e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 1.023517
Average KL loss: 0.394877
Average total loss: 1.418394
tensor(-13.1164, device='cuda:0') tensor(0.5630, device='cuda:0') tensor(2.5166e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 1.022715
Average KL loss: 0.394636
Average total loss: 1.417351
tensor(-13.1379, device='cuda:0') tensor(0.5627, device='cuda:0') tensor(2.7065e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 1.021550
Average KL loss: 0.394395
Average total loss: 1.415945
 Percentile value: -13.477023124694824
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1721 /    1728             ( 99.59%) | total_pruned =       7 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   35700 /   36864             ( 96.84%) | total_pruned =    1164 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   35801 /   36864             ( 97.12%) | total_pruned =    1063 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   35449 /   36864             ( 96.16%) | total_pruned =    1415 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   35065 /   36864             ( 95.12%) | total_pruned =    1799 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   71133 /   73728             ( 96.48%) | total_pruned =    2595 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  138473 /  147456             ( 93.91%) | total_pruned =    8983 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8095 /    8192             ( 98.82%) | total_pruned =      97 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  137672 /  147456             ( 93.36%) | total_pruned =    9784 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  135147 /  147456             ( 91.65%) | total_pruned =   12309 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  276514 /  294912             ( 93.76%) | total_pruned =   18398 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  526455 /  589824             ( 89.26%) | total_pruned =   63369 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   31874 /   32768             ( 97.27%) | total_pruned =     894 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  507042 /  589824             ( 85.96%) | total_pruned =   82782 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  488701 /  589824             ( 82.86%) | total_pruned =  101123 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1038247 / 1179648             ( 88.01%) | total_pruned =  141401 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1839770 / 2359296             ( 77.98%) | total_pruned =  519526 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  122641 /  131072             ( 93.57%) | total_pruned =    8431 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1829444 / 2359296             ( 77.54%) | total_pruned =  529852 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1633363 / 2359296             ( 69.23%) | total_pruned =  725933 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
linear.weight        | nonzeros =    5110 /    5120             ( 99.80%) | total_pruned =      10 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 55/100 Loss: 0.000006 Accuracy: 86.64 100.00 % Best test Accuracy: 86.72%
tensor(-13.1594, device='cuda:0') tensor(0.5623, device='cuda:0') tensor(-2.5958e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.134018
Average KL loss: 0.389918
Average total loss: 1.523936
tensor(-13.2719, device='cuda:0') tensor(0.3771, device='cuda:0') tensor(-1.3164e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.189415
Average KL loss: 0.369276
Average total loss: 1.558692
tensor(-13.3643, device='cuda:0') tensor(0.2945, device='cuda:0') tensor(-1.3228e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.206190
Average KL loss: 0.357632
Average total loss: 1.563821
tensor(-13.4452, device='cuda:0') tensor(0.2529, device='cuda:0') tensor(-6.3832e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.185363
Average KL loss: 0.355247
Average total loss: 1.540610
tensor(-13.5182, device='cuda:0') tensor(0.2272, device='cuda:0') tensor(-6.6517e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.163128
Average KL loss: 0.354717
Average total loss: 1.517845
tensor(-13.5852, device='cuda:0') tensor(0.2092, device='cuda:0') tensor(-5.2497e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.140362
Average KL loss: 0.354008
Average total loss: 1.494370
tensor(-13.6474, device='cuda:0') tensor(0.1962, device='cuda:0') tensor(-2.3988e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.133030
Average KL loss: 0.353758
Average total loss: 1.486788
tensor(-13.7054, device='cuda:0') tensor(0.1864, device='cuda:0') tensor(-5.4667e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.122114
Average KL loss: 0.353306
Average total loss: 1.475420
tensor(-13.7599, device='cuda:0') tensor(0.1789, device='cuda:0') tensor(-3.4329e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.117051
Average KL loss: 0.353024
Average total loss: 1.470074
tensor(-13.8113, device='cuda:0') tensor(0.1730, device='cuda:0') tensor(-3.1906e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.106028
Average KL loss: 0.352598
Average total loss: 1.458626
tensor(-13.8601, device='cuda:0') tensor(0.1684, device='cuda:0') tensor(-2.8218e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.101777
Average KL loss: 0.351894
Average total loss: 1.453670
tensor(-13.9064, device='cuda:0') tensor(0.1647, device='cuda:0') tensor(-1.4064e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.093710
Average KL loss: 0.351102
Average total loss: 1.444812
tensor(-13.9506, device='cuda:0') tensor(0.1616, device='cuda:0') tensor(1.2148e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.097712
Average KL loss: 0.350177
Average total loss: 1.447889
tensor(-13.9928, device='cuda:0') tensor(0.1590, device='cuda:0') tensor(-1.6319e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.094175
Average KL loss: 0.349800
Average total loss: 1.443975
tensor(-14.0332, device='cuda:0') tensor(0.1572, device='cuda:0') tensor(-8.6111e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.087270
Average KL loss: 0.349412
Average total loss: 1.436683
tensor(-14.0720, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(-1.6575e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.084312
Average KL loss: 0.349542
Average total loss: 1.433854
tensor(-14.1093, device='cuda:0') tensor(0.1546, device='cuda:0') tensor(-8.0178e-11, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.080901
Average KL loss: 0.349320
Average total loss: 1.430221
tensor(-14.1452, device='cuda:0') tensor(0.1534, device='cuda:0') tensor(-4.2926e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.078456
Average KL loss: 0.348787
Average total loss: 1.427243
tensor(-14.1798, device='cuda:0') tensor(0.1525, device='cuda:0') tensor(2.2581e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.076187
Average KL loss: 0.348334
Average total loss: 1.424522
tensor(-14.2132, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-5.3877e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.072888
Average KL loss: 0.347975
Average total loss: 1.420863
tensor(-14.2456, device='cuda:0') tensor(0.1514, device='cuda:0') tensor(-1.4402e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.071534
Average KL loss: 0.347846
Average total loss: 1.419380
tensor(-14.2769, device='cuda:0') tensor(0.1512, device='cuda:0') tensor(-2.3437e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.071181
Average KL loss: 0.347478
Average total loss: 1.418659
tensor(-14.3072, device='cuda:0') tensor(0.1509, device='cuda:0') tensor(-9.1449e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.069493
Average KL loss: 0.346916
Average total loss: 1.416409
tensor(-14.3366, device='cuda:0') tensor(0.1508, device='cuda:0') tensor(-1.1881e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.068013
Average KL loss: 0.346454
Average total loss: 1.414467
tensor(-14.3652, device='cuda:0') tensor(0.1508, device='cuda:0') tensor(-8.8742e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.066946
Average KL loss: 0.345942
Average total loss: 1.412887
tensor(-14.3929, device='cuda:0') tensor(0.1507, device='cuda:0') tensor(-1.7598e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.066579
Average KL loss: 0.345577
Average total loss: 1.412157
tensor(-14.4199, device='cuda:0') tensor(0.1508, device='cuda:0') tensor(-1.2296e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.066513
Average KL loss: 0.345311
Average total loss: 1.411824
tensor(-14.4462, device='cuda:0') tensor(0.1509, device='cuda:0') tensor(-3.3468e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.067182
Average KL loss: 0.345092
Average total loss: 1.412274
tensor(-14.4718, device='cuda:0') tensor(0.1511, device='cuda:0') tensor(-2.8723e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.065316
Average KL loss: 0.344928
Average total loss: 1.410244
tensor(-14.4967, device='cuda:0') tensor(0.1514, device='cuda:0') tensor(1.4899e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.062245
Average KL loss: 0.344699
Average total loss: 1.406943
tensor(-14.5211, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(-3.5672e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.061762
Average KL loss: 0.344282
Average total loss: 1.406044
tensor(-14.5448, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-5.3863e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.063434
Average KL loss: 0.344044
Average total loss: 1.407477
tensor(-14.5680, device='cuda:0') tensor(0.1522, device='cuda:0') tensor(2.2323e-11, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.062581
Average KL loss: 0.343989
Average total loss: 1.406570
tensor(-14.5907, device='cuda:0') tensor(0.1525, device='cuda:0') tensor(-9.9081e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.062097
Average KL loss: 0.343881
Average total loss: 1.405978
tensor(-14.6128, device='cuda:0') tensor(0.1528, device='cuda:0') tensor(-2.6485e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.059699
Average KL loss: 0.343479
Average total loss: 1.403179
tensor(-14.6345, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(6.9714e-11, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.059623
Average KL loss: 0.342950
Average total loss: 1.402572
tensor(-14.6557, device='cuda:0') tensor(0.1533, device='cuda:0') tensor(-1.1741e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.060783
Average KL loss: 0.342665
Average total loss: 1.403448
tensor(-14.6765, device='cuda:0') tensor(0.1537, device='cuda:0') tensor(-1.2377e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.060463
Average KL loss: 0.342323
Average total loss: 1.402786
tensor(-14.6969, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(-8.1239e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.059691
Average KL loss: 0.341901
Average total loss: 1.401592
tensor(-14.7168, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(-1.3132e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.059997
Average KL loss: 0.341574
Average total loss: 1.401571
tensor(-14.7363, device='cuda:0') tensor(0.1549, device='cuda:0') tensor(-1.0078e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.058539
Average KL loss: 0.341335
Average total loss: 1.399874
tensor(-14.7555, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(1.7657e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.057843
Average KL loss: 0.341221
Average total loss: 1.399065
tensor(-14.7743, device='cuda:0') tensor(0.1555, device='cuda:0') tensor(-5.1577e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.057101
Average KL loss: 0.341090
Average total loss: 1.398192
tensor(-14.7928, device='cuda:0') tensor(0.1559, device='cuda:0') tensor(-1.1322e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.055776
Average KL loss: 0.340811
Average total loss: 1.396587
tensor(-14.8109, device='cuda:0') tensor(0.1564, device='cuda:0') tensor(5.7646e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.056365
Average KL loss: 0.340349
Average total loss: 1.396714
tensor(-14.8287, device='cuda:0') tensor(0.1568, device='cuda:0') tensor(2.0243e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.057384
Average KL loss: 0.339724
Average total loss: 1.397109
tensor(-14.8462, device='cuda:0') tensor(0.1572, device='cuda:0') tensor(-1.5570e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.057081
Average KL loss: 0.339502
Average total loss: 1.396584
tensor(-14.8634, device='cuda:0') tensor(0.1576, device='cuda:0') tensor(-2.9869e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.056788
Average KL loss: 0.339615
Average total loss: 1.396403
tensor(-14.8803, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-1.5099e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.055993
Average KL loss: 0.339463
Average total loss: 1.395456
tensor(-14.8969, device='cuda:0') tensor(0.1584, device='cuda:0') tensor(-2.6235e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.056186
Average KL loss: 0.339291
Average total loss: 1.395477
tensor(-14.9132, device='cuda:0') tensor(0.1590, device='cuda:0') tensor(-1.0120e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.055280
Average KL loss: 0.339479
Average total loss: 1.394760
tensor(-14.9293, device='cuda:0') tensor(0.1594, device='cuda:0') tensor(-1.7520e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.054896
Average KL loss: 0.339476
Average total loss: 1.394372
tensor(-14.9451, device='cuda:0') tensor(0.1599, device='cuda:0') tensor(-2.1562e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.055777
Average KL loss: 0.339324
Average total loss: 1.395101
tensor(-14.9607, device='cuda:0') tensor(0.1602, device='cuda:0') tensor(-2.0191e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.054539
Average KL loss: 0.339025
Average total loss: 1.393564
tensor(-14.9760, device='cuda:0') tensor(0.1607, device='cuda:0') tensor(-2.7164e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.054255
Average KL loss: 0.338832
Average total loss: 1.393087
tensor(-14.9911, device='cuda:0') tensor(0.1611, device='cuda:0') tensor(-1.0698e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.054264
Average KL loss: 0.338668
Average total loss: 1.392932
tensor(-15.0060, device='cuda:0') tensor(0.1615, device='cuda:0') tensor(-1.0577e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.054253
Average KL loss: 0.338628
Average total loss: 1.392882
tensor(-15.0207, device='cuda:0') tensor(0.1620, device='cuda:0') tensor(-6.8397e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.052893
Average KL loss: 0.338645
Average total loss: 1.391538
tensor(-15.0351, device='cuda:0') tensor(0.1624, device='cuda:0') tensor(-1.3459e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.052182
Average KL loss: 0.338593
Average total loss: 1.390776
tensor(-15.0493, device='cuda:0') tensor(0.1629, device='cuda:0') tensor(5.2988e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.053775
Average KL loss: 0.338510
Average total loss: 1.392285
tensor(-15.0634, device='cuda:0') tensor(0.1635, device='cuda:0') tensor(-7.2277e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.053294
Average KL loss: 0.338477
Average total loss: 1.391771
tensor(-15.0772, device='cuda:0') tensor(0.1639, device='cuda:0') tensor(2.7303e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.052761
Average KL loss: 0.338358
Average total loss: 1.391119
tensor(-15.0909, device='cuda:0') tensor(0.1644, device='cuda:0') tensor(2.6933e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.051829
Average KL loss: 0.338382
Average total loss: 1.390211
tensor(-15.1043, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(1.3832e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.053111
Average KL loss: 0.338338
Average total loss: 1.391448
tensor(-15.1176, device='cuda:0') tensor(0.1655, device='cuda:0') tensor(-1.7360e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.051665
Average KL loss: 0.338377
Average total loss: 1.390042
tensor(-15.1308, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(1.8791e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.052895
Average KL loss: 0.338205
Average total loss: 1.391100
tensor(-15.1437, device='cuda:0') tensor(0.1663, device='cuda:0') tensor(7.9088e-11, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.053567
Average KL loss: 0.337984
Average total loss: 1.391552
tensor(-15.1565, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-1.3624e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.053391
Average KL loss: 0.337722
Average total loss: 1.391113
tensor(-15.1691, device='cuda:0') tensor(0.1671, device='cuda:0') tensor(-5.7027e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.052513
Average KL loss: 0.337711
Average total loss: 1.390224
tensor(-15.1816, device='cuda:0') tensor(0.1674, device='cuda:0') tensor(-7.1827e-11, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.051844
Average KL loss: 0.337662
Average total loss: 1.389506
tensor(-15.1939, device='cuda:0') tensor(0.1677, device='cuda:0') tensor(5.4969e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.053327
Average KL loss: 0.337623
Average total loss: 1.390950
tensor(-15.2061, device='cuda:0') tensor(0.1681, device='cuda:0') tensor(-1.4964e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.051328
Average KL loss: 0.337613
Average total loss: 1.388942
tensor(-15.2181, device='cuda:0') tensor(0.1684, device='cuda:0') tensor(-4.5575e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.050859
Average KL loss: 0.337491
Average total loss: 1.388350
tensor(-15.2300, device='cuda:0') tensor(0.1686, device='cuda:0') tensor(7.9907e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.052694
Average KL loss: 0.337200
Average total loss: 1.389894
tensor(-15.2417, device='cuda:0') tensor(0.1690, device='cuda:0') tensor(-1.1073e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.051469
Average KL loss: 0.337092
Average total loss: 1.388561
tensor(-15.2533, device='cuda:0') tensor(0.1696, device='cuda:0') tensor(-4.3531e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.050197
Average KL loss: 0.337044
Average total loss: 1.387241
tensor(-15.2648, device='cuda:0') tensor(0.1699, device='cuda:0') tensor(3.2511e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.050942
Average KL loss: 0.336896
Average total loss: 1.387839
tensor(-15.2761, device='cuda:0') tensor(0.1702, device='cuda:0') tensor(2.4754e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.050616
Average KL loss: 0.336674
Average total loss: 1.387290
tensor(-15.2873, device='cuda:0') tensor(0.1706, device='cuda:0') tensor(-1.8576e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.051514
Average KL loss: 0.336661
Average total loss: 1.388176
tensor(-15.2984, device='cuda:0') tensor(0.1710, device='cuda:0') tensor(-3.6885e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.051936
Average KL loss: 0.336481
Average total loss: 1.388416
tensor(-15.3093, device='cuda:0') tensor(0.1713, device='cuda:0') tensor(2.4895e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.050605
Average KL loss: 0.336402
Average total loss: 1.387008
tensor(-15.3202, device='cuda:0') tensor(0.1717, device='cuda:0') tensor(-3.6116e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.049588
Average KL loss: 0.336483
Average total loss: 1.386070
tensor(-15.3309, device='cuda:0') tensor(0.1722, device='cuda:0') tensor(-1.6847e-11, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.050095
Average KL loss: 0.336565
Average total loss: 1.386659
tensor(-15.3415, device='cuda:0') tensor(0.1727, device='cuda:0') tensor(4.4018e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.049782
Average KL loss: 0.336537
Average total loss: 1.386319
tensor(-15.3520, device='cuda:0') tensor(0.1730, device='cuda:0') tensor(-3.5753e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.049928
Average KL loss: 0.336331
Average total loss: 1.386259
tensor(-15.3624, device='cuda:0') tensor(0.1734, device='cuda:0') tensor(-2.2013e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.049942
Average KL loss: 0.336055
Average total loss: 1.385996
tensor(-15.3727, device='cuda:0') tensor(0.1738, device='cuda:0') tensor(-7.1987e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.049741
Average KL loss: 0.335889
Average total loss: 1.385630
tensor(-15.3829, device='cuda:0') tensor(0.1740, device='cuda:0') tensor(9.7329e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.049975
Average KL loss: 0.335823
Average total loss: 1.385798
tensor(-15.3930, device='cuda:0') tensor(0.1743, device='cuda:0') tensor(3.8613e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.050228
Average KL loss: 0.335861
Average total loss: 1.386089
tensor(-15.4029, device='cuda:0') tensor(0.1747, device='cuda:0') tensor(-1.4660e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.048658
Average KL loss: 0.335771
Average total loss: 1.384429
tensor(-15.4128, device='cuda:0') tensor(0.1750, device='cuda:0') tensor(-9.6199e-11, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.050305
Average KL loss: 0.335772
Average total loss: 1.386077
tensor(-15.4226, device='cuda:0') tensor(0.1754, device='cuda:0') tensor(-1.4784e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.049190
Average KL loss: 0.335686
Average total loss: 1.384875
tensor(-15.4323, device='cuda:0') tensor(0.1758, device='cuda:0') tensor(-2.7425e-12, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.050508
Average KL loss: 0.335596
Average total loss: 1.386105
tensor(-15.4419, device='cuda:0') tensor(0.1762, device='cuda:0') tensor(-2.7953e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.051367
Average KL loss: 0.335552
Average total loss: 1.386919
tensor(-15.4514, device='cuda:0') tensor(0.1765, device='cuda:0') tensor(3.4419e-11, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.050549
Average KL loss: 0.335637
Average total loss: 1.386186
tensor(-15.4608, device='cuda:0') tensor(0.1769, device='cuda:0') tensor(3.4473e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.048356
Average KL loss: 0.335606
Average total loss: 1.383962
tensor(-15.4701, device='cuda:0') tensor(0.1772, device='cuda:0') tensor(6.3312e-11, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.047947
Average KL loss: 0.335615
Average total loss: 1.383561
tensor(-15.4794, device='cuda:0') tensor(0.1776, device='cuda:0') tensor(-2.0386e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.049523
Average KL loss: 0.335556
Average total loss: 1.385079
tensor(-15.4885, device='cuda:0') tensor(0.1778, device='cuda:0') tensor(-3.9537e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.048805
Average KL loss: 0.335475
Average total loss: 1.384280
tensor(-15.4976, device='cuda:0') tensor(0.1782, device='cuda:0') tensor(-1.2288e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.047670
Average KL loss: 0.335659
Average total loss: 1.383329
tensor(-15.5066, device='cuda:0') tensor(0.1786, device='cuda:0') tensor(7.8058e-12, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.048990
Average KL loss: 0.335699
Average total loss: 1.384689
tensor(-15.5155, device='cuda:0') tensor(0.1789, device='cuda:0') tensor(-2.4381e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.048239
Average KL loss: 0.335627
Average total loss: 1.383865
tensor(-15.5243, device='cuda:0') tensor(0.1793, device='cuda:0') tensor(7.8810e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.048433
Average KL loss: 0.335655
Average total loss: 1.384088
tensor(-15.5331, device='cuda:0') tensor(0.1795, device='cuda:0') tensor(-8.2338e-11, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.048770
Average KL loss: 0.335736
Average total loss: 1.384507
tensor(-15.5418, device='cuda:0') tensor(0.1798, device='cuda:0') tensor(5.0412e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.048125
Average KL loss: 0.335761
Average total loss: 1.383886
tensor(-15.5504, device='cuda:0') tensor(0.1800, device='cuda:0') tensor(-4.5473e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.048882
Average KL loss: 0.335632
Average total loss: 1.384514
tensor(-15.5589, device='cuda:0') tensor(0.1804, device='cuda:0') tensor(-2.2445e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.048607
Average KL loss: 0.335542
Average total loss: 1.384150
tensor(-15.5674, device='cuda:0') tensor(0.1808, device='cuda:0') tensor(-7.4455e-11, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.049284
Average KL loss: 0.335460
Average total loss: 1.384744
tensor(-15.5758, device='cuda:0') tensor(0.1812, device='cuda:0') tensor(1.9525e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.050024
Average KL loss: 0.335401
Average total loss: 1.385425
tensor(-15.5841, device='cuda:0') tensor(0.1815, device='cuda:0') tensor(-9.5118e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.048388
Average KL loss: 0.335416
Average total loss: 1.383805
tensor(-15.5923, device='cuda:0') tensor(0.1819, device='cuda:0') tensor(2.3374e-11, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.048827
Average KL loss: 0.335533
Average total loss: 1.384360
tensor(-15.6005, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(-3.7897e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.047796
Average KL loss: 0.335548
Average total loss: 1.383344
tensor(-15.6013, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(2.1234e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.047948
Average KL loss: 0.335545
Average total loss: 1.383493
tensor(-15.6021, device='cuda:0') tensor(0.1823, device='cuda:0') tensor(-3.8272e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.047697
Average KL loss: 0.335548
Average total loss: 1.383245
tensor(-15.6029, device='cuda:0') tensor(0.1824, device='cuda:0') tensor(-2.9837e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.048408
Average KL loss: 0.335543
Average total loss: 1.383951
tensor(-15.6038, device='cuda:0') tensor(0.1824, device='cuda:0') tensor(2.1174e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.048256
Average KL loss: 0.335543
Average total loss: 1.383799
tensor(-15.6046, device='cuda:0') tensor(0.1824, device='cuda:0') tensor(-4.5785e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.047314
Average KL loss: 0.335536
Average total loss: 1.382850
tensor(-15.6054, device='cuda:0') tensor(0.1825, device='cuda:0') tensor(-1.9811e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.049088
Average KL loss: 0.335525
Average total loss: 1.384613
tensor(-15.6062, device='cuda:0') tensor(0.1825, device='cuda:0') tensor(6.3439e-11, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.048087
Average KL loss: 0.335518
Average total loss: 1.383605
tensor(-15.6070, device='cuda:0') tensor(0.1825, device='cuda:0') tensor(1.3671e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.047352
Average KL loss: 0.335508
Average total loss: 1.382860
tensor(-15.6078, device='cuda:0') tensor(0.1825, device='cuda:0') tensor(-5.0658e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.048226
Average KL loss: 0.335497
Average total loss: 1.383723
tensor(-15.6086, device='cuda:0') tensor(0.1825, device='cuda:0') tensor(7.4760e-12, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.048174
Average KL loss: 0.335493
Average total loss: 1.383668
tensor(-15.6094, device='cuda:0') tensor(0.1826, device='cuda:0') tensor(-3.5275e-11, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.048211
Average KL loss: 0.335491
Average total loss: 1.383702
tensor(-15.6102, device='cuda:0') tensor(0.1826, device='cuda:0') tensor(9.5992e-11, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.047263
Average KL loss: 0.335499
Average total loss: 1.382762
tensor(-15.6110, device='cuda:0') tensor(0.1826, device='cuda:0') tensor(-2.2569e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.048319
Average KL loss: 0.335490
Average total loss: 1.383810
tensor(-15.6118, device='cuda:0') tensor(0.1826, device='cuda:0') tensor(-4.8229e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.049145
Average KL loss: 0.335491
Average total loss: 1.384636
tensor(-15.6127, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(8.1460e-11, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.048006
Average KL loss: 0.335489
Average total loss: 1.383495
tensor(-15.6135, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-3.6813e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.047809
Average KL loss: 0.335486
Average total loss: 1.383295
tensor(-15.6143, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-4.7418e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.047602
Average KL loss: 0.335486
Average total loss: 1.383087
tensor(-15.6144, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-4.1845e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.049031
Average KL loss: 0.335484
Average total loss: 1.384515
tensor(-15.6145, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-1.7422e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.047675
Average KL loss: 0.335483
Average total loss: 1.383158
tensor(-15.6146, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-5.2733e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.047803
Average KL loss: 0.335482
Average total loss: 1.383285
tensor(-15.6146, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(2.0072e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.047414
Average KL loss: 0.335481
Average total loss: 1.382896
tensor(-15.6147, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(1.7009e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.048522
Average KL loss: 0.335481
Average total loss: 1.384003
tensor(-15.6148, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-2.1082e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.048164
Average KL loss: 0.335479
Average total loss: 1.383644
tensor(-15.6149, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(1.8036e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.048131
Average KL loss: 0.335479
Average total loss: 1.383610
tensor(-15.6150, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-1.3788e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.049061
Average KL loss: 0.335478
Average total loss: 1.384539
tensor(-15.6151, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(4.6076e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.047635
Average KL loss: 0.335478
Average total loss: 1.383113
tensor(-15.6152, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(2.4047e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.048081
Average KL loss: 0.335478
Average total loss: 1.383559
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-2.1286e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.048108
Average KL loss: 0.335478
Average total loss: 1.383586
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-2.3237e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.047690
Average KL loss: 0.335478
Average total loss: 1.383168
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(3.5220e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.047730
Average KL loss: 0.335477
Average total loss: 1.383207
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-1.2269e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.047504
Average KL loss: 0.335477
Average total loss: 1.382981
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-1.8497e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.048298
Average KL loss: 0.335477
Average total loss: 1.383775
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(1.1626e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.047198
Average KL loss: 0.335477
Average total loss: 1.382675
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(1.9633e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.048298
Average KL loss: 0.335477
Average total loss: 1.383775
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-6.1507e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.047497
Average KL loss: 0.335477
Average total loss: 1.382974
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(1.1329e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.047911
Average KL loss: 0.335477
Average total loss: 1.383388
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-8.9994e-11, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.047717
Average KL loss: 0.335477
Average total loss: 1.383194
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(6.0362e-11, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.047684
Average KL loss: 0.335477
Average total loss: 1.383161
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-9.5835e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.048321
Average KL loss: 0.335477
Average total loss: 1.383798
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-1.5489e-11, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.048321
Average KL loss: 0.335477
Average total loss: 1.383798
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-5.3348e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.047656
Average KL loss: 0.335477
Average total loss: 1.383133
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(6.5798e-11, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.047481
Average KL loss: 0.335477
Average total loss: 1.382958
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-3.6189e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.047571
Average KL loss: 0.335477
Average total loss: 1.383048
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-6.0872e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.047243
Average KL loss: 0.335477
Average total loss: 1.382720
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-9.6284e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.047376
Average KL loss: 0.335477
Average total loss: 1.382853
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(6.2271e-13, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.048761
Average KL loss: 0.335477
Average total loss: 1.384238
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-5.6275e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.048381
Average KL loss: 0.335477
Average total loss: 1.383858
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(1.6622e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.048229
Average KL loss: 0.335477
Average total loss: 1.383706
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-2.1639e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.048225
Average KL loss: 0.335477
Average total loss: 1.383702
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-6.5042e-11, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.048342
Average KL loss: 0.335477
Average total loss: 1.383819
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(6.1678e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.048091
Average KL loss: 0.335477
Average total loss: 1.383568
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(2.6541e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.048503
Average KL loss: 0.335477
Average total loss: 1.383980
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(8.9692e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.047003
Average KL loss: 0.335477
Average total loss: 1.382480
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-1.8971e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.049790
Average KL loss: 0.335477
Average total loss: 1.385267
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(3.3128e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.047589
Average KL loss: 0.335477
Average total loss: 1.383066
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-3.6139e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.047236
Average KL loss: 0.335477
Average total loss: 1.382713
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-6.3085e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.047663
Average KL loss: 0.335477
Average total loss: 1.383140
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-1.2355e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.048157
Average KL loss: 0.335477
Average total loss: 1.383634
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-3.9478e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.047471
Average KL loss: 0.335477
Average total loss: 1.382947
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(4.9044e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 1.048500
Average KL loss: 0.335477
Average total loss: 1.383977
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(5.2926e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.048235
Average KL loss: 0.335477
Average total loss: 1.383712
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-1.8900e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.047904
Average KL loss: 0.335477
Average total loss: 1.383381
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(6.6368e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 1.048442
Average KL loss: 0.335477
Average total loss: 1.383919
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(-1.0392e-09, device='cuda:0')
 Percentile value: -15.642339706420898
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1711 /    1728             ( 99.02%) | total_pruned =      17 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   34867 /   36864             ( 94.58%) | total_pruned =    1997 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   35083 /   36864             ( 95.17%) | total_pruned =    1781 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   34584 /   36864             ( 93.82%) | total_pruned =    2280 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   33936 /   36864             ( 92.06%) | total_pruned =    2928 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   69593 /   73728             ( 94.39%) | total_pruned =    4135 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  132325 /  147456             ( 89.74%) | total_pruned =   15131 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8056 /    8192             ( 98.34%) | total_pruned =     136 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  131213 /  147456             ( 88.98%) | total_pruned =   16243 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  126638 /  147456             ( 85.88%) | total_pruned =   20818 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  264555 /  294912             ( 89.71%) | total_pruned =   30357 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  481804 /  589824             ( 81.69%) | total_pruned =  108020 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   31331 /   32768             ( 95.61%) | total_pruned =    1437 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  447510 /  589824             ( 75.87%) | total_pruned =  142314 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  416335 /  589824             ( 70.59%) | total_pruned =  173489 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  941173 / 1179648             ( 79.78%) | total_pruned =  238475 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1449219 / 2359296             ( 61.43%) | total_pruned =  910077 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  117217 /  131072             ( 89.43%) | total_pruned =   13855 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1358260 / 2359296             ( 57.57%) | total_pruned = 1001036 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1024322 / 2359296             ( 43.42%) | total_pruned = 1334974 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
linear.weight        | nonzeros =    5096 /    5120             ( 99.53%) | total_pruned =      24 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 27/100 Loss: 0.000027 Accuracy: 86.99 100.00 % Best test Accuracy: 86.99%
tensor(-15.6153, device='cuda:0') tensor(0.1827, device='cuda:0') tensor(1.3298e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.118483
Average KL loss: 0.332531
Average total loss: 1.451014
tensor(-15.6244, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-3.7109e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.234606
Average KL loss: 0.316695
Average total loss: 1.551300
tensor(-15.6328, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-1.5831e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.231324
Average KL loss: 0.312410
Average total loss: 1.543735
tensor(-15.6407, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-2.0518e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.196719
Average KL loss: 0.312472
Average total loss: 1.509191
tensor(-15.6486, device='cuda:0') tensor(0.1217, device='cuda:0') tensor(-1.0912e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.179041
Average KL loss: 0.313222
Average total loss: 1.492263
tensor(-15.6563, device='cuda:0') tensor(0.1228, device='cuda:0') tensor(-7.0274e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.154665
Average KL loss: 0.313806
Average total loss: 1.468470
tensor(-15.6640, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-4.9318e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.148670
Average KL loss: 0.314327
Average total loss: 1.462997
tensor(-15.6716, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(1.6490e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.137754
Average KL loss: 0.314120
Average total loss: 1.451873
tensor(-15.6792, device='cuda:0') tensor(0.1262, device='cuda:0') tensor(-2.9612e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.125774
Average KL loss: 0.314097
Average total loss: 1.439871
tensor(-15.6867, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-3.4197e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.123522
Average KL loss: 0.314109
Average total loss: 1.437631
tensor(-15.6942, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-1.0983e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.123521
Average KL loss: 0.313783
Average total loss: 1.437304
tensor(-15.7016, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-2.9046e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.112028
Average KL loss: 0.313963
Average total loss: 1.425991
tensor(-15.7089, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(-1.3072e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.108304
Average KL loss: 0.314122
Average total loss: 1.422426
tensor(-15.7162, device='cuda:0') tensor(0.1313, device='cuda:0') tensor(-4.9376e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.109296
Average KL loss: 0.314265
Average total loss: 1.423560
tensor(-15.7234, device='cuda:0') tensor(0.1321, device='cuda:0') tensor(-8.2196e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.108015
Average KL loss: 0.314402
Average total loss: 1.422417
tensor(-15.7306, device='cuda:0') tensor(0.1331, device='cuda:0') tensor(-2.4789e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.098901
Average KL loss: 0.314286
Average total loss: 1.413188
tensor(-15.7378, device='cuda:0') tensor(0.1339, device='cuda:0') tensor(-1.4427e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.098772
Average KL loss: 0.314122
Average total loss: 1.412894
tensor(-15.7449, device='cuda:0') tensor(0.1347, device='cuda:0') tensor(-4.3589e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.095912
Average KL loss: 0.313702
Average total loss: 1.409613
tensor(-15.7519, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-3.3403e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.094542
Average KL loss: 0.313400
Average total loss: 1.407942
tensor(-15.7589, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(-1.4537e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.094110
Average KL loss: 0.313121
Average total loss: 1.407230
tensor(-15.7658, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-1.3307e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.092366
Average KL loss: 0.312909
Average total loss: 1.405276
tensor(-15.7727, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(-6.5531e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.091347
Average KL loss: 0.312619
Average total loss: 1.403965
tensor(-15.7796, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(-2.5845e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 55
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 56
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 57
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 58
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 59
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 60
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 61
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 62
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 63
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 64
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 65
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 66
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 67
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 68
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 69
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 70
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 71
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 72
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 73
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 74
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 75
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 76
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  405770 /  589824             ( 68.80%) | total_pruned =  184054 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  416335 /  589824             ( 70.59%) | total_pruned =  173489 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  941173 / 1179648             ( 79.78%) | total_pruned =  238475 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1449219 / 2359296             ( 61.43%) | total_pruned =  910077 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  117217 /  131072             ( 89.43%) | total_pruned =   13855 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1358260 / 2359296             ( 57.57%) | total_pruned = 1001036 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1024322 / 2359296             ( 43.42%) | total_pruned = 1334974 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
linear.weight        | nonzeros =    5096 /    5120             ( 99.53%) | total_pruned =      24 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 34/100 Loss: 2.302596 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  619596 / 1179648             ( 52.52%) | total_pruned =  560052 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1449219 / 2359296             ( 61.43%) | total_pruned =  910077 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  117217 /  131072             ( 89.43%) | total_pruned =   13855 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1358260 / 2359296             ( 57.57%) | total_pruned = 1001036 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1024322 / 2359296             ( 43.42%) | total_pruned = 1334974 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
linear.weight        | nonzeros =    5096 /    5120             ( 99.53%) | total_pruned =      24 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 34/100 Loss: 2.302604 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1154074 / 2359296             ( 48.92%) | total_pruned = 1205222 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  117217 /  131072             ( 89.43%) | total_pruned =   13855 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1358260 / 2359296             ( 57.57%) | total_pruned = 1001036 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1024322 / 2359296             ( 43.42%) | total_pruned = 1334974 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
linear.weight        | nonzeros =    5096 /    5120             ( 99.53%) | total_pruned =      24 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 34/100 Loss: 2.302628 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  421463 / 2359296             ( 17.86%) | total_pruned = 1937833 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  117217 /  131072             ( 89.43%) | total_pruned =   13855 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1358260 / 2359296             ( 57.57%) | total_pruned = 1001036 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1024322 / 2359296             ( 43.42%) | total_pruned = 1334974 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
linear.weight        | nonzeros =    5096 /    5120             ( 99.53%) | total_pruned =      24 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 34/100 Loss: 2.302628 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1312896 / 2359296             ( 55.65%) | total_pruned = 1046400 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1024322 / 2359296             ( 43.42%) | total_pruned = 1334974 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
linear.weight        | nonzeros =    5096 /    5120             ( 99.53%) | total_pruned =      24 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
Train Epoch: 34/100 Loss: 2.302646 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 16.777233123779297%, Non-zero mask percentage: 16.777233123779297%

--- Pruning Level [8/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  844025 / 2359296             ( 35.77%) | total_pruned = 1515271 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1024322 / 2359296             ( 43.42%) | total_pruned = 1334974 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
linear.weight        | nonzeros =    5096 /    5120             ( 99.53%) | total_pruned =      24 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 1875487, pruned : 9303275, total: 11178762, Compression rate :       5.96x  ( 83.22% pruned)
