Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.781581
Average KL loss: 0.022915
Average total loss: 1.804496
tensor(0.0006, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.1547e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.479979
Average KL loss: 0.058272
Average total loss: 1.538250
tensor(0.0007, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.5852e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.272481
Average KL loss: 0.076328
Average total loss: 1.348809
tensor(0.0008, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.5496e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.138971
Average KL loss: 0.085166
Average total loss: 1.224137
tensor(0.0009, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.1944e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.051031
Average KL loss: 0.091656
Average total loss: 1.142688
tensor(0.0012, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.5875e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.969904
Average KL loss: 0.095247
Average total loss: 1.065151
tensor(0.0013, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.8225e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.903427
Average KL loss: 0.097790
Average total loss: 1.001218
tensor(0.0016, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.0753e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.849244
Average KL loss: 0.100548
Average total loss: 0.949792
tensor(0.0017, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.4542e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.777373
Average KL loss: 0.102282
Average total loss: 0.879656
tensor(0.0019, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.8526e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.748213
Average KL loss: 0.102905
Average total loss: 0.851118
tensor(0.0021, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-7.4957e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.712748
Average KL loss: 0.103284
Average total loss: 0.816031
tensor(0.0022, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.9964e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.671457
Average KL loss: 0.104221
Average total loss: 0.775679
tensor(0.0023, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.9778e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.630842
Average KL loss: 0.104695
Average total loss: 0.735537
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.1762e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.616385
Average KL loss: 0.105258
Average total loss: 0.721643
tensor(0.0026, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.4231e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.584807
Average KL loss: 0.105320
Average total loss: 0.690127
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.3865e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.548047
Average KL loss: 0.105806
Average total loss: 0.653853
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.6530e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.513818
Average KL loss: 0.104849
Average total loss: 0.618667
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.6244e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.504959
Average KL loss: 0.104445
Average total loss: 0.609404
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.8013e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.482208
Average KL loss: 0.104828
Average total loss: 0.587036
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.4251e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.467576
Average KL loss: 0.105407
Average total loss: 0.572983
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.8204e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.444845
Average KL loss: 0.105237
Average total loss: 0.550082
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.2903e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.423391
Average KL loss: 0.105376
Average total loss: 0.528767
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.9380e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.409753
Average KL loss: 0.104885
Average total loss: 0.514638
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.0351e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.394528
Average KL loss: 0.105057
Average total loss: 0.499585
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.8894e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.377975
Average KL loss: 0.104943
Average total loss: 0.482918
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6020e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.358811
Average KL loss: 0.104575
Average total loss: 0.463386
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6157e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.351345
Average KL loss: 0.104555
Average total loss: 0.455900
tensor(0.0038, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.2522e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.336375
Average KL loss: 0.104652
Average total loss: 0.441027
tensor(0.0039, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.7072e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.326326
Average KL loss: 0.104912
Average total loss: 0.431239
tensor(0.0039, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.0123e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.311376
Average KL loss: 0.104743
Average total loss: 0.416119
tensor(0.0039, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.7136e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.311340
Average KL loss: 0.104169
Average total loss: 0.415509
tensor(0.0040, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6583e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.292288
Average KL loss: 0.104393
Average total loss: 0.396681
tensor(0.0040, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.3398e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.277253
Average KL loss: 0.103879
Average total loss: 0.381131
tensor(0.0041, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.8263e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.274874
Average KL loss: 0.103563
Average total loss: 0.378437
tensor(0.0042, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.7256e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.272781
Average KL loss: 0.103917
Average total loss: 0.376698
tensor(0.0042, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.9162e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.257492
Average KL loss: 0.104074
Average total loss: 0.361566
tensor(0.0042, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.8884e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.255833
Average KL loss: 0.104825
Average total loss: 0.360657
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6402e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.246381
Average KL loss: 0.105121
Average total loss: 0.351502
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6849e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.237651
Average KL loss: 0.105181
Average total loss: 0.342831
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.8439e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.222925
Average KL loss: 0.104162
Average total loss: 0.327087
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.2318e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.217473
Average KL loss: 0.103188
Average total loss: 0.320661
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.0235e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.212115
Average KL loss: 0.103340
Average total loss: 0.315454
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4346e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.201699
Average KL loss: 0.102807
Average total loss: 0.304506
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.3994e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.210353
Average KL loss: 0.103091
Average total loss: 0.313444
tensor(0.0045, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.9570e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.196199
Average KL loss: 0.103497
Average total loss: 0.299696
tensor(0.0045, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8627e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.187141
Average KL loss: 0.102746
Average total loss: 0.289887
tensor(0.0045, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.6980e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.193485
Average KL loss: 0.102552
Average total loss: 0.296037
tensor(0.0045, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7766e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.180178
Average KL loss: 0.103224
Average total loss: 0.283402
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6197e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.165564
Average KL loss: 0.102694
Average total loss: 0.268258
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.0271e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.170761
Average KL loss: 0.102141
Average total loss: 0.272901
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4624e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.165021
Average KL loss: 0.102143
Average total loss: 0.267164
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7684e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.158368
Average KL loss: 0.102216
Average total loss: 0.260584
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8231e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.155569
Average KL loss: 0.101831
Average total loss: 0.257400
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4833e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.153638
Average KL loss: 0.101074
Average total loss: 0.254712
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.2993e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.148839
Average KL loss: 0.101029
Average total loss: 0.249868
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5768e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.145185
Average KL loss: 0.100715
Average total loss: 0.245901
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5557e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.140930
Average KL loss: 0.100427
Average total loss: 0.241357
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5318e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.140946
Average KL loss: 0.100946
Average total loss: 0.241892
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.7981e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.135439
Average KL loss: 0.100745
Average total loss: 0.236184
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5378e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.127886
Average KL loss: 0.100556
Average total loss: 0.228442
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7945e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.124548
Average KL loss: 0.099436
Average total loss: 0.223984
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0687e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.122970
Average KL loss: 0.098844
Average total loss: 0.221815
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3015e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.125966
Average KL loss: 0.099451
Average total loss: 0.225417
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6158e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.116570
Average KL loss: 0.099011
Average total loss: 0.215582
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.4844e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.113034
Average KL loss: 0.098034
Average total loss: 0.211068
tensor(0.0047, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1456e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.120709
Average KL loss: 0.097709
Average total loss: 0.218418
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3005e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.108732
Average KL loss: 0.098420
Average total loss: 0.207151
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5837e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.111783
Average KL loss: 0.098414
Average total loss: 0.210197
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.9634e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.113613
Average KL loss: 0.098283
Average total loss: 0.211896
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.6512e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.108252
Average KL loss: 0.098988
Average total loss: 0.207240
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.0617e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.104926
Average KL loss: 0.098901
Average total loss: 0.203827
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.5565e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.101908
Average KL loss: 0.098127
Average total loss: 0.200035
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.9785e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.096727
Average KL loss: 0.097325
Average total loss: 0.194052
tensor(0.0048, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.5567e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.101155
Average KL loss: 0.097302
Average total loss: 0.198458
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.1604e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.092656
Average KL loss: 0.097257
Average total loss: 0.189914
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.8732e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.098571
Average KL loss: 0.097537
Average total loss: 0.196107
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.9620e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.094356
Average KL loss: 0.098037
Average total loss: 0.192393
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.8142e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.092114
Average KL loss: 0.097569
Average total loss: 0.189683
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.6523e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.089041
Average KL loss: 0.097587
Average total loss: 0.186628
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.9336e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.087515
Average KL loss: 0.096662
Average total loss: 0.184176
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.6550e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.081658
Average KL loss: 0.095857
Average total loss: 0.177515
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.0571e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.085028
Average KL loss: 0.095018
Average total loss: 0.180046
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.2132e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.081676
Average KL loss: 0.094469
Average total loss: 0.176146
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0701e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.082045
Average KL loss: 0.095047
Average total loss: 0.177092
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.9775e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.081214
Average KL loss: 0.095063
Average total loss: 0.176278
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.6232e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.082661
Average KL loss: 0.095654
Average total loss: 0.178316
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.8928e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.078849
Average KL loss: 0.095893
Average total loss: 0.174741
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.6612e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.073816
Average KL loss: 0.095176
Average total loss: 0.168992
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.4495e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.073589
Average KL loss: 0.093897
Average total loss: 0.167486
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.3313e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.074293
Average KL loss: 0.094082
Average total loss: 0.168376
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.4775e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.071842
Average KL loss: 0.093958
Average total loss: 0.165800
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.0131e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.070900
Average KL loss: 0.094063
Average total loss: 0.164963
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.0265e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.071145
Average KL loss: 0.093464
Average total loss: 0.164609
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.7075e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.065632
Average KL loss: 0.093602
Average total loss: 0.159234
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.8177e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.069612
Average KL loss: 0.093171
Average total loss: 0.162784
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.9970e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.066480
Average KL loss: 0.093743
Average total loss: 0.160223
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2373e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.063725
Average KL loss: 0.092671
Average total loss: 0.156395
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3134e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.066125
Average KL loss: 0.092557
Average total loss: 0.158682
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.5158e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.062936
Average KL loss: 0.092801
Average total loss: 0.155737
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.9893e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.065525
Average KL loss: 0.092323
Average total loss: 0.157848
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.4077e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.060252
Average KL loss: 0.092750
Average total loss: 0.153002
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.4921e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.062894
Average KL loss: 0.091779
Average total loss: 0.154673
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.5107e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.059602
Average KL loss: 0.092448
Average total loss: 0.152049
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.7977e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.059708
Average KL loss: 0.091818
Average total loss: 0.151526
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.3837e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.058585
Average KL loss: 0.091326
Average total loss: 0.149911
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.4487e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.056023
Average KL loss: 0.090879
Average total loss: 0.146902
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2990e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.057102
Average KL loss: 0.090827
Average total loss: 0.147930
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.7662e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.057153
Average KL loss: 0.091195
Average total loss: 0.148348
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.2678e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.055326
Average KL loss: 0.090385
Average total loss: 0.145711
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.4728e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.056119
Average KL loss: 0.090345
Average total loss: 0.146465
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.5202e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.057698
Average KL loss: 0.091418
Average total loss: 0.149115
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.6245e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.052311
Average KL loss: 0.091136
Average total loss: 0.143447
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.5827e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.052438
Average KL loss: 0.089820
Average total loss: 0.142259
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.1456e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.054580
Average KL loss: 0.090505
Average total loss: 0.145085
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.5763e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.052857
Average KL loss: 0.090166
Average total loss: 0.143023
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.1179e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.053456
Average KL loss: 0.090487
Average total loss: 0.143943
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8786e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.052757
Average KL loss: 0.090816
Average total loss: 0.143573
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.6519e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.053488
Average KL loss: 0.091435
Average total loss: 0.144922
tensor(0.0046, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.9328e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.050291
Average KL loss: 0.091249
Average total loss: 0.141540
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.0470e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.049077
Average KL loss: 0.090464
Average total loss: 0.139540
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1736e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.046923
Average KL loss: 0.089705
Average total loss: 0.136628
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.1624e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.049107
Average KL loss: 0.089156
Average total loss: 0.138263
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.5521e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.047763
Average KL loss: 0.089396
Average total loss: 0.137159
tensor(0.0045, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.8167e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.048201
Average KL loss: 0.089247
Average total loss: 0.137447
tensor(0.0045, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.0370e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.046576
Average KL loss: 0.088985
Average total loss: 0.135561
tensor(0.0045, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.3068e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.048412
Average KL loss: 0.089484
Average total loss: 0.137896
tensor(0.0045, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.9681e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.047136
Average KL loss: 0.089814
Average total loss: 0.136950
tensor(0.0045, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.2743e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.049656
Average KL loss: 0.090647
Average total loss: 0.140304
tensor(0.0046, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0727e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.045735
Average KL loss: 0.090068
Average total loss: 0.135803
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.6646e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.046527
Average KL loss: 0.089819
Average total loss: 0.136345
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.8894e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.047779
Average KL loss: 0.090378
Average total loss: 0.138156
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-3.7242e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.047264
Average KL loss: 0.090736
Average total loss: 0.138000
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.7832e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.041933
Average KL loss: 0.090234
Average total loss: 0.132167
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.9440e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.043738
Average KL loss: 0.088916
Average total loss: 0.132654
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.6805e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.043254
Average KL loss: 0.088537
Average total loss: 0.131791
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.1088e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.044819
Average KL loss: 0.089170
Average total loss: 0.133989
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.3789e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.041414
Average KL loss: 0.089241
Average total loss: 0.130654
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.2013e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.042764
Average KL loss: 0.087902
Average total loss: 0.130666
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(1.1491e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.041680
Average KL loss: 0.088009
Average total loss: 0.129689
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-7.1874e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.043757
Average KL loss: 0.088383
Average total loss: 0.132140
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(2.8715e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.042742
Average KL loss: 0.088940
Average total loss: 0.131682
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.4149e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.044301
Average KL loss: 0.089883
Average total loss: 0.134184
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.8524e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.040750
Average KL loss: 0.089466
Average total loss: 0.130216
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(4.6232e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.039786
Average KL loss: 0.088334
Average total loss: 0.128120
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.7855e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.041448
Average KL loss: 0.088480
Average total loss: 0.129928
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.5424e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.043358
Average KL loss: 0.089325
Average total loss: 0.132682
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.2629e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.040836
Average KL loss: 0.089177
Average total loss: 0.130013
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.8643e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.039042
Average KL loss: 0.089081
Average total loss: 0.128123
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-5.9492e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.038748
Average KL loss: 0.088687
Average total loss: 0.127435
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.9755e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.041376
Average KL loss: 0.088984
Average total loss: 0.130360
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.8205e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.040140
Average KL loss: 0.088582
Average total loss: 0.128722
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.0065e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.040259
Average KL loss: 0.088583
Average total loss: 0.128842
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.0140e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.038836
Average KL loss: 0.088600
Average total loss: 0.127435
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.3856e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.039882
Average KL loss: 0.089406
Average total loss: 0.129288
tensor(0.0045, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.7375e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.038408
Average KL loss: 0.088766
Average total loss: 0.127175
tensor(0.0045, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.7966e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.032984
Average KL loss: 0.087530
Average total loss: 0.120513
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.2096e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.036259
Average KL loss: 0.085906
Average total loss: 0.122165
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(1.2021e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.035665
Average KL loss: 0.086317
Average total loss: 0.121982
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.4226e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.036045
Average KL loss: 0.086438
Average total loss: 0.122483
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-3.9945e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.035302
Average KL loss: 0.085956
Average total loss: 0.121258
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.8041e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.034719
Average KL loss: 0.085262
Average total loss: 0.119982
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-9.3639e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.037679
Average KL loss: 0.086229
Average total loss: 0.123907
tensor(0.0044, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.3571e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.036059
Average KL loss: 0.086865
Average total loss: 0.122924
tensor(0.0044, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.3867e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.035157
Average KL loss: 0.085882
Average total loss: 0.121038
tensor(0.0044, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.5324e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.037641
Average KL loss: 0.086798
Average total loss: 0.124439
tensor(0.0045, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(3.0664e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.035381
Average KL loss: 0.087355
Average total loss: 0.122736
tensor(0.0044, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.4048e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.037332
Average KL loss: 0.086788
Average total loss: 0.124120
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(9.4284e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.034512
Average KL loss: 0.087080
Average total loss: 0.121592
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-3.2373e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.035520
Average KL loss: 0.086905
Average total loss: 0.122426
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-2.2830e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.036134
Average KL loss: 0.086511
Average total loss: 0.122645
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(3.8677e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.036416
Average KL loss: 0.087141
Average total loss: 0.123557
tensor(0.0044, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-5.7775e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.035434
Average KL loss: 0.087543
Average total loss: 0.122977
tensor(0.0044, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(5.1394e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.033761
Average KL loss: 0.086280
Average total loss: 0.120041
tensor(0.0044, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.9168e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.033557
Average KL loss: 0.083246
Average total loss: 0.116802
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(8.2886e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.031424
Average KL loss: 0.080896
Average total loss: 0.112320
tensor(0.0044, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.8207e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.033323
Average KL loss: 0.079004
Average total loss: 0.112326
tensor(0.0044, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.4673e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.034102
Average KL loss: 0.077424
Average total loss: 0.111526
tensor(0.0044, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-6.5342e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.032729
Average KL loss: 0.076047
Average total loss: 0.108776
tensor(0.0044, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.3489e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.033317
Average KL loss: 0.074836
Average total loss: 0.108153
tensor(0.0044, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.6407e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.032364
Average KL loss: 0.073755
Average total loss: 0.106118
tensor(0.0044, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.8960e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.034329
Average KL loss: 0.072766
Average total loss: 0.107095
tensor(0.0044, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.7675e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.033883
Average KL loss: 0.071885
Average total loss: 0.105768
tensor(0.0044, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.7903e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.031774
Average KL loss: 0.071040
Average total loss: 0.102814
tensor(0.0044, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.9508e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.031828
Average KL loss: 0.070265
Average total loss: 0.102093
tensor(0.0044, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.9237e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.032551
Average KL loss: 0.069531
Average total loss: 0.102082
tensor(0.0044, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.5946e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.033539
Average KL loss: 0.068879
Average total loss: 0.102418
tensor(0.0044, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2749e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.031630
Average KL loss: 0.068257
Average total loss: 0.099887
tensor(0.0044, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.0416e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.030774
Average KL loss: 0.067615
Average total loss: 0.098389
tensor(0.0044, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3234e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.031561
Average KL loss: 0.067028
Average total loss: 0.098589
tensor(0.0044, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.1571e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.032840
Average KL loss: 0.066525
Average total loss: 0.099365
tensor(0.0044, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.2323e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.029156
Average KL loss: 0.066016
Average total loss: 0.095172
tensor(0.0044, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.5949e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.032747
Average KL loss: 0.065535
Average total loss: 0.098282
tensor(0.0044, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(8.8404e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.031068
Average KL loss: 0.065124
Average total loss: 0.096192
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.1214e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.031571
Average KL loss: 0.064700
Average total loss: 0.096270
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.4386e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.032889
Average KL loss: 0.064316
Average total loss: 0.097205
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.7628e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.033784
Average KL loss: 0.063977
Average total loss: 0.097761
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0554e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.031319
Average KL loss: 0.063638
Average total loss: 0.094957
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.3839e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.031455
Average KL loss: 0.063284
Average total loss: 0.094739
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4471e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.030939
Average KL loss: 0.062966
Average total loss: 0.093904
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.6683e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.032241
Average KL loss: 0.062652
Average total loss: 0.094893
 Percentile value: -0.001948244939558208
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1342 /    1728             ( 77.66%) | total_pruned =     386 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   22741 /   36864             ( 61.69%) | total_pruned =   14123 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   22951 /   36864             ( 62.26%) | total_pruned =   13913 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   23178 /   36864             ( 62.87%) | total_pruned =   13686 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   22982 /   36864             ( 62.34%) | total_pruned =   13882 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   46039 /   73728             ( 62.44%) | total_pruned =   27689 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   92133 /  147456             ( 62.48%) | total_pruned =   55323 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5678 /    8192             ( 69.31%) | total_pruned =    2514 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   96495 /  147456             ( 65.44%) | total_pruned =   50961 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   94481 /  147456             ( 64.07%) | total_pruned =   52975 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  185003 /  294912             ( 62.73%) | total_pruned =  109909 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  377947 /  589824             ( 64.08%) | total_pruned =  211877 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   21154 /   32768             ( 64.56%) | total_pruned =   11614 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  429066 /  589824             ( 72.74%) | total_pruned =  160758 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  423616 /  589824             ( 71.82%) | total_pruned =  166208 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  790269 / 1179648             ( 66.99%) | total_pruned =  389379 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1846281 / 2359296             ( 78.26%) | total_pruned =  513015 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     457 /     512             ( 89.26%) | total_pruned =      55 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   83954 /  131072             ( 64.05%) | total_pruned =   47118 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     450 /     512             ( 87.89%) | total_pruned =      62 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2090328 / 2359296             ( 88.60%) | total_pruned =  268968 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     409 /     512             ( 79.88%) | total_pruned =     103 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2249523 / 2359296             ( 95.35%) | total_pruned =  109773 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     146 /     512             ( 28.52%) | total_pruned =     366 | shape = torch.Size([512])
linear.weight        | nonzeros =    4460 /    5120             ( 87.11%) | total_pruned =     660 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       8 /      10             ( 80.00%) | total_pruned =       2 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 34/100 Loss: 0.000003 Accuracy: 86.76 100.00 % Best test Accuracy: 86.85%
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.4443e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.092509
Average KL loss: 0.065138
Average total loss: 0.157647
tensor(0.0082, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.6219e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.083424
Average KL loss: 0.077086
Average total loss: 0.160510
tensor(0.0080, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-3.4793e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.077413
Average KL loss: 0.083848
Average total loss: 0.161261
tensor(0.0078, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.1688e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.070098
Average KL loss: 0.087827
Average total loss: 0.157925
tensor(0.0076, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(2.8623e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.065419
Average KL loss: 0.090093
Average total loss: 0.155512
tensor(0.0074, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.8284e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.064781
Average KL loss: 0.091666
Average total loss: 0.156447
tensor(0.0073, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.4072e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.062985
Average KL loss: 0.094308
Average total loss: 0.157293
tensor(0.0072, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-6.8114e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.057091
Average KL loss: 0.095040
Average total loss: 0.152131
tensor(0.0071, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(2.0672e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.057797
Average KL loss: 0.095373
Average total loss: 0.153170
tensor(0.0070, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.1880e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.056574
Average KL loss: 0.095925
Average total loss: 0.152499
tensor(0.0069, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.6003e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.055133
Average KL loss: 0.096920
Average total loss: 0.152053
tensor(0.0068, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-2.3631e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.049788
Average KL loss: 0.096554
Average total loss: 0.146341
tensor(0.0067, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.4910e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.051256
Average KL loss: 0.096598
Average total loss: 0.147854
tensor(0.0067, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.5720e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.050769
Average KL loss: 0.096251
Average total loss: 0.147020
tensor(0.0066, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(2.8080e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.049201
Average KL loss: 0.096427
Average total loss: 0.145628
tensor(0.0066, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(1.3290e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.052597
Average KL loss: 0.097134
Average total loss: 0.149731
tensor(0.0065, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(9.1122e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.050179
Average KL loss: 0.098273
Average total loss: 0.148452
tensor(0.0064, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(4.1019e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.048136
Average KL loss: 0.098499
Average total loss: 0.146634
tensor(0.0064, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(7.3073e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.048134
Average KL loss: 0.098359
Average total loss: 0.146493
tensor(0.0064, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-6.5677e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.045613
Average KL loss: 0.097685
Average total loss: 0.143298
tensor(0.0063, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.9753e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.043425
Average KL loss: 0.096813
Average total loss: 0.140238
tensor(0.0062, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(1.0590e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.044562
Average KL loss: 0.096582
Average total loss: 0.141145
tensor(0.0062, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.4453e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.044713
Average KL loss: 0.096842
Average total loss: 0.141555
tensor(0.0062, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-6.7097e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.045623
Average KL loss: 0.096788
Average total loss: 0.142410
tensor(0.0061, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(2.1327e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.043821
Average KL loss: 0.096785
Average total loss: 0.140605
tensor(0.0061, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(1.9560e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.042464
Average KL loss: 0.096452
Average total loss: 0.138917
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(8.8492e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.043382
Average KL loss: 0.096281
Average total loss: 0.139663
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(3.2811e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.042695
Average KL loss: 0.096909
Average total loss: 0.139603
tensor(0.0060, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.9731e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.042896
Average KL loss: 0.096900
Average total loss: 0.139796
tensor(0.0059, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.2276e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.042576
Average KL loss: 0.097411
Average total loss: 0.139988
tensor(0.0060, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.1918e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.043002
Average KL loss: 0.097053
Average total loss: 0.140055
tensor(0.0059, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(8.3724e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.042088
Average KL loss: 0.097369
Average total loss: 0.139457
tensor(0.0059, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(1.3696e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.041002
Average KL loss: 0.096756
Average total loss: 0.137758
tensor(0.0059, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.0577e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.038810
Average KL loss: 0.096690
Average total loss: 0.135500
tensor(0.0058, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-3.9289e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.043339
Average KL loss: 0.096591
Average total loss: 0.139930
tensor(0.0058, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.3427e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.043797
Average KL loss: 0.097875
Average total loss: 0.141672
tensor(0.0058, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-5.5337e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.040025
Average KL loss: 0.098514
Average total loss: 0.138539
tensor(0.0058, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(3.0316e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.041735
Average KL loss: 0.097711
Average total loss: 0.139446
tensor(0.0058, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.4904e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.040748
Average KL loss: 0.098278
Average total loss: 0.139026
tensor(0.0058, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.8382e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.042106
Average KL loss: 0.098349
Average total loss: 0.140455
tensor(0.0058, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(8.2881e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.038550
Average KL loss: 0.098488
Average total loss: 0.137038
tensor(0.0058, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.6184e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.042027
Average KL loss: 0.097555
Average total loss: 0.139582
tensor(0.0057, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.7491e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.041271
Average KL loss: 0.098688
Average total loss: 0.139959
tensor(0.0057, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(2.4048e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.040843
Average KL loss: 0.098929
Average total loss: 0.139771
tensor(0.0057, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-2.1725e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.036897
Average KL loss: 0.098300
Average total loss: 0.135197
tensor(0.0057, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.5941e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.039380
Average KL loss: 0.097338
Average total loss: 0.136718
tensor(0.0057, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-5.6929e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.039312
Average KL loss: 0.097483
Average total loss: 0.136795
tensor(0.0057, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.2744e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.037566
Average KL loss: 0.097763
Average total loss: 0.135329
tensor(0.0057, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(2.2789e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.040770
Average KL loss: 0.097955
Average total loss: 0.138725
tensor(0.0057, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.2599e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.035880
Average KL loss: 0.097778
Average total loss: 0.133659
tensor(0.0056, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-7.6803e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.037400
Average KL loss: 0.097054
Average total loss: 0.134453
tensor(0.0056, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(1.3970e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.036782
Average KL loss: 0.097408
Average total loss: 0.134190
tensor(0.0056, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-5.8591e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.035497
Average KL loss: 0.096720
Average total loss: 0.132217
tensor(0.0056, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-8.6354e-11, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.038921
Average KL loss: 0.096883
Average total loss: 0.135804
tensor(0.0056, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.9448e-11, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.038350
Average KL loss: 0.097690
Average total loss: 0.136041
tensor(0.0056, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(7.9576e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.036451
Average KL loss: 0.097711
Average total loss: 0.134163
tensor(0.0056, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-5.7764e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.038523
Average KL loss: 0.097421
Average total loss: 0.135944
tensor(0.0056, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.3128e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.037890
Average KL loss: 0.098038
Average total loss: 0.135929
tensor(0.0056, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(4.7714e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.038455
Average KL loss: 0.097568
Average total loss: 0.136024
tensor(0.0056, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-4.1958e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.035015
Average KL loss: 0.097829
Average total loss: 0.132844
tensor(0.0056, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.0073e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.039847
Average KL loss: 0.097507
Average total loss: 0.137355
tensor(0.0056, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(8.0571e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.039376
Average KL loss: 0.098768
Average total loss: 0.138145
tensor(0.0056, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.0201e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.037038
Average KL loss: 0.098815
Average total loss: 0.135853
tensor(0.0056, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-9.4442e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.037514
Average KL loss: 0.098764
Average total loss: 0.136278
tensor(0.0056, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.2760e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.035643
Average KL loss: 0.097510
Average total loss: 0.133153
tensor(0.0056, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.0960e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.036343
Average KL loss: 0.095046
Average total loss: 0.131389
tensor(0.0056, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.7208e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.037068
Average KL loss: 0.093065
Average total loss: 0.130133
tensor(0.0056, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(2.3744e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.035800
Average KL loss: 0.091414
Average total loss: 0.127213
tensor(0.0056, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.3530e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.036461
Average KL loss: 0.089954
Average total loss: 0.126415
tensor(0.0056, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.7566e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.031629
Average KL loss: 0.088641
Average total loss: 0.120270
tensor(0.0056, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-4.1311e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.034540
Average KL loss: 0.087428
Average total loss: 0.121968
tensor(0.0056, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(1.7538e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.034300
Average KL loss: 0.086363
Average total loss: 0.120663
tensor(0.0056, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.1530e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.036547
Average KL loss: 0.085387
Average total loss: 0.121934
tensor(0.0056, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-4.0355e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.035329
Average KL loss: 0.084497
Average total loss: 0.119826
tensor(0.0056, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(8.5476e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.034026
Average KL loss: 0.083641
Average total loss: 0.117667
tensor(0.0056, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.6437e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.034362
Average KL loss: 0.082833
Average total loss: 0.117196
tensor(0.0056, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-4.5839e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.035041
Average KL loss: 0.082107
Average total loss: 0.117148
tensor(0.0056, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.6480e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.034881
Average KL loss: 0.081401
Average total loss: 0.116282
tensor(0.0056, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.2573e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.032739
Average KL loss: 0.080742
Average total loss: 0.113481
tensor(0.0056, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.9034e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.036458
Average KL loss: 0.080115
Average total loss: 0.116573
tensor(0.0056, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.5176e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.032900
Average KL loss: 0.079516
Average total loss: 0.112415
tensor(0.0056, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.7077e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.033563
Average KL loss: 0.078946
Average total loss: 0.112508
tensor(0.0056, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-5.5462e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.033192
Average KL loss: 0.078397
Average total loss: 0.111588
tensor(0.0056, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(9.6479e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.033307
Average KL loss: 0.077882
Average total loss: 0.111189
tensor(0.0056, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(1.8794e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.033598
Average KL loss: 0.077365
Average total loss: 0.110963
tensor(0.0055, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(1.7959e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.033841
Average KL loss: 0.076915
Average total loss: 0.110756
tensor(0.0055, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(1.6447e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.035785
Average KL loss: 0.076478
Average total loss: 0.112263
tensor(0.0055, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(2.2309e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.034912
Average KL loss: 0.076084
Average total loss: 0.110996
tensor(0.0055, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.8020e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.035783
Average KL loss: 0.075672
Average total loss: 0.111455
tensor(0.0055, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(4.8204e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.033837
Average KL loss: 0.075290
Average total loss: 0.109127
tensor(0.0055, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.4092e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.033594
Average KL loss: 0.074907
Average total loss: 0.108501
tensor(0.0055, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(2.1221e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.033612
Average KL loss: 0.074550
Average total loss: 0.108161
tensor(0.0055, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.6504e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.037746
Average KL loss: 0.074223
Average total loss: 0.111969
tensor(0.0055, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-6.5641e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.035446
Average KL loss: 0.073947
Average total loss: 0.109393
tensor(0.0055, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-5.0333e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.032096
Average KL loss: 0.073627
Average total loss: 0.105723
tensor(0.0055, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.5074e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.032492
Average KL loss: 0.073272
Average total loss: 0.105764
tensor(0.0055, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.3200e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.031670
Average KL loss: 0.072947
Average total loss: 0.104617
tensor(0.0055, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.2067e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.034120
Average KL loss: 0.072638
Average total loss: 0.106758
tensor(0.0055, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(1.0305e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.033243
Average KL loss: 0.072358
Average total loss: 0.105601
tensor(0.0055, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.8868e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.033391
Average KL loss: 0.072071
Average total loss: 0.105461
tensor(0.0055, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(4.5423e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.034791
Average KL loss: 0.071813
Average total loss: 0.106605
tensor(0.0055, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-4.4482e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.035460
Average KL loss: 0.071586
Average total loss: 0.107045
tensor(0.0055, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(6.2177e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.034791
Average KL loss: 0.071334
Average total loss: 0.106126
tensor(0.0055, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(7.2859e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.035668
Average KL loss: 0.071101
Average total loss: 0.106769
tensor(0.0055, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(1.8787e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.035939
Average KL loss: 0.070892
Average total loss: 0.106831
tensor(0.0055, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(3.6102e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.034075
Average KL loss: 0.070690
Average total loss: 0.104764
tensor(0.0055, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(9.2350e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.032744
Average KL loss: 0.070464
Average total loss: 0.103208
tensor(0.0055, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.4983e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.035118
Average KL loss: 0.070243
Average total loss: 0.105361
tensor(0.0055, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(1.3454e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.032818
Average KL loss: 0.070053
Average total loss: 0.102871
tensor(0.0055, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(4.0142e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.036950
Average KL loss: 0.069850
Average total loss: 0.106800
tensor(0.0055, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(3.3082e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.033806
Average KL loss: 0.069679
Average total loss: 0.103486
tensor(0.0055, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-3.8935e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.033973
Average KL loss: 0.069499
Average total loss: 0.103472
tensor(0.0055, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.1680e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.034424
Average KL loss: 0.069327
Average total loss: 0.103751
tensor(0.0055, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(4.2396e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.033119
Average KL loss: 0.069148
Average total loss: 0.102267
tensor(0.0055, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.3875e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.033644
Average KL loss: 0.068958
Average total loss: 0.102602
tensor(0.0055, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(8.3552e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.033171
Average KL loss: 0.068772
Average total loss: 0.101943
tensor(0.0055, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.3608e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.032983
Average KL loss: 0.068603
Average total loss: 0.101585
tensor(0.0055, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(4.3181e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.032768
Average KL loss: 0.068434
Average total loss: 0.101202
tensor(0.0055, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.7718e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.034044
Average KL loss: 0.068285
Average total loss: 0.102329
tensor(0.0055, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(3.0218e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.034057
Average KL loss: 0.068138
Average total loss: 0.102196
tensor(0.0055, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.4581e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.032668
Average KL loss: 0.067985
Average total loss: 0.100653
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-8.1085e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.034250
Average KL loss: 0.067846
Average total loss: 0.102096
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.8216e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.035784
Average KL loss: 0.067719
Average total loss: 0.103503
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.8102e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.033377
Average KL loss: 0.067612
Average total loss: 0.100989
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.2871e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.032069
Average KL loss: 0.067462
Average total loss: 0.099531
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(7.4841e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.032653
Average KL loss: 0.067311
Average total loss: 0.099964
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.7636e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.037035
Average KL loss: 0.067208
Average total loss: 0.104243
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-3.8043e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.037531
Average KL loss: 0.067152
Average total loss: 0.104682
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.8095e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.031223
Average KL loss: 0.067040
Average total loss: 0.098263
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.6025e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.034755
Average KL loss: 0.066895
Average total loss: 0.101650
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.7056e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.033873
Average KL loss: 0.066797
Average total loss: 0.100669
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-4.1914e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.032602
Average KL loss: 0.066678
Average total loss: 0.099279
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(9.7819e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.035169
Average KL loss: 0.066558
Average total loss: 0.101727
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.6829e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.034001
Average KL loss: 0.066470
Average total loss: 0.100471
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.3877e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.033376
Average KL loss: 0.066369
Average total loss: 0.099745
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.7399e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.035839
Average KL loss: 0.066277
Average total loss: 0.102116
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.5337e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.033995
Average KL loss: 0.066174
Average total loss: 0.100169
tensor(0.0055, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-3.6051e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.034613
Average KL loss: 0.066085
Average total loss: 0.100697
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.5093e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.034321
Average KL loss: 0.065977
Average total loss: 0.100298
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.9716e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.032461
Average KL loss: 0.065885
Average total loss: 0.098346
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.9090e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.033546
Average KL loss: 0.065807
Average total loss: 0.099353
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.6800e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.033460
Average KL loss: 0.065763
Average total loss: 0.099222
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.9002e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.032923
Average KL loss: 0.065720
Average total loss: 0.098643
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.5144e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.032651
Average KL loss: 0.065678
Average total loss: 0.098329
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.4777e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.034138
Average KL loss: 0.065639
Average total loss: 0.099777
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.0627e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.033611
Average KL loss: 0.065602
Average total loss: 0.099213
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.1786e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.034123
Average KL loss: 0.065566
Average total loss: 0.099689
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.1766e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.033527
Average KL loss: 0.065530
Average total loss: 0.099058
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.0969e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.034114
Average KL loss: 0.065496
Average total loss: 0.099610
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.2995e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.032988
Average KL loss: 0.065461
Average total loss: 0.098449
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.7774e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.032713
Average KL loss: 0.065428
Average total loss: 0.098141
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(4.9986e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.033586
Average KL loss: 0.065393
Average total loss: 0.098979
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(5.3510e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.031743
Average KL loss: 0.065359
Average total loss: 0.097103
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.4095e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.031459
Average KL loss: 0.065327
Average total loss: 0.096786
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.5403e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.033814
Average KL loss: 0.065297
Average total loss: 0.099110
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.5803e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.030551
Average KL loss: 0.065266
Average total loss: 0.095817
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.9131e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.032327
Average KL loss: 0.065235
Average total loss: 0.097562
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(3.6527e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.035242
Average KL loss: 0.065205
Average total loss: 0.100447
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.2552e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.034642
Average KL loss: 0.065177
Average total loss: 0.099819
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(3.0368e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.034129
Average KL loss: 0.065150
Average total loss: 0.099279
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.1814e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.033265
Average KL loss: 0.065123
Average total loss: 0.098388
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.4633e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.035418
Average KL loss: 0.065094
Average total loss: 0.100512
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(5.2826e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.031481
Average KL loss: 0.065067
Average total loss: 0.096548
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.8989e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.034470
Average KL loss: 0.065039
Average total loss: 0.099509
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.3516e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.033341
Average KL loss: 0.065012
Average total loss: 0.098353
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.1366e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.033784
Average KL loss: 0.064984
Average total loss: 0.098768
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.7481e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.032476
Average KL loss: 0.064959
Average total loss: 0.097434
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.8154e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.035318
Average KL loss: 0.064944
Average total loss: 0.100262
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.0041e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.033615
Average KL loss: 0.064942
Average total loss: 0.098556
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.9933e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.032919
Average KL loss: 0.064938
Average total loss: 0.097858
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.9448e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.035240
Average KL loss: 0.064936
Average total loss: 0.100175
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.4230e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.033833
Average KL loss: 0.064933
Average total loss: 0.098766
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(4.7461e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.032952
Average KL loss: 0.064930
Average total loss: 0.097882
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.1665e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.034586
Average KL loss: 0.064927
Average total loss: 0.099513
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.3970e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.035274
Average KL loss: 0.064924
Average total loss: 0.100199
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.4482e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.034462
Average KL loss: 0.064922
Average total loss: 0.099383
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.7346e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.034686
Average KL loss: 0.064919
Average total loss: 0.099605
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(7.7262e-10, device='cuda:0')
 Percentile value: -0.0006147853680886328
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1213 /    1728             ( 70.20%) | total_pruned =     515 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   14744 /   36864             ( 40.00%) | total_pruned =   22120 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   14992 /   36864             ( 40.67%) | total_pruned =   21872 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   14988 /   36864             ( 40.66%) | total_pruned =   21876 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   14853 /   36864             ( 40.29%) | total_pruned =   22011 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   29130 /   73728             ( 39.51%) | total_pruned =   44598 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   57948 /  147456             ( 39.30%) | total_pruned =   89508 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4300 /    8192             ( 52.49%) | total_pruned =    3892 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   62612 /  147456             ( 42.46%) | total_pruned =   84844 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   60065 /  147456             ( 40.73%) | total_pruned =   87391 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  115210 /  294912             ( 39.07%) | total_pruned =  179702 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  237323 /  589824             ( 40.24%) | total_pruned =  352501 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   14558 /   32768             ( 44.43%) | total_pruned =   18210 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  300100 /  589824             ( 50.88%) | total_pruned =  289724 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  293616 /  589824             ( 49.78%) | total_pruned =  296208 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  504598 / 1179648             ( 42.78%) | total_pruned =  675050 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1348704 / 2359296             ( 57.17%) | total_pruned = 1010592 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     428 /     512             ( 83.59%) | total_pruned =      84 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   53659 /  131072             ( 40.94%) | total_pruned =   77413 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     421 /     512             ( 82.23%) | total_pruned =      91 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1828551 / 2359296             ( 77.50%) | total_pruned =  530745 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     395 /     512             ( 77.15%) | total_pruned =     117 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     361 /     512             ( 70.51%) | total_pruned =     151 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2166269 / 2359296             ( 91.82%) | total_pruned =  193027 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      65 /     512             ( 12.70%) | total_pruned =     447 | shape = torch.Size([512])
linear.weight        | nonzeros =    3930 /    5120             ( 76.76%) | total_pruned =    1190 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 33/100 Loss: 0.000037 Accuracy: 87.25 100.00 % Best test Accuracy: 87.25%
tensor(0.0055, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.1078e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.105973
Average KL loss: 0.067911
Average total loss: 0.173884
tensor(0.0083, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.1188e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.094331
Average KL loss: 0.078999
Average total loss: 0.173330
tensor(0.0082, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-5.9210e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.088332
Average KL loss: 0.085333
Average total loss: 0.173664
tensor(0.0081, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-7.7270e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.081792
Average KL loss: 0.089922
Average total loss: 0.171714
tensor(0.0080, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(4.3215e-12, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.077937
Average KL loss: 0.093086
Average total loss: 0.171023
tensor(0.0079, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.0255e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.076825
Average KL loss: 0.096236
Average total loss: 0.173062
tensor(0.0079, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.1747e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.072649
Average KL loss: 0.097796
Average total loss: 0.170445
tensor(0.0078, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.9892e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.070688
Average KL loss: 0.099106
Average total loss: 0.169794
tensor(0.0078, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.4828e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.069273
Average KL loss: 0.100293
Average total loss: 0.169567
tensor(0.0078, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(3.7863e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.065721
Average KL loss: 0.101099
Average total loss: 0.166820
tensor(0.0077, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.3683e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.066324
Average KL loss: 0.101766
Average total loss: 0.168090
tensor(0.0076, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.0076e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.063129
Average KL loss: 0.102572
Average total loss: 0.165700
tensor(0.0076, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.5289e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.058147
Average KL loss: 0.103090
Average total loss: 0.161237
tensor(0.0076, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.1603e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.059881
Average KL loss: 0.103212
Average total loss: 0.163093
tensor(0.0075, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.8952e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.056638
Average KL loss: 0.103282
Average total loss: 0.159921
tensor(0.0075, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.0802e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.061251
Average KL loss: 0.103565
Average total loss: 0.164816
tensor(0.0075, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.2145e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.059344
Average KL loss: 0.104776
Average total loss: 0.164119
tensor(0.0074, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.2447e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.057373
Average KL loss: 0.105427
Average total loss: 0.162801
tensor(0.0074, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(3.2491e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.056676
Average KL loss: 0.105369
Average total loss: 0.162045
tensor(0.0074, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(3.1105e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.055031
Average KL loss: 0.105588
Average total loss: 0.160619
tensor(0.0073, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.1210e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.053460
Average KL loss: 0.105069
Average total loss: 0.158529
tensor(0.0073, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.2983e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.059799
Average KL loss: 0.105863
Average total loss: 0.165662
tensor(0.0073, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.2489e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.056121
Average KL loss: 0.107083
Average total loss: 0.163203
tensor(0.0073, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.6859e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.054403
Average KL loss: 0.107477
Average total loss: 0.161880
tensor(0.0073, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(7.5212e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.051736
Average KL loss: 0.106913
Average total loss: 0.158649
tensor(0.0072, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.1021e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.051811
Average KL loss: 0.106387
Average total loss: 0.158197
tensor(0.0072, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.5480e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.053034
Average KL loss: 0.106546
Average total loss: 0.159580
tensor(0.0072, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(3.8111e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.047457
Average KL loss: 0.106598
Average total loss: 0.154054
tensor(0.0071, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-3.7319e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.050567
Average KL loss: 0.105937
Average total loss: 0.156504
tensor(0.0071, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.6713e-11, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.050793
Average KL loss: 0.106212
Average total loss: 0.157005
tensor(0.0071, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-7.6913e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.053325
Average KL loss: 0.106767
Average total loss: 0.160092
tensor(0.0071, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(9.1817e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.050628
Average KL loss: 0.107582
Average total loss: 0.158209
tensor(0.0071, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(1.1492e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.051934
Average KL loss: 0.107791
Average total loss: 0.159724
tensor(0.0071, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(2.5757e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.047768
Average KL loss: 0.107356
Average total loss: 0.155124
tensor(0.0071, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(1.4839e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.047805
Average KL loss: 0.107221
Average total loss: 0.155026
tensor(0.0070, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-4.4679e-11, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.050322
Average KL loss: 0.106821
Average total loss: 0.157144
tensor(0.0070, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.8227e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.047367
Average KL loss: 0.107162
Average total loss: 0.154529
tensor(0.0070, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.7572e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.047862
Average KL loss: 0.107038
Average total loss: 0.154900
tensor(0.0070, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.3505e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.047943
Average KL loss: 0.107064
Average total loss: 0.155007
tensor(0.0070, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-8.7708e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.048171
Average KL loss: 0.106548
Average total loss: 0.154718
tensor(0.0070, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.2024e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.043900
Average KL loss: 0.104656
Average total loss: 0.148555
tensor(0.0070, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.5799e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.045997
Average KL loss: 0.103078
Average total loss: 0.149076
tensor(0.0070, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.7968e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.047879
Average KL loss: 0.101755
Average total loss: 0.149635
tensor(0.0070, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.4255e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.047056
Average KL loss: 0.100609
Average total loss: 0.147665
tensor(0.0070, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.5290e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.045141
Average KL loss: 0.099551
Average total loss: 0.144691
tensor(0.0070, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.5151e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.047212
Average KL loss: 0.098590
Average total loss: 0.145802
tensor(0.0070, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.6559e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.048320
Average KL loss: 0.097725
Average total loss: 0.146045
tensor(0.0070, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.2160e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.045928
Average KL loss: 0.096916
Average total loss: 0.142843
tensor(0.0070, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.8619e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.045591
Average KL loss: 0.096125
Average total loss: 0.141716
tensor(0.0070, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(3.3712e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.047827
Average KL loss: 0.095421
Average total loss: 0.143248
tensor(0.0070, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.4887e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.044935
Average KL loss: 0.094735
Average total loss: 0.139670
tensor(0.0070, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-6.0133e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.045643
Average KL loss: 0.094094
Average total loss: 0.139736
tensor(0.0070, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.3417e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.046774
Average KL loss: 0.093503
Average total loss: 0.140276
tensor(0.0069, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.8637e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.049252
Average KL loss: 0.092950
Average total loss: 0.142202
tensor(0.0069, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.3914e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.045916
Average KL loss: 0.092412
Average total loss: 0.138329
tensor(0.0069, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.8774e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.043576
Average KL loss: 0.091867
Average total loss: 0.135442
tensor(0.0069, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.1801e-11, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.045477
Average KL loss: 0.091332
Average total loss: 0.136809
tensor(0.0069, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.8175e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.047642
Average KL loss: 0.090845
Average total loss: 0.138487
tensor(0.0069, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.9048e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.044097
Average KL loss: 0.090398
Average total loss: 0.134495
tensor(0.0069, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.6730e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.044649
Average KL loss: 0.089931
Average total loss: 0.134580
tensor(0.0069, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.5837e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.049001
Average KL loss: 0.089505
Average total loss: 0.138506
tensor(0.0069, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.1475e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.042452
Average KL loss: 0.089112
Average total loss: 0.131564
tensor(0.0069, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.1007e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.044434
Average KL loss: 0.088686
Average total loss: 0.133120
tensor(0.0069, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.9496e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.047858
Average KL loss: 0.088310
Average total loss: 0.136167
tensor(0.0069, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.7639e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.043766
Average KL loss: 0.087956
Average total loss: 0.131722
tensor(0.0069, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.7907e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.044262
Average KL loss: 0.087604
Average total loss: 0.131867
tensor(0.0069, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.9434e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.044663
Average KL loss: 0.087239
Average total loss: 0.131902
tensor(0.0069, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.1150e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.044130
Average KL loss: 0.086896
Average total loss: 0.131026
tensor(0.0069, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.0325e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.044076
Average KL loss: 0.086565
Average total loss: 0.130641
tensor(0.0069, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.9038e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.045580
Average KL loss: 0.086234
Average total loss: 0.131813
tensor(0.0069, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.3278e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.046518
Average KL loss: 0.085939
Average total loss: 0.132457
tensor(0.0069, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-6.3525e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.044080
Average KL loss: 0.085668
Average total loss: 0.129748
tensor(0.0069, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-8.9795e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.042660
Average KL loss: 0.085361
Average total loss: 0.128020
tensor(0.0069, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.5363e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.041894
Average KL loss: 0.085051
Average total loss: 0.126945
tensor(0.0069, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.7445e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.044777
Average KL loss: 0.084764
Average total loss: 0.129542
tensor(0.0069, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.9447e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.043015
Average KL loss: 0.084498
Average total loss: 0.127513
tensor(0.0069, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.7882e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.046609
Average KL loss: 0.084247
Average total loss: 0.130857
tensor(0.0069, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.4348e-12, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.045237
Average KL loss: 0.084007
Average total loss: 0.129245
tensor(0.0069, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.5719e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.045011
Average KL loss: 0.083774
Average total loss: 0.128785
tensor(0.0069, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.8173e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.044164
Average KL loss: 0.083551
Average total loss: 0.127715
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.4621e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.046394
Average KL loss: 0.083321
Average total loss: 0.129715
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.1124e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.044580
Average KL loss: 0.083115
Average total loss: 0.127696
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-5.4850e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.046187
Average KL loss: 0.082898
Average total loss: 0.129085
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.1796e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.045768
Average KL loss: 0.082667
Average total loss: 0.128435
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.0005e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.045147
Average KL loss: 0.082466
Average total loss: 0.127613
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.8528e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.046729
Average KL loss: 0.082352
Average total loss: 0.129081
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(9.0502e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.044671
Average KL loss: 0.082306
Average total loss: 0.126977
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.7963e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.044996
Average KL loss: 0.082260
Average total loss: 0.127256
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.8512e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.045452
Average KL loss: 0.082215
Average total loss: 0.127667
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.5576e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.043259
Average KL loss: 0.082171
Average total loss: 0.125430
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.8018e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.044375
Average KL loss: 0.082127
Average total loss: 0.126502
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-5.0235e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.043744
Average KL loss: 0.082085
Average total loss: 0.125828
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.6866e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.045371
Average KL loss: 0.082044
Average total loss: 0.127415
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.3747e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.046257
Average KL loss: 0.082004
Average total loss: 0.128261
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.8410e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.043755
Average KL loss: 0.081965
Average total loss: 0.125721
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(5.7716e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.042425
Average KL loss: 0.081925
Average total loss: 0.124350
tensor(0.0069, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.4845e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.047163
Average KL loss: 0.081885
Average total loss: 0.129048
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.0952e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.043647
Average KL loss: 0.081849
Average total loss: 0.125496
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(4.7527e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.045717
Average KL loss: 0.081811
Average total loss: 0.127528
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.4327e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.044743
Average KL loss: 0.081776
Average total loss: 0.126519
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.9429e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.043237
Average KL loss: 0.081739
Average total loss: 0.124975
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.6389e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.045352
Average KL loss: 0.081700
Average total loss: 0.127052
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.6563e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.045416
Average KL loss: 0.081663
Average total loss: 0.127079
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.4354e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.045853
Average KL loss: 0.081628
Average total loss: 0.127480
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.8550e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.048143
Average KL loss: 0.081594
Average total loss: 0.129737
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-5.7101e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.044592
Average KL loss: 0.081562
Average total loss: 0.126154
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(3.0784e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.042544
Average KL loss: 0.081528
Average total loss: 0.124072
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(6.3174e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.044738
Average KL loss: 0.081492
Average total loss: 0.126229
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(4.0790e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.043116
Average KL loss: 0.081457
Average total loss: 0.124573
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(8.0207e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.045687
Average KL loss: 0.081423
Average total loss: 0.127110
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.1051e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.045661
Average KL loss: 0.081389
Average total loss: 0.127050
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.1100e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.043353
Average KL loss: 0.081356
Average total loss: 0.124709
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.6085e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.044944
Average KL loss: 0.081321
Average total loss: 0.126265
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.8362e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.044191
Average KL loss: 0.081287
Average total loss: 0.125478
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.9216e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.043809
Average KL loss: 0.081252
Average total loss: 0.125060
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.5291e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.045215
Average KL loss: 0.081218
Average total loss: 0.126433
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.9550e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.044233
Average KL loss: 0.081186
Average total loss: 0.125419
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(4.1999e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.046610
Average KL loss: 0.081153
Average total loss: 0.127764
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.2458e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.046349
Average KL loss: 0.081135
Average total loss: 0.127484
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.1666e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.046058
Average KL loss: 0.081132
Average total loss: 0.127190
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.1559e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.043397
Average KL loss: 0.081128
Average total loss: 0.124525
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(9.9398e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.044052
Average KL loss: 0.081125
Average total loss: 0.125177
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.7279e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.043262
Average KL loss: 0.081121
Average total loss: 0.124383
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.1573e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.047388
Average KL loss: 0.081118
Average total loss: 0.128506
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.5334e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.044639
Average KL loss: 0.081114
Average total loss: 0.125754
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.5872e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.043689
Average KL loss: 0.081111
Average total loss: 0.124800
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.5770e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.044276
Average KL loss: 0.081108
Average total loss: 0.125383
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(3.9598e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.048903
Average KL loss: 0.081104
Average total loss: 0.130007
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.9192e-09, device='cuda:0')
 Percentile value: -0.00043640133226290355
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =    1146 /    1728             ( 66.32%) | total_pruned =     582 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    9775 /   36864             ( 26.52%) | total_pruned =   27089 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   10235 /   36864             ( 27.76%) | total_pruned =   26629 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   10203 /   36864             ( 27.68%) | total_pruned =   26661 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9958 /   36864             ( 27.01%) | total_pruned =   26906 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   19058 /   73728             ( 25.85%) | total_pruned =   54670 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   37308 /  147456             ( 25.30%) | total_pruned =  110148 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3508 /    8192             ( 42.82%) | total_pruned =    4684 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   40481 /  147456             ( 27.45%) | total_pruned =  106975 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   39048 /  147456             ( 26.48%) | total_pruned =  108408 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   72910 /  294912             ( 24.72%) | total_pruned =  222002 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  148938 /  589824             ( 25.25%) | total_pruned =  440886 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   10849 /   32768             ( 33.11%) | total_pruned =   21919 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  206721 /  589824             ( 35.05%) | total_pruned =  383103 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  201398 /  589824             ( 34.15%) | total_pruned =  388426 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     204 /     256             ( 79.69%) | total_pruned =      52 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  315803 / 1179648             ( 26.77%) | total_pruned =  863845 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  933019 / 2359296             ( 39.55%) | total_pruned = 1426277 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     407 /     512             ( 79.49%) | total_pruned =     105 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   34803 /  131072             ( 26.55%) | total_pruned =   96269 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     406 /     512             ( 79.30%) | total_pruned =     106 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1547964 / 2359296             ( 65.61%) | total_pruned =  811332 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     391 /     512             ( 76.37%) | total_pruned =     121 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     341 /     512             ( 66.60%) | total_pruned =     171 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2054049 / 2359296             ( 87.06%) | total_pruned =  305247 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
linear.weight        | nonzeros =    3500 /    5120             ( 68.36%) | total_pruned =    1620 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 32/100 Loss: 0.000034 Accuracy: 87.12 100.00 % Best test Accuracy: 87.36%
tensor(0.0069, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-9.6256e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.142204
Average KL loss: 0.079943
Average total loss: 0.222147
tensor(0.0101, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-5.6938e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.122471
Average KL loss: 0.088632
Average total loss: 0.211103
tensor(0.0099, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-9.4173e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.115066
Average KL loss: 0.094436
Average total loss: 0.209502
tensor(0.0098, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.3734e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.111839
Average KL loss: 0.099017
Average total loss: 0.210856
tensor(0.0098, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(7.9245e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.100085
Average KL loss: 0.102487
Average total loss: 0.202572
tensor(0.0097, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-5.5555e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.104047
Average KL loss: 0.105036
Average total loss: 0.209083
tensor(0.0096, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(4.0313e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.097411
Average KL loss: 0.108050
Average total loss: 0.205462
tensor(0.0096, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-9.6049e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.091286
Average KL loss: 0.109599
Average total loss: 0.200885
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-7.2188e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.090370
Average KL loss: 0.110714
Average total loss: 0.201084
tensor(0.0095, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.9028e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.088492
Average KL loss: 0.112460
Average total loss: 0.200952
tensor(0.0094, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-8.7852e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.082510
Average KL loss: 0.113256
Average total loss: 0.195766
tensor(0.0094, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.8689e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.083154
Average KL loss: 0.113730
Average total loss: 0.196884
tensor(0.0093, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(1.8019e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.086833
Average KL loss: 0.115052
Average total loss: 0.201885
tensor(0.0093, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(9.4178e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.082049
Average KL loss: 0.116127
Average total loss: 0.198176
tensor(0.0093, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.4075e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.083194
Average KL loss: 0.116861
Average total loss: 0.200055
tensor(0.0092, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-9.4035e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.078719
Average KL loss: 0.117615
Average total loss: 0.196334
tensor(0.0092, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(8.2296e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.076637
Average KL loss: 0.117481
Average total loss: 0.194118
tensor(0.0091, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-4.7866e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.073702
Average KL loss: 0.117907
Average total loss: 0.191609
tensor(0.0091, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-8.0030e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.078779
Average KL loss: 0.118569
Average total loss: 0.197348
tensor(0.0091, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.4058e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.072914
Average KL loss: 0.119132
Average total loss: 0.192046
tensor(0.0090, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.1763e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.075444
Average KL loss: 0.119273
Average total loss: 0.194717
tensor(0.0090, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(3.6043e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.074959
Average KL loss: 0.119645
Average total loss: 0.194604
tensor(0.0090, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(8.3324e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.072161
Average KL loss: 0.120061
Average total loss: 0.192223
tensor(0.0089, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.9625e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.070385
Average KL loss: 0.120287
Average total loss: 0.190672
tensor(0.0089, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-7.2230e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.070542
Average KL loss: 0.120124
Average total loss: 0.190666
tensor(0.0089, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.8794e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.069470
Average KL loss: 0.120505
Average total loss: 0.189975
tensor(0.0088, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-5.7841e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.066849
Average KL loss: 0.120051
Average total loss: 0.186900
tensor(0.0088, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-3.9080e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.066157
Average KL loss: 0.120170
Average total loss: 0.186327
tensor(0.0088, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.8545e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.068067
Average KL loss: 0.120378
Average total loss: 0.188445
tensor(0.0087, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(6.5681e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.067393
Average KL loss: 0.120688
Average total loss: 0.188081
tensor(0.0087, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-4.7782e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.068327
Average KL loss: 0.121105
Average total loss: 0.189432
tensor(0.0087, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(8.1834e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.066935
Average KL loss: 0.121551
Average total loss: 0.188486
tensor(0.0087, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.2331e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.063207
Average KL loss: 0.121548
Average total loss: 0.184755
tensor(0.0087, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.3036e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.063650
Average KL loss: 0.121320
Average total loss: 0.184970
tensor(0.0086, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.8691e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.064037
Average KL loss: 0.121414
Average total loss: 0.185451
tensor(0.0086, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-6.8530e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.063577
Average KL loss: 0.121669
Average total loss: 0.185246
tensor(0.0086, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(2.7488e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.064602
Average KL loss: 0.121829
Average total loss: 0.186431
tensor(0.0086, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-2.7169e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.065975
Average KL loss: 0.122438
Average total loss: 0.188413
tensor(0.0086, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-5.5232e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.062581
Average KL loss: 0.122585
Average total loss: 0.185166
tensor(0.0085, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(7.7787e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.063934
Average KL loss: 0.122797
Average total loss: 0.186731
tensor(0.0086, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(3.6765e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.061850
Average KL loss: 0.122689
Average total loss: 0.184538
tensor(0.0085, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(4.0294e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.064206
Average KL loss: 0.123053
Average total loss: 0.187259
tensor(0.0085, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(1.6766e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.061018
Average KL loss: 0.123082
Average total loss: 0.184100
tensor(0.0085, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.6328e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.061887
Average KL loss: 0.122962
Average total loss: 0.184849
tensor(0.0085, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(6.2072e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.058094
Average KL loss: 0.122541
Average total loss: 0.180634
tensor(0.0085, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-4.8960e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.063494
Average KL loss: 0.122761
Average total loss: 0.186254
tensor(0.0085, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.0573e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.061326
Average KL loss: 0.123208
Average total loss: 0.184534
tensor(0.0085, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-4.6734e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.061376
Average KL loss: 0.123108
Average total loss: 0.184484
tensor(0.0085, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-4.2320e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.060776
Average KL loss: 0.123298
Average total loss: 0.184074
tensor(0.0085, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(1.3212e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.058986
Average KL loss: 0.123389
Average total loss: 0.182374
tensor(0.0085, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-7.9405e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.057851
Average KL loss: 0.122934
Average total loss: 0.180785
tensor(0.0084, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.9164e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.060957
Average KL loss: 0.123330
Average total loss: 0.184287
tensor(0.0084, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(9.3928e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.060418
Average KL loss: 0.123422
Average total loss: 0.183840
tensor(0.0084, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(1.0178e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.059780
Average KL loss: 0.123942
Average total loss: 0.183722
tensor(0.0084, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(4.5811e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.056194
Average KL loss: 0.123784
Average total loss: 0.179977
tensor(0.0084, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(4.5633e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.056141
Average KL loss: 0.123311
Average total loss: 0.179452
tensor(0.0083, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(3.9261e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.056830
Average KL loss: 0.122883
Average total loss: 0.179712
tensor(0.0083, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(6.6113e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.061072
Average KL loss: 0.123290
Average total loss: 0.184361
tensor(0.0083, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.2702e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.061337
Average KL loss: 0.124195
Average total loss: 0.185532
tensor(0.0084, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.7596e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.057521
Average KL loss: 0.124609
Average total loss: 0.182130
tensor(0.0083, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-1.4545e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.057051
Average KL loss: 0.124376
Average total loss: 0.181427
tensor(0.0083, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(1.2685e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.057607
Average KL loss: 0.124112
Average total loss: 0.181719
tensor(0.0083, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(6.2168e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.057383
Average KL loss: 0.123966
Average total loss: 0.181349
tensor(0.0083, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(1.0250e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.055839
Average KL loss: 0.124412
Average total loss: 0.180251
tensor(0.0083, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-2.0055e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.053312
Average KL loss: 0.123855
Average total loss: 0.177166
tensor(0.0083, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-1.5017e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.057288
Average KL loss: 0.123692
Average total loss: 0.180980
tensor(0.0083, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(6.0893e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.057240
Average KL loss: 0.123718
Average total loss: 0.180958
tensor(0.0082, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-1.6723e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.057854
Average KL loss: 0.123869
Average total loss: 0.181723
tensor(0.0082, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-8.2062e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.055977
Average KL loss: 0.124215
Average total loss: 0.180192
tensor(0.0082, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(1.0121e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.055138
Average KL loss: 0.123947
Average total loss: 0.179085
tensor(0.0082, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(1.8563e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.056654
Average KL loss: 0.124020
Average total loss: 0.180674
tensor(0.0082, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-2.2395e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.057763
Average KL loss: 0.124316
Average total loss: 0.182079
tensor(0.0082, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(1.3951e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.056007
Average KL loss: 0.124571
Average total loss: 0.180578
tensor(0.0082, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(1.8480e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.055688
Average KL loss: 0.124417
Average total loss: 0.180105
tensor(0.0082, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-5.8120e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.057069
Average KL loss: 0.124923
Average total loss: 0.181992
tensor(0.0082, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-2.8290e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.055903
Average KL loss: 0.124794
Average total loss: 0.180697
tensor(0.0082, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(2.4504e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.057699
Average KL loss: 0.123993
Average total loss: 0.181693
tensor(0.0082, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(1.4275e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.056491
Average KL loss: 0.122489
Average total loss: 0.178980
tensor(0.0082, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(2.7489e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.055754
Average KL loss: 0.121198
Average total loss: 0.176952
tensor(0.0082, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(4.4987e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.056142
Average KL loss: 0.120084
Average total loss: 0.176226
tensor(0.0082, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-9.8857e-11, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.054705
Average KL loss: 0.119100
Average total loss: 0.173805
tensor(0.0082, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(3.5493e-11, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.055012
Average KL loss: 0.118194
Average total loss: 0.173206
tensor(0.0082, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(1.1828e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.054688
Average KL loss: 0.117363
Average total loss: 0.172051
tensor(0.0082, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-5.3886e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.056521
Average KL loss: 0.116618
Average total loss: 0.173139
tensor(0.0082, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(6.2626e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.056355
Average KL loss: 0.115901
Average total loss: 0.172256
tensor(0.0082, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-3.6579e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.055144
Average KL loss: 0.115230
Average total loss: 0.170375
tensor(0.0082, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(2.6250e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.052267
Average KL loss: 0.114597
Average total loss: 0.166864
tensor(0.0082, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(9.0458e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.053347
Average KL loss: 0.113975
Average total loss: 0.167322
tensor(0.0082, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(2.3548e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.053389
Average KL loss: 0.113381
Average total loss: 0.166770
tensor(0.0082, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(4.5795e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.052181
Average KL loss: 0.112830
Average total loss: 0.165012
tensor(0.0082, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-5.5079e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.056386
Average KL loss: 0.112316
Average total loss: 0.168702
tensor(0.0082, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(4.3979e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.055448
Average KL loss: 0.111831
Average total loss: 0.167279
tensor(0.0082, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-4.0764e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.055430
Average KL loss: 0.111354
Average total loss: 0.166785
tensor(0.0082, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-2.3557e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.053686
Average KL loss: 0.110890
Average total loss: 0.164575
tensor(0.0082, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-2.9262e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.054546
Average KL loss: 0.110439
Average total loss: 0.164986
tensor(0.0082, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-2.9771e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.052922
Average KL loss: 0.110008
Average total loss: 0.162930
tensor(0.0082, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-6.4027e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.054000
Average KL loss: 0.109606
Average total loss: 0.163607
tensor(0.0082, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(3.2335e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.053138
Average KL loss: 0.109202
Average total loss: 0.162340
tensor(0.0082, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.5103e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.054740
Average KL loss: 0.108823
Average total loss: 0.163563
tensor(0.0082, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-2.4020e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.052757
Average KL loss: 0.108471
Average total loss: 0.161228
tensor(0.0082, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(3.2313e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.050630
Average KL loss: 0.108094
Average total loss: 0.158724
tensor(0.0082, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(1.0148e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.050037
Average KL loss: 0.107704
Average total loss: 0.157741
tensor(0.0082, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(4.3435e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.054161
Average KL loss: 0.107354
Average total loss: 0.161516
tensor(0.0082, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.6728e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.051381
Average KL loss: 0.107005
Average total loss: 0.158386
tensor(0.0082, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(4.9282e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.054370
Average KL loss: 0.106675
Average total loss: 0.161045
tensor(0.0082, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.2173e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.052804
Average KL loss: 0.106372
Average total loss: 0.159176
tensor(0.0082, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-7.0170e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.053124
Average KL loss: 0.106067
Average total loss: 0.159191
tensor(0.0082, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(2.6336e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.054038
Average KL loss: 0.105778
Average total loss: 0.159816
tensor(0.0082, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-1.8406e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.051743
Average KL loss: 0.105484
Average total loss: 0.157227
tensor(0.0082, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-3.8510e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.054234
Average KL loss: 0.105194
Average total loss: 0.159427
tensor(0.0082, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(1.9104e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.050327
Average KL loss: 0.104918
Average total loss: 0.155245
tensor(0.0082, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-4.2520e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.055137
Average KL loss: 0.104629
Average total loss: 0.159766
tensor(0.0082, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(5.2307e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.053512
Average KL loss: 0.104370
Average total loss: 0.157882
tensor(0.0082, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-1.2783e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.052658
Average KL loss: 0.104113
Average total loss: 0.156771
tensor(0.0082, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(1.4494e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.051341
Average KL loss: 0.103847
Average total loss: 0.155188
tensor(0.0081, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(1.2292e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.054964
Average KL loss: 0.103617
Average total loss: 0.158581
tensor(0.0081, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-3.5182e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.055373
Average KL loss: 0.103401
Average total loss: 0.158773
tensor(0.0082, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(6.1423e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.054968
Average KL loss: 0.103180
Average total loss: 0.158148
tensor(0.0082, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(3.5717e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.053435
Average KL loss: 0.102955
Average total loss: 0.156390
tensor(0.0081, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-1.0693e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.054192
Average KL loss: 0.102738
Average total loss: 0.156930
tensor(0.0081, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.7778e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.053457
Average KL loss: 0.102539
Average total loss: 0.155996
tensor(0.0081, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(5.2437e-11, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.051330
Average KL loss: 0.102322
Average total loss: 0.153652
tensor(0.0081, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(3.2150e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.052308
Average KL loss: 0.102095
Average total loss: 0.154403
tensor(0.0081, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(4.4933e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.053262
Average KL loss: 0.101878
Average total loss: 0.155140
tensor(0.0081, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.1701e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.052073
Average KL loss: 0.101671
Average total loss: 0.153744
tensor(0.0081, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.4665e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.053307
Average KL loss: 0.101474
Average total loss: 0.154781
tensor(0.0081, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.3812e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.052983
Average KL loss: 0.101286
Average total loss: 0.154269
tensor(0.0081, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.7704e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.050643
Average KL loss: 0.101081
Average total loss: 0.151724
tensor(0.0081, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(4.9108e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.054224
Average KL loss: 0.100885
Average total loss: 0.155109
tensor(0.0081, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.7073e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.053662
Average KL loss: 0.100710
Average total loss: 0.154371
tensor(0.0081, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.9772e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.053888
Average KL loss: 0.100545
Average total loss: 0.154433
tensor(0.0081, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.5815e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.051588
Average KL loss: 0.100371
Average total loss: 0.151959
tensor(0.0081, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-4.1094e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.055025
Average KL loss: 0.100199
Average total loss: 0.155224
tensor(0.0081, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(3.3558e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.051947
Average KL loss: 0.100025
Average total loss: 0.151971
tensor(0.0081, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-4.5566e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.052119
Average KL loss: 0.099851
Average total loss: 0.151970
tensor(0.0081, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(2.3937e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.051183
Average KL loss: 0.099675
Average total loss: 0.150858
tensor(0.0081, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(8.5787e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.053517
Average KL loss: 0.099508
Average total loss: 0.153024
tensor(0.0081, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(3.7396e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.054903
Average KL loss: 0.099362
Average total loss: 0.154266
tensor(0.0081, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(1.7499e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.050442
Average KL loss: 0.099198
Average total loss: 0.149641
tensor(0.0081, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-4.0497e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.051584
Average KL loss: 0.099020
Average total loss: 0.150604
tensor(0.0081, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.7437e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.053826
Average KL loss: 0.098876
Average total loss: 0.152702
tensor(0.0081, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.9534e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.052601
Average KL loss: 0.098742
Average total loss: 0.151343
tensor(0.0081, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.8472e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.055273
Average KL loss: 0.098600
Average total loss: 0.153873
tensor(0.0081, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(8.2719e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.053187
Average KL loss: 0.098463
Average total loss: 0.151650
tensor(0.0081, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(1.2591e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.052068
Average KL loss: 0.098324
Average total loss: 0.150391
tensor(0.0081, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-6.8182e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.052714
Average KL loss: 0.098176
Average total loss: 0.150889
tensor(0.0081, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(3.8925e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.049728
Average KL loss: 0.098023
Average total loss: 0.147750
tensor(0.0081, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(1.2108e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.051963
Average KL loss: 0.097865
Average total loss: 0.149828
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(1.6684e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.053451
Average KL loss: 0.097736
Average total loss: 0.151187
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-4.8334e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.052381
Average KL loss: 0.097613
Average total loss: 0.149995
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(2.4065e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.052740
Average KL loss: 0.097487
Average total loss: 0.150226
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.7064e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.054689
Average KL loss: 0.097379
Average total loss: 0.152068
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-6.1463e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.049340
Average KL loss: 0.097268
Average total loss: 0.146608
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.2089e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.055106
Average KL loss: 0.097145
Average total loss: 0.152251
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(1.8172e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.052162
Average KL loss: 0.097045
Average total loss: 0.149207
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(1.3757e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.054436
Average KL loss: 0.096936
Average total loss: 0.151372
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(3.1188e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.054015
Average KL loss: 0.096819
Average total loss: 0.150834
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.6353e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.050750
Average KL loss: 0.096713
Average total loss: 0.147463
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.5453e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.052225
Average KL loss: 0.096595
Average total loss: 0.148820
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.4185e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.051003
Average KL loss: 0.096484
Average total loss: 0.147486
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.3171e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.050769
Average KL loss: 0.096360
Average total loss: 0.147130
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.4486e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.051579
Average KL loss: 0.096253
Average total loss: 0.147832
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-4.4444e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.052430
Average KL loss: 0.096141
Average total loss: 0.148571
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.2613e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.052651
Average KL loss: 0.096046
Average total loss: 0.148696
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-6.0962e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.053393
Average KL loss: 0.095988
Average total loss: 0.149381
tensor(0.0081, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(2.8653e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.049624
Average KL loss: 0.095957
Average total loss: 0.145581
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.8371e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.055193
Average KL loss: 0.095925
Average total loss: 0.151119
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(2.1034e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.049546
Average KL loss: 0.095895
Average total loss: 0.145442
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(4.2226e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.051049
Average KL loss: 0.095864
Average total loss: 0.146913
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.3189e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.052483
Average KL loss: 0.095835
Average total loss: 0.148318
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(5.5602e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.051014
Average KL loss: 0.095807
Average total loss: 0.146821
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(2.6133e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.052178
Average KL loss: 0.095777
Average total loss: 0.147956
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.3221e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.053307
Average KL loss: 0.095749
Average total loss: 0.149056
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.4540e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.052616
Average KL loss: 0.095723
Average total loss: 0.148339
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(4.3738e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.051319
Average KL loss: 0.095696
Average total loss: 0.147015
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.8456e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.051560
Average KL loss: 0.095669
Average total loss: 0.147229
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.2647e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.051957
Average KL loss: 0.095644
Average total loss: 0.147601
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.7805e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.050972
Average KL loss: 0.095619
Average total loss: 0.146591
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(5.1316e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.052770
Average KL loss: 0.095593
Average total loss: 0.148363
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.2087e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.052219
Average KL loss: 0.095579
Average total loss: 0.147799
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(6.4677e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.053899
Average KL loss: 0.095577
Average total loss: 0.149475
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(3.3937e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.054206
Average KL loss: 0.095574
Average total loss: 0.149780
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.7041e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.052707
Average KL loss: 0.095571
Average total loss: 0.148279
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.2291e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.050536
Average KL loss: 0.095569
Average total loss: 0.146105
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.9724e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.048730
Average KL loss: 0.095566
Average total loss: 0.144296
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-5.3691e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.050423
Average KL loss: 0.095563
Average total loss: 0.145986
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(2.1285e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.052568
Average KL loss: 0.095560
Average total loss: 0.148129
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.0743e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.051495
Average KL loss: 0.095558
Average total loss: 0.147053
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.9106e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.053318
Average KL loss: 0.095555
Average total loss: 0.148873
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.7046e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.052087
Average KL loss: 0.095553
Average total loss: 0.147639
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(5.8466e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.052569
Average KL loss: 0.095550
Average total loss: 0.148118
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.1522e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.053171
Average KL loss: 0.095547
Average total loss: 0.148718
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-4.8651e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.051766
Average KL loss: 0.095545
Average total loss: 0.147311
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(5.1234e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.053551
Average KL loss: 0.095542
Average total loss: 0.149093
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.9037e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.053474
Average KL loss: 0.095540
Average total loss: 0.149013
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(3.1360e-09, device='cuda:0')
 Percentile value: -0.00013746831682510662
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =    1075 /    1728             ( 62.21%) | total_pruned =     653 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6911 /   36864             ( 18.75%) | total_pruned =   29953 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    7297 /   36864             ( 19.79%) | total_pruned =   29567 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    7256 /   36864             ( 19.68%) | total_pruned =   29608 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    7113 /   36864             ( 19.30%) | total_pruned =   29751 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13147 /   73728             ( 17.83%) | total_pruned =   60581 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   25232 /  147456             ( 17.11%) | total_pruned =  122224 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2991 /    8192             ( 36.51%) | total_pruned =    5201 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   27457 /  147456             ( 18.62%) | total_pruned =  119999 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   26433 /  147456             ( 17.93%) | total_pruned =  121023 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   48435 /  294912             ( 16.42%) | total_pruned =  246477 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   96569 /  589824             ( 16.37%) | total_pruned =  493255 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    8520 /   32768             ( 26.00%) | total_pruned =   24248 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  145284 /  589824             ( 24.63%) | total_pruned =  444540 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  141556 /  589824             ( 24.00%) | total_pruned =  448268 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  200595 / 1179648             ( 17.00%) | total_pruned =  979053 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     494 /     512             ( 96.48%) | total_pruned =      18 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  617014 / 2359296             ( 26.15%) | total_pruned = 1742282 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     391 /     512             ( 76.37%) | total_pruned =     121 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   23883 /  131072             ( 18.22%) | total_pruned =  107189 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1267860 / 2359296             ( 53.74%) | total_pruned = 1091436 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     385 /     512             ( 75.20%) | total_pruned =     127 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     335 /     512             ( 65.43%) | total_pruned =     177 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1888438 / 2359296             ( 80.04%) | total_pruned =  470858 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
linear.weight        | nonzeros =    3102 /    5120             ( 60.59%) | total_pruned =    2018 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 29/100 Loss: 0.000020 Accuracy: 87.08 100.00 % Best test Accuracy: 87.17%
tensor(0.0081, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.0782e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.149977
Average KL loss: 0.093234
Average total loss: 0.243212
tensor(0.0107, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.7009e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.136184
Average KL loss: 0.100211
Average total loss: 0.236396
tensor(0.0106, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-8.3997e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.125272
Average KL loss: 0.105678
Average total loss: 0.230950
tensor(0.0106, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.1380e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.116880
Average KL loss: 0.109918
Average total loss: 0.226799
tensor(0.0105, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4027e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.107995
Average KL loss: 0.112850
Average total loss: 0.220844
tensor(0.0105, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-8.9168e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.103690
Average KL loss: 0.115033
Average total loss: 0.218723
tensor(0.0105, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(3.6909e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.104646
Average KL loss: 0.117135
Average total loss: 0.221781
tensor(0.0104, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.5237e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.102259
Average KL loss: 0.119269
Average total loss: 0.221528
tensor(0.0104, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.0436e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.095568
Average KL loss: 0.120956
Average total loss: 0.216524
tensor(0.0104, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(1.3252e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.093773
Average KL loss: 0.122046
Average total loss: 0.215818
tensor(0.0104, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-5.8766e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.095025
Average KL loss: 0.123265
Average total loss: 0.218290
tensor(0.0103, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-8.1544e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.093644
Average KL loss: 0.124665
Average total loss: 0.218309
tensor(0.0103, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-5.6760e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.088088
Average KL loss: 0.125666
Average total loss: 0.213754
tensor(0.0103, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-4.2128e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.088339
Average KL loss: 0.126595
Average total loss: 0.214935
tensor(0.0103, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(9.6749e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.085954
Average KL loss: 0.127069
Average total loss: 0.213023
tensor(0.0102, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(9.9112e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.086222
Average KL loss: 0.127570
Average total loss: 0.213792
tensor(0.0102, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(5.1329e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.084555
Average KL loss: 0.128096
Average total loss: 0.212651
tensor(0.0102, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-3.9423e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.082441
Average KL loss: 0.128858
Average total loss: 0.211299
tensor(0.0102, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-4.7019e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.083729
Average KL loss: 0.129330
Average total loss: 0.213059
tensor(0.0101, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.5349e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.081491
Average KL loss: 0.129984
Average total loss: 0.211475
tensor(0.0101, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.2754e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.080489
Average KL loss: 0.130623
Average total loss: 0.211112
tensor(0.0101, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-2.0417e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.075540
Average KL loss: 0.130683
Average total loss: 0.206223
tensor(0.0101, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-2.2205e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.076616
Average KL loss: 0.130743
Average total loss: 0.207358
tensor(0.0100, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.4086e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.074924
Average KL loss: 0.130751
Average total loss: 0.205676
tensor(0.0100, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(4.2492e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.078887
Average KL loss: 0.131137
Average total loss: 0.210025
tensor(0.0100, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(1.9055e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.077965
Average KL loss: 0.131868
Average total loss: 0.209833
tensor(0.0100, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.0555e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.074321
Average KL loss: 0.131859
Average total loss: 0.206180
tensor(0.0099, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.1139e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.072074
Average KL loss: 0.131827
Average total loss: 0.203902
tensor(0.0099, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-2.1741e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.074013
Average KL loss: 0.131857
Average total loss: 0.205870
tensor(0.0099, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(5.6794e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.073302
Average KL loss: 0.132005
Average total loss: 0.205308
tensor(0.0099, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(2.8513e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.076388
Average KL loss: 0.132027
Average total loss: 0.208415
tensor(0.0099, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(6.1782e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.070538
Average KL loss: 0.132707
Average total loss: 0.203246
tensor(0.0098, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(2.0455e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.070193
Average KL loss: 0.132527
Average total loss: 0.202721
tensor(0.0098, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(3.1200e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.068294
Average KL loss: 0.132534
Average total loss: 0.200828
tensor(0.0098, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-2.0543e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.072753
Average KL loss: 0.132537
Average total loss: 0.205290
tensor(0.0097, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(1.0589e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.074174
Average KL loss: 0.133131
Average total loss: 0.207305
tensor(0.0097, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(4.1417e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.066398
Average KL loss: 0.133372
Average total loss: 0.199771
tensor(0.0097, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-4.4568e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.075476
Average KL loss: 0.133764
Average total loss: 0.209240
tensor(0.0097, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-1.7723e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.072705
Average KL loss: 0.133989
Average total loss: 0.206693
tensor(0.0097, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(1.0448e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.069768
Average KL loss: 0.134442
Average total loss: 0.204209
tensor(0.0097, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-3.9210e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.068205
Average KL loss: 0.134427
Average total loss: 0.202632
tensor(0.0097, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-4.7023e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.070993
Average KL loss: 0.134709
Average total loss: 0.205702
tensor(0.0097, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(1.3476e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.068578
Average KL loss: 0.134692
Average total loss: 0.203270
tensor(0.0097, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.8733e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.067168
Average KL loss: 0.134985
Average total loss: 0.202154
tensor(0.0097, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-2.6173e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.068075
Average KL loss: 0.134900
Average total loss: 0.202975
tensor(0.0096, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-7.1978e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.068687
Average KL loss: 0.134906
Average total loss: 0.203594
tensor(0.0096, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-4.9821e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.065934
Average KL loss: 0.135081
Average total loss: 0.201016
tensor(0.0096, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-3.4284e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.068389
Average KL loss: 0.135129
Average total loss: 0.203518
tensor(0.0096, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-2.0444e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.068719
Average KL loss: 0.134727
Average total loss: 0.203446
tensor(0.0096, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(1.4736e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.065349
Average KL loss: 0.133613
Average total loss: 0.198962
tensor(0.0096, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-6.8849e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.066892
Average KL loss: 0.132649
Average total loss: 0.199541
tensor(0.0096, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(5.1823e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.067795
Average KL loss: 0.131809
Average total loss: 0.199604
tensor(0.0096, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(1.2724e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.063934
Average KL loss: 0.131041
Average total loss: 0.194975
tensor(0.0096, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-3.9918e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.065938
Average KL loss: 0.130346
Average total loss: 0.196284
tensor(0.0096, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(4.9567e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.064735
Average KL loss: 0.129700
Average total loss: 0.194435
tensor(0.0096, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-5.0617e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.066298
Average KL loss: 0.129074
Average total loss: 0.195372
tensor(0.0096, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-8.4150e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.064496
Average KL loss: 0.128501
Average total loss: 0.192997
tensor(0.0096, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-3.9471e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.065557
Average KL loss: 0.127951
Average total loss: 0.193508
tensor(0.0096, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(8.3640e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.064905
Average KL loss: 0.127452
Average total loss: 0.192357
tensor(0.0096, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(1.1286e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.065690
Average KL loss: 0.126967
Average total loss: 0.192657
tensor(0.0096, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(6.4381e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.065137
Average KL loss: 0.126490
Average total loss: 0.191628
tensor(0.0096, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(4.2361e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.064878
Average KL loss: 0.126055
Average total loss: 0.190933
tensor(0.0096, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-2.3947e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.068883
Average KL loss: 0.125629
Average total loss: 0.194512
tensor(0.0096, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(1.8132e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.067956
Average KL loss: 0.125217
Average total loss: 0.193173
tensor(0.0096, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-2.4517e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.062224
Average KL loss: 0.124814
Average total loss: 0.187038
tensor(0.0096, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(1.4262e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.065460
Average KL loss: 0.124417
Average total loss: 0.189878
tensor(0.0096, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(1.8584e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.066147
Average KL loss: 0.124048
Average total loss: 0.190194
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-5.2991e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.063542
Average KL loss: 0.123673
Average total loss: 0.187215
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(1.0783e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.063059
Average KL loss: 0.123294
Average total loss: 0.186353
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(1.1165e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.064723
Average KL loss: 0.122949
Average total loss: 0.187672
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(3.4369e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.064424
Average KL loss: 0.122619
Average total loss: 0.187043
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-2.1162e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.065132
Average KL loss: 0.122295
Average total loss: 0.187427
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(9.3918e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.063714
Average KL loss: 0.121980
Average total loss: 0.185695
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-3.4850e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.066475
Average KL loss: 0.121674
Average total loss: 0.188149
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-4.0674e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.063595
Average KL loss: 0.121371
Average total loss: 0.184966
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(2.3974e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.063767
Average KL loss: 0.121074
Average total loss: 0.184841
tensor(0.0096, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(3.0794e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.060732
Average KL loss: 0.120785
Average total loss: 0.181517
tensor(0.0096, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(6.7133e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.064187
Average KL loss: 0.120497
Average total loss: 0.184684
tensor(0.0096, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(3.8666e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.064569
Average KL loss: 0.120236
Average total loss: 0.184805
tensor(0.0096, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.2188e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.062915
Average KL loss: 0.119973
Average total loss: 0.182888
tensor(0.0096, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(3.7799e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.066012
Average KL loss: 0.119712
Average total loss: 0.185724
tensor(0.0096, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-5.7265e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.066338
Average KL loss: 0.119472
Average total loss: 0.185810
tensor(0.0096, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(2.7552e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.061934
Average KL loss: 0.119228
Average total loss: 0.181161
tensor(0.0096, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-9.5950e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.068540
Average KL loss: 0.118995
Average total loss: 0.187535
tensor(0.0096, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.0267e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.062722
Average KL loss: 0.118789
Average total loss: 0.181510
tensor(0.0096, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.9191e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.065519
Average KL loss: 0.118557
Average total loss: 0.184075
tensor(0.0096, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.4918e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.062527
Average KL loss: 0.118328
Average total loss: 0.180855
tensor(0.0095, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(1.2151e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.064193
Average KL loss: 0.118088
Average total loss: 0.182281
tensor(0.0095, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(1.3565e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.062517
Average KL loss: 0.117859
Average total loss: 0.180376
tensor(0.0095, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-2.1051e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.064301
Average KL loss: 0.117641
Average total loss: 0.181942
tensor(0.0095, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-5.1451e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.064651
Average KL loss: 0.117437
Average total loss: 0.182088
tensor(0.0095, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(4.3805e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.063867
Average KL loss: 0.117227
Average total loss: 0.181094
tensor(0.0095, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(4.1729e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.064944
Average KL loss: 0.117029
Average total loss: 0.181972
tensor(0.0095, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-5.3184e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.062857
Average KL loss: 0.116846
Average total loss: 0.179703
tensor(0.0095, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(4.4524e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.063908
Average KL loss: 0.116645
Average total loss: 0.180553
tensor(0.0095, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(4.1221e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.062012
Average KL loss: 0.116459
Average total loss: 0.178470
tensor(0.0095, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(4.0841e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.063365
Average KL loss: 0.116278
Average total loss: 0.179643
tensor(0.0095, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(9.7982e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.065517
Average KL loss: 0.116087
Average total loss: 0.181605
tensor(0.0095, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-4.3907e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.062032
Average KL loss: 0.115929
Average total loss: 0.177961
tensor(0.0095, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.1349e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.064036
Average KL loss: 0.115752
Average total loss: 0.179788
tensor(0.0095, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(7.4811e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.067399
Average KL loss: 0.115581
Average total loss: 0.182980
tensor(0.0095, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(2.0653e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.059856
Average KL loss: 0.115417
Average total loss: 0.175273
tensor(0.0095, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(2.7807e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.063743
Average KL loss: 0.115248
Average total loss: 0.178991
tensor(0.0095, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.8498e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.065565
Average KL loss: 0.115091
Average total loss: 0.180656
tensor(0.0095, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(1.1481e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.064356
Average KL loss: 0.114943
Average total loss: 0.179299
tensor(0.0095, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(3.8249e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.063067
Average KL loss: 0.114801
Average total loss: 0.177868
tensor(0.0095, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.0934e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.065048
Average KL loss: 0.114642
Average total loss: 0.179690
tensor(0.0095, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(3.9749e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.064752
Average KL loss: 0.114478
Average total loss: 0.179229
tensor(0.0095, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(1.5654e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.063207
Average KL loss: 0.114331
Average total loss: 0.177538
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-7.2752e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.064043
Average KL loss: 0.114194
Average total loss: 0.178237
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-1.8000e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.063254
Average KL loss: 0.114055
Average total loss: 0.177309
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(1.8034e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.064408
Average KL loss: 0.113890
Average total loss: 0.178298
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(2.1764e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.061264
Average KL loss: 0.113762
Average total loss: 0.175026
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-1.6481e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.061450
Average KL loss: 0.113605
Average total loss: 0.175055
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(8.7860e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.062034
Average KL loss: 0.113458
Average total loss: 0.175492
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-1.5055e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.064292
Average KL loss: 0.113322
Average total loss: 0.177614
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-1.2923e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.062275
Average KL loss: 0.113198
Average total loss: 0.175472
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.0016e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.064191
Average KL loss: 0.113069
Average total loss: 0.177260
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(2.0410e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.064319
Average KL loss: 0.112946
Average total loss: 0.177265
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-6.6809e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.062598
Average KL loss: 0.112831
Average total loss: 0.175429
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-3.9566e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.061068
Average KL loss: 0.112695
Average total loss: 0.173763
tensor(0.0095, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-3.5237e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.062055
Average KL loss: 0.112569
Average total loss: 0.174625
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.6764e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.063827
Average KL loss: 0.112446
Average total loss: 0.176273
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-5.3920e-11, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.059948
Average KL loss: 0.112329
Average total loss: 0.172277
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.0007e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.063745
Average KL loss: 0.112207
Average total loss: 0.175952
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(1.2036e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.062246
Average KL loss: 0.112103
Average total loss: 0.174348
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(3.9452e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.063545
Average KL loss: 0.111991
Average total loss: 0.175535
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(2.6865e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.061885
Average KL loss: 0.111867
Average total loss: 0.173752
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(2.7829e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.061990
Average KL loss: 0.111754
Average total loss: 0.173744
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(1.0158e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.061241
Average KL loss: 0.111646
Average total loss: 0.172887
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.6238e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.064389
Average KL loss: 0.111528
Average total loss: 0.175917
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(3.0318e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.064451
Average KL loss: 0.111424
Average total loss: 0.175875
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-5.5934e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.060518
Average KL loss: 0.111328
Average total loss: 0.171847
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-4.3285e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.063880
Average KL loss: 0.111222
Average total loss: 0.175103
tensor(0.0095, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(4.3514e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.062849
Average KL loss: 0.111112
Average total loss: 0.173961
tensor(0.0094, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(1.2645e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.062474
Average KL loss: 0.110999
Average total loss: 0.173473
tensor(0.0094, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(5.4390e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.060758
Average KL loss: 0.110888
Average total loss: 0.171646
tensor(0.0094, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.3341e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.065272
Average KL loss: 0.110799
Average total loss: 0.176071
tensor(0.0094, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(3.6561e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.064728
Average KL loss: 0.110710
Average total loss: 0.175438
tensor(0.0094, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-5.6303e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.060278
Average KL loss: 0.110616
Average total loss: 0.170894
tensor(0.0094, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(1.5954e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.063748
Average KL loss: 0.110509
Average total loss: 0.174258
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(5.5609e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.065038
Average KL loss: 0.110421
Average total loss: 0.175459
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(9.5135e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.062998
Average KL loss: 0.110336
Average total loss: 0.173335
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-3.1234e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.066366
Average KL loss: 0.110247
Average total loss: 0.176613
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-6.6271e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.063285
Average KL loss: 0.110158
Average total loss: 0.173443
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(3.7694e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.064239
Average KL loss: 0.110076
Average total loss: 0.174315
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(7.0492e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.058386
Average KL loss: 0.109995
Average total loss: 0.168381
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(7.1922e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.063957
Average KL loss: 0.109896
Average total loss: 0.173853
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-3.7819e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.062964
Average KL loss: 0.109815
Average total loss: 0.172779
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-4.0900e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.060160
Average KL loss: 0.109719
Average total loss: 0.169879
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-3.1577e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.063632
Average KL loss: 0.109620
Average total loss: 0.173252
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(2.3884e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.064119
Average KL loss: 0.109542
Average total loss: 0.173661
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-3.7341e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.062037
Average KL loss: 0.109468
Average total loss: 0.171506
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(6.0649e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.061368
Average KL loss: 0.109395
Average total loss: 0.170763
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.8808e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.060752
Average KL loss: 0.109303
Average total loss: 0.170055
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.4865e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.061127
Average KL loss: 0.109213
Average total loss: 0.170339
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-2.2726e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.060868
Average KL loss: 0.109128
Average total loss: 0.169997
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-2.1080e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.062597
Average KL loss: 0.109056
Average total loss: 0.171654
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.3776e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.063376
Average KL loss: 0.109022
Average total loss: 0.172398
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.4449e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.066491
Average KL loss: 0.108998
Average total loss: 0.175489
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(3.8166e-11, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.063868
Average KL loss: 0.108977
Average total loss: 0.172844
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.5253e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.061440
Average KL loss: 0.108955
Average total loss: 0.170394
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(7.0130e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.064200
Average KL loss: 0.108933
Average total loss: 0.173133
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.0639e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.062938
Average KL loss: 0.108914
Average total loss: 0.171852
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(4.6507e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.061141
Average KL loss: 0.108893
Average total loss: 0.170035
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-6.7658e-11, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.061585
Average KL loss: 0.108872
Average total loss: 0.170456
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(2.6086e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.063686
Average KL loss: 0.108851
Average total loss: 0.172537
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.8347e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.061256
Average KL loss: 0.108831
Average total loss: 0.170087
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-7.9922e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.063571
Average KL loss: 0.108812
Average total loss: 0.172383
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.3664e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.063531
Average KL loss: 0.108801
Average total loss: 0.172332
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.0711e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.063025
Average KL loss: 0.108798
Average total loss: 0.171823
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.0038e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.062633
Average KL loss: 0.108796
Average total loss: 0.171429
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-8.2158e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.064991
Average KL loss: 0.108794
Average total loss: 0.173785
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(5.1120e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.062292
Average KL loss: 0.108792
Average total loss: 0.171084
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(2.8952e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.061734
Average KL loss: 0.108790
Average total loss: 0.170523
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(3.2429e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.063236
Average KL loss: 0.108788
Average total loss: 0.172023
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-3.1129e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.063521
Average KL loss: 0.108786
Average total loss: 0.172306
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.4208e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.059480
Average KL loss: 0.108784
Average total loss: 0.168264
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(6.1681e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.061089
Average KL loss: 0.108781
Average total loss: 0.169871
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(2.4004e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.061864
Average KL loss: 0.108779
Average total loss: 0.170643
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(6.5435e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.063152
Average KL loss: 0.108777
Average total loss: 0.171930
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-7.2252e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.060923
Average KL loss: 0.108775
Average total loss: 0.169698
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.1458e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.064227
Average KL loss: 0.108773
Average total loss: 0.173000
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(3.8796e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.062571
Average KL loss: 0.108771
Average total loss: 0.171342
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.0446e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.062242
Average KL loss: 0.108769
Average total loss: 0.171011
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(5.6818e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.063977
Average KL loss: 0.108767
Average total loss: 0.172744
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-9.7850e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.063825
Average KL loss: 0.108765
Average total loss: 0.172590
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(3.7083e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.060577
Average KL loss: 0.108763
Average total loss: 0.169340
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-4.5584e-09, device='cuda:0')
 Percentile value: -1.6525542889667122e-07
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =    1044 /    1728             ( 60.42%) | total_pruned =     684 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5168 /   36864             ( 14.02%) | total_pruned =   31696 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5635 /   36864             ( 15.29%) | total_pruned =   31229 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    5465 /   36864             ( 14.82%) | total_pruned =   31399 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    5509 /   36864             ( 14.94%) | total_pruned =   31355 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    9852 /   73728             ( 13.36%) | total_pruned =   63876 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   18156 /  147456             ( 12.31%) | total_pruned =  129300 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2640 /    8192             ( 32.23%) | total_pruned =    5552 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   19662 /  147456             ( 13.33%) | total_pruned =  127794 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   19057 /  147456             ( 12.92%) | total_pruned =  128399 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   34288 /  294912             ( 11.63%) | total_pruned =  260624 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   65688 /  589824             ( 11.14%) | total_pruned =  524136 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7099 /   32768             ( 21.66%) | total_pruned =   25669 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     194 /     256             ( 75.78%) | total_pruned =      62 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  107090 /  589824             ( 18.16%) | total_pruned =  482734 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  104489 /  589824             ( 17.72%) | total_pruned =  485335 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  132434 / 1179648             ( 11.23%) | total_pruned = 1047214 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     492 /     512             ( 96.09%) | total_pruned =      20 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  395054 / 2359296             ( 16.74%) | total_pruned = 1964242 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     388 /     512             ( 75.78%) | total_pruned =     124 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   17339 /  131072             ( 13.23%) | total_pruned =  113733 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     392 /     512             ( 76.56%) | total_pruned =     120 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1025993 / 2359296             ( 43.49%) | total_pruned = 1333303 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     385 /     512             ( 75.20%) | total_pruned =     127 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     330 /     512             ( 64.45%) | total_pruned =     182 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1666082 / 2359296             ( 70.62%) | total_pruned =  693214 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
linear.weight        | nonzeros =    2779 /    5120             ( 54.28%) | total_pruned =    2341 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 25/100 Loss: 0.000011 Accuracy: 86.65 100.00 % Best test Accuracy: 87.46%
tensor(0.0094, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.8987e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.157499
Average KL loss: 0.105111
Average total loss: 0.262611
tensor(0.0115, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.1028e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.148613
Average KL loss: 0.110271
Average total loss: 0.258884
tensor(0.0114, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-8.0743e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.133414
Average KL loss: 0.114627
Average total loss: 0.248041
tensor(0.0114, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(4.9896e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.123771
Average KL loss: 0.117798
Average total loss: 0.241569
tensor(0.0113, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(5.2948e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.119747
Average KL loss: 0.120607
Average total loss: 0.240354
tensor(0.0113, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-2.1838e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.114542
Average KL loss: 0.122950
Average total loss: 0.237492
tensor(0.0113, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-5.8109e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.113511
Average KL loss: 0.124933
Average total loss: 0.238444
tensor(0.0112, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-8.0928e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.110021
Average KL loss: 0.126742
Average total loss: 0.236763
tensor(0.0112, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(2.1839e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.108403
Average KL loss: 0.128232
Average total loss: 0.236635
tensor(0.0112, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(2.7687e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.103155
Average KL loss: 0.129496
Average total loss: 0.232651
tensor(0.0112, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(4.1451e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.104441
Average KL loss: 0.130890
Average total loss: 0.235330
tensor(0.0112, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(2.1197e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.097900
Average KL loss: 0.132244
Average total loss: 0.230144
tensor(0.0112, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-5.5904e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.096496
Average KL loss: 0.132725
Average total loss: 0.229220
tensor(0.0112, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-6.1032e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.095372
Average KL loss: 0.133445
Average total loss: 0.228817
tensor(0.0111, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-3.2025e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.094524
Average KL loss: 0.134079
Average total loss: 0.228602
tensor(0.0111, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-6.2504e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.094843
Average KL loss: 0.134718
Average total loss: 0.229560
tensor(0.0111, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-9.4636e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.092424
Average KL loss: 0.135564
Average total loss: 0.227987
tensor(0.0111, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(7.3723e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.090339
Average KL loss: 0.135817
Average total loss: 0.226156
tensor(0.0110, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(5.3851e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.089285
Average KL loss: 0.136286
Average total loss: 0.225571
tensor(0.0110, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-4.0377e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.088632
Average KL loss: 0.136740
Average total loss: 0.225372
tensor(0.0110, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(1.7357e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.087866
Average KL loss: 0.137224
Average total loss: 0.225091
tensor(0.0109, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.9081e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.088207
Average KL loss: 0.137643
Average total loss: 0.225850
tensor(0.0109, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-3.9658e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.088041
Average KL loss: 0.138226
Average total loss: 0.226267
tensor(0.0109, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-1.1567e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.089974
Average KL loss: 0.138916
Average total loss: 0.228890
tensor(0.0109, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-1.2521e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.085820
Average KL loss: 0.139548
Average total loss: 0.225368
tensor(0.0109, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(5.2722e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.084467
Average KL loss: 0.139848
Average total loss: 0.224315
tensor(0.0109, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(1.9213e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.082914
Average KL loss: 0.140047
Average total loss: 0.222961
tensor(0.0108, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(2.1405e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.083032
Average KL loss: 0.140220
Average total loss: 0.223253
tensor(0.0108, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(3.0846e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.084155
Average KL loss: 0.140537
Average total loss: 0.224692
tensor(0.0108, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(9.1673e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.083487
Average KL loss: 0.140998
Average total loss: 0.224485
tensor(0.0108, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.9141e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.078904
Average KL loss: 0.141263
Average total loss: 0.220167
tensor(0.0108, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-4.5247e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.078724
Average KL loss: 0.141238
Average total loss: 0.219962
tensor(0.0108, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.3012e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.081098
Average KL loss: 0.141472
Average total loss: 0.222570
tensor(0.0107, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(2.4606e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.082447
Average KL loss: 0.141588
Average total loss: 0.224035
tensor(0.0107, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(2.1315e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.083392
Average KL loss: 0.142052
Average total loss: 0.225444
tensor(0.0107, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(2.4266e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.082665
Average KL loss: 0.142566
Average total loss: 0.225230
tensor(0.0107, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(2.1159e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.080702
Average KL loss: 0.142816
Average total loss: 0.223517
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(2.2985e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.078207
Average KL loss: 0.142950
Average total loss: 0.221157
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-4.1346e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.081537
Average KL loss: 0.142951
Average total loss: 0.224488
tensor(0.0106, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.9266e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.077257
Average KL loss: 0.143291
Average total loss: 0.220548
tensor(0.0106, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-5.9214e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.077226
Average KL loss: 0.143268
Average total loss: 0.220495
tensor(0.0106, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(7.8432e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.076978
Average KL loss: 0.143208
Average total loss: 0.220186
tensor(0.0106, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(1.3207e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.078650
Average KL loss: 0.143418
Average total loss: 0.222068
tensor(0.0106, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-7.6874e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.081080
Average KL loss: 0.143362
Average total loss: 0.224442
tensor(0.0106, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(3.2063e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.079507
Average KL loss: 0.142512
Average total loss: 0.222019
tensor(0.0106, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.0858e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.077422
Average KL loss: 0.141779
Average total loss: 0.219201
tensor(0.0106, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-3.3970e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.073539
Average KL loss: 0.141127
Average total loss: 0.214665
tensor(0.0106, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.4768e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.074161
Average KL loss: 0.140525
Average total loss: 0.214686
tensor(0.0106, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.8345e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.078723
Average KL loss: 0.139992
Average total loss: 0.218715
tensor(0.0106, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(2.2946e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.075623
Average KL loss: 0.139490
Average total loss: 0.215113
tensor(0.0106, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(1.0640e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.074104
Average KL loss: 0.139021
Average total loss: 0.213125
tensor(0.0106, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(2.6048e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.074284
Average KL loss: 0.138570
Average total loss: 0.212853
tensor(0.0106, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(3.7274e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.073644
Average KL loss: 0.138138
Average total loss: 0.211782
tensor(0.0106, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(3.8531e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.076274
Average KL loss: 0.137733
Average total loss: 0.214008
tensor(0.0106, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-3.8543e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.072080
Average KL loss: 0.137348
Average total loss: 0.209428
tensor(0.0106, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(1.5353e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.072513
Average KL loss: 0.136958
Average total loss: 0.209471
tensor(0.0106, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-1.4936e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.074271
Average KL loss: 0.136598
Average total loss: 0.210869
tensor(0.0106, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-1.1836e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.074627
Average KL loss: 0.136249
Average total loss: 0.210876
tensor(0.0106, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(4.3614e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.078152
Average KL loss: 0.135922
Average total loss: 0.214075
tensor(0.0106, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(3.3949e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.074658
Average KL loss: 0.135606
Average total loss: 0.210264
tensor(0.0106, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-3.4016e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.074985
Average KL loss: 0.135297
Average total loss: 0.210282
tensor(0.0106, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-4.6604e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.074915
Average KL loss: 0.135002
Average total loss: 0.209917
tensor(0.0106, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-3.1612e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.076650
Average KL loss: 0.134718
Average total loss: 0.211368
tensor(0.0106, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(1.9859e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.072532
Average KL loss: 0.134429
Average total loss: 0.206961
tensor(0.0106, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-3.0146e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.075122
Average KL loss: 0.134156
Average total loss: 0.209278
tensor(0.0106, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(5.2813e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.073134
Average KL loss: 0.133881
Average total loss: 0.207016
tensor(0.0106, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(2.3806e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.074897
Average KL loss: 0.133623
Average total loss: 0.208520
tensor(0.0106, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(4.3665e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.075217
Average KL loss: 0.133387
Average total loss: 0.208604
tensor(0.0106, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(5.0024e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.075118
Average KL loss: 0.133146
Average total loss: 0.208265
tensor(0.0106, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(8.3599e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.074062
Average KL loss: 0.132909
Average total loss: 0.206971
tensor(0.0106, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-9.7062e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.076470
Average KL loss: 0.132672
Average total loss: 0.209142
tensor(0.0105, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.0107e-11, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.075566
Average KL loss: 0.132453
Average total loss: 0.208018
tensor(0.0105, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.5026e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.072589
Average KL loss: 0.132237
Average total loss: 0.204827
tensor(0.0105, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(4.9881e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.073347
Average KL loss: 0.132020
Average total loss: 0.205367
tensor(0.0105, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.2593e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.075465
Average KL loss: 0.131803
Average total loss: 0.207267
tensor(0.0105, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-7.3303e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.072707
Average KL loss: 0.131602
Average total loss: 0.204309
tensor(0.0105, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-7.6492e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.075366
Average KL loss: 0.131412
Average total loss: 0.206778
tensor(0.0105, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-4.0895e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.074651
Average KL loss: 0.131229
Average total loss: 0.205880
tensor(0.0105, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(7.8695e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.075410
Average KL loss: 0.131037
Average total loss: 0.206446
tensor(0.0105, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(1.7791e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.073637
Average KL loss: 0.130837
Average total loss: 0.204474
tensor(0.0105, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-1.5651e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.074341
Average KL loss: 0.130654
Average total loss: 0.204994
tensor(0.0105, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(3.7408e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.074411
Average KL loss: 0.130491
Average total loss: 0.204902
tensor(0.0105, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-2.1604e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.071510
Average KL loss: 0.130314
Average total loss: 0.201823
tensor(0.0105, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(9.4018e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.072610
Average KL loss: 0.130117
Average total loss: 0.202727
tensor(0.0105, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-1.6274e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.074596
Average KL loss: 0.129933
Average total loss: 0.204529
tensor(0.0105, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-2.5765e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.071097
Average KL loss: 0.129747
Average total loss: 0.200844
tensor(0.0105, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(7.6376e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.066696
Average KL loss: 0.129550
Average total loss: 0.196246
tensor(0.0105, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(1.9964e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.073624
Average KL loss: 0.129362
Average total loss: 0.202987
tensor(0.0105, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(1.5327e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.071346
Average KL loss: 0.129199
Average total loss: 0.200544
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(6.7645e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.074077
Average KL loss: 0.129041
Average total loss: 0.203118
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.7497e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.072375
Average KL loss: 0.128880
Average total loss: 0.201256
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(3.7651e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.071130
Average KL loss: 0.128717
Average total loss: 0.199848
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(2.3874e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.072741
Average KL loss: 0.128567
Average total loss: 0.201308
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(4.9036e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.071371
Average KL loss: 0.128412
Average total loss: 0.199783
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(1.6974e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.070942
Average KL loss: 0.128257
Average total loss: 0.199199
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(1.1184e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.075549
Average KL loss: 0.128115
Average total loss: 0.203664
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.9463e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.070651
Average KL loss: 0.127982
Average total loss: 0.198633
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(3.0400e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.072249
Average KL loss: 0.127832
Average total loss: 0.200081
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(1.0077e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.070999
Average KL loss: 0.127745
Average total loss: 0.198744
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.4006e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.073403
Average KL loss: 0.127720
Average total loss: 0.201123
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.1032e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.069196
Average KL loss: 0.127695
Average total loss: 0.196890
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-4.8915e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.074517
Average KL loss: 0.127670
Average total loss: 0.202187
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(1.8261e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.073799
Average KL loss: 0.127647
Average total loss: 0.201446
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-3.7931e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.071024
Average KL loss: 0.127624
Average total loss: 0.198648
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-4.0429e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.075399
Average KL loss: 0.127601
Average total loss: 0.203000
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(6.4044e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.072130
Average KL loss: 0.127578
Average total loss: 0.199709
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(2.1988e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.072146
Average KL loss: 0.127555
Average total loss: 0.199701
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.1480e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.071123
Average KL loss: 0.127532
Average total loss: 0.198655
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(1.4616e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.072821
Average KL loss: 0.127509
Average total loss: 0.200330
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.0641e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.073109
Average KL loss: 0.127496
Average total loss: 0.200605
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.7609e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.071824
Average KL loss: 0.127494
Average total loss: 0.199318
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-3.4970e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.069737
Average KL loss: 0.127491
Average total loss: 0.197228
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-3.9784e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.069560
Average KL loss: 0.127489
Average total loss: 0.197049
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(2.8483e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.070648
Average KL loss: 0.127486
Average total loss: 0.198134
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-3.0610e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.076039
Average KL loss: 0.127484
Average total loss: 0.203523
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(5.1695e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.073025
Average KL loss: 0.127482
Average total loss: 0.200507
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(2.9558e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.075038
Average KL loss: 0.127479
Average total loss: 0.202517
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(3.4788e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.071077
Average KL loss: 0.127477
Average total loss: 0.198554
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(3.5991e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.071890
Average KL loss: 0.127475
Average total loss: 0.199364
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-3.6541e-09, device='cuda:0')
 Percentile value: -1.652481103064929e-07
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =    1012 /    1728             ( 58.56%) | total_pruned =     716 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4093 /   36864             ( 11.10%) | total_pruned =   32771 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4581 /   36864             ( 12.43%) | total_pruned =   32283 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4308 /   36864             ( 11.69%) | total_pruned =   32556 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4407 /   36864             ( 11.95%) | total_pruned =   32457 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    7765 /   73728             ( 10.53%) | total_pruned =   65963 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   13646 /  147456             (  9.25%) | total_pruned =  133810 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2378 /    8192             ( 29.03%) | total_pruned =    5814 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   14626 /  147456             (  9.92%) | total_pruned =  132830 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   14428 /  147456             (  9.78%) | total_pruned =  133028 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   25592 /  294912             (  8.68%) | total_pruned =  269320 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   46708 /  589824             (  7.92%) | total_pruned =  543116 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     188 /     256             ( 73.44%) | total_pruned =      68 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6105 /   32768             ( 18.63%) | total_pruned =   26663 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     181 /     256             ( 70.70%) | total_pruned =      75 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   82741 /  589824             ( 14.03%) | total_pruned =  507083 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   80578 /  589824             ( 13.66%) | total_pruned =  509246 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     150 /     256             ( 58.59%) | total_pruned =     106 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   90015 / 1179648             (  7.63%) | total_pruned = 1089633 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  247481 / 2359296             ( 10.49%) | total_pruned = 2111815 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   13258 /  131072             ( 10.12%) | total_pruned =  117814 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     387 /     512             ( 75.59%) | total_pruned =     125 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  843184 / 2359296             ( 35.74%) | total_pruned = 1516112 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     321 /     512             ( 62.70%) | total_pruned =     191 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1408607 / 2359296             ( 59.70%) | total_pruned =  950689 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      36 /     512             (  7.03%) | total_pruned =     476 | shape = torch.Size([512])
linear.weight        | nonzeros =    2534 /    5120             ( 49.49%) | total_pruned =    2586 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 27/100 Loss: 0.000263 Accuracy: 86.37 100.00 % Best test Accuracy: 87.28%
tensor(0.0105, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.1633e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.198425
Average KL loss: 0.122014
Average total loss: 0.320439
tensor(0.0125, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.0706e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.191337
Average KL loss: 0.125791
Average total loss: 0.317127
tensor(0.0124, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-8.0356e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.168833
Average KL loss: 0.129994
Average total loss: 0.298828
tensor(0.0124, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-2.4733e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.157423
Average KL loss: 0.133181
Average total loss: 0.290604
tensor(0.0124, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-6.5382e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.152323
Average KL loss: 0.135896
Average total loss: 0.288219
tensor(0.0124, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.0906e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.148572
Average KL loss: 0.138214
Average total loss: 0.286786
tensor(0.0123, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-1.4509e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.142611
Average KL loss: 0.140285
Average total loss: 0.282896
tensor(0.0123, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-7.9237e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.141324
Average KL loss: 0.142271
Average total loss: 0.283596
tensor(0.0123, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.2412e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.134581
Average KL loss: 0.143930
Average total loss: 0.278511
tensor(0.0123, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.1136e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.131936
Average KL loss: 0.145388
Average total loss: 0.277325
tensor(0.0123, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-6.1896e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.127094
Average KL loss: 0.146675
Average total loss: 0.273769
tensor(0.0123, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(2.7271e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.128882
Average KL loss: 0.147809
Average total loss: 0.276690
tensor(0.0123, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-8.0840e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.123805
Average KL loss: 0.148958
Average total loss: 0.272762
tensor(0.0123, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-2.3049e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.125271
Average KL loss: 0.150173
Average total loss: 0.275445
tensor(0.0123, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-9.7740e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.119370
Average KL loss: 0.151117
Average total loss: 0.270487
tensor(0.0122, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-5.4890e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.113367
Average KL loss: 0.151788
Average total loss: 0.265154
tensor(0.0122, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-5.4034e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.116309
Average KL loss: 0.152488
Average total loss: 0.268797
tensor(0.0122, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-5.8301e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.112742
Average KL loss: 0.153058
Average total loss: 0.265800
tensor(0.0122, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-7.9988e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.117801
Average KL loss: 0.153897
Average total loss: 0.271698
tensor(0.0122, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-1.1675e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.113024
Average KL loss: 0.154445
Average total loss: 0.267469
tensor(0.0122, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(3.5537e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.112957
Average KL loss: 0.155025
Average total loss: 0.267982
tensor(0.0122, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(2.9107e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.105063
Average KL loss: 0.155474
Average total loss: 0.260538
tensor(0.0121, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-3.9134e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.108923
Average KL loss: 0.155827
Average total loss: 0.264750
tensor(0.0121, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-2.5745e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.110410
Average KL loss: 0.156397
Average total loss: 0.266807
tensor(0.0121, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-2.8767e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.112073
Average KL loss: 0.157075
Average total loss: 0.269148
tensor(0.0121, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-9.3062e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.104319
Average KL loss: 0.157644
Average total loss: 0.261963
tensor(0.0121, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(3.3054e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.102814
Average KL loss: 0.157988
Average total loss: 0.260801
tensor(0.0121, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-3.4362e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.104323
Average KL loss: 0.158351
Average total loss: 0.262673
tensor(0.0121, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-2.3426e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.097124
Average KL loss: 0.158508
Average total loss: 0.255631
tensor(0.0120, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-4.1888e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.104119
Average KL loss: 0.158522
Average total loss: 0.262641
tensor(0.0120, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-6.0791e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.102834
Average KL loss: 0.158860
Average total loss: 0.261695
tensor(0.0120, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(2.7053e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.099450
Average KL loss: 0.159326
Average total loss: 0.258776
tensor(0.0120, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(3.4265e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.096596
Average KL loss: 0.159432
Average total loss: 0.256028
tensor(0.0120, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(3.3750e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.101556
Average KL loss: 0.159974
Average total loss: 0.261530
tensor(0.0120, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(4.9014e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.098486
Average KL loss: 0.160383
Average total loss: 0.258870
tensor(0.0120, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(1.8394e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.096134
Average KL loss: 0.160549
Average total loss: 0.256683
tensor(0.0120, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-2.1014e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.098127
Average KL loss: 0.160945
Average total loss: 0.259073
tensor(0.0119, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(4.6469e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.097192
Average KL loss: 0.161161
Average total loss: 0.258353
tensor(0.0119, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-1.1379e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.095487
Average KL loss: 0.161380
Average total loss: 0.256867
tensor(0.0119, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-3.2941e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.094509
Average KL loss: 0.161568
Average total loss: 0.256077
tensor(0.0119, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-6.6832e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.093077
Average KL loss: 0.161450
Average total loss: 0.254527
tensor(0.0119, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-3.1579e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.094166
Average KL loss: 0.160877
Average total loss: 0.255043
tensor(0.0119, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(3.0355e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.092605
Average KL loss: 0.160368
Average total loss: 0.252974
tensor(0.0119, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-1.2004e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.085377
Average KL loss: 0.159914
Average total loss: 0.245291
tensor(0.0119, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(2.5050e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.093047
Average KL loss: 0.159485
Average total loss: 0.252532
tensor(0.0119, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-2.9927e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.090367
Average KL loss: 0.159093
Average total loss: 0.249460
tensor(0.0119, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(3.6230e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.089402
Average KL loss: 0.158722
Average total loss: 0.248124
tensor(0.0119, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(9.0702e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.089039
Average KL loss: 0.158357
Average total loss: 0.247396
tensor(0.0119, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-5.6442e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.092626
Average KL loss: 0.158030
Average total loss: 0.250656
tensor(0.0119, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(7.7142e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.092955
Average KL loss: 0.157718
Average total loss: 0.250673
tensor(0.0119, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(4.6557e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.094264
Average KL loss: 0.157426
Average total loss: 0.251690
tensor(0.0119, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-7.0684e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.090829
Average KL loss: 0.157141
Average total loss: 0.247969
tensor(0.0119, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-9.7449e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.089009
Average KL loss: 0.156862
Average total loss: 0.245871
tensor(0.0119, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(7.4181e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.090252
Average KL loss: 0.156584
Average total loss: 0.246836
tensor(0.0119, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-3.2402e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.090712
Average KL loss: 0.156320
Average total loss: 0.247032
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(3.8875e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.088160
Average KL loss: 0.156167
Average total loss: 0.244328
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-4.0355e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.087896
Average KL loss: 0.156134
Average total loss: 0.244030
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.1434e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.089599
Average KL loss: 0.156101
Average total loss: 0.245699
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-2.0930e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.090788
Average KL loss: 0.156069
Average total loss: 0.246857
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(9.2760e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.090420
Average KL loss: 0.156038
Average total loss: 0.246458
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-5.4266e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.094766
Average KL loss: 0.156006
Average total loss: 0.250772
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(3.1495e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.089461
Average KL loss: 0.155975
Average total loss: 0.245436
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-5.1995e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.092673
Average KL loss: 0.155943
Average total loss: 0.248616
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(3.5227e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.089552
Average KL loss: 0.155912
Average total loss: 0.245463
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-4.5040e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.089057
Average KL loss: 0.155880
Average total loss: 0.244938
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-3.7706e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.088888
Average KL loss: 0.155849
Average total loss: 0.244737
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(1.9887e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.094032
Average KL loss: 0.155818
Average total loss: 0.249850
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(1.2195e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.087711
Average KL loss: 0.155788
Average total loss: 0.243499
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-4.2649e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.086896
Average KL loss: 0.155757
Average total loss: 0.242653
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.1275e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.091439
Average KL loss: 0.155727
Average total loss: 0.247166
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(1.5924e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.087637
Average KL loss: 0.155696
Average total loss: 0.243333
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.8546e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.094189
Average KL loss: 0.155665
Average total loss: 0.249853
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.1146e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.090257
Average KL loss: 0.155635
Average total loss: 0.245892
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-2.2313e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.090783
Average KL loss: 0.155603
Average total loss: 0.246387
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(3.2737e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.088797
Average KL loss: 0.155572
Average total loss: 0.244370
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-2.9237e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.088224
Average KL loss: 0.155541
Average total loss: 0.243765
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(1.0908e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.091092
Average KL loss: 0.155511
Average total loss: 0.246603
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(1.1734e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.093767
Average KL loss: 0.155482
Average total loss: 0.249249
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-4.3189e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.092088
Average KL loss: 0.155453
Average total loss: 0.247540
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-5.4209e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.091318
Average KL loss: 0.155424
Average total loss: 0.246742
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-3.4989e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.089033
Average KL loss: 0.155408
Average total loss: 0.244440
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(8.8063e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.091867
Average KL loss: 0.155404
Average total loss: 0.247272
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.1119e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.087925
Average KL loss: 0.155401
Average total loss: 0.243326
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-2.0923e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.093100
Average KL loss: 0.155398
Average total loss: 0.248499
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(1.1019e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.090044
Average KL loss: 0.155395
Average total loss: 0.245439
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(1.1699e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.091950
Average KL loss: 0.155392
Average total loss: 0.247342
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-5.5276e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.088688
Average KL loss: 0.155389
Average total loss: 0.244077
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(2.0190e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.089673
Average KL loss: 0.155386
Average total loss: 0.245059
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.5767e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.090413
Average KL loss: 0.155383
Average total loss: 0.245796
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-2.3499e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.091173
Average KL loss: 0.155380
Average total loss: 0.246553
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(4.7076e-09, device='cuda:0')
 Percentile value: -1.652419427955465e-07
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =     985 /    1728             ( 57.00%) | total_pruned =     743 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    3314 /   36864             (  8.99%) | total_pruned =   33550 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    3823 /   36864             ( 10.37%) | total_pruned =   33041 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3534 /   36864             (  9.59%) | total_pruned =   33330 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3578 /   36864             (  9.71%) | total_pruned =   33286 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    6315 /   73728             (  8.57%) | total_pruned =   67413 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   10794 /  147456             (  7.32%) | total_pruned =  136662 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2178 /    8192             ( 26.59%) | total_pruned =    6014 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   11621 /  147456             (  7.88%) | total_pruned =  135835 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   11343 /  147456             (  7.69%) | total_pruned =  136113 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   19869 /  294912             (  6.74%) | total_pruned =  275043 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   34266 /  589824             (  5.81%) | total_pruned =  555558 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5431 /   32768             ( 16.57%) | total_pruned =   27337 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   67449 /  589824             ( 11.44%) | total_pruned =  522375 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     205 /     256             ( 80.08%) | total_pruned =      51 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   65591 /  589824             ( 11.12%) | total_pruned =  524233 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   63789 / 1179648             (  5.41%) | total_pruned = 1115859 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  152529 / 2359296             (  6.47%) | total_pruned = 2206767 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   10733 /  131072             (  8.19%) | total_pruned =  120339 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     383 /     512             ( 74.80%) | total_pruned =     129 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  712341 / 2359296             ( 30.19%) | total_pruned = 1646955 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     310 /     512             ( 60.55%) | total_pruned =     202 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1140344 / 2359296             ( 48.33%) | total_pruned = 1218952 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     468 /     512             ( 91.41%) | total_pruned =      44 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      35 /     512             (  6.84%) | total_pruned =     477 | shape = torch.Size([512])
linear.weight        | nonzeros =    2280 /    5120             ( 44.53%) | total_pruned =    2840 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
Train Epoch: 23/100 Loss: 0.000475 Accuracy: 86.78 100.00 % Best test Accuracy: 87.01%
tensor(0.0119, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-2.0152e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.193512
Average KL loss: 0.145914
Average total loss: 0.339426
tensor(0.0139, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-9.9733e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.182136
Average KL loss: 0.146527
Average total loss: 0.328663
tensor(0.0139, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.6842e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.168005
Average KL loss: 0.149122
Average total loss: 0.317127
tensor(0.0138, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.0210e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.162646
Average KL loss: 0.151275
Average total loss: 0.313921
tensor(0.0137, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.4128e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.162884
Average KL loss: 0.153355
Average total loss: 0.316239
tensor(0.0137, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-1.0956e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.147720
Average KL loss: 0.155041
Average total loss: 0.302761
tensor(0.0136, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-1.3411e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.152322
Average KL loss: 0.156459
Average total loss: 0.308781
tensor(0.0136, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-2.2726e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.150005
Average KL loss: 0.157988
Average total loss: 0.307993
tensor(0.0136, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-8.3473e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.141745
Average KL loss: 0.159310
Average total loss: 0.301055
tensor(0.0135, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-1.0577e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.140745
Average KL loss: 0.160324
Average total loss: 0.301069
tensor(0.0135, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(8.6652e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.136314
Average KL loss: 0.161271
Average total loss: 0.297584
tensor(0.0134, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-4.4092e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.136345
Average KL loss: 0.162240
Average total loss: 0.298586
tensor(0.0134, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-6.0835e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.133293
Average KL loss: 0.163026
Average total loss: 0.296319
tensor(0.0134, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(1.0282e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.136832
Average KL loss: 0.163834
Average total loss: 0.300666
tensor(0.0134, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(2.2169e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.131830
Average KL loss: 0.164542
Average total loss: 0.296372
tensor(0.0133, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(1.1849e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.122054
Average KL loss: 0.165199
Average total loss: 0.287253
tensor(0.0133, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(2.6593e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.126130
Average KL loss: 0.165651
Average total loss: 0.291781
tensor(0.0133, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-3.6569e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.121677
Average KL loss: 0.166336
Average total loss: 0.288013
tensor(0.0132, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-4.7122e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.120338
Average KL loss: 0.166790
Average total loss: 0.287128
tensor(0.0132, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(3.7210e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.127633
Average KL loss: 0.167507
Average total loss: 0.295140
tensor(0.0132, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(1.1148e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.124469
Average KL loss: 0.168074
Average total loss: 0.292543
tensor(0.0132, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-1.6099e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.117119
Average KL loss: 0.168594
Average total loss: 0.285713
tensor(0.0132, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(1.1827e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.115286
Average KL loss: 0.168966
Average total loss: 0.284252
tensor(0.0131, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-2.1761e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.115618
Average KL loss: 0.169218
Average total loss: 0.284836
tensor(0.0131, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-8.2801e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.112454
Average KL loss: 0.169696
Average total loss: 0.282151
tensor(0.0131, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(1.9695e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.115877
Average KL loss: 0.170007
Average total loss: 0.285884
tensor(0.0131, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(1.1541e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.120508
Average KL loss: 0.170645
Average total loss: 0.291153
tensor(0.0131, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.8463e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.113331
Average KL loss: 0.171417
Average total loss: 0.284748
tensor(0.0131, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-1.1078e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.112891
Average KL loss: 0.171797
Average total loss: 0.284689
tensor(0.0131, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(4.3719e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.115526
Average KL loss: 0.172013
Average total loss: 0.287540
tensor(0.0130, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-1.4578e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.108301
Average KL loss: 0.172457
Average total loss: 0.280758
tensor(0.0130, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-6.0207e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.109659
Average KL loss: 0.172606
Average total loss: 0.282265
tensor(0.0130, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-7.1402e-11, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.109500
Average KL loss: 0.172815
Average total loss: 0.282315
tensor(0.0130, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.0878e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.108916
Average KL loss: 0.173068
Average total loss: 0.281985
tensor(0.0130, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-3.1025e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.105438
Average KL loss: 0.173337
Average total loss: 0.278776
tensor(0.0130, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(5.6763e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.103233
Average KL loss: 0.173300
Average total loss: 0.276533
tensor(0.0129, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-8.2425e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.108289
Average KL loss: 0.173553
Average total loss: 0.281842
tensor(0.0129, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-6.4952e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.109101
Average KL loss: 0.173804
Average total loss: 0.282905
tensor(0.0129, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(2.6808e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.103314
Average KL loss: 0.174232
Average total loss: 0.277546
tensor(0.0129, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(4.8273e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.101711
Average KL loss: 0.174214
Average total loss: 0.275925
tensor(0.0129, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(8.0940e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.104358
Average KL loss: 0.174377
Average total loss: 0.278735
tensor(0.0129, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(7.2608e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.103803
Average KL loss: 0.174563
Average total loss: 0.278366
tensor(0.0129, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.0142e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.104118
Average KL loss: 0.174888
Average total loss: 0.279006
tensor(0.0129, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.2703e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.102703
Average KL loss: 0.175185
Average total loss: 0.277888
tensor(0.0128, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.4566e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.100188
Average KL loss: 0.175347
Average total loss: 0.275535
tensor(0.0128, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(1.9666e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.098787
Average KL loss: 0.175416
Average total loss: 0.274203
tensor(0.0128, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-1.0943e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.101028
Average KL loss: 0.175465
Average total loss: 0.276493
tensor(0.0128, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(2.2548e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.101239
Average KL loss: 0.175618
Average total loss: 0.276857
tensor(0.0128, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-2.3100e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.097809
Average KL loss: 0.175853
Average total loss: 0.273662
tensor(0.0128, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-1.1258e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.096192
Average KL loss: 0.175939
Average total loss: 0.272131
tensor(0.0128, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(7.9448e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.099921
Average KL loss: 0.175870
Average total loss: 0.275791
tensor(0.0128, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(1.2533e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.094304
Average KL loss: 0.175884
Average total loss: 0.270188
tensor(0.0127, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(3.4203e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.098099
Average KL loss: 0.175873
Average total loss: 0.273973
tensor(0.0127, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-1.1142e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.099825
Average KL loss: 0.176082
Average total loss: 0.275907
tensor(0.0127, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(4.0022e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.093781
Average KL loss: 0.176314
Average total loss: 0.270095
tensor(0.0127, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-1.4762e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.098717
Average KL loss: 0.176334
Average total loss: 0.275051
tensor(0.0127, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-4.4871e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.093060
Average KL loss: 0.176537
Average total loss: 0.269597
tensor(0.0127, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-7.4108e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.094113
Average KL loss: 0.176490
Average total loss: 0.270603
tensor(0.0127, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(1.6486e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.096767
Average KL loss: 0.176491
Average total loss: 0.273258
tensor(0.0127, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-4.1389e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.096054
Average KL loss: 0.176699
Average total loss: 0.272753
tensor(0.0127, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-7.2839e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.094613
Average KL loss: 0.176800
Average total loss: 0.271413
tensor(0.0127, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(1.9868e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.093558
Average KL loss: 0.176964
Average total loss: 0.270522
tensor(0.0126, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-4.4733e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.094329
Average KL loss: 0.176877
Average total loss: 0.271206
tensor(0.0126, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(3.3897e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.090773
Average KL loss: 0.176898
Average total loss: 0.267671
tensor(0.0126, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-5.2492e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.097280
Average KL loss: 0.177069
Average total loss: 0.274349
tensor(0.0126, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(1.5702e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.091557
Average KL loss: 0.177154
Average total loss: 0.268711
tensor(0.0126, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-1.1998e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.094134
Average KL loss: 0.177331
Average total loss: 0.271464
tensor(0.0126, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-1.3780e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.087638
Average KL loss: 0.177424
Average total loss: 0.265062
tensor(0.0126, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(3.0094e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.092534
Average KL loss: 0.177165
Average total loss: 0.269698
tensor(0.0126, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(3.3416e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.091578
Average KL loss: 0.177216
Average total loss: 0.268793
tensor(0.0126, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-5.2613e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.091424
Average KL loss: 0.177303
Average total loss: 0.268727
tensor(0.0126, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(2.8263e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.093086
Average KL loss: 0.177380
Average total loss: 0.270466
tensor(0.0126, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-9.1753e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.091530
Average KL loss: 0.177499
Average total loss: 0.269029
tensor(0.0126, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.3338e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.090590
Average KL loss: 0.177432
Average total loss: 0.268022
tensor(0.0125, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(1.5262e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.091864
Average KL loss: 0.177341
Average total loss: 0.269205
tensor(0.0125, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.1789e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.092839
Average KL loss: 0.177460
Average total loss: 0.270299
tensor(0.0125, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-3.7484e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.092284
Average KL loss: 0.177731
Average total loss: 0.270015
tensor(0.0125, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-2.5113e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.088838
Average KL loss: 0.177957
Average total loss: 0.266795
tensor(0.0125, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-3.8088e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.090616
Average KL loss: 0.177930
Average total loss: 0.268546
tensor(0.0125, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(3.3449e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.086774
Average KL loss: 0.177792
Average total loss: 0.264566
tensor(0.0125, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(1.6792e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.086752
Average KL loss: 0.177381
Average total loss: 0.264133
tensor(0.0125, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(1.2593e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.085791
Average KL loss: 0.176994
Average total loss: 0.262785
tensor(0.0125, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.2701e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.089600
Average KL loss: 0.176654
Average total loss: 0.266254
tensor(0.0125, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-6.1848e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.088895
Average KL loss: 0.176354
Average total loss: 0.265249
tensor(0.0125, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-3.5227e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.088856
Average KL loss: 0.176057
Average total loss: 0.264913
tensor(0.0125, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-2.1776e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.090379
Average KL loss: 0.175785
Average total loss: 0.266164
tensor(0.0125, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(6.2924e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.091113
Average KL loss: 0.175526
Average total loss: 0.266639
tensor(0.0125, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(1.2372e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.087058
Average KL loss: 0.175270
Average total loss: 0.262328
tensor(0.0125, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(1.8994e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.086811
Average KL loss: 0.175012
Average total loss: 0.261823
tensor(0.0125, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-5.1219e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.088229
Average KL loss: 0.174768
Average total loss: 0.262996
tensor(0.0125, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-5.3866e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.088615
Average KL loss: 0.174534
Average total loss: 0.263149
tensor(0.0125, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(3.4841e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.088136
Average KL loss: 0.174313
Average total loss: 0.262449
tensor(0.0125, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(1.3978e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.084790
Average KL loss: 0.174092
Average total loss: 0.258882
tensor(0.0125, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.1048e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.087473
Average KL loss: 0.173870
Average total loss: 0.261343
tensor(0.0125, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(2.4277e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.086409
Average KL loss: 0.173661
Average total loss: 0.260070
tensor(0.0125, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(3.0765e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.085386
Average KL loss: 0.173450
Average total loss: 0.258836
tensor(0.0125, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.3174e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.087543
Average KL loss: 0.173244
Average total loss: 0.260787
tensor(0.0125, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-5.0858e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.087310
Average KL loss: 0.173046
Average total loss: 0.260356
tensor(0.0125, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-3.3799e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.085411
Average KL loss: 0.172855
Average total loss: 0.258266
tensor(0.0125, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-4.3058e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.085285
Average KL loss: 0.172668
Average total loss: 0.257954
tensor(0.0125, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(3.6244e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.084278
Average KL loss: 0.172482
Average total loss: 0.256760
tensor(0.0125, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(2.4886e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.087233
Average KL loss: 0.172306
Average total loss: 0.259539
tensor(0.0125, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(4.0655e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.081306
Average KL loss: 0.172125
Average total loss: 0.253431
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.0569e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.088178
Average KL loss: 0.171953
Average total loss: 0.260131
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(6.1823e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.085810
Average KL loss: 0.171790
Average total loss: 0.257601
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(4.1895e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.089416
Average KL loss: 0.171624
Average total loss: 0.261040
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.1411e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.089838
Average KL loss: 0.171477
Average total loss: 0.261315
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-3.0858e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.088297
Average KL loss: 0.171335
Average total loss: 0.259632
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-6.4395e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.087834
Average KL loss: 0.171191
Average total loss: 0.259025
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.5271e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.086452
Average KL loss: 0.171038
Average total loss: 0.257489
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-3.7760e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.087049
Average KL loss: 0.170895
Average total loss: 0.257945
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-5.1281e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.085138
Average KL loss: 0.170742
Average total loss: 0.255880
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-8.6944e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.089214
Average KL loss: 0.170594
Average total loss: 0.259808
tensor(0.0125, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(2.4850e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.085098
Average KL loss: 0.170460
Average total loss: 0.255558
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-4.3097e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.088149
Average KL loss: 0.170377
Average total loss: 0.258526
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-7.0362e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.088522
Average KL loss: 0.170358
Average total loss: 0.258880
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-3.0975e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.084985
Average KL loss: 0.170339
Average total loss: 0.255325
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(4.9282e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.089473
Average KL loss: 0.170321
Average total loss: 0.259794
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(1.8224e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.086372
Average KL loss: 0.170302
Average total loss: 0.256674
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(1.4307e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.086462
Average KL loss: 0.170284
Average total loss: 0.256746
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-4.1754e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.088132
Average KL loss: 0.170265
Average total loss: 0.258397
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(3.7371e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.087186
Average KL loss: 0.170248
Average total loss: 0.257433
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-5.0444e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.088679
Average KL loss: 0.170230
Average total loss: 0.258909
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(2.3286e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.085270
Average KL loss: 0.170211
Average total loss: 0.255481
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-6.4874e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.090785
Average KL loss: 0.170194
Average total loss: 0.260979
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.9317e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.087088
Average KL loss: 0.170185
Average total loss: 0.257272
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-2.3078e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.088562
Average KL loss: 0.170183
Average total loss: 0.258745
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(5.1477e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.084172
Average KL loss: 0.170181
Average total loss: 0.254353
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-6.0457e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.088821
Average KL loss: 0.170179
Average total loss: 0.259000
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(2.6228e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.086359
Average KL loss: 0.170177
Average total loss: 0.256536
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-9.3088e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.084475
Average KL loss: 0.170176
Average total loss: 0.254651
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-5.5842e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.086957
Average KL loss: 0.170174
Average total loss: 0.257131
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(1.2257e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.089826
Average KL loss: 0.170172
Average total loss: 0.259998
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(8.8737e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.089000
Average KL loss: 0.170170
Average total loss: 0.259170
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(4.0590e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.088233
Average KL loss: 0.170168
Average total loss: 0.258401
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(6.5842e-09, device='cuda:0')
 Percentile value: -1.6522768930826714e-07
Non-zero model percentage: 16.777233123779297%, Non-zero mask percentage: 16.777233123779297%

--- Pruning Level [8/24]: ---
conv1.weight         | nonzeros =     959 /    1728             ( 55.50%) | total_pruned =     769 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2778 /   36864             (  7.54%) | total_pruned =   34086 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    3265 /   36864             (  8.86%) | total_pruned =   33599 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3004 /   36864             (  8.15%) | total_pruned =   33860 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3053 /   36864             (  8.28%) | total_pruned =   33811 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    5260 /   73728             (  7.13%) | total_pruned =   68468 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    8811 /  147456             (  5.98%) | total_pruned =  138645 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2035 /    8192             ( 24.84%) | total_pruned =    6157 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    9544 /  147456             (  6.47%) | total_pruned =  137912 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    9332 /  147456             (  6.33%) | total_pruned =  138124 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   16016 /  294912             (  5.43%) | total_pruned =  278896 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   26282 /  589824             (  4.46%) | total_pruned =  563542 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4836 /   32768             ( 14.76%) | total_pruned =   27932 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   57443 /  589824             (  9.74%) | total_pruned =  532381 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     188 /     256             ( 73.44%) | total_pruned =      68 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   55680 /  589824             (  9.44%) | total_pruned =  534144 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   47175 / 1179648             (  4.00%) | total_pruned = 1132473 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     448 /     512             ( 87.50%) | total_pruned =      64 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     485 /     512             ( 94.73%) | total_pruned =      27 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   97609 / 2359296             (  4.14%) | total_pruned = 2261687 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     459 /     512             ( 89.65%) | total_pruned =      53 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     371 /     512             ( 72.46%) | total_pruned =     141 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9017 /  131072             (  6.88%) | total_pruned =  122055 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     478 /     512             ( 93.36%) | total_pruned =      34 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  623196 / 2359296             ( 26.41%) | total_pruned = 1736100 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     429 /     512             ( 83.79%) | total_pruned =      83 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     290 /     512             ( 56.64%) | total_pruned =     222 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  876660 / 2359296             ( 37.16%) | total_pruned = 1482636 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     440 /     512             ( 85.94%) | total_pruned =      72 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
linear.weight        | nonzeros =    2094 /    5120             ( 40.90%) | total_pruned =    3026 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 1875487, pruned : 9303275, total: 11178762, Compression rate :       5.96x  ( 83.22% pruned)
Train Epoch: 21/100 Loss: 0.000292 Accuracy: 86.40 100.00 % Best test Accuracy: 87.08%
tensor(0.0125, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.9676e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.189282
Average KL loss: 0.162040
Average total loss: 0.351322
tensor(0.0137, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-7.7351e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.183532
Average KL loss: 0.161856
Average total loss: 0.345388
tensor(0.0138, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.1979e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.172160
Average KL loss: 0.163852
Average total loss: 0.336012
tensor(0.0138, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.8958e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.171362
Average KL loss: 0.165904
Average total loss: 0.337266
tensor(0.0137, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.1538e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.161554
Average KL loss: 0.167794
Average total loss: 0.329348
tensor(0.0137, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.8961e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.156131
Average KL loss: 0.169431
Average total loss: 0.325562
tensor(0.0137, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-6.6153e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.150093
Average KL loss: 0.170829
Average total loss: 0.320923
tensor(0.0137, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-7.4075e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.142659
Average KL loss: 0.172075
Average total loss: 0.314734
tensor(0.0137, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-6.3128e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.151699
Average KL loss: 0.173346
Average total loss: 0.325046
tensor(0.0137, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(9.1976e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.143019
Average KL loss: 0.174543
Average total loss: 0.317562
tensor(0.0137, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-6.2737e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.144467
Average KL loss: 0.175557
Average total loss: 0.320024
tensor(0.0137, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.8331e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.135684
Average KL loss: 0.176485
Average total loss: 0.312168
tensor(0.0137, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(2.9287e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.129364
Average KL loss: 0.177209
Average total loss: 0.306574
tensor(0.0137, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-8.9830e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.127422
Average KL loss: 0.177879
Average total loss: 0.305301
tensor(0.0137, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(3.2336e-11, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.132929
Average KL loss: 0.178506
Average total loss: 0.311435
tensor(0.0137, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(6.4059e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.126968
Average KL loss: 0.179267
Average total loss: 0.306234
tensor(0.0137, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-2.7080e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.136826
Average KL loss: 0.180153
Average total loss: 0.316979
tensor(0.0137, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(2.4852e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.124782
Average KL loss: 0.181005
Average total loss: 0.305787
tensor(0.0137, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(7.5664e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.125999
Average KL loss: 0.181502
Average total loss: 0.307501
tensor(0.0137, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-3.5978e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.121789
Average KL loss: 0.182016
Average total loss: 0.303805
tensor(0.0137, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-5.2708e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.130345
Average KL loss: 0.182480
Average total loss: 0.312824
tensor(0.0137, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(2.3283e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.115608
Average KL loss: 0.183113
Average total loss: 0.298721
tensor(0.0137, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-5.8700e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.113720
Average KL loss: 0.183232
Average total loss: 0.296953
tensor(0.0136, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(1.8744e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.119318
Average KL loss: 0.183543
Average total loss: 0.302862
tensor(0.0136, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-5.4113e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.116516
Average KL loss: 0.184018
Average total loss: 0.300534
tensor(0.0136, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.0570e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.118906
Average KL loss: 0.184436
Average total loss: 0.303342
tensor(0.0136, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-9.2490e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.117200
Average KL loss: 0.184693
Average total loss: 0.301893
tensor(0.0136, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-6.2027e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.112806
Average KL loss: 0.184869
Average total loss: 0.297675
tensor(0.0136, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-8.0973e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.112323
Average KL loss: 0.185102
Average total loss: 0.297425
tensor(0.0136, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(1.0450e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.110800
Average KL loss: 0.185311
Average total loss: 0.296111
tensor(0.0136, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-7.8265e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.114236
Average KL loss: 0.185607
Average total loss: 0.299842
tensor(0.0135, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-8.2341e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.115606
Average KL loss: 0.185941
Average total loss: 0.301547
tensor(0.0135, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(9.1215e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.106679
Average KL loss: 0.186270
Average total loss: 0.292948
tensor(0.0135, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-9.2411e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.110689
Average KL loss: 0.186423
Average total loss: 0.297112
tensor(0.0135, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-8.3877e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.114023
Average KL loss: 0.186802
Average total loss: 0.300826
tensor(0.0135, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(2.8901e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.104775
Average KL loss: 0.187164
Average total loss: 0.291939
tensor(0.0135, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-6.3294e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.104588
Average KL loss: 0.187273
Average total loss: 0.291861
tensor(0.0135, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-5.2860e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.109776
Average KL loss: 0.187430
Average total loss: 0.297205
tensor(0.0135, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-1.4040e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.103710
Average KL loss: 0.187698
Average total loss: 0.291408
tensor(0.0135, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-2.5915e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.106980
Average KL loss: 0.187844
Average total loss: 0.294824
tensor(0.0135, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-2.9393e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.104520
Average KL loss: 0.188001
Average total loss: 0.292521
tensor(0.0135, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-3.0869e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.104177
Average KL loss: 0.188173
Average total loss: 0.292349
tensor(0.0135, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(1.9378e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.106974
Average KL loss: 0.188438
Average total loss: 0.295413
tensor(0.0135, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-3.1398e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.105043
Average KL loss: 0.188792
Average total loss: 0.293836
tensor(0.0135, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-5.5175e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.102363
Average KL loss: 0.188944
Average total loss: 0.291307
tensor(0.0135, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-4.8288e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.102786
Average KL loss: 0.189057
Average total loss: 0.291844
tensor(0.0135, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-8.3535e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.104754
Average KL loss: 0.189134
Average total loss: 0.293888
tensor(0.0134, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-5.6548e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.105914
Average KL loss: 0.189340
Average total loss: 0.295254
tensor(0.0134, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(4.2769e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.104055
Average KL loss: 0.189560
Average total loss: 0.293615
tensor(0.0134, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(3.2485e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.100999
Average KL loss: 0.189658
Average total loss: 0.290658
tensor(0.0134, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-4.6845e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.096706
Average KL loss: 0.189845
Average total loss: 0.286551
tensor(0.0134, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(8.4090e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.100807
Average KL loss: 0.189862
Average total loss: 0.290669
tensor(0.0134, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-5.7989e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.099240
Average KL loss: 0.190019
Average total loss: 0.289259
tensor(0.0134, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-4.8447e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.098686
Average KL loss: 0.190017
Average total loss: 0.288702
tensor(0.0134, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.3679e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.098408
Average KL loss: 0.190097
Average total loss: 0.288506
tensor(0.0134, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.5585e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.098999
Average KL loss: 0.190090
Average total loss: 0.289089
tensor(0.0134, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-7.4948e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.101748
Average KL loss: 0.190290
Average total loss: 0.292038
tensor(0.0134, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-5.9202e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.100038
Average KL loss: 0.190518
Average total loss: 0.290556
tensor(0.0134, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-2.2500e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.097893
Average KL loss: 0.190806
Average total loss: 0.288699
tensor(0.0134, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-2.3503e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.097580
Average KL loss: 0.190909
Average total loss: 0.288490
tensor(0.0134, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(6.3276e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.096232
Average KL loss: 0.190998
Average total loss: 0.287230
tensor(0.0134, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(2.6755e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.098166
Average KL loss: 0.190917
Average total loss: 0.289083
tensor(0.0134, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(5.7123e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.095811
Average KL loss: 0.190881
Average total loss: 0.286691
tensor(0.0134, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-3.0992e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.100305
Average KL loss: 0.190660
Average total loss: 0.290965
tensor(0.0134, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.4120e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.094483
Average KL loss: 0.190449
Average total loss: 0.284932
tensor(0.0133, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(3.7221e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.093915
Average KL loss: 0.190249
Average total loss: 0.284164
tensor(0.0133, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-3.1168e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.093382
Average KL loss: 0.190055
Average total loss: 0.283437
tensor(0.0133, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(1.7899e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.093055
Average KL loss: 0.189865
Average total loss: 0.282920
tensor(0.0133, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-6.9374e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.097052
Average KL loss: 0.189683
Average total loss: 0.286735
tensor(0.0133, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-7.2437e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.094117
Average KL loss: 0.189513
Average total loss: 0.283630
tensor(0.0133, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(1.8830e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.093017
Average KL loss: 0.189339
Average total loss: 0.282356
tensor(0.0133, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-3.5868e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.094349
Average KL loss: 0.189170
Average total loss: 0.283519
tensor(0.0133, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-5.1391e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.098342
Average KL loss: 0.189008
Average total loss: 0.287350
tensor(0.0133, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(8.9962e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.093341
Average KL loss: 0.188862
Average total loss: 0.282203
tensor(0.0133, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-3.7958e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.095481
Average KL loss: 0.188708
Average total loss: 0.284189
tensor(0.0133, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(1.4443e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.095338
Average KL loss: 0.188565
Average total loss: 0.283902
tensor(0.0133, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-4.5047e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.094328
Average KL loss: 0.188416
Average total loss: 0.282744
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-2.6014e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.090657
Average KL loss: 0.188258
Average total loss: 0.278916
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-9.5495e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.095573
Average KL loss: 0.188119
Average total loss: 0.283692
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(2.9122e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.098834
Average KL loss: 0.188005
Average total loss: 0.286839
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(5.3182e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.095006
Average KL loss: 0.187885
Average total loss: 0.282891
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(1.0455e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.092004
Average KL loss: 0.187744
Average total loss: 0.279748
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(2.3750e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.089841
Average KL loss: 0.187604
Average total loss: 0.277445
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(4.3250e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.091040
Average KL loss: 0.187468
Average total loss: 0.278507
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(1.4083e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.091856
Average KL loss: 0.187338
Average total loss: 0.279194
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(1.0816e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.095558
Average KL loss: 0.187222
Average total loss: 0.282780
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-6.3432e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.093451
Average KL loss: 0.187094
Average total loss: 0.280545
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(3.4561e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.094168
Average KL loss: 0.186972
Average total loss: 0.281139
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-4.1969e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.095294
Average KL loss: 0.186861
Average total loss: 0.282155
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.0502e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.094994
Average KL loss: 0.186746
Average total loss: 0.281740
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.8805e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.094628
Average KL loss: 0.186641
Average total loss: 0.281269
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.6053e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.093006
Average KL loss: 0.186531
Average total loss: 0.279537
tensor(0.0133, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-6.2742e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.093775
Average KL loss: 0.186418
Average total loss: 0.280192
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.1922e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.094192
Average KL loss: 0.186306
Average total loss: 0.280497
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(7.6275e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.091538
Average KL loss: 0.186238
Average total loss: 0.277776
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.9366e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.092122
Average KL loss: 0.186224
Average total loss: 0.278346
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-5.4742e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.093822
Average KL loss: 0.186210
Average total loss: 0.280033
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.1230e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.094550
Average KL loss: 0.186197
Average total loss: 0.280747
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(2.3888e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.094804
Average KL loss: 0.186183
Average total loss: 0.280987
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(3.8255e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.090195
Average KL loss: 0.186169
Average total loss: 0.276364
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(1.8052e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.093347
Average KL loss: 0.186155
Average total loss: 0.279503
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(1.8518e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.095611
Average KL loss: 0.186143
Average total loss: 0.281755
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.9617e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.092931
Average KL loss: 0.186131
Average total loss: 0.279062
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.6958e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.091514
Average KL loss: 0.186118
Average total loss: 0.277632
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(3.5296e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.092450
Average KL loss: 0.186104
Average total loss: 0.278554
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.6513e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.095169
Average KL loss: 0.186090
Average total loss: 0.281259
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-7.1565e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.090247
Average KL loss: 0.186078
Average total loss: 0.276325
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(1.3308e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.093707
Average KL loss: 0.186064
Average total loss: 0.279771
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.1076e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.089096
Average KL loss: 0.186052
Average total loss: 0.275148
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-2.0039e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.095380
Average KL loss: 0.186038
Average total loss: 0.281418
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(3.2632e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.090382
Average KL loss: 0.186026
Average total loss: 0.276407
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-6.5529e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.094982
Average KL loss: 0.186013
Average total loss: 0.280995
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(2.5557e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.094565
Average KL loss: 0.186000
Average total loss: 0.280565
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-2.4874e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.093471
Average KL loss: 0.185987
Average total loss: 0.279458
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-5.4012e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.092797
Average KL loss: 0.185975
Average total loss: 0.278771
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(7.8872e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.099301
Average KL loss: 0.185962
Average total loss: 0.285264
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.6033e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.092071
Average KL loss: 0.185950
Average total loss: 0.278021
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-8.5237e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.091400
Average KL loss: 0.185937
Average total loss: 0.277337
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(7.7397e-14, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.092242
Average KL loss: 0.185924
Average total loss: 0.278165
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(6.5566e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.091772
Average KL loss: 0.185910
Average total loss: 0.277683
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.8408e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.094955
Average KL loss: 0.185903
Average total loss: 0.280858
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(1.6300e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.092875
Average KL loss: 0.185902
Average total loss: 0.278777
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.4423e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.089590
Average KL loss: 0.185900
Average total loss: 0.275490
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-2.6402e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.093276
Average KL loss: 0.185899
Average total loss: 0.279174
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(3.0397e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.091983
Average KL loss: 0.185897
Average total loss: 0.277881
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-7.0377e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.089091
Average KL loss: 0.185896
Average total loss: 0.274987
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(1.0370e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.092059
Average KL loss: 0.185895
Average total loss: 0.277954
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-4.4108e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.092980
Average KL loss: 0.185894
Average total loss: 0.278874
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(6.1376e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.092348
Average KL loss: 0.185892
Average total loss: 0.278241
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-7.1812e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.090387
Average KL loss: 0.185891
Average total loss: 0.276278
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-2.2670e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.092294
Average KL loss: 0.185890
Average total loss: 0.278184
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(1.7743e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.089225
Average KL loss: 0.185888
Average total loss: 0.275113
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(3.0410e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.093507
Average KL loss: 0.185887
Average total loss: 0.279394
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(3.0860e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.090611
Average KL loss: 0.185886
Average total loss: 0.276496
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(1.2612e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.094385
Average KL loss: 0.185884
Average total loss: 0.280269
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(4.1052e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.090204
Average KL loss: 0.185883
Average total loss: 0.276087
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(8.2968e-10, device='cuda:0')
 Percentile value: -1.6522973567134613e-07
Non-zero model percentage: 13.42179012298584%, Non-zero mask percentage: 13.42179012298584%

--- Pruning Level [9/24]: ---
conv1.weight         | nonzeros =     933 /    1728             ( 53.99%) | total_pruned =     795 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2437 /   36864             (  6.61%) | total_pruned =   34427 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2903 /   36864             (  7.87%) | total_pruned =   33961 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2639 /   36864             (  7.16%) | total_pruned =   34225 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2702 /   36864             (  7.33%) | total_pruned =   34162 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4631 /   73728             (  6.28%) | total_pruned =   69097 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    7541 /  147456             (  5.11%) | total_pruned =  139915 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1904 /    8192             ( 23.24%) | total_pruned =    6288 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    7912 /  147456             (  5.37%) | total_pruned =  139544 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    7731 /  147456             (  5.24%) | total_pruned =  139725 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   13544 /  294912             (  4.59%) | total_pruned =  281368 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     200 /     256             ( 78.12%) | total_pruned =      56 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   21567 /  589824             (  3.66%) | total_pruned =  568257 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     147 /     256             ( 57.42%) | total_pruned =     109 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4423 /   32768             ( 13.50%) | total_pruned =   28345 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   47325 /  589824             (  8.02%) | total_pruned =  542499 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     182 /     256             ( 71.09%) | total_pruned =      74 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   45584 /  589824             (  7.73%) | total_pruned =  544240 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     200 /     256             ( 78.12%) | total_pruned =      56 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   36999 / 1179648             (  3.14%) | total_pruned = 1142649 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     388 /     512             ( 75.78%) | total_pruned =     124 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     479 /     512             ( 93.55%) | total_pruned =      33 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   67098 / 2359296             (  2.84%) | total_pruned = 2292198 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     411 /     512             ( 80.27%) | total_pruned =     101 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     359 /     512             ( 70.12%) | total_pruned =     153 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    7667 /  131072             (  5.85%) | total_pruned =  123405 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     428 /     512             ( 83.59%) | total_pruned =      84 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     486 /     512             ( 94.92%) | total_pruned =      26 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     369 /     512             ( 72.07%) | total_pruned =     143 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  517458 / 2359296             ( 21.93%) | total_pruned = 1841838 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     370 /     512             ( 72.27%) | total_pruned =     142 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     260 /     512             ( 50.78%) | total_pruned =     252 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  684725 / 2359296             ( 29.02%) | total_pruned = 1674571 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     330 /     512             ( 64.45%) | total_pruned =     182 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     422 /     512             ( 82.42%) | total_pruned =      90 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      28 /     512             (  5.47%) | total_pruned =     484 | shape = torch.Size([512])
linear.weight        | nonzeros =    1939 /    5120             ( 37.87%) | total_pruned =    3181 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 1500390, pruned : 9678372, total: 11178762, Compression rate :       7.45x  ( 86.58% pruned)
Train Epoch: 22/100 Loss: 0.000365 Accuracy: 86.23 100.00 % Best test Accuracy: 86.80%
tensor(0.0133, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-9.9813e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.176652
Average KL loss: 0.178161
Average total loss: 0.354813
tensor(0.0141, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-9.3812e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.171387
Average KL loss: 0.177269
Average total loss: 0.348657
tensor(0.0141, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-1.9211e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.167627
Average KL loss: 0.178665
Average total loss: 0.346293
tensor(0.0141, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(9.2720e-11, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.155061
Average KL loss: 0.180145
Average total loss: 0.335206
tensor(0.0141, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.1992e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.154199
Average KL loss: 0.181530
Average total loss: 0.335729
tensor(0.0141, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.0304e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.151023
Average KL loss: 0.182866
Average total loss: 0.333890
tensor(0.0141, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-5.5190e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.145499
Average KL loss: 0.184050
Average total loss: 0.329550
tensor(0.0141, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.1872e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.144058
Average KL loss: 0.185148
Average total loss: 0.329206
tensor(0.0141, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-9.3280e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.141270
Average KL loss: 0.186246
Average total loss: 0.327517
tensor(0.0142, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.0479e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.139727
Average KL loss: 0.187244
Average total loss: 0.326971
tensor(0.0142, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-4.3355e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.137665
Average KL loss: 0.188159
Average total loss: 0.325825
tensor(0.0142, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-6.9939e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.133592
Average KL loss: 0.188951
Average total loss: 0.322543
tensor(0.0142, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(6.9227e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.126769
Average KL loss: 0.189683
Average total loss: 0.316452
tensor(0.0142, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-6.5826e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.132533
Average KL loss: 0.190308
Average total loss: 0.322841
tensor(0.0142, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-1.1059e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.123955
Average KL loss: 0.190871
Average total loss: 0.314825
tensor(0.0142, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-7.9930e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.127067
Average KL loss: 0.191456
Average total loss: 0.318523
tensor(0.0142, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-5.5448e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.125921
Average KL loss: 0.192056
Average total loss: 0.317977
tensor(0.0142, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-5.6038e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.117629
Average KL loss: 0.192622
Average total loss: 0.310251
tensor(0.0142, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-7.9031e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.121863
Average KL loss: 0.192991
Average total loss: 0.314853
tensor(0.0142, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(2.0268e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.117233
Average KL loss: 0.193324
Average total loss: 0.310557
tensor(0.0141, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.7177e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.122188
Average KL loss: 0.193891
Average total loss: 0.316079
tensor(0.0142, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.5202e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.122050
Average KL loss: 0.194408
Average total loss: 0.316457
tensor(0.0141, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(4.9432e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.119267
Average KL loss: 0.194842
Average total loss: 0.314109
tensor(0.0141, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-2.1279e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.113716
Average KL loss: 0.195221
Average total loss: 0.308936
tensor(0.0141, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-6.3189e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.113954
Average KL loss: 0.195543
Average total loss: 0.309497
tensor(0.0141, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-6.5677e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.112084
Average KL loss: 0.195832
Average total loss: 0.307916
tensor(0.0141, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-3.5534e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.113549
Average KL loss: 0.196129
Average total loss: 0.309678
tensor(0.0141, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(3.7281e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.115450
Average KL loss: 0.196477
Average total loss: 0.311927
tensor(0.0141, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(4.5923e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.114690
Average KL loss: 0.196839
Average total loss: 0.311529
tensor(0.0141, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-2.3017e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.109066
Average KL loss: 0.197123
Average total loss: 0.306189
tensor(0.0141, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-9.0308e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.107249
Average KL loss: 0.197259
Average total loss: 0.304508
tensor(0.0141, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-7.4000e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.111077
Average KL loss: 0.197543
Average total loss: 0.308619
tensor(0.0141, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-1.3454e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.113449
Average KL loss: 0.197874
Average total loss: 0.311323
tensor(0.0141, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(1.3234e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.108856
Average KL loss: 0.198220
Average total loss: 0.307077
tensor(0.0141, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.1562e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.107043
Average KL loss: 0.198450
Average total loss: 0.305493
tensor(0.0141, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-7.2885e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.103948
Average KL loss: 0.198536
Average total loss: 0.302484
tensor(0.0141, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.0935e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.104312
Average KL loss: 0.198733
Average total loss: 0.303044
tensor(0.0141, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-6.6221e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.102414
Average KL loss: 0.198863
Average total loss: 0.301277
tensor(0.0141, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-1.8504e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.103215
Average KL loss: 0.199021
Average total loss: 0.302235
tensor(0.0141, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-5.9042e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.102635
Average KL loss: 0.199114
Average total loss: 0.301749
tensor(0.0141, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.2629e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.111177
Average KL loss: 0.199277
Average total loss: 0.310453
tensor(0.0141, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-7.7627e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.105739
Average KL loss: 0.199552
Average total loss: 0.305291
tensor(0.0141, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-1.0062e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.097148
Average KL loss: 0.199767
Average total loss: 0.296915
tensor(0.0141, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-1.1553e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.101853
Average KL loss: 0.199832
Average total loss: 0.301685
tensor(0.0140, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(8.4233e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.104958
Average KL loss: 0.199898
Average total loss: 0.304856
tensor(0.0140, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-1.5878e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.103467
Average KL loss: 0.200199
Average total loss: 0.303667
tensor(0.0140, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-7.5546e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.103428
Average KL loss: 0.200452
Average total loss: 0.303880
tensor(0.0140, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-2.9740e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.099636
Average KL loss: 0.200611
Average total loss: 0.300247
tensor(0.0140, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-1.7914e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.102013
Average KL loss: 0.200668
Average total loss: 0.302681
tensor(0.0140, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-1.2903e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.096619
Average KL loss: 0.200753
Average total loss: 0.297372
tensor(0.0140, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-4.8624e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.098930
Average KL loss: 0.200731
Average total loss: 0.299661
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-4.7354e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.099129
Average KL loss: 0.200808
Average total loss: 0.299937
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.0427e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.101695
Average KL loss: 0.200950
Average total loss: 0.302645
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-3.2937e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.097182
Average KL loss: 0.201150
Average total loss: 0.298332
tensor(0.0140, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(8.2680e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.097209
Average KL loss: 0.201144
Average total loss: 0.298353
tensor(0.0140, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(2.1441e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.097565
Average KL loss: 0.201008
Average total loss: 0.298573
tensor(0.0140, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-6.8299e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.095614
Average KL loss: 0.200880
Average total loss: 0.296494
tensor(0.0140, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-1.2379e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.097927
Average KL loss: 0.200751
Average total loss: 0.298677
tensor(0.0140, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-2.5575e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.097808
Average KL loss: 0.200635
Average total loss: 0.298444
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-4.0712e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.100224
Average KL loss: 0.200524
Average total loss: 0.300748
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(2.9776e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.094531
Average KL loss: 0.200399
Average total loss: 0.294930
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-3.1458e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.099660
Average KL loss: 0.200287
Average total loss: 0.299947
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-6.1827e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.097699
Average KL loss: 0.200177
Average total loss: 0.297876
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(5.6995e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.098720
Average KL loss: 0.200061
Average total loss: 0.298781
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.2400e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.096782
Average KL loss: 0.199959
Average total loss: 0.296741
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(6.4918e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.095511
Average KL loss: 0.199854
Average total loss: 0.295365
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-3.9496e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.100709
Average KL loss: 0.199748
Average total loss: 0.300458
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.3855e-11, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.094484
Average KL loss: 0.199652
Average total loss: 0.294136
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-4.6770e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.096849
Average KL loss: 0.199553
Average total loss: 0.296402
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-5.7045e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.097012
Average KL loss: 0.199459
Average total loss: 0.296471
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-2.4060e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.097681
Average KL loss: 0.199363
Average total loss: 0.297044
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-2.9126e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.096471
Average KL loss: 0.199266
Average total loss: 0.295737
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.3920e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.098805
Average KL loss: 0.199176
Average total loss: 0.297981
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-4.9183e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.094451
Average KL loss: 0.199087
Average total loss: 0.293538
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(3.8111e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.093659
Average KL loss: 0.198987
Average total loss: 0.292645
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.0623e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.097765
Average KL loss: 0.198898
Average total loss: 0.296663
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(3.1898e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.096627
Average KL loss: 0.198815
Average total loss: 0.295442
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-7.1023e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.092168
Average KL loss: 0.198734
Average total loss: 0.290902
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-6.9231e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.092163
Average KL loss: 0.198635
Average total loss: 0.290799
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-4.4237e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.097116
Average KL loss: 0.198540
Average total loss: 0.295655
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-7.2328e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.100785
Average KL loss: 0.198453
Average total loss: 0.299239
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(2.1618e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.096202
Average KL loss: 0.198380
Average total loss: 0.294581
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-3.8586e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.095302
Average KL loss: 0.198306
Average total loss: 0.293608
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(5.8504e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.094773
Average KL loss: 0.198219
Average total loss: 0.292992
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(4.2013e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.091364
Average KL loss: 0.198134
Average total loss: 0.289498
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-1.6786e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.094173
Average KL loss: 0.198052
Average total loss: 0.292224
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(6.9878e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.091784
Average KL loss: 0.197973
Average total loss: 0.289757
tensor(0.0140, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(6.4068e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.093574
Average KL loss: 0.197896
Average total loss: 0.291470
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(5.1076e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.093021
Average KL loss: 0.197812
Average total loss: 0.290832
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-6.5259e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.097469
Average KL loss: 0.197740
Average total loss: 0.295209
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(4.2093e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.096101
Average KL loss: 0.197665
Average total loss: 0.293767
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.9862e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.095537
Average KL loss: 0.197592
Average total loss: 0.293129
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(2.2064e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.095008
Average KL loss: 0.197518
Average total loss: 0.292526
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(4.2065e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.091111
Average KL loss: 0.197445
Average total loss: 0.288555
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(8.2989e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.098392
Average KL loss: 0.197365
Average total loss: 0.295757
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(2.5060e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.093116
Average KL loss: 0.197302
Average total loss: 0.290418
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(2.5183e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.089783
Average KL loss: 0.197232
Average total loss: 0.287015
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(2.8630e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.093201
Average KL loss: 0.197158
Average total loss: 0.290359
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.3526e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.096091
Average KL loss: 0.197089
Average total loss: 0.293180
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.2080e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.092369
Average KL loss: 0.197014
Average total loss: 0.289383
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-7.2369e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.097573
Average KL loss: 0.196940
Average total loss: 0.294513
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-9.2554e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.096806
Average KL loss: 0.196875
Average total loss: 0.293681
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(1.0462e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.092292
Average KL loss: 0.196814
Average total loss: 0.289106
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-5.3112e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.100485
Average KL loss: 0.196753
Average total loss: 0.297238
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.5150e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.096519
Average KL loss: 0.196691
Average total loss: 0.293209
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-5.7110e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.094736
Average KL loss: 0.196637
Average total loss: 0.291373
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.4734e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.095815
Average KL loss: 0.196579
Average total loss: 0.292393
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-5.8291e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.093316
Average KL loss: 0.196511
Average total loss: 0.289826
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-4.2021e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.098955
Average KL loss: 0.196475
Average total loss: 0.295431
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-7.2313e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.098530
Average KL loss: 0.196469
Average total loss: 0.294998
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(3.6701e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.092139
Average KL loss: 0.196461
Average total loss: 0.288600
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(2.0970e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.094156
Average KL loss: 0.196453
Average total loss: 0.290609
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-6.9129e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.096398
Average KL loss: 0.196445
Average total loss: 0.292843
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-2.8791e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.091271
Average KL loss: 0.196437
Average total loss: 0.287708
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.0625e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.092840
Average KL loss: 0.196429
Average total loss: 0.289269
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(6.9394e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.094252
Average KL loss: 0.196421
Average total loss: 0.290673
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.0720e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.092308
Average KL loss: 0.196413
Average total loss: 0.288721
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.2215e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.094841
Average KL loss: 0.196405
Average total loss: 0.291246
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-2.1101e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.092431
Average KL loss: 0.196398
Average total loss: 0.288829
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.3101e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.098748
Average KL loss: 0.196393
Average total loss: 0.295141
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(3.5163e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.092433
Average KL loss: 0.196393
Average total loss: 0.288825
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(3.1850e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.089183
Average KL loss: 0.196392
Average total loss: 0.285575
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(1.3821e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.096649
Average KL loss: 0.196391
Average total loss: 0.293040
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(3.2253e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.095368
Average KL loss: 0.196390
Average total loss: 0.291758
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-6.1817e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.095049
Average KL loss: 0.196389
Average total loss: 0.291438
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.9972e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.092965
Average KL loss: 0.196389
Average total loss: 0.289354
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-8.9573e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.092198
Average KL loss: 0.196388
Average total loss: 0.288586
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(2.0577e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.093123
Average KL loss: 0.196387
Average total loss: 0.289510
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.3889e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.094728
Average KL loss: 0.196386
Average total loss: 0.291114
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(1.0351e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.090481
Average KL loss: 0.196385
Average total loss: 0.286866
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(2.0677e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.088473
Average KL loss: 0.196384
Average total loss: 0.284858
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.9380e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.091104
Average KL loss: 0.196384
Average total loss: 0.287488
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-4.4271e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.098778
Average KL loss: 0.196383
Average total loss: 0.295161
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-2.7672e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.090194
Average KL loss: 0.196382
Average total loss: 0.286576
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(3.0900e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.096952
Average KL loss: 0.196381
Average total loss: 0.293333
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-6.8777e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.096925
Average KL loss: 0.196380
Average total loss: 0.293306
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-6.2364e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.092127
Average KL loss: 0.196380
Average total loss: 0.288507
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(3.2832e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.092997
Average KL loss: 0.196379
Average total loss: 0.289375
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.1188e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.097019
Average KL loss: 0.196378
Average total loss: 0.293398
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-2.4059e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.094785
Average KL loss: 0.196377
Average total loss: 0.291162
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.5126e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.094702
Average KL loss: 0.196377
Average total loss: 0.291079
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.2549e-09, device='cuda:0')
 Percentile value: -1.6525146406820568e-07
Non-zero model percentage: 10.737431526184082%, Non-zero mask percentage: 10.737431526184082%

--- Pruning Level [10/24]: ---
conv1.weight         | nonzeros =     914 /    1728             ( 52.89%) | total_pruned =     814 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2192 /   36864             (  5.95%) | total_pruned =   34672 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2643 /   36864             (  7.17%) | total_pruned =   34221 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2394 /   36864             (  6.49%) | total_pruned =   34470 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2428 /   36864             (  6.59%) | total_pruned =   34436 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4202 /   73728             (  5.70%) | total_pruned =   69526 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6765 /  147456             (  4.59%) | total_pruned =  140691 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1805 /    8192             ( 22.03%) | total_pruned =    6387 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    6591 /  147456             (  4.47%) | total_pruned =  140865 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    6471 /  147456             (  4.39%) | total_pruned =  140985 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   12048 /  294912             (  4.09%) | total_pruned =  282864 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     177 /     256             ( 69.14%) | total_pruned =      79 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     214 /     256             ( 83.59%) | total_pruned =      42 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   18642 /  589824             (  3.16%) | total_pruned =  571182 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4143 /   32768             ( 12.64%) | total_pruned =   28625 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     178 /     256             ( 69.53%) | total_pruned =      78 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     129 /     256             ( 50.39%) | total_pruned =     127 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   38168 /  589824             (  6.47%) | total_pruned =  551656 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     167 /     256             ( 65.23%) | total_pruned =      89 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   36864 /  589824             (  6.25%) | total_pruned =  552960 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     178 /     256             ( 69.53%) | total_pruned =      78 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      90 /     256             ( 35.16%) | total_pruned =     166 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   30788 / 1179648             (  2.61%) | total_pruned = 1148860 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     346 /     512             ( 67.58%) | total_pruned =     166 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     475 /     512             ( 92.77%) | total_pruned =      37 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   50012 / 2359296             (  2.12%) | total_pruned = 2309284 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     371 /     512             ( 72.46%) | total_pruned =     141 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     350 /     512             ( 68.36%) | total_pruned =     162 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    6650 /  131072             (  5.07%) | total_pruned =  124422 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     393 /     512             ( 76.76%) | total_pruned =     119 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     484 /     512             ( 94.53%) | total_pruned =      28 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     357 /     512             ( 69.73%) | total_pruned =     155 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  417763 / 2359296             ( 17.71%) | total_pruned = 1941533 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     312 /     512             ( 60.94%) | total_pruned =     200 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  536814 / 2359296             ( 22.75%) | total_pruned = 1822482 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     294 /     512             ( 57.42%) | total_pruned =     218 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     407 /     512             ( 79.49%) | total_pruned =     105 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
linear.weight        | nonzeros =    1837 /    5120             ( 35.88%) | total_pruned =    3283 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 1200312, pruned : 9978450, total: 11178762, Compression rate :       9.31x  ( 89.26% pruned)
Train Epoch: 22/100 Loss: 0.000053 Accuracy: 86.23 100.00 % Best test Accuracy: 86.73%
tensor(0.0140, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-9.6621e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.168154
Average KL loss: 0.189716
Average total loss: 0.357869
tensor(0.0142, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-5.9022e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.172309
Average KL loss: 0.189093
Average total loss: 0.361402
tensor(0.0143, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-7.7036e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.166116
Average KL loss: 0.190378
Average total loss: 0.356494
tensor(0.0143, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.2419e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.154970
Average KL loss: 0.191768
Average total loss: 0.346737
tensor(0.0143, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-5.8468e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.153442
Average KL loss: 0.192924
Average total loss: 0.346366
tensor(0.0143, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.4022e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.149111
Average KL loss: 0.194181
Average total loss: 0.343292
tensor(0.0143, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-4.5064e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.146141
Average KL loss: 0.195204
Average total loss: 0.341345
tensor(0.0143, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-4.4982e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.140417
Average KL loss: 0.196210
Average total loss: 0.336627
tensor(0.0144, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-3.8704e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.145779
Average KL loss: 0.197143
Average total loss: 0.342922
tensor(0.0144, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-1.1066e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.144667
Average KL loss: 0.198114
Average total loss: 0.342781
tensor(0.0144, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-6.8339e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.134948
Average KL loss: 0.198932
Average total loss: 0.333880
tensor(0.0144, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-4.4010e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.131737
Average KL loss: 0.199568
Average total loss: 0.331306
tensor(0.0144, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-3.7560e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.129255
Average KL loss: 0.200190
Average total loss: 0.329445
tensor(0.0144, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-8.4108e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.135505
Average KL loss: 0.200857
Average total loss: 0.336363
tensor(0.0144, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-2.7656e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.129113
Average KL loss: 0.201631
Average total loss: 0.330744
tensor(0.0144, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.6542e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.128676
Average KL loss: 0.202210
Average total loss: 0.330885
tensor(0.0144, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-9.3123e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.129606
Average KL loss: 0.202817
Average total loss: 0.332423
tensor(0.0144, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-1.7095e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.127022
Average KL loss: 0.203491
Average total loss: 0.330513
tensor(0.0145, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-7.5764e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.118233
Average KL loss: 0.203954
Average total loss: 0.322187
tensor(0.0145, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-1.6455e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.115529
Average KL loss: 0.204322
Average total loss: 0.319851
tensor(0.0145, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(9.0267e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.118113
Average KL loss: 0.204559
Average total loss: 0.322672
tensor(0.0144, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(3.7092e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.118403
Average KL loss: 0.204913
Average total loss: 0.323316
tensor(0.0145, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-2.3856e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.119432
Average KL loss: 0.205384
Average total loss: 0.324816
tensor(0.0145, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-5.5825e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.119519
Average KL loss: 0.205784
Average total loss: 0.325303
tensor(0.0145, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(4.7392e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.112961
Average KL loss: 0.206169
Average total loss: 0.319130
tensor(0.0145, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-5.4627e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.115946
Average KL loss: 0.206434
Average total loss: 0.322380
tensor(0.0145, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-6.9437e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.112294
Average KL loss: 0.206808
Average total loss: 0.319102
tensor(0.0145, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-1.3489e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.116965
Average KL loss: 0.207138
Average total loss: 0.324103
tensor(0.0145, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-9.3085e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.119227
Average KL loss: 0.207582
Average total loss: 0.326809
tensor(0.0145, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-5.6410e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.114833
Average KL loss: 0.207987
Average total loss: 0.322820
tensor(0.0145, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-1.1916e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.108852
Average KL loss: 0.208350
Average total loss: 0.317202
tensor(0.0145, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(2.1767e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.110829
Average KL loss: 0.208641
Average total loss: 0.319470
tensor(0.0145, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-6.1750e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.112866
Average KL loss: 0.208898
Average total loss: 0.321764
tensor(0.0145, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-1.3403e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.108849
Average KL loss: 0.209248
Average total loss: 0.318097
tensor(0.0145, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(2.5098e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.106842
Average KL loss: 0.209431
Average total loss: 0.316273
tensor(0.0145, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-1.7770e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.107210
Average KL loss: 0.209600
Average total loss: 0.316810
tensor(0.0145, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(4.6751e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.104454
Average KL loss: 0.209790
Average total loss: 0.314244
tensor(0.0145, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.3575e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.103747
Average KL loss: 0.209871
Average total loss: 0.313617
tensor(0.0145, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-5.0102e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.103912
Average KL loss: 0.209961
Average total loss: 0.313874
tensor(0.0145, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-2.3299e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.101674
Average KL loss: 0.210016
Average total loss: 0.311690
tensor(0.0145, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-6.1324e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.102043
Average KL loss: 0.210092
Average total loss: 0.312135
tensor(0.0145, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-9.4008e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.101207
Average KL loss: 0.210211
Average total loss: 0.311418
tensor(0.0145, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(3.6585e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.107337
Average KL loss: 0.210325
Average total loss: 0.317661
tensor(0.0145, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(3.1312e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.098521
Average KL loss: 0.210485
Average total loss: 0.309006
tensor(0.0144, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-5.7560e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.103363
Average KL loss: 0.210596
Average total loss: 0.313958
tensor(0.0144, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-5.7882e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.100889
Average KL loss: 0.210731
Average total loss: 0.311620
tensor(0.0144, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-2.7187e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.101062
Average KL loss: 0.210850
Average total loss: 0.311912
tensor(0.0144, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.0152e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.101110
Average KL loss: 0.210943
Average total loss: 0.312053
tensor(0.0144, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-4.4486e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.100260
Average KL loss: 0.211023
Average total loss: 0.311283
tensor(0.0144, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-2.7983e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.098445
Average KL loss: 0.211202
Average total loss: 0.309646
tensor(0.0144, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-7.4208e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.099318
Average KL loss: 0.211369
Average total loss: 0.310687
tensor(0.0144, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-3.8984e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.102498
Average KL loss: 0.211518
Average total loss: 0.314016
tensor(0.0144, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.3976e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.099869
Average KL loss: 0.211741
Average total loss: 0.311610
tensor(0.0144, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-1.7161e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.098147
Average KL loss: 0.211944
Average total loss: 0.310091
tensor(0.0144, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-1.1892e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.095844
Average KL loss: 0.211963
Average total loss: 0.307807
tensor(0.0144, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-1.6462e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.098437
Average KL loss: 0.212009
Average total loss: 0.310447
tensor(0.0144, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-5.9575e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.096717
Average KL loss: 0.212154
Average total loss: 0.308870
tensor(0.0144, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(4.0892e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.098770
Average KL loss: 0.212286
Average total loss: 0.311056
tensor(0.0144, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(2.2127e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.097261
Average KL loss: 0.212448
Average total loss: 0.309709
tensor(0.0144, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(1.5425e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.096949
Average KL loss: 0.212519
Average total loss: 0.309468
tensor(0.0144, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-2.2797e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.098156
Average KL loss: 0.212569
Average total loss: 0.310725
tensor(0.0144, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-5.1885e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.094061
Average KL loss: 0.212663
Average total loss: 0.306724
tensor(0.0144, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(2.7552e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.095834
Average KL loss: 0.212709
Average total loss: 0.308542
tensor(0.0144, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-1.5255e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.096984
Average KL loss: 0.212825
Average total loss: 0.309809
tensor(0.0144, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(1.8127e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.091545
Average KL loss: 0.212844
Average total loss: 0.304388
tensor(0.0144, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-8.8230e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.092480
Average KL loss: 0.212966
Average total loss: 0.305446
tensor(0.0144, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-5.9174e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.099058
Average KL loss: 0.213081
Average total loss: 0.312139
tensor(0.0144, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-6.4910e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.087597
Average KL loss: 0.213203
Average total loss: 0.300801
tensor(0.0144, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-4.9641e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.089573
Average KL loss: 0.213120
Average total loss: 0.302693
tensor(0.0144, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-4.1084e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.099936
Average KL loss: 0.213193
Average total loss: 0.313130
tensor(0.0144, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-3.6373e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.095050
Average KL loss: 0.213409
Average total loss: 0.308459
tensor(0.0144, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-1.4419e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.094069
Average KL loss: 0.213607
Average total loss: 0.307676
tensor(0.0144, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-5.5553e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.094574
Average KL loss: 0.213698
Average total loss: 0.308272
tensor(0.0144, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-2.2752e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.090389
Average KL loss: 0.213782
Average total loss: 0.304172
tensor(0.0144, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-7.9817e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.085896
Average KL loss: 0.213775
Average total loss: 0.299671
tensor(0.0144, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(1.0821e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.090366
Average KL loss: 0.213713
Average total loss: 0.304079
tensor(0.0144, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(8.9594e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.093616
Average KL loss: 0.213702
Average total loss: 0.307318
tensor(0.0144, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(7.8789e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.088868
Average KL loss: 0.213768
Average total loss: 0.302635
tensor(0.0144, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(6.1775e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.089217
Average KL loss: 0.213803
Average total loss: 0.303020
tensor(0.0144, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(1.4622e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.091690
Average KL loss: 0.213808
Average total loss: 0.305498
tensor(0.0144, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.3387e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.088105
Average KL loss: 0.213831
Average total loss: 0.301937
tensor(0.0144, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(5.1929e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.091843
Average KL loss: 0.213883
Average total loss: 0.305726
tensor(0.0144, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(6.6662e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.096094
Average KL loss: 0.213983
Average total loss: 0.310078
tensor(0.0144, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-4.6414e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.087688
Average KL loss: 0.214059
Average total loss: 0.301747
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.6888e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.094457
Average KL loss: 0.214060
Average total loss: 0.308517
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.9119e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.090656
Average KL loss: 0.214237
Average total loss: 0.304892
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-3.7350e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.091323
Average KL loss: 0.214235
Average total loss: 0.305558
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-6.1496e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.091034
Average KL loss: 0.214145
Average total loss: 0.305179
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.0696e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.084374
Average KL loss: 0.214052
Average total loss: 0.298426
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-7.0004e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.086692
Average KL loss: 0.213948
Average total loss: 0.300639
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-3.3773e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.086105
Average KL loss: 0.213856
Average total loss: 0.299961
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.8715e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.088173
Average KL loss: 0.213771
Average total loss: 0.301943
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(8.8180e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.091154
Average KL loss: 0.213686
Average total loss: 0.304840
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(3.4087e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.088902
Average KL loss: 0.213602
Average total loss: 0.302503
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-8.9716e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.084872
Average KL loss: 0.213519
Average total loss: 0.298392
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(8.5778e-12, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.086035
Average KL loss: 0.213429
Average total loss: 0.299464
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(2.3775e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.086609
Average KL loss: 0.213337
Average total loss: 0.299945
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(1.3337e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.087029
Average KL loss: 0.213249
Average total loss: 0.300277
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(5.3227e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.091396
Average KL loss: 0.213171
Average total loss: 0.304567
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(8.3108e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.085960
Average KL loss: 0.213106
Average total loss: 0.299066
tensor(0.0144, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(1.7591e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.088140
Average KL loss: 0.213033
Average total loss: 0.301173
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-4.8374e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.083276
Average KL loss: 0.212954
Average total loss: 0.296230
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-2.0920e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.088665
Average KL loss: 0.212871
Average total loss: 0.301536
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-3.9877e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.085229
Average KL loss: 0.212795
Average total loss: 0.298024
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-2.8668e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.088665
Average KL loss: 0.212712
Average total loss: 0.301377
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-4.2202e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.083121
Average KL loss: 0.212631
Average total loss: 0.295752
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-2.9531e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.087512
Average KL loss: 0.212547
Average total loss: 0.300059
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-2.1722e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.085950
Average KL loss: 0.212476
Average total loss: 0.298426
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.5002e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.085362
Average KL loss: 0.212392
Average total loss: 0.297754
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-5.6228e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.086168
Average KL loss: 0.212310
Average total loss: 0.298478
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-4.0217e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.084861
Average KL loss: 0.212239
Average total loss: 0.297100
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-3.4452e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.082631
Average KL loss: 0.212168
Average total loss: 0.294799
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.0767e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.085942
Average KL loss: 0.212094
Average total loss: 0.298036
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(3.4977e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.084018
Average KL loss: 0.212022
Average total loss: 0.296040
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-7.1300e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.086865
Average KL loss: 0.211945
Average total loss: 0.298810
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.4717e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.089538
Average KL loss: 0.211878
Average total loss: 0.301416
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(3.8271e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.088314
Average KL loss: 0.211814
Average total loss: 0.300128
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-5.4460e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.085495
Average KL loss: 0.211751
Average total loss: 0.297246
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-4.6650e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.087265
Average KL loss: 0.211685
Average total loss: 0.298949
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-6.2772e-11, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.079537
Average KL loss: 0.211616
Average total loss: 0.291153
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.9751e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.088181
Average KL loss: 0.211541
Average total loss: 0.299722
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(2.6005e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.088930
Average KL loss: 0.211476
Average total loss: 0.300407
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.5709e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.086059
Average KL loss: 0.211417
Average total loss: 0.297476
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(2.8990e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.085926
Average KL loss: 0.211356
Average total loss: 0.297282
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(2.6825e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.088967
Average KL loss: 0.211294
Average total loss: 0.300261
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-5.1849e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.087119
Average KL loss: 0.211234
Average total loss: 0.298353
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-2.1514e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.083815
Average KL loss: 0.211171
Average total loss: 0.294985
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(5.1141e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.084919
Average KL loss: 0.211106
Average total loss: 0.296025
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(6.2420e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.084387
Average KL loss: 0.211044
Average total loss: 0.295431
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.6250e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.089474
Average KL loss: 0.210981
Average total loss: 0.300455
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(3.5216e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.086555
Average KL loss: 0.210918
Average total loss: 0.297473
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.5222e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.089386
Average KL loss: 0.210882
Average total loss: 0.300268
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-3.9883e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.086993
Average KL loss: 0.210875
Average total loss: 0.297868
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.8099e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.090271
Average KL loss: 0.210869
Average total loss: 0.301140
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-6.2592e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.091099
Average KL loss: 0.210863
Average total loss: 0.301962
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.8400e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.086763
Average KL loss: 0.210856
Average total loss: 0.297619
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(4.8300e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.084876
Average KL loss: 0.210849
Average total loss: 0.295725
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.2312e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.086358
Average KL loss: 0.210842
Average total loss: 0.297200
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-4.2524e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.085322
Average KL loss: 0.210836
Average total loss: 0.296158
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-3.1712e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.083840
Average KL loss: 0.210829
Average total loss: 0.294669
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-5.3426e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.088564
Average KL loss: 0.210822
Average total loss: 0.299386
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-2.9534e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.085499
Average KL loss: 0.210816
Average total loss: 0.296315
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-6.9367e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.088588
Average KL loss: 0.210812
Average total loss: 0.299400
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-3.1014e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.089136
Average KL loss: 0.210812
Average total loss: 0.299947
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(3.0932e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.087516
Average KL loss: 0.210811
Average total loss: 0.298327
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-4.8981e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.085064
Average KL loss: 0.210810
Average total loss: 0.295874
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(7.2380e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.088070
Average KL loss: 0.210810
Average total loss: 0.298879
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.7228e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.078984
Average KL loss: 0.210809
Average total loss: 0.289793
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(3.8116e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.087276
Average KL loss: 0.210808
Average total loss: 0.298085
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.6463e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.083421
Average KL loss: 0.210807
Average total loss: 0.294229
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(5.1988e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.085766
Average KL loss: 0.210807
Average total loss: 0.296572
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-5.9829e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.087255
Average KL loss: 0.210806
Average total loss: 0.298061
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-2.6445e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.085345
Average KL loss: 0.210805
Average total loss: 0.296150
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.3084e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.087326
Average KL loss: 0.210804
Average total loss: 0.298130
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(1.3556e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.084836
Average KL loss: 0.210803
Average total loss: 0.295639
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-4.7216e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.081619
Average KL loss: 0.210803
Average total loss: 0.292421
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-3.2437e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.083305
Average KL loss: 0.210802
Average total loss: 0.294107
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-2.4862e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.085748
Average KL loss: 0.210801
Average total loss: 0.296549
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.8506e-09, device='cuda:0')
 Percentile value: -1.65260829021463e-07
Non-zero model percentage: 8.589949607849121%, Non-zero mask percentage: 8.589949607849121%

--- Pruning Level [11/24]: ---
conv1.weight         | nonzeros =     906 /    1728             ( 52.43%) | total_pruned =     822 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1971 /   36864             (  5.35%) | total_pruned =   34893 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2424 /   36864             (  6.58%) | total_pruned =   34440 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2180 /   36864             (  5.91%) | total_pruned =   34684 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2244 /   36864             (  6.09%) | total_pruned =   34620 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3815 /   73728             (  5.17%) | total_pruned =   69913 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6081 /  147456             (  4.12%) | total_pruned =  141375 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1737 /    8192             ( 21.20%) | total_pruned =    6455 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    5560 /  147456             (  3.77%) | total_pruned =  141896 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    5407 /  147456             (  3.67%) | total_pruned =  142049 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   10734 /  294912             (  3.64%) | total_pruned =  284178 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   16205 /  589824             (  2.75%) | total_pruned =  573619 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     182 /     256             ( 71.09%) | total_pruned =      74 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3859 /   32768             ( 11.78%) | total_pruned =   28909 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   30302 /  589824             (  5.14%) | total_pruned =  559522 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     151 /     256             ( 58.98%) | total_pruned =     105 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   29176 /  589824             (  4.95%) | total_pruned =  560648 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   26088 / 1179648             (  2.21%) | total_pruned = 1153560 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     319 /     512             ( 62.30%) | total_pruned =     193 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   38410 / 2359296             (  1.63%) | total_pruned = 2320886 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     333 /     512             ( 65.04%) | total_pruned =     179 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     334 /     512             ( 65.23%) | total_pruned =     178 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    5736 /  131072             (  4.38%) | total_pruned =  125336 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     360 /     512             ( 70.31%) | total_pruned =     152 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     482 /     512             ( 94.14%) | total_pruned =      30 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     341 /     512             ( 66.60%) | total_pruned =     171 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  329092 / 2359296             ( 13.95%) | total_pruned = 2030204 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     270 /     512             ( 52.73%) | total_pruned =     242 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     203 /     512             ( 39.65%) | total_pruned =     309 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  426900 / 2359296             ( 18.09%) | total_pruned = 1932396 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     394 /     512             ( 76.95%) | total_pruned =     118 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
linear.weight        | nonzeros =    1731 /    5120             ( 33.81%) | total_pruned =    3389 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 960250, pruned : 10218512, total: 11178762, Compression rate :      11.64x  ( 91.41% pruned)
Train Epoch: 22/100 Loss: 0.000086 Accuracy: 85.85 100.00 % Best test Accuracy: 86.16%
tensor(0.0144, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.2704e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.157221
Average KL loss: 0.204232
Average total loss: 0.361453
tensor(0.0145, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-6.7346e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.148543
Average KL loss: 0.202930
Average total loss: 0.351473
tensor(0.0145, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-1.8042e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.148397
Average KL loss: 0.203647
Average total loss: 0.352043
tensor(0.0145, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-7.2477e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.142166
Average KL loss: 0.204595
Average total loss: 0.346761
tensor(0.0145, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.3292e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.139922
Average KL loss: 0.205543
Average total loss: 0.345465
tensor(0.0146, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.0828e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.143371
Average KL loss: 0.206494
Average total loss: 0.349865
tensor(0.0146, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-3.3315e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.136567
Average KL loss: 0.207369
Average total loss: 0.343936
tensor(0.0146, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-1.9023e-11, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.128490
Average KL loss: 0.208175
Average total loss: 0.336665
tensor(0.0146, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-1.0617e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.132597
Average KL loss: 0.208875
Average total loss: 0.341472
tensor(0.0146, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-6.5920e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.126291
Average KL loss: 0.209563
Average total loss: 0.335854
tensor(0.0146, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-7.7761e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.129647
Average KL loss: 0.210270
Average total loss: 0.339918
tensor(0.0147, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-7.6317e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.126357
Average KL loss: 0.210964
Average total loss: 0.337321
tensor(0.0147, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.5274e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.123052
Average KL loss: 0.211572
Average total loss: 0.334624
tensor(0.0147, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(1.0118e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.121284
Average KL loss: 0.212111
Average total loss: 0.333396
tensor(0.0147, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-1.1063e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.119575
Average KL loss: 0.212635
Average total loss: 0.332210
tensor(0.0147, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-9.0332e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.121917
Average KL loss: 0.213157
Average total loss: 0.335074
tensor(0.0147, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(2.2867e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.118319
Average KL loss: 0.213596
Average total loss: 0.331915
tensor(0.0147, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-3.9826e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.114519
Average KL loss: 0.214004
Average total loss: 0.328523
tensor(0.0147, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-2.6616e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.122257
Average KL loss: 0.214455
Average total loss: 0.336713
tensor(0.0148, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-4.9603e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.112993
Average KL loss: 0.214931
Average total loss: 0.327924
tensor(0.0148, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-2.2555e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.113052
Average KL loss: 0.215340
Average total loss: 0.328392
tensor(0.0148, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-6.1164e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.109771
Average KL loss: 0.215787
Average total loss: 0.325558
tensor(0.0148, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-4.8505e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.112570
Average KL loss: 0.216133
Average total loss: 0.328703
tensor(0.0148, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-1.1068e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.107274
Average KL loss: 0.216453
Average total loss: 0.323727
tensor(0.0148, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-5.2291e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.111502
Average KL loss: 0.216704
Average total loss: 0.328207
tensor(0.0148, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(9.6665e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.108675
Average KL loss: 0.217044
Average total loss: 0.325719
tensor(0.0148, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-2.6768e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.104147
Average KL loss: 0.217354
Average total loss: 0.321501
tensor(0.0148, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-3.3043e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.109076
Average KL loss: 0.217575
Average total loss: 0.326652
tensor(0.0148, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.5151e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.106972
Average KL loss: 0.217968
Average total loss: 0.324939
tensor(0.0148, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-2.0877e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.102903
Average KL loss: 0.218198
Average total loss: 0.321101
tensor(0.0148, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.0625e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.108152
Average KL loss: 0.218425
Average total loss: 0.326577
tensor(0.0148, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-1.8254e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.102378
Average KL loss: 0.218605
Average total loss: 0.320982
tensor(0.0148, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-5.0680e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.102844
Average KL loss: 0.218787
Average total loss: 0.321630
tensor(0.0148, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-3.1009e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.102997
Average KL loss: 0.218943
Average total loss: 0.321940
tensor(0.0148, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-3.8138e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.099529
Average KL loss: 0.219019
Average total loss: 0.318548
tensor(0.0148, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(7.5162e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.102177
Average KL loss: 0.219164
Average total loss: 0.321341
tensor(0.0148, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-3.0510e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.099567
Average KL loss: 0.219378
Average total loss: 0.318945
tensor(0.0148, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(1.8330e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.100640
Average KL loss: 0.219585
Average total loss: 0.320225
tensor(0.0148, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-4.9400e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.099600
Average KL loss: 0.219837
Average total loss: 0.319437
tensor(0.0148, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.5859e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.101793
Average KL loss: 0.220041
Average total loss: 0.321834
tensor(0.0148, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-7.4116e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.099598
Average KL loss: 0.220230
Average total loss: 0.319828
tensor(0.0148, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-4.6595e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.101476
Average KL loss: 0.220438
Average total loss: 0.321914
tensor(0.0148, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-6.8989e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.096118
Average KL loss: 0.220679
Average total loss: 0.316797
tensor(0.0148, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-4.4788e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.095274
Average KL loss: 0.220835
Average total loss: 0.316109
tensor(0.0148, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(2.3577e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.095096
Average KL loss: 0.220985
Average total loss: 0.316081
tensor(0.0148, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(3.4202e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.093542
Average KL loss: 0.221065
Average total loss: 0.314607
tensor(0.0148, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-2.3634e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.092351
Average KL loss: 0.221111
Average total loss: 0.313461
tensor(0.0148, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-7.2637e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.095995
Average KL loss: 0.221151
Average total loss: 0.317147
tensor(0.0148, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-5.1398e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.093662
Average KL loss: 0.221258
Average total loss: 0.314920
tensor(0.0148, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(7.9794e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.096051
Average KL loss: 0.221433
Average total loss: 0.317484
tensor(0.0148, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-3.9077e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.100989
Average KL loss: 0.221588
Average total loss: 0.322577
tensor(0.0148, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(1.9232e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.095568
Average KL loss: 0.221763
Average total loss: 0.317332
tensor(0.0149, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-4.0886e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.094289
Average KL loss: 0.221820
Average total loss: 0.316109
tensor(0.0148, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-1.0386e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.088923
Average KL loss: 0.221885
Average total loss: 0.310808
tensor(0.0148, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-3.3621e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.089871
Average KL loss: 0.221892
Average total loss: 0.311763
tensor(0.0148, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-6.9909e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.093934
Average KL loss: 0.221959
Average total loss: 0.315893
tensor(0.0148, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-9.0195e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.090252
Average KL loss: 0.222038
Average total loss: 0.312289
tensor(0.0148, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-3.6184e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.090101
Average KL loss: 0.222160
Average total loss: 0.312261
tensor(0.0148, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-4.6588e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.089702
Average KL loss: 0.222261
Average total loss: 0.311964
tensor(0.0148, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-3.7915e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.088972
Average KL loss: 0.222220
Average total loss: 0.311192
tensor(0.0148, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-4.0099e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.092464
Average KL loss: 0.222223
Average total loss: 0.314687
tensor(0.0148, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(3.4512e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.093797
Average KL loss: 0.222331
Average total loss: 0.316127
tensor(0.0148, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(4.0070e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.092081
Average KL loss: 0.222478
Average total loss: 0.314559
tensor(0.0148, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-1.2737e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.088964
Average KL loss: 0.222628
Average total loss: 0.311593
tensor(0.0148, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(8.6322e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.087935
Average KL loss: 0.222718
Average total loss: 0.310653
tensor(0.0148, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-5.2476e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.085135
Average KL loss: 0.222779
Average total loss: 0.307914
tensor(0.0148, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(3.7065e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.091136
Average KL loss: 0.222812
Average total loss: 0.313948
tensor(0.0148, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-2.4349e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.086131
Average KL loss: 0.222890
Average total loss: 0.309021
tensor(0.0148, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(2.0334e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.081741
Average KL loss: 0.222862
Average total loss: 0.304604
tensor(0.0148, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(7.4898e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.087064
Average KL loss: 0.222858
Average total loss: 0.309922
tensor(0.0148, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-3.1095e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.083871
Average KL loss: 0.222848
Average total loss: 0.306719
tensor(0.0148, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-5.6707e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.085495
Average KL loss: 0.222862
Average total loss: 0.308357
tensor(0.0148, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-5.1885e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.092093
Average KL loss: 0.222935
Average total loss: 0.315027
tensor(0.0148, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-4.8803e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.086703
Average KL loss: 0.223055
Average total loss: 0.309759
tensor(0.0148, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-3.7626e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.091430
Average KL loss: 0.223189
Average total loss: 0.314619
tensor(0.0148, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(2.9223e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.084211
Average KL loss: 0.223257
Average total loss: 0.307468
tensor(0.0148, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.3674e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.089336
Average KL loss: 0.223271
Average total loss: 0.312607
tensor(0.0148, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-1.1541e-11, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.083973
Average KL loss: 0.223327
Average total loss: 0.307300
tensor(0.0148, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-1.3391e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.085516
Average KL loss: 0.223245
Average total loss: 0.308761
tensor(0.0148, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-3.5229e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.084269
Average KL loss: 0.223215
Average total loss: 0.307484
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(2.5667e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.081390
Average KL loss: 0.223125
Average total loss: 0.304515
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.9692e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.076373
Average KL loss: 0.223055
Average total loss: 0.299427
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-2.7062e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.090419
Average KL loss: 0.222981
Average total loss: 0.313400
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(6.5519e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.084290
Average KL loss: 0.222919
Average total loss: 0.307209
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-3.2410e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.083759
Average KL loss: 0.222857
Average total loss: 0.306616
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-2.9813e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.084769
Average KL loss: 0.222791
Average total loss: 0.307560
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(3.8666e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.081425
Average KL loss: 0.222718
Average total loss: 0.304143
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-3.0982e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.087315
Average KL loss: 0.222654
Average total loss: 0.309969
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-3.3797e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.084598
Average KL loss: 0.222594
Average total loss: 0.307192
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(3.5580e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.087247
Average KL loss: 0.222535
Average total loss: 0.309781
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(2.3892e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.083293
Average KL loss: 0.222471
Average total loss: 0.305764
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(2.2391e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.086792
Average KL loss: 0.222411
Average total loss: 0.309204
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(1.6453e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.083655
Average KL loss: 0.222360
Average total loss: 0.306015
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.2453e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.082245
Average KL loss: 0.222329
Average total loss: 0.304574
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(4.2375e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.087845
Average KL loss: 0.222323
Average total loss: 0.310168
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-7.8108e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.087058
Average KL loss: 0.222318
Average total loss: 0.309376
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(7.6670e-11, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.081207
Average KL loss: 0.222312
Average total loss: 0.303519
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.8228e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.084044
Average KL loss: 0.222306
Average total loss: 0.306350
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-4.6019e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.084485
Average KL loss: 0.222300
Average total loss: 0.306785
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(1.0430e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.084493
Average KL loss: 0.222294
Average total loss: 0.306787
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-4.7875e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.085102
Average KL loss: 0.222288
Average total loss: 0.307389
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(6.5953e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.087041
Average KL loss: 0.222282
Average total loss: 0.309323
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(2.2656e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.080523
Average KL loss: 0.222275
Average total loss: 0.302798
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.0777e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.083048
Average KL loss: 0.222268
Average total loss: 0.305317
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-7.0247e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.087501
Average KL loss: 0.222265
Average total loss: 0.309766
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-8.2427e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.083103
Average KL loss: 0.222264
Average total loss: 0.305367
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-7.9972e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.084864
Average KL loss: 0.222264
Average total loss: 0.307128
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.8007e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.082962
Average KL loss: 0.222263
Average total loss: 0.305225
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-4.6395e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.087675
Average KL loss: 0.222262
Average total loss: 0.309937
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(2.7440e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.083200
Average KL loss: 0.222262
Average total loss: 0.305462
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(3.8019e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.081720
Average KL loss: 0.222261
Average total loss: 0.303981
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(8.5004e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.084128
Average KL loss: 0.222261
Average total loss: 0.306389
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-7.7174e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.089215
Average KL loss: 0.222260
Average total loss: 0.311475
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-3.1118e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.085202
Average KL loss: 0.222259
Average total loss: 0.307461
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-2.5719e-09, device='cuda:0')
 Percentile value: -1.652323220469043e-07
Non-zero model percentage: 6.871959686279297%, Non-zero mask percentage: 6.871959686279297%

--- Pruning Level [12/24]: ---
conv1.weight         | nonzeros =     894 /    1728             ( 51.74%) | total_pruned =     834 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1827 /   36864             (  4.96%) | total_pruned =   35037 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2254 /   36864             (  6.11%) | total_pruned =   34610 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1999 /   36864             (  5.42%) | total_pruned =   34865 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2079 /   36864             (  5.64%) | total_pruned =   34785 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3525 /   73728             (  4.78%) | total_pruned =   70203 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5566 /  147456             (  3.77%) | total_pruned =  141890 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1675 /    8192             ( 20.45%) | total_pruned =    6517 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4801 /  147456             (  3.26%) | total_pruned =  142655 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4551 /  147456             (  3.09%) | total_pruned =  142905 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    9703 /  294912             (  3.29%) | total_pruned =  285209 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     198 /     256             ( 77.34%) | total_pruned =      58 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   14311 /  589824             (  2.43%) | total_pruned =  575513 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     174 /     256             ( 67.97%) | total_pruned =      82 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     119 /     256             ( 46.48%) | total_pruned =     137 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3624 /   32768             ( 11.06%) | total_pruned =   29144 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     109 /     256             ( 42.58%) | total_pruned =     147 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   24520 /  589824             (  4.16%) | total_pruned =  565304 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     124 /     256             ( 48.44%) | total_pruned =     132 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     132 /     256             ( 51.56%) | total_pruned =     124 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   23509 /  589824             (  3.99%) | total_pruned =  566315 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   22475 / 1179648             (  1.91%) | total_pruned = 1157173 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     278 /     512             ( 54.30%) | total_pruned =     234 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     464 /     512             ( 90.62%) | total_pruned =      48 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   30223 / 2359296             (  1.28%) | total_pruned = 2329073 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     304 /     512             ( 59.38%) | total_pruned =     208 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     319 /     512             ( 62.30%) | total_pruned =     193 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    5018 /  131072             (  3.83%) | total_pruned =  126054 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     321 /     512             ( 62.70%) | total_pruned =     191 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     480 /     512             ( 93.75%) | total_pruned =      32 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     328 /     512             ( 64.06%) | total_pruned =     184 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  261321 / 2359296             ( 11.08%) | total_pruned = 2097975 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     224 /     512             ( 43.75%) | total_pruned =     288 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     181 /     512             ( 35.35%) | total_pruned =     331 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  333433 / 2359296             ( 14.13%) | total_pruned = 2025863 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     226 /     512             ( 44.14%) | total_pruned =     286 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     388 /     512             ( 75.78%) | total_pruned =     124 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
linear.weight        | nonzeros =    1669 /    5120             ( 32.60%) | total_pruned =    3451 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 768200, pruned : 10410562, total: 11178762, Compression rate :      14.55x  ( 93.13% pruned)
Train Epoch: 21/100 Loss: 0.000051 Accuracy: 85.86 100.00 % Best test Accuracy: 85.99%
tensor(0.0148, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-1.2137e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.147756
Average KL loss: 0.215816
Average total loss: 0.363573
tensor(0.0148, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-2.2642e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.143553
Average KL loss: 0.214302
Average total loss: 0.357854
tensor(0.0148, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-4.6493e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.148339
Average KL loss: 0.214802
Average total loss: 0.363141
tensor(0.0148, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.1626e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.142075
Average KL loss: 0.215579
Average total loss: 0.357654
tensor(0.0148, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-1.6123e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.141612
Average KL loss: 0.216470
Average total loss: 0.358082
tensor(0.0148, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-1.4514e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.135113
Average KL loss: 0.217298
Average total loss: 0.352411
tensor(0.0148, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-6.7821e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.130910
Average KL loss: 0.218014
Average total loss: 0.348923
tensor(0.0149, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.1338e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.128073
Average KL loss: 0.218696
Average total loss: 0.346769
tensor(0.0149, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(3.6763e-11, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.127660
Average KL loss: 0.219398
Average total loss: 0.347058
tensor(0.0149, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-8.4981e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.124941
Average KL loss: 0.220089
Average total loss: 0.345030
tensor(0.0149, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-7.2837e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.127672
Average KL loss: 0.220711
Average total loss: 0.348382
tensor(0.0149, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-2.0368e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.123555
Average KL loss: 0.221321
Average total loss: 0.344875
tensor(0.0149, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-3.9152e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.121394
Average KL loss: 0.221833
Average total loss: 0.343228
tensor(0.0150, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.8965e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.118522
Average KL loss: 0.222359
Average total loss: 0.340882
tensor(0.0150, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.2283e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.116322
Average KL loss: 0.222802
Average total loss: 0.339124
tensor(0.0150, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-1.1628e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.114002
Average KL loss: 0.223261
Average total loss: 0.337263
tensor(0.0150, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-1.9617e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.114605
Average KL loss: 0.223683
Average total loss: 0.338287
tensor(0.0150, device='cuda:0') tensor(0.0364, device='cuda:0') tensor(-2.3283e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.111047
Average KL loss: 0.224053
Average total loss: 0.335100
tensor(0.0150, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-9.2550e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.117604
Average KL loss: 0.224407
Average total loss: 0.342011
tensor(0.0150, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-1.0085e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.113034
Average KL loss: 0.224853
Average total loss: 0.337887
tensor(0.0150, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-8.5062e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.103336
Average KL loss: 0.225192
Average total loss: 0.328528
tensor(0.0150, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(8.0578e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.113304
Average KL loss: 0.225474
Average total loss: 0.338778
tensor(0.0151, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-5.1104e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.104163
Average KL loss: 0.225790
Average total loss: 0.329952
tensor(0.0151, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-1.0646e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.104235
Average KL loss: 0.225998
Average total loss: 0.330233
tensor(0.0151, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-4.0568e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.103848
Average KL loss: 0.226230
Average total loss: 0.330078
tensor(0.0151, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-1.0109e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.107036
Average KL loss: 0.226547
Average total loss: 0.333583
tensor(0.0151, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-1.6098e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.112569
Average KL loss: 0.226855
Average total loss: 0.339424
tensor(0.0151, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(7.5410e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.096110
Average KL loss: 0.227095
Average total loss: 0.323205
tensor(0.0151, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(2.2685e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.099640
Average KL loss: 0.227221
Average total loss: 0.326861
tensor(0.0151, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-9.1372e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.100868
Average KL loss: 0.227438
Average total loss: 0.328306
tensor(0.0151, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-3.6918e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.097775
Average KL loss: 0.227639
Average total loss: 0.325414
tensor(0.0151, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-6.3262e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.103366
Average KL loss: 0.227875
Average total loss: 0.331241
tensor(0.0151, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-2.5752e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.101835
Average KL loss: 0.228156
Average total loss: 0.329992
tensor(0.0151, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-4.4853e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.095023
Average KL loss: 0.228351
Average total loss: 0.323373
tensor(0.0151, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(3.1727e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.094058
Average KL loss: 0.228503
Average total loss: 0.322561
tensor(0.0151, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-6.2391e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.097411
Average KL loss: 0.228645
Average total loss: 0.326056
tensor(0.0151, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-5.2356e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.100018
Average KL loss: 0.228840
Average total loss: 0.328858
tensor(0.0151, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-9.5745e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.093108
Average KL loss: 0.229089
Average total loss: 0.322197
tensor(0.0151, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(3.0165e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.095386
Average KL loss: 0.229291
Average total loss: 0.324677
tensor(0.0151, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-3.9855e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.094391
Average KL loss: 0.229458
Average total loss: 0.323849
tensor(0.0151, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(4.7304e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.097771
Average KL loss: 0.229592
Average total loss: 0.327363
tensor(0.0151, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-3.4157e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.094529
Average KL loss: 0.229798
Average total loss: 0.324328
tensor(0.0151, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-8.0085e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.100539
Average KL loss: 0.229948
Average total loss: 0.330487
tensor(0.0151, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-3.2830e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.095413
Average KL loss: 0.230126
Average total loss: 0.325539
tensor(0.0152, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(3.6123e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.091768
Average KL loss: 0.230265
Average total loss: 0.322033
tensor(0.0152, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-2.1877e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.088941
Average KL loss: 0.230344
Average total loss: 0.319285
tensor(0.0152, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-1.2298e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.099266
Average KL loss: 0.230398
Average total loss: 0.329664
tensor(0.0152, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(3.2624e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.088158
Average KL loss: 0.230521
Average total loss: 0.318679
tensor(0.0152, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-7.6790e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.090349
Average KL loss: 0.230566
Average total loss: 0.320915
tensor(0.0152, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-1.6024e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.092082
Average KL loss: 0.230636
Average total loss: 0.322718
tensor(0.0152, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-8.0912e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.090480
Average KL loss: 0.230792
Average total loss: 0.321272
tensor(0.0152, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-3.3304e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.089867
Average KL loss: 0.230859
Average total loss: 0.320726
tensor(0.0152, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(1.6179e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.091013
Average KL loss: 0.230922
Average total loss: 0.321935
tensor(0.0152, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(9.3822e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.089368
Average KL loss: 0.230965
Average total loss: 0.320333
tensor(0.0152, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(8.5186e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.093623
Average KL loss: 0.231051
Average total loss: 0.324674
tensor(0.0152, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(2.2637e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.086329
Average KL loss: 0.231132
Average total loss: 0.317461
tensor(0.0152, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(3.0142e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.089853
Average KL loss: 0.231091
Average total loss: 0.320944
tensor(0.0152, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(4.8164e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.091870
Average KL loss: 0.231131
Average total loss: 0.323001
tensor(0.0152, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-3.5866e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.090204
Average KL loss: 0.231265
Average total loss: 0.321468
tensor(0.0152, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(5.5023e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.085104
Average KL loss: 0.231393
Average total loss: 0.316497
tensor(0.0152, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-3.1928e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.086246
Average KL loss: 0.231427
Average total loss: 0.317673
tensor(0.0152, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-5.7409e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.088378
Average KL loss: 0.231541
Average total loss: 0.319919
tensor(0.0152, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(5.2673e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.087055
Average KL loss: 0.231659
Average total loss: 0.318714
tensor(0.0152, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(3.7373e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.085281
Average KL loss: 0.231698
Average total loss: 0.316979
tensor(0.0152, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(1.8870e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.084971
Average KL loss: 0.231661
Average total loss: 0.316633
tensor(0.0152, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.0352e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.087693
Average KL loss: 0.231670
Average total loss: 0.319363
tensor(0.0152, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(1.1315e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.083157
Average KL loss: 0.231691
Average total loss: 0.314848
tensor(0.0152, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-4.9247e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.083298
Average KL loss: 0.231642
Average total loss: 0.314940
tensor(0.0152, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-5.8497e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.086157
Average KL loss: 0.231619
Average total loss: 0.317776
tensor(0.0152, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-5.3109e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.088063
Average KL loss: 0.231675
Average total loss: 0.319737
tensor(0.0152, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.2788e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.088608
Average KL loss: 0.231772
Average total loss: 0.320380
tensor(0.0152, device='cuda:0') tensor(0.0408, device='cuda:0') tensor(-7.8115e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.084272
Average KL loss: 0.231838
Average total loss: 0.316110
tensor(0.0152, device='cuda:0') tensor(0.0409, device='cuda:0') tensor(-1.4671e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.084103
Average KL loss: 0.231882
Average total loss: 0.315985
tensor(0.0152, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-6.6168e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.088238
Average KL loss: 0.231880
Average total loss: 0.320117
tensor(0.0152, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-4.3910e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.082004
Average KL loss: 0.231979
Average total loss: 0.313983
tensor(0.0152, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(2.2633e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.077891
Average KL loss: 0.231918
Average total loss: 0.309810
tensor(0.0152, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(2.2400e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.081469
Average KL loss: 0.231832
Average total loss: 0.313302
tensor(0.0152, device='cuda:0') tensor(0.0412, device='cuda:0') tensor(-2.0567e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.083485
Average KL loss: 0.231804
Average total loss: 0.315289
tensor(0.0152, device='cuda:0') tensor(0.0412, device='cuda:0') tensor(-7.8547e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.086081
Average KL loss: 0.231816
Average total loss: 0.317897
tensor(0.0152, device='cuda:0') tensor(0.0413, device='cuda:0') tensor(-7.3150e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.084340
Average KL loss: 0.231875
Average total loss: 0.316215
tensor(0.0152, device='cuda:0') tensor(0.0414, device='cuda:0') tensor(-1.6279e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.082364
Average KL loss: 0.231843
Average total loss: 0.314208
tensor(0.0152, device='cuda:0') tensor(0.0414, device='cuda:0') tensor(-3.3340e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.081644
Average KL loss: 0.231830
Average total loss: 0.313474
tensor(0.0152, device='cuda:0') tensor(0.0415, device='cuda:0') tensor(-5.8084e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.079169
Average KL loss: 0.231789
Average total loss: 0.310958
tensor(0.0152, device='cuda:0') tensor(0.0415, device='cuda:0') tensor(-6.7486e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.081240
Average KL loss: 0.231777
Average total loss: 0.313017
tensor(0.0152, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(4.9482e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.082473
Average KL loss: 0.231770
Average total loss: 0.314243
tensor(0.0152, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(-2.3750e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.084389
Average KL loss: 0.231849
Average total loss: 0.316238
tensor(0.0152, device='cuda:0') tensor(0.0417, device='cuda:0') tensor(-1.7859e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.082264
Average KL loss: 0.231975
Average total loss: 0.314239
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-4.2901e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.076210
Average KL loss: 0.232003
Average total loss: 0.308213
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(1.9983e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.079976
Average KL loss: 0.231952
Average total loss: 0.311929
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-3.9523e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.081504
Average KL loss: 0.231906
Average total loss: 0.313410
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-5.1204e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.081928
Average KL loss: 0.231857
Average total loss: 0.313785
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-1.1733e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.084693
Average KL loss: 0.231816
Average total loss: 0.316509
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-3.1557e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.082244
Average KL loss: 0.231772
Average total loss: 0.314017
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-1.9795e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.077747
Average KL loss: 0.231735
Average total loss: 0.309482
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-8.9015e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.083966
Average KL loss: 0.231690
Average total loss: 0.315656
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-1.2192e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.075642
Average KL loss: 0.231651
Average total loss: 0.307293
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-2.9179e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.080689
Average KL loss: 0.231600
Average total loss: 0.312288
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-6.2815e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.082529
Average KL loss: 0.231556
Average total loss: 0.314085
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-1.2936e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.077294
Average KL loss: 0.231515
Average total loss: 0.308809
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-3.6740e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.079871
Average KL loss: 0.231472
Average total loss: 0.311343
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(5.8940e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.082420
Average KL loss: 0.231438
Average total loss: 0.313858
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(5.5533e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.081025
Average KL loss: 0.231401
Average total loss: 0.312426
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-3.9952e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.079373
Average KL loss: 0.231359
Average total loss: 0.310733
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-1.6791e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.080006
Average KL loss: 0.231311
Average total loss: 0.311317
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-7.1277e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.084819
Average KL loss: 0.231272
Average total loss: 0.316091
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-5.0289e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.080280
Average KL loss: 0.231234
Average total loss: 0.311514
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(2.1545e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.083169
Average KL loss: 0.231200
Average total loss: 0.314369
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-3.4451e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.080316
Average KL loss: 0.231177
Average total loss: 0.311493
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(1.1732e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.081346
Average KL loss: 0.231173
Average total loss: 0.312519
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-1.5220e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.081461
Average KL loss: 0.231169
Average total loss: 0.312630
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-5.4327e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.082640
Average KL loss: 0.231164
Average total loss: 0.313804
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-4.5851e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.077002
Average KL loss: 0.231160
Average total loss: 0.308161
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(4.9388e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.076305
Average KL loss: 0.231155
Average total loss: 0.307460
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-2.7161e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.078224
Average KL loss: 0.231150
Average total loss: 0.309375
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-1.8563e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.079130
Average KL loss: 0.231146
Average total loss: 0.310276
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-5.3713e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.081077
Average KL loss: 0.231142
Average total loss: 0.312218
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-1.4442e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.075517
Average KL loss: 0.231138
Average total loss: 0.306655
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(2.6415e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.081444
Average KL loss: 0.231133
Average total loss: 0.312577
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(2.8840e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.078699
Average KL loss: 0.231129
Average total loss: 0.309828
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-1.3123e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.081891
Average KL loss: 0.231125
Average total loss: 0.313016
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-4.0568e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.079462
Average KL loss: 0.231121
Average total loss: 0.310583
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-3.3937e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.078840
Average KL loss: 0.231115
Average total loss: 0.309956
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-1.4442e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.078037
Average KL loss: 0.231111
Average total loss: 0.309148
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(1.0367e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.082680
Average KL loss: 0.231106
Average total loss: 0.313786
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(2.8096e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.079780
Average KL loss: 0.231102
Average total loss: 0.310881
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(3.4368e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.079117
Average KL loss: 0.231097
Average total loss: 0.310213
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-2.9200e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.082352
Average KL loss: 0.231093
Average total loss: 0.313445
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(4.9099e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.080999
Average KL loss: 0.231089
Average total loss: 0.312088
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-4.1645e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.079235
Average KL loss: 0.231087
Average total loss: 0.310322
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-5.7315e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.077134
Average KL loss: 0.231086
Average total loss: 0.308220
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-4.5798e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.081322
Average KL loss: 0.231086
Average total loss: 0.312407
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(3.0787e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.075737
Average KL loss: 0.231085
Average total loss: 0.306822
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-3.7880e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.077840
Average KL loss: 0.231085
Average total loss: 0.308925
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-6.0431e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.077616
Average KL loss: 0.231084
Average total loss: 0.308700
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-3.3105e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.081194
Average KL loss: 0.231084
Average total loss: 0.312277
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-6.6721e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.076652
Average KL loss: 0.231083
Average total loss: 0.307736
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-4.2264e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.080734
Average KL loss: 0.231083
Average total loss: 0.311816
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(1.9229e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.078729
Average KL loss: 0.231082
Average total loss: 0.309811
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-6.5008e-09, device='cuda:0')
 Percentile value: -1.6522059809176426e-07
Non-zero model percentage: 5.497567176818848%, Non-zero mask percentage: 5.497567176818848%

--- Pruning Level [13/24]: ---
conv1.weight         | nonzeros =     881 /    1728             ( 50.98%) | total_pruned =     847 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1705 /   36864             (  4.63%) | total_pruned =   35159 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2117 /   36864             (  5.74%) | total_pruned =   34747 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1847 /   36864             (  5.01%) | total_pruned =   35017 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1951 /   36864             (  5.29%) | total_pruned =   34913 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3308 /   73728             (  4.49%) | total_pruned =   70420 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5167 /  147456             (  3.50%) | total_pruned =  142289 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1603 /    8192             ( 19.57%) | total_pruned =    6589 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4141 /  147456             (  2.81%) | total_pruned =  143315 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3923 /  147456             (  2.66%) | total_pruned =  143533 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8899 /  294912             (  3.02%) | total_pruned =  286013 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     132 /     256             ( 51.56%) | total_pruned =     124 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   12913 /  589824             (  2.19%) | total_pruned =  576911 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     109 /     256             ( 42.58%) | total_pruned =     147 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3424 /   32768             ( 10.45%) | total_pruned =   29344 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     129 /     256             ( 50.39%) | total_pruned =     127 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   19682 /  589824             (  3.34%) | total_pruned =  570142 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     110 /     256             ( 42.97%) | total_pruned =     146 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     110 /     256             ( 42.97%) | total_pruned =     146 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   18985 /  589824             (  3.22%) | total_pruned =  570839 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      67 /     256             ( 26.17%) | total_pruned =     189 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   19801 / 1179648             (  1.68%) | total_pruned = 1159847 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     244 /     512             ( 47.66%) | total_pruned =     268 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     457 /     512             ( 89.26%) | total_pruned =      55 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   24624 / 2359296             (  1.04%) | total_pruned = 2334672 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     266 /     512             ( 51.95%) | total_pruned =     246 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     300 /     512             ( 58.59%) | total_pruned =     212 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4427 /  131072             (  3.38%) | total_pruned =  126645 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     285 /     512             ( 55.66%) | total_pruned =     227 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     475 /     512             ( 92.77%) | total_pruned =      37 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     302 /     512             ( 58.98%) | total_pruned =     210 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  205137 / 2359296             (  8.69%) | total_pruned = 2154159 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     190 /     512             ( 37.11%) | total_pruned =     322 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     153 /     512             ( 29.88%) | total_pruned =     359 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  259629 / 2359296             ( 11.00%) | total_pruned = 2099667 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     383 /     512             ( 74.80%) | total_pruned =     129 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
linear.weight        | nonzeros =    1627 /    5120             ( 31.78%) | total_pruned =    3493 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 614560, pruned : 10564202, total: 11178762, Compression rate :      18.19x  ( 94.50% pruned)
Train Epoch: 21/100 Loss: 0.000072 Accuracy: 85.35 100.00 % Best test Accuracy: 86.09%
tensor(0.0152, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-9.2439e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.134216
Average KL loss: 0.225049
Average total loss: 0.359265
tensor(0.0150, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-3.2102e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.137687
Average KL loss: 0.223475
Average total loss: 0.361162
tensor(0.0150, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-2.6060e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.128878
Average KL loss: 0.223817
Average total loss: 0.352695
tensor(0.0150, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-1.6571e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.129851
Average KL loss: 0.224535
Average total loss: 0.354386
tensor(0.0150, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-4.5622e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.125631
Average KL loss: 0.225150
Average total loss: 0.350781
tensor(0.0150, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-1.4138e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.127959
Average KL loss: 0.225826
Average total loss: 0.353785
tensor(0.0150, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-2.3375e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.126685
Average KL loss: 0.226500
Average total loss: 0.353185
tensor(0.0150, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-9.7711e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.116152
Average KL loss: 0.227135
Average total loss: 0.343287
tensor(0.0151, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.2939e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.112015
Average KL loss: 0.227614
Average total loss: 0.339629
tensor(0.0151, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(2.0347e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.117413
Average KL loss: 0.228090
Average total loss: 0.345503
tensor(0.0151, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-5.5055e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.116101
Average KL loss: 0.228592
Average total loss: 0.344693
tensor(0.0151, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-2.2083e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.113564
Average KL loss: 0.229128
Average total loss: 0.342692
tensor(0.0151, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-7.4300e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.111463
Average KL loss: 0.229576
Average total loss: 0.341040
tensor(0.0151, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-5.7626e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.108261
Average KL loss: 0.229955
Average total loss: 0.338216
tensor(0.0152, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-9.8228e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.110999
Average KL loss: 0.230402
Average total loss: 0.341401
tensor(0.0152, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-2.8752e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.111446
Average KL loss: 0.230863
Average total loss: 0.342309
tensor(0.0152, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-7.4993e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.108110
Average KL loss: 0.231302
Average total loss: 0.339412
tensor(0.0152, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-5.1863e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.104779
Average KL loss: 0.231725
Average total loss: 0.336505
tensor(0.0152, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-9.7862e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.103289
Average KL loss: 0.232125
Average total loss: 0.335414
tensor(0.0152, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-1.3302e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.100419
Average KL loss: 0.232456
Average total loss: 0.332875
tensor(0.0152, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-2.6920e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.102826
Average KL loss: 0.232684
Average total loss: 0.335510
tensor(0.0152, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-4.8001e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.101103
Average KL loss: 0.232942
Average total loss: 0.334045
tensor(0.0153, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-7.9661e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.101595
Average KL loss: 0.233188
Average total loss: 0.334783
tensor(0.0153, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-3.0229e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.099619
Average KL loss: 0.233535
Average total loss: 0.333154
tensor(0.0153, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-1.5365e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.094730
Average KL loss: 0.233761
Average total loss: 0.328491
tensor(0.0153, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(1.7361e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.097279
Average KL loss: 0.233957
Average total loss: 0.331236
tensor(0.0153, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-1.8663e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.094308
Average KL loss: 0.234161
Average total loss: 0.328469
tensor(0.0153, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-2.9485e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.093376
Average KL loss: 0.234359
Average total loss: 0.327736
tensor(0.0153, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-6.3111e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.099384
Average KL loss: 0.234607
Average total loss: 0.333991
tensor(0.0153, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(4.2827e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.097661
Average KL loss: 0.234879
Average total loss: 0.332539
tensor(0.0153, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-4.6110e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.095980
Average KL loss: 0.235098
Average total loss: 0.331078
tensor(0.0153, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(3.5271e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.090517
Average KL loss: 0.235286
Average total loss: 0.325803
tensor(0.0153, device='cuda:0') tensor(0.0408, device='cuda:0') tensor(-5.3815e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.094810
Average KL loss: 0.235472
Average total loss: 0.330282
tensor(0.0153, device='cuda:0') tensor(0.0409, device='cuda:0') tensor(7.4309e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.094745
Average KL loss: 0.235669
Average total loss: 0.330414
tensor(0.0154, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-6.7293e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.089718
Average KL loss: 0.235821
Average total loss: 0.325539
tensor(0.0154, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-1.1360e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.090362
Average KL loss: 0.235959
Average total loss: 0.326321
tensor(0.0154, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(-6.8418e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.090005
Average KL loss: 0.236080
Average total loss: 0.326085
tensor(0.0154, device='cuda:0') tensor(0.0412, device='cuda:0') tensor(1.5122e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.095233
Average KL loss: 0.236155
Average total loss: 0.331389
tensor(0.0154, device='cuda:0') tensor(0.0413, device='cuda:0') tensor(-1.0203e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.087035
Average KL loss: 0.236351
Average total loss: 0.323386
tensor(0.0154, device='cuda:0') tensor(0.0414, device='cuda:0') tensor(-3.4852e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.089637
Average KL loss: 0.236459
Average total loss: 0.326097
tensor(0.0154, device='cuda:0') tensor(0.0415, device='cuda:0') tensor(2.3090e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.086862
Average KL loss: 0.236589
Average total loss: 0.323450
tensor(0.0154, device='cuda:0') tensor(0.0415, device='cuda:0') tensor(1.9468e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.079807
Average KL loss: 0.236672
Average total loss: 0.316479
tensor(0.0154, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(-8.9913e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.091401
Average KL loss: 0.236759
Average total loss: 0.328160
tensor(0.0154, device='cuda:0') tensor(0.0417, device='cuda:0') tensor(-1.1799e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.084907
Average KL loss: 0.236852
Average total loss: 0.321759
tensor(0.0154, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-3.0524e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.085771
Average KL loss: 0.236965
Average total loss: 0.322736
tensor(0.0154, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-2.0983e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.087560
Average KL loss: 0.237099
Average total loss: 0.324659
tensor(0.0154, device='cuda:0') tensor(0.0419, device='cuda:0') tensor(-7.8383e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.088188
Average KL loss: 0.237188
Average total loss: 0.325376
tensor(0.0154, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(-2.5768e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.082808
Average KL loss: 0.237279
Average total loss: 0.320087
tensor(0.0154, device='cuda:0') tensor(0.0421, device='cuda:0') tensor(-9.5306e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.084246
Average KL loss: 0.237307
Average total loss: 0.321552
tensor(0.0154, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(3.0362e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.080525
Average KL loss: 0.237352
Average total loss: 0.317877
tensor(0.0154, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-1.7398e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.082131
Average KL loss: 0.237283
Average total loss: 0.319414
tensor(0.0154, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(2.8176e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.087881
Average KL loss: 0.237304
Average total loss: 0.325185
tensor(0.0154, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-4.9419e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.078907
Average KL loss: 0.237394
Average total loss: 0.316301
tensor(0.0154, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-1.5671e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.087114
Average KL loss: 0.237452
Average total loss: 0.324566
tensor(0.0154, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(1.9997e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.087249
Average KL loss: 0.237545
Average total loss: 0.324795
tensor(0.0154, device='cuda:0') tensor(0.0426, device='cuda:0') tensor(7.1070e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.085154
Average KL loss: 0.237614
Average total loss: 0.322768
tensor(0.0154, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-2.3200e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.084152
Average KL loss: 0.237706
Average total loss: 0.321858
tensor(0.0154, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(3.8831e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.084866
Average KL loss: 0.237757
Average total loss: 0.322623
tensor(0.0154, device='cuda:0') tensor(0.0428, device='cuda:0') tensor(-6.3032e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.082516
Average KL loss: 0.237819
Average total loss: 0.320335
tensor(0.0154, device='cuda:0') tensor(0.0429, device='cuda:0') tensor(-1.7812e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.083935
Average KL loss: 0.237884
Average total loss: 0.321819
tensor(0.0154, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(4.3767e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.084322
Average KL loss: 0.237913
Average total loss: 0.322235
tensor(0.0154, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(4.2095e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.085663
Average KL loss: 0.238005
Average total loss: 0.323668
tensor(0.0154, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-1.6381e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.078506
Average KL loss: 0.238110
Average total loss: 0.316615
tensor(0.0154, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(4.3103e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.076104
Average KL loss: 0.238081
Average total loss: 0.314185
tensor(0.0154, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-3.0770e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.077961
Average KL loss: 0.238108
Average total loss: 0.316069
tensor(0.0154, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(-1.0152e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.079140
Average KL loss: 0.238142
Average total loss: 0.317282
tensor(0.0154, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(-5.5968e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.079801
Average KL loss: 0.238202
Average total loss: 0.318003
tensor(0.0154, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(-8.8694e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.078880
Average KL loss: 0.238319
Average total loss: 0.317199
tensor(0.0154, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-9.7764e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.079409
Average KL loss: 0.238287
Average total loss: 0.317696
tensor(0.0154, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-5.2233e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.078116
Average KL loss: 0.238330
Average total loss: 0.316446
tensor(0.0154, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-2.5361e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.076620
Average KL loss: 0.238339
Average total loss: 0.314960
tensor(0.0154, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-6.4965e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.079870
Average KL loss: 0.238336
Average total loss: 0.318206
tensor(0.0154, device='cuda:0') tensor(0.0438, device='cuda:0') tensor(-6.6124e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.077585
Average KL loss: 0.238286
Average total loss: 0.315871
tensor(0.0154, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-2.9389e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.081030
Average KL loss: 0.238263
Average total loss: 0.319293
tensor(0.0154, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-5.5998e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.077082
Average KL loss: 0.238339
Average total loss: 0.315421
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(2.0247e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.079906
Average KL loss: 0.238315
Average total loss: 0.318221
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-4.0576e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.076381
Average KL loss: 0.238287
Average total loss: 0.314668
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-3.7932e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.079264
Average KL loss: 0.238253
Average total loss: 0.317517
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(5.9181e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.077949
Average KL loss: 0.238219
Average total loss: 0.316168
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-4.3582e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.077417
Average KL loss: 0.238189
Average total loss: 0.315606
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-3.0715e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.076523
Average KL loss: 0.238156
Average total loss: 0.314679
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(1.8317e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.074902
Average KL loss: 0.238121
Average total loss: 0.313023
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-4.4051e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.076679
Average KL loss: 0.238094
Average total loss: 0.314773
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-6.4449e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.072816
Average KL loss: 0.238065
Average total loss: 0.310881
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-6.5013e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.080646
Average KL loss: 0.238038
Average total loss: 0.318684
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-3.7584e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.075582
Average KL loss: 0.238009
Average total loss: 0.313591
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(2.4829e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.075207
Average KL loss: 0.237976
Average total loss: 0.313183
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-8.4889e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.074585
Average KL loss: 0.237947
Average total loss: 0.312532
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-5.7474e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.078943
Average KL loss: 0.237916
Average total loss: 0.316859
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(1.5685e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.078907
Average KL loss: 0.237881
Average total loss: 0.316788
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(1.6541e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.073144
Average KL loss: 0.237847
Average total loss: 0.310991
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(8.6949e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.076682
Average KL loss: 0.237815
Average total loss: 0.314498
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-2.9891e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.079230
Average KL loss: 0.237788
Average total loss: 0.317018
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(1.8832e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.074733
Average KL loss: 0.237757
Average total loss: 0.312491
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-2.1402e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.076477
Average KL loss: 0.237723
Average total loss: 0.314199
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(1.8521e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.075656
Average KL loss: 0.237701
Average total loss: 0.313357
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(1.0590e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.080059
Average KL loss: 0.237697
Average total loss: 0.317756
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-3.9117e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.073943
Average KL loss: 0.237694
Average total loss: 0.311636
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(1.0051e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.073343
Average KL loss: 0.237690
Average total loss: 0.311033
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(7.5373e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.077428
Average KL loss: 0.237688
Average total loss: 0.315116
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-5.6344e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.075103
Average KL loss: 0.237684
Average total loss: 0.312787
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-4.1144e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.074927
Average KL loss: 0.237680
Average total loss: 0.312606
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.7689e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.076731
Average KL loss: 0.237676
Average total loss: 0.314407
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(3.7274e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.075207
Average KL loss: 0.237673
Average total loss: 0.312879
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.7458e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.077366
Average KL loss: 0.237670
Average total loss: 0.315036
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-5.5695e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.075114
Average KL loss: 0.237667
Average total loss: 0.312781
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.1835e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.074553
Average KL loss: 0.237665
Average total loss: 0.312218
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-2.2395e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.074499
Average KL loss: 0.237665
Average total loss: 0.312163
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(8.0356e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.078591
Average KL loss: 0.237664
Average total loss: 0.316255
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(3.9315e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.080250
Average KL loss: 0.237664
Average total loss: 0.317914
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-4.2916e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.073553
Average KL loss: 0.237664
Average total loss: 0.311217
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-4.9688e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.074677
Average KL loss: 0.237663
Average total loss: 0.312341
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-3.7314e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.075892
Average KL loss: 0.237663
Average total loss: 0.313556
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.2749e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.080241
Average KL loss: 0.237663
Average total loss: 0.317904
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(2.5780e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.077920
Average KL loss: 0.237662
Average total loss: 0.315582
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-5.1606e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.072143
Average KL loss: 0.237662
Average total loss: 0.309805
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-4.9101e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.076868
Average KL loss: 0.237662
Average total loss: 0.314530
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.0359e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.080318
Average KL loss: 0.237661
Average total loss: 0.317979
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-3.4326e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.072477
Average KL loss: 0.237661
Average total loss: 0.310138
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-3.4500e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.081146
Average KL loss: 0.237661
Average total loss: 0.318807
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(3.1773e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.077745
Average KL loss: 0.237660
Average total loss: 0.315405
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-2.4099e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.075577
Average KL loss: 0.237660
Average total loss: 0.313237
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-2.6521e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.078053
Average KL loss: 0.237660
Average total loss: 0.315713
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(2.3492e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.076118
Average KL loss: 0.237659
Average total loss: 0.313777
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-7.5446e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.078362
Average KL loss: 0.237659
Average total loss: 0.316021
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.0627e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.078301
Average KL loss: 0.237659
Average total loss: 0.315960
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.2226e-09, device='cuda:0')
 Percentile value: -1.652374521654565e-07
Non-zero model percentage: 4.398054122924805%, Non-zero mask percentage: 4.398054122924805%

--- Pruning Level [14/24]: ---
conv1.weight         | nonzeros =     872 /    1728             ( 50.46%) | total_pruned =     856 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1601 /   36864             (  4.34%) | total_pruned =   35263 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2010 /   36864             (  5.45%) | total_pruned =   34854 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1753 /   36864             (  4.76%) | total_pruned =   35111 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1848 /   36864             (  5.01%) | total_pruned =   35016 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3142 /   73728             (  4.26%) | total_pruned =   70586 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4858 /  147456             (  3.29%) | total_pruned =  142598 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1567 /    8192             ( 19.13%) | total_pruned =    6625 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3581 /  147456             (  2.43%) | total_pruned =  143875 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3423 /  147456             (  2.32%) | total_pruned =  144033 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8318 /  294912             (  2.82%) | total_pruned =  286594 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     187 /     256             ( 73.05%) | total_pruned =      69 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   11898 /  589824             (  2.02%) | total_pruned =  577926 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     150 /     256             ( 58.59%) | total_pruned =     106 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     107 /     256             ( 41.80%) | total_pruned =     149 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3290 /   32768             ( 10.04%) | total_pruned =   29478 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     121 /     256             ( 47.27%) | total_pruned =     135 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   15626 /  589824             (  2.65%) | total_pruned =  574198 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      90 /     256             ( 35.16%) | total_pruned =     166 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     101 /     256             ( 39.45%) | total_pruned =     155 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   15110 /  589824             (  2.56%) | total_pruned =  574714 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      66 /     256             ( 25.78%) | total_pruned =     190 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   17765 / 1179648             (  1.51%) | total_pruned = 1161883 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     211 /     512             ( 41.21%) | total_pruned =     301 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     448 /     512             ( 87.50%) | total_pruned =      64 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   20730 / 2359296             (  0.88%) | total_pruned = 2338566 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     240 /     512             ( 46.88%) | total_pruned =     272 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3993 /  131072             (  3.05%) | total_pruned =  127079 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     257 /     512             ( 50.20%) | total_pruned =     255 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     473 /     512             ( 92.38%) | total_pruned =      39 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     285 /     512             ( 55.66%) | total_pruned =     227 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  159330 / 2359296             (  6.75%) | total_pruned = 2199966 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     131 /     512             ( 25.59%) | total_pruned =     381 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  200927 / 2359296             (  8.52%) | total_pruned = 2158369 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     179 /     512             ( 34.96%) | total_pruned =     333 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     379 /     512             ( 74.02%) | total_pruned =     133 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
linear.weight        | nonzeros =    1595 /    5120             ( 31.15%) | total_pruned =    3525 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 491648, pruned : 10687114, total: 11178762, Compression rate :      22.74x  ( 95.60% pruned)
Train Epoch: 21/100 Loss: 0.000026 Accuracy: 85.13 100.00 % Best test Accuracy: 85.45%
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-9.4004e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.135570
Average KL loss: 0.232092
Average total loss: 0.367662
tensor(0.0151, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-8.7703e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.131492
Average KL loss: 0.230600
Average total loss: 0.362092
tensor(0.0151, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-1.1346e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.134469
Average KL loss: 0.230886
Average total loss: 0.365356
tensor(0.0151, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-3.9767e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.129663
Average KL loss: 0.231453
Average total loss: 0.361116
tensor(0.0151, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-1.2325e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.123357
Average KL loss: 0.232076
Average total loss: 0.355433
tensor(0.0151, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-1.1421e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.122813
Average KL loss: 0.232732
Average total loss: 0.355545
tensor(0.0152, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-6.7055e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.121098
Average KL loss: 0.233340
Average total loss: 0.354438
tensor(0.0152, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-6.4421e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.116650
Average KL loss: 0.233838
Average total loss: 0.350488
tensor(0.0152, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(-4.5444e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.114721
Average KL loss: 0.234350
Average total loss: 0.349071
tensor(0.0152, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.4735e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.113618
Average KL loss: 0.234854
Average total loss: 0.348472
tensor(0.0152, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-1.1968e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.111557
Average KL loss: 0.235339
Average total loss: 0.346896
tensor(0.0153, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.3791e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.118538
Average KL loss: 0.235870
Average total loss: 0.354408
tensor(0.0153, device='cuda:0') tensor(0.0409, device='cuda:0') tensor(-8.8802e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.113548
Average KL loss: 0.236436
Average total loss: 0.349984
tensor(0.0153, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-4.7310e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.110048
Average KL loss: 0.236896
Average total loss: 0.346944
tensor(0.0153, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(-9.2818e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.111424
Average KL loss: 0.237342
Average total loss: 0.348766
tensor(0.0153, device='cuda:0') tensor(0.0413, device='cuda:0') tensor(-6.3843e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.103893
Average KL loss: 0.237788
Average total loss: 0.341681
tensor(0.0153, device='cuda:0') tensor(0.0414, device='cuda:0') tensor(7.6983e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.104203
Average KL loss: 0.238084
Average total loss: 0.342287
tensor(0.0154, device='cuda:0') tensor(0.0415, device='cuda:0') tensor(-6.4060e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.104004
Average KL loss: 0.238376
Average total loss: 0.342380
tensor(0.0154, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(-1.6922e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.102062
Average KL loss: 0.238675
Average total loss: 0.340737
tensor(0.0154, device='cuda:0') tensor(0.0417, device='cuda:0') tensor(-7.8707e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.105162
Average KL loss: 0.239048
Average total loss: 0.344209
tensor(0.0154, device='cuda:0') tensor(0.0419, device='cuda:0') tensor(1.5729e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.102593
Average KL loss: 0.239448
Average total loss: 0.342040
tensor(0.0154, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(-5.6362e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.101151
Average KL loss: 0.239732
Average total loss: 0.340884
tensor(0.0154, device='cuda:0') tensor(0.0421, device='cuda:0') tensor(-1.1154e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.099833
Average KL loss: 0.240057
Average total loss: 0.339890
tensor(0.0154, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-5.3869e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.096773
Average KL loss: 0.240330
Average total loss: 0.337103
tensor(0.0154, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(2.1900e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.096345
Average KL loss: 0.240646
Average total loss: 0.336991
tensor(0.0155, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(1.8799e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.094442
Average KL loss: 0.240899
Average total loss: 0.335341
tensor(0.0155, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-1.9395e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.095025
Average KL loss: 0.241070
Average total loss: 0.336095
tensor(0.0155, device='cuda:0') tensor(0.0426, device='cuda:0') tensor(-1.4230e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.092698
Average KL loss: 0.241280
Average total loss: 0.333978
tensor(0.0155, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-1.4689e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.095586
Average KL loss: 0.241455
Average total loss: 0.337040
tensor(0.0155, device='cuda:0') tensor(0.0428, device='cuda:0') tensor(-1.8370e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.094582
Average KL loss: 0.241639
Average total loss: 0.336221
tensor(0.0155, device='cuda:0') tensor(0.0429, device='cuda:0') tensor(-2.3551e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.093697
Average KL loss: 0.241874
Average total loss: 0.335571
tensor(0.0155, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(-7.8244e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.091531
Average KL loss: 0.242128
Average total loss: 0.333659
tensor(0.0155, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-9.9059e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.093126
Average KL loss: 0.242303
Average total loss: 0.335429
tensor(0.0155, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-1.1647e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.089832
Average KL loss: 0.242478
Average total loss: 0.332310
tensor(0.0155, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(1.2064e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.085820
Average KL loss: 0.242583
Average total loss: 0.328403
tensor(0.0155, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(2.8369e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.090085
Average KL loss: 0.242779
Average total loss: 0.332865
tensor(0.0155, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-6.9393e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.093433
Average KL loss: 0.242952
Average total loss: 0.336386
tensor(0.0156, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(3.9903e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.088396
Average KL loss: 0.243160
Average total loss: 0.331556
tensor(0.0156, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-8.3091e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.088449
Average KL loss: 0.243303
Average total loss: 0.331752
tensor(0.0156, device='cuda:0') tensor(0.0438, device='cuda:0') tensor(-4.0875e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.085023
Average KL loss: 0.243349
Average total loss: 0.328372
tensor(0.0156, device='cuda:0') tensor(0.0438, device='cuda:0') tensor(-4.9890e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.087942
Average KL loss: 0.243457
Average total loss: 0.331398
tensor(0.0156, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-5.9526e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.086295
Average KL loss: 0.243539
Average total loss: 0.329833
tensor(0.0156, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-5.6884e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.087835
Average KL loss: 0.243657
Average total loss: 0.331492
tensor(0.0156, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-5.3042e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.085786
Average KL loss: 0.243845
Average total loss: 0.329631
tensor(0.0156, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-5.9395e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.081527
Average KL loss: 0.243939
Average total loss: 0.325467
tensor(0.0156, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-2.4490e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.082428
Average KL loss: 0.243969
Average total loss: 0.326397
tensor(0.0156, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-7.5016e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.085872
Average KL loss: 0.243998
Average total loss: 0.329870
tensor(0.0156, device='cuda:0') tensor(0.0444, device='cuda:0') tensor(-1.3357e-11, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.082638
Average KL loss: 0.244089
Average total loss: 0.326727
tensor(0.0156, device='cuda:0') tensor(0.0445, device='cuda:0') tensor(-2.4506e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.084248
Average KL loss: 0.244209
Average total loss: 0.328457
tensor(0.0156, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-2.4914e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.080114
Average KL loss: 0.244278
Average total loss: 0.324392
tensor(0.0156, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(4.6472e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.081360
Average KL loss: 0.244260
Average total loss: 0.325620
tensor(0.0156, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-5.0948e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.084764
Average KL loss: 0.244267
Average total loss: 0.329031
tensor(0.0156, device='cuda:0') tensor(0.0448, device='cuda:0') tensor(-4.0354e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.083097
Average KL loss: 0.244310
Average total loss: 0.327407
tensor(0.0156, device='cuda:0') tensor(0.0448, device='cuda:0') tensor(-2.1163e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.083811
Average KL loss: 0.244389
Average total loss: 0.328199
tensor(0.0156, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(-4.5941e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.087529
Average KL loss: 0.244494
Average total loss: 0.332023
tensor(0.0156, device='cuda:0') tensor(0.0450, device='cuda:0') tensor(-4.2659e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.082235
Average KL loss: 0.244667
Average total loss: 0.326901
tensor(0.0156, device='cuda:0') tensor(0.0451, device='cuda:0') tensor(-2.5927e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.081242
Average KL loss: 0.244735
Average total loss: 0.325977
tensor(0.0156, device='cuda:0') tensor(0.0452, device='cuda:0') tensor(-9.5227e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.080383
Average KL loss: 0.244847
Average total loss: 0.325230
tensor(0.0156, device='cuda:0') tensor(0.0453, device='cuda:0') tensor(-6.5411e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.084612
Average KL loss: 0.244886
Average total loss: 0.329499
tensor(0.0156, device='cuda:0') tensor(0.0453, device='cuda:0') tensor(1.1768e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.078693
Average KL loss: 0.244949
Average total loss: 0.323642
tensor(0.0156, device='cuda:0') tensor(0.0454, device='cuda:0') tensor(-2.1610e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.076150
Average KL loss: 0.244955
Average total loss: 0.321106
tensor(0.0156, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-7.2103e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.082440
Average KL loss: 0.244946
Average total loss: 0.327386
tensor(0.0156, device='cuda:0') tensor(0.0456, device='cuda:0') tensor(-5.9857e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.080289
Average KL loss: 0.245013
Average total loss: 0.325302
tensor(0.0156, device='cuda:0') tensor(0.0456, device='cuda:0') tensor(-2.4311e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.077078
Average KL loss: 0.245056
Average total loss: 0.322134
tensor(0.0156, device='cuda:0') tensor(0.0457, device='cuda:0') tensor(1.0480e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.072908
Average KL loss: 0.245026
Average total loss: 0.317934
tensor(0.0156, device='cuda:0') tensor(0.0457, device='cuda:0') tensor(-9.7425e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.078233
Average KL loss: 0.244986
Average total loss: 0.323219
tensor(0.0156, device='cuda:0') tensor(0.0458, device='cuda:0') tensor(-3.3650e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.079644
Average KL loss: 0.244982
Average total loss: 0.324627
tensor(0.0156, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(1.0025e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.072225
Average KL loss: 0.244966
Average total loss: 0.317191
tensor(0.0156, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(-2.7703e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.078107
Average KL loss: 0.244974
Average total loss: 0.323081
tensor(0.0156, device='cuda:0') tensor(0.0460, device='cuda:0') tensor(-1.1501e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.082146
Average KL loss: 0.245020
Average total loss: 0.327166
tensor(0.0156, device='cuda:0') tensor(0.0461, device='cuda:0') tensor(8.2876e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.074705
Average KL loss: 0.245080
Average total loss: 0.319785
tensor(0.0156, device='cuda:0') tensor(0.0461, device='cuda:0') tensor(-2.9370e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.076904
Average KL loss: 0.245168
Average total loss: 0.322072
tensor(0.0157, device='cuda:0') tensor(0.0462, device='cuda:0') tensor(-3.6796e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.074668
Average KL loss: 0.245169
Average total loss: 0.319836
tensor(0.0157, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-6.8704e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.073513
Average KL loss: 0.245169
Average total loss: 0.318683
tensor(0.0157, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-6.7517e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.078960
Average KL loss: 0.245190
Average total loss: 0.324150
tensor(0.0157, device='cuda:0') tensor(0.0464, device='cuda:0') tensor(1.7202e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.077310
Average KL loss: 0.245256
Average total loss: 0.322566
tensor(0.0157, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(5.7126e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.075300
Average KL loss: 0.245260
Average total loss: 0.320560
tensor(0.0157, device='cuda:0') tensor(0.0466, device='cuda:0') tensor(-3.2567e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.076426
Average KL loss: 0.245289
Average total loss: 0.321716
tensor(0.0157, device='cuda:0') tensor(0.0466, device='cuda:0') tensor(-4.4174e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.072828
Average KL loss: 0.245325
Average total loss: 0.318154
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.5475e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.075573
Average KL loss: 0.245292
Average total loss: 0.320865
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(7.6879e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.072146
Average KL loss: 0.245257
Average total loss: 0.317403
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.8072e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.075623
Average KL loss: 0.245225
Average total loss: 0.320848
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-3.7130e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.075939
Average KL loss: 0.245207
Average total loss: 0.321146
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.8922e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.074306
Average KL loss: 0.245174
Average total loss: 0.319480
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(3.0508e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.071865
Average KL loss: 0.245148
Average total loss: 0.317013
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.6669e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.073674
Average KL loss: 0.245119
Average total loss: 0.318793
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-2.9834e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.069613
Average KL loss: 0.245097
Average total loss: 0.314710
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-4.0260e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.071722
Average KL loss: 0.245065
Average total loss: 0.316787
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-5.1684e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.073666
Average KL loss: 0.245034
Average total loss: 0.318700
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(7.5002e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.073985
Average KL loss: 0.245005
Average total loss: 0.318990
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-2.0964e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.076436
Average KL loss: 0.244979
Average total loss: 0.321415
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-2.2426e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.072593
Average KL loss: 0.244957
Average total loss: 0.317550
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.3190e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.073978
Average KL loss: 0.244936
Average total loss: 0.318915
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(4.6127e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.070897
Average KL loss: 0.244908
Average total loss: 0.315805
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.7048e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.072258
Average KL loss: 0.244873
Average total loss: 0.317131
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.2894e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.073227
Average KL loss: 0.244845
Average total loss: 0.318071
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-3.4791e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.076146
Average KL loss: 0.244822
Average total loss: 0.320967
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-7.4090e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.070552
Average KL loss: 0.244803
Average total loss: 0.315355
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.6693e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.076162
Average KL loss: 0.244787
Average total loss: 0.320949
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.0238e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.071224
Average KL loss: 0.244784
Average total loss: 0.316008
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(3.9545e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.071051
Average KL loss: 0.244781
Average total loss: 0.315832
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(7.5934e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.076484
Average KL loss: 0.244778
Average total loss: 0.321262
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(2.9063e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.071965
Average KL loss: 0.244776
Average total loss: 0.316741
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-3.8612e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.069831
Average KL loss: 0.244773
Average total loss: 0.314603
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-3.6098e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.070824
Average KL loss: 0.244770
Average total loss: 0.315594
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(5.1412e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.070028
Average KL loss: 0.244767
Average total loss: 0.314795
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-4.4383e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.073588
Average KL loss: 0.244764
Average total loss: 0.318352
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.9610e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.075910
Average KL loss: 0.244762
Average total loss: 0.320671
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.1001e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.073120
Average KL loss: 0.244759
Average total loss: 0.317879
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.6860e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.075182
Average KL loss: 0.244756
Average total loss: 0.319939
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-7.4805e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.073250
Average KL loss: 0.244754
Average total loss: 0.318004
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(2.0122e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.074200
Average KL loss: 0.244751
Average total loss: 0.318951
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-5.7295e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.073938
Average KL loss: 0.244748
Average total loss: 0.318686
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.0547e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.068385
Average KL loss: 0.244746
Average total loss: 0.313130
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.7900e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.072720
Average KL loss: 0.244743
Average total loss: 0.317463
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(2.5170e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.072858
Average KL loss: 0.244740
Average total loss: 0.317597
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-2.0872e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.068841
Average KL loss: 0.244737
Average total loss: 0.313578
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-6.6849e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.076460
Average KL loss: 0.244734
Average total loss: 0.321193
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-2.8843e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.068563
Average KL loss: 0.244732
Average total loss: 0.313295
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-2.9505e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.074033
Average KL loss: 0.244729
Average total loss: 0.318762
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.1252e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.068612
Average KL loss: 0.244725
Average total loss: 0.313337
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-4.0750e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.075317
Average KL loss: 0.244722
Average total loss: 0.320040
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-4.5586e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.070271
Average KL loss: 0.244720
Average total loss: 0.314991
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.2579e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.071189
Average KL loss: 0.244716
Average total loss: 0.315905
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(2.1319e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.068937
Average KL loss: 0.244712
Average total loss: 0.313650
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(2.4681e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.073326
Average KL loss: 0.244711
Average total loss: 0.318037
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.8154e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.071350
Average KL loss: 0.244710
Average total loss: 0.316061
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-5.5143e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.073000
Average KL loss: 0.244710
Average total loss: 0.317710
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(3.6016e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.072368
Average KL loss: 0.244710
Average total loss: 0.317078
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-4.3285e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.074876
Average KL loss: 0.244709
Average total loss: 0.319586
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.1140e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.069106
Average KL loss: 0.244709
Average total loss: 0.313815
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.2416e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.075227
Average KL loss: 0.244709
Average total loss: 0.319936
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-4.7780e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.072483
Average KL loss: 0.244709
Average total loss: 0.317192
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(4.4529e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.074759
Average KL loss: 0.244708
Average total loss: 0.319467
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-8.0341e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.074295
Average KL loss: 0.244708
Average total loss: 0.319003
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-6.3250e-09, device='cuda:0')
 Percentile value: -1.652316683475874e-07
Non-zero model percentage: 3.5184483528137207%, Non-zero mask percentage: 3.5184483528137207%

--- Pruning Level [15/24]: ---
conv1.weight         | nonzeros =     865 /    1728             ( 50.06%) | total_pruned =     863 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1526 /   36864             (  4.14%) | total_pruned =   35338 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1900 /   36864             (  5.15%) | total_pruned =   34964 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1658 /   36864             (  4.50%) | total_pruned =   35206 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1746 /   36864             (  4.74%) | total_pruned =   35118 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3001 /   73728             (  4.07%) | total_pruned =   70727 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4560 /  147456             (  3.09%) | total_pruned =  142896 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1532 /    8192             ( 18.70%) | total_pruned =    6660 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3163 /  147456             (  2.15%) | total_pruned =  144293 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2993 /  147456             (  2.03%) | total_pruned =  144463 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7806 /  294912             (  2.65%) | total_pruned =  287106 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     106 /     256             ( 41.41%) | total_pruned =     150 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     181 /     256             ( 70.70%) | total_pruned =      75 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   11068 /  589824             (  1.88%) | total_pruned =  578756 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     146 /     256             ( 57.03%) | total_pruned =     110 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3159 /   32768             (  9.64%) | total_pruned =   29609 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   12480 /  589824             (  2.12%) | total_pruned =  577344 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      84 /     256             ( 32.81%) | total_pruned =     172 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      92 /     256             ( 35.94%) | total_pruned =     164 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   11947 /  589824             (  2.03%) | total_pruned =  577877 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     119 /     256             ( 46.48%) | total_pruned =     137 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   16151 / 1179648             (  1.37%) | total_pruned = 1163497 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     188 /     512             ( 36.72%) | total_pruned =     324 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     440 /     512             ( 85.94%) | total_pruned =      72 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   17639 / 2359296             (  0.75%) | total_pruned = 2341657 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     214 /     512             ( 41.80%) | total_pruned =     298 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     264 /     512             ( 51.56%) | total_pruned =     248 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3551 /  131072             (  2.71%) | total_pruned =  127521 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     226 /     512             ( 44.14%) | total_pruned =     286 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     469 /     512             ( 91.60%) | total_pruned =      43 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     273 /     512             ( 53.32%) | total_pruned =     239 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  122314 / 2359296             (  5.18%) | total_pruned = 2236982 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     138 /     512             ( 26.95%) | total_pruned =     374 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     112 /     512             ( 21.88%) | total_pruned =     400 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  154575 / 2359296             (  6.55%) | total_pruned = 2204721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     164 /     512             ( 32.03%) | total_pruned =     348 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
linear.weight        | nonzeros =    1567 /    5120             ( 30.61%) | total_pruned =    3553 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 393319, pruned : 10785443, total: 11178762, Compression rate :      28.42x  ( 96.48% pruned)
Train Epoch: 21/100 Loss: 0.001840 Accuracy: 85.51 100.00 % Best test Accuracy: 85.57%
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-6.1107e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.111527
Average KL loss: 0.239011
Average total loss: 0.350538
tensor(0.0153, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(-1.4660e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.112370
Average KL loss: 0.237199
Average total loss: 0.349569
tensor(0.0152, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-6.8770e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.114484
Average KL loss: 0.237235
Average total loss: 0.351719
tensor(0.0152, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(-8.2746e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.115850
Average KL loss: 0.237664
Average total loss: 0.353514
tensor(0.0152, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(-4.9657e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.106705
Average KL loss: 0.238095
Average total loss: 0.344800
tensor(0.0153, device='cuda:0') tensor(0.0421, device='cuda:0') tensor(-1.2013e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.117969
Average KL loss: 0.238587
Average total loss: 0.356556
tensor(0.0153, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-1.0239e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.108465
Average KL loss: 0.239133
Average total loss: 0.347599
tensor(0.0153, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(-8.3000e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.104309
Average KL loss: 0.239576
Average total loss: 0.343885
tensor(0.0153, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(4.8785e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.103291
Average KL loss: 0.239998
Average total loss: 0.343288
tensor(0.0153, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-1.1410e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.103609
Average KL loss: 0.240435
Average total loss: 0.344045
tensor(0.0154, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-8.3424e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.106240
Average KL loss: 0.240881
Average total loss: 0.347121
tensor(0.0154, device='cuda:0') tensor(0.0428, device='cuda:0') tensor(-7.4522e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.098471
Average KL loss: 0.241279
Average total loss: 0.339750
tensor(0.0154, device='cuda:0') tensor(0.0429, device='cuda:0') tensor(-9.4911e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.101241
Average KL loss: 0.241645
Average total loss: 0.342886
tensor(0.0154, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(-3.9503e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.098405
Average KL loss: 0.241945
Average total loss: 0.340350
tensor(0.0154, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-1.1575e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.096367
Average KL loss: 0.242285
Average total loss: 0.338653
tensor(0.0154, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(-9.5060e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.093701
Average KL loss: 0.242604
Average total loss: 0.336305
tensor(0.0155, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(-2.7611e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.092827
Average KL loss: 0.242824
Average total loss: 0.335651
tensor(0.0155, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-1.0596e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.089961
Average KL loss: 0.243090
Average total loss: 0.333051
tensor(0.0155, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-6.0622e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.090888
Average KL loss: 0.243417
Average total loss: 0.334305
tensor(0.0155, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-2.9471e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.088955
Average KL loss: 0.243646
Average total loss: 0.332601
tensor(0.0155, device='cuda:0') tensor(0.0438, device='cuda:0') tensor(-5.8453e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.088633
Average KL loss: 0.243845
Average total loss: 0.332478
tensor(0.0155, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-8.8464e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.085794
Average KL loss: 0.244047
Average total loss: 0.329841
tensor(0.0155, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.2405e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.091083
Average KL loss: 0.244268
Average total loss: 0.335352
tensor(0.0155, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-1.1663e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.087366
Average KL loss: 0.244524
Average total loss: 0.331890
tensor(0.0155, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-3.0897e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.085800
Average KL loss: 0.244715
Average total loss: 0.330514
tensor(0.0156, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(1.2896e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.084986
Average KL loss: 0.244873
Average total loss: 0.329859
tensor(0.0156, device='cuda:0') tensor(0.0444, device='cuda:0') tensor(-9.1198e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.086665
Average KL loss: 0.244979
Average total loss: 0.331644
tensor(0.0156, device='cuda:0') tensor(0.0445, device='cuda:0') tensor(-2.7201e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.087789
Average KL loss: 0.245165
Average total loss: 0.332954
tensor(0.0156, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-3.1175e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.079781
Average KL loss: 0.245339
Average total loss: 0.325119
tensor(0.0156, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-3.4073e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.085810
Average KL loss: 0.245377
Average total loss: 0.331187
tensor(0.0156, device='cuda:0') tensor(0.0448, device='cuda:0') tensor(-5.2110e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.082663
Average KL loss: 0.245471
Average total loss: 0.328134
tensor(0.0156, device='cuda:0') tensor(0.0448, device='cuda:0') tensor(-4.4141e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.083842
Average KL loss: 0.245529
Average total loss: 0.329371
tensor(0.0156, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(-9.6965e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.080444
Average KL loss: 0.245679
Average total loss: 0.326123
tensor(0.0156, device='cuda:0') tensor(0.0450, device='cuda:0') tensor(2.8289e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.081853
Average KL loss: 0.245824
Average total loss: 0.327678
tensor(0.0156, device='cuda:0') tensor(0.0451, device='cuda:0') tensor(-1.3556e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.082974
Average KL loss: 0.245951
Average total loss: 0.328925
tensor(0.0156, device='cuda:0') tensor(0.0452, device='cuda:0') tensor(-8.3615e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.081926
Average KL loss: 0.246062
Average total loss: 0.327988
tensor(0.0156, device='cuda:0') tensor(0.0453, device='cuda:0') tensor(-3.1753e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.082062
Average KL loss: 0.246226
Average total loss: 0.328288
tensor(0.0156, device='cuda:0') tensor(0.0454, device='cuda:0') tensor(-6.9818e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.079836
Average KL loss: 0.246385
Average total loss: 0.326220
tensor(0.0156, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-1.1618e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.080699
Average KL loss: 0.246438
Average total loss: 0.327137
tensor(0.0156, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(5.3552e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.073121
Average KL loss: 0.246509
Average total loss: 0.319630
tensor(0.0156, device='cuda:0') tensor(0.0456, device='cuda:0') tensor(-7.3759e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.076524
Average KL loss: 0.246503
Average total loss: 0.323027
tensor(0.0156, device='cuda:0') tensor(0.0457, device='cuda:0') tensor(-5.1032e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.079152
Average KL loss: 0.246575
Average total loss: 0.325726
tensor(0.0156, device='cuda:0') tensor(0.0458, device='cuda:0') tensor(1.7107e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.079693
Average KL loss: 0.246683
Average total loss: 0.326376
tensor(0.0156, device='cuda:0') tensor(0.0458, device='cuda:0') tensor(2.8727e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.076352
Average KL loss: 0.246737
Average total loss: 0.323089
tensor(0.0157, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(3.6390e-11, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.077372
Average KL loss: 0.246796
Average total loss: 0.324168
tensor(0.0157, device='cuda:0') tensor(0.0460, device='cuda:0') tensor(-9.5961e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.078720
Average KL loss: 0.246862
Average total loss: 0.325582
tensor(0.0157, device='cuda:0') tensor(0.0461, device='cuda:0') tensor(-8.3713e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.076891
Average KL loss: 0.246957
Average total loss: 0.323847
tensor(0.0157, device='cuda:0') tensor(0.0462, device='cuda:0') tensor(-3.0489e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.073567
Average KL loss: 0.247027
Average total loss: 0.320594
tensor(0.0157, device='cuda:0') tensor(0.0462, device='cuda:0') tensor(-1.0022e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.076343
Average KL loss: 0.247015
Average total loss: 0.323358
tensor(0.0157, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(4.9332e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.071445
Average KL loss: 0.247080
Average total loss: 0.318525
tensor(0.0157, device='cuda:0') tensor(0.0464, device='cuda:0') tensor(-2.8920e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.078731
Average KL loss: 0.247090
Average total loss: 0.325821
tensor(0.0157, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-1.0862e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.074906
Average KL loss: 0.247147
Average total loss: 0.322053
tensor(0.0157, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(1.9453e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.072036
Average KL loss: 0.247158
Average total loss: 0.319194
tensor(0.0157, device='cuda:0') tensor(0.0466, device='cuda:0') tensor(-7.2141e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.075067
Average KL loss: 0.247178
Average total loss: 0.322245
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(1.2301e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.078148
Average KL loss: 0.247230
Average total loss: 0.325378
tensor(0.0157, device='cuda:0') tensor(0.0468, device='cuda:0') tensor(-6.7219e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.075207
Average KL loss: 0.247377
Average total loss: 0.322584
tensor(0.0157, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(1.7984e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.075804
Average KL loss: 0.247454
Average total loss: 0.323258
tensor(0.0157, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(-2.0171e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.073461
Average KL loss: 0.247502
Average total loss: 0.320963
tensor(0.0157, device='cuda:0') tensor(0.0470, device='cuda:0') tensor(-6.6773e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.073377
Average KL loss: 0.247433
Average total loss: 0.320811
tensor(0.0157, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-3.2415e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.075450
Average KL loss: 0.247392
Average total loss: 0.322842
tensor(0.0157, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-2.0816e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.071599
Average KL loss: 0.247453
Average total loss: 0.319052
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(1.8303e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.071721
Average KL loss: 0.247453
Average total loss: 0.319174
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-4.4026e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.071651
Average KL loss: 0.247438
Average total loss: 0.319089
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-6.8186e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.073992
Average KL loss: 0.247425
Average total loss: 0.321417
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(1.2567e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.072423
Average KL loss: 0.247416
Average total loss: 0.319839
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(1.3515e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.071872
Average KL loss: 0.247400
Average total loss: 0.319272
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-3.9522e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.074223
Average KL loss: 0.247388
Average total loss: 0.321611
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-1.8743e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.069035
Average KL loss: 0.247377
Average total loss: 0.316411
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-1.8452e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.072125
Average KL loss: 0.247358
Average total loss: 0.319483
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(2.7391e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.072783
Average KL loss: 0.247341
Average total loss: 0.320123
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(2.9064e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.073766
Average KL loss: 0.247325
Average total loss: 0.321091
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-4.1992e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.070974
Average KL loss: 0.247308
Average total loss: 0.318282
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-1.5453e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.070553
Average KL loss: 0.247287
Average total loss: 0.317840
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(3.0821e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.070619
Average KL loss: 0.247271
Average total loss: 0.317889
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-3.8244e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.074049
Average KL loss: 0.247254
Average total loss: 0.321303
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-4.5632e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.071583
Average KL loss: 0.247243
Average total loss: 0.318827
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(1.6564e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.073462
Average KL loss: 0.247225
Average total loss: 0.320687
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(1.9968e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.069446
Average KL loss: 0.247212
Average total loss: 0.316658
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(3.1513e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.070879
Average KL loss: 0.247195
Average total loss: 0.318074
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(5.1575e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.066312
Average KL loss: 0.247188
Average total loss: 0.313500
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-3.1166e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.074471
Average KL loss: 0.247185
Average total loss: 0.321656
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(4.0268e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.075391
Average KL loss: 0.247184
Average total loss: 0.322575
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(4.7714e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.071480
Average KL loss: 0.247182
Average total loss: 0.318663
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-2.1557e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.070654
Average KL loss: 0.247180
Average total loss: 0.317834
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(1.7021e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.072134
Average KL loss: 0.247178
Average total loss: 0.319312
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-3.1167e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.072694
Average KL loss: 0.247176
Average total loss: 0.319870
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(6.9638e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.070962
Average KL loss: 0.247174
Average total loss: 0.318136
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-2.6417e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.067998
Average KL loss: 0.247173
Average total loss: 0.315171
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(9.3874e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.069408
Average KL loss: 0.247171
Average total loss: 0.316579
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-7.4245e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.072411
Average KL loss: 0.247170
Average total loss: 0.319581
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(9.7039e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.068629
Average KL loss: 0.247168
Average total loss: 0.315797
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-4.8117e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.072407
Average KL loss: 0.247167
Average total loss: 0.319574
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-8.5082e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.072147
Average KL loss: 0.247166
Average total loss: 0.319314
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(2.0960e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.071638
Average KL loss: 0.247166
Average total loss: 0.318805
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-3.9582e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.071784
Average KL loss: 0.247166
Average total loss: 0.318950
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-9.3311e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.069751
Average KL loss: 0.247166
Average total loss: 0.316917
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-6.0183e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.074603
Average KL loss: 0.247166
Average total loss: 0.321769
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-8.9141e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.070965
Average KL loss: 0.247166
Average total loss: 0.318131
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-1.3410e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.071132
Average KL loss: 0.247165
Average total loss: 0.318297
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(1.0222e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.073317
Average KL loss: 0.247165
Average total loss: 0.320482
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-5.6876e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.070566
Average KL loss: 0.247165
Average total loss: 0.317731
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-9.8059e-09, device='cuda:0')
 Percentile value: -1.652175569688552e-07
Non-zero model percentage: 2.8147659301757812%, Non-zero mask percentage: 2.8147659301757812%

--- Pruning Level [16/24]: ---
conv1.weight         | nonzeros =     860 /    1728             ( 49.77%) | total_pruned =     868 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1473 /   36864             (  4.00%) | total_pruned =   35391 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1834 /   36864             (  4.98%) | total_pruned =   35030 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1590 /   36864             (  4.31%) | total_pruned =   35274 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1675 /   36864             (  4.54%) | total_pruned =   35189 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2868 /   73728             (  3.89%) | total_pruned =   70860 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4333 /  147456             (  2.94%) | total_pruned =  143123 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1498 /    8192             ( 18.29%) | total_pruned =    6694 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2817 /  147456             (  1.91%) | total_pruned =  144639 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2666 /  147456             (  1.81%) | total_pruned =  144790 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7488 /  294912             (  2.54%) | total_pruned =  287424 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     178 /     256             ( 69.53%) | total_pruned =      78 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   10471 /  589824             (  1.78%) | total_pruned =  579353 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3051 /   32768             (  9.31%) | total_pruned =   29717 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      90 /     256             ( 35.16%) | total_pruned =     166 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   10156 /  589824             (  1.72%) | total_pruned =  579668 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      74 /     256             ( 28.91%) | total_pruned =     182 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    9712 /  589824             (  1.65%) | total_pruned =  580112 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     107 /     256             ( 41.80%) | total_pruned =     149 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   14901 / 1179648             (  1.26%) | total_pruned = 1164747 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     435 /     512             ( 84.96%) | total_pruned =      77 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   15514 / 2359296             (  0.66%) | total_pruned = 2343782 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     187 /     512             ( 36.52%) | total_pruned =     325 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     249 /     512             ( 48.63%) | total_pruned =     263 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3220 /  131072             (  2.46%) | total_pruned =  127852 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     205 /     512             ( 40.04%) | total_pruned =     307 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     464 /     512             ( 90.62%) | total_pruned =      48 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     262 /     512             ( 51.17%) | total_pruned =     250 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   91828 / 2359296             (  3.89%) | total_pruned = 2267468 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     117 /     512             ( 22.85%) | total_pruned =     395 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     103 /     512             ( 20.12%) | total_pruned =     409 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  117312 / 2359296             (  4.97%) | total_pruned = 2241984 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     147 /     512             ( 28.71%) | total_pruned =     365 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
linear.weight        | nonzeros =    1546 /    5120             ( 30.20%) | total_pruned =    3574 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 314656, pruned : 10864106, total: 11178762, Compression rate :      35.53x  ( 97.19% pruned)
Train Epoch: 21/100 Loss: 0.000046 Accuracy: 85.25 100.00 % Best test Accuracy: 85.47%
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(5.4346e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.105870
Average KL loss: 0.241771
Average total loss: 0.347641
tensor(0.0153, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-1.3722e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.111313
Average KL loss: 0.240112
Average total loss: 0.351426
tensor(0.0152, device='cuda:0') tensor(0.0428, device='cuda:0') tensor(-1.4095e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.109605
Average KL loss: 0.240232
Average total loss: 0.349837
tensor(0.0152, device='cuda:0') tensor(0.0426, device='cuda:0') tensor(-4.5088e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.109896
Average KL loss: 0.240562
Average total loss: 0.350458
tensor(0.0152, device='cuda:0') tensor(0.0426, device='cuda:0') tensor(-1.0214e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.112549
Average KL loss: 0.240939
Average total loss: 0.353488
tensor(0.0152, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-5.8157e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.108415
Average KL loss: 0.241376
Average total loss: 0.349791
tensor(0.0153, device='cuda:0') tensor(0.0428, device='cuda:0') tensor(-8.0545e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.107557
Average KL loss: 0.241843
Average total loss: 0.349400
tensor(0.0153, device='cuda:0') tensor(0.0429, device='cuda:0') tensor(-9.8534e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.108006
Average KL loss: 0.242293
Average total loss: 0.350299
tensor(0.0153, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(-1.6068e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.105336
Average KL loss: 0.242735
Average total loss: 0.348071
tensor(0.0153, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-1.3642e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.105237
Average KL loss: 0.243217
Average total loss: 0.348453
tensor(0.0153, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(-7.8068e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.097960
Average KL loss: 0.243636
Average total loss: 0.341596
tensor(0.0154, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-6.5845e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.102799
Average KL loss: 0.243985
Average total loss: 0.346785
tensor(0.0154, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-3.7291e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.097824
Average KL loss: 0.244358
Average total loss: 0.342182
tensor(0.0154, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-6.3645e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.097772
Average KL loss: 0.244692
Average total loss: 0.342464
tensor(0.0154, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-1.6110e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.093419
Average KL loss: 0.245035
Average total loss: 0.338454
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.2067e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.098201
Average KL loss: 0.245366
Average total loss: 0.343568
tensor(0.0154, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-1.2611e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.097224
Average KL loss: 0.245696
Average total loss: 0.342919
tensor(0.0155, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-1.3054e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.094302
Average KL loss: 0.245973
Average total loss: 0.340275
tensor(0.0155, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-4.3669e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.088386
Average KL loss: 0.246197
Average total loss: 0.334583
tensor(0.0155, device='cuda:0') tensor(0.0444, device='cuda:0') tensor(-1.2404e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.090012
Average KL loss: 0.246427
Average total loss: 0.336439
tensor(0.0155, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-5.8886e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.088720
Average KL loss: 0.246700
Average total loss: 0.335421
tensor(0.0155, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.7199e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.092225
Average KL loss: 0.246938
Average total loss: 0.339163
tensor(0.0155, device='cuda:0') tensor(0.0448, device='cuda:0') tensor(-2.6976e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.087047
Average KL loss: 0.247252
Average total loss: 0.334299
tensor(0.0155, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(1.1751e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.090621
Average KL loss: 0.247463
Average total loss: 0.338083
tensor(0.0156, device='cuda:0') tensor(0.0450, device='cuda:0') tensor(-3.2092e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.088010
Average KL loss: 0.247655
Average total loss: 0.335665
tensor(0.0156, device='cuda:0') tensor(0.0451, device='cuda:0') tensor(7.2671e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.088971
Average KL loss: 0.247831
Average total loss: 0.336801
tensor(0.0156, device='cuda:0') tensor(0.0452, device='cuda:0') tensor(-4.5975e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.086584
Average KL loss: 0.248039
Average total loss: 0.334623
tensor(0.0156, device='cuda:0') tensor(0.0453, device='cuda:0') tensor(-6.4075e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.084430
Average KL loss: 0.248257
Average total loss: 0.332688
tensor(0.0156, device='cuda:0') tensor(0.0454, device='cuda:0') tensor(-7.6751e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.082994
Average KL loss: 0.248429
Average total loss: 0.331423
tensor(0.0156, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-1.0727e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.085162
Average KL loss: 0.248569
Average total loss: 0.333731
tensor(0.0156, device='cuda:0') tensor(0.0456, device='cuda:0') tensor(-6.6714e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.084389
Average KL loss: 0.248753
Average total loss: 0.333141
tensor(0.0156, device='cuda:0') tensor(0.0457, device='cuda:0') tensor(-5.0777e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.079863
Average KL loss: 0.248851
Average total loss: 0.328714
tensor(0.0156, device='cuda:0') tensor(0.0458, device='cuda:0') tensor(3.1644e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.080230
Average KL loss: 0.248942
Average total loss: 0.329172
tensor(0.0156, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(2.4582e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.080210
Average KL loss: 0.249079
Average total loss: 0.329289
tensor(0.0156, device='cuda:0') tensor(0.0460, device='cuda:0') tensor(-1.3970e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.084078
Average KL loss: 0.249228
Average total loss: 0.333306
tensor(0.0157, device='cuda:0') tensor(0.0461, device='cuda:0') tensor(-7.1495e-11, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.079981
Average KL loss: 0.249380
Average total loss: 0.329361
tensor(0.0157, device='cuda:0') tensor(0.0462, device='cuda:0') tensor(-3.4748e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.078506
Average KL loss: 0.249490
Average total loss: 0.327996
tensor(0.0157, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-1.0203e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.078119
Average KL loss: 0.249591
Average total loss: 0.327710
tensor(0.0157, device='cuda:0') tensor(0.0464, device='cuda:0') tensor(-8.4888e-11, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.078516
Average KL loss: 0.249694
Average total loss: 0.328210
tensor(0.0157, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-4.4410e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.083258
Average KL loss: 0.249811
Average total loss: 0.333069
tensor(0.0157, device='cuda:0') tensor(0.0466, device='cuda:0') tensor(-3.7415e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.076254
Average KL loss: 0.249890
Average total loss: 0.326144
tensor(0.0157, device='cuda:0') tensor(0.0466, device='cuda:0') tensor(-3.5073e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.079230
Average KL loss: 0.249941
Average total loss: 0.329170
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(2.8286e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.077996
Average KL loss: 0.250058
Average total loss: 0.328054
tensor(0.0157, device='cuda:0') tensor(0.0468, device='cuda:0') tensor(-9.3474e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.077976
Average KL loss: 0.250121
Average total loss: 0.328097
tensor(0.0157, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(-7.0988e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.069719
Average KL loss: 0.250153
Average total loss: 0.319872
tensor(0.0157, device='cuda:0') tensor(0.0470, device='cuda:0') tensor(-3.2118e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.076524
Average KL loss: 0.250081
Average total loss: 0.326605
tensor(0.0157, device='cuda:0') tensor(0.0470, device='cuda:0') tensor(-1.5205e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.072123
Average KL loss: 0.250109
Average total loss: 0.322232
tensor(0.0157, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-6.5378e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.071270
Average KL loss: 0.250091
Average total loss: 0.321360
tensor(0.0157, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-5.6103e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.072955
Average KL loss: 0.250120
Average total loss: 0.323075
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(4.8320e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.078307
Average KL loss: 0.250221
Average total loss: 0.328528
tensor(0.0157, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-1.0507e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.071138
Average KL loss: 0.250376
Average total loss: 0.321514
tensor(0.0157, device='cuda:0') tensor(0.0474, device='cuda:0') tensor(-1.1234e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.071980
Average KL loss: 0.250400
Average total loss: 0.322380
tensor(0.0157, device='cuda:0') tensor(0.0475, device='cuda:0') tensor(-8.5264e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.072151
Average KL loss: 0.250394
Average total loss: 0.322545
tensor(0.0157, device='cuda:0') tensor(0.0475, device='cuda:0') tensor(-1.5627e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.070045
Average KL loss: 0.250428
Average total loss: 0.320473
tensor(0.0157, device='cuda:0') tensor(0.0476, device='cuda:0') tensor(4.6976e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.073365
Average KL loss: 0.250423
Average total loss: 0.323788
tensor(0.0157, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-3.6307e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.074378
Average KL loss: 0.250556
Average total loss: 0.324933
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-1.0012e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.069671
Average KL loss: 0.250574
Average total loss: 0.320245
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-3.8577e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.068851
Average KL loss: 0.250556
Average total loss: 0.319407
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-3.8066e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.074601
Average KL loss: 0.250538
Average total loss: 0.325139
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(6.7312e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.070916
Average KL loss: 0.250525
Average total loss: 0.321441
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-4.1639e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.070079
Average KL loss: 0.250512
Average total loss: 0.320591
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-5.0450e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.075312
Average KL loss: 0.250499
Average total loss: 0.325811
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(1.0812e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.072189
Average KL loss: 0.250491
Average total loss: 0.322680
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-9.2663e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.070538
Average KL loss: 0.250485
Average total loss: 0.321023
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-2.1657e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.072250
Average KL loss: 0.250476
Average total loss: 0.322726
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(3.4000e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.070868
Average KL loss: 0.250462
Average total loss: 0.321331
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-3.2248e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.073876
Average KL loss: 0.250444
Average total loss: 0.324320
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-6.2558e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.071540
Average KL loss: 0.250431
Average total loss: 0.321971
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-1.2749e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.071750
Average KL loss: 0.250418
Average total loss: 0.322168
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(4.2531e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.068370
Average KL loss: 0.250411
Average total loss: 0.318782
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-1.0100e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.071114
Average KL loss: 0.250409
Average total loss: 0.321523
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-3.5883e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.072450
Average KL loss: 0.250408
Average total loss: 0.322858
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-5.2415e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.073874
Average KL loss: 0.250406
Average total loss: 0.324280
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(3.3323e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.072258
Average KL loss: 0.250405
Average total loss: 0.322663
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-5.1170e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.071471
Average KL loss: 0.250404
Average total loss: 0.321875
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-6.3274e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.072973
Average KL loss: 0.250402
Average total loss: 0.323376
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-8.7839e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.071309
Average KL loss: 0.250402
Average total loss: 0.321710
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(7.1866e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.072018
Average KL loss: 0.250400
Average total loss: 0.322418
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-3.8582e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.068801
Average KL loss: 0.250399
Average total loss: 0.319200
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(1.7807e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.069643
Average KL loss: 0.250397
Average total loss: 0.320040
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-1.8444e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.073029
Average KL loss: 0.250396
Average total loss: 0.323425
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-5.4617e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.073848
Average KL loss: 0.250396
Average total loss: 0.324243
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-6.8136e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.069783
Average KL loss: 0.250396
Average total loss: 0.320178
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-2.8077e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.072833
Average KL loss: 0.250395
Average total loss: 0.323229
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-1.8727e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.074856
Average KL loss: 0.250395
Average total loss: 0.325251
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-8.5611e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.076038
Average KL loss: 0.250395
Average total loss: 0.326433
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-4.8215e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.073644
Average KL loss: 0.250395
Average total loss: 0.324039
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(5.8135e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.072160
Average KL loss: 0.250395
Average total loss: 0.322555
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-3.2444e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.071604
Average KL loss: 0.250395
Average total loss: 0.321999
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-3.8833e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.070064
Average KL loss: 0.250395
Average total loss: 0.320458
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-4.8893e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.068905
Average KL loss: 0.250395
Average total loss: 0.319299
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-3.9844e-09, device='cuda:0')
 Percentile value: -1.6524255386229925e-07
Non-zero model percentage: 2.251814603805542%, Non-zero mask percentage: 2.251814603805542%

--- Pruning Level [17/24]: ---
conv1.weight         | nonzeros =     852 /    1728             ( 49.31%) | total_pruned =     876 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1437 /   36864             (  3.90%) | total_pruned =   35427 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1774 /   36864             (  4.81%) | total_pruned =   35090 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1525 /   36864             (  4.14%) | total_pruned =   35339 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1641 /   36864             (  4.45%) | total_pruned =   35223 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2777 /   73728             (  3.77%) | total_pruned =   70951 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4144 /  147456             (  2.81%) | total_pruned =  143312 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1474 /    8192             ( 17.99%) | total_pruned =    6718 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2589 /  147456             (  1.76%) | total_pruned =  144867 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2435 /  147456             (  1.65%) | total_pruned =  145021 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7185 /  294912             (  2.44%) | total_pruned =  287727 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    9994 /  589824             (  1.69%) | total_pruned =  579830 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2977 /   32768             (  9.09%) | total_pruned =   29791 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      88 /     256             ( 34.38%) | total_pruned =     168 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      89 /     256             ( 34.77%) | total_pruned =     167 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    8197 /  589824             (  1.39%) | total_pruned =  581627 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      68 /     256             ( 26.56%) | total_pruned =     188 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    7793 /  589824             (  1.32%) | total_pruned =  582031 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      63 /     256             ( 24.61%) | total_pruned =     193 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   13911 / 1179648             (  1.18%) | total_pruned = 1165737 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     145 /     512             ( 28.32%) | total_pruned =     367 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     431 /     512             ( 84.18%) | total_pruned =      81 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   13923 / 2359296             (  0.59%) | total_pruned = 2345373 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     175 /     512             ( 34.18%) | total_pruned =     337 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     241 /     512             ( 47.07%) | total_pruned =     271 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2987 /  131072             (  2.28%) | total_pruned =  128085 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     185 /     512             ( 36.13%) | total_pruned =     327 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     461 /     512             ( 90.04%) | total_pruned =      51 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     258 /     512             ( 50.39%) | total_pruned =     254 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   69587 / 2359296             (  2.95%) | total_pruned = 2289709 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     102 /     512             ( 19.92%) | total_pruned =     410 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     381 /     512             ( 74.41%) | total_pruned =     131 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      83 /     512             ( 16.21%) | total_pruned =     429 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   85357 / 2359296             (  3.62%) | total_pruned = 2273939 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     137 /     512             ( 26.76%) | total_pruned =     375 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
linear.weight        | nonzeros =    1524 /    5120             ( 29.77%) | total_pruned =    3596 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 251725, pruned : 10927037, total: 11178762, Compression rate :      44.41x  ( 97.75% pruned)
Train Epoch: 20/100 Loss: 0.017247 Accuracy: 85.13 100.00 % Best test Accuracy: 85.21%
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-8.0333e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.106138
Average KL loss: 0.245187
Average total loss: 0.351325
tensor(0.0153, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-5.2572e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.113978
Average KL loss: 0.243554
Average total loss: 0.357532
tensor(0.0153, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-7.3273e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.112335
Average KL loss: 0.243668
Average total loss: 0.356003
tensor(0.0152, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(-1.3116e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.115530
Average KL loss: 0.244014
Average total loss: 0.359544
tensor(0.0153, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(-1.2559e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.113923
Average KL loss: 0.244473
Average total loss: 0.358396
tensor(0.0153, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-4.2632e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.111433
Average KL loss: 0.244950
Average total loss: 0.356383
tensor(0.0153, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-9.5308e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.104829
Average KL loss: 0.245385
Average total loss: 0.350215
tensor(0.0153, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-5.7294e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.102982
Average KL loss: 0.245778
Average total loss: 0.348760
tensor(0.0153, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-4.6115e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.102064
Average KL loss: 0.246164
Average total loss: 0.348228
tensor(0.0154, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.0152e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.101536
Average KL loss: 0.246515
Average total loss: 0.348051
tensor(0.0154, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-3.2440e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.098066
Average KL loss: 0.246890
Average total loss: 0.344955
tensor(0.0154, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-4.6927e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.095614
Average KL loss: 0.247206
Average total loss: 0.342820
tensor(0.0154, device='cuda:0') tensor(0.0444, device='cuda:0') tensor(-1.0309e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.096978
Average KL loss: 0.247535
Average total loss: 0.344514
tensor(0.0154, device='cuda:0') tensor(0.0445, device='cuda:0') tensor(-6.9445e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.102161
Average KL loss: 0.247899
Average total loss: 0.350060
tensor(0.0154, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-1.3281e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.097131
Average KL loss: 0.248296
Average total loss: 0.345427
tensor(0.0155, device='cuda:0') tensor(0.0448, device='cuda:0') tensor(-1.7878e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.091566
Average KL loss: 0.248584
Average total loss: 0.340150
tensor(0.0155, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(-4.0724e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.093825
Average KL loss: 0.248811
Average total loss: 0.342637
tensor(0.0155, device='cuda:0') tensor(0.0450, device='cuda:0') tensor(-1.5746e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.093768
Average KL loss: 0.249025
Average total loss: 0.342793
tensor(0.0155, device='cuda:0') tensor(0.0451, device='cuda:0') tensor(-6.7336e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.093433
Average KL loss: 0.249290
Average total loss: 0.342722
tensor(0.0155, device='cuda:0') tensor(0.0452, device='cuda:0') tensor(-1.1028e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.093840
Average KL loss: 0.249530
Average total loss: 0.343370
tensor(0.0155, device='cuda:0') tensor(0.0454, device='cuda:0') tensor(-1.8377e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.085260
Average KL loss: 0.249782
Average total loss: 0.335042
tensor(0.0156, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-7.0214e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.093937
Average KL loss: 0.249999
Average total loss: 0.343936
tensor(0.0156, device='cuda:0') tensor(0.0456, device='cuda:0') tensor(-8.8747e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.087767
Average KL loss: 0.250249
Average total loss: 0.338016
tensor(0.0156, device='cuda:0') tensor(0.0457, device='cuda:0') tensor(-3.7312e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.087132
Average KL loss: 0.250466
Average total loss: 0.337597
tensor(0.0156, device='cuda:0') tensor(0.0458, device='cuda:0') tensor(-3.7613e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.089029
Average KL loss: 0.250674
Average total loss: 0.339702
tensor(0.0156, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(-1.1799e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.086358
Average KL loss: 0.250869
Average total loss: 0.337227
tensor(0.0156, device='cuda:0') tensor(0.0461, device='cuda:0') tensor(-5.8363e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.084002
Average KL loss: 0.251065
Average total loss: 0.335067
tensor(0.0156, device='cuda:0') tensor(0.0462, device='cuda:0') tensor(-1.2901e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.084274
Average KL loss: 0.251249
Average total loss: 0.335523
tensor(0.0156, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-5.2463e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.079721
Average KL loss: 0.251354
Average total loss: 0.331075
tensor(0.0156, device='cuda:0') tensor(0.0464, device='cuda:0') tensor(-5.6576e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.078657
Average KL loss: 0.251474
Average total loss: 0.330131
tensor(0.0157, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-6.7916e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.080255
Average KL loss: 0.251618
Average total loss: 0.331873
tensor(0.0157, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-6.7357e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.081529
Average KL loss: 0.251784
Average total loss: 0.333313
tensor(0.0157, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.8215e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.081421
Average KL loss: 0.251937
Average total loss: 0.333358
tensor(0.0157, device='cuda:0') tensor(0.0468, device='cuda:0') tensor(1.0184e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.083996
Average KL loss: 0.252096
Average total loss: 0.336093
tensor(0.0157, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(-2.7907e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.081337
Average KL loss: 0.252244
Average total loss: 0.333581
tensor(0.0157, device='cuda:0') tensor(0.0470, device='cuda:0') tensor(-3.2435e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.076877
Average KL loss: 0.252299
Average total loss: 0.329176
tensor(0.0157, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-4.5108e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.079022
Average KL loss: 0.252423
Average total loss: 0.331445
tensor(0.0157, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-8.8383e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.076207
Average KL loss: 0.252487
Average total loss: 0.328694
tensor(0.0157, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-2.1851e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.076963
Average KL loss: 0.252551
Average total loss: 0.329513
tensor(0.0157, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-4.2359e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.078221
Average KL loss: 0.252630
Average total loss: 0.330851
tensor(0.0157, device='cuda:0') tensor(0.0474, device='cuda:0') tensor(5.1584e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.076152
Average KL loss: 0.252653
Average total loss: 0.328805
tensor(0.0157, device='cuda:0') tensor(0.0475, device='cuda:0') tensor(8.4967e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.077157
Average KL loss: 0.252712
Average total loss: 0.329869
tensor(0.0157, device='cuda:0') tensor(0.0476, device='cuda:0') tensor(-2.2775e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.078518
Average KL loss: 0.252855
Average total loss: 0.331373
tensor(0.0158, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-1.5139e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.074304
Average KL loss: 0.252938
Average total loss: 0.327242
tensor(0.0158, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-1.2733e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.077862
Average KL loss: 0.252980
Average total loss: 0.330842
tensor(0.0158, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-3.4170e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.073030
Average KL loss: 0.253048
Average total loss: 0.326077
tensor(0.0158, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-3.2099e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.072330
Average KL loss: 0.253075
Average total loss: 0.325405
tensor(0.0158, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-3.4917e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.072976
Average KL loss: 0.253134
Average total loss: 0.326110
tensor(0.0158, device='cuda:0') tensor(0.0481, device='cuda:0') tensor(-5.1096e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.072460
Average KL loss: 0.253204
Average total loss: 0.325664
tensor(0.0158, device='cuda:0') tensor(0.0482, device='cuda:0') tensor(-4.8452e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.074346
Average KL loss: 0.253250
Average total loss: 0.327595
tensor(0.0158, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-2.0703e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.075764
Average KL loss: 0.253332
Average total loss: 0.329096
tensor(0.0158, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-6.2422e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.072567
Average KL loss: 0.253370
Average total loss: 0.325937
tensor(0.0158, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-3.6359e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.072419
Average KL loss: 0.253370
Average total loss: 0.325789
tensor(0.0158, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-4.2374e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.072348
Average KL loss: 0.253384
Average total loss: 0.325732
tensor(0.0158, device='cuda:0') tensor(0.0486, device='cuda:0') tensor(3.4931e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.067693
Average KL loss: 0.253380
Average total loss: 0.321072
tensor(0.0158, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-4.3725e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.070067
Average KL loss: 0.253353
Average total loss: 0.323421
tensor(0.0158, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(1.7360e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.069165
Average KL loss: 0.253325
Average total loss: 0.322490
tensor(0.0158, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-4.2374e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.075632
Average KL loss: 0.253348
Average total loss: 0.328981
tensor(0.0158, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(1.2583e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.073371
Average KL loss: 0.253426
Average total loss: 0.326796
tensor(0.0158, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-7.5880e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.067981
Average KL loss: 0.253445
Average total loss: 0.321426
tensor(0.0158, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-7.7794e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.070355
Average KL loss: 0.253476
Average total loss: 0.323831
tensor(0.0158, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(-5.9597e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.069611
Average KL loss: 0.253539
Average total loss: 0.323150
tensor(0.0158, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(6.9212e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.067735
Average KL loss: 0.253596
Average total loss: 0.321331
tensor(0.0158, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(5.6585e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.068044
Average KL loss: 0.253584
Average total loss: 0.321628
tensor(0.0158, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-8.1255e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.066521
Average KL loss: 0.253528
Average total loss: 0.320048
tensor(0.0158, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-4.9088e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.068879
Average KL loss: 0.253512
Average total loss: 0.322391
tensor(0.0158, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-2.6932e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.066044
Average KL loss: 0.253547
Average total loss: 0.319590
tensor(0.0158, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(-1.3141e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.070358
Average KL loss: 0.253549
Average total loss: 0.323907
tensor(0.0159, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(-6.0018e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.066546
Average KL loss: 0.253533
Average total loss: 0.320080
tensor(0.0158, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(-2.8926e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.066209
Average KL loss: 0.253495
Average total loss: 0.319704
tensor(0.0159, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(-2.3808e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.068617
Average KL loss: 0.253455
Average total loss: 0.322073
tensor(0.0159, device='cuda:0') tensor(0.0499, device='cuda:0') tensor(-7.8310e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.065676
Average KL loss: 0.253446
Average total loss: 0.319122
tensor(0.0159, device='cuda:0') tensor(0.0499, device='cuda:0') tensor(-1.1762e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.065225
Average KL loss: 0.253467
Average total loss: 0.318692
tensor(0.0159, device='cuda:0') tensor(0.0500, device='cuda:0') tensor(-2.3515e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.069512
Average KL loss: 0.253512
Average total loss: 0.323024
tensor(0.0159, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-2.8337e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.063868
Average KL loss: 0.253509
Average total loss: 0.317377
tensor(0.0159, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-1.0005e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.064159
Average KL loss: 0.253417
Average total loss: 0.317576
tensor(0.0159, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(-4.0940e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.066041
Average KL loss: 0.253383
Average total loss: 0.319424
tensor(0.0159, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(-6.0685e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.065536
Average KL loss: 0.253396
Average total loss: 0.318932
tensor(0.0159, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(-4.5109e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.065588
Average KL loss: 0.253413
Average total loss: 0.319002
tensor(0.0159, device='cuda:0') tensor(0.0504, device='cuda:0') tensor(-9.7514e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.065262
Average KL loss: 0.253430
Average total loss: 0.318692
tensor(0.0159, device='cuda:0') tensor(0.0505, device='cuda:0') tensor(-3.5139e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.066565
Average KL loss: 0.253452
Average total loss: 0.320017
tensor(0.0159, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-9.1554e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.065838
Average KL loss: 0.253461
Average total loss: 0.319299
tensor(0.0159, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-1.3486e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.063295
Average KL loss: 0.253441
Average total loss: 0.316736
tensor(0.0159, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(-5.6346e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.066626
Average KL loss: 0.253440
Average total loss: 0.320066
tensor(0.0159, device='cuda:0') tensor(0.0508, device='cuda:0') tensor(-9.5622e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.063691
Average KL loss: 0.253476
Average total loss: 0.317167
tensor(0.0159, device='cuda:0') tensor(0.0508, device='cuda:0') tensor(-2.6438e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.064981
Average KL loss: 0.253507
Average total loss: 0.318488
tensor(0.0159, device='cuda:0') tensor(0.0509, device='cuda:0') tensor(-4.7764e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.059302
Average KL loss: 0.253455
Average total loss: 0.312757
tensor(0.0159, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(-1.3522e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.062637
Average KL loss: 0.253396
Average total loss: 0.316033
tensor(0.0159, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(-8.5545e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.067556
Average KL loss: 0.253403
Average total loss: 0.320959
tensor(0.0159, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(1.4871e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.064121
Average KL loss: 0.253487
Average total loss: 0.317607
tensor(0.0159, device='cuda:0') tensor(0.0512, device='cuda:0') tensor(-3.4836e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.065151
Average KL loss: 0.253476
Average total loss: 0.318626
tensor(0.0159, device='cuda:0') tensor(0.0512, device='cuda:0') tensor(-4.4249e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.063569
Average KL loss: 0.253469
Average total loss: 0.317039
tensor(0.0159, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(-6.3585e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.063263
Average KL loss: 0.253471
Average total loss: 0.316734
tensor(0.0159, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(2.1063e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.059468
Average KL loss: 0.253448
Average total loss: 0.312917
tensor(0.0159, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(-5.0361e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.061365
Average KL loss: 0.253426
Average total loss: 0.314791
tensor(0.0159, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-5.3563e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.063552
Average KL loss: 0.253380
Average total loss: 0.316931
tensor(0.0159, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-5.5815e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.060455
Average KL loss: 0.253395
Average total loss: 0.313850
tensor(0.0159, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-3.7982e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.066007
Average KL loss: 0.253363
Average total loss: 0.319370
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-1.0562e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.062091
Average KL loss: 0.253359
Average total loss: 0.315450
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-2.7946e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.064165
Average KL loss: 0.253340
Average total loss: 0.317504
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-4.8300e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.062486
Average KL loss: 0.253327
Average total loss: 0.315814
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-4.7219e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.062398
Average KL loss: 0.253314
Average total loss: 0.315712
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(2.1063e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.061242
Average KL loss: 0.253294
Average total loss: 0.314537
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(6.6555e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.061729
Average KL loss: 0.253279
Average total loss: 0.315008
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-1.3377e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.068945
Average KL loss: 0.253267
Average total loss: 0.322212
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-7.0865e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.064849
Average KL loss: 0.253253
Average total loss: 0.318102
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(8.5802e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.059938
Average KL loss: 0.253239
Average total loss: 0.313177
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-1.1531e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.062956
Average KL loss: 0.253220
Average total loss: 0.316177
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(1.0816e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.061842
Average KL loss: 0.253205
Average total loss: 0.315047
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-2.8472e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.060350
Average KL loss: 0.253195
Average total loss: 0.313546
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-7.2482e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.062732
Average KL loss: 0.253195
Average total loss: 0.315926
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-3.8682e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.065117
Average KL loss: 0.253193
Average total loss: 0.318310
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-4.9003e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.061283
Average KL loss: 0.253191
Average total loss: 0.314475
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-2.9571e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.061790
Average KL loss: 0.253189
Average total loss: 0.314979
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(4.1855e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.060068
Average KL loss: 0.253187
Average total loss: 0.313255
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-2.3449e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.062533
Average KL loss: 0.253185
Average total loss: 0.315718
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(3.0949e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.060859
Average KL loss: 0.253184
Average total loss: 0.314043
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(4.2913e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.059856
Average KL loss: 0.253182
Average total loss: 0.313038
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-3.0577e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.062737
Average KL loss: 0.253180
Average total loss: 0.315916
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(3.8911e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.060329
Average KL loss: 0.253177
Average total loss: 0.313506
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-6.0015e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.059432
Average KL loss: 0.253176
Average total loss: 0.312609
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-4.2430e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.070861
Average KL loss: 0.253176
Average total loss: 0.324037
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-3.1550e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.066113
Average KL loss: 0.253176
Average total loss: 0.319290
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-3.6954e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.063324
Average KL loss: 0.253176
Average total loss: 0.316500
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(7.4708e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.059975
Average KL loss: 0.253176
Average total loss: 0.313151
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-7.6617e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.064506
Average KL loss: 0.253176
Average total loss: 0.317682
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-9.3189e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.062717
Average KL loss: 0.253176
Average total loss: 0.315893
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(4.7747e-11, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.062519
Average KL loss: 0.253175
Average total loss: 0.315695
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-4.7377e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.067235
Average KL loss: 0.253175
Average total loss: 0.320410
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(3.4497e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.061874
Average KL loss: 0.253175
Average total loss: 0.315050
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-3.3472e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.064308
Average KL loss: 0.253175
Average total loss: 0.317483
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-8.1384e-09, device='cuda:0')
 Percentile value: -1.651972780791766e-07
Non-zero model percentage: 1.8014516830444336%, Non-zero mask percentage: 1.8014516830444336%

--- Pruning Level [18/24]: ---
conv1.weight         | nonzeros =     843 /    1728             ( 48.78%) | total_pruned =     885 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1384 /   36864             (  3.75%) | total_pruned =   35480 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1702 /   36864             (  4.62%) | total_pruned =   35162 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1470 /   36864             (  3.99%) | total_pruned =   35394 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1589 /   36864             (  4.31%) | total_pruned =   35275 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2654 /   73728             (  3.60%) | total_pruned =   71074 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3966 /  147456             (  2.69%) | total_pruned =  143490 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1449 /    8192             ( 17.69%) | total_pruned =    6743 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2357 /  147456             (  1.60%) | total_pruned =  145099 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2206 /  147456             (  1.50%) | total_pruned =  145250 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6858 /  294912             (  2.33%) | total_pruned =  288054 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      81 /     256             ( 31.64%) | total_pruned =     175 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    9484 /  589824             (  1.61%) | total_pruned =  580340 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      91 /     256             ( 35.55%) | total_pruned =     165 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2897 /   32768             (  8.84%) | total_pruned =   29871 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6443 /  589824             (  1.09%) | total_pruned =  583381 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      62 /     256             ( 24.22%) | total_pruned =     194 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    6181 /  589824             (  1.05%) | total_pruned =  583643 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12950 / 1179648             (  1.10%) | total_pruned = 1166698 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     123 /     512             ( 24.02%) | total_pruned =     389 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     421 /     512             ( 82.23%) | total_pruned =      91 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   12365 / 2359296             (  0.52%) | total_pruned = 2346931 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     161 /     512             ( 31.45%) | total_pruned =     351 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     218 /     512             ( 42.58%) | total_pruned =     294 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2762 /  131072             (  2.11%) | total_pruned =  128310 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     157 /     512             ( 30.66%) | total_pruned =     355 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     459 /     512             ( 89.65%) | total_pruned =      53 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     233 /     512             ( 45.51%) | total_pruned =     279 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   50563 / 2359296             (  2.14%) | total_pruned = 2308733 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      81 /     512             ( 15.82%) | total_pruned =     431 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     379 /     512             ( 74.02%) | total_pruned =     133 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      73 /     512             ( 14.26%) | total_pruned =     439 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   62377 / 2359296             (  2.64%) | total_pruned = 2296919 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     125 /     512             ( 24.41%) | total_pruned =     387 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
linear.weight        | nonzeros =    1502 /    5120             ( 29.34%) | total_pruned =    3618 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 201380, pruned : 10977382, total: 11178762, Compression rate :      55.51x  ( 98.20% pruned)
Train Epoch: 21/100 Loss: 0.000424 Accuracy: 85.55 100.00 % Best test Accuracy: 85.55%
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-6.3332e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.092149
Average KL loss: 0.248041
Average total loss: 0.340190
tensor(0.0155, device='cuda:0') tensor(0.0475, device='cuda:0') tensor(-3.8069e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.106159
Average KL loss: 0.246136
Average total loss: 0.352295
tensor(0.0154, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-1.3583e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.104915
Average KL loss: 0.246086
Average total loss: 0.351001
tensor(0.0154, device='cuda:0') tensor(0.0462, device='cuda:0') tensor(-6.4966e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.104996
Average KL loss: 0.246384
Average total loss: 0.351380
tensor(0.0154, device='cuda:0') tensor(0.0462, device='cuda:0') tensor(-6.9577e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.098985
Average KL loss: 0.246793
Average total loss: 0.345777
tensor(0.0154, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-9.5759e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.102141
Average KL loss: 0.247117
Average total loss: 0.349258
tensor(0.0154, device='cuda:0') tensor(0.0464, device='cuda:0') tensor(-4.1836e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.100134
Average KL loss: 0.247531
Average total loss: 0.347665
tensor(0.0154, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-4.3114e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.094849
Average KL loss: 0.247942
Average total loss: 0.342791
tensor(0.0154, device='cuda:0') tensor(0.0466, device='cuda:0') tensor(-6.4489e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.094434
Average KL loss: 0.248337
Average total loss: 0.342771
tensor(0.0155, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-6.4556e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.095926
Average KL loss: 0.248726
Average total loss: 0.344652
tensor(0.0155, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(-5.8641e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.094309
Average KL loss: 0.249129
Average total loss: 0.343439
tensor(0.0155, device='cuda:0') tensor(0.0470, device='cuda:0') tensor(-6.2732e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.090352
Average KL loss: 0.249466
Average total loss: 0.339818
tensor(0.0155, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-6.5165e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.090716
Average KL loss: 0.249815
Average total loss: 0.340531
tensor(0.0155, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-1.9932e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.087812
Average KL loss: 0.250037
Average total loss: 0.337848
tensor(0.0156, device='cuda:0') tensor(0.0474, device='cuda:0') tensor(-1.8228e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.084343
Average KL loss: 0.250289
Average total loss: 0.334632
tensor(0.0156, device='cuda:0') tensor(0.0475, device='cuda:0') tensor(-8.7146e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.086356
Average KL loss: 0.250503
Average total loss: 0.336859
tensor(0.0156, device='cuda:0') tensor(0.0476, device='cuda:0') tensor(-7.4232e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.085574
Average KL loss: 0.250736
Average total loss: 0.336309
tensor(0.0156, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-2.7415e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.089412
Average KL loss: 0.251004
Average total loss: 0.340416
tensor(0.0156, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-4.5185e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.086809
Average KL loss: 0.251313
Average total loss: 0.338122
tensor(0.0156, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-8.2471e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.081456
Average KL loss: 0.251559
Average total loss: 0.333015
tensor(0.0156, device='cuda:0') tensor(0.0481, device='cuda:0') tensor(-3.4336e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.080775
Average KL loss: 0.251731
Average total loss: 0.332506
tensor(0.0157, device='cuda:0') tensor(0.0482, device='cuda:0') tensor(-2.3192e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.082001
Average KL loss: 0.251953
Average total loss: 0.333953
tensor(0.0157, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-9.2024e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.081093
Average KL loss: 0.252111
Average total loss: 0.333204
tensor(0.0157, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-5.0602e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.082750
Average KL loss: 0.252312
Average total loss: 0.335063
tensor(0.0157, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-2.4550e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.077645
Average KL loss: 0.252516
Average total loss: 0.330161
tensor(0.0157, device='cuda:0') tensor(0.0486, device='cuda:0') tensor(-2.6513e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.074411
Average KL loss: 0.252670
Average total loss: 0.327082
tensor(0.0157, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(3.9030e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.079177
Average KL loss: 0.252779
Average total loss: 0.331956
tensor(0.0157, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-3.9928e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.078035
Average KL loss: 0.252909
Average total loss: 0.330943
tensor(0.0157, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(1.6973e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.072743
Average KL loss: 0.253048
Average total loss: 0.325791
tensor(0.0157, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-3.1116e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.078097
Average KL loss: 0.253196
Average total loss: 0.331293
tensor(0.0158, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(-5.5983e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.075610
Average KL loss: 0.253362
Average total loss: 0.328973
tensor(0.0158, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(-3.9050e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.070612
Average KL loss: 0.253508
Average total loss: 0.324120
tensor(0.0158, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(3.2072e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.069302
Average KL loss: 0.253630
Average total loss: 0.322932
tensor(0.0158, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-8.2613e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.072635
Average KL loss: 0.253696
Average total loss: 0.326331
tensor(0.0158, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-2.2832e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.072753
Average KL loss: 0.253769
Average total loss: 0.326521
tensor(0.0158, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(-8.9396e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.072296
Average KL loss: 0.253842
Average total loss: 0.326138
tensor(0.0158, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(-5.2144e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.076794
Average KL loss: 0.253935
Average total loss: 0.330729
tensor(0.0158, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(2.5873e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.076280
Average KL loss: 0.254098
Average total loss: 0.330377
tensor(0.0158, device='cuda:0') tensor(0.0499, device='cuda:0') tensor(-8.5089e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.072875
Average KL loss: 0.254240
Average total loss: 0.327114
tensor(0.0158, device='cuda:0') tensor(0.0500, device='cuda:0') tensor(-1.2606e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.069869
Average KL loss: 0.254345
Average total loss: 0.324214
tensor(0.0158, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-6.3003e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.069270
Average KL loss: 0.254386
Average total loss: 0.323656
tensor(0.0158, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-6.4321e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.066994
Average KL loss: 0.254451
Average total loss: 0.321445
tensor(0.0159, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(-5.1816e-11, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.067001
Average KL loss: 0.254540
Average total loss: 0.321540
tensor(0.0159, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(-7.4031e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.066129
Average KL loss: 0.254592
Average total loss: 0.320720
tensor(0.0159, device='cuda:0') tensor(0.0504, device='cuda:0') tensor(-5.5640e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.066151
Average KL loss: 0.254647
Average total loss: 0.320799
tensor(0.0159, device='cuda:0') tensor(0.0505, device='cuda:0') tensor(-4.8955e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.067482
Average KL loss: 0.254705
Average total loss: 0.322186
tensor(0.0159, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-7.7102e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.071096
Average KL loss: 0.254737
Average total loss: 0.325833
tensor(0.0159, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(-4.7932e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.069479
Average KL loss: 0.254798
Average total loss: 0.324277
tensor(0.0159, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(-7.4282e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.071712
Average KL loss: 0.254862
Average total loss: 0.326574
tensor(0.0159, device='cuda:0') tensor(0.0508, device='cuda:0') tensor(-4.6921e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.066605
Average KL loss: 0.254975
Average total loss: 0.321580
tensor(0.0159, device='cuda:0') tensor(0.0509, device='cuda:0') tensor(3.0624e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.064077
Average KL loss: 0.254977
Average total loss: 0.319054
tensor(0.0159, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(-2.3142e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.068494
Average KL loss: 0.254988
Average total loss: 0.323482
tensor(0.0159, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(7.3192e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.067353
Average KL loss: 0.255019
Average total loss: 0.322371
tensor(0.0159, device='cuda:0') tensor(0.0512, device='cuda:0') tensor(-3.7326e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.068905
Average KL loss: 0.255142
Average total loss: 0.324047
tensor(0.0159, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(1.1865e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.065021
Average KL loss: 0.255217
Average total loss: 0.320239
tensor(0.0159, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(5.1561e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.063087
Average KL loss: 0.255238
Average total loss: 0.318325
tensor(0.0159, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(1.2380e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.065599
Average KL loss: 0.255223
Average total loss: 0.320823
tensor(0.0159, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-2.5267e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.066335
Average KL loss: 0.255233
Average total loss: 0.321568
tensor(0.0159, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(1.5721e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.062410
Average KL loss: 0.255213
Average total loss: 0.317623
tensor(0.0159, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-3.5534e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.065730
Average KL loss: 0.255189
Average total loss: 0.320919
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-3.6163e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.063196
Average KL loss: 0.255248
Average total loss: 0.318444
tensor(0.0160, device='cuda:0') tensor(0.0518, device='cuda:0') tensor(-1.3299e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.066712
Average KL loss: 0.255250
Average total loss: 0.321962
tensor(0.0160, device='cuda:0') tensor(0.0518, device='cuda:0') tensor(-4.4554e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.064487
Average KL loss: 0.255360
Average total loss: 0.319847
tensor(0.0160, device='cuda:0') tensor(0.0519, device='cuda:0') tensor(-6.2687e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.063695
Average KL loss: 0.255390
Average total loss: 0.319085
tensor(0.0160, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(-1.6358e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.061271
Average KL loss: 0.255440
Average total loss: 0.316711
tensor(0.0160, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(-4.3349e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.063769
Average KL loss: 0.255437
Average total loss: 0.319206
tensor(0.0160, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(4.6560e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.065412
Average KL loss: 0.255496
Average total loss: 0.320908
tensor(0.0160, device='cuda:0') tensor(0.0522, device='cuda:0') tensor(-4.8517e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.065771
Average KL loss: 0.255528
Average total loss: 0.321299
tensor(0.0160, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(-2.6194e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.060465
Average KL loss: 0.255540
Average total loss: 0.316005
tensor(0.0160, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(1.0397e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.060729
Average KL loss: 0.255488
Average total loss: 0.316217
tensor(0.0160, device='cuda:0') tensor(0.0524, device='cuda:0') tensor(-4.6146e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.060422
Average KL loss: 0.255487
Average total loss: 0.315910
tensor(0.0160, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-7.9303e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.061517
Average KL loss: 0.255495
Average total loss: 0.317012
tensor(0.0160, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-8.3111e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.062305
Average KL loss: 0.255473
Average total loss: 0.317777
tensor(0.0160, device='cuda:0') tensor(0.0526, device='cuda:0') tensor(1.3764e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.060150
Average KL loss: 0.255420
Average total loss: 0.315570
tensor(0.0160, device='cuda:0') tensor(0.0526, device='cuda:0') tensor(2.3015e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.062043
Average KL loss: 0.255403
Average total loss: 0.317446
tensor(0.0160, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(-2.9145e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.059888
Average KL loss: 0.255385
Average total loss: 0.315273
tensor(0.0160, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(2.7466e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.058468
Average KL loss: 0.255345
Average total loss: 0.313812
tensor(0.0160, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(1.8990e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.056994
Average KL loss: 0.255271
Average total loss: 0.312265
tensor(0.0160, device='cuda:0') tensor(0.0529, device='cuda:0') tensor(-2.1773e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.058905
Average KL loss: 0.255206
Average total loss: 0.314111
tensor(0.0160, device='cuda:0') tensor(0.0529, device='cuda:0') tensor(-1.9307e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.060798
Average KL loss: 0.255195
Average total loss: 0.315992
tensor(0.0160, device='cuda:0') tensor(0.0530, device='cuda:0') tensor(-4.9279e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.058905
Average KL loss: 0.255184
Average total loss: 0.314088
tensor(0.0160, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(-3.8444e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.061299
Average KL loss: 0.255180
Average total loss: 0.316480
tensor(0.0160, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(-5.1188e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.057090
Average KL loss: 0.255171
Average total loss: 0.312261
tensor(0.0160, device='cuda:0') tensor(0.0532, device='cuda:0') tensor(-3.0431e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.062489
Average KL loss: 0.255137
Average total loss: 0.317626
tensor(0.0160, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(-2.7635e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.060436
Average KL loss: 0.255099
Average total loss: 0.315535
tensor(0.0160, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(2.0047e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.057433
Average KL loss: 0.255063
Average total loss: 0.312497
tensor(0.0160, device='cuda:0') tensor(0.0534, device='cuda:0') tensor(-1.0663e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.059751
Average KL loss: 0.255052
Average total loss: 0.314802
tensor(0.0160, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(-1.1119e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.057244
Average KL loss: 0.254997
Average total loss: 0.312241
tensor(0.0160, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(-3.4314e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.057771
Average KL loss: 0.254957
Average total loss: 0.312728
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.6944e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.057158
Average KL loss: 0.254912
Average total loss: 0.312070
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-2.9554e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.061567
Average KL loss: 0.254901
Average total loss: 0.316468
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(1.6575e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.060240
Average KL loss: 0.254884
Average total loss: 0.315124
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-3.2155e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.056582
Average KL loss: 0.254869
Average total loss: 0.311451
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.8243e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.057974
Average KL loss: 0.254857
Average total loss: 0.312831
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-5.8403e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.058556
Average KL loss: 0.254842
Average total loss: 0.313398
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(8.4554e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.058367
Average KL loss: 0.254828
Average total loss: 0.313196
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.4391e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.058831
Average KL loss: 0.254815
Average total loss: 0.313645
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-4.3293e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.058552
Average KL loss: 0.254804
Average total loss: 0.313355
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-2.8766e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.061154
Average KL loss: 0.254791
Average total loss: 0.315945
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.2558e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.059227
Average KL loss: 0.254784
Average total loss: 0.314011
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-2.4041e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.059448
Average KL loss: 0.254772
Average total loss: 0.314220
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(1.6216e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.058339
Average KL loss: 0.254761
Average total loss: 0.313100
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-3.6342e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.060973
Average KL loss: 0.254747
Average total loss: 0.315720
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.2337e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.059921
Average KL loss: 0.254741
Average total loss: 0.314662
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-5.1434e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.055368
Average KL loss: 0.254736
Average total loss: 0.310103
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-2.7200e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.060076
Average KL loss: 0.254734
Average total loss: 0.314811
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.1077e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.060804
Average KL loss: 0.254734
Average total loss: 0.315538
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.3656e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.061503
Average KL loss: 0.254733
Average total loss: 0.316235
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.2783e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.061247
Average KL loss: 0.254732
Average total loss: 0.315979
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-4.2893e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.061834
Average KL loss: 0.254731
Average total loss: 0.316565
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-4.4435e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.060891
Average KL loss: 0.254729
Average total loss: 0.315620
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(1.4638e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.057087
Average KL loss: 0.254728
Average total loss: 0.311815
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-2.6149e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.062142
Average KL loss: 0.254727
Average total loss: 0.316869
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(1.2668e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.063445
Average KL loss: 0.254726
Average total loss: 0.318171
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-9.9222e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.056378
Average KL loss: 0.254725
Average total loss: 0.311103
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-5.6377e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.061550
Average KL loss: 0.254725
Average total loss: 0.316274
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-2.6221e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.062208
Average KL loss: 0.254724
Average total loss: 0.316933
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-7.1946e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.056969
Average KL loss: 0.254724
Average total loss: 0.311693
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.0494e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.057592
Average KL loss: 0.254724
Average total loss: 0.312316
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-6.3093e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.059937
Average KL loss: 0.254724
Average total loss: 0.314662
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-2.5927e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.055215
Average KL loss: 0.254724
Average total loss: 0.309939
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-2.1420e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.060136
Average KL loss: 0.254724
Average total loss: 0.314860
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-4.5961e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.057223
Average KL loss: 0.254724
Average total loss: 0.311947
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-2.0448e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.060854
Average KL loss: 0.254724
Average total loss: 0.315577
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(7.4340e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.057766
Average KL loss: 0.254723
Average total loss: 0.312490
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-8.8660e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.058325
Average KL loss: 0.254723
Average total loss: 0.313048
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-9.6187e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.058778
Average KL loss: 0.254723
Average total loss: 0.313501
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(2.6860e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.061329
Average KL loss: 0.254723
Average total loss: 0.316052
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(6.5465e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.055494
Average KL loss: 0.254723
Average total loss: 0.310217
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.4492e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.056625
Average KL loss: 0.254723
Average total loss: 0.311348
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-3.2665e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.060270
Average KL loss: 0.254723
Average total loss: 0.314993
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.3495e-09, device='cuda:0')
 Percentile value: -1.6521553902748565e-07
Non-zero model percentage: 1.4411613941192627%, Non-zero mask percentage: 1.4411613941192627%

--- Pruning Level [19/24]: ---
conv1.weight         | nonzeros =     830 /    1728             ( 48.03%) | total_pruned =     898 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1343 /   36864             (  3.64%) | total_pruned =   35521 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1645 /   36864             (  4.46%) | total_pruned =   35219 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1426 /   36864             (  3.87%) | total_pruned =   35438 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1547 /   36864             (  4.20%) | total_pruned =   35317 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2575 /   73728             (  3.49%) | total_pruned =   71153 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3837 /  147456             (  2.60%) | total_pruned =  143619 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1423 /    8192             ( 17.37%) | total_pruned =    6769 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2200 /  147456             (  1.49%) | total_pruned =  145256 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2058 /  147456             (  1.40%) | total_pruned =  145398 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6573 /  294912             (  2.23%) | total_pruned =  288339 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    9048 /  589824             (  1.53%) | total_pruned =  580776 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     103 /     256             ( 40.23%) | total_pruned =     153 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2818 /   32768             (  8.60%) | total_pruned =   29950 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      85 /     256             ( 33.20%) | total_pruned =     171 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    5390 /  589824             (  0.91%) | total_pruned =  584434 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    5193 /  589824             (  0.88%) | total_pruned =  584631 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      56 /     256             ( 21.88%) | total_pruned =     200 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12185 / 1179648             (  1.03%) | total_pruned = 1167463 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     109 /     512             ( 21.29%) | total_pruned =     403 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     410 /     512             ( 80.08%) | total_pruned =     102 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   11174 / 2359296             (  0.47%) | total_pruned = 2348122 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     147 /     512             ( 28.71%) | total_pruned =     365 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2576 /  131072             (  1.97%) | total_pruned =  128496 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     457 /     512             ( 89.26%) | total_pruned =      55 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     214 /     512             ( 41.80%) | total_pruned =     298 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   36055 / 2359296             (  1.53%) | total_pruned = 2323241 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      68 /     512             ( 13.28%) | total_pruned =     444 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   42569 / 2359296             (  1.80%) | total_pruned = 2316727 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
linear.weight        | nonzeros =    1487 /    5120             ( 29.04%) | total_pruned =    3633 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 161104, pruned : 11017658, total: 11178762, Compression rate :      69.39x  ( 98.56% pruned)
Train Epoch: 21/100 Loss: 0.000180 Accuracy: 85.01 100.00 % Best test Accuracy: 85.04%
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.1369e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.092417
Average KL loss: 0.249728
Average total loss: 0.342145
tensor(0.0155, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(-1.2191e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.097956
Average KL loss: 0.247845
Average total loss: 0.345801
tensor(0.0154, device='cuda:0') tensor(0.0481, device='cuda:0') tensor(-1.0443e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.095151
Average KL loss: 0.247768
Average total loss: 0.342919
tensor(0.0154, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-2.6027e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.093100
Average KL loss: 0.247980
Average total loss: 0.341081
tensor(0.0154, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-9.0010e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.095140
Average KL loss: 0.248277
Average total loss: 0.343417
tensor(0.0154, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-9.7281e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.094339
Average KL loss: 0.248604
Average total loss: 0.342943
tensor(0.0154, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-9.1374e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.090484
Average KL loss: 0.248987
Average total loss: 0.339471
tensor(0.0155, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-5.7234e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.092400
Average KL loss: 0.249333
Average total loss: 0.341733
tensor(0.0155, device='cuda:0') tensor(0.0481, device='cuda:0') tensor(-7.1928e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.083529
Average KL loss: 0.249639
Average total loss: 0.333167
tensor(0.0155, device='cuda:0') tensor(0.0482, device='cuda:0') tensor(-1.3938e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.087658
Average KL loss: 0.249888
Average total loss: 0.337546
tensor(0.0155, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-3.0732e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.087800
Average KL loss: 0.250177
Average total loss: 0.337977
tensor(0.0155, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(2.9974e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.087569
Average KL loss: 0.250508
Average total loss: 0.338077
tensor(0.0155, device='cuda:0') tensor(0.0486, device='cuda:0') tensor(-2.9997e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.085037
Average KL loss: 0.250847
Average total loss: 0.335884
tensor(0.0156, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-1.1999e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.085953
Average KL loss: 0.251199
Average total loss: 0.337151
tensor(0.0156, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-2.5178e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.077954
Average KL loss: 0.251529
Average total loss: 0.329483
tensor(0.0156, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-5.7106e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.082901
Average KL loss: 0.251726
Average total loss: 0.334627
tensor(0.0156, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(-6.3212e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.081290
Average KL loss: 0.251950
Average total loss: 0.333240
tensor(0.0156, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(-6.6640e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.076681
Average KL loss: 0.252141
Average total loss: 0.328821
tensor(0.0156, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(-8.2674e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.082557
Average KL loss: 0.252327
Average total loss: 0.334884
tensor(0.0156, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(5.0527e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.078476
Average KL loss: 0.252473
Average total loss: 0.330949
tensor(0.0157, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-7.3904e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.073127
Average KL loss: 0.252642
Average total loss: 0.325768
tensor(0.0157, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(-3.3832e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.075117
Average KL loss: 0.252832
Average total loss: 0.327949
tensor(0.0157, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(-5.3905e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.074990
Average KL loss: 0.253030
Average total loss: 0.328020
tensor(0.0157, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(-9.3813e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.077266
Average KL loss: 0.253253
Average total loss: 0.330519
tensor(0.0157, device='cuda:0') tensor(0.0500, device='cuda:0') tensor(-1.1492e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.073103
Average KL loss: 0.253465
Average total loss: 0.326568
tensor(0.0157, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(2.8966e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.072134
Average KL loss: 0.253610
Average total loss: 0.325744
tensor(0.0157, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(2.0568e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.075650
Average KL loss: 0.253749
Average total loss: 0.329399
tensor(0.0157, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(-5.5920e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.074515
Average KL loss: 0.253970
Average total loss: 0.328486
tensor(0.0158, device='cuda:0') tensor(0.0504, device='cuda:0') tensor(-8.0074e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.071454
Average KL loss: 0.254114
Average total loss: 0.325567
tensor(0.0158, device='cuda:0') tensor(0.0505, device='cuda:0') tensor(-8.1827e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.069398
Average KL loss: 0.254272
Average total loss: 0.323670
tensor(0.0158, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-3.0361e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.075567
Average KL loss: 0.254453
Average total loss: 0.330021
tensor(0.0158, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(-1.0190e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.069551
Average KL loss: 0.254621
Average total loss: 0.324172
tensor(0.0158, device='cuda:0') tensor(0.0508, device='cuda:0') tensor(1.5362e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.069337
Average KL loss: 0.254734
Average total loss: 0.324072
tensor(0.0158, device='cuda:0') tensor(0.0509, device='cuda:0') tensor(-4.4149e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.069742
Average KL loss: 0.254817
Average total loss: 0.324559
tensor(0.0158, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(-6.9962e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.071513
Average KL loss: 0.254874
Average total loss: 0.326387
tensor(0.0158, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(-4.5145e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.068953
Average KL loss: 0.254904
Average total loss: 0.323857
tensor(0.0158, device='cuda:0') tensor(0.0512, device='cuda:0') tensor(-3.3258e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.070313
Average KL loss: 0.255011
Average total loss: 0.325324
tensor(0.0158, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(-1.0998e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.073196
Average KL loss: 0.255180
Average total loss: 0.328376
tensor(0.0159, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(-4.4019e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.067163
Average KL loss: 0.255316
Average total loss: 0.322479
tensor(0.0159, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-4.0528e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.068507
Average KL loss: 0.255374
Average total loss: 0.323881
tensor(0.0159, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-3.5488e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.062637
Average KL loss: 0.255418
Average total loss: 0.318055
tensor(0.0159, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(2.2751e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.064639
Average KL loss: 0.255418
Average total loss: 0.320057
tensor(0.0159, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-5.9651e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.066847
Average KL loss: 0.255464
Average total loss: 0.322311
tensor(0.0159, device='cuda:0') tensor(0.0518, device='cuda:0') tensor(-8.5655e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.062349
Average KL loss: 0.255499
Average total loss: 0.317849
tensor(0.0159, device='cuda:0') tensor(0.0519, device='cuda:0') tensor(-5.9409e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.066186
Average KL loss: 0.255525
Average total loss: 0.321711
tensor(0.0159, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(-3.0709e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.064329
Average KL loss: 0.255633
Average total loss: 0.319962
tensor(0.0159, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(1.2329e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.064514
Average KL loss: 0.255627
Average total loss: 0.320141
tensor(0.0159, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(-5.4932e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.065123
Average KL loss: 0.255636
Average total loss: 0.320760
tensor(0.0159, device='cuda:0') tensor(0.0522, device='cuda:0') tensor(-6.4226e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.067208
Average KL loss: 0.255731
Average total loss: 0.322939
tensor(0.0159, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(-4.4422e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.063336
Average KL loss: 0.255828
Average total loss: 0.319165
tensor(0.0159, device='cuda:0') tensor(0.0524, device='cuda:0') tensor(-7.3585e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.064931
Average KL loss: 0.255867
Average total loss: 0.320798
tensor(0.0159, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(2.3628e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.060900
Average KL loss: 0.255926
Average total loss: 0.316826
tensor(0.0159, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(3.8434e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.059821
Average KL loss: 0.255904
Average total loss: 0.315725
tensor(0.0159, device='cuda:0') tensor(0.0526, device='cuda:0') tensor(9.6673e-11, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.064314
Average KL loss: 0.255873
Average total loss: 0.320187
tensor(0.0159, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(2.9272e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.064492
Average KL loss: 0.255918
Average total loss: 0.320409
tensor(0.0160, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(-4.9991e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.061281
Average KL loss: 0.255984
Average total loss: 0.317265
tensor(0.0160, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(-1.3122e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.060097
Average KL loss: 0.255949
Average total loss: 0.316046
tensor(0.0160, device='cuda:0') tensor(0.0529, device='cuda:0') tensor(-5.6742e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.056755
Average KL loss: 0.255946
Average total loss: 0.312700
tensor(0.0160, device='cuda:0') tensor(0.0530, device='cuda:0') tensor(1.2938e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.060046
Average KL loss: 0.255874
Average total loss: 0.315920
tensor(0.0160, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(5.5994e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.060024
Average KL loss: 0.255861
Average total loss: 0.315885
tensor(0.0160, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(-3.1362e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.062044
Average KL loss: 0.255879
Average total loss: 0.317922
tensor(0.0160, device='cuda:0') tensor(0.0532, device='cuda:0') tensor(-8.7362e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.058451
Average KL loss: 0.255883
Average total loss: 0.314334
tensor(0.0160, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(-7.0111e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.062309
Average KL loss: 0.255846
Average total loss: 0.318155
tensor(0.0160, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(-3.4678e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.061662
Average KL loss: 0.255881
Average total loss: 0.317543
tensor(0.0160, device='cuda:0') tensor(0.0534, device='cuda:0') tensor(-4.3092e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.057372
Average KL loss: 0.255903
Average total loss: 0.313275
tensor(0.0160, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(-4.8881e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.055817
Average KL loss: 0.255903
Average total loss: 0.311721
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-1.2347e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.060766
Average KL loss: 0.255853
Average total loss: 0.316618
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(4.6223e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.058618
Average KL loss: 0.255940
Average total loss: 0.314558
tensor(0.0160, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(1.3271e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.056616
Average KL loss: 0.255889
Average total loss: 0.312505
tensor(0.0160, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(-1.4597e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.059923
Average KL loss: 0.255826
Average total loss: 0.315749
tensor(0.0160, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(2.6830e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.060002
Average KL loss: 0.255861
Average total loss: 0.315863
tensor(0.0160, device='cuda:0') tensor(0.0539, device='cuda:0') tensor(4.6319e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.057231
Average KL loss: 0.255826
Average total loss: 0.313057
tensor(0.0160, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(-6.9936e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.056848
Average KL loss: 0.255825
Average total loss: 0.312673
tensor(0.0160, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(2.7826e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.058366
Average KL loss: 0.255805
Average total loss: 0.314171
tensor(0.0160, device='cuda:0') tensor(0.0541, device='cuda:0') tensor(2.0244e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.058949
Average KL loss: 0.255817
Average total loss: 0.314766
tensor(0.0160, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-2.4850e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.057235
Average KL loss: 0.255835
Average total loss: 0.313071
tensor(0.0160, device='cuda:0') tensor(0.0543, device='cuda:0') tensor(-7.2870e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.059293
Average KL loss: 0.255793
Average total loss: 0.315087
tensor(0.0160, device='cuda:0') tensor(0.0543, device='cuda:0') tensor(-1.5409e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.054588
Average KL loss: 0.255813
Average total loss: 0.310401
tensor(0.0160, device='cuda:0') tensor(0.0543, device='cuda:0') tensor(-2.2041e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.058244
Average KL loss: 0.255799
Average total loss: 0.314043
tensor(0.0160, device='cuda:0') tensor(0.0543, device='cuda:0') tensor(-1.7384e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.053816
Average KL loss: 0.255787
Average total loss: 0.309602
tensor(0.0160, device='cuda:0') tensor(0.0543, device='cuda:0') tensor(-3.2579e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.058307
Average KL loss: 0.255777
Average total loss: 0.314084
tensor(0.0160, device='cuda:0') tensor(0.0543, device='cuda:0') tensor(-2.7156e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.058802
Average KL loss: 0.255773
Average total loss: 0.314575
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-2.1707e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.057152
Average KL loss: 0.255767
Average total loss: 0.312919
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(2.7572e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.057189
Average KL loss: 0.255761
Average total loss: 0.312950
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-3.7968e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.057347
Average KL loss: 0.255751
Average total loss: 0.313098
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-2.3884e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.055368
Average KL loss: 0.255741
Average total loss: 0.311110
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(4.2255e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.052816
Average KL loss: 0.255729
Average total loss: 0.308546
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(2.4156e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.058164
Average KL loss: 0.255716
Average total loss: 0.313880
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(4.8657e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.061279
Average KL loss: 0.255710
Average total loss: 0.316989
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-1.1291e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.057097
Average KL loss: 0.255710
Average total loss: 0.312807
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-3.8797e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.055972
Average KL loss: 0.255697
Average total loss: 0.311669
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-6.8630e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.057309
Average KL loss: 0.255689
Average total loss: 0.312999
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(1.9037e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.057524
Average KL loss: 0.255682
Average total loss: 0.313206
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(2.5533e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.057382
Average KL loss: 0.255674
Average total loss: 0.313056
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-6.1064e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.059088
Average KL loss: 0.255667
Average total loss: 0.314755
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-3.5164e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.054612
Average KL loss: 0.255659
Average total loss: 0.310271
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-7.4769e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.058314
Average KL loss: 0.255654
Average total loss: 0.313968
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-4.8352e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.057784
Average KL loss: 0.255644
Average total loss: 0.313429
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-3.6770e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.055471
Average KL loss: 0.255638
Average total loss: 0.311109
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(2.1108e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.057590
Average KL loss: 0.255638
Average total loss: 0.313228
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-3.6581e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.057665
Average KL loss: 0.255637
Average total loss: 0.313302
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-6.9660e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.055905
Average KL loss: 0.255636
Average total loss: 0.311541
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(3.4914e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.058337
Average KL loss: 0.255635
Average total loss: 0.313972
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-7.8190e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.059482
Average KL loss: 0.255634
Average total loss: 0.315116
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(5.1811e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.054401
Average KL loss: 0.255632
Average total loss: 0.310034
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-2.2947e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.056774
Average KL loss: 0.255631
Average total loss: 0.312405
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-5.6648e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.054692
Average KL loss: 0.255630
Average total loss: 0.310321
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-8.6093e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.055449
Average KL loss: 0.255629
Average total loss: 0.311078
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(2.0206e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.058005
Average KL loss: 0.255628
Average total loss: 0.313633
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-4.9765e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.051710
Average KL loss: 0.255627
Average total loss: 0.307338
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-8.0871e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.057482
Average KL loss: 0.255627
Average total loss: 0.313109
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-1.4808e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.057731
Average KL loss: 0.255627
Average total loss: 0.313358
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-7.4669e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.053314
Average KL loss: 0.255627
Average total loss: 0.308941
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-1.1534e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.056310
Average KL loss: 0.255627
Average total loss: 0.311937
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(3.8880e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.056148
Average KL loss: 0.255626
Average total loss: 0.311775
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-5.7462e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.055339
Average KL loss: 0.255626
Average total loss: 0.310965
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-7.6744e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.056966
Average KL loss: 0.255626
Average total loss: 0.312592
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-2.5195e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.057788
Average KL loss: 0.255626
Average total loss: 0.313414
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(4.0967e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.053455
Average KL loss: 0.255626
Average total loss: 0.309081
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-1.7645e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.051938
Average KL loss: 0.255626
Average total loss: 0.307564
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-2.7897e-09, device='cuda:0')
 Percentile value: -1.6521818224646267e-07
Non-zero model percentage: 1.1529362201690674%, Non-zero mask percentage: 1.1529362201690674%

--- Pruning Level [20/24]: ---
conv1.weight         | nonzeros =     823 /    1728             ( 47.63%) | total_pruned =     905 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1303 /   36864             (  3.53%) | total_pruned =   35561 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1613 /   36864             (  4.38%) | total_pruned =   35251 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1389 /   36864             (  3.77%) | total_pruned =   35475 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1505 /   36864             (  4.08%) | total_pruned =   35359 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2497 /   73728             (  3.39%) | total_pruned =   71231 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3723 /  147456             (  2.52%) | total_pruned =  143733 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1405 /    8192             ( 17.15%) | total_pruned =    6787 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2046 /  147456             (  1.39%) | total_pruned =  145410 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1905 /  147456             (  1.29%) | total_pruned =  145551 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6338 /  294912             (  2.15%) | total_pruned =  288574 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    8674 /  589824             (  1.47%) | total_pruned =  581150 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      98 /     256             ( 38.28%) | total_pruned =     158 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2763 /   32768             (  8.43%) | total_pruned =   30005 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      69 /     256             ( 26.95%) | total_pruned =     187 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      84 /     256             ( 32.81%) | total_pruned =     172 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4391 /  589824             (  0.74%) | total_pruned =  585433 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      63 /     256             ( 24.61%) | total_pruned =     193 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4231 /  589824             (  0.72%) | total_pruned =  585593 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      65 /     256             ( 25.39%) | total_pruned =     191 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      56 /     256             ( 21.88%) | total_pruned =     200 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   11541 / 1179648             (  0.98%) | total_pruned = 1168107 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     405 /     512             ( 79.10%) | total_pruned =     107 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   10239 / 2359296             (  0.43%) | total_pruned = 2349057 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     134 /     512             ( 26.17%) | total_pruned =     378 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     193 /     512             ( 37.70%) | total_pruned =     319 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2419 /  131072             (  1.85%) | total_pruned =  128653 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     132 /     512             ( 25.78%) | total_pruned =     380 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     456 /     512             ( 89.06%) | total_pruned =      56 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   24088 / 2359296             (  1.02%) | total_pruned = 2335208 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      59 /     512             ( 11.52%) | total_pruned =     453 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     371 /     512             ( 72.46%) | total_pruned =     141 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   27515 / 2359296             (  1.17%) | total_pruned = 2331781 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
linear.weight        | nonzeros =    1476 /    5120             ( 28.83%) | total_pruned =    3644 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 128884, pruned : 11049878, total: 11178762, Compression rate :      86.74x  ( 98.85% pruned)
Train Epoch: 20/100 Loss: 0.001101 Accuracy: 84.86 100.00 % Best test Accuracy: 85.12%
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-4.3663e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.086567
Average KL loss: 0.250701
Average total loss: 0.337268
tensor(0.0155, device='cuda:0') tensor(0.0499, device='cuda:0') tensor(-3.9655e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.092389
Average KL loss: 0.248740
Average total loss: 0.341129
tensor(0.0154, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-1.3679e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.097227
Average KL loss: 0.248645
Average total loss: 0.345872
tensor(0.0154, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-7.6353e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.089357
Average KL loss: 0.248847
Average total loss: 0.338204
tensor(0.0154, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-7.4726e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.096446
Average KL loss: 0.249107
Average total loss: 0.345553
tensor(0.0154, device='cuda:0') tensor(0.0484, device='cuda:0') tensor(-1.4545e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.091777
Average KL loss: 0.249455
Average total loss: 0.341232
tensor(0.0154, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-4.5280e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.092282
Average KL loss: 0.249799
Average total loss: 0.342081
tensor(0.0154, device='cuda:0') tensor(0.0486, device='cuda:0') tensor(-9.0081e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.081788
Average KL loss: 0.250169
Average total loss: 0.331956
tensor(0.0154, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-5.8897e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.082545
Average KL loss: 0.250423
Average total loss: 0.332968
tensor(0.0155, device='cuda:0') tensor(0.0488, device='cuda:0') tensor(-7.8885e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.086508
Average KL loss: 0.250664
Average total loss: 0.337171
tensor(0.0155, device='cuda:0') tensor(0.0490, device='cuda:0') tensor(-2.0875e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.083655
Average KL loss: 0.250954
Average total loss: 0.334609
tensor(0.0155, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(-5.8213e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.083849
Average KL loss: 0.251262
Average total loss: 0.335111
tensor(0.0155, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(3.0378e-11, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.084379
Average KL loss: 0.251557
Average total loss: 0.335936
tensor(0.0155, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(-1.2975e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.083227
Average KL loss: 0.251841
Average total loss: 0.335067
tensor(0.0155, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.1404e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.079838
Average KL loss: 0.252105
Average total loss: 0.331943
tensor(0.0156, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(1.1272e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.082433
Average KL loss: 0.252390
Average total loss: 0.334823
tensor(0.0156, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(-6.9662e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.078785
Average KL loss: 0.252658
Average total loss: 0.331443
tensor(0.0156, device='cuda:0') tensor(0.0499, device='cuda:0') tensor(-3.9268e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.076661
Average KL loss: 0.252884
Average total loss: 0.329546
tensor(0.0156, device='cuda:0') tensor(0.0500, device='cuda:0') tensor(-3.2112e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.077172
Average KL loss: 0.253148
Average total loss: 0.330320
tensor(0.0156, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-2.5421e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.074986
Average KL loss: 0.253348
Average total loss: 0.328334
tensor(0.0156, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(-6.4552e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.078023
Average KL loss: 0.253519
Average total loss: 0.331542
tensor(0.0157, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(-2.6537e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.074088
Average KL loss: 0.253721
Average total loss: 0.327808
tensor(0.0157, device='cuda:0') tensor(0.0504, device='cuda:0') tensor(1.2454e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.074383
Average KL loss: 0.253912
Average total loss: 0.328295
tensor(0.0157, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-4.5846e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.074225
Average KL loss: 0.254127
Average total loss: 0.328353
tensor(0.0157, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(-6.2529e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.074955
Average KL loss: 0.254278
Average total loss: 0.329234
tensor(0.0157, device='cuda:0') tensor(0.0508, device='cuda:0') tensor(-4.3356e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.071444
Average KL loss: 0.254444
Average total loss: 0.325888
tensor(0.0157, device='cuda:0') tensor(0.0509, device='cuda:0') tensor(3.2471e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.068903
Average KL loss: 0.254578
Average total loss: 0.323481
tensor(0.0157, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(-1.3926e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.068600
Average KL loss: 0.254694
Average total loss: 0.323294
tensor(0.0157, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(-6.5465e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.068344
Average KL loss: 0.254828
Average total loss: 0.323171
tensor(0.0157, device='cuda:0') tensor(0.0512, device='cuda:0') tensor(-6.3492e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.068288
Average KL loss: 0.254934
Average total loss: 0.323223
tensor(0.0158, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(-1.5139e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.068820
Average KL loss: 0.255039
Average total loss: 0.323859
tensor(0.0158, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(-2.9860e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.064920
Average KL loss: 0.255174
Average total loss: 0.320094
tensor(0.0158, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-1.2939e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.071318
Average KL loss: 0.255318
Average total loss: 0.326636
tensor(0.0158, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-5.9580e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.068180
Average KL loss: 0.255431
Average total loss: 0.323611
tensor(0.0158, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-1.9516e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.065551
Average KL loss: 0.255521
Average total loss: 0.321073
tensor(0.0158, device='cuda:0') tensor(0.0518, device='cuda:0') tensor(-2.7572e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.065084
Average KL loss: 0.255616
Average total loss: 0.320700
tensor(0.0158, device='cuda:0') tensor(0.0519, device='cuda:0') tensor(-3.6917e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.071257
Average KL loss: 0.255688
Average total loss: 0.326945
tensor(0.0158, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(-1.0124e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.062569
Average KL loss: 0.255827
Average total loss: 0.318396
tensor(0.0158, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(3.0868e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.067524
Average KL loss: 0.255901
Average total loss: 0.323425
tensor(0.0158, device='cuda:0') tensor(0.0522, device='cuda:0') tensor(-2.4086e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.066509
Average KL loss: 0.256014
Average total loss: 0.322523
tensor(0.0159, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(-5.8193e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.066557
Average KL loss: 0.256137
Average total loss: 0.322694
tensor(0.0159, device='cuda:0') tensor(0.0524, device='cuda:0') tensor(-3.5656e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.059378
Average KL loss: 0.256223
Average total loss: 0.315600
tensor(0.0159, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-1.0473e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.065739
Average KL loss: 0.256274
Average total loss: 0.322013
tensor(0.0159, device='cuda:0') tensor(0.0526, device='cuda:0') tensor(-4.8033e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.063494
Average KL loss: 0.256343
Average total loss: 0.319837
tensor(0.0159, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(-3.5217e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.061855
Average KL loss: 0.256375
Average total loss: 0.318230
tensor(0.0159, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(5.3801e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.065272
Average KL loss: 0.256455
Average total loss: 0.321727
tensor(0.0159, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(-5.4229e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.063694
Average KL loss: 0.256497
Average total loss: 0.320191
tensor(0.0159, device='cuda:0') tensor(0.0529, device='cuda:0') tensor(-2.3392e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.057891
Average KL loss: 0.256524
Average total loss: 0.314414
tensor(0.0159, device='cuda:0') tensor(0.0530, device='cuda:0') tensor(1.4533e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.060301
Average KL loss: 0.256530
Average total loss: 0.316831
tensor(0.0159, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(-2.3608e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.062730
Average KL loss: 0.256570
Average total loss: 0.319300
tensor(0.0159, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(-3.3160e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.060814
Average KL loss: 0.256587
Average total loss: 0.317401
tensor(0.0159, device='cuda:0') tensor(0.0532, device='cuda:0') tensor(-1.9633e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.061354
Average KL loss: 0.256599
Average total loss: 0.317952
tensor(0.0159, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(-1.8813e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.061159
Average KL loss: 0.256619
Average total loss: 0.317778
tensor(0.0159, device='cuda:0') tensor(0.0534, device='cuda:0') tensor(1.9897e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.062969
Average KL loss: 0.256644
Average total loss: 0.319614
tensor(0.0159, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(-1.3838e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.060749
Average KL loss: 0.256697
Average total loss: 0.317446
tensor(0.0159, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(-3.1151e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.059537
Average KL loss: 0.256719
Average total loss: 0.316256
tensor(0.0160, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(6.8077e-11, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.058056
Average KL loss: 0.256696
Average total loss: 0.314752
tensor(0.0160, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(-7.0280e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.057784
Average KL loss: 0.256726
Average total loss: 0.314510
tensor(0.0160, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(-2.5716e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.055721
Average KL loss: 0.256705
Average total loss: 0.312427
tensor(0.0160, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(1.4546e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.059511
Average KL loss: 0.256669
Average total loss: 0.316180
tensor(0.0160, device='cuda:0') tensor(0.0539, device='cuda:0') tensor(-3.6982e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.059387
Average KL loss: 0.256674
Average total loss: 0.316060
tensor(0.0160, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(-3.1739e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.057446
Average KL loss: 0.256717
Average total loss: 0.314163
tensor(0.0160, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(-5.6632e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.059387
Average KL loss: 0.256700
Average total loss: 0.316088
tensor(0.0160, device='cuda:0') tensor(0.0541, device='cuda:0') tensor(1.6235e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.056363
Average KL loss: 0.256720
Average total loss: 0.313083
tensor(0.0160, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-2.2507e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.054916
Average KL loss: 0.256740
Average total loss: 0.311657
tensor(0.0160, device='cuda:0') tensor(0.0543, device='cuda:0') tensor(8.8089e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.055922
Average KL loss: 0.256746
Average total loss: 0.312668
tensor(0.0160, device='cuda:0') tensor(0.0543, device='cuda:0') tensor(-1.5451e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.061562
Average KL loss: 0.256754
Average total loss: 0.318317
tensor(0.0160, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-3.1217e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.057278
Average KL loss: 0.256808
Average total loss: 0.314086
tensor(0.0160, device='cuda:0') tensor(0.0545, device='cuda:0') tensor(-5.3432e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.056992
Average KL loss: 0.256785
Average total loss: 0.313777
tensor(0.0160, device='cuda:0') tensor(0.0546, device='cuda:0') tensor(-3.9731e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.057006
Average KL loss: 0.256771
Average total loss: 0.313777
tensor(0.0160, device='cuda:0') tensor(0.0546, device='cuda:0') tensor(1.8204e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.057011
Average KL loss: 0.256768
Average total loss: 0.313779
tensor(0.0160, device='cuda:0') tensor(0.0547, device='cuda:0') tensor(1.8633e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.054744
Average KL loss: 0.256760
Average total loss: 0.311504
tensor(0.0160, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(-6.3602e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.055838
Average KL loss: 0.256730
Average total loss: 0.312568
tensor(0.0160, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(1.1821e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.056627
Average KL loss: 0.256680
Average total loss: 0.313306
tensor(0.0160, device='cuda:0') tensor(0.0549, device='cuda:0') tensor(-2.7460e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.060519
Average KL loss: 0.256690
Average total loss: 0.317210
tensor(0.0160, device='cuda:0') tensor(0.0550, device='cuda:0') tensor(-4.4763e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.054961
Average KL loss: 0.256695
Average total loss: 0.311657
tensor(0.0160, device='cuda:0') tensor(0.0551, device='cuda:0') tensor(-4.1366e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.054827
Average KL loss: 0.256702
Average total loss: 0.311529
tensor(0.0160, device='cuda:0') tensor(0.0551, device='cuda:0') tensor(-5.1086e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.053807
Average KL loss: 0.256719
Average total loss: 0.310525
tensor(0.0160, device='cuda:0') tensor(0.0552, device='cuda:0') tensor(-1.9821e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.055586
Average KL loss: 0.256698
Average total loss: 0.312285
tensor(0.0160, device='cuda:0') tensor(0.0553, device='cuda:0') tensor(-4.1651e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.051440
Average KL loss: 0.256671
Average total loss: 0.308111
tensor(0.0160, device='cuda:0') tensor(0.0553, device='cuda:0') tensor(1.6968e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.057547
Average KL loss: 0.256629
Average total loss: 0.314176
tensor(0.0161, device='cuda:0') tensor(0.0554, device='cuda:0') tensor(-4.6489e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.052258
Average KL loss: 0.256646
Average total loss: 0.308904
tensor(0.0161, device='cuda:0') tensor(0.0555, device='cuda:0') tensor(3.2549e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.054667
Average KL loss: 0.256626
Average total loss: 0.311293
tensor(0.0161, device='cuda:0') tensor(0.0555, device='cuda:0') tensor(-3.4521e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.053508
Average KL loss: 0.256650
Average total loss: 0.310158
tensor(0.0161, device='cuda:0') tensor(0.0556, device='cuda:0') tensor(-2.0353e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.053418
Average KL loss: 0.256609
Average total loss: 0.310027
tensor(0.0161, device='cuda:0') tensor(0.0557, device='cuda:0') tensor(-2.7251e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.058865
Average KL loss: 0.256612
Average total loss: 0.315476
tensor(0.0161, device='cuda:0') tensor(0.0558, device='cuda:0') tensor(-1.1408e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.058515
Average KL loss: 0.256647
Average total loss: 0.315162
tensor(0.0161, device='cuda:0') tensor(0.0558, device='cuda:0') tensor(-4.2332e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.061446
Average KL loss: 0.256686
Average total loss: 0.318132
tensor(0.0161, device='cuda:0') tensor(0.0559, device='cuda:0') tensor(-6.5899e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.052568
Average KL loss: 0.256723
Average total loss: 0.309291
tensor(0.0161, device='cuda:0') tensor(0.0560, device='cuda:0') tensor(6.2518e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.052688
Average KL loss: 0.256722
Average total loss: 0.309409
tensor(0.0161, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(3.1928e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.052099
Average KL loss: 0.256721
Average total loss: 0.308820
tensor(0.0161, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(-1.1686e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.055047
Average KL loss: 0.256713
Average total loss: 0.311759
tensor(0.0161, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(9.1054e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.053561
Average KL loss: 0.256702
Average total loss: 0.310263
tensor(0.0161, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(8.0022e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.051477
Average KL loss: 0.256695
Average total loss: 0.308172
tensor(0.0161, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(-4.6994e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.052583
Average KL loss: 0.256682
Average total loss: 0.309265
tensor(0.0161, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(-5.4281e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.054214
Average KL loss: 0.256671
Average total loss: 0.310886
tensor(0.0161, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(1.3236e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.051023
Average KL loss: 0.256659
Average total loss: 0.307682
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-3.3731e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.054099
Average KL loss: 0.256646
Average total loss: 0.310745
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-2.4296e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.048716
Average KL loss: 0.256629
Average total loss: 0.305345
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(5.4314e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.052478
Average KL loss: 0.256616
Average total loss: 0.309094
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-5.5875e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.054465
Average KL loss: 0.256600
Average total loss: 0.311065
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-2.1846e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.049358
Average KL loss: 0.256586
Average total loss: 0.305944
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-2.5564e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.056140
Average KL loss: 0.256572
Average total loss: 0.312711
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-8.1604e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.054492
Average KL loss: 0.256560
Average total loss: 0.311052
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-6.9922e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.052244
Average KL loss: 0.256550
Average total loss: 0.308794
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-4.5073e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.054005
Average KL loss: 0.256546
Average total loss: 0.310550
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-2.2821e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.053025
Average KL loss: 0.256534
Average total loss: 0.309560
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-1.8248e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.051987
Average KL loss: 0.256522
Average total loss: 0.308509
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-4.4487e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.054392
Average KL loss: 0.256513
Average total loss: 0.310905
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-1.4028e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.048186
Average KL loss: 0.256501
Average total loss: 0.304687
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(1.3432e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.051171
Average KL loss: 0.256480
Average total loss: 0.307650
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-4.7465e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.055289
Average KL loss: 0.256467
Average total loss: 0.311756
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-3.3174e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.050487
Average KL loss: 0.256457
Average total loss: 0.306944
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-4.4770e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.053558
Average KL loss: 0.256444
Average total loss: 0.310002
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-8.8603e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.050646
Average KL loss: 0.256432
Average total loss: 0.307078
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-7.9125e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.053627
Average KL loss: 0.256423
Average total loss: 0.310050
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(2.0563e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.052635
Average KL loss: 0.256412
Average total loss: 0.309046
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-1.4057e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.050507
Average KL loss: 0.256400
Average total loss: 0.306907
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(2.6117e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.050651
Average KL loss: 0.256385
Average total loss: 0.307036
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-6.3296e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.050599
Average KL loss: 0.256368
Average total loss: 0.306967
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-5.9960e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.053998
Average KL loss: 0.256353
Average total loss: 0.310351
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(7.5598e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.051856
Average KL loss: 0.256348
Average total loss: 0.308203
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-1.8935e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.049704
Average KL loss: 0.256346
Average total loss: 0.306050
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-4.8389e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.053147
Average KL loss: 0.256345
Average total loss: 0.309492
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-3.7702e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.053182
Average KL loss: 0.256344
Average total loss: 0.309526
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-3.2320e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.049511
Average KL loss: 0.256343
Average total loss: 0.305854
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(2.1718e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.052150
Average KL loss: 0.256342
Average total loss: 0.308491
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(1.4228e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.052276
Average KL loss: 0.256341
Average total loss: 0.308617
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(8.2918e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.053488
Average KL loss: 0.256340
Average total loss: 0.309828
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(1.3556e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.052314
Average KL loss: 0.256339
Average total loss: 0.308653
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(2.1009e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.052912
Average KL loss: 0.256338
Average total loss: 0.309250
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-5.5984e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.051783
Average KL loss: 0.256337
Average total loss: 0.308120
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-6.7752e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.052686
Average KL loss: 0.256336
Average total loss: 0.309022
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(2.8904e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.054569
Average KL loss: 0.256336
Average total loss: 0.310906
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-2.9594e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.055324
Average KL loss: 0.256336
Average total loss: 0.311660
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-2.6846e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.050234
Average KL loss: 0.256336
Average total loss: 0.306570
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-3.8876e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.055265
Average KL loss: 0.256336
Average total loss: 0.311601
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-4.0955e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.051689
Average KL loss: 0.256336
Average total loss: 0.308024
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-5.2281e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.053746
Average KL loss: 0.256336
Average total loss: 0.310081
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-4.2069e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.052006
Average KL loss: 0.256335
Average total loss: 0.308341
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-4.3649e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.051639
Average KL loss: 0.256335
Average total loss: 0.307974
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-2.9558e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.051550
Average KL loss: 0.256335
Average total loss: 0.307885
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-1.0480e-10, device='cuda:0')
 Percentile value: -1.6522089651971328e-07
Non-zero model percentage: 0.9223561882972717%, Non-zero mask percentage: 0.9223561882972717%

--- Pruning Level [21/24]: ---
conv1.weight         | nonzeros =     816 /    1728             ( 47.22%) | total_pruned =     912 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1253 /   36864             (  3.40%) | total_pruned =   35611 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1572 /   36864             (  4.26%) | total_pruned =   35292 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1355 /   36864             (  3.68%) | total_pruned =   35509 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1475 /   36864             (  4.00%) | total_pruned =   35389 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2425 /   73728             (  3.29%) | total_pruned =   71303 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3608 /  147456             (  2.45%) | total_pruned =  143848 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1384 /    8192             ( 16.89%) | total_pruned =    6808 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1910 /  147456             (  1.30%) | total_pruned =  145546 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1793 /  147456             (  1.22%) | total_pruned =  145663 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6137 /  294912             (  2.08%) | total_pruned =  288775 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      65 /     256             ( 25.39%) | total_pruned =     191 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    8357 /  589824             (  1.42%) | total_pruned =  581467 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      85 /     256             ( 33.20%) | total_pruned =     171 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2699 /   32768             (  8.24%) | total_pruned =   30069 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3588 /  589824             (  0.61%) | total_pruned =  586236 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      44 /     256             ( 17.19%) | total_pruned =     212 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      62 /     256             ( 24.22%) | total_pruned =     194 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3471 /  589824             (  0.59%) | total_pruned =  586353 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      61 /     256             ( 23.83%) | total_pruned =     195 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   10965 / 1179648             (  0.93%) | total_pruned = 1168683 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      89 /     512             ( 17.38%) | total_pruned =     423 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     398 /     512             ( 77.73%) | total_pruned =     114 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    9428 / 2359296             (  0.40%) | total_pruned = 2349868 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     124 /     512             ( 24.22%) | total_pruned =     388 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     182 /     512             ( 35.55%) | total_pruned =     330 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2279 /  131072             (  1.74%) | total_pruned =  128793 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     123 /     512             ( 24.02%) | total_pruned =     389 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     454 /     512             ( 88.67%) | total_pruned =      58 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     190 /     512             ( 37.11%) | total_pruned =     322 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   14426 / 2359296             (  0.61%) | total_pruned = 2344870 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     370 /     512             ( 72.27%) | total_pruned =     142 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      50 /     512             (  9.77%) | total_pruned =     462 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   15864 / 2359296             (  0.67%) | total_pruned = 2343432 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     103 /     512             ( 20.12%) | total_pruned =     409 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     372 /     512             ( 72.66%) | total_pruned =     140 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
linear.weight        | nonzeros =    1465 /    5120             ( 28.61%) | total_pruned =    3655 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 103108, pruned : 11075654, total: 11178762, Compression rate :     108.42x  ( 99.08% pruned)
Train Epoch: 21/100 Loss: 0.000070 Accuracy: 84.91 100.00 % Best test Accuracy: 85.03%
tensor(0.0161, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-3.4914e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.080328
Average KL loss: 0.251616
Average total loss: 0.331944
tensor(0.0156, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-7.1581e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.081629
Average KL loss: 0.249653
Average total loss: 0.331282
tensor(0.0154, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(-6.1753e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.083935
Average KL loss: 0.249336
Average total loss: 0.333270
tensor(0.0154, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(-9.5076e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.083366
Average KL loss: 0.249431
Average total loss: 0.332797
tensor(0.0154, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(-9.1683e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.088198
Average KL loss: 0.249706
Average total loss: 0.337904
tensor(0.0154, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(-1.6608e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.077225
Average KL loss: 0.250010
Average total loss: 0.327235
tensor(0.0154, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(-1.2327e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.087194
Average KL loss: 0.250288
Average total loss: 0.337482
tensor(0.0154, device='cuda:0') tensor(0.0500, device='cuda:0') tensor(-2.3554e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.082934
Average KL loss: 0.250628
Average total loss: 0.333561
tensor(0.0155, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-1.0374e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.078824
Average KL loss: 0.250909
Average total loss: 0.329733
tensor(0.0155, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(-1.9437e-13, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.078293
Average KL loss: 0.251161
Average total loss: 0.329454
tensor(0.0155, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(-7.5153e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.078837
Average KL loss: 0.251408
Average total loss: 0.330246
tensor(0.0155, device='cuda:0') tensor(0.0504, device='cuda:0') tensor(-3.6925e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.080166
Average KL loss: 0.251676
Average total loss: 0.331842
tensor(0.0155, device='cuda:0') tensor(0.0505, device='cuda:0') tensor(-5.2540e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.073121
Average KL loss: 0.251946
Average total loss: 0.325068
tensor(0.0155, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-3.4323e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.075760
Average KL loss: 0.252152
Average total loss: 0.327912
tensor(0.0155, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(-5.7282e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.072780
Average KL loss: 0.252327
Average total loss: 0.325106
tensor(0.0156, device='cuda:0') tensor(0.0508, device='cuda:0') tensor(1.0702e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.074816
Average KL loss: 0.252518
Average total loss: 0.327335
tensor(0.0156, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(-1.0972e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.077304
Average KL loss: 0.252776
Average total loss: 0.330080
tensor(0.0156, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(-1.0365e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.069398
Average KL loss: 0.252993
Average total loss: 0.322391
tensor(0.0156, device='cuda:0') tensor(0.0512, device='cuda:0') tensor(-9.5524e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.069418
Average KL loss: 0.253192
Average total loss: 0.322611
tensor(0.0156, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(-8.3550e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.069834
Average KL loss: 0.253366
Average total loss: 0.323200
tensor(0.0156, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(-7.2383e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.071875
Average KL loss: 0.253522
Average total loss: 0.325397
tensor(0.0157, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-5.1387e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.066528
Average KL loss: 0.253716
Average total loss: 0.320244
tensor(0.0157, device='cuda:0') tensor(0.0517, device='cuda:0') tensor(-4.9465e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.065172
Average KL loss: 0.253848
Average total loss: 0.319020
tensor(0.0157, device='cuda:0') tensor(0.0518, device='cuda:0') tensor(-2.4650e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.066806
Average KL loss: 0.254012
Average total loss: 0.320818
tensor(0.0157, device='cuda:0') tensor(0.0519, device='cuda:0') tensor(-7.0039e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.067653
Average KL loss: 0.254164
Average total loss: 0.321817
tensor(0.0157, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(-5.1596e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.071340
Average KL loss: 0.254395
Average total loss: 0.325735
tensor(0.0157, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(2.1497e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.066834
Average KL loss: 0.254532
Average total loss: 0.321366
tensor(0.0157, device='cuda:0') tensor(0.0522, device='cuda:0') tensor(-1.2454e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.066953
Average KL loss: 0.254658
Average total loss: 0.321611
tensor(0.0157, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(-1.8923e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.065325
Average KL loss: 0.254767
Average total loss: 0.320091
tensor(0.0157, device='cuda:0') tensor(0.0524, device='cuda:0') tensor(-3.1031e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.065366
Average KL loss: 0.254884
Average total loss: 0.320250
tensor(0.0158, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(1.0381e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.066646
Average KL loss: 0.255050
Average total loss: 0.321696
tensor(0.0158, device='cuda:0') tensor(0.0526, device='cuda:0') tensor(-3.9461e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.064458
Average KL loss: 0.255167
Average total loss: 0.319625
tensor(0.0158, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(-2.5028e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.062994
Average KL loss: 0.255267
Average total loss: 0.318262
tensor(0.0158, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(-2.7570e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.061898
Average KL loss: 0.255371
Average total loss: 0.317269
tensor(0.0158, device='cuda:0') tensor(0.0529, device='cuda:0') tensor(3.2659e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.062131
Average KL loss: 0.255480
Average total loss: 0.317612
tensor(0.0158, device='cuda:0') tensor(0.0530, device='cuda:0') tensor(-5.9957e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.063470
Average KL loss: 0.255556
Average total loss: 0.319026
tensor(0.0158, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(-8.0048e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.060537
Average KL loss: 0.255626
Average total loss: 0.316163
tensor(0.0158, device='cuda:0') tensor(0.0532, device='cuda:0') tensor(-7.7813e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.057637
Average KL loss: 0.255658
Average total loss: 0.313295
tensor(0.0158, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(-9.9240e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.060513
Average KL loss: 0.255693
Average total loss: 0.316207
tensor(0.0158, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(8.7146e-11, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.060782
Average KL loss: 0.255764
Average total loss: 0.316546
tensor(0.0158, device='cuda:0') tensor(0.0534, device='cuda:0') tensor(-3.7786e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.060325
Average KL loss: 0.255813
Average total loss: 0.316139
tensor(0.0159, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(-6.9865e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.061676
Average KL loss: 0.255919
Average total loss: 0.317595
tensor(0.0159, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-9.2281e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.062845
Average KL loss: 0.255997
Average total loss: 0.318842
tensor(0.0159, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(-8.2050e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.056340
Average KL loss: 0.256024
Average total loss: 0.312365
tensor(0.0159, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(2.5195e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.056214
Average KL loss: 0.256040
Average total loss: 0.312254
tensor(0.0159, device='cuda:0') tensor(0.0539, device='cuda:0') tensor(-1.4189e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.055769
Average KL loss: 0.256028
Average total loss: 0.311797
tensor(0.0159, device='cuda:0') tensor(0.0539, device='cuda:0') tensor(-3.9544e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.059233
Average KL loss: 0.256028
Average total loss: 0.315260
tensor(0.0159, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(1.5891e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.057284
Average KL loss: 0.256034
Average total loss: 0.313318
tensor(0.0159, device='cuda:0') tensor(0.0541, device='cuda:0') tensor(-2.1164e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.055377
Average KL loss: 0.256002
Average total loss: 0.311380
tensor(0.0159, device='cuda:0') tensor(0.0541, device='cuda:0') tensor(2.4011e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.058441
Average KL loss: 0.256013
Average total loss: 0.314454
tensor(0.0159, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-2.0199e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.058206
Average KL loss: 0.256065
Average total loss: 0.314271
tensor(0.0159, device='cuda:0') tensor(0.0543, device='cuda:0') tensor(-7.9600e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.052755
Average KL loss: 0.256085
Average total loss: 0.308841
tensor(0.0159, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(6.8563e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.060774
Average KL loss: 0.256098
Average total loss: 0.316872
tensor(0.0159, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(3.2373e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.058169
Average KL loss: 0.256129
Average total loss: 0.314299
tensor(0.0159, device='cuda:0') tensor(0.0545, device='cuda:0') tensor(-2.4517e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.055036
Average KL loss: 0.256182
Average total loss: 0.311218
tensor(0.0159, device='cuda:0') tensor(0.0546, device='cuda:0') tensor(-6.7784e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.055461
Average KL loss: 0.256220
Average total loss: 0.311681
tensor(0.0159, device='cuda:0') tensor(0.0547, device='cuda:0') tensor(1.8670e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.057105
Average KL loss: 0.256216
Average total loss: 0.313322
tensor(0.0159, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(-1.8849e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.055296
Average KL loss: 0.256218
Average total loss: 0.311514
tensor(0.0159, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(-3.3404e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.052476
Average KL loss: 0.256190
Average total loss: 0.308667
tensor(0.0159, device='cuda:0') tensor(0.0549, device='cuda:0') tensor(-5.1927e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.057133
Average KL loss: 0.256200
Average total loss: 0.313333
tensor(0.0160, device='cuda:0') tensor(0.0550, device='cuda:0') tensor(1.4320e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.056443
Average KL loss: 0.256278
Average total loss: 0.312721
tensor(0.0160, device='cuda:0') tensor(0.0551, device='cuda:0') tensor(-1.3628e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.055282
Average KL loss: 0.256312
Average total loss: 0.311594
tensor(0.0160, device='cuda:0') tensor(0.0552, device='cuda:0') tensor(-3.1223e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.051046
Average KL loss: 0.256331
Average total loss: 0.307377
tensor(0.0160, device='cuda:0') tensor(0.0552, device='cuda:0') tensor(-5.5310e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.052611
Average KL loss: 0.256262
Average total loss: 0.308872
tensor(0.0160, device='cuda:0') tensor(0.0553, device='cuda:0') tensor(-3.0034e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.051046
Average KL loss: 0.256265
Average total loss: 0.307311
tensor(0.0160, device='cuda:0') tensor(0.0554, device='cuda:0') tensor(-2.1417e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.054798
Average KL loss: 0.256246
Average total loss: 0.311044
tensor(0.0160, device='cuda:0') tensor(0.0554, device='cuda:0') tensor(-4.0012e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.056199
Average KL loss: 0.256288
Average total loss: 0.312487
tensor(0.0160, device='cuda:0') tensor(0.0555, device='cuda:0') tensor(-6.5465e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.052576
Average KL loss: 0.256326
Average total loss: 0.308902
tensor(0.0160, device='cuda:0') tensor(0.0556, device='cuda:0') tensor(-2.6943e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.053110
Average KL loss: 0.256326
Average total loss: 0.309437
tensor(0.0160, device='cuda:0') tensor(0.0557, device='cuda:0') tensor(-4.3099e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.053752
Average KL loss: 0.256350
Average total loss: 0.310102
tensor(0.0160, device='cuda:0') tensor(0.0558, device='cuda:0') tensor(-4.2510e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.055931
Average KL loss: 0.256361
Average total loss: 0.312292
tensor(0.0160, device='cuda:0') tensor(0.0558, device='cuda:0') tensor(-7.8408e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.054122
Average KL loss: 0.256403
Average total loss: 0.310526
tensor(0.0160, device='cuda:0') tensor(0.0559, device='cuda:0') tensor(-6.6127e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.053600
Average KL loss: 0.256441
Average total loss: 0.310040
tensor(0.0160, device='cuda:0') tensor(0.0560, device='cuda:0') tensor(-2.2064e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.054849
Average KL loss: 0.256455
Average total loss: 0.311304
tensor(0.0160, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(1.1134e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.050965
Average KL loss: 0.256442
Average total loss: 0.307407
tensor(0.0160, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(2.1947e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.053274
Average KL loss: 0.256398
Average total loss: 0.309673
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-1.7100e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.054400
Average KL loss: 0.256354
Average total loss: 0.310754
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(2.5306e-11, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.054044
Average KL loss: 0.256345
Average total loss: 0.310389
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-2.9055e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.052730
Average KL loss: 0.256334
Average total loss: 0.309064
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-5.9233e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.048815
Average KL loss: 0.256327
Average total loss: 0.305142
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-3.4369e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.053142
Average KL loss: 0.256315
Average total loss: 0.309457
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-1.1160e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.050457
Average KL loss: 0.256305
Average total loss: 0.306763
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(7.2351e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.048782
Average KL loss: 0.256294
Average total loss: 0.305076
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-1.5587e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.050999
Average KL loss: 0.256283
Average total loss: 0.307281
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-5.1175e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.054598
Average KL loss: 0.256279
Average total loss: 0.310877
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-4.0005e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.050065
Average KL loss: 0.256269
Average total loss: 0.306334
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-5.0025e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.051481
Average KL loss: 0.256259
Average total loss: 0.307740
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-2.8816e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.050991
Average KL loss: 0.256249
Average total loss: 0.307240
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(8.7114e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.052981
Average KL loss: 0.256240
Average total loss: 0.309221
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-7.0368e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.052186
Average KL loss: 0.256232
Average total loss: 0.308418
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-1.6217e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.050381
Average KL loss: 0.256221
Average total loss: 0.306602
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-4.9610e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.048551
Average KL loss: 0.256212
Average total loss: 0.304763
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-6.2703e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.047673
Average KL loss: 0.256196
Average total loss: 0.303869
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-1.8767e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.053686
Average KL loss: 0.256184
Average total loss: 0.309870
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-1.7673e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.053999
Average KL loss: 0.256181
Average total loss: 0.310180
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-4.8684e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.052142
Average KL loss: 0.256177
Average total loss: 0.308318
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-2.6203e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.049932
Average KL loss: 0.256165
Average total loss: 0.306097
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-2.8837e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.055379
Average KL loss: 0.256152
Average total loss: 0.311532
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-6.3176e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.055829
Average KL loss: 0.256153
Average total loss: 0.311981
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-4.8745e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.051183
Average KL loss: 0.256147
Average total loss: 0.307330
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(1.2555e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.051395
Average KL loss: 0.256137
Average total loss: 0.307532
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(1.1128e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.050094
Average KL loss: 0.256131
Average total loss: 0.306225
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-5.4524e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.052534
Average KL loss: 0.256121
Average total loss: 0.308655
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-2.5615e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.049743
Average KL loss: 0.256114
Average total loss: 0.305857
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(1.4700e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.049681
Average KL loss: 0.256111
Average total loss: 0.305792
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(4.7111e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.052006
Average KL loss: 0.256110
Average total loss: 0.308116
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-2.9493e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.050280
Average KL loss: 0.256109
Average total loss: 0.306389
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-4.6555e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.051196
Average KL loss: 0.256108
Average total loss: 0.307304
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-1.3113e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.053626
Average KL loss: 0.256107
Average total loss: 0.309733
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-3.3454e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.052843
Average KL loss: 0.256107
Average total loss: 0.308950
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-6.7715e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.051901
Average KL loss: 0.256106
Average total loss: 0.308007
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(4.0083e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.050192
Average KL loss: 0.256105
Average total loss: 0.306297
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-3.8824e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.051816
Average KL loss: 0.256104
Average total loss: 0.307920
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-3.0335e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.049585
Average KL loss: 0.256104
Average total loss: 0.305688
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-7.7697e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.052619
Average KL loss: 0.256103
Average total loss: 0.308723
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(2.2691e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.053000
Average KL loss: 0.256103
Average total loss: 0.309103
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-2.0264e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.051831
Average KL loss: 0.256103
Average total loss: 0.307934
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(6.8546e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.052621
Average KL loss: 0.256103
Average total loss: 0.308723
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-2.2010e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.054800
Average KL loss: 0.256103
Average total loss: 0.310903
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(1.7023e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.052305
Average KL loss: 0.256103
Average total loss: 0.308408
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-1.7970e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.050531
Average KL loss: 0.256103
Average total loss: 0.306634
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-1.2798e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.050034
Average KL loss: 0.256103
Average total loss: 0.306137
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(3.0702e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.048925
Average KL loss: 0.256103
Average total loss: 0.305027
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-1.6635e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.052236
Average KL loss: 0.256102
Average total loss: 0.308339
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(1.8703e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.051698
Average KL loss: 0.256102
Average total loss: 0.307801
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(1.4141e-09, device='cuda:0')
 Percentile value: 0.567266869544983
Non-zero model percentage: 0.7378903031349182%, Non-zero mask percentage: 0.7378903031349182%

--- Pruning Level [22/24]: ---
conv1.weight         | nonzeros =     807 /    1728             ( 46.70%) | total_pruned =     921 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1227 /   36864             (  3.33%) | total_pruned =   35637 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1543 /   36864             (  4.19%) | total_pruned =   35321 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1316 /   36864             (  3.57%) | total_pruned =   35548 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1451 /   36864             (  3.94%) | total_pruned =   35413 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2377 /   73728             (  3.22%) | total_pruned =   71351 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3520 /  147456             (  2.39%) | total_pruned =  143936 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1370 /    8192             ( 16.72%) | total_pruned =    6822 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1808 /  147456             (  1.23%) | total_pruned =  145648 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1707 /  147456             (  1.16%) | total_pruned =  145749 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    5939 /  294912             (  2.01%) | total_pruned =  288973 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      61 /     256             ( 23.83%) | total_pruned =     195 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     166 /     256             ( 64.84%) | total_pruned =      90 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    8059 /  589824             (  1.37%) | total_pruned =  581765 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      78 /     256             ( 30.47%) | total_pruned =     178 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2654 /   32768             (  8.10%) | total_pruned =   30114 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      58 /     256             ( 22.66%) | total_pruned =     198 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      81 /     256             ( 31.64%) | total_pruned =     175 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2964 /  589824             (  0.50%) | total_pruned =  586860 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      61 /     256             ( 23.83%) | total_pruned =     195 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2853 /  589824             (  0.48%) | total_pruned =  586971 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      57 /     256             ( 22.27%) | total_pruned =     199 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   10496 / 1179648             (  0.89%) | total_pruned = 1169152 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      80 /     512             ( 15.62%) | total_pruned =     432 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     390 /     512             ( 76.17%) | total_pruned =     122 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    8763 / 2359296             (  0.37%) | total_pruned = 2350533 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     166 /     512             ( 32.42%) | total_pruned =     346 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2182 /  131072             (  1.66%) | total_pruned =  128890 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     109 /     512             ( 21.29%) | total_pruned =     403 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     454 /     512             ( 88.67%) | total_pruned =      58 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     176 /     512             ( 34.38%) | total_pruned =     336 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    6600 / 2359296             (  0.28%) | total_pruned = 2352696 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      44 /     512             (  8.59%) | total_pruned =     468 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     368 /     512             ( 71.88%) | total_pruned =     144 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      47 /     512             (  9.18%) | total_pruned =     465 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    6702 / 2359296             (  0.28%) | total_pruned = 2352594 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     372 /     512             ( 72.66%) | total_pruned =     140 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
linear.weight        | nonzeros =    1455 /    5120             ( 28.42%) | total_pruned =    3665 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 82487, pruned : 11096275, total: 11178762, Compression rate :     135.52x  ( 99.26% pruned)
Train Epoch: 20/100 Loss: 0.000059 Accuracy: 84.69 100.00 % Best test Accuracy: 84.72%
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-1.3868e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.084444
Average KL loss: 0.251499
Average total loss: 0.335943
tensor(0.0155, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-7.8992e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.088325
Average KL loss: 0.249625
Average total loss: 0.337949
tensor(0.0154, device='cuda:0') tensor(0.0504, device='cuda:0') tensor(-8.3049e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.094164
Average KL loss: 0.249494
Average total loss: 0.343658
tensor(0.0153, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-5.8977e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.083415
Average KL loss: 0.249664
Average total loss: 0.333079
tensor(0.0153, device='cuda:0') tensor(0.0500, device='cuda:0') tensor(-9.5556e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.085281
Average KL loss: 0.249917
Average total loss: 0.335198
tensor(0.0154, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-2.2823e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.082741
Average KL loss: 0.250229
Average total loss: 0.332970
tensor(0.0154, device='cuda:0') tensor(0.0502, device='cuda:0') tensor(-1.0426e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.083475
Average KL loss: 0.250559
Average total loss: 0.334034
tensor(0.0154, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(-5.3516e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.086140
Average KL loss: 0.250865
Average total loss: 0.337005
tensor(0.0154, device='cuda:0') tensor(0.0504, device='cuda:0') tensor(-1.9525e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.079725
Average KL loss: 0.251148
Average total loss: 0.330874
tensor(0.0154, device='cuda:0') tensor(0.0505, device='cuda:0') tensor(-1.0124e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.082775
Average KL loss: 0.251444
Average total loss: 0.334219
tensor(0.0154, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-1.4845e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.076821
Average KL loss: 0.251741
Average total loss: 0.328562
tensor(0.0155, device='cuda:0') tensor(0.0508, device='cuda:0') tensor(-1.0743e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.080504
Average KL loss: 0.251996
Average total loss: 0.332500
tensor(0.0155, device='cuda:0') tensor(0.0509, device='cuda:0') tensor(-1.2061e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.078089
Average KL loss: 0.252219
Average total loss: 0.330308
tensor(0.0155, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(-4.9700e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.079384
Average KL loss: 0.252498
Average total loss: 0.331882
tensor(0.0155, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(-3.7287e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.078787
Average KL loss: 0.252748
Average total loss: 0.331535
tensor(0.0155, device='cuda:0') tensor(0.0513, device='cuda:0') tensor(-9.7740e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.075073
Average KL loss: 0.252973
Average total loss: 0.328046
tensor(0.0155, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(-6.6098e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.073343
Average KL loss: 0.253173
Average total loss: 0.326516
tensor(0.0156, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-1.4916e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.077306
Average KL loss: 0.253419
Average total loss: 0.330724
tensor(0.0156, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-9.7034e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.073617
Average KL loss: 0.253650
Average total loss: 0.327268
tensor(0.0156, device='cuda:0') tensor(0.0518, device='cuda:0') tensor(-3.0803e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.068748
Average KL loss: 0.253825
Average total loss: 0.322574
tensor(0.0156, device='cuda:0') tensor(0.0519, device='cuda:0') tensor(-1.2844e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.070692
Average KL loss: 0.253933
Average total loss: 0.324626
tensor(0.0156, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(1.4579e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.067273
Average KL loss: 0.254070
Average total loss: 0.321343
tensor(0.0156, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(-9.8448e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.064757
Average KL loss: 0.254185
Average total loss: 0.318941
tensor(0.0156, device='cuda:0') tensor(0.0522, device='cuda:0') tensor(-2.9941e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.070087
Average KL loss: 0.254338
Average total loss: 0.324425
tensor(0.0156, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(-2.0172e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.066622
Average KL loss: 0.254477
Average total loss: 0.321099
tensor(0.0157, device='cuda:0') tensor(0.0524, device='cuda:0') tensor(-5.6189e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.068559
Average KL loss: 0.254642
Average total loss: 0.323202
tensor(0.0157, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-1.0193e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.063465
Average KL loss: 0.254795
Average total loss: 0.318261
tensor(0.0157, device='cuda:0') tensor(0.0526, device='cuda:0') tensor(-7.8602e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.067894
Average KL loss: 0.254947
Average total loss: 0.322840
tensor(0.0157, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(-3.7370e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.066173
Average KL loss: 0.255102
Average total loss: 0.321275
tensor(0.0157, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(1.0150e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.068230
Average KL loss: 0.255226
Average total loss: 0.323456
tensor(0.0157, device='cuda:0') tensor(0.0529, device='cuda:0') tensor(-5.5696e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.068787
Average KL loss: 0.255334
Average total loss: 0.324121
tensor(0.0157, device='cuda:0') tensor(0.0530, device='cuda:0') tensor(-1.4321e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.067964
Average KL loss: 0.255469
Average total loss: 0.323433
tensor(0.0157, device='cuda:0') tensor(0.0532, device='cuda:0') tensor(-7.3732e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.063850
Average KL loss: 0.255608
Average total loss: 0.319458
tensor(0.0158, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(-3.1436e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.058949
Average KL loss: 0.255747
Average total loss: 0.314696
tensor(0.0158, device='cuda:0') tensor(0.0534, device='cuda:0') tensor(-7.7812e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.063156
Average KL loss: 0.255848
Average total loss: 0.319004
tensor(0.0158, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(-2.8577e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.059865
Average KL loss: 0.255996
Average total loss: 0.315861
tensor(0.0158, device='cuda:0') tensor(0.0536, device='cuda:0') tensor(-5.3681e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.065040
Average KL loss: 0.256094
Average total loss: 0.321134
tensor(0.0158, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(6.8398e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.060849
Average KL loss: 0.256182
Average total loss: 0.317031
tensor(0.0158, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(2.5491e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.059022
Average KL loss: 0.256250
Average total loss: 0.315272
tensor(0.0158, device='cuda:0') tensor(0.0539, device='cuda:0') tensor(5.7747e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.057115
Average KL loss: 0.256318
Average total loss: 0.313433
tensor(0.0158, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(-1.4450e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.062655
Average KL loss: 0.256377
Average total loss: 0.319032
tensor(0.0158, device='cuda:0') tensor(0.0541, device='cuda:0') tensor(-6.3088e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.062791
Average KL loss: 0.256468
Average total loss: 0.319259
tensor(0.0158, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-7.1338e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.058395
Average KL loss: 0.256549
Average total loss: 0.314944
tensor(0.0159, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-8.5083e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.064156
Average KL loss: 0.256675
Average total loss: 0.320831
tensor(0.0159, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(3.0081e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.060095
Average KL loss: 0.256791
Average total loss: 0.316886
tensor(0.0159, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-4.9423e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.055760
Average KL loss: 0.256840
Average total loss: 0.312600
tensor(0.0159, device='cuda:0') tensor(0.0545, device='cuda:0') tensor(-2.1211e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.059133
Average KL loss: 0.256892
Average total loss: 0.316025
tensor(0.0159, device='cuda:0') tensor(0.0546, device='cuda:0') tensor(-1.1711e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.056788
Average KL loss: 0.256975
Average total loss: 0.313764
tensor(0.0159, device='cuda:0') tensor(0.0547, device='cuda:0') tensor(-1.2154e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.056177
Average KL loss: 0.256987
Average total loss: 0.313164
tensor(0.0159, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(-6.4486e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.058194
Average KL loss: 0.257035
Average total loss: 0.315229
tensor(0.0159, device='cuda:0') tensor(0.0549, device='cuda:0') tensor(-2.0766e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.056602
Average KL loss: 0.257056
Average total loss: 0.313658
tensor(0.0159, device='cuda:0') tensor(0.0550, device='cuda:0') tensor(-2.3858e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.058764
Average KL loss: 0.257093
Average total loss: 0.315856
tensor(0.0159, device='cuda:0') tensor(0.0551, device='cuda:0') tensor(-4.4539e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.056202
Average KL loss: 0.257128
Average total loss: 0.313330
tensor(0.0159, device='cuda:0') tensor(0.0551, device='cuda:0') tensor(1.4304e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.056323
Average KL loss: 0.257116
Average total loss: 0.313439
tensor(0.0159, device='cuda:0') tensor(0.0552, device='cuda:0') tensor(-3.6473e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.056079
Average KL loss: 0.257151
Average total loss: 0.313230
tensor(0.0159, device='cuda:0') tensor(0.0553, device='cuda:0') tensor(-4.8333e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.052770
Average KL loss: 0.257187
Average total loss: 0.309957
tensor(0.0159, device='cuda:0') tensor(0.0554, device='cuda:0') tensor(6.6021e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.053919
Average KL loss: 0.257188
Average total loss: 0.311107
tensor(0.0160, device='cuda:0') tensor(0.0555, device='cuda:0') tensor(-5.5093e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.053899
Average KL loss: 0.257174
Average total loss: 0.311073
tensor(0.0160, device='cuda:0') tensor(0.0555, device='cuda:0') tensor(-6.3165e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.058134
Average KL loss: 0.257193
Average total loss: 0.315327
tensor(0.0160, device='cuda:0') tensor(0.0556, device='cuda:0') tensor(-4.7570e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.054287
Average KL loss: 0.257222
Average total loss: 0.311508
tensor(0.0160, device='cuda:0') tensor(0.0557, device='cuda:0') tensor(-1.1687e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.054919
Average KL loss: 0.257230
Average total loss: 0.312149
tensor(0.0160, device='cuda:0') tensor(0.0558, device='cuda:0') tensor(-7.8399e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.059357
Average KL loss: 0.257302
Average total loss: 0.316658
tensor(0.0160, device='cuda:0') tensor(0.0559, device='cuda:0') tensor(-2.1408e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.051577
Average KL loss: 0.257346
Average total loss: 0.308924
tensor(0.0160, device='cuda:0') tensor(0.0560, device='cuda:0') tensor(1.8143e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.058559
Average KL loss: 0.257354
Average total loss: 0.315913
tensor(0.0160, device='cuda:0') tensor(0.0560, device='cuda:0') tensor(3.9754e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.052406
Average KL loss: 0.257394
Average total loss: 0.309800
tensor(0.0160, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(-6.9068e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.050795
Average KL loss: 0.257346
Average total loss: 0.308141
tensor(0.0160, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-5.6640e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.050647
Average KL loss: 0.257308
Average total loss: 0.307955
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(1.4866e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.052701
Average KL loss: 0.257268
Average total loss: 0.309970
tensor(0.0160, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-1.1090e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.054323
Average KL loss: 0.257312
Average total loss: 0.311636
tensor(0.0160, device='cuda:0') tensor(0.0564, device='cuda:0') tensor(-7.5387e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.051079
Average KL loss: 0.257334
Average total loss: 0.308413
tensor(0.0160, device='cuda:0') tensor(0.0565, device='cuda:0') tensor(-9.0838e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.052977
Average KL loss: 0.257395
Average total loss: 0.310372
tensor(0.0160, device='cuda:0') tensor(0.0566, device='cuda:0') tensor(-6.8365e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.054234
Average KL loss: 0.257438
Average total loss: 0.311672
tensor(0.0160, device='cuda:0') tensor(0.0567, device='cuda:0') tensor(-1.8636e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.052039
Average KL loss: 0.257431
Average total loss: 0.309471
tensor(0.0160, device='cuda:0') tensor(0.0567, device='cuda:0') tensor(-1.3931e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.049613
Average KL loss: 0.257444
Average total loss: 0.307057
tensor(0.0160, device='cuda:0') tensor(0.0568, device='cuda:0') tensor(2.0309e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.052071
Average KL loss: 0.257429
Average total loss: 0.309500
tensor(0.0161, device='cuda:0') tensor(0.0569, device='cuda:0') tensor(3.3097e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.052096
Average KL loss: 0.257436
Average total loss: 0.309532
tensor(0.0161, device='cuda:0') tensor(0.0569, device='cuda:0') tensor(4.3073e-11, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.048514
Average KL loss: 0.257403
Average total loss: 0.305917
tensor(0.0161, device='cuda:0') tensor(0.0570, device='cuda:0') tensor(5.3251e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.051675
Average KL loss: 0.257380
Average total loss: 0.309055
tensor(0.0161, device='cuda:0') tensor(0.0571, device='cuda:0') tensor(-2.1404e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.053341
Average KL loss: 0.257386
Average total loss: 0.310728
tensor(0.0161, device='cuda:0') tensor(0.0572, device='cuda:0') tensor(-2.5929e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.052613
Average KL loss: 0.257405
Average total loss: 0.310018
tensor(0.0161, device='cuda:0') tensor(0.0572, device='cuda:0') tensor(-5.0210e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.053590
Average KL loss: 0.257420
Average total loss: 0.311011
tensor(0.0161, device='cuda:0') tensor(0.0573, device='cuda:0') tensor(-1.6081e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.050420
Average KL loss: 0.257406
Average total loss: 0.307826
tensor(0.0161, device='cuda:0') tensor(0.0574, device='cuda:0') tensor(1.1175e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.050776
Average KL loss: 0.257393
Average total loss: 0.308169
tensor(0.0161, device='cuda:0') tensor(0.0574, device='cuda:0') tensor(-1.4534e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.052681
Average KL loss: 0.257389
Average total loss: 0.310071
tensor(0.0161, device='cuda:0') tensor(0.0575, device='cuda:0') tensor(-3.4897e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.051868
Average KL loss: 0.257445
Average total loss: 0.309314
tensor(0.0161, device='cuda:0') tensor(0.0576, device='cuda:0') tensor(3.8376e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.047309
Average KL loss: 0.257454
Average total loss: 0.304763
tensor(0.0161, device='cuda:0') tensor(0.0577, device='cuda:0') tensor(-1.4931e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.048918
Average KL loss: 0.257395
Average total loss: 0.306313
tensor(0.0161, device='cuda:0') tensor(0.0577, device='cuda:0') tensor(-8.5301e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.050842
Average KL loss: 0.257393
Average total loss: 0.308235
tensor(0.0161, device='cuda:0') tensor(0.0578, device='cuda:0') tensor(-7.6336e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.047028
Average KL loss: 0.257374
Average total loss: 0.304401
tensor(0.0161, device='cuda:0') tensor(0.0579, device='cuda:0') tensor(-1.7578e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.045988
Average KL loss: 0.257323
Average total loss: 0.303311
tensor(0.0161, device='cuda:0') tensor(0.0579, device='cuda:0') tensor(-1.1475e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.049598
Average KL loss: 0.257274
Average total loss: 0.306872
tensor(0.0161, device='cuda:0') tensor(0.0580, device='cuda:0') tensor(2.3273e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.049142
Average KL loss: 0.257250
Average total loss: 0.306392
tensor(0.0161, device='cuda:0') tensor(0.0580, device='cuda:0') tensor(-2.3077e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.048106
Average KL loss: 0.257199
Average total loss: 0.305306
tensor(0.0161, device='cuda:0') tensor(0.0581, device='cuda:0') tensor(-7.3631e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.048186
Average KL loss: 0.257165
Average total loss: 0.305351
tensor(0.0161, device='cuda:0') tensor(0.0582, device='cuda:0') tensor(-6.0639e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.049414
Average KL loss: 0.257173
Average total loss: 0.306587
tensor(0.0161, device='cuda:0') tensor(0.0583, device='cuda:0') tensor(-3.9309e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.047509
Average KL loss: 0.257168
Average total loss: 0.304677
tensor(0.0161, device='cuda:0') tensor(0.0583, device='cuda:0') tensor(-1.4973e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.047063
Average KL loss: 0.257094
Average total loss: 0.304157
tensor(0.0161, device='cuda:0') tensor(0.0584, device='cuda:0') tensor(-2.5588e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.048158
Average KL loss: 0.257091
Average total loss: 0.305249
tensor(0.0161, device='cuda:0') tensor(0.0584, device='cuda:0') tensor(-5.1784e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.046989
Average KL loss: 0.257040
Average total loss: 0.304028
tensor(0.0161, device='cuda:0') tensor(0.0585, device='cuda:0') tensor(-1.5535e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.048208
Average KL loss: 0.257031
Average total loss: 0.305240
tensor(0.0161, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(1.5344e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.047873
Average KL loss: 0.256977
Average total loss: 0.304850
tensor(0.0161, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(-4.7276e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.051379
Average KL loss: 0.256934
Average total loss: 0.308314
tensor(0.0161, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(-2.0759e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.047525
Average KL loss: 0.256929
Average total loss: 0.304454
tensor(0.0161, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(-3.2126e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.049443
Average KL loss: 0.256924
Average total loss: 0.306367
tensor(0.0161, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(1.7028e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.050080
Average KL loss: 0.256917
Average total loss: 0.306997
tensor(0.0161, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(-2.4387e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.049930
Average KL loss: 0.256912
Average total loss: 0.306842
tensor(0.0161, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(-1.1329e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.047700
Average KL loss: 0.256909
Average total loss: 0.304609
tensor(0.0161, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(-1.3166e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.047774
Average KL loss: 0.256903
Average total loss: 0.304677
tensor(0.0161, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(1.1994e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.051793
Average KL loss: 0.256894
Average total loss: 0.308687
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-2.3309e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.048532
Average KL loss: 0.256887
Average total loss: 0.305419
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-1.3197e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.048272
Average KL loss: 0.256879
Average total loss: 0.305151
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-9.8525e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.050760
Average KL loss: 0.256876
Average total loss: 0.307636
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-8.9698e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.049453
Average KL loss: 0.256873
Average total loss: 0.306326
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-2.8737e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.045388
Average KL loss: 0.256873
Average total loss: 0.302261
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(6.0941e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.049906
Average KL loss: 0.256872
Average total loss: 0.306777
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-3.8210e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.048184
Average KL loss: 0.256871
Average total loss: 0.305055
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(1.5592e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.045428
Average KL loss: 0.256870
Average total loss: 0.302298
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-3.7465e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.048306
Average KL loss: 0.256869
Average total loss: 0.305175
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-1.9616e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.049231
Average KL loss: 0.256868
Average total loss: 0.306099
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(1.4603e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.050375
Average KL loss: 0.256868
Average total loss: 0.307243
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-8.1023e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.050812
Average KL loss: 0.256867
Average total loss: 0.307679
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(2.7696e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.046266
Average KL loss: 0.256866
Average total loss: 0.303133
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-9.2266e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.052738
Average KL loss: 0.256866
Average total loss: 0.309604
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(1.5204e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.053054
Average KL loss: 0.256865
Average total loss: 0.309919
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(3.0538e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.048013
Average KL loss: 0.256865
Average total loss: 0.304878
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-3.9920e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.046827
Average KL loss: 0.256865
Average total loss: 0.303692
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(7.9047e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.047880
Average KL loss: 0.256865
Average total loss: 0.304745
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-1.4369e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.044862
Average KL loss: 0.256865
Average total loss: 0.301727
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-2.9892e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.046064
Average KL loss: 0.256865
Average total loss: 0.302929
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(7.9548e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.046663
Average KL loss: 0.256864
Average total loss: 0.303527
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-3.8216e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.051367
Average KL loss: 0.256864
Average total loss: 0.308231
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-7.4934e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.049112
Average KL loss: 0.256864
Average total loss: 0.305977
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(8.6905e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.048435
Average KL loss: 0.256864
Average total loss: 0.305299
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(1.6901e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.049030
Average KL loss: 0.256864
Average total loss: 0.305894
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(8.9851e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.049444
Average KL loss: 0.256864
Average total loss: 0.306308
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-2.4228e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.047746
Average KL loss: 0.256864
Average total loss: 0.304610
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-2.9992e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.049298
Average KL loss: 0.256864
Average total loss: 0.306162
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-6.9508e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.053281
Average KL loss: 0.256864
Average total loss: 0.310145
tensor(0.0161, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-3.2073e-09, device='cuda:0')
 Percentile value: 1.159634041786194
Non-zero model percentage: 0.5903157591819763%, Non-zero mask percentage: 0.5903157591819763%

--- Pruning Level [23/24]: ---
conv1.weight         | nonzeros =     792 /    1728             ( 45.83%) | total_pruned =     936 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1109 /   36864             (  3.01%) | total_pruned =   35755 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1425 /   36864             (  3.87%) | total_pruned =   35439 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1197 /   36864             (  3.25%) | total_pruned =   35667 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1347 /   36864             (  3.65%) | total_pruned =   35517 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2180 /   73728             (  2.96%) | total_pruned =   71548 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3145 /  147456             (  2.13%) | total_pruned =  144311 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1310 /    8192             ( 15.99%) | total_pruned =    6882 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1574 /  147456             (  1.07%) | total_pruned =  145882 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1497 /  147456             (  1.02%) | total_pruned =  145959 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    5288 /  294912             (  1.79%) | total_pruned =  289624 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    7004 /  589824             (  1.19%) | total_pruned =  582820 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      78 /     256             ( 30.47%) | total_pruned =     178 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2459 /   32768             (  7.50%) | total_pruned =   30309 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2404 /  589824             (  0.41%) | total_pruned =  587420 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      57 /     256             ( 22.27%) | total_pruned =     199 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2278 /  589824             (  0.39%) | total_pruned =  587546 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    8802 / 1179648             (  0.75%) | total_pruned = 1170846 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     369 /     512             ( 72.07%) | total_pruned =     143 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    6834 / 2359296             (  0.29%) | total_pruned = 2352462 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     135 /     512             ( 26.37%) | total_pruned =     377 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1887 /  131072             (  1.44%) | total_pruned =  129185 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     446 /     512             ( 87.11%) | total_pruned =      66 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     144 /     512             ( 28.12%) | total_pruned =     368 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3908 / 2359296             (  0.17%) | total_pruned = 2355388 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     362 /     512             ( 70.70%) | total_pruned =     150 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2437 / 2359296             (  0.10%) | total_pruned = 2356859 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     372 /     512             ( 72.66%) | total_pruned =     140 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    1426 /    5120             ( 27.85%) | total_pruned =    3694 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 65990, pruned : 11112772, total: 11178762, Compression rate :     169.40x  ( 99.41% pruned)
Train Epoch: 21/100 Loss: 0.000199 Accuracy: 83.97 100.00 % Best test Accuracy: 84.33%
